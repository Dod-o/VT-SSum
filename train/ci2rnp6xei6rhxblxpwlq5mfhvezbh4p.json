{
    "id": "ci2rnp6xei6rhxblxpwlq5mfhvezbh4p",
    "title": "Traffic Analytics for Linked Data Publishers",
    "info": {
        "author": [
            "Luca Costabello, Fujitsu Ireland"
        ],
        "published": "July 10, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2017_costabello_linked_data/",
    "segmentation": [
        [
            "Alright, now in the in the last year."
        ],
        [
            "In the last years, our community focused on providing techniques, tools and protocols and models to publish data on the web right?",
            "A lot has been done, but what we think is still missing is is something that gives data publishers insight on access traffic to their data sets.",
            "We actually claim that to date Link data publishers have very limited awareness of how Vergara is being accessed by visitors.",
            "Write an innocence.",
            "There is no tool to mine link data.",
            "Servers access logs.",
            "Why?",
            "Why is this important?",
            "You may ask?",
            "Well, knowing which kind of incoming traffic you have may help justify investment in Link data with your management, for example, which is kind of useful thing to do in times of tight budgets.",
            "You may want to act on cost control.",
            "For example, knowing your traffic may help you renegotiating your.",
            "Service layer agreement with your hosting supplier.",
            "Then you can identify abuses.",
            "You can blacklist IPS which abuse your triple store or you have new means to interpret access peaks right?"
        ],
        [
            "But finding a mining information about traffic on your data set has a lot of challenges.",
            "First of all, we need to decide which kind of metrics we want to measure.",
            "So are our conventional web analytics metrics enough, or should we perhaps define link data specific extensions, right?",
            "Once we identify which what we want to measure.",
            "How do we?",
            "How do you extract?",
            "How do we extract to compute such metrics?",
            "Which data sources should we track clients?",
            "Should we just limit to mine server logs?",
            "Then we need to support that you'll data access protocol.",
            "Both HTTP operations on one side, an sparkle queries on the other right?",
            "We need to filter noise, which is a big problem.",
            "We need to detect high session to give a more comprehensive and meaningful overview.",
            "Of incoming traffic and you may also want to try to detect activity peaks in sparkle traffic on your on your server."
        ],
        [
            "What we're trying to do in this work is fundamentally trying to fill a gap in the state of the art, because, well, as you, as you obviously know, there are tools for web analytics, one for all Google Analytics, but none of these works focus sending data specific metrics, right?",
            "Ann, on the other hand, there are papers the which have been published a few years ago which focus on specific link database metrics, but they don't go any further right.",
            "They don't provide a comprehensive platform to extract traffic insights from from data set logs."
        ],
        [
            "So here we come, the contribution that we want to put forward is a traffic analytics platform for linked data servers.",
            "But I will explain and show you in this talk.",
            "I will also describe the kind of metrics that we extract and I will explain how we extract such metrics an I will.",
            "I will focus on how we detect visitor sessions.",
            "And how we try to Gorge sparkle traffic peaks by labeling sparkle, query, source light and heavy and then a few words about the results and about a trial with that we carried out with the bar colleagues in at the British Library."
        ],
        [
            "So the final the final two looks like this.",
            "This is the web UI of our platform and it has a number of dashboards which show the metrics that we extract an the way we extract such information relies on this pipeline."
        ],
        [
            "She is a simplified overview of what we do.",
            "So we start from left to right and we start with data publisher logs which look pretty much like this timestamped records with IP addresses, user agents and requested resources, which may or may not include sparkle queries because we support both HTTP operations, an sparkle queries to link data servers when we have an ETL component with it, which is pretty much standard.",
            "We ingest logs with filter noise.",
            "We extract metrics more on that later on and we put everything in a data warehouse which will feed the web UI that you saw in the previous slide."
        ],
        [
            "Now 2 words on the metrics that we extract."
        ],
        [
            "We had three families of metrics.",
            "This is the first one.",
            "It's called.",
            "We call these measures content metrics.",
            "It's well, it boils down to counting.",
            "How many classes are how many times class property or or graphs have been accessed by visitors, right?",
            "Ann, this is this link data specific because you won't be able to do that with our traditional web analytics tool.",
            "And we then have a number of metrics."
        ],
        [
            "Which are rather protocol oriented so the the dotted red boxes identify metrics which are more link data specific, like counting how many requests we have in HTTP or sparkle, trying to determine the amount of sparkle requests according to Sparkle Verb used, we try to like I said, label Sparkle queries as light or heavy.",
            "More on that later on we can't be free or free patterns.",
            "And we also provide.",
            "The count of malformed queries, which is also kind of useful to know if you're a data publisher.",
            "You may want to tweak about your data set to try to help users consume your data."
        ],
        [
            "This wall of text here you don't need to go for it.",
            "It's just the first family of metrics it's we call them audience metrics.",
            "The link data specific metric, but we added.",
            "Is the language thing we we count?",
            "How many times access the language tag string literals appear in sparkle queries, which is something where perhaps you want to know if you spent a considerable amount of effort in adding these tags in your data set, and then you find out that perhaps no one has ever queried then.",
            "So it's something that you want to have a look at.",
            "We also have other traditional measures like location, network provider, but there is a section in this slide here at the bottom where we have a number of metrics which are based on the on the notion of session right, which brings me."
        ],
        [
            "Two to the next slide where I will try to describe how we."
        ],
        [
            "Detect visitor sessions from visitor access logs.",
            "So first of all we we define a session as a sequence of requests.",
            "HTTP operations or sparkle queries doesn't matter.",
            "Issued with no significant interruptions by a uniquely identified visitor, right?",
            "So our goal here is to try to group these requests together.",
            "Cluster these requests to create sessions right?",
            "And to do so we use.",
            "An off the shelf model, which is a variant of here Erekle Agglomerative clustering proposed few years ago in the community of.",
            "Traditional web log analysis on the web is business model.",
            "Works in is like it's an unsupervised model which is entirely based on.",
            "The temporal dimension.",
            "So it's based on gaps between consecutive requests an it has the big benefit of relying on a visitor specific cut off right, which is very important when you operate in.",
            "This link data specific scenario where you have visitors which come from, well maybe human beings using desktop browsers or semantic web applications.",
            "They have different patterns so we need we need really need visitor specific temporal cut off.",
            "So the way the way Hacs works is very straightforward.",
            "It's a two step procedure.",
            "First, the algorithm identifies the gap, which significantly significantly.",
            "He sees the variance right?",
            "Across all the requests issued for a specific unique visitor and once identified, it groups HTTP or Sparkle requests into sessions.",
            "According to the vet cut off."
        ],
        [
            "Now there was a first data mining activity where we carried out.",
            "We have a second task which is the classification of sparkle queries as heavy or light.",
            "Here the goal was to try to give a rough estimate of the quantity, the amount of heavy and light queries issue 2, two triple store.",
            "So we came up with a very very.",
            "General an well rough if you want definition.",
            "Very informal definition of heavy sparkle query.",
            "So the goal here is by no mean to to enter this.",
            "This area of research which has a large body of works.",
            "We just trying to figure out whether we can with the supervised binary classification approach and using entirely sparkle syntactic teachers we can.",
            "Label queries as light or heavy like this example.",
            "Here we have a query with union with one Union statement, a filter, regular expression evaluation and optional so this is intuitively way."
        ],
        [
            "More complex than the one on top right?",
            "So this is the intuition behind behind this this task."
        ],
        [
            "And."
        ],
        [
            "Do so we rely on feature vectors like I said, which include only syntactic features an we actually experimented with five different groups of features with feature vectors of different length.",
            "These feature vectors include different different features that we extracted from from the sparkle queries in the logs.",
            "Now."
        ],
        [
            "Sure, towards on the results that we that we got first we."
        ],
        [
            "We we worked in close collaboration with the British National Library and they gave us.",
            "They gave us 13 months of access logs to there.",
            "Apple store.",
            "An we had pretty much around, roughly around 10 million requests per month, so we have a quite significant corpus of data, but to ensure reproducible results we also run experiments on the PDF reader 9 access log so that if you want to rerun what we did, you will get pretty much same results.",
            "I would start with."
        ],
        [
            "Describing what what happened when we try to evaluate the session detection task.",
            "So the goal was to detect the beginning of a new session right?",
            "And So what we did first of all was to build the data set.",
            "So we took the anonymized queries from the British Library data sets we took frequently.",
            "Consecutive days came up with 16,000 HTTP requests or Sparkle requests, 2/3 of which were generated by.",
            "Semantic web applications.",
            "An and then we manually annotated the beginning of each of each session, right?",
            "And the goal was to detect whether we were good at detecting this.",
            "The beginning of Ave section.",
            "An an we found out we compared our performance with the with what we have performance of three baselines that rely on fixed length cut offs.",
            "30 and 60 minutes.",
            "And what we find out is that Hacs outperforms fixed length cut off, which is an interesting result.",
            "Anne."
        ],
        [
            "Then we are obviously try to evaluate the binary classifier for sparkle.",
            "So in this case we relied on the PDF, read online access logs.",
            "But because we don't have running time execution times in logs, we had to re run these queries again and we did so on a local clone of DB pedia.",
            "We run multiple times the queries, we shuffle them and we just kept.",
            "We kept the eventually 3700 queries, the ones with low variance and we of course work with the mean execution time.",
            "As you can see from here, the big data set is unbalanced 'cause it was kind of harder and trickier to find heavy queries.",
            "They are of course less present and then like queries.",
            "At some stage of this stage we had to manually annotate the queries as light or heavy.",
            "So by discussing with the partners are British Library, we decided that in this context for this specific data set in this setting, it was reasonable to consider that 100 milliseconds was was the cutoff threshold.",
            "That divides light from from heavy queries, this is.",
            "This is of course.",
            "Uh, it may vary, or it's obviously a user defined parameter, so every time we deploy the application on different data set, we can play with different values for discard threshold which will influence of course final results.",
            "Ben, we labeled query size light or heavy and then we run off shells, binary classifiers.",
            "We play with multinomial naive Bayes and support support vector machine classifiers, model selection with great search over a number of hyperparameters, randomized search and well 10 fold cross validation.",
            "Pretty standard setting an we end up with."
        ],
        [
            "And F1 measure for the support vector classifier of .91, which is fairly good.",
            "All in all we are very good at detecting light queries both in terms of precision and recall.",
            "In terms of when it comes to to detect to label heavy queries, we are fairly good up in terms of precision, less less code in terms of recall a little bit better with Nate Base, but here there is a bit of room to improve our results an we also try to play with different feature vectors.",
            "I showed you the five groups in a few slides before an we ended up by.",
            "Showing that the best result are obtained with all the features that we listed previously an we get value of area under the precision recall curve or .67 reason they use PR.",
            "AUC is that classes are unbalanced, so this is a fairer.",
            "Metric, right?"
        ],
        [
            "Now."
        ],
        [
            "2 words on what we actually find on those 13 months of access logs.",
            "First of all, this was quite astonishing, but less than 1% of those records where genuine semantic web traffic, all the rest, was noise crawlers, search engines and so that was quite a quite a shock.",
            "An out of those .6% we nevertheless noticed 30% increase in traffic over over the 13 months, which is good.",
            "We, we all we saw, we noticed a 100 fold increase in requests from software libraries, which is interesting.",
            "Anwell sparkle accounts for 30% of requests.",
            "6% of those were labeled as heavy.",
            "And then we saw that 37 days had like big Peaks, unusual peaks of traffic.",
            "So perhaps something went wrong.",
            "Bounce rate it means that roughly half of the users that visited never came back, and then, well, software libraries had bigger, deeper and longer session.",
            "So in an."
        ],
        [
            "We leave publishers from manual and time consuming access log mining, which is nice.",
            "We support thing data specific metrics, but you won't find in traditional tools we reconstruct link data visitor sessions and we classify queries according to their sparkles syntax.",
            "Um?",
            "We will work."
        ],
        [
            "In the future, or of on providing statistics on on noise which we just discard for now.",
            "An well will try to refine a bit the feature for the heavy like classifier.",
            "Also will try to.",
            "See the approach generalizes buying, adding.",
            "Queries from from other sources to get a more diverse training set right.",
            "Ann will try to go beyond time based detection for sessions.",
            "We try to add a bit of content based heuristics to see if we get better results.",
            "Now I am almost done.",
            "Just last thing, there is a public."
        ],
        [
            "Demo published at this address so please check it out if you want to play with that a bit.",
            "the British Library was kind enough to disclose one month of traffic logs, So what you will see there is actually one month worth of data.",
            "You can play a bit with the UI that we developed an well.",
            "If you want to know more please keep in touch.",
            "Just shoot me an email, thanks.",
            "OK, do you take into account also the result set of sparkle queries for both logging and the classification of queries?",
            "We don't.",
            "It's the approach is entirely based on Sparkle syntax.",
            "When to be fair, also sparkled algebra.",
            "So we take queries and we for example we extract a number of joins in the query, but it's entirely based on.",
            "Entirely based on Sparkle syntax and which is why to date we need to train the model on each different data sets that we want to work with.",
            "'cause we we haven't tried yet to train the model on more diverse data set so that the approach we haven't showed yet that we approach generalizes.",
            "Hi there, very interesting talk, thank you.",
            "I'm curious if you have any guesses or insights into the unusual days that you saw.",
            "Did the unusual activity tend to come from the same IP for example, or did it come from many different ones?",
            "Yeah, I I have a funny story actually.",
            "Hi, I didn't put it in the in the slides but for example we saw that one.",
            "They had this big peak.",
            "We had like 50,000 heavy sparkle queries all concentrated in one hour right and we said and this is really something wrong right?",
            "So and no one actually realized that before mining the data we were to LAN.",
            "We found out that.",
            "It was basically most probably a client application, semantic web, little application written in Java.",
            "User Agent was Java.",
            "Anyway, an requests were coming from the same IP address so and they were pretty much the same request with only few.",
            "Throughput patterns changing, so perhaps it was something some sort of for loop.",
            "Bugging an application an and so well, this sort of this sort of tool will help you.",
            "Find detect these sort of problems.",
            "You may want to blacklist certain addresses, for example, but in general, no.",
            "We we we saw that there is a lot of dirt coming from.",
            "Malicious, our sources, and so we we suggested to blacklist a number of IP addresses ranges.",
            "Yeah, thank you.",
            "OK, we have another question here.",
            "Hi, so do you consider also to try to compare with the more declarative approach, maybe from metric temporal logic?",
            "Or 10 projects are used in the world of log log analysis as well, which allows you to track the collective.",
            "Though they don't learn the chunking of the log, but you have to declare it in the language for which task.",
            "Sorry for the definition of the different portion of the log to extract information.",
            "No, we haven't think of that.",
            "We had in total that yeah there must be.",
            "There could be an extension yet.",
            "Any other question?",
            "OK, another question.",
            "Actually it's a curiosity.",
            "How do you deal with 303?",
            "Redir intern, how do you check the atomic city of this kind of request?",
            "Yeah?",
            "I mean it is a longer of debate in the community about with directs how to do so that we will we will.",
            "We simply do is just tracking the numbers off your three patterns.",
            "This is what we simply do.",
            "But if you try to do so with an official tool, sometimes you may.",
            "I have wrong results because the first the first request may be counted twice, so statistics would be would be wrong.",
            "So now we take that into account, of course yeah.",
            "Let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, now in the in the last year.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the last years, our community focused on providing techniques, tools and protocols and models to publish data on the web right?",
                    "label": 0
                },
                {
                    "sent": "A lot has been done, but what we think is still missing is is something that gives data publishers insight on access traffic to their data sets.",
                    "label": 0
                },
                {
                    "sent": "We actually claim that to date Link data publishers have very limited awareness of how Vergara is being accessed by visitors.",
                    "label": 1
                },
                {
                    "sent": "Write an innocence.",
                    "label": 1
                },
                {
                    "sent": "There is no tool to mine link data.",
                    "label": 0
                },
                {
                    "sent": "Servers access logs.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Why is this important?",
                    "label": 0
                },
                {
                    "sent": "You may ask?",
                    "label": 0
                },
                {
                    "sent": "Well, knowing which kind of incoming traffic you have may help justify investment in Link data with your management, for example, which is kind of useful thing to do in times of tight budgets.",
                    "label": 0
                },
                {
                    "sent": "You may want to act on cost control.",
                    "label": 0
                },
                {
                    "sent": "For example, knowing your traffic may help you renegotiating your.",
                    "label": 1
                },
                {
                    "sent": "Service layer agreement with your hosting supplier.",
                    "label": 0
                },
                {
                    "sent": "Then you can identify abuses.",
                    "label": 0
                },
                {
                    "sent": "You can blacklist IPS which abuse your triple store or you have new means to interpret access peaks right?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But finding a mining information about traffic on your data set has a lot of challenges.",
                    "label": 0
                },
                {
                    "sent": "First of all, we need to decide which kind of metrics we want to measure.",
                    "label": 0
                },
                {
                    "sent": "So are our conventional web analytics metrics enough, or should we perhaps define link data specific extensions, right?",
                    "label": 1
                },
                {
                    "sent": "Once we identify which what we want to measure.",
                    "label": 0
                },
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "How do you extract?",
                    "label": 1
                },
                {
                    "sent": "How do we extract to compute such metrics?",
                    "label": 1
                },
                {
                    "sent": "Which data sources should we track clients?",
                    "label": 1
                },
                {
                    "sent": "Should we just limit to mine server logs?",
                    "label": 0
                },
                {
                    "sent": "Then we need to support that you'll data access protocol.",
                    "label": 1
                },
                {
                    "sent": "Both HTTP operations on one side, an sparkle queries on the other right?",
                    "label": 0
                },
                {
                    "sent": "We need to filter noise, which is a big problem.",
                    "label": 0
                },
                {
                    "sent": "We need to detect high session to give a more comprehensive and meaningful overview.",
                    "label": 0
                },
                {
                    "sent": "Of incoming traffic and you may also want to try to detect activity peaks in sparkle traffic on your on your server.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we're trying to do in this work is fundamentally trying to fill a gap in the state of the art, because, well, as you, as you obviously know, there are tools for web analytics, one for all Google Analytics, but none of these works focus sending data specific metrics, right?",
                    "label": 1
                },
                {
                    "sent": "Ann, on the other hand, there are papers the which have been published a few years ago which focus on specific link database metrics, but they don't go any further right.",
                    "label": 0
                },
                {
                    "sent": "They don't provide a comprehensive platform to extract traffic insights from from data set logs.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we come, the contribution that we want to put forward is a traffic analytics platform for linked data servers.",
                    "label": 1
                },
                {
                    "sent": "But I will explain and show you in this talk.",
                    "label": 0
                },
                {
                    "sent": "I will also describe the kind of metrics that we extract and I will explain how we extract such metrics an I will.",
                    "label": 1
                },
                {
                    "sent": "I will focus on how we detect visitor sessions.",
                    "label": 0
                },
                {
                    "sent": "And how we try to Gorge sparkle traffic peaks by labeling sparkle, query, source light and heavy and then a few words about the results and about a trial with that we carried out with the bar colleagues in at the British Library.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the final the final two looks like this.",
                    "label": 0
                },
                {
                    "sent": "This is the web UI of our platform and it has a number of dashboards which show the metrics that we extract an the way we extract such information relies on this pipeline.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She is a simplified overview of what we do.",
                    "label": 0
                },
                {
                    "sent": "So we start from left to right and we start with data publisher logs which look pretty much like this timestamped records with IP addresses, user agents and requested resources, which may or may not include sparkle queries because we support both HTTP operations, an sparkle queries to link data servers when we have an ETL component with it, which is pretty much standard.",
                    "label": 0
                },
                {
                    "sent": "We ingest logs with filter noise.",
                    "label": 0
                },
                {
                    "sent": "We extract metrics more on that later on and we put everything in a data warehouse which will feed the web UI that you saw in the previous slide.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now 2 words on the metrics that we extract.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We had three families of metrics.",
                    "label": 0
                },
                {
                    "sent": "This is the first one.",
                    "label": 0
                },
                {
                    "sent": "It's called.",
                    "label": 0
                },
                {
                    "sent": "We call these measures content metrics.",
                    "label": 0
                },
                {
                    "sent": "It's well, it boils down to counting.",
                    "label": 0
                },
                {
                    "sent": "How many classes are how many times class property or or graphs have been accessed by visitors, right?",
                    "label": 0
                },
                {
                    "sent": "Ann, this is this link data specific because you won't be able to do that with our traditional web analytics tool.",
                    "label": 0
                },
                {
                    "sent": "And we then have a number of metrics.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which are rather protocol oriented so the the dotted red boxes identify metrics which are more link data specific, like counting how many requests we have in HTTP or sparkle, trying to determine the amount of sparkle requests according to Sparkle Verb used, we try to like I said, label Sparkle queries as light or heavy.",
                    "label": 0
                },
                {
                    "sent": "More on that later on we can't be free or free patterns.",
                    "label": 0
                },
                {
                    "sent": "And we also provide.",
                    "label": 0
                },
                {
                    "sent": "The count of malformed queries, which is also kind of useful to know if you're a data publisher.",
                    "label": 0
                },
                {
                    "sent": "You may want to tweak about your data set to try to help users consume your data.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This wall of text here you don't need to go for it.",
                    "label": 0
                },
                {
                    "sent": "It's just the first family of metrics it's we call them audience metrics.",
                    "label": 0
                },
                {
                    "sent": "The link data specific metric, but we added.",
                    "label": 0
                },
                {
                    "sent": "Is the language thing we we count?",
                    "label": 0
                },
                {
                    "sent": "How many times access the language tag string literals appear in sparkle queries, which is something where perhaps you want to know if you spent a considerable amount of effort in adding these tags in your data set, and then you find out that perhaps no one has ever queried then.",
                    "label": 0
                },
                {
                    "sent": "So it's something that you want to have a look at.",
                    "label": 0
                },
                {
                    "sent": "We also have other traditional measures like location, network provider, but there is a section in this slide here at the bottom where we have a number of metrics which are based on the on the notion of session right, which brings me.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two to the next slide where I will try to describe how we.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detect visitor sessions from visitor access logs.",
                    "label": 1
                },
                {
                    "sent": "So first of all we we define a session as a sequence of requests.",
                    "label": 0
                },
                {
                    "sent": "HTTP operations or sparkle queries doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Issued with no significant interruptions by a uniquely identified visitor, right?",
                    "label": 0
                },
                {
                    "sent": "So our goal here is to try to group these requests together.",
                    "label": 0
                },
                {
                    "sent": "Cluster these requests to create sessions right?",
                    "label": 0
                },
                {
                    "sent": "And to do so we use.",
                    "label": 0
                },
                {
                    "sent": "An off the shelf model, which is a variant of here Erekle Agglomerative clustering proposed few years ago in the community of.",
                    "label": 0
                },
                {
                    "sent": "Traditional web log analysis on the web is business model.",
                    "label": 0
                },
                {
                    "sent": "Works in is like it's an unsupervised model which is entirely based on.",
                    "label": 0
                },
                {
                    "sent": "The temporal dimension.",
                    "label": 0
                },
                {
                    "sent": "So it's based on gaps between consecutive requests an it has the big benefit of relying on a visitor specific cut off right, which is very important when you operate in.",
                    "label": 0
                },
                {
                    "sent": "This link data specific scenario where you have visitors which come from, well maybe human beings using desktop browsers or semantic web applications.",
                    "label": 0
                },
                {
                    "sent": "They have different patterns so we need we need really need visitor specific temporal cut off.",
                    "label": 0
                },
                {
                    "sent": "So the way the way Hacs works is very straightforward.",
                    "label": 0
                },
                {
                    "sent": "It's a two step procedure.",
                    "label": 0
                },
                {
                    "sent": "First, the algorithm identifies the gap, which significantly significantly.",
                    "label": 0
                },
                {
                    "sent": "He sees the variance right?",
                    "label": 0
                },
                {
                    "sent": "Across all the requests issued for a specific unique visitor and once identified, it groups HTTP or Sparkle requests into sessions.",
                    "label": 0
                },
                {
                    "sent": "According to the vet cut off.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there was a first data mining activity where we carried out.",
                    "label": 0
                },
                {
                    "sent": "We have a second task which is the classification of sparkle queries as heavy or light.",
                    "label": 0
                },
                {
                    "sent": "Here the goal was to try to give a rough estimate of the quantity, the amount of heavy and light queries issue 2, two triple store.",
                    "label": 0
                },
                {
                    "sent": "So we came up with a very very.",
                    "label": 0
                },
                {
                    "sent": "General an well rough if you want definition.",
                    "label": 0
                },
                {
                    "sent": "Very informal definition of heavy sparkle query.",
                    "label": 0
                },
                {
                    "sent": "So the goal here is by no mean to to enter this.",
                    "label": 0
                },
                {
                    "sent": "This area of research which has a large body of works.",
                    "label": 0
                },
                {
                    "sent": "We just trying to figure out whether we can with the supervised binary classification approach and using entirely sparkle syntactic teachers we can.",
                    "label": 0
                },
                {
                    "sent": "Label queries as light or heavy like this example.",
                    "label": 0
                },
                {
                    "sent": "Here we have a query with union with one Union statement, a filter, regular expression evaluation and optional so this is intuitively way.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More complex than the one on top right?",
                    "label": 0
                },
                {
                    "sent": "So this is the intuition behind behind this this task.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do so we rely on feature vectors like I said, which include only syntactic features an we actually experimented with five different groups of features with feature vectors of different length.",
                    "label": 1
                },
                {
                    "sent": "These feature vectors include different different features that we extracted from from the sparkle queries in the logs.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sure, towards on the results that we that we got first we.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We we worked in close collaboration with the British National Library and they gave us.",
                    "label": 0
                },
                {
                    "sent": "They gave us 13 months of access logs to there.",
                    "label": 0
                },
                {
                    "sent": "Apple store.",
                    "label": 0
                },
                {
                    "sent": "An we had pretty much around, roughly around 10 million requests per month, so we have a quite significant corpus of data, but to ensure reproducible results we also run experiments on the PDF reader 9 access log so that if you want to rerun what we did, you will get pretty much same results.",
                    "label": 0
                },
                {
                    "sent": "I would start with.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Describing what what happened when we try to evaluate the session detection task.",
                    "label": 0
                },
                {
                    "sent": "So the goal was to detect the beginning of a new session right?",
                    "label": 0
                },
                {
                    "sent": "And So what we did first of all was to build the data set.",
                    "label": 0
                },
                {
                    "sent": "So we took the anonymized queries from the British Library data sets we took frequently.",
                    "label": 0
                },
                {
                    "sent": "Consecutive days came up with 16,000 HTTP requests or Sparkle requests, 2/3 of which were generated by.",
                    "label": 0
                },
                {
                    "sent": "Semantic web applications.",
                    "label": 0
                },
                {
                    "sent": "An and then we manually annotated the beginning of each of each session, right?",
                    "label": 0
                },
                {
                    "sent": "And the goal was to detect whether we were good at detecting this.",
                    "label": 0
                },
                {
                    "sent": "The beginning of Ave section.",
                    "label": 0
                },
                {
                    "sent": "An an we found out we compared our performance with the with what we have performance of three baselines that rely on fixed length cut offs.",
                    "label": 0
                },
                {
                    "sent": "30 and 60 minutes.",
                    "label": 0
                },
                {
                    "sent": "And what we find out is that Hacs outperforms fixed length cut off, which is an interesting result.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we are obviously try to evaluate the binary classifier for sparkle.",
                    "label": 0
                },
                {
                    "sent": "So in this case we relied on the PDF, read online access logs.",
                    "label": 0
                },
                {
                    "sent": "But because we don't have running time execution times in logs, we had to re run these queries again and we did so on a local clone of DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We run multiple times the queries, we shuffle them and we just kept.",
                    "label": 0
                },
                {
                    "sent": "We kept the eventually 3700 queries, the ones with low variance and we of course work with the mean execution time.",
                    "label": 0
                },
                {
                    "sent": "As you can see from here, the big data set is unbalanced 'cause it was kind of harder and trickier to find heavy queries.",
                    "label": 0
                },
                {
                    "sent": "They are of course less present and then like queries.",
                    "label": 0
                },
                {
                    "sent": "At some stage of this stage we had to manually annotate the queries as light or heavy.",
                    "label": 0
                },
                {
                    "sent": "So by discussing with the partners are British Library, we decided that in this context for this specific data set in this setting, it was reasonable to consider that 100 milliseconds was was the cutoff threshold.",
                    "label": 0
                },
                {
                    "sent": "That divides light from from heavy queries, this is.",
                    "label": 0
                },
                {
                    "sent": "This is of course.",
                    "label": 0
                },
                {
                    "sent": "Uh, it may vary, or it's obviously a user defined parameter, so every time we deploy the application on different data set, we can play with different values for discard threshold which will influence of course final results.",
                    "label": 0
                },
                {
                    "sent": "Ben, we labeled query size light or heavy and then we run off shells, binary classifiers.",
                    "label": 0
                },
                {
                    "sent": "We play with multinomial naive Bayes and support support vector machine classifiers, model selection with great search over a number of hyperparameters, randomized search and well 10 fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "Pretty standard setting an we end up with.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And F1 measure for the support vector classifier of .91, which is fairly good.",
                    "label": 0
                },
                {
                    "sent": "All in all we are very good at detecting light queries both in terms of precision and recall.",
                    "label": 0
                },
                {
                    "sent": "In terms of when it comes to to detect to label heavy queries, we are fairly good up in terms of precision, less less code in terms of recall a little bit better with Nate Base, but here there is a bit of room to improve our results an we also try to play with different feature vectors.",
                    "label": 0
                },
                {
                    "sent": "I showed you the five groups in a few slides before an we ended up by.",
                    "label": 0
                },
                {
                    "sent": "Showing that the best result are obtained with all the features that we listed previously an we get value of area under the precision recall curve or .67 reason they use PR.",
                    "label": 0
                },
                {
                    "sent": "AUC is that classes are unbalanced, so this is a fairer.",
                    "label": 0
                },
                {
                    "sent": "Metric, right?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "2 words on what we actually find on those 13 months of access logs.",
                    "label": 0
                },
                {
                    "sent": "First of all, this was quite astonishing, but less than 1% of those records where genuine semantic web traffic, all the rest, was noise crawlers, search engines and so that was quite a quite a shock.",
                    "label": 0
                },
                {
                    "sent": "An out of those .6% we nevertheless noticed 30% increase in traffic over over the 13 months, which is good.",
                    "label": 1
                },
                {
                    "sent": "We, we all we saw, we noticed a 100 fold increase in requests from software libraries, which is interesting.",
                    "label": 1
                },
                {
                    "sent": "Anwell sparkle accounts for 30% of requests.",
                    "label": 0
                },
                {
                    "sent": "6% of those were labeled as heavy.",
                    "label": 0
                },
                {
                    "sent": "And then we saw that 37 days had like big Peaks, unusual peaks of traffic.",
                    "label": 0
                },
                {
                    "sent": "So perhaps something went wrong.",
                    "label": 1
                },
                {
                    "sent": "Bounce rate it means that roughly half of the users that visited never came back, and then, well, software libraries had bigger, deeper and longer session.",
                    "label": 0
                },
                {
                    "sent": "So in an.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We leave publishers from manual and time consuming access log mining, which is nice.",
                    "label": 0
                },
                {
                    "sent": "We support thing data specific metrics, but you won't find in traditional tools we reconstruct link data visitor sessions and we classify queries according to their sparkles syntax.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We will work.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the future, or of on providing statistics on on noise which we just discard for now.",
                    "label": 0
                },
                {
                    "sent": "An well will try to refine a bit the feature for the heavy like classifier.",
                    "label": 0
                },
                {
                    "sent": "Also will try to.",
                    "label": 0
                },
                {
                    "sent": "See the approach generalizes buying, adding.",
                    "label": 0
                },
                {
                    "sent": "Queries from from other sources to get a more diverse training set right.",
                    "label": 0
                },
                {
                    "sent": "Ann will try to go beyond time based detection for sessions.",
                    "label": 0
                },
                {
                    "sent": "We try to add a bit of content based heuristics to see if we get better results.",
                    "label": 0
                },
                {
                    "sent": "Now I am almost done.",
                    "label": 0
                },
                {
                    "sent": "Just last thing, there is a public.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Demo published at this address so please check it out if you want to play with that a bit.",
                    "label": 0
                },
                {
                    "sent": "the British Library was kind enough to disclose one month of traffic logs, So what you will see there is actually one month worth of data.",
                    "label": 0
                },
                {
                    "sent": "You can play a bit with the UI that we developed an well.",
                    "label": 0
                },
                {
                    "sent": "If you want to know more please keep in touch.",
                    "label": 0
                },
                {
                    "sent": "Just shoot me an email, thanks.",
                    "label": 0
                },
                {
                    "sent": "OK, do you take into account also the result set of sparkle queries for both logging and the classification of queries?",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "It's the approach is entirely based on Sparkle syntax.",
                    "label": 0
                },
                {
                    "sent": "When to be fair, also sparkled algebra.",
                    "label": 0
                },
                {
                    "sent": "So we take queries and we for example we extract a number of joins in the query, but it's entirely based on.",
                    "label": 0
                },
                {
                    "sent": "Entirely based on Sparkle syntax and which is why to date we need to train the model on each different data sets that we want to work with.",
                    "label": 0
                },
                {
                    "sent": "'cause we we haven't tried yet to train the model on more diverse data set so that the approach we haven't showed yet that we approach generalizes.",
                    "label": 0
                },
                {
                    "sent": "Hi there, very interesting talk, thank you.",
                    "label": 0
                },
                {
                    "sent": "I'm curious if you have any guesses or insights into the unusual days that you saw.",
                    "label": 0
                },
                {
                    "sent": "Did the unusual activity tend to come from the same IP for example, or did it come from many different ones?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I I have a funny story actually.",
                    "label": 0
                },
                {
                    "sent": "Hi, I didn't put it in the in the slides but for example we saw that one.",
                    "label": 0
                },
                {
                    "sent": "They had this big peak.",
                    "label": 0
                },
                {
                    "sent": "We had like 50,000 heavy sparkle queries all concentrated in one hour right and we said and this is really something wrong right?",
                    "label": 0
                },
                {
                    "sent": "So and no one actually realized that before mining the data we were to LAN.",
                    "label": 0
                },
                {
                    "sent": "We found out that.",
                    "label": 0
                },
                {
                    "sent": "It was basically most probably a client application, semantic web, little application written in Java.",
                    "label": 0
                },
                {
                    "sent": "User Agent was Java.",
                    "label": 0
                },
                {
                    "sent": "Anyway, an requests were coming from the same IP address so and they were pretty much the same request with only few.",
                    "label": 0
                },
                {
                    "sent": "Throughput patterns changing, so perhaps it was something some sort of for loop.",
                    "label": 0
                },
                {
                    "sent": "Bugging an application an and so well, this sort of this sort of tool will help you.",
                    "label": 0
                },
                {
                    "sent": "Find detect these sort of problems.",
                    "label": 0
                },
                {
                    "sent": "You may want to blacklist certain addresses, for example, but in general, no.",
                    "label": 0
                },
                {
                    "sent": "We we we saw that there is a lot of dirt coming from.",
                    "label": 0
                },
                {
                    "sent": "Malicious, our sources, and so we we suggested to blacklist a number of IP addresses ranges.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, we have another question here.",
                    "label": 0
                },
                {
                    "sent": "Hi, so do you consider also to try to compare with the more declarative approach, maybe from metric temporal logic?",
                    "label": 0
                },
                {
                    "sent": "Or 10 projects are used in the world of log log analysis as well, which allows you to track the collective.",
                    "label": 0
                },
                {
                    "sent": "Though they don't learn the chunking of the log, but you have to declare it in the language for which task.",
                    "label": 0
                },
                {
                    "sent": "Sorry for the definition of the different portion of the log to extract information.",
                    "label": 0
                },
                {
                    "sent": "No, we haven't think of that.",
                    "label": 0
                },
                {
                    "sent": "We had in total that yeah there must be.",
                    "label": 0
                },
                {
                    "sent": "There could be an extension yet.",
                    "label": 0
                },
                {
                    "sent": "Any other question?",
                    "label": 0
                },
                {
                    "sent": "OK, another question.",
                    "label": 0
                },
                {
                    "sent": "Actually it's a curiosity.",
                    "label": 0
                },
                {
                    "sent": "How do you deal with 303?",
                    "label": 0
                },
                {
                    "sent": "Redir intern, how do you check the atomic city of this kind of request?",
                    "label": 0
                },
                {
                    "sent": "Yeah?",
                    "label": 0
                },
                {
                    "sent": "I mean it is a longer of debate in the community about with directs how to do so that we will we will.",
                    "label": 0
                },
                {
                    "sent": "We simply do is just tracking the numbers off your three patterns.",
                    "label": 0
                },
                {
                    "sent": "This is what we simply do.",
                    "label": 0
                },
                {
                    "sent": "But if you try to do so with an official tool, sometimes you may.",
                    "label": 0
                },
                {
                    "sent": "I have wrong results because the first the first request may be counted twice, so statistics would be would be wrong.",
                    "label": 0
                },
                {
                    "sent": "So now we take that into account, of course yeah.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}