{
    "id": "v75sjpf63ikqhfhvtcoxx5wbupscvi46",
    "title": "How to Grow a Mind: Statistics, Structure and Abstraction",
    "info": {
        "author": [
            "Joshua B. Tenenbaum, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 17, 2012",
        "recorded": "July 2012",
        "category": [
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Sociology->Social Sciences Methodology and Statistics",
            "Top->Mathematics->Statistics",
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/aaai2012_tenenbaum_grow_mind/",
    "segmentation": [
        [
            "It's a great honor to be here.",
            "I think I might be able to compress some of the introduction to my talk, but 'cause I think you summed up very well what I want.",
            "Why I'm here and what I'm trying to achieve.",
            "Let me start off just by acknowledging the people who."
        ],
        [
            "Did the work and thought many if not most or even close to all of the really good ideas here.",
            "These are junior researchers have worked with who over the years are now gone on to become rather senior themselves.",
            "Tom Griffiths and Charles Camp were two of the first students who work with me there.",
            "Now faculty at Berkeley and CMU respectively and their work is sort of very very much.",
            "The first part of this talk and they're thinking is deeply interlaced throughout it.",
            "Noah Goodman and the Kashman Sinka, or more recent alumni of our group Noah is now a professor at Stanford.",
            "Akash is a research scientist at MIT and they played the lead role on the key idea that I'm most excited about.",
            "Sort of what I hope will be the climax here.",
            "This notion of probabilistic programs.",
            "And then I want to highlight a few other researchers, Dan Ryan.",
            "Cameron Freer, who have been doing some really interesting theoretical work and helped me think about some of the connections between probabilistic programs, their role in cognitive modeling and Turing's original vision for AI.",
            "Because of course in this year, that's what everybody has to think about rightfully so.",
            "And then researchers who are currently in our group have done that.",
            "Taking the lead on the main modeling and experimental projects, Peter Battalia, Chris Baker, Toma Roman and Steve to see.",
            "Actually Steve recently graduated."
        ],
        [
            "So the goal here the way I like to think of what I'm trying to do, is reverse engineering the mind.",
            "I'm trying to understand human cognition.",
            "If I had to choose you MI a cognitive scientist or an AI researcher, I'm I'm a cognitive scientist first and foremost, but the kind of science we're trying to do is a reverse engineering enterprise.",
            "We want to understand how the mind works in the same kinds of terms that you would use to build an intelligent system.",
            "Some some kind of human like intelligence in a machine, and we do AI research and other related work in machine learning, partly for its practical benefit, but partly as it may be.",
            "Most deeply, as a proof of principle, to show these ideas, these engineering ideas that we think explain how natural intelligence works actually work.",
            "It's rather surprising if you look at how many models, theories, informal and formal accounts that have been proposed over the years in cognitive science or psychology don't actually work as engineering solutions, and that's central to what we think counts as adequate science here.",
            "Yeah, as Bart mentioned, the fields of cognitive science and AI have grew up together starting in say, the 1950s, and I would say by the 1980s were largely growing apart.",
            "Cognitive scientists looked at AI and saw field of people who are increasingly just focused on practical applications had given up the big vision of real and human like intelligence, and we're using a lot of math they didn't understand, and AI researchers looked at cognitive scientists and other psychologists and Sodom obsessed with strange, peculiar processing details that didn't really seem to illuminate those big questions anyway.",
            "And you know, we're very fuzzy and didn't understand any of the math that they should be using now.",
            "These fields are starting to come back together.",
            "It's a very exciting time driven by the shared sense that actually they might have something to say to each other.",
            "Again, Anna, common language.",
            "Really, that's quite fundamental.",
            "A common language in which to say it.",
            "If you had to say where does this start from?",
            "Let's start from success."
        ],
        [
            "AI has been a success or we're living in an era of real AI successes.",
            "Maybe that's a better way to put it.",
            "Certainly this conference highlighted some of these successes we're all familiar with them in our daily lives.",
            "You know, even those.",
            "Even if we weren't, all AI professionals here, you can actually read about working AI technologies in the newspaper.",
            "See them on TV.",
            "Use them in your daily life.",
            "And these are technologies that the early founders of the field.",
            "Whatever the big vision they had, they would have to have been impressed, right?",
            "Clearly?",
            "These are successes.",
            "These systems, whether it's Google face recognition, pedestrian recognition systems, various kinds of recommendation systems, things like you know these, Siri, the new Voice interface to the iPhone, which works at least some of the time, maybe most prominently in the news.",
            "IBM's Watson Jeopardy playing system or after this morning.",
            "I definitely have to add Google's self driving cars.",
            "I mean who couldn't have failed to be impressed by these amazing things.",
            "And if we have to say well what's driving them, maybe the sort of one word.",
            "One phrase story is something like statistics, statistics on the grand scale, massive data coming in through all kinds of sensors, and then various kinds of sophisticated ways of finding patterns in that data, clusters, correlations, low dimensional structure, maybe even something a little bit causal.",
            "And that has not how could that fail to get the attention of people in many fields.",
            "In particular, cognitive scientists.",
            "You know people like me.",
            "I got into the field in the mid 90s and while that was well before these successes were hitting the front pages, you know there were much smaller scale versions that we also clearly saw where these were coming from.",
            "You know the whole probabilistic revolution in AI that was.",
            "That was the time I was getting into the field.",
            "So that got attention at the same time, the gaps are also clear.",
            "While each of these systems achieves."
        ],
        [
            "Some human level, maybe even expert level you know as good or better than the experts performance in some particular aspect of intelligent behavior.",
            "None of them we would say is truly intelligent.",
            "Some actually intelligent engineers had to build them and each one of them does one of these things.",
            "But compared with you know and no one had to engineer you to solve these problems to to learn how to drive or learn how to play jeopardy.",
            "You may not play Jeopardy as well as Watson, but you only had to watch that game for a couple of minutes maybe, maybe not even be told the rules or just be told the rules in just a couple of sentences.",
            "And then you get it and you can perform an endless number of tasks without having to be programmed.",
            "You program yourself.",
            "We want to understand that gap.",
            "So I want to talk about the successes that have driven the reconvergence, largely thinking about various kinds of statistical approaches.",
            "But how do we make these kinds of approaches more sophisticated to actually get at the remaining gap?",
            "Now let me shift over to the cognitive science side and say, here's the big question that animates."
        ],
        [
            "Me as a cognitive scientist and a lot of a lot of other work in our field and we'll see how this starts to come back to to wear this gap is when we look at at cognition we see throughout whether we're talking about perception, reasoning, learning.",
            "We see this fundamental gap between the data coming in through your senses and what you do with it.",
            "Our minds build models, abstractions, generalizations that seem to go so far beyond the data.",
            "That's their house."
        ],
        [
            "Be able to do that.",
            "Here's a little demo."
        ],
        [
            "So that is something that we've been studying in the lab.",
            "It's meant to abstract in a form that we can study with adults.",
            "The problem that a child faces when they're learning a word as anybody who's ever been a child or had a child might remember.",
            "A remarkable ability, you see, a remarkable ability in children to learn concepts, even just to label a concept like table Chair, Cup dog from just a very small number of positive examples.",
            "Contrast this with the situation of most traditional machine learning, where classification is seen as something which requires many positive and negative examples.",
            "So to remind you of this phenomenon and how much fun it is, we'll just do a little demo here to wake everyone up after lunch.",
            "I've shown you these novel objects we made in an object generating program and I've highlighted.",
            "A few examples of Tufas, and now you tell me which are the other two things will just go through this with the pointer, so too far yes or no.",
            "Here, but it's too far from my pointer in my shaky hands, so I'll do it like this if you can say OK, yes now this one.",
            "Wake up yes or no too far no.",
            "OK this one.",
            "This one.",
            "This one.",
            "This one.",
            "This one.",
            "Yeah, little more uncertainty there.",
            "That's OK, because we've got probabilistic models here.",
            "So, so what's going on?",
            "Think of this as a math problem, right?",
            "There's this infinite set of all objects, and it's truly infinite, because we generated it with a generative program and somewhere in this infinite space of all objects is an infinite but very constrained subset that you could call the two phase.",
            "And somehow you're able to pick out the boundaries of that said, not perfectly, but roughly from just these few points randomly sampled within it.",
            "And we work on these kinds of prob."
        ],
        [
            "Whether we're thinking about, they often arise in language or or, for example, causal learning, right?",
            "So you know.",
            "Again, I mean, it's a great time to be addressing AI audience because of the very broad recognition of the work of Judea Pearl.",
            "That's not only revolutionized AI, but also many other fields.",
            "And so we're all familiar now with various kinds of principles that can be used to learn causal structure from observation, ull an interventional data.",
            "But think about the way.",
            "That children often learn causal structure.",
            "Sometimes they get it wrong, but you know, quite quite often get it right from just not not even enough data to sort of compute the patterns of conditional dependence and independence that are at the heart of classic Bayes net causal structure learning algorithms.",
            "But even just a few, again, a few data points that aren't even enough to establish a reliable reliable pattern of statistical dependence or correlation, right like the right kind of spatial temporal coincidence.",
            "How how are children able to do that?",
            "I would say the most exciting thing that we're getting at here is larger scale systems of knowledge.",
            "What are sometimes called intuitive theories, not just learning a single concept, but systems of concepts that together describe some common sense domain like common sense physics or common sense psychology.",
            "So just to illustrate this a little bit, I'm talking about these kinds of problems and you'll see I think, hopefully the."
        ],
        [
            "AI relevance of these problems, let's say we're interested in understanding a visual scene like the one in the upper left.",
            "We don't just want to know what is where, to recognize objects and localized, but we want to understand what's going on in terms of the physics, like this table of supporting those objects or certain objects must be very likely to be attached to that back wall that you couldn't move them.",
            "Others are hanging there, so they're not going to fall, but you could lift them up right?",
            "Or looking at that, looking at the construction senior, how do you know which of those planks of wood you could move?",
            "Or Witcher Witcher free, which were attached?",
            "Which are absolutely vital to supporting structure?",
            "We use this kind of intuitive physical knowledge to diagnose situations that are maybe accidents waiting to happen or requiring special care like the stack of dishes, and then think about social interaction between people.",
            "How do we look at a scene where?"
        ],
        [
            "We're just an observer watching one of these scenes or a participant and just get instantly what's going on, what the what, the different people in the scene are thinking, what they want, what they're feeling, how do we get at their mental states from their actions?",
            "That's a kind of intuitive psychology.",
            "These are hard problems.",
            "If we could solve this would pretty much be done, and this, But these are.",
            "These are the problems that we're setting our sights on.",
            "We want to get there by backing off to some easier problems, and many AI researchers as well as cognitive scientists have pointed out that you could get a lot of these basic kind of common sense physics and psychology.",
            "By just studying what small children do with stacks of blocks on their own, building up things or in combination, and I'll show you some research that's really trying to get at this, but you can start even simpler.",
            "Let me show you a couple of two other demos that I think are some of the nicest ways to see these kind of core common sense, intuitive physical and intuitive psychological theories at work and again show you these minds that remark."
        ],
        [
            "Capability to make inferences from sparse data.",
            "So here are a couple of little movies.",
            "The first one is by Southgate and Chevre, two developmental psychologists.",
            "It's from a study with 13 month old infants, so just watch this.",
            "I'll play it a couple of times and you can see here.",
            "Well, what do you see?",
            "You see 2 balls, a blue ball.",
            "Just play it again.",
            "Anna Red Ball and they're rolling on a green surface with some kind of beige obstacles, right?",
            "But if you were to describe this, what's the most natural way to describe what's going on here?",
            "Chasing right?",
            "Yeah, that's that's I heard that from a few different people it looks like the blue ball is chasing the red ball in the red balls trying to get away.",
            "And while it's an interesting kind of chasing because it's also kind of slightly dumb chasing right the blue ball thinks he can fit through those holes that he can't actually right, and he seems to have to sort of back out and go around.",
            "So you're attributing a goal to the blue ball and also to the red ball.",
            "The red ball is trying to get away a kind of desire, as well as the belief of maybe a false belief in this case that he thinks he can fit through some holes which he can, as well as some true beliefs.",
            "He roughly seems to know where the red guy is.",
            "Alright, here's another video which is much more famous.",
            "That's a classic in social psychology.",
            "It's from 2 psychologists.",
            "Hydrogen symbol in a study that was published in the 1940s.",
            "Just curious how many people are familiar with hydrogen symbol video.",
            "Yeah, I mean, it's so striking.",
            "If you haven't seen it before and all you remember from the talk is this video great?",
            "So again, you could parse this as two triangles moving in a circle, moving and some other lines, but you don't see it that way.",
            "You see objects that are banging into each other and the again you feel like they're intentional agents with stories and desires.",
            "It looks like that big triangle is kind of.",
            "I'll just play it again.",
            "It's kind of maybe bullying the little triangle.",
            "Banging into him and then he's going to be sort of the circle.",
            "Kind of seems to observe and now is going to hide inside, and once the big triangle is kind of scared off the little triangle there he goes back in, goes in there and sort of Q the ominous scary music.",
            "You haven't seen this video.",
            "You can watch it all on YouTube and I know I left it at a kind of a moment of suspense.",
            "Don't worry, it ends happily, at least for the two of the three characters.",
            "Alright, so what's going on here again?"
        ],
        [
            "You know from just what you could think of is just a few numbers in time.",
            "These are low dimensional time series.",
            "If you think about how many, how much information is required to describe these movies?",
            "They're not nearly as rich as a full natural scene.",
            "I mean contrast this strikingly with what Sebastian showed us is the really massive data coming in from a street scene to a Google self driving car.",
            "Here you have very little data, but look at how much you see you see real physics objects with force dynamics.",
            "You see real psychology, beliefs, desires, intentions, emotions.",
            "And even more what you might call things like sort of morality in sociology, like who's on Who's team, who's a good guy, who's a bad guy?",
            "Most people here see the big triangle is kind of a bad guy and the other two is being on a team.",
            "So how do you do that?",
            "How do you get so much from so little?",
            "This is the kind of thing we want to understand, and I think if we could even make progress on just those last steps and then building up to things like kids with their with their blocks and building up to sort of real common sense physics and psychology and natural scenes would be somewhere OK."
        ],
        [
            "So the approach that we've been pursuing over, I would say over the last 10 or 15 years or so in computational cognitive science is very much one that I think many people will recognize here is in common with a lot of the state of the art.",
            "In AI, there's a clear recognition of the importance of statistics, both in data in terms of inference, but the really the heart of things is about the interaction between statistics and knowledge.",
            "In all these cases, the data on its own that's observed isn't enough to make the inferences you make, so something else has to fill in the gaps some other kind of abstract or background knowledge.",
            "And the key questions have to do with the interaction between those.",
            "How does background knowledge guide these inferences from such sparse data?",
            "What form does that knowledge take across the all these different domains and tasks?",
            "And maybe most interesting, how might how might it get in there if the brain is doesn't isn't programmed by a smart engineer?",
            "In some sense, it has to program itself learning of abstract knowledge is absolutely critical, so the kind of."
        ],
        [
            "Ideas that we've been pursuing are shown here in red.",
            "Broadly, we're taking a Bayesian approach with the probabilistic inference framework, where that part of things is some kind of a generative model, some kind of hypothesis space of ways to account for the data, and some kind of prior over those.",
            "But it will go well beyond anything that looks just like Bayes rule, where as an AI we're not talking about exact Bayesian inference, we're talking about some kind of approximation, because these computations are going to be intractable to do in any exact way.",
            "And again as as is pretty much now, I think you know, well recognized in this community, but is one that say the statistical machine learning community is only more recently coming too and sometimes not even at all, and is also still quite new in the cognitive science and neuroscience community.",
            "Statistics is not just something you do with numbers, it's not just something you do in high dimensional vector spaces, but it's something that you can do with real knowledge with representations of the world and data that look much more like the sort of earlier classic AI approaches.",
            "Various kinds of symbolic knowledge, representations, graphs, grammars, schemas, predicate logic, and I think in common with a number of people in this community that the number one thing we need to do to understand to build tools that can allow us to understand this kind of these aspects of human intelligence is to understand how statistical inference and learning can operate with these kinds of representations.",
            "And that takes us beyond what is unfortunate, common legacy of these two fields, which is, you know, decades of fighting over statistics versus.",
            "Structured representations, it's nice that you know in the last decade we've seen how these approaches can interweave, and really deep and interesting ways.",
            "Maybe most exciting is this idea, which I'll try to get to by the end of what we call probabilistic programs.",
            "So where you're doing probabilistic reasoning, not just over things like grammars or predicate logic, But actual programs.",
            "In particular, we're looking at functional programs, so list is come back in our work in a certain way here, and I'll try to argue why this is.",
            "I think an approach that subsumes a lot of what we and others have been doing with other kinds of structured probabilistic models in a powerful way for common sense reasoning.",
            "And then this last maybe most compelling question of how might knowledge itself be acquired?",
            "Well, here we've been drawing on ideas that have become very popular in the Bayesian machine learning community and themselves drew on the Bayesian statistics community what are called hierarchical models or Hierarchical Bayes where you don't just have one level of a hypothesis generating data and a prior there but but multiple levels hypothesis spaces of hypothesis, an priors on priors, and by doing inference at all levels of that hierarchy, you can explain how some piece of abstract knowledge at a certain level isn't just useful in guiding influence at the lower level.",
            "But itself might be learned over, say, broader timescale or broader sources of data by inference at higher levels of abstraction, and when you put all of these things together, you put hierarchical Bayes together with the idea of probabilistic programs as your basic knowledge representation.",
            "Then you're talking about these hierarchies of programs that generate other programs.",
            "Again, an idea that has very important early precursors.",
            "If people remember the work of people like Feldman, Horning on grammar grammars, and the earliest probabilistic grammar induction approaches, and.",
            "It's sort of a kind of a hierarchical Bayesian approach to learning as program induction.",
            "This is just something we can glimpse at this point, and maybe at the end I'll show you a little bit of a demo of where we're going with that, but it's just, you know that's mostly as Sebastian said, you invite me back in 2028 or something, and maybe we'll actually have that settled.",
            "OK, so.",
            "I want to do here is in this talk is give you a bit of a tour.",
            "Through the way we've been using these ideas to understand these hard problems of human cognition, things like learning from very few examples or common sense, intuitive physics and psychology.",
            "I want to take one step back just because I'm coming from a different field."
        ],
        [
            "And just set a little bit again of the context.",
            "You'll see a parallel with the AI field.",
            "When I got into cognitive science, this was in the mid 90s.",
            "Basically in grad school, just as just as an AI.",
            "There was a lot of skepticism over whether statistics and probability infants was even relevant.",
            "Probably many people are familiar with the work of condiment averse key, very important work, justly deserving of the Nobel Prize that Kahneman won in economics in 2002.",
            "But the headline of this work for psychologist was basically people aren't Bayesian.",
            "They gave people an.",
            "A lot of other researchers in the field of judgment and decision making around and following them gave people very, very basic Bayesian stats.",
            "Questions like these things simple earn problems like you've drawn a certain sample of red and white chips out of this order that turn, and they have the urns have different composition of red and white chips in them proportions.",
            "Which one is more likely, or what's the relative probability that this order and it turns out people are kind of things, or you give them just a few statistics that they could plug into Bayes rule in a very elementary way, and the average person that's often doesn't know what to do with that.",
            "And this crapped out into the popular press in all sorts of ways.",
            "Maybe the most famous was one of Stephen Jay Gould's most famous essays.",
            "Yet again, this is what people were reading when I got into the field, saying our minds are not built for whatever reason to work by the rules of probability.",
            "But people who came of age when I did, you know they saw the not just the work that you did.",
            "Pearl was doing, but all of the probabilistic revolution in machine learning and AI.",
            "We just thought you know that's that's crazy.",
            "Clearly this this is a strong candidate, at least for understanding something about intelligence.",
            "So the beginning of this research program was for me at least, was work that I did together with Tom Griffiths, where we took a number of basic cognitive capacities and just."
        ],
        [
            "I to see could we understand these as basic forms of intuitive statistics, typically Bayesian statistics where there's some kind of key role being played by some prior knowledge that we can formalize in simple kind of textbook style statistical distribution.",
            "So I'll show you just one exam."
        ],
        [
            "All of this 'cause it's one that anybody who studied Bayesian statistics might recognize, and it sort of sets out the logic you might want to to aim for, and then raises a challenge for.",
            "How do we get to more structured kinds of abstract knowledge?",
            "So here are a bunch of problems that all have a similar form.",
            "You read about a movie that's made $60,000,000 to date.",
            "How much money will it make in total?",
            "You see that something's been baking in the oven for 34 minutes.",
            "How long until it's ready?",
            "You meet someone who is 78 years old?",
            "How long will they live?",
            "Your friend quotes to you from line 17 of his favorite poem.",
            "How long is the poem?",
            "Or you need a US Congressman who served for 11 years.",
            "How long will he serve in total?",
            "So each of these is what we call in every day prediction form.",
            "There's some quantity event duration will represent that with T that you would like to make an inference about, but you don't deserve this.",
            "You just observe some sample or let's say sorry I use my notation teetotal is represents the unknown total extent or duration of one of these phenomena.",
            "And you observe one data point."
        ],
        [
            "That all you know is that it's a random sample between zero and T total and you have to make a guess at thetotal.",
            "Now what's nice about these problems is that these different classes of everyday events we can go out and with publicly available data come up with the right prior.",
            "Those are shown along the top here, and I won't really go through the specifics, but for each of these different domains, movie grosses poems, and so on, life spans you can compute the empirical distribution on how long these things last, and then you can now do Bayesian inference.",
            "You can condition this prior on one observation and then make a guess the particular estimator that we're using is what's called the posterior median.",
            "So we're updating this prior with one sample that we know is all we know is that it's between zero and and T, and that's the prior on the total.",
            "And then we take our posterior distribution and we look at the median and say that's our best guess at how long this thing is going to last and what you can see on the bottom are plots of the posterior median predictor for for the for the empirical priors up there, and they're plotted against peoples judgments for five of five different data points.",
            "The X axis is represents the value that people were given.",
            "the Y axis is the median of peoples guesses on on each of these problems.",
            "Given one of those inputs so.",
            "Just to be very concrete, that means like some subjects were told about a movie that made $60,000,000, but others were told about one that may say $30,000,000 or 100 million dollars.",
            "And there were five different values across subjects for each of these different questions.",
            "And all I want you to take out from this is that people are extremely close to the Bayesian predictions.",
            "There's a sense here in which people are sort of doubly optimal, their optimal in the sense that the mapping from the top to the bottom, the prior to the posterior predictive is the optimal Bayesian prediction.",
            "And people seem to match that.",
            "But notice how the qualitative form of the optimal Bayesian prediction varies across each of these domains, 'cause the priors have different forms and that shows up in the posterior prediction.",
            "People seem to get it.",
            "It's as if they're doing the right mapping from prior to posterior with the right prior that's tuned to the structure of the domain.",
            "So this another kind of very basic quantitative success is convinced us and others to take the idea of probabilistic inference framework for cognition seriously.",
            "But how do you now get this?",
            "To scale up to these hard problems that I'm saying, we really want to solve like the problem of learning.",
            "Allez."
        ],
        [
            "For objects from a few examples or intuitive reasoning about physical scenes or intentional agents interactions, it's not even clear here what's the right prior hypothesis space, or how you could measure it for us as scientists, let alone for human learners who are trying to build up this knowledge.",
            "So this leads us to turn towards some kind of more expressive knowledge, representation language, something that isn't just you know, exponential family distribution you can get from a Bayesian stats book.",
            "And like many people in a I was heavily influenced by.",
            "The work of."
        ],
        [
            "Not just Pearl, but many others.",
            "In the tradition of probabilistic graphical models, Bayes Nets directed graphical models seem particularly appealing because so much of human cognition, so much of what I've been talking about here is essentially causal.",
            "But it no more generally the toolkit of graphical models has been very influential, not only in AI, but to cognitive modelers for similar reasons.",
            "It gives you 2 main things.",
            "It gives you a general purpose knowledge representation language right away to represent the structure of some complex domain, and it gives you general tools for doing inference.",
            "So all you have to do is the modeler is described the causal structure.",
            "Let's say you're using a Bayes net and just the sort of direct causal dependencies.",
            "That's the arrows in the graph, and then the tools of Bayes Nets give you in principle and in working tools that people have built.",
            "And ability to do arbitrary conditional inference is to observe some variables and make inferences about others, right?",
            "So in the famous QMR network there you might observe symptoms and make inferences about diseases.",
            "You might then make predictions about other symptoms, the results of medical tests you might see, and so on.",
            "This is, again, very familiar.",
            "And something basically, I think there's something basically right about some kind of probabilistic causal representation language as the way to think about common sense, but what's missing from this well?"
        ],
        [
            "This is what leads us to these.",
            "These kinds of representations we call probabilistic programs.",
            "Basically, it's the idea that a graph is too impoverished, representation too simple.",
            "To describe the kind of rich knowledge that humans have about the causal structure of the world, we need some kind of more powerful probabilistic language, some more powerful way of describing the probabilistic causal structure of the world.",
            "So think about this kind of this workshop scene that I've shown a few times.",
            "How can you take an image and make an inference about not just what's where but what?",
            "What supporting what would happen if you if you move the table, you know that those things would fall.",
            "You can see there's a tire, maybe you can see over there on the lower right there's a tire leaning up against.",
            "The table you can probably make the inference that tire is a little more precarious than, say, one of those cups.",
            "That's right there very solidly on the top of the table, so a slight bump might make the table might make the tire fall, but won't affect the cups on there.",
            "How can you do this?",
            "Well, here's a way of thinking about it, which in some sense looks like a Bayes net as a way to capture this intuitive knowledge here.",
            "But it also I think, draws attention to what's missing, so we have this have this picture here, which describes what I think of is roughly the causal processes that are giving rise to this data.",
            "There is some kind of image that you observe and here I'm showing just a static image, but in general we could be looking at dynamic scenes like those movies I showed and that image is is some kind of output of a graphics processor graphics is that, let's say is the process which takes some underlying 3D World state, which we could think of something like a CAD model, and that's not.",
            "That's not directly observed, so I've grayed out the world state there at time T and but some graphics function renders that 3D World state into a 2D observable image.",
            "And overtime, the world state evolves with some other causal process which we could call physics.",
            "And then again graphics keeps operating each point in time right?",
            "So and what you observe is the output of that process.",
            "The sequence of images.",
            "So probably most people in the recognize that that looks just like an hmm, right?",
            "That's there's an underlying latent state evolves with some dynamics, and then there's observations that are conditionally independent of different points in time conditioned on the current state.",
            "OK, but would we actually want to use an HMM and the standard tools of hidden Markov models for representing this?",
            "No, I don't think so, right, because there isn't.",
            "If you want to think about intuitive physics in these scenes, there isn't any kind of fixed dimensional state vector, right?",
            "And even if we were to try to represent with some fixed dimensional state, it wouldn't capture the intrinsic relational nature of what's going on here that this object is on top of that object.",
            "Or this one is attached to that object?",
            "And if we think about the state transition matrix or the observation matrix, yes, you could encode all your knowledge of graphics and a gigantic state transition matrix.",
            "Which state state observation matrix which has on one dimension every possible configuration of every possible set of objects, and then on the other dimension every possible image.",
            "And you can encode all your knowledge of physics in a gigantic state transition matrix, but all the interesting structure that you could actually use to support learning reasoning would be lossed there.",
            "So instead think about the kind of representation that other areas of computer science used for these kinds of things, like people who are interested in graphics or physical simulation.",
            "They don't draw graphs, they write programs, and that's the basic insight here is to try to define probabilistic causal models where the underlying representation isn't a graph with nodes and arrows, but functions which call other functions the way you might have a node.",
            "That sort of calls other nodes.",
            "It's parents, right?",
            "And these are these are probably."
        ],
        [
            "Programs where we use probabilities to capture the uncertainty about the things we don't directly observe, just like in probabilistic graphical models.",
            "And just like in graphical models, the main work is done by specifying the program and then you can and then you can run this in any which way you can run it forward to do prediction planning.",
            "Maybe an you can run it backwards in some sense to do inference, explanation and learning, and I'm not going to say very much about the inference algorithms.",
            "I'm actually going to say almost nothing about the inference algorithms that people have been using for these probabilistic programs.",
            "The main ones that we and others use our various kinds of conditional simulation like Monte Carlo algorithms that will sort of forward sample or try to do some kind of the same way that we use MCMC, Metropolis Hastings type algorithms.",
            "For example, we can do Metropolis Hastings.",
            "In graphical models we can do Metropolis Hastings in the space of program evaluation traces.",
            "That's at least the conceptual idea for how you, how you run these programs backwards, but just the high level point is think about inference in probabilistic programs as taking programs describe the causal structure of the world.",
            "Just like the graph in a Bayes net and then just like the way you sort of turn the Bayesian crank and a graphical models generic inference algorithm.",
            "Our hope is to be able to have some kind of generic Bayesian crank you can turn which will allow you to run these programs backwards or forwards to condition on partial.",
            "Outputs and make inferences about the inputs of these programs or other outputs.",
            "And maybe one other summary here is to and this is not the only way to think about a public program, but to me, and for the purposes of common sense reasoning, I'm saying, think of a public program as a representation for causal process that like a Bayes net is generative.",
            "But unlike a traditional Bayes net, is relational.",
            "It's sort of object and entity and relation based.",
            "It can support recursion, and they can be composed just like programs.",
            "And really in a sense it's a computationally universal representation.",
            "Which is both of course very powerful thing and a very dangerous thing to illustrate.",
            "Again, another place where you want to think about public programs.",
            "This other kind of common sense domain.",
            "Think about intuitive psychology here, right?",
            "So the classic, the classic way that both psychology."
        ],
        [
            "And AI researchers have thought the most minimal kind of model of intentional agent is to say, well, there's some beliefs and desires and they give rise to actions.",
            "Right now the the classic sort of intuitive qualitative way to say what's the relation between beliefs and desires and actions.",
            "Will something like this.",
            "A principle of rationality?",
            "Intentional agents will tend to choose sequences of actions that they expect in light of their beliefs to lead to their desires being achieved as efficiently effectively as possible.",
            "Something like that right now you."
        ],
        [
            "Capture that."
        ],
        [
            "As again, you could try to capture that with a gigantic conditional probability table if you wanted to represent this as a Bayes net right, you have some conditional probability of how actions dependable using desires and then observing actions you could work backwards turning that Bayesian crank to make inferences about the beliefs and desires, but again, you'd have this infinite by infinite by infinite matrix because the space of beliefs, desires and actions of any reasonably complex agent is infinite, but it not only is it infinite, but it's highly structured in ways that the conditional probability table doesn't get at.",
            "On the other hand, if we use."
        ],
        [
            "Thing like a program to describe these arrows.",
            "A planning program then not only is it much more compact, but it preserves all that structure, right?",
            "That's just just as that's basically what graphics and physics programs are as they describe those thick arrows in that intuitive physics model, A planning program will describe that the thick arrows here.",
            "So that's our basic I."
        ],
        [
            "Yeah, and let me show you how we use these ideas of probabilistic programs.",
            "There's a lot of technical details that I would point to my colleagues who actually have done all the hard and interesting conceptual technical work here.",
            "So for example, people like like Noah Goodman, the conferencing, and others developed a particular probabilistic programming language called Church, which is based on Lisp.",
            "And basically we're just we're using the functional programming nature of list to define one of these probabilistic programs.",
            "I'm not going to say very much, although you can read their paper or.",
            "Our paper I'm an author on it.",
            "They did this work while they were in my lab, but really it's their work.",
            "I'll just draw your attention to.",
            "Here's a couple of examples of church programs that describes a theory, a simple theory of physical objects or rational agents or causal networks, and the church program just consists of a bunch of defined program statements, so they're just defining functions there.",
            "Stochastic functions which call other functions, and that's just the exact analogue of writing down a graphic."
        ],
        [
            "Model where you have nodes and they are defined in terms of other nodes, their parents and that's the Church style of programming.",
            "It's not just writing a list program and putting in some randomness in a way that would look relatively similar to earlier generations of list based AI, but rather the whole point is to write a program that describes the causal processes and then there are other functions, in particular a query function which does this inference by conditional simulation which takes a set of defined statements which define a model, condition it on some, say partial output, and then make inferences about say, the inputs or other outputs of those programs."
        ],
        [
            "The idea let me just check on how I'm doing on time here.",
            "Well, OK, I'm I want to make sure I get to some actual good concrete results.",
            "So I had a little bit more background on precursor to this idea, but I'll just say very quickly the basic idea was anticipated by a brilliant Englishman who was born about 100 years ago and got involved in the war effort and while doing absolutely pivotal instrumental work, came up with some clever ideas about how the mind might work, and nothing has ever been quite the same and tragically died too young to see.",
            "His legacy developed and of course you know who I'm talking about.",
            "It's Ken Craig.",
            "He's not quite as maybe that's not who you thought it was going to talk about.",
            "How many people have heard of Ken Cray?"
        ],
        [
            "Yeah, so he's not quite as famous as that other famous Englishman who was born exactly 100 years ago, but he's well worth reading.",
            "He was basically the inventor of cognitive Science in psychology in Britain, and he in a classic work that he wrote just shortly before he died tragically in a bike accident, his.",
            "Really laid out this idea of a view of what kind of machine the mind might be, which is basically a simulation engine and engine that builds these kind."
        ],
        [
            "Runnable mental models and uses them for for all the different tasks of common sense, intelligence, reasoning, planning, explanation and so on.",
            "And it's a fascinating view which then influence the tradition of work on mental models."
        ],
        [
            "Other other kinds of AI people have been influenced by his ideas, the sort of qualitative reasoning tradition, which again is 1, which has not been traditionally associated with a probabilistic inference, but another way to understand what we're trying to get at with these probabilistic programs is bringing those traditions together."
        ],
        [
            "And I'll skip that solo."
        ],
        [
            "Actually put these into action, how might you say capture this learning concepts from a few examples?",
            "Well, somehow you gotta take all the objects that you've seen here and represent something about the abstract structure of the domain, the generative processes that gave rise to what you see and link the concept to something in that generative structure.",
            "So something like, for example, the way a biologist might look at objects and think about the evolutionary processes, processes that rise to them.",
            "You might look at these object."
        ],
        [
            "And organize them into some kind of hierarchical taxonomic tree that reflects some intuitions about about which what they have in common.",
            "The generative processes that gave rise on the parts that grow, for example, and then you see."
        ],
        [
            "Few examples of a new concept like those over there in that part of the tree and you make some guess of where the where that where the concept refers to.",
            "Exactly how we capture this is a Bayesian inference.",
            "I'm not going to go into the technical details, but basically we have hypothesis, which are the branch points of the tree, right?",
            "You assume that the possible concepts are each branch of the tree, and the longer the branch, the more distinctive it is for the higher prior probability it has for being labeled by a word.",
            "And then there's a likelihood which is just captures the suspicious coincidence of seeing those three things all clustered there in that part of the tree.",
            "You could say, well, these three examples here.",
            "They could also be an instance of, say, a concept labeling that branch for that branch or that branch, but then it would be.",
            "A big coincidence to see them all.",
            "The first examples clustered over there, and with that strong hypothesis space just a couple of examples provides enough statistical leverage to figure out that the concept is basically just those things there and not anything else.",
            "And we can, just as I showed you for those everyday predictions, turn this into a quantitatively predictive model that we can compare with how both adults and children generalize words but."
        ],
        [
            "But I'm not going to tell you the details of this experiment 'cause I want to emphasize more of these deeper questions of where the abstract knowledge comes from.",
            "What leads us to these probabilistic programs?",
            "So how in particular did you figure out that you should be building a tree, I mean."
        ],
        [
            "You know, we might think of objects is organized into something like a tree structure, their taxonomic relations, but there's other domains of reasoning that have other kinds of structures, so in some very neat work that Charles tempted when he was in our group, he gave.",
            "You could think of as a kind of hierarchical Bayesian approach to learning the abstract structure of different domains.",
            "That is, maybe the first bit of kind of hierarchical Bayesian program induction that at least we worked on where we say, OK, we what we observe is at the at the bottom.",
            "Here is some.",
            "Features of objects in this domain.",
            "Let's say the features of animals or plants or something, and then we assume those were given rise to buy some kind of process operates some kind of stochastic process operating over, let's say some kind of graph structure.",
            "Let's say here it's a tree structure.",
            "What we want to learn is not only the tree that underlies those particular objects that domain, but the general principle, which says that it's a tree as opposed to some other kind of structure, and so Charles's idea was to represent that higher level knowledge of something like a graph grammar.",
            "So it's.",
            "It's a principle that a little rule that generates structures of a particular constrained sort, namely trees and then bye bye bye giving different kinds of graph grammars we can grow out different kinds of structures like chains or rings or cylinders or grids and so on, and by doing inference at multiple levels of this hierarchy released these two, you can simultaneously infer the grammar that's most likely to have generated the data domain as well as the most likely graph.",
            "If you like the parse.",
            "Of the observed data under that grammar, so it's directly analogous to a kind of grammar induction in the couple of problems with grammar reduction.",
            "Parsing in language, and these are just a couple of results from this.",
            "From this model, given a data set of animals and features, this approach was able to figure out that it was organized into something like a tree structure to learn that kind of organizing principle.",
            "But say, for example, given data on the voting patterns of Supreme Court justices in the US, was able to figure out not a tree structure.",
            "As most appropriate, but actually a linear structure here you know it might be, it might be a little small to see, but here we've got the Supreme Court justices who served under the Rehnquist Court, and you've got the sort of very liberal ones here on the left, and the very right wing ones.",
            "Scalia and Thomas and so on over there on the right.",
            "And this algorithm is figuring out that out of all these different possible simple forms of structure for the data that consists of how they voted on different cases, just as a tree structure is the most appropriate to think about animals in there.",
            "Properties are 1 dimensional.",
            "Chain structures are familiar, left, right continuum is the most appropriate structure there.",
            "Or for example given distances between cities.",
            "It figures out that something like a cylinder, a cross between a chain and a ring roughly corresponding to our concept of latitude in lanja tude is the right way to represent that data.",
            "So it's at least beginning to show how a hierarchical Bayesian approach could learn something that we'd really want to call a kind of abstract knowledge.",
            "Here's another application of this to a more of a causal reasoning setting where you know again we're all familiar with the I."
        ],
        [
            "Of Bayes net learning as a kind of probabilistic inference, we can say we can talk about a graphical model that reflects, say, for example, intuitive medical knowledge, diseases and symptoms and so on.",
            "But then we can say learning that that graphical model is itself inference in this kind of hierarchical based have a level of different causal models.",
            "So here we can consider hypothesis on different causal graphs and then we have some data that we assume is generated from that.",
            "And we could say, well put a prior on graphs and.",
            "Observe samples events sampled from that graph.",
            "Hypothetical patient data and make an inference about what causes what.",
            "That's basically the generic approach to Bayes net structure learning.",
            "That's very hard because the hypothesis is very big and unconstrained.",
            "If you're just thinking about graphs, what in one project that we did to try to again get it at some of the value of hierarchical Bayesian learning of abstract knowledge, we said.",
            "Well, suppose you can add some extra constraints that come from, say, a kind of a graph schema.",
            "So suppose we know that our variables can be sort."
        ],
        [
            "Into three classes, let's call them behaviors, diseases, and symptoms, and we know which variables in which class.",
            "And we know that the behaviors cause diseases, and the diseases caused the symptoms.",
            "That's a hugely valuable constraint if we think of that is putting a prior on graph, so we're only going to learn just as those those graph grammars before put priors on the graphs that we use to parse object attribute data.",
            "This now puts a prior on the causal graphs, and it makes learning much more tractable.",
            "In this case, it cuts down the hypothesis space from roughly 521 gazillion or whatever it is, the number of Bayes Nets on 12 nodes.",
            "Or just directed acyclic graphs?",
            "It's you know it's huge, it's super exponential to only 131 thousand, and it allows you to learn this graph instead of requiring about 1000 samples to really get that.",
            "If you just take 1000 independent samples only just a few 10s of samples.",
            "Can do that now.",
            "Of course that shouldn't be too surprising because we all know that by cutting down hypothesis faces by putting in some kind of prior knowledge, we can make learning more tractable.",
            "But the neat thing about this particular product here is we were also learning the graph schema.",
            "I won't go into the technical details of how we did it, it's a certain kind of nonparametric Bayesian approach.",
            "If you're familiar with Dirichlet processes or Chinese restaurant processes, it's a kind of a graph based Chinese restaurant process prior that allows you to say I know these variables are in some classes, but I don't know how many classes there are, which variables in which class, so you're.",
            "You're basically doing inference over every possible way of dividing the variables into classes at the same time as you're doing inference about what causes what.",
            "That more specific level and what we showed is that you're able to learn very quickly.",
            "Actually, I mean, again, I can't tell you the details, but we showed.",
            "Here's an example of learning that shows just after 20 observations from a two layer network were able to."
        ],
        [
            "Figure out that there's two layers there could be any number of layers and we were able to figure out which variable is in which layer.",
            "That's shown here, and we're able to figure out that the variables in one layer caused the variables in the other layer, even though we don't yet know what causes what.",
            "That's what's shown here by this kind of blurry graph connectivity matrix in the upper right, and then with just a few more data points you can fill in the details.",
            "It's a nice example of how abstract knowledge really really helps you.",
            "The ability to divide in this case variables in these abstract classes.",
            "But, and we have to in order to get its benefit for learning, we have to have the ability to form that knowledge.",
            "But we don't have to have it wired in any specific detail.",
            "We didn't have to know in advance that there are diseases and symptoms and what's a disease and what's its symptom that can be discovered almost as quickly.",
            "And in this case actually much more quickly than the more specific knowledge that's constraining.",
            "So I think this is a very powerful idea for AI.",
            "The ability to get the power of background knowledge that we all know is necessary to constrain inductive inference.",
            "But to be able to learn that background knowledge together.",
            "Earning the more specific knowledge that enables.",
            "OK, so in the few minutes I have left I want to get to the common sense reasoning cases which I think are make the best case for why we have to be thin."
        ],
        [
            "Thing about probabilistic programs that aren't just, you know, grammars, and those graph schemas.",
            "You can think of those as simple kinds of programs, but why we need something like a computationally universal framework for public programming?",
            "So we've been doing a lot of work in our lab on studying intuitive physics.",
            "With this case study of stability.",
            "It's very, very compelling.",
            "Intuitively, let me give you an example of an experiment that we do to get people's intuitive concepts of physical reasoning here.",
            "So we show people.",
            "It's a little bit dark unfortunately, but we show people these these."
        ],
        [
            "Stacks of blocks.",
            "These towers, some of which look very stable and others of which look very unstable.",
            "And then we'll ask them to judge how stable they are so you can try this too, so these ones."
        ],
        [
            "You look fairly stable."
        ],
        [
            "How about this one?",
            "Stable or unstable?",
            "Full"
        ],
        [
            "A bit more unstable.",
            "Yeah, this one.",
            "Also little bit."
        ],
        [
            "Unstable these ones."
        ],
        [
            "Kind of in between.",
            "So in a typical experiment we might show people 60 different examples of these stacks of 10 blocks and have them judged on a scale of 1 to 7.",
            "How stable they are.",
            "And then we build a model of what's going on in their head."
        ],
        [
            "That looks just like what I showed you before.",
            "I mean, you could think of it as one of these fancy kinds of Hmm's.",
            "But really what we've got is we've got some.",
            "We were modeling that we're assuming they have some representation of the not directly observable world state, which is."
        ],
        [
            "Something like a CAD description of these objects which they infer with some kind of approximate Bayesian inference from the image by inverting a kind of graphics simple graphics rendering model.",
            "And then once you have that state description, you can judge stability by just propagating forward with something like a kind of a physics engine.",
            "So here we're using the way we actually build this.",
            "This model of people's mental models we use like simple game physics engine's.",
            "There probably pretty much everyone here knows fast and ready approximations to classical.",
            "Newtonian mechanics and so.",
            "In this case you have these objects and you can say, well, now if we turn on physics, what happens?",
            "Well, it'll fall in some pattern, and because it's probable."
        ],
        [
            "Stick, this is just only one of a number of possible guesses, right?",
            "We can't where the probability is coming in various places, but one place they come in is that you can't exactly invert this this graphics model.",
            "You can't from a single image guess exactly.",
            "Certainly people can't exactly the precise state of those 3D objects just from a quick glance you makes."
        ],
        [
            "Yes, so here's another hypothesis of what the underlying state could be, and then you can run Newtonian physics on that and you get a different answer.",
            "So in the particular models that we've built, uncertainty comes into these public programs in just two places just to keep it simple.",
            "One is state uncertainty.",
            "That's the Sigma parameter.",
            "So how how much?",
            "Basically it's saying?",
            "How precisely can you localize the objects, the blocks from the image that you see?",
            "And then there's some latent force uncertainty we put in certain basic forces into our physics engine, like gravity and friction.",
            "But we allow for that.",
            "There could be other forces that you maybe you didn't know about, like for example somebody could walk by and knock the table.",
            "A little bitter wind could blow.",
            "In this first experiment, that's not a big deal, I mean.",
            "Or rather, we didn't tell anybody about latent forces, so that parameter won't do anything, but that's one of the things we could manipulate later on.",
            "So here's an example of actually getting some predictive power out of this model.",
            "And again, I'm not going to go through that."
        ],
        [
            "With experience, but I'm going to show you a bunch of scatter plots of data because I want to emphasize how this is enabling us to make precise quantitative reverse engineering models of these aspects of common sense, which traditionally have not been amenable to quantitative analysis.",
            "So in this plot here, each each dot is one of these 60 towers, and the model predictions are shown on the X axis and peoples judges on the Y axis.",
            "And again, but we're asking people to judges on a scale of 1 to 7.",
            "How stable is this?",
            "This one is very unstable.",
            "This one is judges very stable, so those are the two ends of this.",
            "Continuum and then we're basically asking our model the same thing.",
            "How does it work?",
            "It just runs a few of these conditional simulations, forming an estimate of the block posterior bought position posterior, then propagating physics forward and then it just inspects the output of those simulations to see just what fraction of the tower fell.",
            "That's what gives us our quantitative measure, and you can see that we do a pretty good job of capturing the range of variation in peoples influences.",
            "The correlation here is is in the mid point it's about .85 on linear correlation.",
            "Now there's parameters that we have to fit, but there's really only one parameter that has to be fit here, which is that state uncertainty 'cause we haven't modeled in detail how their visual system works, and that that single parameter corresponds to, you know, a relatively small fraction of one of the smaller side of the block.",
            "It turns out that that's actually very important for modeling this.",
            "If you.",
            "If you assume that people were able to localize the objects perfectly, then it wouldn't fit nearly as well now.",
            "Certainly as some."
        ],
        [
            "Both AI researchers and psychologists whenever we consider a very complex model like we're going to do probabilistic inference over a physics simulation, we might also want to consider alternatives which are simpler.",
            "Approach is certainly in psychology.",
            "Many people would find it a little bit implausible this idea that you have something like a game physics engine in your head, so we can consider many different simple heuristics that you could compute just on the image themselves or on some kind of geometric description without going to the dynamics like the height of the tower or something about the top heaviness or various skew things.",
            "I won't go into the details.",
            "But I will say that for a whole bunch of different judgments, there are heuristics we can come up with which can do almost as well as these physics models.",
            "But the key thing that shows you that you've really got some kind of intuitive theory here, some kind of ability to run a rich physics simulation in your head."
        ],
        [
            "Is all the different kinds of things you can do with this model.",
            "It's a kind of a Turing test.",
            "If you like.",
            "Again it's kinda echo theme from Judy's lectures are kind of a mini Turing test here.",
            "A bunch of questions that we've we've got experiments.",
            "I showed you one where the judgment is just, you know, will the tower fall.",
            "But think about all the other questions you could ask about just this kind of stimulus.",
            "So which way will the tower fall if it falls?",
            "Or how far will the blocks?",
            "But will they go all the way down over the table?",
            "Or just just kind of crumble?",
            "Or suppose you bump the table.",
            "So suppose you added another force now.",
            "And you have blocks of different colors when you have more red or yellow blocks.",
            "Or what if you bump this side or that side?",
            "Or what if the blocks are different shapes and sizes?",
            "Or what about kind of counterfactual reasoning?",
            "Did adding the block caused the thing to fall?",
            "Or what?",
            "If we add other kinds of physical parameters like suppose the red blocks or 10 times heavier than the other blocks, what's going to happen?",
            "Well, it turns out that we can.",
            "We can do all of these things here.",
            "So for example, we can.",
            "We can get."
        ],
        [
            "People to judge this is this is an actual snapshot of a subject playing this little game."
        ],
        [
            "Where he's simultaneously judging which way that blocks will fall in how far he didn't really get the direction very well, but there wasn't really a good answer to that.",
            "But consider this one.",
            "Tried this task in your head.",
            "Along with this, try to imagine which way the blocks are falling so there it's a little bit better try.",
            "Here's one more night try, but before you see it, which way are they going to fall?",
            "Except good, pretty good.",
            "So people, it turns out, are pretty good at at a bunch of these tasks.",
            "Or here we can say, suppose these."
        ],
        [
            "Gray blocks are 10 times heavier like these are stone and this is some kind of lightweight plastic and then we can show subjects the very same sets of blocks but coloring them differently.",
            "You're going to get a very different prediction if the Gray ones are heavy.",
            "This one now.",
            "Hopefully you can see is pretty unstable, whereas this one is much more stable.",
            "Or here if you say which way is it going to fall if the Gray ones are much heavier than the green ones, then you can say, well, it's in this case it's going to fall that way, whereas in this case it's more likely to fall that way, and it turns out again that people are basically quite accurate at this.",
            "If we just add in these differences to the model, just add in the different the mass differences.",
            "Again, we get correlations that are not perfect, but you know around in the mid, mid to high point 8 levels.",
            "We can, we can just keep pushing this sort of thing like we can say, alright, imaje."
        ],
        [
            "You have this table an.",
            "We knock the table so now we."
        ],
        [
            "Add an outside force and we say is it more likely to have.",
            "If I knock this table hard enough to knock some of the blocks onto the floor, is it more likely to be red or yellow blocks that fall off?",
            "So what do you think?",
            "Red or yellow?"
        ],
        [
            "OK here."
        ],
        [
            "Isn't it amazing how such had?",
            "Like just a little subtle difference between these two yeah switches, most people switch from yellow here to read.",
            "OK, so how are you?"
        ],
        [
            "Doing that well again, the IDR.",
            "Our thought is that you're running some kind of simulation in your head.",
            "That's like this.",
            "This is a snapshot from our simulator where you take this table and you bump it and you see what happens.",
            "That was a little bump.",
            "Here's a bigger bump.",
            "In this case, basically the same result.",
            "The yellow ones are the ones that get knocked off, and so we build the model which."
        ],
        [
            "Just the very same physics model from before, but now it considers a range of different possible bump directions and magnitudes, and again we don't fit people's judgments perfectly.",
            "But across a ride wide range of towers, varying the number of positions of different kinds of rocks pretty well, we capture most of the variance.",
            "With this model, we can keep going.",
            "I mean, I don't want to bore you with all of this, but."
        ],
        [
            "The point is just just like the Turing test if you want to take the idea seriously that you have this kind of abstract mental model that you can run and you want to show that it's really there, you have to push it to some extent to show that it's really doing enough work for you.",
            "So here I can't.",
            "Not sure how well you can see it.",
            "We vary the size and shape of the object.",
            "Summer tall.",
            "We put these funny kind of rails on different sides of the table or we might Q forces we might say in some cases I'm not going to tell you which way I bumped the table so you have to kind of integrate that out and other ones.",
            "I say it was bumped from this side or that side of that side.",
            "And again, the same thing cult.",
            "Basically this model for both acute and uncured forces for different sizes and shapes of blocks.",
            "It's just this massive experiment here that's all you could get from that scatter plot is across all these factors which we very it captures.",
            "Most of the variance.",
            "It's interesting.",
            "I think that it doesn't capture all the very I mean, it's sort of consistently imperfect, right?",
            "I think that's telling us that we are imperfectly capturing something real.",
            "There is a real physics simulation engine in your head that you can make these probabilistic inference about.",
            "We haven't got it exactly."
        ],
        [
            "Right, with the particular approximations."
        ],
        [
            "We're making OK now if I'm sure at this point I'm probably out of time.",
            "Is that just just about so I don't really have time to go into the last bit of the talk, which is I'm going to show you the same kind of thing about how to do."
        ],
        [
            "These probabilistic programs, now for intuitive psychology, but just to give you a very sort of quick tour of this.",
            "Basically these you know.",
            "I think this is, if anything is going to be more familiar to this audience because we're using all the success in probabilistic planning and particularly using MDP and Palm DP planning algorithms.",
            "And we're basically saying just like, just like there's this crazy idea that your intuitive physics might be based on a physics game engine in your head.",
            "Here we're suggesting that you have something like a palm DP in your head, and you interpret other peoples.",
            "Another intentional agents, whether people are little blobs moving around as if they were choosing actions by solving a palm DP.",
            "Now I think of Palm DP is way too simple, but it, but it's just.",
            "It's the kind of technology that I think many people here are familiar with.",
            "The basic idea is to say I mean or I'll just show you a couple of experiments just evocatively.",
            "So here we can see an agent moving in a simple environment where there's three possible goals and some constraints.",
            "If you look down here, you can see.",
            "You know various different experiment, different experimental conditions where we move the objects around or we vary whether there's a wall.",
            "Or maybe there's a hole in the wall, and then the agent follows various paths and at different points along the path we stop the movie and we say to the subject.",
            "What do you think this guy wants?",
            "Does he want a B or C?",
            "Where does he trying to get to and as a function of all these different factors, we can very people make judgments that you can see here on the 2nd row, the red, blue and green are color coded to the three objects, and you know if you if you take a look at this paper and studied in a little bit more detail if you.",
            "Interested, but you'll see fairly intuitive variations.",
            "First, he thinks I can't really tell whether it's A or B on now.",
            "I'm definitely sure it's a as he heads there, or I thought it was.",
            "In this case, I thought it would be, but then it seems like you switch to a or you can get all these very complex things like, alright, I think it's probably not be, but I can tell this every now and then, say, OK, let's be or I think it's B here, but no, it's definitely not now, let's say and this model captures all of those details with an even higher correlation.",
            "The intuitive physics model.",
            "I mean here, the correlation is in the high Point 9.",
            "What is it doing?",
            "Well, again, like the physics simulator.",
            "It's very complex in some ways and very simple in others.",
            "It's complex in that in this case it's solving MDP.",
            "There's no partial observe ability.",
            "We assume that the agent knows everything in the environment.",
            "But it's an it's it's a.",
            "It's a relatively simple kind of gridworld standard kind of MVP.",
            "There's you get a high reward for getting to your goal, and you have a small cost for each step that you take, and then basically you observe the actions that come from solving that under a probabilistic, both in policy and you have to figure out which goal or rich reward function best explains the observed sequences of actions.",
            "So in some sense, it's kind of complicated, but it's very simple as a mathematical model has very few free parameters.",
            "There's only there's only two free parameters here, which is basically how stochastic is the agent.",
            "And, um.",
            "What's his probability of switching his goal?",
            "It turns out if you look at this, you have to be able to posit that the agent can switch his goal that his goal doesn't necessarily constant in time, and with just those two free parameters we can capture.",
            "You know, almost all the variance in hundreds of different judgments.",
            "We can extend this to cases where you have we have belief, so you're making inference about not just what an age."
        ],
        [
            "ENT wants, but what they believe.",
            "Here's an instance of your watching agent.",
            "Sort of.",
            "This agent is like a grad student who's going to a food truck on the University campus, and he doesn't know what's behind this wall.",
            "He goes behind it to look and then turns around and goes back to this object, and you can make inferences.",
            "I won't go through the details here because I don't have time, but you can make inferences about both what he thought was there and the fact that what he wanted is a thing that wasn't there.",
            "You have to explain why did he go and look and then come back.",
            "It must be that the thing that he wanted is actually the one thing that isn't present there.",
            "And now here we're doing.",
            "We're taking this as a palm DP, and we're modeling both the agents belief state as a function of what he can observe based on line of sight as well as his reward function.",
            "We can extend this to multiagent setting again.",
            "I mean, if you really want to take this seriously as an account of an intuitive theory, you have to keep pushing it.",
            "So you say, well, how can I infer whether somebody that groups whether some say?"
        ],
        [
            "Whether somebody is a good guy or a bad guy?",
            "Well let's define a multi agent.",
            "Model where you have agents and Agent who can have as a goal to help or hinder another agent.",
            "If there's a lot of, there's a lot of research showing even young babies, like in that video I showed you with the chasing and fleeing.",
            "Even young babies can see, for example, this little yellow guy pushing the red.",
            "The red guy here is sort of.",
            "Seems like he's trying to get the yellow guy pushes him from behind and he's seen as a good guy.",
            "A helper.",
            "The infants like to play with him, whereas if a blue guy comes and pushes the red guy downhill, he seen as a hinderer and we can model this as well as more complicated kind of gridworld helping hindering things.",
            "With these recursive utility functions, where what it is to help or hinder is to try to maximize not your own expected utility, but your expectation about the other agents.",
            "Expected utility is a kind of probabilistic Golden rule.",
            "In some very exciting work that Noah Goodman is done, this is not work that I invite."
        ],
        [
            "But it takes the same kind of model and uses it to model pragmatics in language so."
        ],
        [
            "I I, I think I've used my alot of time so let me just try to summarize where we're up to.",
            "We've showed you how we can account for."
        ],
        [
            "Build some of the first quantitative models of intuitive physics and now intuitive psychology, and there's far more than I have."
        ],
        [
            "Time to cover here.",
            "There's some important frontiers that particularly any but I think are of interest to any computer scientists, but certainly to AI researchers, and I just want to highlight these frontiers.",
            "For those people who might be interested in working on them, these are things where some work is already being done, but most of the good work is not being done by me but by various collaborators like the Koch Mensinga, Dan Roy, Cameron Freer, Noah Goodman, others.",
            "So the number one computer science challenge here is to actually build effective universal inference algorithms for these probabilistic programs.",
            "I showed you a little sketch of some programs in the Church, probabilistic programming language, and there have been universal inference algorithms for church, so you can take it's rather remarkable thing that Nolan Bkash did and others is.",
            "You can write down in church in this kind of stochastic Lisp.",
            "You can write down any computable probability model, universal language and you can do any conditional inference that's computable with a query function that's also recursively defined.",
            "So you can nest queries inside other queries.",
            "And it's all you can do that all by Metropolis Hastings.",
            "And it's rather remarkable that there's a basically a metropolis Hastings algorithm that exists.",
            "You can play with it on our website if you Google for the MIT Church wiki can play with it with a server side.",
            "Inference engine, but as anyone who's ever used Metropolis Hastings on much simpler models, knows that to think that you could just do everything with Metropolis.",
            "Hastings is kind of hopeless, it's it's just too slow for all the ways that these models can get complex.",
            "So for the particular public programs I showed you like the physics model in psychology model, we're not using this generic Metropolis Hastings inference album.",
            "We're using special purpose simulators that we built based on certain kind of game engines and then doing Monte Carlo on that or based on Palm DP solvers for example.",
            "But we have the same situation when you data and others first started working on Bayes Nets.",
            "Right, they only had effective general inference algorithms for very simple special cases, and then it took another generation of research to build effective general purpose inference tools for graphical models.",
            "But being able to define the representation language and show that you could get it to work at least in simple cases and sort of map out theoretically what's possible that was.",
            "That was the early stage, and I'd say we're just beginning that stage in public programs, but if you could help work on this, it would be a tremendous thing an I would say talk to people like the Koch men, singer Noah Goodman and others.",
            "There's also really interesting theory questions here that are what people like Dan Ryan Cameron fear of testing, and also the cache like what when is when is influencing public programs computable at all?",
            "When is it?",
            "When is it tractable?",
            "What are its complexity characteristics?",
            "Dan Cameron have developed some rather remarkable and mostly beyond me theoretical results at the foundations or where the foundations of compute ability theory and complexity theory intersect with the foundations of probability, and it's really cool stuff.",
            "I just point you to their work using these ideas to actually again make the link from theory to practice to build inference algorithms that are better usefully informed by theory still open, and maybe the last question that the hardest, most interesting one is the problem of learning.",
            "In probabilistic programming languages, right?",
            "So I showed you some initial kind of warm up cases right?",
            "Like learning graph grammars for describing structural forms or learning those graphs, schemas for describing abstract kinds of variables in a causal graph, though, you can think of those as a simple kind of hierarchical Bayesian program induction, but where the programs are not computationally universal, they're just very specific ways of generating graphs.",
            "Now, can we do that for these universal programming languages?",
            "Well, obviously you know there's a long tradition of people realizing that learning should be something like program synthesis or program induction, and then.",
            "Kind of getting very scary and saying that just seems that seems impossible, but yet I think something like this has to be right, and so we've been working on various kinds of warmup cases that we can test with people.",
            "But again, for people in AI, I would very much encourage you if you want to take on a real challenge to try to work on this problem of learning as a kind of Bayesian program induction.",
            "Alright, so just to conclude, then the cognitive science question that motivated this work is this question of how does the mind get so much from so little across all these different domains of cognition?",
            "And I tried to show you a toolkit that we've been building on the cognitive science side over the last 10 or 15 years, but in close contact both ways with state of the art research in AI, the idea, the basic idea of thinking of cognition as Bayesian inference in a probabilistic model, but then building these probabilistic models over increasingly structured representations, making them hierarchical with inference at multiple levels of abstraction.",
            "To explain, not just where the knowledge, how the knowledge enables very specific learning from a few examples of how that knowledge itself might be built.",
            "And then most recently and excitingly to us.",
            "This idea of probabilistic programs moving from graphical models where a graph is your basic knowledge representation to a much richer way to think about the causal structure of the world representation language, which is still causal in generative but which is relational, recursive composable.",
            "So we can embed physics inside psychology or think about beliefs about beliefs or desires about desires.",
            "And computationally universal.",
            "This idea of inference as running these programs backwards by conditional simulation is in principle very powerful in practice.",
            "Very intriguing and very difficult, but I hope I've encouraged you to work on it.",
            "The card that there's a long dream of cognitive scientists here, which is also been an AI dream, which is how can we understand common sense, and I can't claim that we've actually got models of human common sense, but we have, I think, made some of the first progress on building quantitative rigorous reverse engineering models.",
            "Of what I could call and what others in cognition is called.",
            "The cognitive science common sense core.",
            "This basic capacity for reasoning about physical objects, intentional agents and their interactions which emerges in early infancy, right?",
            "I didn't describe the infant experiments, but I showed a few of the stimuli.",
            "Even preverbal infants younger than one year who don't talk who don't walk.",
            "Really.",
            "They can do these kinds of common sense inferences, and we built some of the first quantitative models and how these how these theories support inference.",
            "And we're starting to get it how they might be learned as a kind of program induction just a few.",
            "A few last thoughts for AI researchers.",
            "Those who are interested in building human like AI systems, if that's what you want to do.",
            "Just three little pieces of advice, focus on the common sense core.",
            "That's what I think we in cognitive science, and I don't just me, but I mean all the experimentalists and many other modelers over the last say two decades have identified as the heart of things.",
            "This common sense, intuitive physics and psychology that emerges very early in that we can now describe.",
            "With these rigorous reverse engineering models, of course, abstract knowledge is essential.",
            "There's no inductive inference without background knowledge.",
            "That's one of the basic lessons we all have learned over and over many times, but don't think that abstract background knowledge innocence has to be all wired in.",
            "Think about how it might grow.",
            "Think about how it might grow flexibly robustly in response to experience and Lastly, probabilistic programs are the way to go.",
            "But they're hard.",
            "And if you want to work on them, there's.",
            "Many great challenges that will bring you into bidirectional contact with other areas of computer science, right?",
            "So you saw little hints of this was."
        ],
        [
            "Bing, but what's one of the great things about about working with public programs as the basis of AI systems is they bring you into they allow you to build on great successes in the areas of computer science that work even better than I like graphics or physical simulation, right?",
            "Or algorithms are programming languages and they also pose really interesting challenges for people who are coming from those angles.",
            "So it's an exciting time both.",
            "I think for what's going on in cognitive science for the AI cognitive science interface, and I hope I've been able to spread some of that excitement back to.",
            "Two AI and please join us in this.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a great honor to be here.",
                    "label": 0
                },
                {
                    "sent": "I think I might be able to compress some of the introduction to my talk, but 'cause I think you summed up very well what I want.",
                    "label": 0
                },
                {
                    "sent": "Why I'm here and what I'm trying to achieve.",
                    "label": 0
                },
                {
                    "sent": "Let me start off just by acknowledging the people who.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Did the work and thought many if not most or even close to all of the really good ideas here.",
                    "label": 0
                },
                {
                    "sent": "These are junior researchers have worked with who over the years are now gone on to become rather senior themselves.",
                    "label": 0
                },
                {
                    "sent": "Tom Griffiths and Charles Camp were two of the first students who work with me there.",
                    "label": 1
                },
                {
                    "sent": "Now faculty at Berkeley and CMU respectively and their work is sort of very very much.",
                    "label": 0
                },
                {
                    "sent": "The first part of this talk and they're thinking is deeply interlaced throughout it.",
                    "label": 1
                },
                {
                    "sent": "Noah Goodman and the Kashman Sinka, or more recent alumni of our group Noah is now a professor at Stanford.",
                    "label": 0
                },
                {
                    "sent": "Akash is a research scientist at MIT and they played the lead role on the key idea that I'm most excited about.",
                    "label": 0
                },
                {
                    "sent": "Sort of what I hope will be the climax here.",
                    "label": 0
                },
                {
                    "sent": "This notion of probabilistic programs.",
                    "label": 0
                },
                {
                    "sent": "And then I want to highlight a few other researchers, Dan Ryan.",
                    "label": 0
                },
                {
                    "sent": "Cameron Freer, who have been doing some really interesting theoretical work and helped me think about some of the connections between probabilistic programs, their role in cognitive modeling and Turing's original vision for AI.",
                    "label": 1
                },
                {
                    "sent": "Because of course in this year, that's what everybody has to think about rightfully so.",
                    "label": 0
                },
                {
                    "sent": "And then researchers who are currently in our group have done that.",
                    "label": 0
                },
                {
                    "sent": "Taking the lead on the main modeling and experimental projects, Peter Battalia, Chris Baker, Toma Roman and Steve to see.",
                    "label": 1
                },
                {
                    "sent": "Actually Steve recently graduated.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal here the way I like to think of what I'm trying to do, is reverse engineering the mind.",
                    "label": 1
                },
                {
                    "sent": "I'm trying to understand human cognition.",
                    "label": 0
                },
                {
                    "sent": "If I had to choose you MI a cognitive scientist or an AI researcher, I'm I'm a cognitive scientist first and foremost, but the kind of science we're trying to do is a reverse engineering enterprise.",
                    "label": 0
                },
                {
                    "sent": "We want to understand how the mind works in the same kinds of terms that you would use to build an intelligent system.",
                    "label": 1
                },
                {
                    "sent": "Some some kind of human like intelligence in a machine, and we do AI research and other related work in machine learning, partly for its practical benefit, but partly as it may be.",
                    "label": 0
                },
                {
                    "sent": "Most deeply, as a proof of principle, to show these ideas, these engineering ideas that we think explain how natural intelligence works actually work.",
                    "label": 0
                },
                {
                    "sent": "It's rather surprising if you look at how many models, theories, informal and formal accounts that have been proposed over the years in cognitive science or psychology don't actually work as engineering solutions, and that's central to what we think counts as adequate science here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, as Bart mentioned, the fields of cognitive science and AI have grew up together starting in say, the 1950s, and I would say by the 1980s were largely growing apart.",
                    "label": 0
                },
                {
                    "sent": "Cognitive scientists looked at AI and saw field of people who are increasingly just focused on practical applications had given up the big vision of real and human like intelligence, and we're using a lot of math they didn't understand, and AI researchers looked at cognitive scientists and other psychologists and Sodom obsessed with strange, peculiar processing details that didn't really seem to illuminate those big questions anyway.",
                    "label": 0
                },
                {
                    "sent": "And you know, we're very fuzzy and didn't understand any of the math that they should be using now.",
                    "label": 0
                },
                {
                    "sent": "These fields are starting to come back together.",
                    "label": 0
                },
                {
                    "sent": "It's a very exciting time driven by the shared sense that actually they might have something to say to each other.",
                    "label": 0
                },
                {
                    "sent": "Again, Anna, common language.",
                    "label": 0
                },
                {
                    "sent": "Really, that's quite fundamental.",
                    "label": 0
                },
                {
                    "sent": "A common language in which to say it.",
                    "label": 0
                },
                {
                    "sent": "If you had to say where does this start from?",
                    "label": 0
                },
                {
                    "sent": "Let's start from success.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "AI has been a success or we're living in an era of real AI successes.",
                    "label": 1
                },
                {
                    "sent": "Maybe that's a better way to put it.",
                    "label": 0
                },
                {
                    "sent": "Certainly this conference highlighted some of these successes we're all familiar with them in our daily lives.",
                    "label": 0
                },
                {
                    "sent": "You know, even those.",
                    "label": 1
                },
                {
                    "sent": "Even if we weren't, all AI professionals here, you can actually read about working AI technologies in the newspaper.",
                    "label": 0
                },
                {
                    "sent": "See them on TV.",
                    "label": 0
                },
                {
                    "sent": "Use them in your daily life.",
                    "label": 0
                },
                {
                    "sent": "And these are technologies that the early founders of the field.",
                    "label": 0
                },
                {
                    "sent": "Whatever the big vision they had, they would have to have been impressed, right?",
                    "label": 0
                },
                {
                    "sent": "Clearly?",
                    "label": 0
                },
                {
                    "sent": "These are successes.",
                    "label": 0
                },
                {
                    "sent": "These systems, whether it's Google face recognition, pedestrian recognition systems, various kinds of recommendation systems, things like you know these, Siri, the new Voice interface to the iPhone, which works at least some of the time, maybe most prominently in the news.",
                    "label": 0
                },
                {
                    "sent": "IBM's Watson Jeopardy playing system or after this morning.",
                    "label": 0
                },
                {
                    "sent": "I definitely have to add Google's self driving cars.",
                    "label": 0
                },
                {
                    "sent": "I mean who couldn't have failed to be impressed by these amazing things.",
                    "label": 0
                },
                {
                    "sent": "And if we have to say well what's driving them, maybe the sort of one word.",
                    "label": 0
                },
                {
                    "sent": "One phrase story is something like statistics, statistics on the grand scale, massive data coming in through all kinds of sensors, and then various kinds of sophisticated ways of finding patterns in that data, clusters, correlations, low dimensional structure, maybe even something a little bit causal.",
                    "label": 0
                },
                {
                    "sent": "And that has not how could that fail to get the attention of people in many fields.",
                    "label": 0
                },
                {
                    "sent": "In particular, cognitive scientists.",
                    "label": 0
                },
                {
                    "sent": "You know people like me.",
                    "label": 0
                },
                {
                    "sent": "I got into the field in the mid 90s and while that was well before these successes were hitting the front pages, you know there were much smaller scale versions that we also clearly saw where these were coming from.",
                    "label": 0
                },
                {
                    "sent": "You know the whole probabilistic revolution in AI that was.",
                    "label": 0
                },
                {
                    "sent": "That was the time I was getting into the field.",
                    "label": 0
                },
                {
                    "sent": "So that got attention at the same time, the gaps are also clear.",
                    "label": 0
                },
                {
                    "sent": "While each of these systems achieves.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some human level, maybe even expert level you know as good or better than the experts performance in some particular aspect of intelligent behavior.",
                    "label": 0
                },
                {
                    "sent": "None of them we would say is truly intelligent.",
                    "label": 0
                },
                {
                    "sent": "Some actually intelligent engineers had to build them and each one of them does one of these things.",
                    "label": 0
                },
                {
                    "sent": "But compared with you know and no one had to engineer you to solve these problems to to learn how to drive or learn how to play jeopardy.",
                    "label": 0
                },
                {
                    "sent": "You may not play Jeopardy as well as Watson, but you only had to watch that game for a couple of minutes maybe, maybe not even be told the rules or just be told the rules in just a couple of sentences.",
                    "label": 0
                },
                {
                    "sent": "And then you get it and you can perform an endless number of tasks without having to be programmed.",
                    "label": 0
                },
                {
                    "sent": "You program yourself.",
                    "label": 0
                },
                {
                    "sent": "We want to understand that gap.",
                    "label": 0
                },
                {
                    "sent": "So I want to talk about the successes that have driven the reconvergence, largely thinking about various kinds of statistical approaches.",
                    "label": 0
                },
                {
                    "sent": "But how do we make these kinds of approaches more sophisticated to actually get at the remaining gap?",
                    "label": 0
                },
                {
                    "sent": "Now let me shift over to the cognitive science side and say, here's the big question that animates.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Me as a cognitive scientist and a lot of a lot of other work in our field and we'll see how this starts to come back to to wear this gap is when we look at at cognition we see throughout whether we're talking about perception, reasoning, learning.",
                    "label": 0
                },
                {
                    "sent": "We see this fundamental gap between the data coming in through your senses and what you do with it.",
                    "label": 0
                },
                {
                    "sent": "Our minds build models, abstractions, generalizations that seem to go so far beyond the data.",
                    "label": 0
                },
                {
                    "sent": "That's their house.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be able to do that.",
                    "label": 0
                },
                {
                    "sent": "Here's a little demo.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that is something that we've been studying in the lab.",
                    "label": 0
                },
                {
                    "sent": "It's meant to abstract in a form that we can study with adults.",
                    "label": 0
                },
                {
                    "sent": "The problem that a child faces when they're learning a word as anybody who's ever been a child or had a child might remember.",
                    "label": 0
                },
                {
                    "sent": "A remarkable ability, you see, a remarkable ability in children to learn concepts, even just to label a concept like table Chair, Cup dog from just a very small number of positive examples.",
                    "label": 0
                },
                {
                    "sent": "Contrast this with the situation of most traditional machine learning, where classification is seen as something which requires many positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "So to remind you of this phenomenon and how much fun it is, we'll just do a little demo here to wake everyone up after lunch.",
                    "label": 0
                },
                {
                    "sent": "I've shown you these novel objects we made in an object generating program and I've highlighted.",
                    "label": 0
                },
                {
                    "sent": "A few examples of Tufas, and now you tell me which are the other two things will just go through this with the pointer, so too far yes or no.",
                    "label": 1
                },
                {
                    "sent": "Here, but it's too far from my pointer in my shaky hands, so I'll do it like this if you can say OK, yes now this one.",
                    "label": 0
                },
                {
                    "sent": "Wake up yes or no too far no.",
                    "label": 0
                },
                {
                    "sent": "OK this one.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, little more uncertainty there.",
                    "label": 0
                },
                {
                    "sent": "That's OK, because we've got probabilistic models here.",
                    "label": 0
                },
                {
                    "sent": "So, so what's going on?",
                    "label": 0
                },
                {
                    "sent": "Think of this as a math problem, right?",
                    "label": 0
                },
                {
                    "sent": "There's this infinite set of all objects, and it's truly infinite, because we generated it with a generative program and somewhere in this infinite space of all objects is an infinite but very constrained subset that you could call the two phase.",
                    "label": 0
                },
                {
                    "sent": "And somehow you're able to pick out the boundaries of that said, not perfectly, but roughly from just these few points randomly sampled within it.",
                    "label": 0
                },
                {
                    "sent": "And we work on these kinds of prob.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whether we're thinking about, they often arise in language or or, for example, causal learning, right?",
                    "label": 0
                },
                {
                    "sent": "So you know.",
                    "label": 0
                },
                {
                    "sent": "Again, I mean, it's a great time to be addressing AI audience because of the very broad recognition of the work of Judea Pearl.",
                    "label": 0
                },
                {
                    "sent": "That's not only revolutionized AI, but also many other fields.",
                    "label": 0
                },
                {
                    "sent": "And so we're all familiar now with various kinds of principles that can be used to learn causal structure from observation, ull an interventional data.",
                    "label": 0
                },
                {
                    "sent": "But think about the way.",
                    "label": 0
                },
                {
                    "sent": "That children often learn causal structure.",
                    "label": 0
                },
                {
                    "sent": "Sometimes they get it wrong, but you know, quite quite often get it right from just not not even enough data to sort of compute the patterns of conditional dependence and independence that are at the heart of classic Bayes net causal structure learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "But even just a few, again, a few data points that aren't even enough to establish a reliable reliable pattern of statistical dependence or correlation, right like the right kind of spatial temporal coincidence.",
                    "label": 0
                },
                {
                    "sent": "How how are children able to do that?",
                    "label": 0
                },
                {
                    "sent": "I would say the most exciting thing that we're getting at here is larger scale systems of knowledge.",
                    "label": 0
                },
                {
                    "sent": "What are sometimes called intuitive theories, not just learning a single concept, but systems of concepts that together describe some common sense domain like common sense physics or common sense psychology.",
                    "label": 0
                },
                {
                    "sent": "So just to illustrate this a little bit, I'm talking about these kinds of problems and you'll see I think, hopefully the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "AI relevance of these problems, let's say we're interested in understanding a visual scene like the one in the upper left.",
                    "label": 0
                },
                {
                    "sent": "We don't just want to know what is where, to recognize objects and localized, but we want to understand what's going on in terms of the physics, like this table of supporting those objects or certain objects must be very likely to be attached to that back wall that you couldn't move them.",
                    "label": 0
                },
                {
                    "sent": "Others are hanging there, so they're not going to fall, but you could lift them up right?",
                    "label": 0
                },
                {
                    "sent": "Or looking at that, looking at the construction senior, how do you know which of those planks of wood you could move?",
                    "label": 0
                },
                {
                    "sent": "Or Witcher Witcher free, which were attached?",
                    "label": 0
                },
                {
                    "sent": "Which are absolutely vital to supporting structure?",
                    "label": 0
                },
                {
                    "sent": "We use this kind of intuitive physical knowledge to diagnose situations that are maybe accidents waiting to happen or requiring special care like the stack of dishes, and then think about social interaction between people.",
                    "label": 0
                },
                {
                    "sent": "How do we look at a scene where?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're just an observer watching one of these scenes or a participant and just get instantly what's going on, what the what, the different people in the scene are thinking, what they want, what they're feeling, how do we get at their mental states from their actions?",
                    "label": 0
                },
                {
                    "sent": "That's a kind of intuitive psychology.",
                    "label": 0
                },
                {
                    "sent": "These are hard problems.",
                    "label": 0
                },
                {
                    "sent": "If we could solve this would pretty much be done, and this, But these are.",
                    "label": 0
                },
                {
                    "sent": "These are the problems that we're setting our sights on.",
                    "label": 0
                },
                {
                    "sent": "We want to get there by backing off to some easier problems, and many AI researchers as well as cognitive scientists have pointed out that you could get a lot of these basic kind of common sense physics and psychology.",
                    "label": 0
                },
                {
                    "sent": "By just studying what small children do with stacks of blocks on their own, building up things or in combination, and I'll show you some research that's really trying to get at this, but you can start even simpler.",
                    "label": 0
                },
                {
                    "sent": "Let me show you a couple of two other demos that I think are some of the nicest ways to see these kind of core common sense, intuitive physical and intuitive psychological theories at work and again show you these minds that remark.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Capability to make inferences from sparse data.",
                    "label": 0
                },
                {
                    "sent": "So here are a couple of little movies.",
                    "label": 0
                },
                {
                    "sent": "The first one is by Southgate and Chevre, two developmental psychologists.",
                    "label": 1
                },
                {
                    "sent": "It's from a study with 13 month old infants, so just watch this.",
                    "label": 0
                },
                {
                    "sent": "I'll play it a couple of times and you can see here.",
                    "label": 0
                },
                {
                    "sent": "Well, what do you see?",
                    "label": 0
                },
                {
                    "sent": "You see 2 balls, a blue ball.",
                    "label": 0
                },
                {
                    "sent": "Just play it again.",
                    "label": 0
                },
                {
                    "sent": "Anna Red Ball and they're rolling on a green surface with some kind of beige obstacles, right?",
                    "label": 0
                },
                {
                    "sent": "But if you were to describe this, what's the most natural way to describe what's going on here?",
                    "label": 0
                },
                {
                    "sent": "Chasing right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's that's I heard that from a few different people it looks like the blue ball is chasing the red ball in the red balls trying to get away.",
                    "label": 0
                },
                {
                    "sent": "And while it's an interesting kind of chasing because it's also kind of slightly dumb chasing right the blue ball thinks he can fit through those holes that he can't actually right, and he seems to have to sort of back out and go around.",
                    "label": 0
                },
                {
                    "sent": "So you're attributing a goal to the blue ball and also to the red ball.",
                    "label": 0
                },
                {
                    "sent": "The red ball is trying to get away a kind of desire, as well as the belief of maybe a false belief in this case that he thinks he can fit through some holes which he can, as well as some true beliefs.",
                    "label": 0
                },
                {
                    "sent": "He roughly seems to know where the red guy is.",
                    "label": 0
                },
                {
                    "sent": "Alright, here's another video which is much more famous.",
                    "label": 0
                },
                {
                    "sent": "That's a classic in social psychology.",
                    "label": 0
                },
                {
                    "sent": "It's from 2 psychologists.",
                    "label": 0
                },
                {
                    "sent": "Hydrogen symbol in a study that was published in the 1940s.",
                    "label": 0
                },
                {
                    "sent": "Just curious how many people are familiar with hydrogen symbol video.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, it's so striking.",
                    "label": 0
                },
                {
                    "sent": "If you haven't seen it before and all you remember from the talk is this video great?",
                    "label": 0
                },
                {
                    "sent": "So again, you could parse this as two triangles moving in a circle, moving and some other lines, but you don't see it that way.",
                    "label": 0
                },
                {
                    "sent": "You see objects that are banging into each other and the again you feel like they're intentional agents with stories and desires.",
                    "label": 0
                },
                {
                    "sent": "It looks like that big triangle is kind of.",
                    "label": 0
                },
                {
                    "sent": "I'll just play it again.",
                    "label": 0
                },
                {
                    "sent": "It's kind of maybe bullying the little triangle.",
                    "label": 0
                },
                {
                    "sent": "Banging into him and then he's going to be sort of the circle.",
                    "label": 0
                },
                {
                    "sent": "Kind of seems to observe and now is going to hide inside, and once the big triangle is kind of scared off the little triangle there he goes back in, goes in there and sort of Q the ominous scary music.",
                    "label": 0
                },
                {
                    "sent": "You haven't seen this video.",
                    "label": 0
                },
                {
                    "sent": "You can watch it all on YouTube and I know I left it at a kind of a moment of suspense.",
                    "label": 0
                },
                {
                    "sent": "Don't worry, it ends happily, at least for the two of the three characters.",
                    "label": 0
                },
                {
                    "sent": "Alright, so what's going on here again?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know from just what you could think of is just a few numbers in time.",
                    "label": 0
                },
                {
                    "sent": "These are low dimensional time series.",
                    "label": 0
                },
                {
                    "sent": "If you think about how many, how much information is required to describe these movies?",
                    "label": 0
                },
                {
                    "sent": "They're not nearly as rich as a full natural scene.",
                    "label": 0
                },
                {
                    "sent": "I mean contrast this strikingly with what Sebastian showed us is the really massive data coming in from a street scene to a Google self driving car.",
                    "label": 0
                },
                {
                    "sent": "Here you have very little data, but look at how much you see you see real physics objects with force dynamics.",
                    "label": 0
                },
                {
                    "sent": "You see real psychology, beliefs, desires, intentions, emotions.",
                    "label": 0
                },
                {
                    "sent": "And even more what you might call things like sort of morality in sociology, like who's on Who's team, who's a good guy, who's a bad guy?",
                    "label": 0
                },
                {
                    "sent": "Most people here see the big triangle is kind of a bad guy and the other two is being on a team.",
                    "label": 0
                },
                {
                    "sent": "So how do you do that?",
                    "label": 0
                },
                {
                    "sent": "How do you get so much from so little?",
                    "label": 0
                },
                {
                    "sent": "This is the kind of thing we want to understand, and I think if we could even make progress on just those last steps and then building up to things like kids with their with their blocks and building up to sort of real common sense physics and psychology and natural scenes would be somewhere OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the approach that we've been pursuing over, I would say over the last 10 or 15 years or so in computational cognitive science is very much one that I think many people will recognize here is in common with a lot of the state of the art.",
                    "label": 0
                },
                {
                    "sent": "In AI, there's a clear recognition of the importance of statistics, both in data in terms of inference, but the really the heart of things is about the interaction between statistics and knowledge.",
                    "label": 0
                },
                {
                    "sent": "In all these cases, the data on its own that's observed isn't enough to make the inferences you make, so something else has to fill in the gaps some other kind of abstract or background knowledge.",
                    "label": 0
                },
                {
                    "sent": "And the key questions have to do with the interaction between those.",
                    "label": 0
                },
                {
                    "sent": "How does background knowledge guide these inferences from such sparse data?",
                    "label": 1
                },
                {
                    "sent": "What form does that knowledge take across the all these different domains and tasks?",
                    "label": 0
                },
                {
                    "sent": "And maybe most interesting, how might how might it get in there if the brain is doesn't isn't programmed by a smart engineer?",
                    "label": 0
                },
                {
                    "sent": "In some sense, it has to program itself learning of abstract knowledge is absolutely critical, so the kind of.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ideas that we've been pursuing are shown here in red.",
                    "label": 0
                },
                {
                    "sent": "Broadly, we're taking a Bayesian approach with the probabilistic inference framework, where that part of things is some kind of a generative model, some kind of hypothesis space of ways to account for the data, and some kind of prior over those.",
                    "label": 0
                },
                {
                    "sent": "But it will go well beyond anything that looks just like Bayes rule, where as an AI we're not talking about exact Bayesian inference, we're talking about some kind of approximation, because these computations are going to be intractable to do in any exact way.",
                    "label": 0
                },
                {
                    "sent": "And again as as is pretty much now, I think you know, well recognized in this community, but is one that say the statistical machine learning community is only more recently coming too and sometimes not even at all, and is also still quite new in the cognitive science and neuroscience community.",
                    "label": 0
                },
                {
                    "sent": "Statistics is not just something you do with numbers, it's not just something you do in high dimensional vector spaces, but it's something that you can do with real knowledge with representations of the world and data that look much more like the sort of earlier classic AI approaches.",
                    "label": 0
                },
                {
                    "sent": "Various kinds of symbolic knowledge, representations, graphs, grammars, schemas, predicate logic, and I think in common with a number of people in this community that the number one thing we need to do to understand to build tools that can allow us to understand this kind of these aspects of human intelligence is to understand how statistical inference and learning can operate with these kinds of representations.",
                    "label": 1
                },
                {
                    "sent": "And that takes us beyond what is unfortunate, common legacy of these two fields, which is, you know, decades of fighting over statistics versus.",
                    "label": 0
                },
                {
                    "sent": "Structured representations, it's nice that you know in the last decade we've seen how these approaches can interweave, and really deep and interesting ways.",
                    "label": 0
                },
                {
                    "sent": "Maybe most exciting is this idea, which I'll try to get to by the end of what we call probabilistic programs.",
                    "label": 0
                },
                {
                    "sent": "So where you're doing probabilistic reasoning, not just over things like grammars or predicate logic, But actual programs.",
                    "label": 0
                },
                {
                    "sent": "In particular, we're looking at functional programs, so list is come back in our work in a certain way here, and I'll try to argue why this is.",
                    "label": 1
                },
                {
                    "sent": "I think an approach that subsumes a lot of what we and others have been doing with other kinds of structured probabilistic models in a powerful way for common sense reasoning.",
                    "label": 1
                },
                {
                    "sent": "And then this last maybe most compelling question of how might knowledge itself be acquired?",
                    "label": 0
                },
                {
                    "sent": "Well, here we've been drawing on ideas that have become very popular in the Bayesian machine learning community and themselves drew on the Bayesian statistics community what are called hierarchical models or Hierarchical Bayes where you don't just have one level of a hypothesis generating data and a prior there but but multiple levels hypothesis spaces of hypothesis, an priors on priors, and by doing inference at all levels of that hierarchy, you can explain how some piece of abstract knowledge at a certain level isn't just useful in guiding influence at the lower level.",
                    "label": 1
                },
                {
                    "sent": "But itself might be learned over, say, broader timescale or broader sources of data by inference at higher levels of abstraction, and when you put all of these things together, you put hierarchical Bayes together with the idea of probabilistic programs as your basic knowledge representation.",
                    "label": 0
                },
                {
                    "sent": "Then you're talking about these hierarchies of programs that generate other programs.",
                    "label": 0
                },
                {
                    "sent": "Again, an idea that has very important early precursors.",
                    "label": 1
                },
                {
                    "sent": "If people remember the work of people like Feldman, Horning on grammar grammars, and the earliest probabilistic grammar induction approaches, and.",
                    "label": 0
                },
                {
                    "sent": "It's sort of a kind of a hierarchical Bayesian approach to learning as program induction.",
                    "label": 0
                },
                {
                    "sent": "This is just something we can glimpse at this point, and maybe at the end I'll show you a little bit of a demo of where we're going with that, but it's just, you know that's mostly as Sebastian said, you invite me back in 2028 or something, and maybe we'll actually have that settled.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I want to do here is in this talk is give you a bit of a tour.",
                    "label": 0
                },
                {
                    "sent": "Through the way we've been using these ideas to understand these hard problems of human cognition, things like learning from very few examples or common sense, intuitive physics and psychology.",
                    "label": 0
                },
                {
                    "sent": "I want to take one step back just because I'm coming from a different field.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And just set a little bit again of the context.",
                    "label": 0
                },
                {
                    "sent": "You'll see a parallel with the AI field.",
                    "label": 0
                },
                {
                    "sent": "When I got into cognitive science, this was in the mid 90s.",
                    "label": 0
                },
                {
                    "sent": "Basically in grad school, just as just as an AI.",
                    "label": 0
                },
                {
                    "sent": "There was a lot of skepticism over whether statistics and probability infants was even relevant.",
                    "label": 0
                },
                {
                    "sent": "Probably many people are familiar with the work of condiment averse key, very important work, justly deserving of the Nobel Prize that Kahneman won in economics in 2002.",
                    "label": 0
                },
                {
                    "sent": "But the headline of this work for psychologist was basically people aren't Bayesian.",
                    "label": 1
                },
                {
                    "sent": "They gave people an.",
                    "label": 0
                },
                {
                    "sent": "A lot of other researchers in the field of judgment and decision making around and following them gave people very, very basic Bayesian stats.",
                    "label": 0
                },
                {
                    "sent": "Questions like these things simple earn problems like you've drawn a certain sample of red and white chips out of this order that turn, and they have the urns have different composition of red and white chips in them proportions.",
                    "label": 0
                },
                {
                    "sent": "Which one is more likely, or what's the relative probability that this order and it turns out people are kind of things, or you give them just a few statistics that they could plug into Bayes rule in a very elementary way, and the average person that's often doesn't know what to do with that.",
                    "label": 0
                },
                {
                    "sent": "And this crapped out into the popular press in all sorts of ways.",
                    "label": 1
                },
                {
                    "sent": "Maybe the most famous was one of Stephen Jay Gould's most famous essays.",
                    "label": 0
                },
                {
                    "sent": "Yet again, this is what people were reading when I got into the field, saying our minds are not built for whatever reason to work by the rules of probability.",
                    "label": 1
                },
                {
                    "sent": "But people who came of age when I did, you know they saw the not just the work that you did.",
                    "label": 0
                },
                {
                    "sent": "Pearl was doing, but all of the probabilistic revolution in machine learning and AI.",
                    "label": 0
                },
                {
                    "sent": "We just thought you know that's that's crazy.",
                    "label": 0
                },
                {
                    "sent": "Clearly this this is a strong candidate, at least for understanding something about intelligence.",
                    "label": 0
                },
                {
                    "sent": "So the beginning of this research program was for me at least, was work that I did together with Tom Griffiths, where we took a number of basic cognitive capacities and just.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I to see could we understand these as basic forms of intuitive statistics, typically Bayesian statistics where there's some kind of key role being played by some prior knowledge that we can formalize in simple kind of textbook style statistical distribution.",
                    "label": 0
                },
                {
                    "sent": "So I'll show you just one exam.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All of this 'cause it's one that anybody who studied Bayesian statistics might recognize, and it sort of sets out the logic you might want to to aim for, and then raises a challenge for.",
                    "label": 0
                },
                {
                    "sent": "How do we get to more structured kinds of abstract knowledge?",
                    "label": 0
                },
                {
                    "sent": "So here are a bunch of problems that all have a similar form.",
                    "label": 0
                },
                {
                    "sent": "You read about a movie that's made $60,000,000 to date.",
                    "label": 1
                },
                {
                    "sent": "How much money will it make in total?",
                    "label": 1
                },
                {
                    "sent": "You see that something's been baking in the oven for 34 minutes.",
                    "label": 1
                },
                {
                    "sent": "How long until it's ready?",
                    "label": 0
                },
                {
                    "sent": "You meet someone who is 78 years old?",
                    "label": 0
                },
                {
                    "sent": "How long will they live?",
                    "label": 0
                },
                {
                    "sent": "Your friend quotes to you from line 17 of his favorite poem.",
                    "label": 1
                },
                {
                    "sent": "How long is the poem?",
                    "label": 0
                },
                {
                    "sent": "Or you need a US Congressman who served for 11 years.",
                    "label": 0
                },
                {
                    "sent": "How long will he serve in total?",
                    "label": 0
                },
                {
                    "sent": "So each of these is what we call in every day prediction form.",
                    "label": 0
                },
                {
                    "sent": "There's some quantity event duration will represent that with T that you would like to make an inference about, but you don't deserve this.",
                    "label": 0
                },
                {
                    "sent": "You just observe some sample or let's say sorry I use my notation teetotal is represents the unknown total extent or duration of one of these phenomena.",
                    "label": 0
                },
                {
                    "sent": "And you observe one data point.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That all you know is that it's a random sample between zero and T total and you have to make a guess at thetotal.",
                    "label": 0
                },
                {
                    "sent": "Now what's nice about these problems is that these different classes of everyday events we can go out and with publicly available data come up with the right prior.",
                    "label": 0
                },
                {
                    "sent": "Those are shown along the top here, and I won't really go through the specifics, but for each of these different domains, movie grosses poems, and so on, life spans you can compute the empirical distribution on how long these things last, and then you can now do Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "You can condition this prior on one observation and then make a guess the particular estimator that we're using is what's called the posterior median.",
                    "label": 0
                },
                {
                    "sent": "So we're updating this prior with one sample that we know is all we know is that it's between zero and and T, and that's the prior on the total.",
                    "label": 1
                },
                {
                    "sent": "And then we take our posterior distribution and we look at the median and say that's our best guess at how long this thing is going to last and what you can see on the bottom are plots of the posterior median predictor for for the for the empirical priors up there, and they're plotted against peoples judgments for five of five different data points.",
                    "label": 0
                },
                {
                    "sent": "The X axis is represents the value that people were given.",
                    "label": 1
                },
                {
                    "sent": "the Y axis is the median of peoples guesses on on each of these problems.",
                    "label": 0
                },
                {
                    "sent": "Given one of those inputs so.",
                    "label": 1
                },
                {
                    "sent": "Just to be very concrete, that means like some subjects were told about a movie that made $60,000,000, but others were told about one that may say $30,000,000 or 100 million dollars.",
                    "label": 0
                },
                {
                    "sent": "And there were five different values across subjects for each of these different questions.",
                    "label": 0
                },
                {
                    "sent": "And all I want you to take out from this is that people are extremely close to the Bayesian predictions.",
                    "label": 0
                },
                {
                    "sent": "There's a sense here in which people are sort of doubly optimal, their optimal in the sense that the mapping from the top to the bottom, the prior to the posterior predictive is the optimal Bayesian prediction.",
                    "label": 0
                },
                {
                    "sent": "And people seem to match that.",
                    "label": 0
                },
                {
                    "sent": "But notice how the qualitative form of the optimal Bayesian prediction varies across each of these domains, 'cause the priors have different forms and that shows up in the posterior prediction.",
                    "label": 1
                },
                {
                    "sent": "People seem to get it.",
                    "label": 0
                },
                {
                    "sent": "It's as if they're doing the right mapping from prior to posterior with the right prior that's tuned to the structure of the domain.",
                    "label": 0
                },
                {
                    "sent": "So this another kind of very basic quantitative success is convinced us and others to take the idea of probabilistic inference framework for cognition seriously.",
                    "label": 0
                },
                {
                    "sent": "But how do you now get this?",
                    "label": 0
                },
                {
                    "sent": "To scale up to these hard problems that I'm saying, we really want to solve like the problem of learning.",
                    "label": 0
                },
                {
                    "sent": "Allez.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For objects from a few examples or intuitive reasoning about physical scenes or intentional agents interactions, it's not even clear here what's the right prior hypothesis space, or how you could measure it for us as scientists, let alone for human learners who are trying to build up this knowledge.",
                    "label": 1
                },
                {
                    "sent": "So this leads us to turn towards some kind of more expressive knowledge, representation language, something that isn't just you know, exponential family distribution you can get from a Bayesian stats book.",
                    "label": 0
                },
                {
                    "sent": "And like many people in a I was heavily influenced by.",
                    "label": 0
                },
                {
                    "sent": "The work of.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not just Pearl, but many others.",
                    "label": 0
                },
                {
                    "sent": "In the tradition of probabilistic graphical models, Bayes Nets directed graphical models seem particularly appealing because so much of human cognition, so much of what I've been talking about here is essentially causal.",
                    "label": 1
                },
                {
                    "sent": "But it no more generally the toolkit of graphical models has been very influential, not only in AI, but to cognitive modelers for similar reasons.",
                    "label": 0
                },
                {
                    "sent": "It gives you 2 main things.",
                    "label": 0
                },
                {
                    "sent": "It gives you a general purpose knowledge representation language right away to represent the structure of some complex domain, and it gives you general tools for doing inference.",
                    "label": 0
                },
                {
                    "sent": "So all you have to do is the modeler is described the causal structure.",
                    "label": 0
                },
                {
                    "sent": "Let's say you're using a Bayes net and just the sort of direct causal dependencies.",
                    "label": 0
                },
                {
                    "sent": "That's the arrows in the graph, and then the tools of Bayes Nets give you in principle and in working tools that people have built.",
                    "label": 0
                },
                {
                    "sent": "And ability to do arbitrary conditional inference is to observe some variables and make inferences about others, right?",
                    "label": 0
                },
                {
                    "sent": "So in the famous QMR network there you might observe symptoms and make inferences about diseases.",
                    "label": 0
                },
                {
                    "sent": "You might then make predictions about other symptoms, the results of medical tests you might see, and so on.",
                    "label": 0
                },
                {
                    "sent": "This is, again, very familiar.",
                    "label": 0
                },
                {
                    "sent": "And something basically, I think there's something basically right about some kind of probabilistic causal representation language as the way to think about common sense, but what's missing from this well?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is what leads us to these.",
                    "label": 0
                },
                {
                    "sent": "These kinds of representations we call probabilistic programs.",
                    "label": 1
                },
                {
                    "sent": "Basically, it's the idea that a graph is too impoverished, representation too simple.",
                    "label": 0
                },
                {
                    "sent": "To describe the kind of rich knowledge that humans have about the causal structure of the world, we need some kind of more powerful probabilistic language, some more powerful way of describing the probabilistic causal structure of the world.",
                    "label": 1
                },
                {
                    "sent": "So think about this kind of this workshop scene that I've shown a few times.",
                    "label": 0
                },
                {
                    "sent": "How can you take an image and make an inference about not just what's where but what?",
                    "label": 0
                },
                {
                    "sent": "What supporting what would happen if you if you move the table, you know that those things would fall.",
                    "label": 0
                },
                {
                    "sent": "You can see there's a tire, maybe you can see over there on the lower right there's a tire leaning up against.",
                    "label": 0
                },
                {
                    "sent": "The table you can probably make the inference that tire is a little more precarious than, say, one of those cups.",
                    "label": 0
                },
                {
                    "sent": "That's right there very solidly on the top of the table, so a slight bump might make the table might make the tire fall, but won't affect the cups on there.",
                    "label": 0
                },
                {
                    "sent": "How can you do this?",
                    "label": 0
                },
                {
                    "sent": "Well, here's a way of thinking about it, which in some sense looks like a Bayes net as a way to capture this intuitive knowledge here.",
                    "label": 0
                },
                {
                    "sent": "But it also I think, draws attention to what's missing, so we have this have this picture here, which describes what I think of is roughly the causal processes that are giving rise to this data.",
                    "label": 0
                },
                {
                    "sent": "There is some kind of image that you observe and here I'm showing just a static image, but in general we could be looking at dynamic scenes like those movies I showed and that image is is some kind of output of a graphics processor graphics is that, let's say is the process which takes some underlying 3D World state, which we could think of something like a CAD model, and that's not.",
                    "label": 0
                },
                {
                    "sent": "That's not directly observed, so I've grayed out the world state there at time T and but some graphics function renders that 3D World state into a 2D observable image.",
                    "label": 0
                },
                {
                    "sent": "And overtime, the world state evolves with some other causal process which we could call physics.",
                    "label": 0
                },
                {
                    "sent": "And then again graphics keeps operating each point in time right?",
                    "label": 0
                },
                {
                    "sent": "So and what you observe is the output of that process.",
                    "label": 0
                },
                {
                    "sent": "The sequence of images.",
                    "label": 0
                },
                {
                    "sent": "So probably most people in the recognize that that looks just like an hmm, right?",
                    "label": 0
                },
                {
                    "sent": "That's there's an underlying latent state evolves with some dynamics, and then there's observations that are conditionally independent of different points in time conditioned on the current state.",
                    "label": 0
                },
                {
                    "sent": "OK, but would we actually want to use an HMM and the standard tools of hidden Markov models for representing this?",
                    "label": 0
                },
                {
                    "sent": "No, I don't think so, right, because there isn't.",
                    "label": 0
                },
                {
                    "sent": "If you want to think about intuitive physics in these scenes, there isn't any kind of fixed dimensional state vector, right?",
                    "label": 0
                },
                {
                    "sent": "And even if we were to try to represent with some fixed dimensional state, it wouldn't capture the intrinsic relational nature of what's going on here that this object is on top of that object.",
                    "label": 0
                },
                {
                    "sent": "Or this one is attached to that object?",
                    "label": 0
                },
                {
                    "sent": "And if we think about the state transition matrix or the observation matrix, yes, you could encode all your knowledge of graphics and a gigantic state transition matrix.",
                    "label": 0
                },
                {
                    "sent": "Which state state observation matrix which has on one dimension every possible configuration of every possible set of objects, and then on the other dimension every possible image.",
                    "label": 0
                },
                {
                    "sent": "And you can encode all your knowledge of physics in a gigantic state transition matrix, but all the interesting structure that you could actually use to support learning reasoning would be lossed there.",
                    "label": 0
                },
                {
                    "sent": "So instead think about the kind of representation that other areas of computer science used for these kinds of things, like people who are interested in graphics or physical simulation.",
                    "label": 0
                },
                {
                    "sent": "They don't draw graphs, they write programs, and that's the basic insight here is to try to define probabilistic causal models where the underlying representation isn't a graph with nodes and arrows, but functions which call other functions the way you might have a node.",
                    "label": 0
                },
                {
                    "sent": "That sort of calls other nodes.",
                    "label": 0
                },
                {
                    "sent": "It's parents, right?",
                    "label": 0
                },
                {
                    "sent": "And these are these are probably.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Programs where we use probabilities to capture the uncertainty about the things we don't directly observe, just like in probabilistic graphical models.",
                    "label": 1
                },
                {
                    "sent": "And just like in graphical models, the main work is done by specifying the program and then you can and then you can run this in any which way you can run it forward to do prediction planning.",
                    "label": 0
                },
                {
                    "sent": "Maybe an you can run it backwards in some sense to do inference, explanation and learning, and I'm not going to say very much about the inference algorithms.",
                    "label": 1
                },
                {
                    "sent": "I'm actually going to say almost nothing about the inference algorithms that people have been using for these probabilistic programs.",
                    "label": 0
                },
                {
                    "sent": "The main ones that we and others use our various kinds of conditional simulation like Monte Carlo algorithms that will sort of forward sample or try to do some kind of the same way that we use MCMC, Metropolis Hastings type algorithms.",
                    "label": 0
                },
                {
                    "sent": "For example, we can do Metropolis Hastings.",
                    "label": 1
                },
                {
                    "sent": "In graphical models we can do Metropolis Hastings in the space of program evaluation traces.",
                    "label": 0
                },
                {
                    "sent": "That's at least the conceptual idea for how you, how you run these programs backwards, but just the high level point is think about inference in probabilistic programs as taking programs describe the causal structure of the world.",
                    "label": 0
                },
                {
                    "sent": "Just like the graph in a Bayes net and then just like the way you sort of turn the Bayesian crank and a graphical models generic inference algorithm.",
                    "label": 0
                },
                {
                    "sent": "Our hope is to be able to have some kind of generic Bayesian crank you can turn which will allow you to run these programs backwards or forwards to condition on partial.",
                    "label": 0
                },
                {
                    "sent": "Outputs and make inferences about the inputs of these programs or other outputs.",
                    "label": 0
                },
                {
                    "sent": "And maybe one other summary here is to and this is not the only way to think about a public program, but to me, and for the purposes of common sense reasoning, I'm saying, think of a public program as a representation for causal process that like a Bayes net is generative.",
                    "label": 0
                },
                {
                    "sent": "But unlike a traditional Bayes net, is relational.",
                    "label": 1
                },
                {
                    "sent": "It's sort of object and entity and relation based.",
                    "label": 1
                },
                {
                    "sent": "It can support recursion, and they can be composed just like programs.",
                    "label": 0
                },
                {
                    "sent": "And really in a sense it's a computationally universal representation.",
                    "label": 0
                },
                {
                    "sent": "Which is both of course very powerful thing and a very dangerous thing to illustrate.",
                    "label": 0
                },
                {
                    "sent": "Again, another place where you want to think about public programs.",
                    "label": 0
                },
                {
                    "sent": "This other kind of common sense domain.",
                    "label": 0
                },
                {
                    "sent": "Think about intuitive psychology here, right?",
                    "label": 0
                },
                {
                    "sent": "So the classic, the classic way that both psychology.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And AI researchers have thought the most minimal kind of model of intentional agent is to say, well, there's some beliefs and desires and they give rise to actions.",
                    "label": 0
                },
                {
                    "sent": "Right now the the classic sort of intuitive qualitative way to say what's the relation between beliefs and desires and actions.",
                    "label": 0
                },
                {
                    "sent": "Will something like this.",
                    "label": 0
                },
                {
                    "sent": "A principle of rationality?",
                    "label": 0
                },
                {
                    "sent": "Intentional agents will tend to choose sequences of actions that they expect in light of their beliefs to lead to their desires being achieved as efficiently effectively as possible.",
                    "label": 0
                },
                {
                    "sent": "Something like that right now you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Capture that.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As again, you could try to capture that with a gigantic conditional probability table if you wanted to represent this as a Bayes net right, you have some conditional probability of how actions dependable using desires and then observing actions you could work backwards turning that Bayesian crank to make inferences about the beliefs and desires, but again, you'd have this infinite by infinite by infinite matrix because the space of beliefs, desires and actions of any reasonably complex agent is infinite, but it not only is it infinite, but it's highly structured in ways that the conditional probability table doesn't get at.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if we use.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing like a program to describe these arrows.",
                    "label": 0
                },
                {
                    "sent": "A planning program then not only is it much more compact, but it preserves all that structure, right?",
                    "label": 0
                },
                {
                    "sent": "That's just just as that's basically what graphics and physics programs are as they describe those thick arrows in that intuitive physics model, A planning program will describe that the thick arrows here.",
                    "label": 0
                },
                {
                    "sent": "So that's our basic I.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, and let me show you how we use these ideas of probabilistic programs.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of technical details that I would point to my colleagues who actually have done all the hard and interesting conceptual technical work here.",
                    "label": 0
                },
                {
                    "sent": "So for example, people like like Noah Goodman, the conferencing, and others developed a particular probabilistic programming language called Church, which is based on Lisp.",
                    "label": 1
                },
                {
                    "sent": "And basically we're just we're using the functional programming nature of list to define one of these probabilistic programs.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to say very much, although you can read their paper or.",
                    "label": 0
                },
                {
                    "sent": "Our paper I'm an author on it.",
                    "label": 0
                },
                {
                    "sent": "They did this work while they were in my lab, but really it's their work.",
                    "label": 0
                },
                {
                    "sent": "I'll just draw your attention to.",
                    "label": 0
                },
                {
                    "sent": "Here's a couple of examples of church programs that describes a theory, a simple theory of physical objects or rational agents or causal networks, and the church program just consists of a bunch of defined program statements, so they're just defining functions there.",
                    "label": 1
                },
                {
                    "sent": "Stochastic functions which call other functions, and that's just the exact analogue of writing down a graphic.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model where you have nodes and they are defined in terms of other nodes, their parents and that's the Church style of programming.",
                    "label": 0
                },
                {
                    "sent": "It's not just writing a list program and putting in some randomness in a way that would look relatively similar to earlier generations of list based AI, but rather the whole point is to write a program that describes the causal processes and then there are other functions, in particular a query function which does this inference by conditional simulation which takes a set of defined statements which define a model, condition it on some, say partial output, and then make inferences about say, the inputs or other outputs of those programs.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea let me just check on how I'm doing on time here.",
                    "label": 0
                },
                {
                    "sent": "Well, OK, I'm I want to make sure I get to some actual good concrete results.",
                    "label": 0
                },
                {
                    "sent": "So I had a little bit more background on precursor to this idea, but I'll just say very quickly the basic idea was anticipated by a brilliant Englishman who was born about 100 years ago and got involved in the war effort and while doing absolutely pivotal instrumental work, came up with some clever ideas about how the mind might work, and nothing has ever been quite the same and tragically died too young to see.",
                    "label": 0
                },
                {
                    "sent": "His legacy developed and of course you know who I'm talking about.",
                    "label": 0
                },
                {
                    "sent": "It's Ken Craig.",
                    "label": 0
                },
                {
                    "sent": "He's not quite as maybe that's not who you thought it was going to talk about.",
                    "label": 0
                },
                {
                    "sent": "How many people have heard of Ken Cray?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so he's not quite as famous as that other famous Englishman who was born exactly 100 years ago, but he's well worth reading.",
                    "label": 0
                },
                {
                    "sent": "He was basically the inventor of cognitive Science in psychology in Britain, and he in a classic work that he wrote just shortly before he died tragically in a bike accident, his.",
                    "label": 0
                },
                {
                    "sent": "Really laid out this idea of a view of what kind of machine the mind might be, which is basically a simulation engine and engine that builds these kind.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Runnable mental models and uses them for for all the different tasks of common sense, intelligence, reasoning, planning, explanation and so on.",
                    "label": 0
                },
                {
                    "sent": "And it's a fascinating view which then influence the tradition of work on mental models.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other other kinds of AI people have been influenced by his ideas, the sort of qualitative reasoning tradition, which again is 1, which has not been traditionally associated with a probabilistic inference, but another way to understand what we're trying to get at with these probabilistic programs is bringing those traditions together.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll skip that solo.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually put these into action, how might you say capture this learning concepts from a few examples?",
                    "label": 1
                },
                {
                    "sent": "Well, somehow you gotta take all the objects that you've seen here and represent something about the abstract structure of the domain, the generative processes that gave rise to what you see and link the concept to something in that generative structure.",
                    "label": 0
                },
                {
                    "sent": "So something like, for example, the way a biologist might look at objects and think about the evolutionary processes, processes that rise to them.",
                    "label": 0
                },
                {
                    "sent": "You might look at these object.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And organize them into some kind of hierarchical taxonomic tree that reflects some intuitions about about which what they have in common.",
                    "label": 0
                },
                {
                    "sent": "The generative processes that gave rise on the parts that grow, for example, and then you see.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Few examples of a new concept like those over there in that part of the tree and you make some guess of where the where that where the concept refers to.",
                    "label": 0
                },
                {
                    "sent": "Exactly how we capture this is a Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into the technical details, but basically we have hypothesis, which are the branch points of the tree, right?",
                    "label": 0
                },
                {
                    "sent": "You assume that the possible concepts are each branch of the tree, and the longer the branch, the more distinctive it is for the higher prior probability it has for being labeled by a word.",
                    "label": 0
                },
                {
                    "sent": "And then there's a likelihood which is just captures the suspicious coincidence of seeing those three things all clustered there in that part of the tree.",
                    "label": 0
                },
                {
                    "sent": "You could say, well, these three examples here.",
                    "label": 0
                },
                {
                    "sent": "They could also be an instance of, say, a concept labeling that branch for that branch or that branch, but then it would be.",
                    "label": 0
                },
                {
                    "sent": "A big coincidence to see them all.",
                    "label": 0
                },
                {
                    "sent": "The first examples clustered over there, and with that strong hypothesis space just a couple of examples provides enough statistical leverage to figure out that the concept is basically just those things there and not anything else.",
                    "label": 0
                },
                {
                    "sent": "And we can, just as I showed you for those everyday predictions, turn this into a quantitatively predictive model that we can compare with how both adults and children generalize words but.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I'm not going to tell you the details of this experiment 'cause I want to emphasize more of these deeper questions of where the abstract knowledge comes from.",
                    "label": 0
                },
                {
                    "sent": "What leads us to these probabilistic programs?",
                    "label": 0
                },
                {
                    "sent": "So how in particular did you figure out that you should be building a tree, I mean.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, we might think of objects is organized into something like a tree structure, their taxonomic relations, but there's other domains of reasoning that have other kinds of structures, so in some very neat work that Charles tempted when he was in our group, he gave.",
                    "label": 0
                },
                {
                    "sent": "You could think of as a kind of hierarchical Bayesian approach to learning the abstract structure of different domains.",
                    "label": 0
                },
                {
                    "sent": "That is, maybe the first bit of kind of hierarchical Bayesian program induction that at least we worked on where we say, OK, we what we observe is at the at the bottom.",
                    "label": 0
                },
                {
                    "sent": "Here is some.",
                    "label": 0
                },
                {
                    "sent": "Features of objects in this domain.",
                    "label": 0
                },
                {
                    "sent": "Let's say the features of animals or plants or something, and then we assume those were given rise to buy some kind of process operates some kind of stochastic process operating over, let's say some kind of graph structure.",
                    "label": 0
                },
                {
                    "sent": "Let's say here it's a tree structure.",
                    "label": 0
                },
                {
                    "sent": "What we want to learn is not only the tree that underlies those particular objects that domain, but the general principle, which says that it's a tree as opposed to some other kind of structure, and so Charles's idea was to represent that higher level knowledge of something like a graph grammar.",
                    "label": 0
                },
                {
                    "sent": "So it's.",
                    "label": 0
                },
                {
                    "sent": "It's a principle that a little rule that generates structures of a particular constrained sort, namely trees and then bye bye bye giving different kinds of graph grammars we can grow out different kinds of structures like chains or rings or cylinders or grids and so on, and by doing inference at multiple levels of this hierarchy released these two, you can simultaneously infer the grammar that's most likely to have generated the data domain as well as the most likely graph.",
                    "label": 0
                },
                {
                    "sent": "If you like the parse.",
                    "label": 0
                },
                {
                    "sent": "Of the observed data under that grammar, so it's directly analogous to a kind of grammar induction in the couple of problems with grammar reduction.",
                    "label": 0
                },
                {
                    "sent": "Parsing in language, and these are just a couple of results from this.",
                    "label": 0
                },
                {
                    "sent": "From this model, given a data set of animals and features, this approach was able to figure out that it was organized into something like a tree structure to learn that kind of organizing principle.",
                    "label": 0
                },
                {
                    "sent": "But say, for example, given data on the voting patterns of Supreme Court justices in the US, was able to figure out not a tree structure.",
                    "label": 0
                },
                {
                    "sent": "As most appropriate, but actually a linear structure here you know it might be, it might be a little small to see, but here we've got the Supreme Court justices who served under the Rehnquist Court, and you've got the sort of very liberal ones here on the left, and the very right wing ones.",
                    "label": 0
                },
                {
                    "sent": "Scalia and Thomas and so on over there on the right.",
                    "label": 0
                },
                {
                    "sent": "And this algorithm is figuring out that out of all these different possible simple forms of structure for the data that consists of how they voted on different cases, just as a tree structure is the most appropriate to think about animals in there.",
                    "label": 0
                },
                {
                    "sent": "Properties are 1 dimensional.",
                    "label": 0
                },
                {
                    "sent": "Chain structures are familiar, left, right continuum is the most appropriate structure there.",
                    "label": 0
                },
                {
                    "sent": "Or for example given distances between cities.",
                    "label": 0
                },
                {
                    "sent": "It figures out that something like a cylinder, a cross between a chain and a ring roughly corresponding to our concept of latitude in lanja tude is the right way to represent that data.",
                    "label": 0
                },
                {
                    "sent": "So it's at least beginning to show how a hierarchical Bayesian approach could learn something that we'd really want to call a kind of abstract knowledge.",
                    "label": 0
                },
                {
                    "sent": "Here's another application of this to a more of a causal reasoning setting where you know again we're all familiar with the I.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of Bayes net learning as a kind of probabilistic inference, we can say we can talk about a graphical model that reflects, say, for example, intuitive medical knowledge, diseases and symptoms and so on.",
                    "label": 0
                },
                {
                    "sent": "But then we can say learning that that graphical model is itself inference in this kind of hierarchical based have a level of different causal models.",
                    "label": 0
                },
                {
                    "sent": "So here we can consider hypothesis on different causal graphs and then we have some data that we assume is generated from that.",
                    "label": 0
                },
                {
                    "sent": "And we could say, well put a prior on graphs and.",
                    "label": 0
                },
                {
                    "sent": "Observe samples events sampled from that graph.",
                    "label": 0
                },
                {
                    "sent": "Hypothetical patient data and make an inference about what causes what.",
                    "label": 0
                },
                {
                    "sent": "That's basically the generic approach to Bayes net structure learning.",
                    "label": 0
                },
                {
                    "sent": "That's very hard because the hypothesis is very big and unconstrained.",
                    "label": 0
                },
                {
                    "sent": "If you're just thinking about graphs, what in one project that we did to try to again get it at some of the value of hierarchical Bayesian learning of abstract knowledge, we said.",
                    "label": 0
                },
                {
                    "sent": "Well, suppose you can add some extra constraints that come from, say, a kind of a graph schema.",
                    "label": 0
                },
                {
                    "sent": "So suppose we know that our variables can be sort.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into three classes, let's call them behaviors, diseases, and symptoms, and we know which variables in which class.",
                    "label": 0
                },
                {
                    "sent": "And we know that the behaviors cause diseases, and the diseases caused the symptoms.",
                    "label": 0
                },
                {
                    "sent": "That's a hugely valuable constraint if we think of that is putting a prior on graph, so we're only going to learn just as those those graph grammars before put priors on the graphs that we use to parse object attribute data.",
                    "label": 0
                },
                {
                    "sent": "This now puts a prior on the causal graphs, and it makes learning much more tractable.",
                    "label": 0
                },
                {
                    "sent": "In this case, it cuts down the hypothesis space from roughly 521 gazillion or whatever it is, the number of Bayes Nets on 12 nodes.",
                    "label": 0
                },
                {
                    "sent": "Or just directed acyclic graphs?",
                    "label": 0
                },
                {
                    "sent": "It's you know it's huge, it's super exponential to only 131 thousand, and it allows you to learn this graph instead of requiring about 1000 samples to really get that.",
                    "label": 0
                },
                {
                    "sent": "If you just take 1000 independent samples only just a few 10s of samples.",
                    "label": 0
                },
                {
                    "sent": "Can do that now.",
                    "label": 0
                },
                {
                    "sent": "Of course that shouldn't be too surprising because we all know that by cutting down hypothesis faces by putting in some kind of prior knowledge, we can make learning more tractable.",
                    "label": 0
                },
                {
                    "sent": "But the neat thing about this particular product here is we were also learning the graph schema.",
                    "label": 0
                },
                {
                    "sent": "I won't go into the technical details of how we did it, it's a certain kind of nonparametric Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "If you're familiar with Dirichlet processes or Chinese restaurant processes, it's a kind of a graph based Chinese restaurant process prior that allows you to say I know these variables are in some classes, but I don't know how many classes there are, which variables in which class, so you're.",
                    "label": 0
                },
                {
                    "sent": "You're basically doing inference over every possible way of dividing the variables into classes at the same time as you're doing inference about what causes what.",
                    "label": 0
                },
                {
                    "sent": "That more specific level and what we showed is that you're able to learn very quickly.",
                    "label": 0
                },
                {
                    "sent": "Actually, I mean, again, I can't tell you the details, but we showed.",
                    "label": 0
                },
                {
                    "sent": "Here's an example of learning that shows just after 20 observations from a two layer network were able to.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Figure out that there's two layers there could be any number of layers and we were able to figure out which variable is in which layer.",
                    "label": 0
                },
                {
                    "sent": "That's shown here, and we're able to figure out that the variables in one layer caused the variables in the other layer, even though we don't yet know what causes what.",
                    "label": 0
                },
                {
                    "sent": "That's what's shown here by this kind of blurry graph connectivity matrix in the upper right, and then with just a few more data points you can fill in the details.",
                    "label": 0
                },
                {
                    "sent": "It's a nice example of how abstract knowledge really really helps you.",
                    "label": 0
                },
                {
                    "sent": "The ability to divide in this case variables in these abstract classes.",
                    "label": 0
                },
                {
                    "sent": "But, and we have to in order to get its benefit for learning, we have to have the ability to form that knowledge.",
                    "label": 0
                },
                {
                    "sent": "But we don't have to have it wired in any specific detail.",
                    "label": 0
                },
                {
                    "sent": "We didn't have to know in advance that there are diseases and symptoms and what's a disease and what's its symptom that can be discovered almost as quickly.",
                    "label": 0
                },
                {
                    "sent": "And in this case actually much more quickly than the more specific knowledge that's constraining.",
                    "label": 0
                },
                {
                    "sent": "So I think this is a very powerful idea for AI.",
                    "label": 0
                },
                {
                    "sent": "The ability to get the power of background knowledge that we all know is necessary to constrain inductive inference.",
                    "label": 0
                },
                {
                    "sent": "But to be able to learn that background knowledge together.",
                    "label": 0
                },
                {
                    "sent": "Earning the more specific knowledge that enables.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the few minutes I have left I want to get to the common sense reasoning cases which I think are make the best case for why we have to be thin.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing about probabilistic programs that aren't just, you know, grammars, and those graph schemas.",
                    "label": 0
                },
                {
                    "sent": "You can think of those as simple kinds of programs, but why we need something like a computationally universal framework for public programming?",
                    "label": 0
                },
                {
                    "sent": "So we've been doing a lot of work in our lab on studying intuitive physics.",
                    "label": 0
                },
                {
                    "sent": "With this case study of stability.",
                    "label": 0
                },
                {
                    "sent": "It's very, very compelling.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, let me give you an example of an experiment that we do to get people's intuitive concepts of physical reasoning here.",
                    "label": 0
                },
                {
                    "sent": "So we show people.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit dark unfortunately, but we show people these these.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stacks of blocks.",
                    "label": 0
                },
                {
                    "sent": "These towers, some of which look very stable and others of which look very unstable.",
                    "label": 0
                },
                {
                    "sent": "And then we'll ask them to judge how stable they are so you can try this too, so these ones.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You look fairly stable.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How about this one?",
                    "label": 0
                },
                {
                    "sent": "Stable or unstable?",
                    "label": 0
                },
                {
                    "sent": "Full",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A bit more unstable.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this one.",
                    "label": 0
                },
                {
                    "sent": "Also little bit.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unstable these ones.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of in between.",
                    "label": 0
                },
                {
                    "sent": "So in a typical experiment we might show people 60 different examples of these stacks of 10 blocks and have them judged on a scale of 1 to 7.",
                    "label": 0
                },
                {
                    "sent": "How stable they are.",
                    "label": 0
                },
                {
                    "sent": "And then we build a model of what's going on in their head.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That looks just like what I showed you before.",
                    "label": 0
                },
                {
                    "sent": "I mean, you could think of it as one of these fancy kinds of Hmm's.",
                    "label": 0
                },
                {
                    "sent": "But really what we've got is we've got some.",
                    "label": 0
                },
                {
                    "sent": "We were modeling that we're assuming they have some representation of the not directly observable world state, which is.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something like a CAD description of these objects which they infer with some kind of approximate Bayesian inference from the image by inverting a kind of graphics simple graphics rendering model.",
                    "label": 0
                },
                {
                    "sent": "And then once you have that state description, you can judge stability by just propagating forward with something like a kind of a physics engine.",
                    "label": 0
                },
                {
                    "sent": "So here we're using the way we actually build this.",
                    "label": 0
                },
                {
                    "sent": "This model of people's mental models we use like simple game physics engine's.",
                    "label": 0
                },
                {
                    "sent": "There probably pretty much everyone here knows fast and ready approximations to classical.",
                    "label": 0
                },
                {
                    "sent": "Newtonian mechanics and so.",
                    "label": 0
                },
                {
                    "sent": "In this case you have these objects and you can say, well, now if we turn on physics, what happens?",
                    "label": 0
                },
                {
                    "sent": "Well, it'll fall in some pattern, and because it's probable.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stick, this is just only one of a number of possible guesses, right?",
                    "label": 0
                },
                {
                    "sent": "We can't where the probability is coming in various places, but one place they come in is that you can't exactly invert this this graphics model.",
                    "label": 0
                },
                {
                    "sent": "You can't from a single image guess exactly.",
                    "label": 0
                },
                {
                    "sent": "Certainly people can't exactly the precise state of those 3D objects just from a quick glance you makes.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so here's another hypothesis of what the underlying state could be, and then you can run Newtonian physics on that and you get a different answer.",
                    "label": 0
                },
                {
                    "sent": "So in the particular models that we've built, uncertainty comes into these public programs in just two places just to keep it simple.",
                    "label": 0
                },
                {
                    "sent": "One is state uncertainty.",
                    "label": 0
                },
                {
                    "sent": "That's the Sigma parameter.",
                    "label": 0
                },
                {
                    "sent": "So how how much?",
                    "label": 0
                },
                {
                    "sent": "Basically it's saying?",
                    "label": 0
                },
                {
                    "sent": "How precisely can you localize the objects, the blocks from the image that you see?",
                    "label": 0
                },
                {
                    "sent": "And then there's some latent force uncertainty we put in certain basic forces into our physics engine, like gravity and friction.",
                    "label": 0
                },
                {
                    "sent": "But we allow for that.",
                    "label": 0
                },
                {
                    "sent": "There could be other forces that you maybe you didn't know about, like for example somebody could walk by and knock the table.",
                    "label": 0
                },
                {
                    "sent": "A little bitter wind could blow.",
                    "label": 0
                },
                {
                    "sent": "In this first experiment, that's not a big deal, I mean.",
                    "label": 0
                },
                {
                    "sent": "Or rather, we didn't tell anybody about latent forces, so that parameter won't do anything, but that's one of the things we could manipulate later on.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of actually getting some predictive power out of this model.",
                    "label": 0
                },
                {
                    "sent": "And again, I'm not going to go through that.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With experience, but I'm going to show you a bunch of scatter plots of data because I want to emphasize how this is enabling us to make precise quantitative reverse engineering models of these aspects of common sense, which traditionally have not been amenable to quantitative analysis.",
                    "label": 0
                },
                {
                    "sent": "So in this plot here, each each dot is one of these 60 towers, and the model predictions are shown on the X axis and peoples judges on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "And again, but we're asking people to judges on a scale of 1 to 7.",
                    "label": 0
                },
                {
                    "sent": "How stable is this?",
                    "label": 0
                },
                {
                    "sent": "This one is very unstable.",
                    "label": 0
                },
                {
                    "sent": "This one is judges very stable, so those are the two ends of this.",
                    "label": 0
                },
                {
                    "sent": "Continuum and then we're basically asking our model the same thing.",
                    "label": 0
                },
                {
                    "sent": "How does it work?",
                    "label": 0
                },
                {
                    "sent": "It just runs a few of these conditional simulations, forming an estimate of the block posterior bought position posterior, then propagating physics forward and then it just inspects the output of those simulations to see just what fraction of the tower fell.",
                    "label": 0
                },
                {
                    "sent": "That's what gives us our quantitative measure, and you can see that we do a pretty good job of capturing the range of variation in peoples influences.",
                    "label": 0
                },
                {
                    "sent": "The correlation here is is in the mid point it's about .85 on linear correlation.",
                    "label": 0
                },
                {
                    "sent": "Now there's parameters that we have to fit, but there's really only one parameter that has to be fit here, which is that state uncertainty 'cause we haven't modeled in detail how their visual system works, and that that single parameter corresponds to, you know, a relatively small fraction of one of the smaller side of the block.",
                    "label": 0
                },
                {
                    "sent": "It turns out that that's actually very important for modeling this.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "If you assume that people were able to localize the objects perfectly, then it wouldn't fit nearly as well now.",
                    "label": 0
                },
                {
                    "sent": "Certainly as some.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Both AI researchers and psychologists whenever we consider a very complex model like we're going to do probabilistic inference over a physics simulation, we might also want to consider alternatives which are simpler.",
                    "label": 0
                },
                {
                    "sent": "Approach is certainly in psychology.",
                    "label": 0
                },
                {
                    "sent": "Many people would find it a little bit implausible this idea that you have something like a game physics engine in your head, so we can consider many different simple heuristics that you could compute just on the image themselves or on some kind of geometric description without going to the dynamics like the height of the tower or something about the top heaviness or various skew things.",
                    "label": 0
                },
                {
                    "sent": "I won't go into the details.",
                    "label": 0
                },
                {
                    "sent": "But I will say that for a whole bunch of different judgments, there are heuristics we can come up with which can do almost as well as these physics models.",
                    "label": 1
                },
                {
                    "sent": "But the key thing that shows you that you've really got some kind of intuitive theory here, some kind of ability to run a rich physics simulation in your head.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is all the different kinds of things you can do with this model.",
                    "label": 0
                },
                {
                    "sent": "It's a kind of a Turing test.",
                    "label": 0
                },
                {
                    "sent": "If you like.",
                    "label": 0
                },
                {
                    "sent": "Again it's kinda echo theme from Judy's lectures are kind of a mini Turing test here.",
                    "label": 0
                },
                {
                    "sent": "A bunch of questions that we've we've got experiments.",
                    "label": 0
                },
                {
                    "sent": "I showed you one where the judgment is just, you know, will the tower fall.",
                    "label": 1
                },
                {
                    "sent": "But think about all the other questions you could ask about just this kind of stimulus.",
                    "label": 0
                },
                {
                    "sent": "So which way will the tower fall if it falls?",
                    "label": 1
                },
                {
                    "sent": "Or how far will the blocks?",
                    "label": 0
                },
                {
                    "sent": "But will they go all the way down over the table?",
                    "label": 1
                },
                {
                    "sent": "Or just just kind of crumble?",
                    "label": 0
                },
                {
                    "sent": "Or suppose you bump the table.",
                    "label": 0
                },
                {
                    "sent": "So suppose you added another force now.",
                    "label": 1
                },
                {
                    "sent": "And you have blocks of different colors when you have more red or yellow blocks.",
                    "label": 0
                },
                {
                    "sent": "Or what if you bump this side or that side?",
                    "label": 1
                },
                {
                    "sent": "Or what if the blocks are different shapes and sizes?",
                    "label": 1
                },
                {
                    "sent": "Or what about kind of counterfactual reasoning?",
                    "label": 0
                },
                {
                    "sent": "Did adding the block caused the thing to fall?",
                    "label": 1
                },
                {
                    "sent": "Or what?",
                    "label": 0
                },
                {
                    "sent": "If we add other kinds of physical parameters like suppose the red blocks or 10 times heavier than the other blocks, what's going to happen?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that we can.",
                    "label": 0
                },
                {
                    "sent": "We can do all of these things here.",
                    "label": 0
                },
                {
                    "sent": "So for example, we can.",
                    "label": 0
                },
                {
                    "sent": "We can get.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People to judge this is this is an actual snapshot of a subject playing this little game.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where he's simultaneously judging which way that blocks will fall in how far he didn't really get the direction very well, but there wasn't really a good answer to that.",
                    "label": 0
                },
                {
                    "sent": "But consider this one.",
                    "label": 0
                },
                {
                    "sent": "Tried this task in your head.",
                    "label": 0
                },
                {
                    "sent": "Along with this, try to imagine which way the blocks are falling so there it's a little bit better try.",
                    "label": 0
                },
                {
                    "sent": "Here's one more night try, but before you see it, which way are they going to fall?",
                    "label": 0
                },
                {
                    "sent": "Except good, pretty good.",
                    "label": 0
                },
                {
                    "sent": "So people, it turns out, are pretty good at at a bunch of these tasks.",
                    "label": 0
                },
                {
                    "sent": "Or here we can say, suppose these.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gray blocks are 10 times heavier like these are stone and this is some kind of lightweight plastic and then we can show subjects the very same sets of blocks but coloring them differently.",
                    "label": 1
                },
                {
                    "sent": "You're going to get a very different prediction if the Gray ones are heavy.",
                    "label": 0
                },
                {
                    "sent": "This one now.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you can see is pretty unstable, whereas this one is much more stable.",
                    "label": 0
                },
                {
                    "sent": "Or here if you say which way is it going to fall if the Gray ones are much heavier than the green ones, then you can say, well, it's in this case it's going to fall that way, whereas in this case it's more likely to fall that way, and it turns out again that people are basically quite accurate at this.",
                    "label": 0
                },
                {
                    "sent": "If we just add in these differences to the model, just add in the different the mass differences.",
                    "label": 0
                },
                {
                    "sent": "Again, we get correlations that are not perfect, but you know around in the mid, mid to high point 8 levels.",
                    "label": 0
                },
                {
                    "sent": "We can, we can just keep pushing this sort of thing like we can say, alright, imaje.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have this table an.",
                    "label": 0
                },
                {
                    "sent": "We knock the table so now we.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add an outside force and we say is it more likely to have.",
                    "label": 0
                },
                {
                    "sent": "If I knock this table hard enough to knock some of the blocks onto the floor, is it more likely to be red or yellow blocks that fall off?",
                    "label": 1
                },
                {
                    "sent": "So what do you think?",
                    "label": 0
                },
                {
                    "sent": "Red or yellow?",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK here.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Isn't it amazing how such had?",
                    "label": 0
                },
                {
                    "sent": "Like just a little subtle difference between these two yeah switches, most people switch from yellow here to read.",
                    "label": 0
                },
                {
                    "sent": "OK, so how are you?",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doing that well again, the IDR.",
                    "label": 0
                },
                {
                    "sent": "Our thought is that you're running some kind of simulation in your head.",
                    "label": 0
                },
                {
                    "sent": "That's like this.",
                    "label": 0
                },
                {
                    "sent": "This is a snapshot from our simulator where you take this table and you bump it and you see what happens.",
                    "label": 1
                },
                {
                    "sent": "That was a little bump.",
                    "label": 0
                },
                {
                    "sent": "Here's a bigger bump.",
                    "label": 0
                },
                {
                    "sent": "In this case, basically the same result.",
                    "label": 0
                },
                {
                    "sent": "The yellow ones are the ones that get knocked off, and so we build the model which.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just the very same physics model from before, but now it considers a range of different possible bump directions and magnitudes, and again we don't fit people's judgments perfectly.",
                    "label": 1
                },
                {
                    "sent": "But across a ride wide range of towers, varying the number of positions of different kinds of rocks pretty well, we capture most of the variance.",
                    "label": 0
                },
                {
                    "sent": "With this model, we can keep going.",
                    "label": 0
                },
                {
                    "sent": "I mean, I don't want to bore you with all of this, but.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The point is just just like the Turing test if you want to take the idea seriously that you have this kind of abstract mental model that you can run and you want to show that it's really there, you have to push it to some extent to show that it's really doing enough work for you.",
                    "label": 0
                },
                {
                    "sent": "So here I can't.",
                    "label": 0
                },
                {
                    "sent": "Not sure how well you can see it.",
                    "label": 0
                },
                {
                    "sent": "We vary the size and shape of the object.",
                    "label": 0
                },
                {
                    "sent": "Summer tall.",
                    "label": 0
                },
                {
                    "sent": "We put these funny kind of rails on different sides of the table or we might Q forces we might say in some cases I'm not going to tell you which way I bumped the table so you have to kind of integrate that out and other ones.",
                    "label": 0
                },
                {
                    "sent": "I say it was bumped from this side or that side of that side.",
                    "label": 0
                },
                {
                    "sent": "And again, the same thing cult.",
                    "label": 0
                },
                {
                    "sent": "Basically this model for both acute and uncured forces for different sizes and shapes of blocks.",
                    "label": 0
                },
                {
                    "sent": "It's just this massive experiment here that's all you could get from that scatter plot is across all these factors which we very it captures.",
                    "label": 0
                },
                {
                    "sent": "Most of the variance.",
                    "label": 0
                },
                {
                    "sent": "It's interesting.",
                    "label": 0
                },
                {
                    "sent": "I think that it doesn't capture all the very I mean, it's sort of consistently imperfect, right?",
                    "label": 0
                },
                {
                    "sent": "I think that's telling us that we are imperfectly capturing something real.",
                    "label": 0
                },
                {
                    "sent": "There is a real physics simulation engine in your head that you can make these probabilistic inference about.",
                    "label": 0
                },
                {
                    "sent": "We haven't got it exactly.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, with the particular approximations.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're making OK now if I'm sure at this point I'm probably out of time.",
                    "label": 0
                },
                {
                    "sent": "Is that just just about so I don't really have time to go into the last bit of the talk, which is I'm going to show you the same kind of thing about how to do.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These probabilistic programs, now for intuitive psychology, but just to give you a very sort of quick tour of this.",
                    "label": 0
                },
                {
                    "sent": "Basically these you know.",
                    "label": 0
                },
                {
                    "sent": "I think this is, if anything is going to be more familiar to this audience because we're using all the success in probabilistic planning and particularly using MDP and Palm DP planning algorithms.",
                    "label": 1
                },
                {
                    "sent": "And we're basically saying just like, just like there's this crazy idea that your intuitive physics might be based on a physics game engine in your head.",
                    "label": 0
                },
                {
                    "sent": "Here we're suggesting that you have something like a palm DP in your head, and you interpret other peoples.",
                    "label": 0
                },
                {
                    "sent": "Another intentional agents, whether people are little blobs moving around as if they were choosing actions by solving a palm DP.",
                    "label": 0
                },
                {
                    "sent": "Now I think of Palm DP is way too simple, but it, but it's just.",
                    "label": 0
                },
                {
                    "sent": "It's the kind of technology that I think many people here are familiar with.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is to say I mean or I'll just show you a couple of experiments just evocatively.",
                    "label": 0
                },
                {
                    "sent": "So here we can see an agent moving in a simple environment where there's three possible goals and some constraints.",
                    "label": 0
                },
                {
                    "sent": "If you look down here, you can see.",
                    "label": 0
                },
                {
                    "sent": "You know various different experiment, different experimental conditions where we move the objects around or we vary whether there's a wall.",
                    "label": 0
                },
                {
                    "sent": "Or maybe there's a hole in the wall, and then the agent follows various paths and at different points along the path we stop the movie and we say to the subject.",
                    "label": 0
                },
                {
                    "sent": "What do you think this guy wants?",
                    "label": 0
                },
                {
                    "sent": "Does he want a B or C?",
                    "label": 0
                },
                {
                    "sent": "Where does he trying to get to and as a function of all these different factors, we can very people make judgments that you can see here on the 2nd row, the red, blue and green are color coded to the three objects, and you know if you if you take a look at this paper and studied in a little bit more detail if you.",
                    "label": 0
                },
                {
                    "sent": "Interested, but you'll see fairly intuitive variations.",
                    "label": 0
                },
                {
                    "sent": "First, he thinks I can't really tell whether it's A or B on now.",
                    "label": 0
                },
                {
                    "sent": "I'm definitely sure it's a as he heads there, or I thought it was.",
                    "label": 0
                },
                {
                    "sent": "In this case, I thought it would be, but then it seems like you switch to a or you can get all these very complex things like, alright, I think it's probably not be, but I can tell this every now and then, say, OK, let's be or I think it's B here, but no, it's definitely not now, let's say and this model captures all of those details with an even higher correlation.",
                    "label": 0
                },
                {
                    "sent": "The intuitive physics model.",
                    "label": 0
                },
                {
                    "sent": "I mean here, the correlation is in the high Point 9.",
                    "label": 0
                },
                {
                    "sent": "What is it doing?",
                    "label": 0
                },
                {
                    "sent": "Well, again, like the physics simulator.",
                    "label": 0
                },
                {
                    "sent": "It's very complex in some ways and very simple in others.",
                    "label": 0
                },
                {
                    "sent": "It's complex in that in this case it's solving MDP.",
                    "label": 0
                },
                {
                    "sent": "There's no partial observe ability.",
                    "label": 0
                },
                {
                    "sent": "We assume that the agent knows everything in the environment.",
                    "label": 0
                },
                {
                    "sent": "But it's an it's it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a relatively simple kind of gridworld standard kind of MVP.",
                    "label": 0
                },
                {
                    "sent": "There's you get a high reward for getting to your goal, and you have a small cost for each step that you take, and then basically you observe the actions that come from solving that under a probabilistic, both in policy and you have to figure out which goal or rich reward function best explains the observed sequences of actions.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, it's kind of complicated, but it's very simple as a mathematical model has very few free parameters.",
                    "label": 0
                },
                {
                    "sent": "There's only there's only two free parameters here, which is basically how stochastic is the agent.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "What's his probability of switching his goal?",
                    "label": 0
                },
                {
                    "sent": "It turns out if you look at this, you have to be able to posit that the agent can switch his goal that his goal doesn't necessarily constant in time, and with just those two free parameters we can capture.",
                    "label": 0
                },
                {
                    "sent": "You know, almost all the variance in hundreds of different judgments.",
                    "label": 0
                },
                {
                    "sent": "We can extend this to cases where you have we have belief, so you're making inference about not just what an age.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "ENT wants, but what they believe.",
                    "label": 0
                },
                {
                    "sent": "Here's an instance of your watching agent.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "This agent is like a grad student who's going to a food truck on the University campus, and he doesn't know what's behind this wall.",
                    "label": 1
                },
                {
                    "sent": "He goes behind it to look and then turns around and goes back to this object, and you can make inferences.",
                    "label": 0
                },
                {
                    "sent": "I won't go through the details here because I don't have time, but you can make inferences about both what he thought was there and the fact that what he wanted is a thing that wasn't there.",
                    "label": 1
                },
                {
                    "sent": "You have to explain why did he go and look and then come back.",
                    "label": 0
                },
                {
                    "sent": "It must be that the thing that he wanted is actually the one thing that isn't present there.",
                    "label": 0
                },
                {
                    "sent": "And now here we're doing.",
                    "label": 0
                },
                {
                    "sent": "We're taking this as a palm DP, and we're modeling both the agents belief state as a function of what he can observe based on line of sight as well as his reward function.",
                    "label": 0
                },
                {
                    "sent": "We can extend this to multiagent setting again.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you really want to take this seriously as an account of an intuitive theory, you have to keep pushing it.",
                    "label": 0
                },
                {
                    "sent": "So you say, well, how can I infer whether somebody that groups whether some say?",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whether somebody is a good guy or a bad guy?",
                    "label": 0
                },
                {
                    "sent": "Well let's define a multi agent.",
                    "label": 0
                },
                {
                    "sent": "Model where you have agents and Agent who can have as a goal to help or hinder another agent.",
                    "label": 0
                },
                {
                    "sent": "If there's a lot of, there's a lot of research showing even young babies, like in that video I showed you with the chasing and fleeing.",
                    "label": 0
                },
                {
                    "sent": "Even young babies can see, for example, this little yellow guy pushing the red.",
                    "label": 0
                },
                {
                    "sent": "The red guy here is sort of.",
                    "label": 0
                },
                {
                    "sent": "Seems like he's trying to get the yellow guy pushes him from behind and he's seen as a good guy.",
                    "label": 0
                },
                {
                    "sent": "A helper.",
                    "label": 0
                },
                {
                    "sent": "The infants like to play with him, whereas if a blue guy comes and pushes the red guy downhill, he seen as a hinderer and we can model this as well as more complicated kind of gridworld helping hindering things.",
                    "label": 0
                },
                {
                    "sent": "With these recursive utility functions, where what it is to help or hinder is to try to maximize not your own expected utility, but your expectation about the other agents.",
                    "label": 0
                },
                {
                    "sent": "Expected utility is a kind of probabilistic Golden rule.",
                    "label": 0
                },
                {
                    "sent": "In some very exciting work that Noah Goodman is done, this is not work that I invite.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it takes the same kind of model and uses it to model pragmatics in language so.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I I, I think I've used my alot of time so let me just try to summarize where we're up to.",
                    "label": 0
                },
                {
                    "sent": "We've showed you how we can account for.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Build some of the first quantitative models of intuitive physics and now intuitive psychology, and there's far more than I have.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Time to cover here.",
                    "label": 0
                },
                {
                    "sent": "There's some important frontiers that particularly any but I think are of interest to any computer scientists, but certainly to AI researchers, and I just want to highlight these frontiers.",
                    "label": 0
                },
                {
                    "sent": "For those people who might be interested in working on them, these are things where some work is already being done, but most of the good work is not being done by me but by various collaborators like the Koch Mensinga, Dan Roy, Cameron Freer, Noah Goodman, others.",
                    "label": 0
                },
                {
                    "sent": "So the number one computer science challenge here is to actually build effective universal inference algorithms for these probabilistic programs.",
                    "label": 1
                },
                {
                    "sent": "I showed you a little sketch of some programs in the Church, probabilistic programming language, and there have been universal inference algorithms for church, so you can take it's rather remarkable thing that Nolan Bkash did and others is.",
                    "label": 0
                },
                {
                    "sent": "You can write down in church in this kind of stochastic Lisp.",
                    "label": 0
                },
                {
                    "sent": "You can write down any computable probability model, universal language and you can do any conditional inference that's computable with a query function that's also recursively defined.",
                    "label": 0
                },
                {
                    "sent": "So you can nest queries inside other queries.",
                    "label": 0
                },
                {
                    "sent": "And it's all you can do that all by Metropolis Hastings.",
                    "label": 0
                },
                {
                    "sent": "And it's rather remarkable that there's a basically a metropolis Hastings algorithm that exists.",
                    "label": 0
                },
                {
                    "sent": "You can play with it on our website if you Google for the MIT Church wiki can play with it with a server side.",
                    "label": 0
                },
                {
                    "sent": "Inference engine, but as anyone who's ever used Metropolis Hastings on much simpler models, knows that to think that you could just do everything with Metropolis.",
                    "label": 0
                },
                {
                    "sent": "Hastings is kind of hopeless, it's it's just too slow for all the ways that these models can get complex.",
                    "label": 0
                },
                {
                    "sent": "So for the particular public programs I showed you like the physics model in psychology model, we're not using this generic Metropolis Hastings inference album.",
                    "label": 0
                },
                {
                    "sent": "We're using special purpose simulators that we built based on certain kind of game engines and then doing Monte Carlo on that or based on Palm DP solvers for example.",
                    "label": 0
                },
                {
                    "sent": "But we have the same situation when you data and others first started working on Bayes Nets.",
                    "label": 0
                },
                {
                    "sent": "Right, they only had effective general inference algorithms for very simple special cases, and then it took another generation of research to build effective general purpose inference tools for graphical models.",
                    "label": 0
                },
                {
                    "sent": "But being able to define the representation language and show that you could get it to work at least in simple cases and sort of map out theoretically what's possible that was.",
                    "label": 0
                },
                {
                    "sent": "That was the early stage, and I'd say we're just beginning that stage in public programs, but if you could help work on this, it would be a tremendous thing an I would say talk to people like the Koch men, singer Noah Goodman and others.",
                    "label": 0
                },
                {
                    "sent": "There's also really interesting theory questions here that are what people like Dan Ryan Cameron fear of testing, and also the cache like what when is when is influencing public programs computable at all?",
                    "label": 0
                },
                {
                    "sent": "When is it?",
                    "label": 0
                },
                {
                    "sent": "When is it tractable?",
                    "label": 0
                },
                {
                    "sent": "What are its complexity characteristics?",
                    "label": 0
                },
                {
                    "sent": "Dan Cameron have developed some rather remarkable and mostly beyond me theoretical results at the foundations or where the foundations of compute ability theory and complexity theory intersect with the foundations of probability, and it's really cool stuff.",
                    "label": 0
                },
                {
                    "sent": "I just point you to their work using these ideas to actually again make the link from theory to practice to build inference algorithms that are better usefully informed by theory still open, and maybe the last question that the hardest, most interesting one is the problem of learning.",
                    "label": 0
                },
                {
                    "sent": "In probabilistic programming languages, right?",
                    "label": 1
                },
                {
                    "sent": "So I showed you some initial kind of warm up cases right?",
                    "label": 0
                },
                {
                    "sent": "Like learning graph grammars for describing structural forms or learning those graphs, schemas for describing abstract kinds of variables in a causal graph, though, you can think of those as a simple kind of hierarchical Bayesian program induction, but where the programs are not computationally universal, they're just very specific ways of generating graphs.",
                    "label": 0
                },
                {
                    "sent": "Now, can we do that for these universal programming languages?",
                    "label": 0
                },
                {
                    "sent": "Well, obviously you know there's a long tradition of people realizing that learning should be something like program synthesis or program induction, and then.",
                    "label": 0
                },
                {
                    "sent": "Kind of getting very scary and saying that just seems that seems impossible, but yet I think something like this has to be right, and so we've been working on various kinds of warmup cases that we can test with people.",
                    "label": 0
                },
                {
                    "sent": "But again, for people in AI, I would very much encourage you if you want to take on a real challenge to try to work on this problem of learning as a kind of Bayesian program induction.",
                    "label": 0
                },
                {
                    "sent": "Alright, so just to conclude, then the cognitive science question that motivated this work is this question of how does the mind get so much from so little across all these different domains of cognition?",
                    "label": 0
                },
                {
                    "sent": "And I tried to show you a toolkit that we've been building on the cognitive science side over the last 10 or 15 years, but in close contact both ways with state of the art research in AI, the idea, the basic idea of thinking of cognition as Bayesian inference in a probabilistic model, but then building these probabilistic models over increasingly structured representations, making them hierarchical with inference at multiple levels of abstraction.",
                    "label": 0
                },
                {
                    "sent": "To explain, not just where the knowledge, how the knowledge enables very specific learning from a few examples of how that knowledge itself might be built.",
                    "label": 0
                },
                {
                    "sent": "And then most recently and excitingly to us.",
                    "label": 0
                },
                {
                    "sent": "This idea of probabilistic programs moving from graphical models where a graph is your basic knowledge representation to a much richer way to think about the causal structure of the world representation language, which is still causal in generative but which is relational, recursive composable.",
                    "label": 0
                },
                {
                    "sent": "So we can embed physics inside psychology or think about beliefs about beliefs or desires about desires.",
                    "label": 0
                },
                {
                    "sent": "And computationally universal.",
                    "label": 0
                },
                {
                    "sent": "This idea of inference as running these programs backwards by conditional simulation is in principle very powerful in practice.",
                    "label": 0
                },
                {
                    "sent": "Very intriguing and very difficult, but I hope I've encouraged you to work on it.",
                    "label": 0
                },
                {
                    "sent": "The card that there's a long dream of cognitive scientists here, which is also been an AI dream, which is how can we understand common sense, and I can't claim that we've actually got models of human common sense, but we have, I think, made some of the first progress on building quantitative rigorous reverse engineering models.",
                    "label": 0
                },
                {
                    "sent": "Of what I could call and what others in cognition is called.",
                    "label": 0
                },
                {
                    "sent": "The cognitive science common sense core.",
                    "label": 0
                },
                {
                    "sent": "This basic capacity for reasoning about physical objects, intentional agents and their interactions which emerges in early infancy, right?",
                    "label": 0
                },
                {
                    "sent": "I didn't describe the infant experiments, but I showed a few of the stimuli.",
                    "label": 0
                },
                {
                    "sent": "Even preverbal infants younger than one year who don't talk who don't walk.",
                    "label": 0
                },
                {
                    "sent": "Really.",
                    "label": 0
                },
                {
                    "sent": "They can do these kinds of common sense inferences, and we built some of the first quantitative models and how these how these theories support inference.",
                    "label": 0
                },
                {
                    "sent": "And we're starting to get it how they might be learned as a kind of program induction just a few.",
                    "label": 0
                },
                {
                    "sent": "A few last thoughts for AI researchers.",
                    "label": 0
                },
                {
                    "sent": "Those who are interested in building human like AI systems, if that's what you want to do.",
                    "label": 0
                },
                {
                    "sent": "Just three little pieces of advice, focus on the common sense core.",
                    "label": 0
                },
                {
                    "sent": "That's what I think we in cognitive science, and I don't just me, but I mean all the experimentalists and many other modelers over the last say two decades have identified as the heart of things.",
                    "label": 0
                },
                {
                    "sent": "This common sense, intuitive physics and psychology that emerges very early in that we can now describe.",
                    "label": 0
                },
                {
                    "sent": "With these rigorous reverse engineering models, of course, abstract knowledge is essential.",
                    "label": 0
                },
                {
                    "sent": "There's no inductive inference without background knowledge.",
                    "label": 0
                },
                {
                    "sent": "That's one of the basic lessons we all have learned over and over many times, but don't think that abstract background knowledge innocence has to be all wired in.",
                    "label": 0
                },
                {
                    "sent": "Think about how it might grow.",
                    "label": 0
                },
                {
                    "sent": "Think about how it might grow flexibly robustly in response to experience and Lastly, probabilistic programs are the way to go.",
                    "label": 0
                },
                {
                    "sent": "But they're hard.",
                    "label": 0
                },
                {
                    "sent": "And if you want to work on them, there's.",
                    "label": 0
                },
                {
                    "sent": "Many great challenges that will bring you into bidirectional contact with other areas of computer science, right?",
                    "label": 0
                },
                {
                    "sent": "So you saw little hints of this was.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bing, but what's one of the great things about about working with public programs as the basis of AI systems is they bring you into they allow you to build on great successes in the areas of computer science that work even better than I like graphics or physical simulation, right?",
                    "label": 0
                },
                {
                    "sent": "Or algorithms are programming languages and they also pose really interesting challenges for people who are coming from those angles.",
                    "label": 0
                },
                {
                    "sent": "So it's an exciting time both.",
                    "label": 0
                },
                {
                    "sent": "I think for what's going on in cognitive science for the AI cognitive science interface, and I hope I've been able to spread some of that excitement back to.",
                    "label": 0
                },
                {
                    "sent": "Two AI and please join us in this.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}