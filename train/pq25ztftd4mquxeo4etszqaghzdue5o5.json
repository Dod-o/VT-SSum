{
    "id": "pq25ztftd4mquxeo4etszqaghzdue5o5",
    "title": "On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization",
    "info": {
        "author": [
            "Ohad Shamir, Faculty of Mathematics and Computer Science, Weizmann Institute of Science"
        ],
        "published": "Jan. 16, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Optimization Methods->Convex Optimization"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2012_shamir_optimization/",
    "segmentation": [
        [
            "So the."
        ],
        [
            "A setting I'm going to discuss deals really with a very simple and fundamental problem, so assuming I have some convex function over some convex domain, to which I only have black box access, I don't know.",
            "I can't compute gradients or Hessians or things like that.",
            "I can only get a noisy values at various points.",
            "I want to optimize this function using as few queries as possible.",
            "A."
        ],
        [
            "So this setting received interest in at least two communities.",
            "So in the optimization community it's known as derivative free or sometimes zero.",
            "Order is stochastic convex optimization.",
            "The motivation usually comes from situations where the gradient is either hard or impossible to compute.",
            "So to be a very simple example, when we try to pick parameters for some learning algorithm, the only thing we do we can do is really pick a parameter, run the algorithm.",
            "You can't really calculate the gradient for these kinds of things, and the goal, and as an optimization is to minimize the error.",
            "So after 80 queries we want to find some point WRT which is as close as possible to the optimum in the online learning community.",
            "These kind of problems are known as bandit problems.",
            "The motivation there usually come from sequential decision making where you have a uncertainty.",
            "So maybe the simplest cases multi arm bandits, which really.",
            "Corresponds to a linear function over simplex, but the metric there is a regret, so there we want that the sequence of a points that we pick these WTS, on average would be close to optimum and they know that minimizing regret is only harder than minimizing error.",
            "Because if I have an algorithm with low regret, then just by picking the average of these points by instance inequality, I also get a low air."
        ],
        [
            "OK, and the question I'd like to discuss is what is the error?",
            "The regret that we can get in terms of two fundamental quantities.",
            "So one is the number of queries and the 2nd is the dimension of the domain.",
            "So if you have gradient information then this situation is relatively well understood, so we know that if the function is convex we can get a one over square root T rate if it strongly convex, it's a 1 / T or maybe log T / T and without dependence on the dimension, assuming everything is.",
            "Scaled in L2 and.",
            "All this holds both is upper bounds, lower bounds, and things are quite well understood.",
            "However in the."
        ],
        [
            "Bandit or derivative free setting.",
            "Things are much less clear, so just to go."
        ],
        [
            "A few points so the multi unbanded setting is relatively well understood.",
            "We know that we can get sqrt D / T. This is tight.",
            "But as soon as you move to for instance still."
        ],
        [
            "Linear function, but more general convex domains.",
            "Things start to become a messier, so there are various say, bounded.",
            "The literature order, sqrt D, /, T, sometimes the squared over T. Sometimes one can also show a lower bounds, but we usually depend on a very careful construction of the domain.",
            "They're not very natural domains."
        ],
        [
            "And once you talk about general convex functions, things become very even, much less clear than that.",
            "And there are several upper bounds in the literature, which usually either have good dependence on T but very bad dependence on the dimension or vice versa.",
            "And this is this problem is open for more than 30 years now.",
            "So when you dinner asking their seminal 1979 work on the complexity of convex optimization, Notice this.",
            "Thing that there doesn't seem to be a method that gets the best of both worlds or both depends on the dimension and the rate and overall the situation is still very far from clear."
        ],
        [
            "So in our work, what we do is to try and study what is the complexity of these settings for nonlinear if functions, particularly focusing on strongly convex ones, and we have a few results.",
            "So the first one is that we characterize the complexity for functions which are strongly convex and smooth, showing it's exactly square root of the squared over 2."
        ],
        [
            "And this is several implications.",
            "So first of all, it's a tight characterization for general nonlinear class.",
            "It shows that in general team a skill at least quadratic in the dimension, and the lower bounds that we show also implies strong lower bounds for more."
        ],
        [
            "General cases.",
            "The 2nd result that we show is a more positive one, namely that for a particular class of strongly convex and smooth functions, namely quadratic functions, you can actually get a rate of the squared over T without a square root, and you can even improve the dependence on the dimension in some cases.",
            "So as far as we know this is the first demonstration that for a general natural class of functions you can get fast rate even if you don't have access to the gradients, just.",
            "The function values an.",
            "Actually there was a paper at this nips which showed for quadratic functions and lower bound of sqrt D / T. And as you may notice, this is larger than this, and it turns out that our result sort of circumnavigates circumvents there a lower bound in some nice wine.",
            "I'll maybe discuss it a bit more later on."
        ],
        [
            "And the 3rd result.",
            "So this squared over T is for the optimization error, But it turns out that the attainable regret that you can get for even for quadratic functions is only square root of the squared over T. And again this is tight, so we see here that there is a very large gap between what you can get in terms of regret and in terms of optimization.",
            "In sharp contrast to what you have in the full information case and for linear functions.",
            "So here it really goes from square root T to 1 / T."
        ],
        [
            "And this is just a summary in table form.",
            "So again we show that for quadratic we have this big gap between error and regret for strongly convex since we get a tight characterization tools both for error an regret and results also imply strong lower bound."
        ],
        [
            "For more general cases.",
            "OK, so let's start going to the specific so quadratic functions are of course for two functions of this form, and I'm assuming that everything is scaled to be a constant for simplicity, and I'm going to make this technical assumption that I can query points in some ball around the optimum W star so the optimum doesn't lie exactly at the boundary in with linear functions this is.",
            "Not a reasonable assumption, because with linear functions the ultimate is always at the boundary, but with strongly convex functions.",
            "Assuming that the optimum is on the boundary is not very natural, and we can actually relax it and it simplifies things quite a bit."
        ],
        [
            "A OK, so as I said for quadratic functions we can show that it is possible to get this squared over T in upper bound and the reason it circumvents the lower bound from paper presented a few days ago is because.",
            "They show a result which holds if the for a domain which actually depends on.",
            "In our terminology it's a domain that actually shrinks with the T. So in our setting it means that you take epsilon to be 0 and then it's no surprise that you get a bad day right here.",
            "But if you make the natural assumption that the domain is something fixed, then it's not an issue.",
            "And the algorithm is yes, so I guess it seems like you're are you.",
            "Are you assuming that the set is like a unitary to wall?",
            "More less?",
            "Or is there any assumption so set an no really the only thing is that you can query at some point and yeah, so I mean in the next slide will show the algorithm and it's really something very simple, OK?",
            "I was curious in terms of how the OK because so if I was wondering how the size of the set matters to the rate, because OK if epsilon kind of needs to be a constant for this to be run on T and then how do those constraints interact?",
            "And if you're essentially asking for the W start we more or less at the center very close to the centre.",
            "Or can it be still fairly for now?",
            "It can be anywhere then domain as long as.",
            "So the simplest case is to assume it's unbounded domain, and then I either assume that the optimum is at least epsilon far from the boundary of the domain, or that I can query a distance epsilon outside the domain over which I wish to optimize.",
            "Yes, has to be there in that one.",
            "A well, not necessarily.",
            "I mean, for the linear case there are of course techniques that allow you to optimize even if the optimum is at the boundary.",
            "But then you need to use some heavy machinery, self concordant functions and so on.",
            "And this assumption is.",
            "For us, makes things much easier, and it seems very natural here, but I can't.",
            "I don't know if the dependence on epsilon here is tight.",
            "So yeah, if you have no epsilon dollar, then you really can't read it.",
            "Yes, yes so."
        ],
        [
            "OK.",
            "So the algorithm is really very simple.",
            "There is no magic here, it's based on the standard technique of doing stochastic gradient descent with one point gradient estimate.",
            "And really the only keen observation that we make here is that usually with these one point estimates you need to query very close to the point that you wish to estimate its gradient, because otherwise you start getting biases.",
            "But quadratic functions have a very nice structure, which means that even if you query is very far away from the function.",
            "You can still get an unbiased estimate, and because you can query from a relatively large ball, it gives you it sort of reduces the variance of your gradients and this is the key that allows you to get improved rates.",
            "And this is basically the algorithm which we get the upper bound."
        ],
        [
            "So just as a small sidenote.",
            "So while this thing holds, it turns out that if you are willing to assume a bit more on the structure of the noise, you can actually get stronger results.",
            "So under certain assumptions you can get bounds, which instead of the squared you have the times the Frobenius norm square root of your quadratic term.",
            "For instance, if you look at something which looks like a black box version version of Ridge regression you can get.",
            "D / T rate.",
            "Of course, I'm not suggesting anyone should solve Ridge regression with this algorithm, but just this just shows you that things can be a bit subtle, depending on how you define things."
        ],
        [
            "OK, and I said earlier.",
            "We showed that this thing is tight so we can also get a matching lower bound of the squared over T. And note that to get this lower bound we can even allow queries anywhere in equation space, so we're not hiding anything here in terms of the domain definition you can get as much power as you want and you still have this squared over T."
        ],
        [
            "I won't go over the proof details.",
            "The main challenge was to really get this, so getting a dependence on D is not too hard.",
            "The technical challenge was getting depends on these squared, and the idea is to use strong convexity to show that the suboptimality serve reduces to a sum of.",
            "Think of hypothesis testing problem.",
            "So you really need to be able to estimate the sign of the optimum and each one of its coordinates.",
            "And as long as you make a mistake in some constant fraction of it, you have a mistake of at least the squared."
        ],
        [
            "And the rest is like a relative entropy argument, and I won't go into the details and so this was for error.",
            "And now there is this interesting thing that happens when you now switch to talk about regret sofa regrets.",
            "We show that a lower bound which is square root of the squared over T. And the intuition of the idea is really very simple.",
            "So when you look more closely at the lower bound, the previous lower bound in the quadratic case, it turns out that it actually depends where exactly you query an.",
            "It actually depends on the norm of the points you pick, and it's actually very reasonable, because if you look at, say, the one dimensional case, if you query and you want to, say, discern whether your function is the blue one or the red one, if you query very far away, it's actually easier for you to discern.",
            "Whether it's red, red, blue because the values get more different.",
            "But if you want to minimize regrets then.",
            "You actually can't go too far away from the optimum, so you have like this.",
            "No win situation here either.",
            "You query very far away and get a lot of information, but also get hit with a lot of regret or you query very close to the optimum and then you get less regret.",
            "But you also get less information.",
            "So no matter what you do, if you construct things correctly, you cannot avoid this square root D ^2 / T bound.",
            "Sorry, yes.",
            "BLUE T -- W star the norm a wear.",
            "Relative entropy terms depends on norm of WT.",
            "Yes.",
            "The distance of the Queen of Lumpy and it is, but I construct things so that W store is some point very close to 0.",
            "So yeah, it's actually would depend on the distance, but OK."
        ],
        [
            "OK, and now there's this 3rd result, namely that say you can get the square root of the square Doherty lower bound.",
            "Even if you talk about error once you move to this more general, strongly convex and smooth functions, now we know that this is not true for a quadratic, so we have to move to a non quadratic function and the function we consider is this one.",
            "It might not be immediately obvious, but this function is strongly convex.",
            "And smooth and it has this nice property that close to its optimum, it behaves like a quadratic function and like the optimum really depends.",
            "On this choice of East.",
            "But as you move further away, all these functions converge to the same standard.",
            "FW equals W squared function, and what this means is that even in the case of in the case of optimization, when you can query very far away, it actually won't help you because these functions just become more and more similar.",
            "So in a sense you get the same kind of hardness that you get in the regret setting with quadratic functions with similar lower bound."
        ],
        [
            "OK. And that's basically it.",
            "So, just to summarize, we gave an exact characterization for the complexity in the strongly convex and smooth case, which also implies new lower bounds.",
            "For more general settings, and showing that you really get quadratic dependence on the dimension in general.",
            "We showed that you can get fast error rates at least in certain cases, even if you don't have gradients and we show that there is can be substantial gaps between error and regret it once you move beyond the.",
            "In your case, and maybe the main open question is now to try and understand what's the complexity for more general functions.",
            "Strongly convex or general convex problems.",
            "And again there is a huge gap between our current upper bounds and lower bounds in my conjecture based on the lower bounds and sort of looking at the best behavior in terms of both.",
            "T&D is that this thing is really tight.",
            "The square root of the squared over T, but it seems that none of our standard methods allow us to.",
            "Approach such a thing so we really need some fundamentally new algorithms apparently to get this behavior, so that's it.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A setting I'm going to discuss deals really with a very simple and fundamental problem, so assuming I have some convex function over some convex domain, to which I only have black box access, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I can't compute gradients or Hessians or things like that.",
                    "label": 0
                },
                {
                    "sent": "I can only get a noisy values at various points.",
                    "label": 0
                },
                {
                    "sent": "I want to optimize this function using as few queries as possible.",
                    "label": 1
                },
                {
                    "sent": "A.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this setting received interest in at least two communities.",
                    "label": 0
                },
                {
                    "sent": "So in the optimization community it's known as derivative free or sometimes zero.",
                    "label": 0
                },
                {
                    "sent": "Order is stochastic convex optimization.",
                    "label": 1
                },
                {
                    "sent": "The motivation usually comes from situations where the gradient is either hard or impossible to compute.",
                    "label": 1
                },
                {
                    "sent": "So to be a very simple example, when we try to pick parameters for some learning algorithm, the only thing we do we can do is really pick a parameter, run the algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can't really calculate the gradient for these kinds of things, and the goal, and as an optimization is to minimize the error.",
                    "label": 0
                },
                {
                    "sent": "So after 80 queries we want to find some point WRT which is as close as possible to the optimum in the online learning community.",
                    "label": 1
                },
                {
                    "sent": "These kind of problems are known as bandit problems.",
                    "label": 0
                },
                {
                    "sent": "The motivation there usually come from sequential decision making where you have a uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So maybe the simplest cases multi arm bandits, which really.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to a linear function over simplex, but the metric there is a regret, so there we want that the sequence of a points that we pick these WTS, on average would be close to optimum and they know that minimizing regret is only harder than minimizing error.",
                    "label": 1
                },
                {
                    "sent": "Because if I have an algorithm with low regret, then just by picking the average of these points by instance inequality, I also get a low air.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and the question I'd like to discuss is what is the error?",
                    "label": 1
                },
                {
                    "sent": "The regret that we can get in terms of two fundamental quantities.",
                    "label": 1
                },
                {
                    "sent": "So one is the number of queries and the 2nd is the dimension of the domain.",
                    "label": 1
                },
                {
                    "sent": "So if you have gradient information then this situation is relatively well understood, so we know that if the function is convex we can get a one over square root T rate if it strongly convex, it's a 1 / T or maybe log T / T and without dependence on the dimension, assuming everything is.",
                    "label": 0
                },
                {
                    "sent": "Scaled in L2 and.",
                    "label": 0
                },
                {
                    "sent": "All this holds both is upper bounds, lower bounds, and things are quite well understood.",
                    "label": 0
                },
                {
                    "sent": "However in the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bandit or derivative free setting.",
                    "label": 0
                },
                {
                    "sent": "Things are much less clear, so just to go.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A few points so the multi unbanded setting is relatively well understood.",
                    "label": 0
                },
                {
                    "sent": "We know that we can get sqrt D / T. This is tight.",
                    "label": 0
                },
                {
                    "sent": "But as soon as you move to for instance still.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Linear function, but more general convex domains.",
                    "label": 0
                },
                {
                    "sent": "Things start to become a messier, so there are various say, bounded.",
                    "label": 0
                },
                {
                    "sent": "The literature order, sqrt D, /, T, sometimes the squared over T. Sometimes one can also show a lower bounds, but we usually depend on a very careful construction of the domain.",
                    "label": 0
                },
                {
                    "sent": "They're not very natural domains.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And once you talk about general convex functions, things become very even, much less clear than that.",
                    "label": 1
                },
                {
                    "sent": "And there are several upper bounds in the literature, which usually either have good dependence on T but very bad dependence on the dimension or vice versa.",
                    "label": 0
                },
                {
                    "sent": "And this is this problem is open for more than 30 years now.",
                    "label": 1
                },
                {
                    "sent": "So when you dinner asking their seminal 1979 work on the complexity of convex optimization, Notice this.",
                    "label": 0
                },
                {
                    "sent": "Thing that there doesn't seem to be a method that gets the best of both worlds or both depends on the dimension and the rate and overall the situation is still very far from clear.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our work, what we do is to try and study what is the complexity of these settings for nonlinear if functions, particularly focusing on strongly convex ones, and we have a few results.",
                    "label": 0
                },
                {
                    "sent": "So the first one is that we characterize the complexity for functions which are strongly convex and smooth, showing it's exactly square root of the squared over 2.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is several implications.",
                    "label": 0
                },
                {
                    "sent": "So first of all, it's a tight characterization for general nonlinear class.",
                    "label": 1
                },
                {
                    "sent": "It shows that in general team a skill at least quadratic in the dimension, and the lower bounds that we show also implies strong lower bounds for more.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "General cases.",
                    "label": 0
                },
                {
                    "sent": "The 2nd result that we show is a more positive one, namely that for a particular class of strongly convex and smooth functions, namely quadratic functions, you can actually get a rate of the squared over T without a square root, and you can even improve the dependence on the dimension in some cases.",
                    "label": 0
                },
                {
                    "sent": "So as far as we know this is the first demonstration that for a general natural class of functions you can get fast rate even if you don't have access to the gradients, just.",
                    "label": 1
                },
                {
                    "sent": "The function values an.",
                    "label": 0
                },
                {
                    "sent": "Actually there was a paper at this nips which showed for quadratic functions and lower bound of sqrt D / T. And as you may notice, this is larger than this, and it turns out that our result sort of circumnavigates circumvents there a lower bound in some nice wine.",
                    "label": 1
                },
                {
                    "sent": "I'll maybe discuss it a bit more later on.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the 3rd result.",
                    "label": 0
                },
                {
                    "sent": "So this squared over T is for the optimization error, But it turns out that the attainable regret that you can get for even for quadratic functions is only square root of the squared over T. And again this is tight, so we see here that there is a very large gap between what you can get in terms of regret and in terms of optimization.",
                    "label": 1
                },
                {
                    "sent": "In sharp contrast to what you have in the full information case and for linear functions.",
                    "label": 0
                },
                {
                    "sent": "So here it really goes from square root T to 1 / T.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is just a summary in table form.",
                    "label": 0
                },
                {
                    "sent": "So again we show that for quadratic we have this big gap between error and regret for strongly convex since we get a tight characterization tools both for error an regret and results also imply strong lower bound.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For more general cases.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's start going to the specific so quadratic functions are of course for two functions of this form, and I'm assuming that everything is scaled to be a constant for simplicity, and I'm going to make this technical assumption that I can query points in some ball around the optimum W star so the optimum doesn't lie exactly at the boundary in with linear functions this is.",
                    "label": 0
                },
                {
                    "sent": "Not a reasonable assumption, because with linear functions the ultimate is always at the boundary, but with strongly convex functions.",
                    "label": 0
                },
                {
                    "sent": "Assuming that the optimum is on the boundary is not very natural, and we can actually relax it and it simplifies things quite a bit.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A OK, so as I said for quadratic functions we can show that it is possible to get this squared over T in upper bound and the reason it circumvents the lower bound from paper presented a few days ago is because.",
                    "label": 0
                },
                {
                    "sent": "They show a result which holds if the for a domain which actually depends on.",
                    "label": 0
                },
                {
                    "sent": "In our terminology it's a domain that actually shrinks with the T. So in our setting it means that you take epsilon to be 0 and then it's no surprise that you get a bad day right here.",
                    "label": 0
                },
                {
                    "sent": "But if you make the natural assumption that the domain is something fixed, then it's not an issue.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm is yes, so I guess it seems like you're are you.",
                    "label": 0
                },
                {
                    "sent": "Are you assuming that the set is like a unitary to wall?",
                    "label": 0
                },
                {
                    "sent": "More less?",
                    "label": 0
                },
                {
                    "sent": "Or is there any assumption so set an no really the only thing is that you can query at some point and yeah, so I mean in the next slide will show the algorithm and it's really something very simple, OK?",
                    "label": 0
                },
                {
                    "sent": "I was curious in terms of how the OK because so if I was wondering how the size of the set matters to the rate, because OK if epsilon kind of needs to be a constant for this to be run on T and then how do those constraints interact?",
                    "label": 0
                },
                {
                    "sent": "And if you're essentially asking for the W start we more or less at the center very close to the centre.",
                    "label": 0
                },
                {
                    "sent": "Or can it be still fairly for now?",
                    "label": 0
                },
                {
                    "sent": "It can be anywhere then domain as long as.",
                    "label": 0
                },
                {
                    "sent": "So the simplest case is to assume it's unbounded domain, and then I either assume that the optimum is at least epsilon far from the boundary of the domain, or that I can query a distance epsilon outside the domain over which I wish to optimize.",
                    "label": 0
                },
                {
                    "sent": "Yes, has to be there in that one.",
                    "label": 0
                },
                {
                    "sent": "A well, not necessarily.",
                    "label": 0
                },
                {
                    "sent": "I mean, for the linear case there are of course techniques that allow you to optimize even if the optimum is at the boundary.",
                    "label": 0
                },
                {
                    "sent": "But then you need to use some heavy machinery, self concordant functions and so on.",
                    "label": 0
                },
                {
                    "sent": "And this assumption is.",
                    "label": 0
                },
                {
                    "sent": "For us, makes things much easier, and it seems very natural here, but I can't.",
                    "label": 0
                },
                {
                    "sent": "I don't know if the dependence on epsilon here is tight.",
                    "label": 0
                },
                {
                    "sent": "So yeah, if you have no epsilon dollar, then you really can't read it.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is really very simple.",
                    "label": 0
                },
                {
                    "sent": "There is no magic here, it's based on the standard technique of doing stochastic gradient descent with one point gradient estimate.",
                    "label": 0
                },
                {
                    "sent": "And really the only keen observation that we make here is that usually with these one point estimates you need to query very close to the point that you wish to estimate its gradient, because otherwise you start getting biases.",
                    "label": 0
                },
                {
                    "sent": "But quadratic functions have a very nice structure, which means that even if you query is very far away from the function.",
                    "label": 0
                },
                {
                    "sent": "You can still get an unbiased estimate, and because you can query from a relatively large ball, it gives you it sort of reduces the variance of your gradients and this is the key that allows you to get improved rates.",
                    "label": 0
                },
                {
                    "sent": "And this is basically the algorithm which we get the upper bound.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just as a small sidenote.",
                    "label": 0
                },
                {
                    "sent": "So while this thing holds, it turns out that if you are willing to assume a bit more on the structure of the noise, you can actually get stronger results.",
                    "label": 0
                },
                {
                    "sent": "So under certain assumptions you can get bounds, which instead of the squared you have the times the Frobenius norm square root of your quadratic term.",
                    "label": 0
                },
                {
                    "sent": "For instance, if you look at something which looks like a black box version version of Ridge regression you can get.",
                    "label": 0
                },
                {
                    "sent": "D / T rate.",
                    "label": 0
                },
                {
                    "sent": "Of course, I'm not suggesting anyone should solve Ridge regression with this algorithm, but just this just shows you that things can be a bit subtle, depending on how you define things.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and I said earlier.",
                    "label": 0
                },
                {
                    "sent": "We showed that this thing is tight so we can also get a matching lower bound of the squared over T. And note that to get this lower bound we can even allow queries anywhere in equation space, so we're not hiding anything here in terms of the domain definition you can get as much power as you want and you still have this squared over T.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I won't go over the proof details.",
                    "label": 0
                },
                {
                    "sent": "The main challenge was to really get this, so getting a dependence on D is not too hard.",
                    "label": 0
                },
                {
                    "sent": "The technical challenge was getting depends on these squared, and the idea is to use strong convexity to show that the suboptimality serve reduces to a sum of.",
                    "label": 1
                },
                {
                    "sent": "Think of hypothesis testing problem.",
                    "label": 0
                },
                {
                    "sent": "So you really need to be able to estimate the sign of the optimum and each one of its coordinates.",
                    "label": 0
                },
                {
                    "sent": "And as long as you make a mistake in some constant fraction of it, you have a mistake of at least the squared.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the rest is like a relative entropy argument, and I won't go into the details and so this was for error.",
                    "label": 0
                },
                {
                    "sent": "And now there is this interesting thing that happens when you now switch to talk about regret sofa regrets.",
                    "label": 0
                },
                {
                    "sent": "We show that a lower bound which is square root of the squared over T. And the intuition of the idea is really very simple.",
                    "label": 0
                },
                {
                    "sent": "So when you look more closely at the lower bound, the previous lower bound in the quadratic case, it turns out that it actually depends where exactly you query an.",
                    "label": 0
                },
                {
                    "sent": "It actually depends on the norm of the points you pick, and it's actually very reasonable, because if you look at, say, the one dimensional case, if you query and you want to, say, discern whether your function is the blue one or the red one, if you query very far away, it's actually easier for you to discern.",
                    "label": 0
                },
                {
                    "sent": "Whether it's red, red, blue because the values get more different.",
                    "label": 0
                },
                {
                    "sent": "But if you want to minimize regrets then.",
                    "label": 0
                },
                {
                    "sent": "You actually can't go too far away from the optimum, so you have like this.",
                    "label": 0
                },
                {
                    "sent": "No win situation here either.",
                    "label": 0
                },
                {
                    "sent": "You query very far away and get a lot of information, but also get hit with a lot of regret or you query very close to the optimum and then you get less regret.",
                    "label": 0
                },
                {
                    "sent": "But you also get less information.",
                    "label": 0
                },
                {
                    "sent": "So no matter what you do, if you construct things correctly, you cannot avoid this square root D ^2 / T bound.",
                    "label": 0
                },
                {
                    "sent": "Sorry, yes.",
                    "label": 0
                },
                {
                    "sent": "BLUE T -- W star the norm a wear.",
                    "label": 0
                },
                {
                    "sent": "Relative entropy terms depends on norm of WT.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "The distance of the Queen of Lumpy and it is, but I construct things so that W store is some point very close to 0.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it's actually would depend on the distance, but OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and now there's this 3rd result, namely that say you can get the square root of the square Doherty lower bound.",
                    "label": 1
                },
                {
                    "sent": "Even if you talk about error once you move to this more general, strongly convex and smooth functions, now we know that this is not true for a quadratic, so we have to move to a non quadratic function and the function we consider is this one.",
                    "label": 1
                },
                {
                    "sent": "It might not be immediately obvious, but this function is strongly convex.",
                    "label": 0
                },
                {
                    "sent": "And smooth and it has this nice property that close to its optimum, it behaves like a quadratic function and like the optimum really depends.",
                    "label": 0
                },
                {
                    "sent": "On this choice of East.",
                    "label": 1
                },
                {
                    "sent": "But as you move further away, all these functions converge to the same standard.",
                    "label": 0
                },
                {
                    "sent": "FW equals W squared function, and what this means is that even in the case of in the case of optimization, when you can query very far away, it actually won't help you because these functions just become more and more similar.",
                    "label": 0
                },
                {
                    "sent": "So in a sense you get the same kind of hardness that you get in the regret setting with quadratic functions with similar lower bound.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And that's basically it.",
                    "label": 0
                },
                {
                    "sent": "So, just to summarize, we gave an exact characterization for the complexity in the strongly convex and smooth case, which also implies new lower bounds.",
                    "label": 1
                },
                {
                    "sent": "For more general settings, and showing that you really get quadratic dependence on the dimension in general.",
                    "label": 0
                },
                {
                    "sent": "We showed that you can get fast error rates at least in certain cases, even if you don't have gradients and we show that there is can be substantial gaps between error and regret it once you move beyond the.",
                    "label": 0
                },
                {
                    "sent": "In your case, and maybe the main open question is now to try and understand what's the complexity for more general functions.",
                    "label": 0
                },
                {
                    "sent": "Strongly convex or general convex problems.",
                    "label": 0
                },
                {
                    "sent": "And again there is a huge gap between our current upper bounds and lower bounds in my conjecture based on the lower bounds and sort of looking at the best behavior in terms of both.",
                    "label": 0
                },
                {
                    "sent": "T&D is that this thing is really tight.",
                    "label": 0
                },
                {
                    "sent": "The square root of the squared over T, but it seems that none of our standard methods allow us to.",
                    "label": 0
                },
                {
                    "sent": "Approach such a thing so we really need some fundamentally new algorithms apparently to get this behavior, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}