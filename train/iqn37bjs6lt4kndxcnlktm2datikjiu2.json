{
    "id": "iqn37bjs6lt4kndxcnlktm2datikjiu2",
    "title": "Convex transduction with the normalized cut",
    "info": {
        "author": [
            "Tijl De Bie, Department of Engineering Mathematics, University of Bristol"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "March 2005",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlsvmlso05_bie_ctnc/",
    "segmentation": [
        [
            "Master now.",
            "Will get it.",
            "Already.",
            "So does the title of my talk, so I."
        ],
        [
            "About transaction, so I think it's good to define what transaction is.",
            "It's a method to learn classes of samples, so you will give it a set of something you want to find the classes.",
            "What you were given actually is a training set of labeled samples and the test set of all the unlabeled samples for which you want another classes.",
            "So after you solve the task, you will not be presented at the other animals for which he wants to learn the label.",
            "So the task is to find all the labels of the unlabeled samples.",
            "Because Thor."
        ],
        [
            "This morning said that he thinks it's this problem is not really useful in most applications.",
            "I have to give at least two examples in which is interesting.",
            "So the first one is image segmentation.",
            "For example, you want to separate the object in case the line would be injected.",
            "Background is all the rest.",
            "It is quite difficult to do this in a totally different way because the line is this pattern in it.",
            "To Tiger I guess.",
            "What you could ask you is to label a few of the points as being foreground or as being background, and then solve the problem subject to these constraints.",
            "So then you are given all the unlabeled samples for spot in the picture.",
            "Or labeled, namely the pixels you pointed to and you labeled yourself.",
            "This problem of paper by you and she."
        ],
        [
            "Please are environments where you categorize genes into functional classes, for example, or any other.",
            "Classification problem of and because all the genes set of genes is limited.",
            "So you take your own at least your sequence.",
            "So again, you're presented with the entire data set and so on.",
            "The jeans might be way.",
            "Time.",
            "So you can see that you can arrive to projectable, the clustering image segmentation, add some constraints, or you can extend the classification problem.",
            "Transaction problem where you immediately the labels of the unlabeled samples.",
            "The approach we take here is take a clustering algorithm as some constraints on the tables.",
            "And this approach can actually be extended to more general settings and transaction, but I will not go into that."
        ],
        [
            "So the string method we will try to make computationally tractable is a normalized cuts cost function, so I will first explain this cost function actually optimize it, and because it's it will turn out to be very difficult exactly.",
            "Fixations.",
            "And the spectral relaxation is very fast, the slower with better special relaxation is known for awhile already.",
            "And then I will show how these methods is to relaxations can be extended to update residents, do transaction with it.",
            "So the beginning the 1st three parts are just for clearing up sources for transaction.",
            "So."
        ],
        [
            "For the normalized, the data as notes in a weighted graph.",
            "This would be the way to pick up everything.",
            "Note corresponds to one of the samples in the data set.",
            "I'm.",
            "So the graph is effectively connected.",
            "I only drove a few of the of the lines because otherwise it would be a mess, so it's basically means that every edge has a weight which is positive and AI is AJ.",
            "I saw it so it's metric similarity measure between.",
            "So the higher disease, more similarly to samples are.",
            "And then a min cut clustering.",
            "To find your drop, for example, this cuts such that the sum of the edges you cut the some of the ways of the cut is as small as possible.",
            "So if P is samples, an inset updated Templeton way to to write this down.",
            "This is quite easy to solve polynomial time with to immediately see it leads to very imbalanced clusterings, as in this it would probably be best to just this one in the negative clauses in the positive class.",
            "So."
        ],
        [
            "So optimizing normalized cut instead of the cut itself.",
            "So we add a factor before the cuts, which will try to apply towards a more balanced solution.",
            "So I will."
        ],
        [
            "Rewrite this cost function and explain about what these terms are so I will rewrite it in terms of.",
            "Which is a vector containing uppance minus one and one is a constant factor.",
            "So I will use E for cause.",
            "The vector containing all the row sums of a, which is the same as a column sound because X.",
            "The affinity, so all the weights of the edges and D is just the economics.",
            "So then add this."
        ],
        [
            "Cut as we've seen it on the previous is just the sum of all collecting samples here with samples collecting samples there that we can represent it as like notation in this way.",
            "Then this is."
        ],
        [
            "Determine that an.",
            "In the normalization term.",
            "Proposed to the sum of all the edges between the negative sets and the entire data, which means so.",
            "Which means that if this negative set is really small, this time will be really small universe of the sun will be really large, since you want to minimize this.",
            "Like a small negative stuff."
        ],
        [
            "For the positive set.",
            "So in that sense you can see it biases towards more balanced solutions.",
            "This.",
            "This can be expressed in this outbreak terms and we will introduce it from S plus.",
            "So is the sum of the edges of the positive class to the other ones, and this is fine.",
            "So then if you put this notation than the cost."
        ],
        [
            "Dictation problem looks like this, so this is 1 divided by this prediction, so the cuts.",
            "So we want Y to be.",
            "Minus 1 + 1 and these are the equation specifying what as pleasant as minus are.",
            "We will use this which you can obtain my summing and subtracting these two equations so now as opposed to min cuts is a communitarian problem.",
            "It's very hard in this case."
        ],
        [
            "So.",
            "A way to solve that people study by doing a spectral relaxation."
        ],
        [
            "Can explain in two slides I think.",
            "So this is again the same problem.",
            "You solve 2 slides ago and he writes this in terms of provide Tilda, which is just an affine transformation of why?",
            "So you ask the customer to the white vector with another constant?",
            "Done."
        ],
        [
            "Translation problem becomes like this, which doesn't look much nicer at first sight.",
            "And this is not even negative of this, because S + / X minus and it is worse.",
            "But starting from this optimization problem is very easy to relax.",
            "The problem with these people.",
            "Art.",
            "But we can relax it by observing that is normal in the metric, is it?",
            "So if you work it through you will see.",
            "Drop this one inflated by something that is easier and less less tight, so this constraint becomes relevant.",
            "This plus, minus does not appear anywhere else anymore, so you can just drop it and this is the result in relaxed problem.",
            "Man.",
            "You probably see that if you wouldn't have this is like saying volume problem.",
            "In this constraints D transpose times Y~ equal to 0 means."
        ],
        [
            "We're interested in adding value well in the smallest angle value which is equal to 0 milliseconds.",
            "Smallest angle value.",
            "So you just have to solve this eigenvalue problem and take the small.",
            "I think it's corresponding to smaller values, so this result has been writing in a different, slightly different way.",
            "Machine Molly."
        ],
        [
            "So now people are showing as EP relaxation which is at."
        ],
        [
            "Fighter.",
            "Did more difficult to solve, so again this is the same optimization problem and I believe it using a label matrix gamma, which is why times Y transports at the sum of all elements of a which is also equal to this.",
            "Just a different notation to make it easier in Q is 1 / 4 plus minus.",
            "So this is a constant.",
            "It really only depends on A and this is a variable.",
            "So using this notation we can rewrite this.",
            "As this quite easily and at this you cannot just rewrite it, but you can rewrite this query of it, because this car is equal to this phone, which means that it's going to ask where minus 1 / Q.",
            "It is just kind of being."
        ],
        [
            "So the result if you plug this phone is this minimization problem.",
            "It still looks quite different.",
            "Quite difficult.",
            "You have 1 divided by cube from.",
            "This is not linear at all and you have Q times gamma, which is the multiplication of two variables, so it's still not solved.",
            "And also we still have the communitarian problem.",
            "Constraint, but you can reject it as we know.",
            "So it's actually a simple to get rid of this Q and this you just substitute gamma heads.",
            "And then I can just relax.",
            "These constraints to.",
            "Being positive semidefinite and the diagonal being equal to two times a constant."
        ],
        [
            "This is the final final primal formulation of.",
            "His optimization problem, which is.",
            "A standard as the people.",
            "Of course, now you have gamma head instead of a labeled vector, but there are several ways to label vector from the label matrix.",
            "For example, taking the dominant eigenvector or just any of these columns.",
            "There are also randomized strategies today."
        ],
        [
            "Now the dual problem is.",
            "Looks much better than this because it is over squared in the dimension of the matrix which is.",
            "The number of samples you have in the data set, but I did you pretty simple Max cut problem.",
            "Lambda which is of size linear in the data set and which is just one variable.",
            "So it's quite easy if you exploit this primal duality.",
            "So much more efficient."
        ],
        [
            "So absolutely was all about.",
            "Look how it's possible to.",
            "Impose some label constraints and do transactions.",
            "Sorry."
        ],
        [
            "All this optimization problem before doing allocation from which we derive the spectral relaxation.",
            "So let's fix some of the training labels because we know them."
        ],
        [
            "And this can be done in a very easy way, just by saying that.",
            "The label.",
            "This form L times another vector or relative to this, and these pearls corresponds to.",
            "To samples reportedly labeled and these drugs to samples.",
            "This constant column we needed because.",
            "This and this are not the opposite of each other."
        ],
        [
            "So I don't know where as this was the problem you had to solve in the case for transaction you just solve this problem where you see that.",
            "Volume problem and it's the effect of a smaller size, so it solve it if you have."
        ],
        [
            "Now what?",
            "They're very similar.",
            "There's a label matrix gamma.",
            "As we get back with this way is this times of this form.",
            "This form is a vector.com.",
            "You can see that track, heading this way.",
            "Then it has to be of this form where.",
            "Is proportional to the training vector times its transpose, and this training, picture vector transport X Factor, which we don't know and this we also don't know."
        ],
        [
            "Put all this in, it is just a matter of getting flooding at this gamma heads in.",
            "Then you get this as a result, which is again easier than the unconstrained problem because.",
            "L transpose times this is smaller than D -- 8 itself.",
            "Store now."
        ],
        [
            "Have two relaxations.",
            "We have a spectral relaxation and SDP relaxation.",
            "Spectral is really fast.",
            "The Sep is quite slowly.",
            "In fact you can scale up to about 1000 samples like you from acting on such such a computer.",
            "So it's it's not for very large datasets.",
            "But"
        ],
        [
            "We can we can try and combine.",
            "That approach may be improved to relaxation in quality and make these appear bit faster.",
            "So that's when I will explain.",
            "And in fact, it is interesting to notice that the spectral excitation is in fact the reputation of the aesopi relaxation.",
            "So I do not show it, but it can be show."
        ],
        [
            "So the trick people used to combine it approaches that.",
            "Imagine you know with substance.",
            "For which you know the effector combination of it so lightly.",
            "Night night.",
            "Matrix YY transpose.",
            "In this way with them quite tricks.",
            "So rows and columns as many as you as a dimensionality of the topic.",
            "And the online, it reduces to and as it is much more.",
            "Ideally we want it to be rank one, of course, because you want to label vector.",
            "OK, be constraint.",
            "And now, because I'm much more much faster, the problem is of this."
        ],
        [
            "And you can see that.",
            "This is still the same size, which is a bit annoying, but it is smaller and the object is all objective is also smaller.",
            "And of course the number of variables is much more than.",
            "It was before.",
            "But now Miss Witch witch Witch witch is."
        ],
        [
            "Can we find a good estimate of a subspace?",
            "For this we can use a spectral relaxation to estimate to estimate it.",
            "So you're just essentially taking the.",
            "Eigenvector corresponding to the second thing, if you take a few of them so the third smallest and so on, as many as you can computationally handle.",
            "And I'm one problem is that this subspace is not going to be perfect, so the label vector will not be exactly in the subspace.",
            "So this constraints on the diagonal of Gamma Hat, which is the angle of contact speech transports not be exactly equal to Q * A constant.",
            "Being two and one can show that it doesn't matter with inequality or large generated so."
        ],
        [
            "Because of this, the problem just changed a little bit.",
            "Here comes a greater than or equal an.",
            "Here the lambdas have to be greater than or equal to 0."
        ],
        [
            "Now, if you want to do transaction is exactly the same approach except for the fact that you used the spectral transaction.",
            "Spectral clustering method to find the subspace Phi.",
            "So result quite efficient and you can actually choose yourself how fast it will be by taking more plus eigenvector.",
            "So taking a larger or smaller.",
            "Subspace parameterized Ivy, and in fact for full rank.",
            "So if you take the entire space that is taken to approximate."
        ],
        [
            "I will show just a few experiments."
        ],
        [
            "This text, datasets and the text data set consists of.",
            "The same.",
            "In fact, this Wisconsin Constitution, so you have different articles in the Constitution that translated for languages in French, English, German and Italian.",
            "Do is 2 transaction problems.",
            "The first one is a classified English and French are one plus Germany plus the total number of samples is 780 right away and then we get.",
            "You get this on the test set performance.",
            "For increasing training set size.",
            "So if you label more samples the performance improves.",
            "Another blew it for different classification problem on the same data set name.",
            "If you classify the largest chapter in this Constitution versus the other chapters in the Constitution, so then particles of the same language going the same path basically which makes it much more difficult because it's much easier to think based on the language that based on the topic.",
            "So then we get the blue curve.",
            "So you see that.",
            "If you get more samples also the performance improves.",
            "And then another."
        ],
        [
            "Department this is for a data set that is too large to start off with the.",
            "With the as a P methods.",
            "So this has been solved with the combination of the spectral and easy method and on the horizontal axis the rank of these for the size of the.",
            "The dimensionality of feature and is the score, and you see that if we increase is in general explain these.",
            "I don't know where that comes from.",
            "So that is for three different sizes.",
            "So."
        ],
        [
            "I think the most probably the most interesting part is is.",
            "Petrol and relax stations because it's probably triggers other problems as well."
        ],
        [
            "So that still remains to be done is expecting that problem structure.",
            "Is this possible?",
            "Speed it up a bit further and then something more relevant for people is also to do statistical study of use of the normalized cuts in this transaction comps and then.",
            "Something else is for the Mexican problem.",
            "For example, if you are axiomatic problem, you can prove that you will reach the true optimum within a certain factor, so it will be interesting to see if we can prove something similar here about on the currency of the proximation, and then maybe Lastly do an extension to multiclass problems.",
            "So investing.",
            "So going back to experience.",
            "It's a mega first girl."
        ],
        [
            "And the data set.",
            "The vocabulary.",
            "Exactly, and there's a lot of power.",
            "Under next time we have this.",
            "Pat"
        ],
        [
            "So does it mean that you actually?",
            "I mean.",
            "Be taking 2 dimensions to approximately.",
            "Yeah.",
            "Effective mean that that it may be for further measures you cannot estimate it as effectively.",
            "I mean.",
            "I.",
            "But it's not exactly.",
            "This is not exactly done with them.",
            "Because I developed the other one, when I showed a few days ago, so I did.",
            "So I think maybe with this method is not going to be there anymore.",
            "Can see something?",
            "Tension.",
            "I think yeah."
        ],
        [
            "Also on everything.",
            "Have a report.",
            "I don't think it's published.",
            "An was true, in which they also didn't develop the relaxation of the normalized cuts.",
            "This different one is computationally more much more difficult to solve because the jewel is not contains many more variables in this form.",
            "They did do it for a multiclass problem.",
            "Think it's possible to do it, but look into it yet.",
            "No, that's for clustering with a semi supervised learning.",
            "Population, I think it is.",
            "But because of the fact that it's a more difficult as it is only possible to solve for up to 100 centers, I think I didn't implement it myself, but I think.",
            "Yes we do.",
            "Thank you very often.",
            "Active.",
            "Maybe?",
            "Space clustering.",
            "Resume video.",
            "You'll be.",
            "Multiclass clustering on reduced representation.",
            "So I mean, that's how it is.",
            "Search admin.",
            "Pick more simpler when I try to do this in the multiclass setting.",
            "I don't know yet, I didn't.",
            "Maybe in 2018?",
            "I don't think so really depends on what is your.",
            "Either.",
            "But I don't.",
            "Transaction.",
            "Happy.",
            "For sure."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Master now.",
                    "label": 0
                },
                {
                    "sent": "Will get it.",
                    "label": 0
                },
                {
                    "sent": "Already.",
                    "label": 0
                },
                {
                    "sent": "So does the title of my talk, so I.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About transaction, so I think it's good to define what transaction is.",
                    "label": 0
                },
                {
                    "sent": "It's a method to learn classes of samples, so you will give it a set of something you want to find the classes.",
                    "label": 0
                },
                {
                    "sent": "What you were given actually is a training set of labeled samples and the test set of all the unlabeled samples for which you want another classes.",
                    "label": 1
                },
                {
                    "sent": "So after you solve the task, you will not be presented at the other animals for which he wants to learn the label.",
                    "label": 0
                },
                {
                    "sent": "So the task is to find all the labels of the unlabeled samples.",
                    "label": 0
                },
                {
                    "sent": "Because Thor.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This morning said that he thinks it's this problem is not really useful in most applications.",
                    "label": 0
                },
                {
                    "sent": "I have to give at least two examples in which is interesting.",
                    "label": 0
                },
                {
                    "sent": "So the first one is image segmentation.",
                    "label": 0
                },
                {
                    "sent": "For example, you want to separate the object in case the line would be injected.",
                    "label": 0
                },
                {
                    "sent": "Background is all the rest.",
                    "label": 0
                },
                {
                    "sent": "It is quite difficult to do this in a totally different way because the line is this pattern in it.",
                    "label": 0
                },
                {
                    "sent": "To Tiger I guess.",
                    "label": 0
                },
                {
                    "sent": "What you could ask you is to label a few of the points as being foreground or as being background, and then solve the problem subject to these constraints.",
                    "label": 0
                },
                {
                    "sent": "So then you are given all the unlabeled samples for spot in the picture.",
                    "label": 0
                },
                {
                    "sent": "Or labeled, namely the pixels you pointed to and you labeled yourself.",
                    "label": 0
                },
                {
                    "sent": "This problem of paper by you and she.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Please are environments where you categorize genes into functional classes, for example, or any other.",
                    "label": 1
                },
                {
                    "sent": "Classification problem of and because all the genes set of genes is limited.",
                    "label": 0
                },
                {
                    "sent": "So you take your own at least your sequence.",
                    "label": 0
                },
                {
                    "sent": "So again, you're presented with the entire data set and so on.",
                    "label": 0
                },
                {
                    "sent": "The jeans might be way.",
                    "label": 0
                },
                {
                    "sent": "Time.",
                    "label": 0
                },
                {
                    "sent": "So you can see that you can arrive to projectable, the clustering image segmentation, add some constraints, or you can extend the classification problem.",
                    "label": 0
                },
                {
                    "sent": "Transaction problem where you immediately the labels of the unlabeled samples.",
                    "label": 0
                },
                {
                    "sent": "The approach we take here is take a clustering algorithm as some constraints on the tables.",
                    "label": 0
                },
                {
                    "sent": "And this approach can actually be extended to more general settings and transaction, but I will not go into that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the string method we will try to make computationally tractable is a normalized cuts cost function, so I will first explain this cost function actually optimize it, and because it's it will turn out to be very difficult exactly.",
                    "label": 0
                },
                {
                    "sent": "Fixations.",
                    "label": 0
                },
                {
                    "sent": "And the spectral relaxation is very fast, the slower with better special relaxation is known for awhile already.",
                    "label": 0
                },
                {
                    "sent": "And then I will show how these methods is to relaxations can be extended to update residents, do transaction with it.",
                    "label": 0
                },
                {
                    "sent": "So the beginning the 1st three parts are just for clearing up sources for transaction.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the normalized, the data as notes in a weighted graph.",
                    "label": 0
                },
                {
                    "sent": "This would be the way to pick up everything.",
                    "label": 0
                },
                {
                    "sent": "Note corresponds to one of the samples in the data set.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So the graph is effectively connected.",
                    "label": 0
                },
                {
                    "sent": "I only drove a few of the of the lines because otherwise it would be a mess, so it's basically means that every edge has a weight which is positive and AI is AJ.",
                    "label": 0
                },
                {
                    "sent": "I saw it so it's metric similarity measure between.",
                    "label": 0
                },
                {
                    "sent": "So the higher disease, more similarly to samples are.",
                    "label": 0
                },
                {
                    "sent": "And then a min cut clustering.",
                    "label": 0
                },
                {
                    "sent": "To find your drop, for example, this cuts such that the sum of the edges you cut the some of the ways of the cut is as small as possible.",
                    "label": 0
                },
                {
                    "sent": "So if P is samples, an inset updated Templeton way to to write this down.",
                    "label": 0
                },
                {
                    "sent": "This is quite easy to solve polynomial time with to immediately see it leads to very imbalanced clusterings, as in this it would probably be best to just this one in the negative clauses in the positive class.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So optimizing normalized cut instead of the cut itself.",
                    "label": 0
                },
                {
                    "sent": "So we add a factor before the cuts, which will try to apply towards a more balanced solution.",
                    "label": 0
                },
                {
                    "sent": "So I will.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rewrite this cost function and explain about what these terms are so I will rewrite it in terms of.",
                    "label": 0
                },
                {
                    "sent": "Which is a vector containing uppance minus one and one is a constant factor.",
                    "label": 0
                },
                {
                    "sent": "So I will use E for cause.",
                    "label": 0
                },
                {
                    "sent": "The vector containing all the row sums of a, which is the same as a column sound because X.",
                    "label": 0
                },
                {
                    "sent": "The affinity, so all the weights of the edges and D is just the economics.",
                    "label": 0
                },
                {
                    "sent": "So then add this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cut as we've seen it on the previous is just the sum of all collecting samples here with samples collecting samples there that we can represent it as like notation in this way.",
                    "label": 0
                },
                {
                    "sent": "Then this is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Determine that an.",
                    "label": 0
                },
                {
                    "sent": "In the normalization term.",
                    "label": 0
                },
                {
                    "sent": "Proposed to the sum of all the edges between the negative sets and the entire data, which means so.",
                    "label": 0
                },
                {
                    "sent": "Which means that if this negative set is really small, this time will be really small universe of the sun will be really large, since you want to minimize this.",
                    "label": 0
                },
                {
                    "sent": "Like a small negative stuff.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the positive set.",
                    "label": 0
                },
                {
                    "sent": "So in that sense you can see it biases towards more balanced solutions.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "This can be expressed in this outbreak terms and we will introduce it from S plus.",
                    "label": 0
                },
                {
                    "sent": "So is the sum of the edges of the positive class to the other ones, and this is fine.",
                    "label": 0
                },
                {
                    "sent": "So then if you put this notation than the cost.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dictation problem looks like this, so this is 1 divided by this prediction, so the cuts.",
                    "label": 0
                },
                {
                    "sent": "So we want Y to be.",
                    "label": 0
                },
                {
                    "sent": "Minus 1 + 1 and these are the equation specifying what as pleasant as minus are.",
                    "label": 0
                },
                {
                    "sent": "We will use this which you can obtain my summing and subtracting these two equations so now as opposed to min cuts is a communitarian problem.",
                    "label": 0
                },
                {
                    "sent": "It's very hard in this case.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "A way to solve that people study by doing a spectral relaxation.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can explain in two slides I think.",
                    "label": 0
                },
                {
                    "sent": "So this is again the same problem.",
                    "label": 0
                },
                {
                    "sent": "You solve 2 slides ago and he writes this in terms of provide Tilda, which is just an affine transformation of why?",
                    "label": 0
                },
                {
                    "sent": "So you ask the customer to the white vector with another constant?",
                    "label": 0
                },
                {
                    "sent": "Done.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Translation problem becomes like this, which doesn't look much nicer at first sight.",
                    "label": 0
                },
                {
                    "sent": "And this is not even negative of this, because S + / X minus and it is worse.",
                    "label": 0
                },
                {
                    "sent": "But starting from this optimization problem is very easy to relax.",
                    "label": 0
                },
                {
                    "sent": "The problem with these people.",
                    "label": 0
                },
                {
                    "sent": "Art.",
                    "label": 0
                },
                {
                    "sent": "But we can relax it by observing that is normal in the metric, is it?",
                    "label": 0
                },
                {
                    "sent": "So if you work it through you will see.",
                    "label": 0
                },
                {
                    "sent": "Drop this one inflated by something that is easier and less less tight, so this constraint becomes relevant.",
                    "label": 0
                },
                {
                    "sent": "This plus, minus does not appear anywhere else anymore, so you can just drop it and this is the result in relaxed problem.",
                    "label": 0
                },
                {
                    "sent": "Man.",
                    "label": 0
                },
                {
                    "sent": "You probably see that if you wouldn't have this is like saying volume problem.",
                    "label": 0
                },
                {
                    "sent": "In this constraints D transpose times Y~ equal to 0 means.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're interested in adding value well in the smallest angle value which is equal to 0 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "Smallest angle value.",
                    "label": 0
                },
                {
                    "sent": "So you just have to solve this eigenvalue problem and take the small.",
                    "label": 0
                },
                {
                    "sent": "I think it's corresponding to smaller values, so this result has been writing in a different, slightly different way.",
                    "label": 1
                },
                {
                    "sent": "Machine Molly.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now people are showing as EP relaxation which is at.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fighter.",
                    "label": 0
                },
                {
                    "sent": "Did more difficult to solve, so again this is the same optimization problem and I believe it using a label matrix gamma, which is why times Y transports at the sum of all elements of a which is also equal to this.",
                    "label": 0
                },
                {
                    "sent": "Just a different notation to make it easier in Q is 1 / 4 plus minus.",
                    "label": 0
                },
                {
                    "sent": "So this is a constant.",
                    "label": 0
                },
                {
                    "sent": "It really only depends on A and this is a variable.",
                    "label": 0
                },
                {
                    "sent": "So using this notation we can rewrite this.",
                    "label": 0
                },
                {
                    "sent": "As this quite easily and at this you cannot just rewrite it, but you can rewrite this query of it, because this car is equal to this phone, which means that it's going to ask where minus 1 / Q.",
                    "label": 0
                },
                {
                    "sent": "It is just kind of being.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the result if you plug this phone is this minimization problem.",
                    "label": 0
                },
                {
                    "sent": "It still looks quite different.",
                    "label": 0
                },
                {
                    "sent": "Quite difficult.",
                    "label": 0
                },
                {
                    "sent": "You have 1 divided by cube from.",
                    "label": 0
                },
                {
                    "sent": "This is not linear at all and you have Q times gamma, which is the multiplication of two variables, so it's still not solved.",
                    "label": 0
                },
                {
                    "sent": "And also we still have the communitarian problem.",
                    "label": 0
                },
                {
                    "sent": "Constraint, but you can reject it as we know.",
                    "label": 0
                },
                {
                    "sent": "So it's actually a simple to get rid of this Q and this you just substitute gamma heads.",
                    "label": 0
                },
                {
                    "sent": "And then I can just relax.",
                    "label": 0
                },
                {
                    "sent": "These constraints to.",
                    "label": 0
                },
                {
                    "sent": "Being positive semidefinite and the diagonal being equal to two times a constant.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the final final primal formulation of.",
                    "label": 0
                },
                {
                    "sent": "His optimization problem, which is.",
                    "label": 0
                },
                {
                    "sent": "A standard as the people.",
                    "label": 0
                },
                {
                    "sent": "Of course, now you have gamma head instead of a labeled vector, but there are several ways to label vector from the label matrix.",
                    "label": 1
                },
                {
                    "sent": "For example, taking the dominant eigenvector or just any of these columns.",
                    "label": 1
                },
                {
                    "sent": "There are also randomized strategies today.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the dual problem is.",
                    "label": 0
                },
                {
                    "sent": "Looks much better than this because it is over squared in the dimension of the matrix which is.",
                    "label": 0
                },
                {
                    "sent": "The number of samples you have in the data set, but I did you pretty simple Max cut problem.",
                    "label": 0
                },
                {
                    "sent": "Lambda which is of size linear in the data set and which is just one variable.",
                    "label": 0
                },
                {
                    "sent": "So it's quite easy if you exploit this primal duality.",
                    "label": 0
                },
                {
                    "sent": "So much more efficient.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So absolutely was all about.",
                    "label": 0
                },
                {
                    "sent": "Look how it's possible to.",
                    "label": 0
                },
                {
                    "sent": "Impose some label constraints and do transactions.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All this optimization problem before doing allocation from which we derive the spectral relaxation.",
                    "label": 0
                },
                {
                    "sent": "So let's fix some of the training labels because we know them.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this can be done in a very easy way, just by saying that.",
                    "label": 0
                },
                {
                    "sent": "The label.",
                    "label": 0
                },
                {
                    "sent": "This form L times another vector or relative to this, and these pearls corresponds to.",
                    "label": 0
                },
                {
                    "sent": "To samples reportedly labeled and these drugs to samples.",
                    "label": 0
                },
                {
                    "sent": "This constant column we needed because.",
                    "label": 0
                },
                {
                    "sent": "This and this are not the opposite of each other.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I don't know where as this was the problem you had to solve in the case for transaction you just solve this problem where you see that.",
                    "label": 0
                },
                {
                    "sent": "Volume problem and it's the effect of a smaller size, so it solve it if you have.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what?",
                    "label": 0
                },
                {
                    "sent": "They're very similar.",
                    "label": 0
                },
                {
                    "sent": "There's a label matrix gamma.",
                    "label": 0
                },
                {
                    "sent": "As we get back with this way is this times of this form.",
                    "label": 0
                },
                {
                    "sent": "This form is a vector.com.",
                    "label": 0
                },
                {
                    "sent": "You can see that track, heading this way.",
                    "label": 0
                },
                {
                    "sent": "Then it has to be of this form where.",
                    "label": 0
                },
                {
                    "sent": "Is proportional to the training vector times its transpose, and this training, picture vector transport X Factor, which we don't know and this we also don't know.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Put all this in, it is just a matter of getting flooding at this gamma heads in.",
                    "label": 0
                },
                {
                    "sent": "Then you get this as a result, which is again easier than the unconstrained problem because.",
                    "label": 1
                },
                {
                    "sent": "L transpose times this is smaller than D -- 8 itself.",
                    "label": 0
                },
                {
                    "sent": "Store now.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have two relaxations.",
                    "label": 0
                },
                {
                    "sent": "We have a spectral relaxation and SDP relaxation.",
                    "label": 1
                },
                {
                    "sent": "Spectral is really fast.",
                    "label": 0
                },
                {
                    "sent": "The Sep is quite slowly.",
                    "label": 0
                },
                {
                    "sent": "In fact you can scale up to about 1000 samples like you from acting on such such a computer.",
                    "label": 0
                },
                {
                    "sent": "So it's it's not for very large datasets.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can we can try and combine.",
                    "label": 0
                },
                {
                    "sent": "That approach may be improved to relaxation in quality and make these appear bit faster.",
                    "label": 0
                },
                {
                    "sent": "So that's when I will explain.",
                    "label": 0
                },
                {
                    "sent": "And in fact, it is interesting to notice that the spectral excitation is in fact the reputation of the aesopi relaxation.",
                    "label": 0
                },
                {
                    "sent": "So I do not show it, but it can be show.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the trick people used to combine it approaches that.",
                    "label": 0
                },
                {
                    "sent": "Imagine you know with substance.",
                    "label": 0
                },
                {
                    "sent": "For which you know the effector combination of it so lightly.",
                    "label": 0
                },
                {
                    "sent": "Night night.",
                    "label": 0
                },
                {
                    "sent": "Matrix YY transpose.",
                    "label": 0
                },
                {
                    "sent": "In this way with them quite tricks.",
                    "label": 0
                },
                {
                    "sent": "So rows and columns as many as you as a dimensionality of the topic.",
                    "label": 0
                },
                {
                    "sent": "And the online, it reduces to and as it is much more.",
                    "label": 0
                },
                {
                    "sent": "Ideally we want it to be rank one, of course, because you want to label vector.",
                    "label": 0
                },
                {
                    "sent": "OK, be constraint.",
                    "label": 0
                },
                {
                    "sent": "And now, because I'm much more much faster, the problem is of this.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you can see that.",
                    "label": 0
                },
                {
                    "sent": "This is still the same size, which is a bit annoying, but it is smaller and the object is all objective is also smaller.",
                    "label": 0
                },
                {
                    "sent": "And of course the number of variables is much more than.",
                    "label": 1
                },
                {
                    "sent": "It was before.",
                    "label": 0
                },
                {
                    "sent": "But now Miss Witch witch Witch witch is.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can we find a good estimate of a subspace?",
                    "label": 0
                },
                {
                    "sent": "For this we can use a spectral relaxation to estimate to estimate it.",
                    "label": 1
                },
                {
                    "sent": "So you're just essentially taking the.",
                    "label": 1
                },
                {
                    "sent": "Eigenvector corresponding to the second thing, if you take a few of them so the third smallest and so on, as many as you can computationally handle.",
                    "label": 1
                },
                {
                    "sent": "And I'm one problem is that this subspace is not going to be perfect, so the label vector will not be exactly in the subspace.",
                    "label": 0
                },
                {
                    "sent": "So this constraints on the diagonal of Gamma Hat, which is the angle of contact speech transports not be exactly equal to Q * A constant.",
                    "label": 0
                },
                {
                    "sent": "Being two and one can show that it doesn't matter with inequality or large generated so.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because of this, the problem just changed a little bit.",
                    "label": 0
                },
                {
                    "sent": "Here comes a greater than or equal an.",
                    "label": 0
                },
                {
                    "sent": "Here the lambdas have to be greater than or equal to 0.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, if you want to do transaction is exactly the same approach except for the fact that you used the spectral transaction.",
                    "label": 0
                },
                {
                    "sent": "Spectral clustering method to find the subspace Phi.",
                    "label": 1
                },
                {
                    "sent": "So result quite efficient and you can actually choose yourself how fast it will be by taking more plus eigenvector.",
                    "label": 0
                },
                {
                    "sent": "So taking a larger or smaller.",
                    "label": 1
                },
                {
                    "sent": "Subspace parameterized Ivy, and in fact for full rank.",
                    "label": 0
                },
                {
                    "sent": "So if you take the entire space that is taken to approximate.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will show just a few experiments.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This text, datasets and the text data set consists of.",
                    "label": 0
                },
                {
                    "sent": "The same.",
                    "label": 0
                },
                {
                    "sent": "In fact, this Wisconsin Constitution, so you have different articles in the Constitution that translated for languages in French, English, German and Italian.",
                    "label": 0
                },
                {
                    "sent": "Do is 2 transaction problems.",
                    "label": 0
                },
                {
                    "sent": "The first one is a classified English and French are one plus Germany plus the total number of samples is 780 right away and then we get.",
                    "label": 0
                },
                {
                    "sent": "You get this on the test set performance.",
                    "label": 0
                },
                {
                    "sent": "For increasing training set size.",
                    "label": 0
                },
                {
                    "sent": "So if you label more samples the performance improves.",
                    "label": 0
                },
                {
                    "sent": "Another blew it for different classification problem on the same data set name.",
                    "label": 0
                },
                {
                    "sent": "If you classify the largest chapter in this Constitution versus the other chapters in the Constitution, so then particles of the same language going the same path basically which makes it much more difficult because it's much easier to think based on the language that based on the topic.",
                    "label": 0
                },
                {
                    "sent": "So then we get the blue curve.",
                    "label": 0
                },
                {
                    "sent": "So you see that.",
                    "label": 0
                },
                {
                    "sent": "If you get more samples also the performance improves.",
                    "label": 0
                },
                {
                    "sent": "And then another.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Department this is for a data set that is too large to start off with the.",
                    "label": 0
                },
                {
                    "sent": "With the as a P methods.",
                    "label": 0
                },
                {
                    "sent": "So this has been solved with the combination of the spectral and easy method and on the horizontal axis the rank of these for the size of the.",
                    "label": 0
                },
                {
                    "sent": "The dimensionality of feature and is the score, and you see that if we increase is in general explain these.",
                    "label": 0
                },
                {
                    "sent": "I don't know where that comes from.",
                    "label": 0
                },
                {
                    "sent": "So that is for three different sizes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think the most probably the most interesting part is is.",
                    "label": 0
                },
                {
                    "sent": "Petrol and relax stations because it's probably triggers other problems as well.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that still remains to be done is expecting that problem structure.",
                    "label": 1
                },
                {
                    "sent": "Is this possible?",
                    "label": 0
                },
                {
                    "sent": "Speed it up a bit further and then something more relevant for people is also to do statistical study of use of the normalized cuts in this transaction comps and then.",
                    "label": 1
                },
                {
                    "sent": "Something else is for the Mexican problem.",
                    "label": 1
                },
                {
                    "sent": "For example, if you are axiomatic problem, you can prove that you will reach the true optimum within a certain factor, so it will be interesting to see if we can prove something similar here about on the currency of the proximation, and then maybe Lastly do an extension to multiclass problems.",
                    "label": 0
                },
                {
                    "sent": "So investing.",
                    "label": 0
                },
                {
                    "sent": "So going back to experience.",
                    "label": 0
                },
                {
                    "sent": "It's a mega first girl.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the data set.",
                    "label": 0
                },
                {
                    "sent": "The vocabulary.",
                    "label": 0
                },
                {
                    "sent": "Exactly, and there's a lot of power.",
                    "label": 0
                },
                {
                    "sent": "Under next time we have this.",
                    "label": 0
                },
                {
                    "sent": "Pat",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So does it mean that you actually?",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "Be taking 2 dimensions to approximately.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Effective mean that that it may be for further measures you cannot estimate it as effectively.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "But it's not exactly.",
                    "label": 0
                },
                {
                    "sent": "This is not exactly done with them.",
                    "label": 0
                },
                {
                    "sent": "Because I developed the other one, when I showed a few days ago, so I did.",
                    "label": 0
                },
                {
                    "sent": "So I think maybe with this method is not going to be there anymore.",
                    "label": 0
                },
                {
                    "sent": "Can see something?",
                    "label": 0
                },
                {
                    "sent": "Tension.",
                    "label": 0
                },
                {
                    "sent": "I think yeah.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also on everything.",
                    "label": 0
                },
                {
                    "sent": "Have a report.",
                    "label": 0
                },
                {
                    "sent": "I don't think it's published.",
                    "label": 0
                },
                {
                    "sent": "An was true, in which they also didn't develop the relaxation of the normalized cuts.",
                    "label": 1
                },
                {
                    "sent": "This different one is computationally more much more difficult to solve because the jewel is not contains many more variables in this form.",
                    "label": 0
                },
                {
                    "sent": "They did do it for a multiclass problem.",
                    "label": 0
                },
                {
                    "sent": "Think it's possible to do it, but look into it yet.",
                    "label": 1
                },
                {
                    "sent": "No, that's for clustering with a semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Population, I think it is.",
                    "label": 0
                },
                {
                    "sent": "But because of the fact that it's a more difficult as it is only possible to solve for up to 100 centers, I think I didn't implement it myself, but I think.",
                    "label": 0
                },
                {
                    "sent": "Yes we do.",
                    "label": 0
                },
                {
                    "sent": "Thank you very often.",
                    "label": 0
                },
                {
                    "sent": "Active.",
                    "label": 0
                },
                {
                    "sent": "Maybe?",
                    "label": 0
                },
                {
                    "sent": "Space clustering.",
                    "label": 0
                },
                {
                    "sent": "Resume video.",
                    "label": 0
                },
                {
                    "sent": "You'll be.",
                    "label": 0
                },
                {
                    "sent": "Multiclass clustering on reduced representation.",
                    "label": 0
                },
                {
                    "sent": "So I mean, that's how it is.",
                    "label": 0
                },
                {
                    "sent": "Search admin.",
                    "label": 0
                },
                {
                    "sent": "Pick more simpler when I try to do this in the multiclass setting.",
                    "label": 0
                },
                {
                    "sent": "I don't know yet, I didn't.",
                    "label": 0
                },
                {
                    "sent": "Maybe in 2018?",
                    "label": 0
                },
                {
                    "sent": "I don't think so really depends on what is your.",
                    "label": 0
                },
                {
                    "sent": "Either.",
                    "label": 0
                },
                {
                    "sent": "But I don't.",
                    "label": 0
                },
                {
                    "sent": "Transaction.",
                    "label": 0
                },
                {
                    "sent": "Happy.",
                    "label": 0
                },
                {
                    "sent": "For sure.",
                    "label": 0
                }
            ]
        }
    }
}