{
    "id": "ng4w3ateq5yve6muzoe3fl3luhpgfrx7",
    "title": "Efficient Shape Matching using Vector Extrapolation",
    "info": {
        "author": [
            "Emanuele Rodol\u00e0, Faculty of Informatics, TU Munich"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_rodola_vector_extrapolation/",
    "segmentation": [
        [
            "So I am a little dollar from the University of Tokyo and from the Technical University of Munich and this is a joint work with that's where other and just work on your shin.",
            "Daniel cremers."
        ],
        [
            "So in this talk, we will consider the problem of shape matching.",
            "This is a rather pervasive problem in computer vision.",
            "And it's frequently arises in several different areas such."
        ],
        [
            "As.",
            "Rigid alignment of range Maps for three dimensional reconstruction.",
            "Or"
        ],
        [
            "Object in cluster recognition or."
        ],
        [
            "Feature matching for structure from motion pipelines, for instance."
        ],
        [
            "So this is a very general problem, an usually devising specific techniques for reaching a solution can be very challenging, so there have been proposed many general formulations.",
            "Such as the quadratic assignment problem formulation an in all these cases you need to consider more general optimization algorithms such as gradient methods.",
            "An an issue with these algorithms is that they tend to be slow in large scale problems, such as in real world."
        ],
        [
            "So let us first define a shape correspondence.",
            "So let us be given two shapes X&Y and we define a point to point correspondence to be a function taking a pair of points on the two shapes.",
            "An giving a value close to one.",
            "If these two points represent a match or a value close to 0 if they are not a match.",
            "And this binary function.",
            "This fuzzy function must satisfy certain mapping constraints, such as one to one mapping or one to many mapping and so forth."
        ],
        [
            "So let us consider for moments the case in which the two shapes are metric spaces, so they are equipped with the magic function on each space.",
            "An let's say we want to quantify the quality of a given correspondence so we can do this by directly measuring the deviation from isometry induced by the correspondence.",
            "So in this example here I'm showing a rigid alignment problem, so we would consider Euclidean metrics for example.",
            "So."
        ],
        [
            "More frequently in the community, we do not consider metric spaces, so instead of measuring."
        ],
        [
            "A local distortion in the magic we usually."
        ],
        [
            "Define some measure of similarity among pairs of matches.",
            "This is much more frequency, much more frequent, especially in the graph matching community.",
            "And then we can define the total similarity of the correspondence as a weighted sum of all the local similarities so.",
            "While"
        ],
        [
            "And in the metric space view, we would be interested in minimizing the overall distortion than in the similarity."
        ],
        [
            "If you would be interested in maximizing the overall similarity of the correspondences."
        ],
        [
            "So if we were to write this problem in matrix notation, we would obtain the so called quadratic assignment problem, or acuity in short.",
            "So we have to maximize our quadratic form over X&X here represents.",
            "The the the correspondence function, so it takes values in 01 and each element corresponds to a candidate match and then we have matrix S encoding the similarity terms from the previous formula and general function Pi imposing mapping constraints over the correspondence.",
            "So in this function \u03c0 in general can be nonlinear, can be linear, can be anything, so just imposing one to one or one to many and so forth."
        ],
        [
            "So there is a very well known relaxation to the QEP, which is takes the name of spectral matching.",
            "This is due to Lee Ordean, when Herbert from my CV 2005.",
            "So basically what they do is they replace the mapping constraints with the unit norm constraints on a correspondent function in the L2 cents.",
            "So an by Rayleigh theorem this allows them to compute the global maximum to the quadratic form just by looking at the principal eigenvector of the similarity matrix.",
            "And this is an example result that we get when when doing this.",
            "When applying this approach in a non rigid matching problem.",
            "So we get many correct matches, but also many mismatches.",
            "And this is because it is a spectral solution, so it is very sensitive to noise to symmetries in the data and so on and so on."
        ],
        [
            "So in 2012 we proposed to replace this unit.",
            "Norm constraints on the correspondence function by a simplex constraint.",
            "So basically we are replacing the L2 norm with the L1 norm and by doing this we proposed a game theoretic framework for reaching a solution which was very efficient.",
            "And as we could expect, the L1 norm on X will favor.",
            "Very sparse solutions, but this will also be very very stable.",
            "So yesterday that there was a presentation as opposed to station, but by Michael Donoso and they were doing something very similar, but in a clustering setting."
        ],
        [
            "So what we could do now is to take.",
            "A linear combination of these two approaches, so we have on one hand the spectral approach, on the other hand, the game theoretic approach and by looking at these combination in particular convex combination of this whole approach is we make use of what is known as elastic net constraint.",
            "So also yesterday there was a talk by Luca Marcus Ottey using the same constraints for a different problem.",
            "So by using the elastic net basically we have a way.",
            "To control sparsity of the correspondence function.",
            "So we have this convexity parameter Alpha from zero to one which goes from the spectral solution from the game theoretic solution for Alpha equals 0.",
            "So the spectral solution for Alpha equals one, and then we have all the intermediate solutions in between so."
        ],
        [
            "For instance.",
            "This is our new formulation for the matching problem.",
            "It is elastic net matching, let's say, and.",
            "On the left we have the game theoretic solution.",
            "On the right the spectral solution and in the middle we have an intermediate solution obtained by imposing Alpha equals 0.85 and this solution is very accurate and it's much denser than the game theoretic approach."
        ],
        [
            "So how do we optimize this?",
            "We take a projected gradient approach.",
            "So basically it's just a gradient ascent where we have a projection operator onto the feasible set.",
            "So in this case onto the boundary of the elastic netball at Convexity Alpha.",
            "And this is this plot shows a typical vector sequence generated by the optimization process and this vector sequence looks rather smooth, so."
        ],
        [
            "What we ask is, given that these vector sequences rather smooth, maybe we could infer the general direction of convergence by just looking at previous at pastita rates.",
            "OK, so."
        ],
        [
            "And actually this can be done.",
            "So let us see how in order to do this we look at the family of techniques called vector extrapolation and.",
            "These this family of techniques arised in.",
            "In in the field of.",
            "Computational physics I believe, and they where they are used to compute solutions.",
            "Approximate solutions to very large nonlinear systems.",
            "So let us first look at the linear at the linear setting.",
            "So consider a vector sequence generated by a linear process.",
            "And.",
            "If this sequence converges, then it it it comes to convergence at the unique solution to a linear system.",
            "So the point is that we do not assume that we have explicit knowledge of matrix A or vector B.",
            "So we are only given the generating sequence, the generating process or the vector sequence.",
            "And we want to estimate the limit vector."
        ],
        [
            "So this process often requires many iterations to come to convergence, and above all, deem dividual terms of the sequence could be very expensive to compute.",
            "So if we look again, there are a matching scenario.",
            "We have the projection step.",
            "Onto the set of mapping constraints, which can be very expensive to compute, so that depends on what kind of mapping constraints we're going to impose."
        ],
        [
            "So what we would like to do is to compute this limit vector using as few times as possible, let's say using K terms so.",
            "It turns out, so I invite you to look at the papers of the paper for the technical details, but it turns out that we can obtain an estimate to the to this vector sequence to the limit of this vector sequence by just taking a linear combination of previous iterates.",
            "So we have to solve for these coefficients in the linear combination, but it is a very can be done very efficiently.",
            "By minimizing the least least square problem, which is the last formula in this slide?",
            "So.",
            "Also, in in case the sequence is linearly generated, we have the guarantee that this estimation will give the global optimum.",
            "So the."
        ],
        [
            "From is that in our matching scenario, the sequence is not generated by linear process, so we have these nonlinear process.",
            "Where the non linearity is brought in by the projection operator over the of the mapping constraints.",
            "So how can we deal with this?"
        ],
        [
            "We resort to a procedure known as cycling.",
            "So basically which is 2 parameters, an NK, and then we perform N + K + 1 standard projected gradient steps.",
            "And we keep only the last K vectors.",
            "Then we can apply."
        ],
        [
            "Vector extrapolation to these vectors.",
            "So they're just came of them.",
            "And we obtain an estimate for the for the limit vector."
        ],
        [
            "And of course this estimate is not necessarily lying over the feasible set, so we have to re project this solution over the feasible set.",
            "And we."
        ],
        [
            "Check the objective value of the projector solution and if it attains a greater value than we we proceed and we repeat another cycle."
        ],
        [
            "We do that do this many times until we reach convergence."
        ],
        [
            "So this."
        ],
        [
            "Cycling procedure does not give any guarantee, but in the physical community that there is.",
            "They have observed very good convergence properties and this is what we observed in this case as well."
        ],
        [
            "So let us let us look at some examples.",
            "So the first setting is rather classical.",
            "Also not very difficult, it's just rigid matching of point clouds.",
            "So we are given two point clouds.",
            "Then we need to determine to establish point to point correspondences among these two point clouds and in order to do this we can just define a similarity function enforcing rigid isometries.",
            "And.",
            "Since this is a not a very difficult problem, this allows us to perform some sensitivity analysis on the parameters of our method, so namely."
        ],
        [
            "The length.",
            "Of the of the site of the cycle cycling.",
            "So."
        ],
        [
            "What is surprising is that.",
            "It turns out that for short periods we obtain much better results.",
            "I mean the final.",
            "Vector at convergence is always the same, but we have one order of magnitude improvement.",
            "Over the same technique, with no extrapolation at all and over.",
            "In longer periods for the cycling procedure, so this problem is not perhaps many much interesting because it's quite well understood.",
            "So let's go to."
        ],
        [
            "Experiment #2 matching of deformable shapes so by deformable shapes we mean shape that undergo anything which is not a rigid deformation.",
            "So we can have isometric deformations or different scales.",
            "Partiality deformations, affine transformations and so on."
        ],
        [
            "So this is a very challenging problem and it is also a very active area of research in the computer vision and computer graphics communities.",
            "So to do this to solve this problem with."
        ],
        [
            "Take the same similarity function from the rigid case in which we replace the Euclidean metric by some intrinsic metric, so in."
        ],
        [
            "So we take diffusion magic over the two shapes over the two manifolds.",
            "And surprisingly, also in this case we obtain one order of magnitude of improvement.",
            "Over them helped him.",
            "Organization performed with no extrapolation at all, and also in this case shorter periods give the best results.",
            "So in this case we're just taking five iterates from the optimization process.",
            "So basically the memory usage requirements are very, very low, almost nonexistent.",
            "And using the elastic net formulation, we are also obtaining state of the art results on our standard datasets on Shrek 2010 for the isometry class."
        ],
        [
            "As a final example, here I'm showing some experiments with the multiple View stereo application.",
            "So here I'm refering to the classical pipeline in which we have a feature matching step followed by a bundle adjustment step.",
            "So an as you know, if the bundle adjustment step should not be given outliers in the data, otherwise the reconstruction will will will be screwed up basically.",
            "So in order to meet these strong selectivity requirements.",
            "We set Alpha equals 0.2 to into the elastic net, so this means that the matching will be very, very selective and very stable.",
            "And for this class of problems we only observed more than moderate improvements, so.",
            "Just 30% less iterations with respect to no extrapolation at all an.",
            "In particular, using short cycles in a cycling procedure leads to premature convergence, so we had to use longer cycles like 1525 or 30.",
            "An this is probably due to the presence of repeated structure and textures in the data, which make the whole setting more unstable with respect to the previous scenarios.",
            "And this concludes my presentation.",
            "So if you have any questions, I will be happy to answer."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I am a little dollar from the University of Tokyo and from the Technical University of Munich and this is a joint work with that's where other and just work on your shin.",
                    "label": 0
                },
                {
                    "sent": "Daniel cremers.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk, we will consider the problem of shape matching.",
                    "label": 0
                },
                {
                    "sent": "This is a rather pervasive problem in computer vision.",
                    "label": 1
                },
                {
                    "sent": "And it's frequently arises in several different areas such.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As.",
                    "label": 0
                },
                {
                    "sent": "Rigid alignment of range Maps for three dimensional reconstruction.",
                    "label": 0
                },
                {
                    "sent": "Or",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Object in cluster recognition or.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feature matching for structure from motion pipelines, for instance.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a very general problem, an usually devising specific techniques for reaching a solution can be very challenging, so there have been proposed many general formulations.",
                    "label": 1
                },
                {
                    "sent": "Such as the quadratic assignment problem formulation an in all these cases you need to consider more general optimization algorithms such as gradient methods.",
                    "label": 1
                },
                {
                    "sent": "An an issue with these algorithms is that they tend to be slow in large scale problems, such as in real world.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let us first define a shape correspondence.",
                    "label": 1
                },
                {
                    "sent": "So let us be given two shapes X&Y and we define a point to point correspondence to be a function taking a pair of points on the two shapes.",
                    "label": 0
                },
                {
                    "sent": "An giving a value close to one.",
                    "label": 0
                },
                {
                    "sent": "If these two points represent a match or a value close to 0 if they are not a match.",
                    "label": 0
                },
                {
                    "sent": "And this binary function.",
                    "label": 0
                },
                {
                    "sent": "This fuzzy function must satisfy certain mapping constraints, such as one to one mapping or one to many mapping and so forth.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let us consider for moments the case in which the two shapes are metric spaces, so they are equipped with the magic function on each space.",
                    "label": 0
                },
                {
                    "sent": "An let's say we want to quantify the quality of a given correspondence so we can do this by directly measuring the deviation from isometry induced by the correspondence.",
                    "label": 0
                },
                {
                    "sent": "So in this example here I'm showing a rigid alignment problem, so we would consider Euclidean metrics for example.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More frequently in the community, we do not consider metric spaces, so instead of measuring.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A local distortion in the magic we usually.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Define some measure of similarity among pairs of matches.",
                    "label": 1
                },
                {
                    "sent": "This is much more frequency, much more frequent, especially in the graph matching community.",
                    "label": 1
                },
                {
                    "sent": "And then we can define the total similarity of the correspondence as a weighted sum of all the local similarities so.",
                    "label": 0
                },
                {
                    "sent": "While",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the metric space view, we would be interested in minimizing the overall distortion than in the similarity.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you would be interested in maximizing the overall similarity of the correspondences.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we were to write this problem in matrix notation, we would obtain the so called quadratic assignment problem, or acuity in short.",
                    "label": 1
                },
                {
                    "sent": "So we have to maximize our quadratic form over X&X here represents.",
                    "label": 0
                },
                {
                    "sent": "The the the correspondence function, so it takes values in 01 and each element corresponds to a candidate match and then we have matrix S encoding the similarity terms from the previous formula and general function Pi imposing mapping constraints over the correspondence.",
                    "label": 1
                },
                {
                    "sent": "So in this function \u03c0 in general can be nonlinear, can be linear, can be anything, so just imposing one to one or one to many and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is a very well known relaxation to the QEP, which is takes the name of spectral matching.",
                    "label": 1
                },
                {
                    "sent": "This is due to Lee Ordean, when Herbert from my CV 2005.",
                    "label": 0
                },
                {
                    "sent": "So basically what they do is they replace the mapping constraints with the unit norm constraints on a correspondent function in the L2 cents.",
                    "label": 0
                },
                {
                    "sent": "So an by Rayleigh theorem this allows them to compute the global maximum to the quadratic form just by looking at the principal eigenvector of the similarity matrix.",
                    "label": 0
                },
                {
                    "sent": "And this is an example result that we get when when doing this.",
                    "label": 0
                },
                {
                    "sent": "When applying this approach in a non rigid matching problem.",
                    "label": 0
                },
                {
                    "sent": "So we get many correct matches, but also many mismatches.",
                    "label": 0
                },
                {
                    "sent": "And this is because it is a spectral solution, so it is very sensitive to noise to symmetries in the data and so on and so on.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in 2012 we proposed to replace this unit.",
                    "label": 0
                },
                {
                    "sent": "Norm constraints on the correspondence function by a simplex constraint.",
                    "label": 1
                },
                {
                    "sent": "So basically we are replacing the L2 norm with the L1 norm and by doing this we proposed a game theoretic framework for reaching a solution which was very efficient.",
                    "label": 0
                },
                {
                    "sent": "And as we could expect, the L1 norm on X will favor.",
                    "label": 1
                },
                {
                    "sent": "Very sparse solutions, but this will also be very very stable.",
                    "label": 0
                },
                {
                    "sent": "So yesterday that there was a presentation as opposed to station, but by Michael Donoso and they were doing something very similar, but in a clustering setting.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we could do now is to take.",
                    "label": 0
                },
                {
                    "sent": "A linear combination of these two approaches, so we have on one hand the spectral approach, on the other hand, the game theoretic approach and by looking at these combination in particular convex combination of this whole approach is we make use of what is known as elastic net constraint.",
                    "label": 0
                },
                {
                    "sent": "So also yesterday there was a talk by Luca Marcus Ottey using the same constraints for a different problem.",
                    "label": 0
                },
                {
                    "sent": "So by using the elastic net basically we have a way.",
                    "label": 1
                },
                {
                    "sent": "To control sparsity of the correspondence function.",
                    "label": 0
                },
                {
                    "sent": "So we have this convexity parameter Alpha from zero to one which goes from the spectral solution from the game theoretic solution for Alpha equals 0.",
                    "label": 0
                },
                {
                    "sent": "So the spectral solution for Alpha equals one, and then we have all the intermediate solutions in between so.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "This is our new formulation for the matching problem.",
                    "label": 0
                },
                {
                    "sent": "It is elastic net matching, let's say, and.",
                    "label": 1
                },
                {
                    "sent": "On the left we have the game theoretic solution.",
                    "label": 0
                },
                {
                    "sent": "On the right the spectral solution and in the middle we have an intermediate solution obtained by imposing Alpha equals 0.85 and this solution is very accurate and it's much denser than the game theoretic approach.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we optimize this?",
                    "label": 0
                },
                {
                    "sent": "We take a projected gradient approach.",
                    "label": 1
                },
                {
                    "sent": "So basically it's just a gradient ascent where we have a projection operator onto the feasible set.",
                    "label": 1
                },
                {
                    "sent": "So in this case onto the boundary of the elastic netball at Convexity Alpha.",
                    "label": 0
                },
                {
                    "sent": "And this is this plot shows a typical vector sequence generated by the optimization process and this vector sequence looks rather smooth, so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we ask is, given that these vector sequences rather smooth, maybe we could infer the general direction of convergence by just looking at previous at pastita rates.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And actually this can be done.",
                    "label": 0
                },
                {
                    "sent": "So let us see how in order to do this we look at the family of techniques called vector extrapolation and.",
                    "label": 0
                },
                {
                    "sent": "These this family of techniques arised in.",
                    "label": 0
                },
                {
                    "sent": "In in the field of.",
                    "label": 0
                },
                {
                    "sent": "Computational physics I believe, and they where they are used to compute solutions.",
                    "label": 0
                },
                {
                    "sent": "Approximate solutions to very large nonlinear systems.",
                    "label": 0
                },
                {
                    "sent": "So let us first look at the linear at the linear setting.",
                    "label": 0
                },
                {
                    "sent": "So consider a vector sequence generated by a linear process.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If this sequence converges, then it it it comes to convergence at the unique solution to a linear system.",
                    "label": 1
                },
                {
                    "sent": "So the point is that we do not assume that we have explicit knowledge of matrix A or vector B.",
                    "label": 0
                },
                {
                    "sent": "So we are only given the generating sequence, the generating process or the vector sequence.",
                    "label": 1
                },
                {
                    "sent": "And we want to estimate the limit vector.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this process often requires many iterations to come to convergence, and above all, deem dividual terms of the sequence could be very expensive to compute.",
                    "label": 1
                },
                {
                    "sent": "So if we look again, there are a matching scenario.",
                    "label": 0
                },
                {
                    "sent": "We have the projection step.",
                    "label": 0
                },
                {
                    "sent": "Onto the set of mapping constraints, which can be very expensive to compute, so that depends on what kind of mapping constraints we're going to impose.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we would like to do is to compute this limit vector using as few times as possible, let's say using K terms so.",
                    "label": 1
                },
                {
                    "sent": "It turns out, so I invite you to look at the papers of the paper for the technical details, but it turns out that we can obtain an estimate to the to this vector sequence to the limit of this vector sequence by just taking a linear combination of previous iterates.",
                    "label": 0
                },
                {
                    "sent": "So we have to solve for these coefficients in the linear combination, but it is a very can be done very efficiently.",
                    "label": 1
                },
                {
                    "sent": "By minimizing the least least square problem, which is the last formula in this slide?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Also, in in case the sequence is linearly generated, we have the guarantee that this estimation will give the global optimum.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From is that in our matching scenario, the sequence is not generated by linear process, so we have these nonlinear process.",
                    "label": 1
                },
                {
                    "sent": "Where the non linearity is brought in by the projection operator over the of the mapping constraints.",
                    "label": 0
                },
                {
                    "sent": "So how can we deal with this?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We resort to a procedure known as cycling.",
                    "label": 0
                },
                {
                    "sent": "So basically which is 2 parameters, an NK, and then we perform N + K + 1 standard projected gradient steps.",
                    "label": 1
                },
                {
                    "sent": "And we keep only the last K vectors.",
                    "label": 0
                },
                {
                    "sent": "Then we can apply.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vector extrapolation to these vectors.",
                    "label": 0
                },
                {
                    "sent": "So they're just came of them.",
                    "label": 0
                },
                {
                    "sent": "And we obtain an estimate for the for the limit vector.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course this estimate is not necessarily lying over the feasible set, so we have to re project this solution over the feasible set.",
                    "label": 0
                },
                {
                    "sent": "And we.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Check the objective value of the projector solution and if it attains a greater value than we we proceed and we repeat another cycle.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do that do this many times until we reach convergence.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cycling procedure does not give any guarantee, but in the physical community that there is.",
                    "label": 0
                },
                {
                    "sent": "They have observed very good convergence properties and this is what we observed in this case as well.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let us let us look at some examples.",
                    "label": 0
                },
                {
                    "sent": "So the first setting is rather classical.",
                    "label": 0
                },
                {
                    "sent": "Also not very difficult, it's just rigid matching of point clouds.",
                    "label": 1
                },
                {
                    "sent": "So we are given two point clouds.",
                    "label": 0
                },
                {
                    "sent": "Then we need to determine to establish point to point correspondences among these two point clouds and in order to do this we can just define a similarity function enforcing rigid isometries.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Since this is a not a very difficult problem, this allows us to perform some sensitivity analysis on the parameters of our method, so namely.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The length.",
                    "label": 0
                },
                {
                    "sent": "Of the of the site of the cycle cycling.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is surprising is that.",
                    "label": 0
                },
                {
                    "sent": "It turns out that for short periods we obtain much better results.",
                    "label": 0
                },
                {
                    "sent": "I mean the final.",
                    "label": 0
                },
                {
                    "sent": "Vector at convergence is always the same, but we have one order of magnitude improvement.",
                    "label": 0
                },
                {
                    "sent": "Over the same technique, with no extrapolation at all and over.",
                    "label": 0
                },
                {
                    "sent": "In longer periods for the cycling procedure, so this problem is not perhaps many much interesting because it's quite well understood.",
                    "label": 0
                },
                {
                    "sent": "So let's go to.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experiment #2 matching of deformable shapes so by deformable shapes we mean shape that undergo anything which is not a rigid deformation.",
                    "label": 1
                },
                {
                    "sent": "So we can have isometric deformations or different scales.",
                    "label": 0
                },
                {
                    "sent": "Partiality deformations, affine transformations and so on.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a very challenging problem and it is also a very active area of research in the computer vision and computer graphics communities.",
                    "label": 0
                },
                {
                    "sent": "So to do this to solve this problem with.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Take the same similarity function from the rigid case in which we replace the Euclidean metric by some intrinsic metric, so in.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we take diffusion magic over the two shapes over the two manifolds.",
                    "label": 0
                },
                {
                    "sent": "And surprisingly, also in this case we obtain one order of magnitude of improvement.",
                    "label": 1
                },
                {
                    "sent": "Over them helped him.",
                    "label": 0
                },
                {
                    "sent": "Organization performed with no extrapolation at all, and also in this case shorter periods give the best results.",
                    "label": 0
                },
                {
                    "sent": "So in this case we're just taking five iterates from the optimization process.",
                    "label": 0
                },
                {
                    "sent": "So basically the memory usage requirements are very, very low, almost nonexistent.",
                    "label": 0
                },
                {
                    "sent": "And using the elastic net formulation, we are also obtaining state of the art results on our standard datasets on Shrek 2010 for the isometry class.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a final example, here I'm showing some experiments with the multiple View stereo application.",
                    "label": 0
                },
                {
                    "sent": "So here I'm refering to the classical pipeline in which we have a feature matching step followed by a bundle adjustment step.",
                    "label": 0
                },
                {
                    "sent": "So an as you know, if the bundle adjustment step should not be given outliers in the data, otherwise the reconstruction will will will be screwed up basically.",
                    "label": 0
                },
                {
                    "sent": "So in order to meet these strong selectivity requirements.",
                    "label": 1
                },
                {
                    "sent": "We set Alpha equals 0.2 to into the elastic net, so this means that the matching will be very, very selective and very stable.",
                    "label": 1
                },
                {
                    "sent": "And for this class of problems we only observed more than moderate improvements, so.",
                    "label": 0
                },
                {
                    "sent": "Just 30% less iterations with respect to no extrapolation at all an.",
                    "label": 0
                },
                {
                    "sent": "In particular, using short cycles in a cycling procedure leads to premature convergence, so we had to use longer cycles like 1525 or 30.",
                    "label": 0
                },
                {
                    "sent": "An this is probably due to the presence of repeated structure and textures in the data, which make the whole setting more unstable with respect to the previous scenarios.",
                    "label": 1
                },
                {
                    "sent": "And this concludes my presentation.",
                    "label": 0
                },
                {
                    "sent": "So if you have any questions, I will be happy to answer.",
                    "label": 0
                }
            ]
        }
    }
}