{
    "id": "y3dds2qqvmglcwpcewhlzurf4uuyaxzg",
    "title": "Elastic and scalable processing of Linked Stream Data in the Cloud",
    "info": {
        "author": [
            "Danh Le Phuoc, TU Berlin"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2013_le_phuoc_data_cloud/",
    "segmentation": [
        [
            "Hi, I'm down at work from inside and I got way used to be used to be dairy and I present the work with my colleagues about enabling the scalable an elastic processing for link link stream data.",
            "So before going to the talk I just."
        ],
        [
            "Reveal a bit.",
            "Is link stream Processing is a new processing model that coming up in last five years?",
            "So basically processing link stream data is about correlating the data in stream presented in audio format.",
            "An static data that you have from Linda to claw.",
            "The query model is different from sparkle.",
            "One sort query is continuous query.",
            "That means you stress the query is stay there and whenever new data coming this system you got the new answers so."
        ],
        [
            "So.",
            "That's a bunch of work there, and there's some limitation on in terms of scalability at that motivate us to work toward Tulip that limitation the first thing is scalability issue of the current engine is they provide slow throughput in in the contact list in processing a row 100 triple SEC.",
            "If you go up to 101 thousand query concurrent query, STD is very modest.",
            "You say you do with the stream processing.",
            "The thing is they had a big problem to deal with the big data set where.",
            "That's that cause memory problem other things an the user you skin test they do with their outlook window with 101 thousand record or maybe a bit bigger than another thing is that cause that limitaciones.",
            "Processing on single computer had with disadvantage in terms of scalability because they help a limitation of hardware configuration.",
            "You know that the computer getting more more powerful by model Model Law, but it seems you still have about the total cost of ownership.",
            "If you want to go for the big configuration, for example, if.",
            "Who won the system can have 60 core with wanted to buy a program you had to pay much more than network.",
            "Let's system with comedy commodity PC with a computer with a Koran 60 gigabyte grams.",
            "So from that limitation."
        ],
        [
            "Out motivators to be the new requirement, so I borrow some.",
            "Falvey requirement for big data from McKinsey.",
            "So two requirement about for big data velocity and volume velocity we Emmitt to up to 100K triple SEC for our 10K query relative to the system and also the volume that mean you want to correlate some big.",
            "Windows data like you can look back the data for the new data with the older for maybe million right calls that you have to maintain any windows and the big data set like you want to correlate with Lingo data that 2 billion records triple something.",
            "So we had Elastic City requirement that.",
            "If you add up more computer than you can have fastest processing in faster percent, faster processing, the system can provide in here a the throughput accumulated throughput that system can handle.",
            "That means you can have the support horizon to scalability, and the system had to run on the paper.",
            "Use network system like Amazon EC2, Google Cloud and whatever.",
            "So from that."
        ],
        [
            "We come up with a parallel execution model that abstract enough to to be the system, so the input of the system that you post the query in SQL Query language.",
            "Continuous query language for link data stream and you build a logical query network and diploid in the abstract elastic execution architecture on the right.",
            "If you see here.",
            "It's it's really.",
            "General model that used most of the distributed system.",
            "You have the the global scheduler.",
            "You have coded ordination service Toccoa know coordinate the processing on other local processing.",
            "But the requirement here when you add up the system add up the computing power the system had to have to be able to continue processing an the performance had to be improved."
        ],
        [
            "So.",
            "With the system we have, we come up with some parallelizing approach that works.",
            "Quite well with the other batch system like MapReduce and Hadoop.",
            "So you have to parallel the sub operator of pipelines so when you come up with the processing network you provide the sub processing pipeline that you can parallel.",
            "Another thing is we see if you correlate with big data set like Villain Triple data set.",
            "You need a lot of IO before because you cannot host everything in the memory in some state.",
            "So you assume that you have a lot of computer node and allow the physical disks.",
            "You can parallel the iOS set to make it faster things with the processing on the network computer you will run into a problem that we call over hearing that you send a lot of data and we saturate the network and you will get the limit of the processing.",
            "So you have to correlate the data operation with the data.",
            "On the processing, other thing is, network bandwidth is doesn't come at free even you have optical network.",
            "So you have to find a way to have the compact processing state that you need the data structure to somehow to make the processing stay small enough to transfer the leg work to reduce the network overhead.",
            "Why is that?",
            "For example, with audio app data, providing the raw form you have like.",
            "One idea of note might be concerned around 100 bite, but in the triple store it you see people are represented at an integer, so one triple may be consumed 24 bike or something or even less.",
            "And with integer you can pack it in the bat and you use very efficient compressing algorithm to make it smaller.",
            "An we come up with some splitting and grouping schedule scheduling strategy to microsystem faster.",
            "I will come to the detail in Somerset.",
            "With that"
        ],
        [
            "So we build a system with architecture like this so we can buy some underlining parallel processing model like MapReduce with height base in the storm for stream processing, gender extreme processing.",
            "So what did we use from that to be our system?",
            "We need the storm to coordinate the pipe libel processing on continuous task when you head base to parallel the IO process, the Zookeeper is the common.",
            "Coordination.",
            "Submit that to this system used to code in ordinary the distribute tasks an we had a system that run on local node light on the right.",
            "Yeah, if you're familiar with heck based.",
            "Another thing you see, the data will be distributed on the node that we have to.",
            "So to meet the requirement that the data locality."
        ],
        [
            "I.",
            "Here is some component that we inherit from our standalone system cause SQL.",
            "So we build the system by reuse some physical operation and some scheduling optimizer and cat manager some things so I don't have time to go to detail on this thing you interested.",
            "You can go to our paper and to see the details just to see that we build something from the stand alone, but we try to distribute the part that.",
            "Then the my have the bottleneck in terms of processing."
        ],
        [
            "So.",
            "With that architecture we designed some incremental computing algorithm for stream processing.",
            "I also don't have time to present here.",
            "You can find detail in the paper, but just to do so, some operate to operate operation we do.",
            "We come up with the parallel incremental computing algorithm like some stateless operator is easy.",
            "We do dictionary and encoding.",
            "Operate on distributed data.",
            "Distributed architectures an we also come up with some stateful windowing operator like integration."
        ],
        [
            "Gation to give you an interview institution.",
            "In two issue intuition of how we design one algorithm that I mentioned that we had two phase splitting the work and grouping, they were the split link for example like you have multi wage on here you have any work for that come from an stream to the windows.",
            "So whenever the new data come into system an we model that as the symmetric parallel process.",
            "For example here you have one update for one.",
            "The first buffer they had to correlate with other buffer to generate the John, so we we come up the algorithm to make it can run in parallel an independent.",
            "For example, when you have the update look the same and it can be parallelized."
        ],
        [
            "So we had another step that we call grouping for example, like you had the data from 2 stream, but you have three query that jawn 2 Windows on this trip.",
            "So we see that if you run it separated in different processes that cause a lot of communication overhead.",
            "So we tried to group them in two one John operator an this thing there's some.",
            "Some we add another step called router so we do one drawn for overall this window we had the router to route weekday to go to query so the processing can be done in one note and you can avoid the communication.",
            "For example in here you had above for the data coming out like this you have to update.",
            "You do one step of finding the new data out from the Jaune and you route the data into destiny.",
            "Query like like this, so if you're interested I can show more detail, but just to give you intuition from housework so."
        ],
        [
            "So.",
            "We did the experiment on Amazon EC2 where.",
            "On the cluster row from two to three.",
            "Processing note and a call.",
            "We have some other administrative note to do coordination as well.",
            "For like we run some nimbus for deploying the Code Zookeeper coordinating service, an fault tolerant and heck they musta coordinator halfway processing node.",
            "We use the band marking system to call L spent to simulate the social network stream so that we can control the rate and data distribution.",
            "Another thing we do.",
            "Two experiment.",
            "The first experiment we.",
            "We want to analyze the scaling behavior of the the operator and we see how we inject the concurrent query effects."
        ],
        [
            "So for the scalable operator you see when we increase the node.",
            "An the note you see the system will scale in a Ray ban my that this log scale from Bo SS one the behavior of the system we want to analyze a the PIC network traffic to see if the network had the saturation situation that can microsystem hit the limit order so the the time for the consuming is 4 gigabites work by OK with Amazon infrastructure with 10 Gigabit."
        ],
        [
            "An we test with concurrent query from 10 to 10,000 queries.",
            "We still have the same scaling behavior with the real data set from simulation up the social stream.",
            "So in conclusion that we."
        ],
        [
            "We meet our requirement is we can support horizon to an elastic scalability that mean if you add up more hardware you can improve the performance linearly and the foot that we read that STL ten 100K for per second without NK query and we test mostly on Route 100 to 10,000,000 record window is really big.",
            "Windows caused data loss space optimization during the test.",
            "Anne.",
            "Are you interested in can talk all day about this?",
            "How to optimize an and other things that we find interesting.",
            "Adaptive load balancing is that you increase the stream rate.",
            "How the system can automatically scale and when you don't need it.",
            "How you remove the processing.",
            "That's all, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm down at work from inside and I got way used to be used to be dairy and I present the work with my colleagues about enabling the scalable an elastic processing for link link stream data.",
                    "label": 0
                },
                {
                    "sent": "So before going to the talk I just.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reveal a bit.",
                    "label": 0
                },
                {
                    "sent": "Is link stream Processing is a new processing model that coming up in last five years?",
                    "label": 0
                },
                {
                    "sent": "So basically processing link stream data is about correlating the data in stream presented in audio format.",
                    "label": 1
                },
                {
                    "sent": "An static data that you have from Linda to claw.",
                    "label": 0
                },
                {
                    "sent": "The query model is different from sparkle.",
                    "label": 0
                },
                {
                    "sent": "One sort query is continuous query.",
                    "label": 0
                },
                {
                    "sent": "That means you stress the query is stay there and whenever new data coming this system you got the new answers so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's a bunch of work there, and there's some limitation on in terms of scalability at that motivate us to work toward Tulip that limitation the first thing is scalability issue of the current engine is they provide slow throughput in in the contact list in processing a row 100 triple SEC.",
                    "label": 0
                },
                {
                    "sent": "If you go up to 101 thousand query concurrent query, STD is very modest.",
                    "label": 0
                },
                {
                    "sent": "You say you do with the stream processing.",
                    "label": 0
                },
                {
                    "sent": "The thing is they had a big problem to deal with the big data set where.",
                    "label": 0
                },
                {
                    "sent": "That's that cause memory problem other things an the user you skin test they do with their outlook window with 101 thousand record or maybe a bit bigger than another thing is that cause that limitaciones.",
                    "label": 0
                },
                {
                    "sent": "Processing on single computer had with disadvantage in terms of scalability because they help a limitation of hardware configuration.",
                    "label": 1
                },
                {
                    "sent": "You know that the computer getting more more powerful by model Model Law, but it seems you still have about the total cost of ownership.",
                    "label": 0
                },
                {
                    "sent": "If you want to go for the big configuration, for example, if.",
                    "label": 0
                },
                {
                    "sent": "Who won the system can have 60 core with wanted to buy a program you had to pay much more than network.",
                    "label": 0
                },
                {
                    "sent": "Let's system with comedy commodity PC with a computer with a Koran 60 gigabyte grams.",
                    "label": 0
                },
                {
                    "sent": "So from that limitation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out motivators to be the new requirement, so I borrow some.",
                    "label": 0
                },
                {
                    "sent": "Falvey requirement for big data from McKinsey.",
                    "label": 0
                },
                {
                    "sent": "So two requirement about for big data velocity and volume velocity we Emmitt to up to 100K triple SEC for our 10K query relative to the system and also the volume that mean you want to correlate some big.",
                    "label": 1
                },
                {
                    "sent": "Windows data like you can look back the data for the new data with the older for maybe million right calls that you have to maintain any windows and the big data set like you want to correlate with Lingo data that 2 billion records triple something.",
                    "label": 0
                },
                {
                    "sent": "So we had Elastic City requirement that.",
                    "label": 0
                },
                {
                    "sent": "If you add up more computer than you can have fastest processing in faster percent, faster processing, the system can provide in here a the throughput accumulated throughput that system can handle.",
                    "label": 0
                },
                {
                    "sent": "That means you can have the support horizon to scalability, and the system had to run on the paper.",
                    "label": 0
                },
                {
                    "sent": "Use network system like Amazon EC2, Google Cloud and whatever.",
                    "label": 0
                },
                {
                    "sent": "So from that.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We come up with a parallel execution model that abstract enough to to be the system, so the input of the system that you post the query in SQL Query language.",
                    "label": 0
                },
                {
                    "sent": "Continuous query language for link data stream and you build a logical query network and diploid in the abstract elastic execution architecture on the right.",
                    "label": 0
                },
                {
                    "sent": "If you see here.",
                    "label": 0
                },
                {
                    "sent": "It's it's really.",
                    "label": 0
                },
                {
                    "sent": "General model that used most of the distributed system.",
                    "label": 0
                },
                {
                    "sent": "You have the the global scheduler.",
                    "label": 0
                },
                {
                    "sent": "You have coded ordination service Toccoa know coordinate the processing on other local processing.",
                    "label": 0
                },
                {
                    "sent": "But the requirement here when you add up the system add up the computing power the system had to have to be able to continue processing an the performance had to be improved.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "With the system we have, we come up with some parallelizing approach that works.",
                    "label": 1
                },
                {
                    "sent": "Quite well with the other batch system like MapReduce and Hadoop.",
                    "label": 0
                },
                {
                    "sent": "So you have to parallel the sub operator of pipelines so when you come up with the processing network you provide the sub processing pipeline that you can parallel.",
                    "label": 0
                },
                {
                    "sent": "Another thing is we see if you correlate with big data set like Villain Triple data set.",
                    "label": 0
                },
                {
                    "sent": "You need a lot of IO before because you cannot host everything in the memory in some state.",
                    "label": 0
                },
                {
                    "sent": "So you assume that you have a lot of computer node and allow the physical disks.",
                    "label": 0
                },
                {
                    "sent": "You can parallel the iOS set to make it faster things with the processing on the network computer you will run into a problem that we call over hearing that you send a lot of data and we saturate the network and you will get the limit of the processing.",
                    "label": 0
                },
                {
                    "sent": "So you have to correlate the data operation with the data.",
                    "label": 0
                },
                {
                    "sent": "On the processing, other thing is, network bandwidth is doesn't come at free even you have optical network.",
                    "label": 0
                },
                {
                    "sent": "So you have to find a way to have the compact processing state that you need the data structure to somehow to make the processing stay small enough to transfer the leg work to reduce the network overhead.",
                    "label": 0
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "For example, with audio app data, providing the raw form you have like.",
                    "label": 0
                },
                {
                    "sent": "One idea of note might be concerned around 100 bite, but in the triple store it you see people are represented at an integer, so one triple may be consumed 24 bike or something or even less.",
                    "label": 0
                },
                {
                    "sent": "And with integer you can pack it in the bat and you use very efficient compressing algorithm to make it smaller.",
                    "label": 0
                },
                {
                    "sent": "An we come up with some splitting and grouping schedule scheduling strategy to microsystem faster.",
                    "label": 1
                },
                {
                    "sent": "I will come to the detail in Somerset.",
                    "label": 0
                },
                {
                    "sent": "With that",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we build a system with architecture like this so we can buy some underlining parallel processing model like MapReduce with height base in the storm for stream processing, gender extreme processing.",
                    "label": 0
                },
                {
                    "sent": "So what did we use from that to be our system?",
                    "label": 0
                },
                {
                    "sent": "We need the storm to coordinate the pipe libel processing on continuous task when you head base to parallel the IO process, the Zookeeper is the common.",
                    "label": 0
                },
                {
                    "sent": "Coordination.",
                    "label": 0
                },
                {
                    "sent": "Submit that to this system used to code in ordinary the distribute tasks an we had a system that run on local node light on the right.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you're familiar with heck based.",
                    "label": 0
                },
                {
                    "sent": "Another thing you see, the data will be distributed on the node that we have to.",
                    "label": 0
                },
                {
                    "sent": "So to meet the requirement that the data locality.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Here is some component that we inherit from our standalone system cause SQL.",
                    "label": 0
                },
                {
                    "sent": "So we build the system by reuse some physical operation and some scheduling optimizer and cat manager some things so I don't have time to go to detail on this thing you interested.",
                    "label": 0
                },
                {
                    "sent": "You can go to our paper and to see the details just to see that we build something from the stand alone, but we try to distribute the part that.",
                    "label": 0
                },
                {
                    "sent": "Then the my have the bottleneck in terms of processing.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "With that architecture we designed some incremental computing algorithm for stream processing.",
                    "label": 0
                },
                {
                    "sent": "I also don't have time to present here.",
                    "label": 0
                },
                {
                    "sent": "You can find detail in the paper, but just to do so, some operate to operate operation we do.",
                    "label": 0
                },
                {
                    "sent": "We come up with the parallel incremental computing algorithm like some stateless operator is easy.",
                    "label": 1
                },
                {
                    "sent": "We do dictionary and encoding.",
                    "label": 0
                },
                {
                    "sent": "Operate on distributed data.",
                    "label": 0
                },
                {
                    "sent": "Distributed architectures an we also come up with some stateful windowing operator like integration.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gation to give you an interview institution.",
                    "label": 0
                },
                {
                    "sent": "In two issue intuition of how we design one algorithm that I mentioned that we had two phase splitting the work and grouping, they were the split link for example like you have multi wage on here you have any work for that come from an stream to the windows.",
                    "label": 0
                },
                {
                    "sent": "So whenever the new data come into system an we model that as the symmetric parallel process.",
                    "label": 0
                },
                {
                    "sent": "For example here you have one update for one.",
                    "label": 0
                },
                {
                    "sent": "The first buffer they had to correlate with other buffer to generate the John, so we we come up the algorithm to make it can run in parallel an independent.",
                    "label": 0
                },
                {
                    "sent": "For example, when you have the update look the same and it can be parallelized.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we had another step that we call grouping for example, like you had the data from 2 stream, but you have three query that jawn 2 Windows on this trip.",
                    "label": 0
                },
                {
                    "sent": "So we see that if you run it separated in different processes that cause a lot of communication overhead.",
                    "label": 0
                },
                {
                    "sent": "So we tried to group them in two one John operator an this thing there's some.",
                    "label": 0
                },
                {
                    "sent": "Some we add another step called router so we do one drawn for overall this window we had the router to route weekday to go to query so the processing can be done in one note and you can avoid the communication.",
                    "label": 0
                },
                {
                    "sent": "For example in here you had above for the data coming out like this you have to update.",
                    "label": 0
                },
                {
                    "sent": "You do one step of finding the new data out from the Jaune and you route the data into destiny.",
                    "label": 0
                },
                {
                    "sent": "Query like like this, so if you're interested I can show more detail, but just to give you intuition from housework so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We did the experiment on Amazon EC2 where.",
                    "label": 1
                },
                {
                    "sent": "On the cluster row from two to three.",
                    "label": 0
                },
                {
                    "sent": "Processing note and a call.",
                    "label": 0
                },
                {
                    "sent": "We have some other administrative note to do coordination as well.",
                    "label": 0
                },
                {
                    "sent": "For like we run some nimbus for deploying the Code Zookeeper coordinating service, an fault tolerant and heck they musta coordinator halfway processing node.",
                    "label": 0
                },
                {
                    "sent": "We use the band marking system to call L spent to simulate the social network stream so that we can control the rate and data distribution.",
                    "label": 1
                },
                {
                    "sent": "Another thing we do.",
                    "label": 0
                },
                {
                    "sent": "Two experiment.",
                    "label": 0
                },
                {
                    "sent": "The first experiment we.",
                    "label": 0
                },
                {
                    "sent": "We want to analyze the scaling behavior of the the operator and we see how we inject the concurrent query effects.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the scalable operator you see when we increase the node.",
                    "label": 0
                },
                {
                    "sent": "An the note you see the system will scale in a Ray ban my that this log scale from Bo SS one the behavior of the system we want to analyze a the PIC network traffic to see if the network had the saturation situation that can microsystem hit the limit order so the the time for the consuming is 4 gigabites work by OK with Amazon infrastructure with 10 Gigabit.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An we test with concurrent query from 10 to 10,000 queries.",
                    "label": 0
                },
                {
                    "sent": "We still have the same scaling behavior with the real data set from simulation up the social stream.",
                    "label": 0
                },
                {
                    "sent": "So in conclusion that we.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We meet our requirement is we can support horizon to an elastic scalability that mean if you add up more hardware you can improve the performance linearly and the foot that we read that STL ten 100K for per second without NK query and we test mostly on Route 100 to 10,000,000 record window is really big.",
                    "label": 0
                },
                {
                    "sent": "Windows caused data loss space optimization during the test.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Are you interested in can talk all day about this?",
                    "label": 0
                },
                {
                    "sent": "How to optimize an and other things that we find interesting.",
                    "label": 0
                },
                {
                    "sent": "Adaptive load balancing is that you increase the stream rate.",
                    "label": 0
                },
                {
                    "sent": "How the system can automatically scale and when you don't need it.",
                    "label": 0
                },
                {
                    "sent": "How you remove the processing.",
                    "label": 0
                },
                {
                    "sent": "That's all, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}