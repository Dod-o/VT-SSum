{
    "id": "ympvtdqifmikqiqijpgalxkd2hd6nnzg",
    "title": "Learning right-to-left and left-to right iterative languages",
    "info": {
        "author": [
            "Jeffrey Heinz, University of Delaware"
        ],
        "published": "Oct. 9, 2008",
        "recorded": "September 2008",
        "category": [
            "Top->Computer Science->Programming Languages"
        ]
    },
    "url": "http://videolectures.net/icgi08_heinz_lrlil/",
    "segmentation": [
        [
            "The first speaker is Jeffrey Hines.",
            "Like to lift on the left to like.",
            "Thank you.",
            "Yeah, thank you for having me today.",
            "So what are the left to right and right to?"
        ],
        [
            "Little languages, well, they are previously unnoticed infinite subclasses of the regular language."
        ],
        [
            "Is that are identifiable in the limit from positive data?"
        ],
        [
            "Only an essentially the classes that you can get by merging final and start States and prefix and suffix trees of samples from.",
            "From"
        ],
        [
            "Superstar.",
            "They're interesting for, I think for a couple of reasons.",
            "One is that some of the algorithms that learn these language classes are very similar to the algorithms are presented by the dangling 92 paper.",
            "Basically, you just remove one line from the ER algorithm and you get learner for the left to right of languages."
        ],
        [
            "There are also interesting because there are step towards mapping out the space of language classes obtainable by Muggleton's 1990 general state merging algorithm, which he called.",
            "I am one and so I'll talk about what that is a little bit later in the talk and we'll see that the.",
            "Learners are just instantiations of this more general learning algorithm."
        ],
        [
            "Because we start to map out the space of language classes obtainable in this way, it begins to reveal the underlying algebraic structure that underlies the state, merging in the reverse operator, and so the exact properties that takes structure remains to be determined.",
            "But we can begin to see something that I think is pretty interesting."
        ],
        [
            "And finally, they're related to a linguistic hypothesis, which is that all phonotactic patterns are neighborhood distinct.",
            "The way this talk is going to be organized is I'm actually going to start in the bottom here because I think.",
            "Many of you are probably wondering what phonotactic patterns are, so I'd like to give you some examples of those, and I'll mention with this hypothesis is that I won't go into too much detail right away, and then what I'll do is with that in mind, will move to the left and right of languages and the relative languages, and I'll show you how you can learn them, how to learn relate to Angwin.",
            "I'll talk about them to general algorithm and I'll come down through here.",
            "So really, going for one 2, three in the course of this talk."
        ],
        [
            "So what are phonotactic patterns?",
            "These are, the rules are the constraints that govern word well formedness, so I think oftentimes people think of natural language patterns.",
            "They think of sentence well, formedness OK, but here we're looking at word well."
        ],
        [
            "What is wearable form and as well as an example of what are the possible words of English?",
            "Possible words of English include actual words of English words like slam and fist, but they also include logically possible strings that could be words of English.",
            "So so native English speakers could use a word like Blick or word like flump to name something if they wanted to name a new object or a new action, they could use words."
        ],
        [
            "Booker flump that's in contrast to logically possible strings that people could not use to name new things in English, so words like Schramm or fist, Nick, or flunk, these are all logically possible strings, but they're not possible words of English, so we can talk about word well, formedness over individual sounds in the same way about sentence, well, formedness over."
        ],
        [
            "Over words or morphemes?",
            "What are the specific sound patterns we have in the world's languages?",
            "There's been a great deal of studying this over the past 3040 years, so this is a very simple example.",
            "Comes from the language yellow menu cuts, which doesn't allow."
        ],
        [
            "Triple consonant clusters, so this set would include.",
            "We have very simple alphabet.",
            "A&B would include words like AB and AB and AB."
        ],
        [
            "Other, but it would exclude words that have three days in a row.",
            "OK, this is very simple pattern."
        ],
        [
            "No problem, there are more complicated funnel tactic pattern that's found in many worlds.",
            "Languages found in Navajo.",
            "This is an example of what I'll call symmetric."
        ],
        [
            "Harmony in this language.",
            "You, Navajo native Navajo speakers, could name new objects or new words are new actions with words like so sore Sotos or show short osh.",
            "This little.",
            "This symbol.",
            "Here is the sound as sure as in shoe in English.",
            "OK so these are all possible words of Navajo show show Tosh and so and so."
        ],
        [
            "Photos, but crucially, you can't have words like social or shoto's or so or so to shin Navajo.",
            "This is quite productive process in Navajo.",
            "Even morphological alternations.",
            "Obey it.",
            "So, for example, if you have a word, I'm just making this up, but if you had a word like Shiba Lucky, and there's a C prefix, I'm sorry.",
            "C suffix in Navajo.",
            "If you have Shiba Luchian you add the C suffix to it.",
            "You can't say she Baluchi C. You have to say she.",
            "Ballou kishi.",
            "OK, so it's very striking about it.",
            "Is that of course the distances between the sounds.",
            "These sounds are called sibilance.",
            "That's in the show sounds.",
            "They can be quite far apart unlike this case, so it's quite a different kind of pattern."
        ],
        [
            "And even more complicated pattern and the meaning of the word complex that I'm using when we make concrete in a moment, is found in asymmetric sibling harmony which is."
        ],
        [
            "Evil comes from Sarsi.",
            "Let's see here.",
            "This is like the Navajos sibling harmony pattern, in which we allow words like so since the totos and show show Tosh.",
            "But we exclude words like shows.",
            "I'm sorry we include words like show Sancho toes.",
            "These are OK because the show is proceeding.",
            "The S in the word.",
            "That's OK."
        ],
        [
            "Crucially, you can't have it the other way around.",
            "You can't have words in Farsi that are like so, so tosh and so Tosh, OK, and we'll see in a minute well why this makes it more complex in this pattern.",
            "We may ask how common these patterns are.",
            "They're not as rare as you might think.",
            "There's actually it's been documented over over 100 languages have patterns like like these in different language families and so on.",
            "So although we're not there might be unfamiliar to you, they're actually not so in common cross linguistically."
        ],
        [
            "So what's striking is we can try to place these patterns in the Chomsky hierarchy in the same way that we place a sentence with four minutes patterns."
        ],
        [
            "So it's well known, for example, that.",
            "If we look at syntax, it's been argued for a long time that we need at least context free kinds of.",
            "Computations over sentences.",
            "So that was kinda 50s, so receiver in the 80s.",
            "So we need to go beyond that to model kind of sensitive.",
            "Recently great Kobela has argued on the basis of an unbounded copying construction Yorba we have to go all the way up into this area, but what sort of striking is that when you try to place those language sound patterns that I showed you earlier?"
        ],
        [
            "They're all regular.",
            "They're all right here.",
            "I didn't mention the Pintupi stress pattern, but you can ask me about it later if you like, but the sibling harmony pattern, both symmetric and asymmetric or regular, as are the simple adjacency restrictions from consonant clusters.",
            "These are all regular patterns.",
            "So it's sort of a striking fact that as far as we know, in order to compute sentence well, formedness, that seems to require at least.",
            "Or at least context free computations over individual words.",
            "But if you want to compute word well formedness, you really just need regular computations over individual sounds."
        ],
        [
            "So we can try to place those sounds in the regular hierarchy, which was.",
            "This is sort of the main work there.",
            "Linguists finally took note of it.",
            "You know, only 36 years later."
        ],
        [
            "Here we've got it.",
            "What we've got is something like this.",
            "The adjacency restrictions, like the yellow Mineo cuts don't have triple consonant clusters.",
            "That's a locally testable in a strict sense.",
            "Locally testable metric sense.",
            "It's actually 3 LTSS, the symmetric comedy pattern of a hoe is actually locally testable.",
            "It's in this case is actually one testable.",
            "The asymmetric comedy patterns tend to follow our non counting.",
            "Crucially, the order matters.",
            "We need to know.",
            "Can they show proof CVS or can this procedure show so the non counting classes also?",
            "Call locally testable with order, also called Star free.",
            "I didn't mention stress patterns, but they tend to fall into two groups, bounded stress and unbounded stress.",
            "The bounded ones are locally testing the strict sense, but the.",
            "Unbounded ones are up here in the non counting region, so this is where sound patterns are in the sub regular hierarchy.",
            "And if you ask linguists.",
            "You know, we don't think that any regular language could be a possible sound pattern.",
            "Human sound pattern, so I think we're pretty interested in subclasses of the regular languages that include these patterns, and that are identifiable that are learnable in ways we can."
        ],
        [
            "Bus.",
            "So consequently, when if you've worked on learning subclasses with regular languages, in a sense, you are a theoretical phonologist because the properties that are.",
            "Learnable subclass of regular languages are really now candidates as universal properties of sound patterns.",
            "Because you're carving out regions in the subway in the subject of the regular languages.",
            "Do those regions match up with what link?"
        ],
        [
            "With snow with the language of the range of variation so we can take a look at those subclasses."
        ],
        [
            "We can ask.",
            "We can evaluate them by these sort of candidate properties."
        ],
        [
            "By asking to match up with the linguists knowledge."
        ],
        [
            "Range variation and also perhaps like linguistic evidence about the state."
        ],
        [
            "Infants knowledge, so there's been a lot of research showing that infants before the age of 1 year of life before they can talk have learned something about the sound patterns of their language, and so it's quite striking that they can do that before they're really talking.",
            "They're just listening, and yet they can figure out many of these patterns.",
            "OK, so.",
            "So in a sense, you're all theoretical phonologists, and I'm really happy to be speaking to a bunch of theoretical phonologie."
        ],
        [
            "About this"
        ],
        [
            "Hey.",
            "So one proposal that's been made is that it's been on the basis of typological evidence.",
            "It's been argued that for small neighborhoods, all of these patterns are neighborhood distinct.",
            "Now I'll define neighborhood distinctness later on in the talk, but I just want to make it clear what it is.",
            "There's two parameters, and so we're talking about 11 neighborhood distinctness.",
            "That's 11.",
            "Makes it sort of small neighborhood.",
            "The locally testable language in the the three locally testable language in strict sense.",
            "Are proper subset of the one neighborhood sickness as other presidents languages?",
            "I haven't defined those, but they tend to include these harmony patterns that cross cuts locally testable and counting just to get these guys there.",
            "Also one neighborhood distinct.",
            "And if you look at the attested stress patterns and there's a typology of over 400 languages that includes over 100 distinct stress patterns from over 70 different language families.",
            "All but two of those are also one neighborhood distinct and the two are stress patterns and there are a bit controversial, so I think it's.",
            "Not so bad.",
            "So we actually had good typological coverage with this hypothesis.",
            "So."
        ],
        [
            "That's all sort of background for this talk, and I'd like to actually move on to the left to right or right of languages themselves, which are the what.",
            "This talk is really about, but as a phonologist I wanted to share with you what we know about.",
            "Tactic patterns.",
            "In this way.",
            "So the left to right iterative languages are defined as the intersection of two classes of languages.",
            "So here I'm giving you the language theoretic character."
        ],
        [
            "Azatian so whenever there all those languages such that whenever U&V are belong to the language, then they share the same good tales."
        ],
        [
            "OK, that's one class of languages.",
            "The other one is all those languages you can get by picking two finite languages.",
            "So I'm using Elf in here to indicate the class of finite languages.",
            "You pick two finite languages, you concatenate them and you start the second one.",
            "This is the other class of languages whose intersection of these is.",
            "The left is how I define left, right.",
            "Of languages.",
            "I should note that neither of these classes identified woman from positive data on their own, so that in the first case that can be established with a simple limit point proof, and in this case it's easy to see that this class includes all finite languages and at least one infinite language, and so therefore by one of those early results.",
            "We can't do it in either case, but the intersection is."
        ],
        [
            "Going to be OK.",
            "So I'm going to give you.",
            "I want to give you a number theoretic characterization of the left right of languages, and so we'll start by doing it just by giving you another characterization of the first class of languages.",
            "This one it happens to be those languages recognizable finance data which are for deterministic can have at most."
        ],
        [
            "Final state, so this is just an example.",
            "This is a Ford Taurus otamatone has at most one final state.",
            "You can see that if it accepts two strings like B and ABC, then they have the same good tales and likewise for any two strings at this language accepts it shares the same good tales because it's for determining has one final state."
        ],
        [
            "So now I can give you the oh and I'll call these languages one final deterministic on the basis of this."
        ],
        [
            "Theoretic characterization.",
            "So the language is left to right iterative, so now here's the automata characterization of the lri class.",
            "It's left."
        ],
        [
            "It if if, and only if the tail Canonical except for the language is 1 final deterministic, so it has to look something like this."
        ],
        [
            "But crucially, if the language is infinite, then every loop has to pass through the final state, so that has the effect of cutting out the loops that I had here at one and three in.",
            "In here OK and you can see that.",
            "As a result, we have an L1 here, which is a finite language and we have an L2 here which then is allowed to loop around on itself.",
            "OK.",
            "The consequences for inference of having both of these properties."
        ],
        [
            "So if you're given two strings, avian ABCD, you can infer that ABCD star belongs to the language."
        ],
        [
            "Generally, if you're given you an UV in now, you can infer that UV star belongs to the language, and it's pretty clear how this is going to work."
        ],
        [
            "In a state merging perspective, if you know that both of you have a finite state representation of the strings, unv belonging to L as a prefix tree, then you can merge the final states."
        ],
        [
            "And you'll see that you get UV star.",
            "OK, so it's pretty."
        ],
        [
            "Straight forward, and so this is exactly the learner that will use will just take a sample.",
            "Will build a prefix tree to sample and then will partition the states of that tree according to all the final states in one block and the other blocks remain distinct.",
            "Have each their own state that each has their own non state and then we.",
            "We just basically merge final states in the preview."
        ],
        [
            "We will do one more step because when you merge function previously, you often get another term, top, so we will merge states.",
            "Eliminate forward determinism.",
            "I want to just point."
        ],
        [
            "Note that this last step is actually not required because it does not change the language of the machine.",
            "So once you've merged the final state of the previous treatments, to, but it does accept the target language proficiency sample and so on, which will see we have in a min."
        ],
        [
            "Let me just illustrate that for you, so you have a sample ABABCD ABCD.",
            "You build this prefix tree stage 145 and eight are gonna get merged, so they'll be over here and then.",
            "You'll see will get a loopy CD and will have another PCB."
        ],
        [
            "And so we get and then you can see this is nondeterministic.",
            "If you're at the state and CFB, you can go here or here.",
            "So now we can merge states two and six to eliminate the non determinism.",
            "Crucially, when we do that, we're not going to change the language of them."
        ],
        [
            "Gene at all.",
            "OK, likewise, this process continues recursively.",
            "So now we've created more nondeterminism.",
            "Here again, we can merge these states without changing the language of the machine."
        ],
        [
            "OK. And now you can see we have.",
            "A nice for deterministic machine.",
            "That's one final deterministic and all the loops pass through the final state.",
            "OK."
        ],
        [
            "So with striking about this algorithm, is that it only differs from XR and that states are not merged to remove reverse nondeterminism.",
            "So NSR, you wouldn't stop here.",
            "You'd say look if I'm at this state and the machine is running backwards.",
            "I've got reversed nondeterminism here.",
            "I can go take a be this way.",
            "In this way if I'm running the machine backwards.",
            "So NSR, you have to merge these states to eliminate that.",
            "But here we don't do that.",
            "So this algorithm does strictly less than XR.",
            "And so therefore it sufficient because ER was efficient."
        ],
        [
            "So the results we have for this are straightforward.",
            "Every language in Lri has a characteristic sample.",
            "Basically it's going to look like this.",
            "It's going to be the finite language, since you know it's sort of a composition of two finite languages, we just need a sample like this will be sufficient.",
            "You could get a smaller one, but this will be fine.",
            "Language you get when you merge it.",
            "When you take any sample and Sigma star Ann, you do this process.",
            "It's a smallest language and lri which includes that language and therefore it's small step from there to show that the learner identifies lri in the limit from positive data OK."
        ],
        [
            "It's incomparable with reversible languages."
        ],
        [
            "It's incomparable with other language classes that make up the circular hierarchy."
        ],
        [
            "I don't know if its function distinguished, but my hunch is there is a distinguishable function which can characterize this this class."
        ],
        [
            "The right to left iterative languages.",
            "These are the reverse of languages in Lri.",
            "OK, they are the reverse of the languages."
        ],
        [
            "Consequently, there in automata theoretic characterization."
        ],
        [
            "Will just be those that say the head Canonical acceptors have at most one final state.",
            "What's ahead, Canonical acceptor.",
            "It's the smallest reverse deterministic acceptor for regular language.",
            "OK, so often those acceptors are massively nondeterministic.",
            "They might have many start states, but here the head Canonical acceptor has to have at most one."
        ],
        [
            "Start state and all loops have to pass through the start state."
        ],
        [
            "OK. An RLI can be learned by a learner which simply merges start states in the suffix tree of the sample.",
            "So instead of building a prefix tree of the sample, you build a suffix tree, which again might be massively nondeterministic, but it is reverse deterministic, and then you can just merge the start states in there and you'll get the smallest right to left it of language that includes the sample that you were looking at.",
            "I don't have more to say about this.",
            "If you have questions RLI you can ask me in the Q&A.",
            "I have some more slides on it, but they're not.",
            "They're sort of in the appendices."
        ],
        [
            "OK.",
            "So with this.",
            "With that also in mind, I'd like to turn now to muggleton's 1990 General State merging algorithm.",
            "Here you begin with with a structure representation of the sample of prefix tree."
        ],
        [
            "We notice that you can use an equivalence relation to determine which states to merge, so Muggleton said."
        ],
        [
            "Look, you know we can really generalize state merging by talking about just some function F An.",
            "We say two seats are equivalent as long as the function Maps those two states of the same thing will decide to put in the."
        ],
        [
            "In block and.",
            "So basically we can generalize state merging by talking about this algorithm where we can choose how we want to specify this function F OK."
        ],
        [
            "Here we can actually generalize.",
            "Generalize that a little bit by thinking not just about prefix trees, but really any structure representation of the sample.",
            "Any finite state representation of the sample.",
            "OK, beta prefix tree, beta, suffix tree."
        ],
        [
            "And so on."
        ],
        [
            "So for."
        ],
        [
            "This is M we can."
        ],
        [
            "Consider prefix tree instead."
        ],
        [
            "History we might consider other choices."
        ],
        [
            "For choices."
        ],
        [
            "F We might decide to merge the same incoming paths of a state.",
            "Here I'm showing you the one path."
        ],
        [
            "We might decide to merge states according to the same outgoing."
        ],
        [
            "Hey pads.",
            "The final states that this is the function that I used basically for the left."
        ],
        [
            "Right, if language is the non final states, we may."
        ],
        [
            "Decide to merge nonfinal states.",
            "Start states if we have a prefix tree.",
            "I'm using the hex."
        ],
        [
            "Again, to indicate the start state, an non start and non start states you could do that too."
        ],
        [
            "OK, so here's what I think is known about.",
            "The class is obtained in this way and maybe some of you here.",
            "No more so that would be great.",
            "Actually, I'd like to know, but here in this column with the function.",
            "Here's the algorithm prefix merging prefix trees appointed that function or emerging suffix trees according to human relations by that function.",
            "Garcia all showed that if you order the same incoming paths, you get the Cape as you get the cables.",
            "One local strict sense.",
            "It's not hard to see that if you were to merge the same outgoing paths in a suffix tree, you get the same language class, not surprisingly.",
            "This class is closed under reversal, i.e.",
            "It's the reverse of itself.",
            "I don't know what we're going to get here.",
            "In fact, I'm not even sure if this General Ironwood algorithm will converge, but I think the slight modification."
        ],
        [
            "And of of it might.",
            "If we merge, say, start states in the prefix tree, was only one start state, so you don't do any merging and you can basically learn elfin in that way like same if you merge final states in the suffix trees.",
            "There's only one final state, so you'll get elfin.",
            "These are of course are closed and reversal again with each other."
        ],
        [
            "What I've shown you today is that if you merge final states in prefix trees, you get left to right iterative, which again is the reverse of right to left iterative."
        ],
        [
            "Likewise, you do not fall on start.",
            "This is just the language certification of the two state machines you get in these particular cases.",
            "And again here I don't know what the result is.",
            "I think how much time do I have?",
            "5 minutes OK great OK so.",
            "OK, so that's."
        ],
        [
            "I think what we know.",
            "So now I'd like to go back to the reach back to the beginning of the talk about how all funnel tactic patterns are neighborhood distinct.",
            "OK, I could define neighborhood distance for you now because it's basically a function of a state.",
            "We have a state Q.",
            "The neighborhood is sort of this complex function.",
            "It's a tuple, and there's many different parts to it, so it's the parameters are JNC here, so we have the incoming J pads.",
            "The outgoing K pads, then these indicator functions, which, which, if it's a final state this gets to one.",
            "If it's not a final status 0.",
            "And so on.",
            "If you had some large acceptor where these two states were in it, we would decide that these two states have the same neighborhood because they have the same incoming pads, the same outgoing paths of length, one at least for about 1 one neighborhood.",
            "They're both non final states in the both non stop."
        ],
        [
            "States so neighborhood think languages are those recognized by Fsas.",
            "Where distinct states have distinct neighborhoods.",
            "OK."
        ],
        [
            "But we don't have a language theoretic characterization of this class, and there's a lot about this class that we don't understand.",
            "We know a few things is not closed.",
            "An intersection is not closed under Union, and things like that, so we're seeing some nice properties, but we don't have a language theater creation.",
            "You know, I like to know more about."
        ],
        [
            "This class of languages, so the strategy is that if you understand the parts, you can understand the whole.",
            "So this neighborhood function is really a Boolean composition of simpler functions that I mentioned earlier.",
            "OK, and so.",
            "This is how the left to right of languages relate to."
        ],
        [
            "The neighborhood hypothesis that I mentioned at the beginning of the talk.",
            "So again, we can see that the got the incoming guy."
        ],
        [
            "To be the same, but also the outgoing guys have to be the same."
        ],
        [
            "Name?",
            "OK, and you have to both be a final state or not."
        ],
        [
            "State and just both the initial state or."
        ],
        [
            "Not initial state.",
            "So."
        ],
        [
            "So this function final Q, which helped us get the left right of languages is really part of the Boolean composition of this part here.",
            "Anne."
        ],
        [
            "Similarly, the start to function which helps with her eye, is part of the bowling composition of this guy."
        ],
        [
            "So when we go back and look at this summary of known classes obtainable in this fashion.",
            "There's really a lot of things we can look at here, so these are sort of maybe perhaps primitive functions, but we can start to make more complex functions by taking building compositions of them and it's and we can try to figure out what those language classes are obtainable in that kind of way, and so in this manner, I'm hoping to get a better understanding of what the neighborhood distinct languages are."
        ],
        [
            "OK, so in conclusion, I just want to say that left, right, and relative languages are infinite subclasses of the regular languages."
        ],
        [
            "That are obtainable by merging final and start states in prefix and suffix respectively."
        ],
        [
            "There are cousins of the reversible languages in the sense that there algorithmically very similar."
        ],
        [
            "Two XR they begin to help reveal the algebra underlying state merging algorithms and the reverse operator.",
            "We saw that certain cells in that table reverse language."
        ],
        [
            "Masses of each other.",
            "Also, we talked about fun tactic patterns.",
            "I argue that they're all regular, and so it's an open question.",
            "Which of their properties are sufficient or necessary for learning one?"
        ],
        [
            "Pozol is the neighborhood."
        ],
        [
            "Hypothesis, and I think the left or right of languages are small but necessary step towards a better understanding of that proposal.",
            "Like to stop there, thank you.",
            "I was wondering, are you familiar with them?",
            "Theory, yes.",
            "The regular riot affected supply through right so?",
            "Because there are some.",
            "There are some results.",
            "There is work by Gary Cater.",
            "For example.",
            "He wrote his son which algorithm.",
            "Obviously they have some extra extra assumptions about exactly how is normally takes place in numerous shifting news explains around.",
            "If any of you might be late, sure, yeah.",
            "I have a I have a few things to say about that.",
            "So if if let's see.",
            "Um?",
            "So optimality theory is a popular theory of phonology today, and it differs from what we're doing here in a really crucial way, and that is in optimality theory."
        ],
        [
            "It's assumed that there's a universal set of constraints operating constraints that humans have.",
            "An languages only vary in the way that they prioritize these constraints OK, and so consequently a language like yell menu cuts.",
            "For example, we might say that all languages have a constraint that says don't have triple consonant clusters, but that menu codes.",
            "That's a very important constraint in other languages, like English or in other languages, it's not such an important constraint, OK?",
            "But yet that constraint still exists for English speakers.",
            "So I mean this work, I think is very different from that perspective, because here we're trying to just to learn the constraints themselves were not assume that there are priority given and have to be ranked.",
            "We're assuming that we have that we can just discover them themselves.",
            "I think it's quite interesting that when you look at finite state models optimality theory, you can encode the various operating constraints as finite state machines and you can compose them in particular kinds of ways to.",
            "Basically, come up with the same sets that I have here, and so I think this is actually a. I guess a more straightforward representation of.",
            "Over the set things we're talking about, then, assuming that there's sort of this complex composition of many a priority given constraints.",
            "Here we just get it directly.",
            "Distance.",
            "Describing these slang terms of that they don't have.",
            "It's more reasonable to so learn that directed towards the negative constraints or defining.",
            "Concentrate on those languages.",
            "Yeah, that's a good question so.",
            "Yeah, that's one way of proceeding.",
            "So certainly in the final logical literature, these are talked about as negative constraints, which you can't have.",
            "And you're right.",
            "What I've done here, as I've said, well, let's look at the."
        ],
        [
            "That that you actually get and you know we can think about the set that we don't actually get.",
            "The reason I've done that is because you know, I tend, you know in for syntax it might be different where we might get, you know, implicit negative evidence in some kind of way, but given the acquisition evidence that says that kids seem to learn a lot about their sound patterns at very early ages, I think it is sort of the cases they get them from from primarily positive data, and so it was easier for me to think about learning these sets in this way.",
            "If you want to, we can take the compliment of the set that we get, and then you've got your.",
            "Your negative one, so you know.",
            "But I think you're right, that's the way you can proceed.",
            "It's not the way I preceded, but I'm not sure how you would be able to to learn this pattern.",
            "If you're not giving examples of it, you're just giving, so I guess you're asking about could you learn a pattern given?",
            "If you could learn this set given negative examples of that set.",
            "Around I don't know.",
            "Seems that everything is defined negatively and then you will go down to the other problems.",
            "Because of the formula.",
            "Yeah, but I think there will be differences, different predictions that are made say in stages of learning, which in principle can be tested by second linguistic experiments.",
            "But yeah, I hadn't thought about.",
            "I mean, this is the way that I preceded, but I think you're right you can't proceed this other way that you're talking about.",
            "Are you picking up?",
            "So essentially you're picking out certain words that have a certain structure.",
            "I mean, there are other words in these natural languages that that we do not have these properties, but are still in the language.",
            "I mean, sure.",
            "So there are Navajo words, for example that don't have Essentia in them at all, right?",
            "Those are those are part of this set by the way, right?",
            "S&T shirt that's right, that's right.",
            "They are included in this set.",
            "Reversal.",
            "And work.",
            "I think it's.",
            "In these particular kinds of sequences, so all words that don't have an estimate in it are because I could relevant.",
            "You just leave the map.",
            "I mean it, it looks like that if you get these example, yeah, if we add a word like bot in here, that's a possible word of Navajo.",
            "So my feeling was that only works.",
            "We say this in a show working there because it's.",
            "No, no yeah.",
            "I guess these examples might be misleading.",
            "I should include words like BA in here and in here.",
            "I should include, you know.",
            "Toto Toto's in here words that don't have the siblings in them are also possible though, which make up this set.",
            "The words that have these properties and they would not work.",
            "That's right, that's exactly right.",
            "That's exactly right.",
            "Great, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first speaker is Jeffrey Hines.",
                    "label": 0
                },
                {
                    "sent": "Like to lift on the left to like.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you for having me today.",
                    "label": 0
                },
                {
                    "sent": "So what are the left to right and right to?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Little languages, well, they are previously unnoticed infinite subclasses of the regular language.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that are identifiable in the limit from positive data?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only an essentially the classes that you can get by merging final and start States and prefix and suffix trees of samples from.",
                    "label": 0
                },
                {
                    "sent": "From",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Superstar.",
                    "label": 0
                },
                {
                    "sent": "They're interesting for, I think for a couple of reasons.",
                    "label": 0
                },
                {
                    "sent": "One is that some of the algorithms that learn these language classes are very similar to the algorithms are presented by the dangling 92 paper.",
                    "label": 1
                },
                {
                    "sent": "Basically, you just remove one line from the ER algorithm and you get learner for the left to right of languages.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are also interesting because there are step towards mapping out the space of language classes obtainable by Muggleton's 1990 general state merging algorithm, which he called.",
                    "label": 1
                },
                {
                    "sent": "I am one and so I'll talk about what that is a little bit later in the talk and we'll see that the.",
                    "label": 0
                },
                {
                    "sent": "Learners are just instantiations of this more general learning algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because we start to map out the space of language classes obtainable in this way, it begins to reveal the underlying algebraic structure that underlies the state, merging in the reverse operator, and so the exact properties that takes structure remains to be determined.",
                    "label": 0
                },
                {
                    "sent": "But we can begin to see something that I think is pretty interesting.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, they're related to a linguistic hypothesis, which is that all phonotactic patterns are neighborhood distinct.",
                    "label": 1
                },
                {
                    "sent": "The way this talk is going to be organized is I'm actually going to start in the bottom here because I think.",
                    "label": 0
                },
                {
                    "sent": "Many of you are probably wondering what phonotactic patterns are, so I'd like to give you some examples of those, and I'll mention with this hypothesis is that I won't go into too much detail right away, and then what I'll do is with that in mind, will move to the left and right of languages and the relative languages, and I'll show you how you can learn them, how to learn relate to Angwin.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about them to general algorithm and I'll come down through here.",
                    "label": 0
                },
                {
                    "sent": "So really, going for one 2, three in the course of this talk.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what are phonotactic patterns?",
                    "label": 0
                },
                {
                    "sent": "These are, the rules are the constraints that govern word well formedness, so I think oftentimes people think of natural language patterns.",
                    "label": 0
                },
                {
                    "sent": "They think of sentence well, formedness OK, but here we're looking at word well.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is wearable form and as well as an example of what are the possible words of English?",
                    "label": 1
                },
                {
                    "sent": "Possible words of English include actual words of English words like slam and fist, but they also include logically possible strings that could be words of English.",
                    "label": 0
                },
                {
                    "sent": "So so native English speakers could use a word like Blick or word like flump to name something if they wanted to name a new object or a new action, they could use words.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Booker flump that's in contrast to logically possible strings that people could not use to name new things in English, so words like Schramm or fist, Nick, or flunk, these are all logically possible strings, but they're not possible words of English, so we can talk about word well, formedness over individual sounds in the same way about sentence, well, formedness over.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Over words or morphemes?",
                    "label": 0
                },
                {
                    "sent": "What are the specific sound patterns we have in the world's languages?",
                    "label": 1
                },
                {
                    "sent": "There's been a great deal of studying this over the past 3040 years, so this is a very simple example.",
                    "label": 0
                },
                {
                    "sent": "Comes from the language yellow menu cuts, which doesn't allow.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Triple consonant clusters, so this set would include.",
                    "label": 1
                },
                {
                    "sent": "We have very simple alphabet.",
                    "label": 0
                },
                {
                    "sent": "A&B would include words like AB and AB and AB.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other, but it would exclude words that have three days in a row.",
                    "label": 0
                },
                {
                    "sent": "OK, this is very simple pattern.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No problem, there are more complicated funnel tactic pattern that's found in many worlds.",
                    "label": 0
                },
                {
                    "sent": "Languages found in Navajo.",
                    "label": 0
                },
                {
                    "sent": "This is an example of what I'll call symmetric.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Harmony in this language.",
                    "label": 0
                },
                {
                    "sent": "You, Navajo native Navajo speakers, could name new objects or new words are new actions with words like so sore Sotos or show short osh.",
                    "label": 0
                },
                {
                    "sent": "This little.",
                    "label": 0
                },
                {
                    "sent": "This symbol.",
                    "label": 0
                },
                {
                    "sent": "Here is the sound as sure as in shoe in English.",
                    "label": 0
                },
                {
                    "sent": "OK so these are all possible words of Navajo show show Tosh and so and so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Photos, but crucially, you can't have words like social or shoto's or so or so to shin Navajo.",
                    "label": 0
                },
                {
                    "sent": "This is quite productive process in Navajo.",
                    "label": 0
                },
                {
                    "sent": "Even morphological alternations.",
                    "label": 0
                },
                {
                    "sent": "Obey it.",
                    "label": 0
                },
                {
                    "sent": "So, for example, if you have a word, I'm just making this up, but if you had a word like Shiba Lucky, and there's a C prefix, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "C suffix in Navajo.",
                    "label": 0
                },
                {
                    "sent": "If you have Shiba Luchian you add the C suffix to it.",
                    "label": 0
                },
                {
                    "sent": "You can't say she Baluchi C. You have to say she.",
                    "label": 0
                },
                {
                    "sent": "Ballou kishi.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's very striking about it.",
                    "label": 0
                },
                {
                    "sent": "Is that of course the distances between the sounds.",
                    "label": 0
                },
                {
                    "sent": "These sounds are called sibilance.",
                    "label": 0
                },
                {
                    "sent": "That's in the show sounds.",
                    "label": 0
                },
                {
                    "sent": "They can be quite far apart unlike this case, so it's quite a different kind of pattern.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And even more complicated pattern and the meaning of the word complex that I'm using when we make concrete in a moment, is found in asymmetric sibling harmony which is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evil comes from Sarsi.",
                    "label": 0
                },
                {
                    "sent": "Let's see here.",
                    "label": 0
                },
                {
                    "sent": "This is like the Navajos sibling harmony pattern, in which we allow words like so since the totos and show show Tosh.",
                    "label": 0
                },
                {
                    "sent": "But we exclude words like shows.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry we include words like show Sancho toes.",
                    "label": 0
                },
                {
                    "sent": "These are OK because the show is proceeding.",
                    "label": 0
                },
                {
                    "sent": "The S in the word.",
                    "label": 0
                },
                {
                    "sent": "That's OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Crucially, you can't have it the other way around.",
                    "label": 0
                },
                {
                    "sent": "You can't have words in Farsi that are like so, so tosh and so Tosh, OK, and we'll see in a minute well why this makes it more complex in this pattern.",
                    "label": 0
                },
                {
                    "sent": "We may ask how common these patterns are.",
                    "label": 0
                },
                {
                    "sent": "They're not as rare as you might think.",
                    "label": 0
                },
                {
                    "sent": "There's actually it's been documented over over 100 languages have patterns like like these in different language families and so on.",
                    "label": 0
                },
                {
                    "sent": "So although we're not there might be unfamiliar to you, they're actually not so in common cross linguistically.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what's striking is we can try to place these patterns in the Chomsky hierarchy in the same way that we place a sentence with four minutes patterns.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's well known, for example, that.",
                    "label": 0
                },
                {
                    "sent": "If we look at syntax, it's been argued for a long time that we need at least context free kinds of.",
                    "label": 0
                },
                {
                    "sent": "Computations over sentences.",
                    "label": 0
                },
                {
                    "sent": "So that was kinda 50s, so receiver in the 80s.",
                    "label": 0
                },
                {
                    "sent": "So we need to go beyond that to model kind of sensitive.",
                    "label": 0
                },
                {
                    "sent": "Recently great Kobela has argued on the basis of an unbounded copying construction Yorba we have to go all the way up into this area, but what sort of striking is that when you try to place those language sound patterns that I showed you earlier?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They're all regular.",
                    "label": 0
                },
                {
                    "sent": "They're all right here.",
                    "label": 0
                },
                {
                    "sent": "I didn't mention the Pintupi stress pattern, but you can ask me about it later if you like, but the sibling harmony pattern, both symmetric and asymmetric or regular, as are the simple adjacency restrictions from consonant clusters.",
                    "label": 0
                },
                {
                    "sent": "These are all regular patterns.",
                    "label": 0
                },
                {
                    "sent": "So it's sort of a striking fact that as far as we know, in order to compute sentence well, formedness, that seems to require at least.",
                    "label": 0
                },
                {
                    "sent": "Or at least context free computations over individual words.",
                    "label": 0
                },
                {
                    "sent": "But if you want to compute word well formedness, you really just need regular computations over individual sounds.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can try to place those sounds in the regular hierarchy, which was.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the main work there.",
                    "label": 0
                },
                {
                    "sent": "Linguists finally took note of it.",
                    "label": 0
                },
                {
                    "sent": "You know, only 36 years later.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we've got it.",
                    "label": 0
                },
                {
                    "sent": "What we've got is something like this.",
                    "label": 0
                },
                {
                    "sent": "The adjacency restrictions, like the yellow Mineo cuts don't have triple consonant clusters.",
                    "label": 1
                },
                {
                    "sent": "That's a locally testable in a strict sense.",
                    "label": 1
                },
                {
                    "sent": "Locally testable metric sense.",
                    "label": 0
                },
                {
                    "sent": "It's actually 3 LTSS, the symmetric comedy pattern of a hoe is actually locally testable.",
                    "label": 0
                },
                {
                    "sent": "It's in this case is actually one testable.",
                    "label": 0
                },
                {
                    "sent": "The asymmetric comedy patterns tend to follow our non counting.",
                    "label": 0
                },
                {
                    "sent": "Crucially, the order matters.",
                    "label": 0
                },
                {
                    "sent": "We need to know.",
                    "label": 0
                },
                {
                    "sent": "Can they show proof CVS or can this procedure show so the non counting classes also?",
                    "label": 1
                },
                {
                    "sent": "Call locally testable with order, also called Star free.",
                    "label": 0
                },
                {
                    "sent": "I didn't mention stress patterns, but they tend to fall into two groups, bounded stress and unbounded stress.",
                    "label": 1
                },
                {
                    "sent": "The bounded ones are locally testing the strict sense, but the.",
                    "label": 0
                },
                {
                    "sent": "Unbounded ones are up here in the non counting region, so this is where sound patterns are in the sub regular hierarchy.",
                    "label": 0
                },
                {
                    "sent": "And if you ask linguists.",
                    "label": 0
                },
                {
                    "sent": "You know, we don't think that any regular language could be a possible sound pattern.",
                    "label": 0
                },
                {
                    "sent": "Human sound pattern, so I think we're pretty interested in subclasses of the regular languages that include these patterns, and that are identifiable that are learnable in ways we can.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bus.",
                    "label": 0
                },
                {
                    "sent": "So consequently, when if you've worked on learning subclasses with regular languages, in a sense, you are a theoretical phonologist because the properties that are.",
                    "label": 0
                },
                {
                    "sent": "Learnable subclass of regular languages are really now candidates as universal properties of sound patterns.",
                    "label": 1
                },
                {
                    "sent": "Because you're carving out regions in the subway in the subject of the regular languages.",
                    "label": 0
                },
                {
                    "sent": "Do those regions match up with what link?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With snow with the language of the range of variation so we can take a look at those subclasses.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can ask.",
                    "label": 0
                },
                {
                    "sent": "We can evaluate them by these sort of candidate properties.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By asking to match up with the linguists knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Range variation and also perhaps like linguistic evidence about the state.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Infants knowledge, so there's been a lot of research showing that infants before the age of 1 year of life before they can talk have learned something about the sound patterns of their language, and so it's quite striking that they can do that before they're really talking.",
                    "label": 0
                },
                {
                    "sent": "They're just listening, and yet they can figure out many of these patterns.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, you're all theoretical phonologists, and I'm really happy to be speaking to a bunch of theoretical phonologie.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About this",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hey.",
                    "label": 0
                },
                {
                    "sent": "So one proposal that's been made is that it's been on the basis of typological evidence.",
                    "label": 0
                },
                {
                    "sent": "It's been argued that for small neighborhoods, all of these patterns are neighborhood distinct.",
                    "label": 1
                },
                {
                    "sent": "Now I'll define neighborhood distinctness later on in the talk, but I just want to make it clear what it is.",
                    "label": 0
                },
                {
                    "sent": "There's two parameters, and so we're talking about 11 neighborhood distinctness.",
                    "label": 0
                },
                {
                    "sent": "That's 11.",
                    "label": 0
                },
                {
                    "sent": "Makes it sort of small neighborhood.",
                    "label": 1
                },
                {
                    "sent": "The locally testable language in the the three locally testable language in strict sense.",
                    "label": 0
                },
                {
                    "sent": "Are proper subset of the one neighborhood sickness as other presidents languages?",
                    "label": 0
                },
                {
                    "sent": "I haven't defined those, but they tend to include these harmony patterns that cross cuts locally testable and counting just to get these guys there.",
                    "label": 0
                },
                {
                    "sent": "Also one neighborhood distinct.",
                    "label": 1
                },
                {
                    "sent": "And if you look at the attested stress patterns and there's a typology of over 400 languages that includes over 100 distinct stress patterns from over 70 different language families.",
                    "label": 0
                },
                {
                    "sent": "All but two of those are also one neighborhood distinct and the two are stress patterns and there are a bit controversial, so I think it's.",
                    "label": 0
                },
                {
                    "sent": "Not so bad.",
                    "label": 0
                },
                {
                    "sent": "So we actually had good typological coverage with this hypothesis.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all sort of background for this talk, and I'd like to actually move on to the left to right or right of languages themselves, which are the what.",
                    "label": 0
                },
                {
                    "sent": "This talk is really about, but as a phonologist I wanted to share with you what we know about.",
                    "label": 0
                },
                {
                    "sent": "Tactic patterns.",
                    "label": 0
                },
                {
                    "sent": "In this way.",
                    "label": 0
                },
                {
                    "sent": "So the left to right iterative languages are defined as the intersection of two classes of languages.",
                    "label": 0
                },
                {
                    "sent": "So here I'm giving you the language theoretic character.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Azatian so whenever there all those languages such that whenever U&V are belong to the language, then they share the same good tales.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, that's one class of languages.",
                    "label": 0
                },
                {
                    "sent": "The other one is all those languages you can get by picking two finite languages.",
                    "label": 0
                },
                {
                    "sent": "So I'm using Elf in here to indicate the class of finite languages.",
                    "label": 0
                },
                {
                    "sent": "You pick two finite languages, you concatenate them and you start the second one.",
                    "label": 0
                },
                {
                    "sent": "This is the other class of languages whose intersection of these is.",
                    "label": 0
                },
                {
                    "sent": "The left is how I define left, right.",
                    "label": 0
                },
                {
                    "sent": "Of languages.",
                    "label": 0
                },
                {
                    "sent": "I should note that neither of these classes identified woman from positive data on their own, so that in the first case that can be established with a simple limit point proof, and in this case it's easy to see that this class includes all finite languages and at least one infinite language, and so therefore by one of those early results.",
                    "label": 0
                },
                {
                    "sent": "We can't do it in either case, but the intersection is.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to be OK.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to give you.",
                    "label": 0
                },
                {
                    "sent": "I want to give you a number theoretic characterization of the left right of languages, and so we'll start by doing it just by giving you another characterization of the first class of languages.",
                    "label": 0
                },
                {
                    "sent": "This one it happens to be those languages recognizable finance data which are for deterministic can have at most.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Final state, so this is just an example.",
                    "label": 0
                },
                {
                    "sent": "This is a Ford Taurus otamatone has at most one final state.",
                    "label": 1
                },
                {
                    "sent": "You can see that if it accepts two strings like B and ABC, then they have the same good tales and likewise for any two strings at this language accepts it shares the same good tales because it's for determining has one final state.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I can give you the oh and I'll call these languages one final deterministic on the basis of this.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Theoretic characterization.",
                    "label": 0
                },
                {
                    "sent": "So the language is left to right iterative, so now here's the automata characterization of the lri class.",
                    "label": 0
                },
                {
                    "sent": "It's left.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It if if, and only if the tail Canonical except for the language is 1 final deterministic, so it has to look something like this.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But crucially, if the language is infinite, then every loop has to pass through the final state, so that has the effect of cutting out the loops that I had here at one and three in.",
                    "label": 1
                },
                {
                    "sent": "In here OK and you can see that.",
                    "label": 0
                },
                {
                    "sent": "As a result, we have an L1 here, which is a finite language and we have an L2 here which then is allowed to loop around on itself.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The consequences for inference of having both of these properties.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you're given two strings, avian ABCD, you can infer that ABCD star belongs to the language.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generally, if you're given you an UV in now, you can infer that UV star belongs to the language, and it's pretty clear how this is going to work.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a state merging perspective, if you know that both of you have a finite state representation of the strings, unv belonging to L as a prefix tree, then you can merge the final states.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you'll see that you get UV star.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's pretty.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Straight forward, and so this is exactly the learner that will use will just take a sample.",
                    "label": 0
                },
                {
                    "sent": "Will build a prefix tree to sample and then will partition the states of that tree according to all the final states in one block and the other blocks remain distinct.",
                    "label": 0
                },
                {
                    "sent": "Have each their own state that each has their own non state and then we.",
                    "label": 0
                },
                {
                    "sent": "We just basically merge final states in the preview.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will do one more step because when you merge function previously, you often get another term, top, so we will merge states.",
                    "label": 0
                },
                {
                    "sent": "Eliminate forward determinism.",
                    "label": 0
                },
                {
                    "sent": "I want to just point.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Note that this last step is actually not required because it does not change the language of the machine.",
                    "label": 0
                },
                {
                    "sent": "So once you've merged the final state of the previous treatments, to, but it does accept the target language proficiency sample and so on, which will see we have in a min.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just illustrate that for you, so you have a sample ABABCD ABCD.",
                    "label": 0
                },
                {
                    "sent": "You build this prefix tree stage 145 and eight are gonna get merged, so they'll be over here and then.",
                    "label": 0
                },
                {
                    "sent": "You'll see will get a loopy CD and will have another PCB.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we get and then you can see this is nondeterministic.",
                    "label": 0
                },
                {
                    "sent": "If you're at the state and CFB, you can go here or here.",
                    "label": 0
                },
                {
                    "sent": "So now we can merge states two and six to eliminate the non determinism.",
                    "label": 0
                },
                {
                    "sent": "Crucially, when we do that, we're not going to change the language of them.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gene at all.",
                    "label": 0
                },
                {
                    "sent": "OK, likewise, this process continues recursively.",
                    "label": 0
                },
                {
                    "sent": "So now we've created more nondeterminism.",
                    "label": 0
                },
                {
                    "sent": "Here again, we can merge these states without changing the language of the machine.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. And now you can see we have.",
                    "label": 0
                },
                {
                    "sent": "A nice for deterministic machine.",
                    "label": 0
                },
                {
                    "sent": "That's one final deterministic and all the loops pass through the final state.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with striking about this algorithm, is that it only differs from XR and that states are not merged to remove reverse nondeterminism.",
                    "label": 0
                },
                {
                    "sent": "So NSR, you wouldn't stop here.",
                    "label": 0
                },
                {
                    "sent": "You'd say look if I'm at this state and the machine is running backwards.",
                    "label": 0
                },
                {
                    "sent": "I've got reversed nondeterminism here.",
                    "label": 0
                },
                {
                    "sent": "I can go take a be this way.",
                    "label": 0
                },
                {
                    "sent": "In this way if I'm running the machine backwards.",
                    "label": 0
                },
                {
                    "sent": "So NSR, you have to merge these states to eliminate that.",
                    "label": 0
                },
                {
                    "sent": "But here we don't do that.",
                    "label": 0
                },
                {
                    "sent": "So this algorithm does strictly less than XR.",
                    "label": 0
                },
                {
                    "sent": "And so therefore it sufficient because ER was efficient.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the results we have for this are straightforward.",
                    "label": 0
                },
                {
                    "sent": "Every language in Lri has a characteristic sample.",
                    "label": 0
                },
                {
                    "sent": "Basically it's going to look like this.",
                    "label": 0
                },
                {
                    "sent": "It's going to be the finite language, since you know it's sort of a composition of two finite languages, we just need a sample like this will be sufficient.",
                    "label": 0
                },
                {
                    "sent": "You could get a smaller one, but this will be fine.",
                    "label": 0
                },
                {
                    "sent": "Language you get when you merge it.",
                    "label": 0
                },
                {
                    "sent": "When you take any sample and Sigma star Ann, you do this process.",
                    "label": 0
                },
                {
                    "sent": "It's a smallest language and lri which includes that language and therefore it's small step from there to show that the learner identifies lri in the limit from positive data OK.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's incomparable with reversible languages.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's incomparable with other language classes that make up the circular hierarchy.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't know if its function distinguished, but my hunch is there is a distinguishable function which can characterize this this class.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The right to left iterative languages.",
                    "label": 0
                },
                {
                    "sent": "These are the reverse of languages in Lri.",
                    "label": 0
                },
                {
                    "sent": "OK, they are the reverse of the languages.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consequently, there in automata theoretic characterization.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Will just be those that say the head Canonical acceptors have at most one final state.",
                    "label": 1
                },
                {
                    "sent": "What's ahead, Canonical acceptor.",
                    "label": 0
                },
                {
                    "sent": "It's the smallest reverse deterministic acceptor for regular language.",
                    "label": 0
                },
                {
                    "sent": "OK, so often those acceptors are massively nondeterministic.",
                    "label": 1
                },
                {
                    "sent": "They might have many start states, but here the head Canonical acceptor has to have at most one.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start state and all loops have to pass through the start state.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. An RLI can be learned by a learner which simply merges start states in the suffix tree of the sample.",
                    "label": 1
                },
                {
                    "sent": "So instead of building a prefix tree of the sample, you build a suffix tree, which again might be massively nondeterministic, but it is reverse deterministic, and then you can just merge the start states in there and you'll get the smallest right to left it of language that includes the sample that you were looking at.",
                    "label": 0
                },
                {
                    "sent": "I don't have more to say about this.",
                    "label": 0
                },
                {
                    "sent": "If you have questions RLI you can ask me in the Q&A.",
                    "label": 0
                },
                {
                    "sent": "I have some more slides on it, but they're not.",
                    "label": 0
                },
                {
                    "sent": "They're sort of in the appendices.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So with this.",
                    "label": 0
                },
                {
                    "sent": "With that also in mind, I'd like to turn now to muggleton's 1990 General State merging algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here you begin with with a structure representation of the sample of prefix tree.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We notice that you can use an equivalence relation to determine which states to merge, so Muggleton said.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look, you know we can really generalize state merging by talking about just some function F An.",
                    "label": 0
                },
                {
                    "sent": "We say two seats are equivalent as long as the function Maps those two states of the same thing will decide to put in the.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In block and.",
                    "label": 0
                },
                {
                    "sent": "So basically we can generalize state merging by talking about this algorithm where we can choose how we want to specify this function F OK.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we can actually generalize.",
                    "label": 0
                },
                {
                    "sent": "Generalize that a little bit by thinking not just about prefix trees, but really any structure representation of the sample.",
                    "label": 0
                },
                {
                    "sent": "Any finite state representation of the sample.",
                    "label": 1
                },
                {
                    "sent": "OK, beta prefix tree, beta, suffix tree.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so on.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is M we can.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consider prefix tree instead.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "History we might consider other choices.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For choices.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "F We might decide to merge the same incoming paths of a state.",
                    "label": 0
                },
                {
                    "sent": "Here I'm showing you the one path.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We might decide to merge states according to the same outgoing.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey pads.",
                    "label": 0
                },
                {
                    "sent": "The final states that this is the function that I used basically for the left.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, if language is the non final states, we may.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Decide to merge nonfinal states.",
                    "label": 0
                },
                {
                    "sent": "Start states if we have a prefix tree.",
                    "label": 1
                },
                {
                    "sent": "I'm using the hex.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, to indicate the start state, an non start and non start states you could do that too.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's what I think is known about.",
                    "label": 0
                },
                {
                    "sent": "The class is obtained in this way and maybe some of you here.",
                    "label": 0
                },
                {
                    "sent": "No more so that would be great.",
                    "label": 0
                },
                {
                    "sent": "Actually, I'd like to know, but here in this column with the function.",
                    "label": 0
                },
                {
                    "sent": "Here's the algorithm prefix merging prefix trees appointed that function or emerging suffix trees according to human relations by that function.",
                    "label": 0
                },
                {
                    "sent": "Garcia all showed that if you order the same incoming paths, you get the Cape as you get the cables.",
                    "label": 1
                },
                {
                    "sent": "One local strict sense.",
                    "label": 0
                },
                {
                    "sent": "It's not hard to see that if you were to merge the same outgoing paths in a suffix tree, you get the same language class, not surprisingly.",
                    "label": 1
                },
                {
                    "sent": "This class is closed under reversal, i.e.",
                    "label": 0
                },
                {
                    "sent": "It's the reverse of itself.",
                    "label": 0
                },
                {
                    "sent": "I don't know what we're going to get here.",
                    "label": 0
                },
                {
                    "sent": "In fact, I'm not even sure if this General Ironwood algorithm will converge, but I think the slight modification.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of of it might.",
                    "label": 0
                },
                {
                    "sent": "If we merge, say, start states in the prefix tree, was only one start state, so you don't do any merging and you can basically learn elfin in that way like same if you merge final states in the suffix trees.",
                    "label": 0
                },
                {
                    "sent": "There's only one final state, so you'll get elfin.",
                    "label": 0
                },
                {
                    "sent": "These are of course are closed and reversal again with each other.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What I've shown you today is that if you merge final states in prefix trees, you get left to right iterative, which again is the reverse of right to left iterative.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Likewise, you do not fall on start.",
                    "label": 0
                },
                {
                    "sent": "This is just the language certification of the two state machines you get in these particular cases.",
                    "label": 0
                },
                {
                    "sent": "And again here I don't know what the result is.",
                    "label": 0
                },
                {
                    "sent": "I think how much time do I have?",
                    "label": 0
                },
                {
                    "sent": "5 minutes OK great OK so.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think what we know.",
                    "label": 0
                },
                {
                    "sent": "So now I'd like to go back to the reach back to the beginning of the talk about how all funnel tactic patterns are neighborhood distinct.",
                    "label": 0
                },
                {
                    "sent": "OK, I could define neighborhood distance for you now because it's basically a function of a state.",
                    "label": 0
                },
                {
                    "sent": "We have a state Q.",
                    "label": 0
                },
                {
                    "sent": "The neighborhood is sort of this complex function.",
                    "label": 0
                },
                {
                    "sent": "It's a tuple, and there's many different parts to it, so it's the parameters are JNC here, so we have the incoming J pads.",
                    "label": 0
                },
                {
                    "sent": "The outgoing K pads, then these indicator functions, which, which, if it's a final state this gets to one.",
                    "label": 0
                },
                {
                    "sent": "If it's not a final status 0.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "If you had some large acceptor where these two states were in it, we would decide that these two states have the same neighborhood because they have the same incoming pads, the same outgoing paths of length, one at least for about 1 one neighborhood.",
                    "label": 0
                },
                {
                    "sent": "They're both non final states in the both non stop.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "States so neighborhood think languages are those recognized by Fsas.",
                    "label": 1
                },
                {
                    "sent": "Where distinct states have distinct neighborhoods.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we don't have a language theoretic characterization of this class, and there's a lot about this class that we don't understand.",
                    "label": 0
                },
                {
                    "sent": "We know a few things is not closed.",
                    "label": 0
                },
                {
                    "sent": "An intersection is not closed under Union, and things like that, so we're seeing some nice properties, but we don't have a language theater creation.",
                    "label": 0
                },
                {
                    "sent": "You know, I like to know more about.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This class of languages, so the strategy is that if you understand the parts, you can understand the whole.",
                    "label": 0
                },
                {
                    "sent": "So this neighborhood function is really a Boolean composition of simpler functions that I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "OK, and so.",
                    "label": 0
                },
                {
                    "sent": "This is how the left to right of languages relate to.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The neighborhood hypothesis that I mentioned at the beginning of the talk.",
                    "label": 0
                },
                {
                    "sent": "So again, we can see that the got the incoming guy.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To be the same, but also the outgoing guys have to be the same.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Name?",
                    "label": 0
                },
                {
                    "sent": "OK, and you have to both be a final state or not.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "State and just both the initial state or.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not initial state.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this function final Q, which helped us get the left right of languages is really part of the Boolean composition of this part here.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similarly, the start to function which helps with her eye, is part of the bowling composition of this guy.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we go back and look at this summary of known classes obtainable in this fashion.",
                    "label": 0
                },
                {
                    "sent": "There's really a lot of things we can look at here, so these are sort of maybe perhaps primitive functions, but we can start to make more complex functions by taking building compositions of them and it's and we can try to figure out what those language classes are obtainable in that kind of way, and so in this manner, I'm hoping to get a better understanding of what the neighborhood distinct languages are.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in conclusion, I just want to say that left, right, and relative languages are infinite subclasses of the regular languages.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That are obtainable by merging final and start states in prefix and suffix respectively.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are cousins of the reversible languages in the sense that there algorithmically very similar.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two XR they begin to help reveal the algebra underlying state merging algorithms and the reverse operator.",
                    "label": 0
                },
                {
                    "sent": "We saw that certain cells in that table reverse language.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Masses of each other.",
                    "label": 0
                },
                {
                    "sent": "Also, we talked about fun tactic patterns.",
                    "label": 0
                },
                {
                    "sent": "I argue that they're all regular, and so it's an open question.",
                    "label": 1
                },
                {
                    "sent": "Which of their properties are sufficient or necessary for learning one?",
                    "label": 1
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pozol is the neighborhood.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hypothesis, and I think the left or right of languages are small but necessary step towards a better understanding of that proposal.",
                    "label": 1
                },
                {
                    "sent": "Like to stop there, thank you.",
                    "label": 0
                },
                {
                    "sent": "I was wondering, are you familiar with them?",
                    "label": 0
                },
                {
                    "sent": "Theory, yes.",
                    "label": 1
                },
                {
                    "sent": "The regular riot affected supply through right so?",
                    "label": 0
                },
                {
                    "sent": "Because there are some.",
                    "label": 0
                },
                {
                    "sent": "There are some results.",
                    "label": 0
                },
                {
                    "sent": "There is work by Gary Cater.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "He wrote his son which algorithm.",
                    "label": 0
                },
                {
                    "sent": "Obviously they have some extra extra assumptions about exactly how is normally takes place in numerous shifting news explains around.",
                    "label": 0
                },
                {
                    "sent": "If any of you might be late, sure, yeah.",
                    "label": 0
                },
                {
                    "sent": "I have a I have a few things to say about that.",
                    "label": 0
                },
                {
                    "sent": "So if if let's see.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So optimality theory is a popular theory of phonology today, and it differs from what we're doing here in a really crucial way, and that is in optimality theory.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's assumed that there's a universal set of constraints operating constraints that humans have.",
                    "label": 0
                },
                {
                    "sent": "An languages only vary in the way that they prioritize these constraints OK, and so consequently a language like yell menu cuts.",
                    "label": 0
                },
                {
                    "sent": "For example, we might say that all languages have a constraint that says don't have triple consonant clusters, but that menu codes.",
                    "label": 0
                },
                {
                    "sent": "That's a very important constraint in other languages, like English or in other languages, it's not such an important constraint, OK?",
                    "label": 0
                },
                {
                    "sent": "But yet that constraint still exists for English speakers.",
                    "label": 0
                },
                {
                    "sent": "So I mean this work, I think is very different from that perspective, because here we're trying to just to learn the constraints themselves were not assume that there are priority given and have to be ranked.",
                    "label": 0
                },
                {
                    "sent": "We're assuming that we have that we can just discover them themselves.",
                    "label": 0
                },
                {
                    "sent": "I think it's quite interesting that when you look at finite state models optimality theory, you can encode the various operating constraints as finite state machines and you can compose them in particular kinds of ways to.",
                    "label": 0
                },
                {
                    "sent": "Basically, come up with the same sets that I have here, and so I think this is actually a. I guess a more straightforward representation of.",
                    "label": 0
                },
                {
                    "sent": "Over the set things we're talking about, then, assuming that there's sort of this complex composition of many a priority given constraints.",
                    "label": 0
                },
                {
                    "sent": "Here we just get it directly.",
                    "label": 0
                },
                {
                    "sent": "Distance.",
                    "label": 0
                },
                {
                    "sent": "Describing these slang terms of that they don't have.",
                    "label": 0
                },
                {
                    "sent": "It's more reasonable to so learn that directed towards the negative constraints or defining.",
                    "label": 0
                },
                {
                    "sent": "Concentrate on those languages.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's a good question so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's one way of proceeding.",
                    "label": 0
                },
                {
                    "sent": "So certainly in the final logical literature, these are talked about as negative constraints, which you can't have.",
                    "label": 0
                },
                {
                    "sent": "And you're right.",
                    "label": 0
                },
                {
                    "sent": "What I've done here, as I've said, well, let's look at the.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That that you actually get and you know we can think about the set that we don't actually get.",
                    "label": 0
                },
                {
                    "sent": "The reason I've done that is because you know, I tend, you know in for syntax it might be different where we might get, you know, implicit negative evidence in some kind of way, but given the acquisition evidence that says that kids seem to learn a lot about their sound patterns at very early ages, I think it is sort of the cases they get them from from primarily positive data, and so it was easier for me to think about learning these sets in this way.",
                    "label": 0
                },
                {
                    "sent": "If you want to, we can take the compliment of the set that we get, and then you've got your.",
                    "label": 0
                },
                {
                    "sent": "Your negative one, so you know.",
                    "label": 0
                },
                {
                    "sent": "But I think you're right, that's the way you can proceed.",
                    "label": 0
                },
                {
                    "sent": "It's not the way I preceded, but I'm not sure how you would be able to to learn this pattern.",
                    "label": 0
                },
                {
                    "sent": "If you're not giving examples of it, you're just giving, so I guess you're asking about could you learn a pattern given?",
                    "label": 0
                },
                {
                    "sent": "If you could learn this set given negative examples of that set.",
                    "label": 0
                },
                {
                    "sent": "Around I don't know.",
                    "label": 0
                },
                {
                    "sent": "Seems that everything is defined negatively and then you will go down to the other problems.",
                    "label": 0
                },
                {
                    "sent": "Because of the formula.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but I think there will be differences, different predictions that are made say in stages of learning, which in principle can be tested by second linguistic experiments.",
                    "label": 0
                },
                {
                    "sent": "But yeah, I hadn't thought about.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is the way that I preceded, but I think you're right you can't proceed this other way that you're talking about.",
                    "label": 0
                },
                {
                    "sent": "Are you picking up?",
                    "label": 0
                },
                {
                    "sent": "So essentially you're picking out certain words that have a certain structure.",
                    "label": 0
                },
                {
                    "sent": "I mean, there are other words in these natural languages that that we do not have these properties, but are still in the language.",
                    "label": 0
                },
                {
                    "sent": "I mean, sure.",
                    "label": 0
                },
                {
                    "sent": "So there are Navajo words, for example that don't have Essentia in them at all, right?",
                    "label": 0
                },
                {
                    "sent": "Those are those are part of this set by the way, right?",
                    "label": 0
                },
                {
                    "sent": "S&T shirt that's right, that's right.",
                    "label": 0
                },
                {
                    "sent": "They are included in this set.",
                    "label": 0
                },
                {
                    "sent": "Reversal.",
                    "label": 0
                },
                {
                    "sent": "And work.",
                    "label": 0
                },
                {
                    "sent": "I think it's.",
                    "label": 0
                },
                {
                    "sent": "In these particular kinds of sequences, so all words that don't have an estimate in it are because I could relevant.",
                    "label": 0
                },
                {
                    "sent": "You just leave the map.",
                    "label": 0
                },
                {
                    "sent": "I mean it, it looks like that if you get these example, yeah, if we add a word like bot in here, that's a possible word of Navajo.",
                    "label": 0
                },
                {
                    "sent": "So my feeling was that only works.",
                    "label": 0
                },
                {
                    "sent": "We say this in a show working there because it's.",
                    "label": 0
                },
                {
                    "sent": "No, no yeah.",
                    "label": 0
                },
                {
                    "sent": "I guess these examples might be misleading.",
                    "label": 0
                },
                {
                    "sent": "I should include words like BA in here and in here.",
                    "label": 0
                },
                {
                    "sent": "I should include, you know.",
                    "label": 0
                },
                {
                    "sent": "Toto Toto's in here words that don't have the siblings in them are also possible though, which make up this set.",
                    "label": 0
                },
                {
                    "sent": "The words that have these properties and they would not work.",
                    "label": 0
                },
                {
                    "sent": "That's right, that's exactly right.",
                    "label": 0
                },
                {
                    "sent": "That's exactly right.",
                    "label": 0
                },
                {
                    "sent": "Great, thank you.",
                    "label": 0
                }
            ]
        }
    }
}