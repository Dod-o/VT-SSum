{
    "id": "es5lja6vi55z5zox3ky2tzmrxm74ibjy",
    "title": "Improved Algorithms for Linear Stochastic Bandits",
    "info": {
        "author": [
            "Yasin Abbasi-Yadkori, Department of Computing Science, University of Alberta"
        ],
        "published": "Sept. 6, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/nips2011_abbasi_yadkori_stochastic/",
    "segmentation": [
        [
            "I'm just nervous about Korean.",
            "This is a joint work with David Paul and Java Safari and this is a paper about."
        ],
        [
            "Stochastic linear bandits.",
            "So in the linear bandits, at each time step we are taking an action extend from the from a bounded decision set an.",
            "In response we receive a reward which is a linear function of the action plus some noise, and the goal is to maximize the total reward.",
            "This problem has applications in web advertisement routing problems and many others.",
            "We assume that the noise is conditionally sub Gaussian, which means it satisfies this inequality.",
            "But this is not a very restrictive assumption.",
            "For instance, Gaussian random variables satisfied that on any zero mean bounded random variable also satisfies this."
        ],
        [
            "The algorithm that we use is based on the optimism in the face of uncertainty principle.",
            "This principle is used by many people to design bandit algorithms, in particular Danny Hayastan, Kakadu have used principle to design an algorithm for the linear bandit problem and we are also building on their porch.",
            "The main novelty of this paper is the construction of tight confidence sets.",
            "So we use the Ridge regression to estimate the parameter vector and then with the confidence that on top of that the confidence that is shown by the inequality.",
            "That inequality, as you can see, it's ellipsoid centered on the Ridge regression estimate and the right hand side, which is the radius of the ellipsoid, is a function of the 2nd order moment matrix underlying data.",
            "So this is so we have a data driven confidence set.",
            "Now having a smaller confidence.",
            "That means that the algorithm is going to be going to exploit Moran so it's regrets going to be smaller if you compare the regret of our algorithm with the results of Daniel.",
            "Well, then you observe that in the worst case removal logarithmic term and in the problem dependent case we can remove logarithmic terms and also improve in dimensionality.",
            "But notice that this results are like upper bounds, so they might not reveal the true relationship between these algorithms.",
            "Now we did some."
        ],
        [
            "Experiments to compare the regret bounds.",
            "The blue curve is the algorithm that uses the old confidence set from Daniel Thorn and Black Curve, which might be a bit hard to see is the algorithm that uses the new confidence set and you can see that there is a huge difference in terms of regret, so lower is better now than you also.",
            "The attribute this improvement to the fact that the confidence it is data driven and the constants are also much smaller and we also consider the another version of the algorithm that changes the action exponentially to save to save computation, and its regular is shown by the red curve and you can see that the regret is almost the same as the regret of the original algorithm, so we don't lose much.",
            "The bottom figure is just.",
            "The same result showing different view.",
            "So thank you very much and please see our post."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm just nervous about Korean.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with David Paul and Java Safari and this is a paper about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stochastic linear bandits.",
                    "label": 0
                },
                {
                    "sent": "So in the linear bandits, at each time step we are taking an action extend from the from a bounded decision set an.",
                    "label": 1
                },
                {
                    "sent": "In response we receive a reward which is a linear function of the action plus some noise, and the goal is to maximize the total reward.",
                    "label": 1
                },
                {
                    "sent": "This problem has applications in web advertisement routing problems and many others.",
                    "label": 0
                },
                {
                    "sent": "We assume that the noise is conditionally sub Gaussian, which means it satisfies this inequality.",
                    "label": 0
                },
                {
                    "sent": "But this is not a very restrictive assumption.",
                    "label": 0
                },
                {
                    "sent": "For instance, Gaussian random variables satisfied that on any zero mean bounded random variable also satisfies this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The algorithm that we use is based on the optimism in the face of uncertainty principle.",
                    "label": 1
                },
                {
                    "sent": "This principle is used by many people to design bandit algorithms, in particular Danny Hayastan, Kakadu have used principle to design an algorithm for the linear bandit problem and we are also building on their porch.",
                    "label": 0
                },
                {
                    "sent": "The main novelty of this paper is the construction of tight confidence sets.",
                    "label": 0
                },
                {
                    "sent": "So we use the Ridge regression to estimate the parameter vector and then with the confidence that on top of that the confidence that is shown by the inequality.",
                    "label": 0
                },
                {
                    "sent": "That inequality, as you can see, it's ellipsoid centered on the Ridge regression estimate and the right hand side, which is the radius of the ellipsoid, is a function of the 2nd order moment matrix underlying data.",
                    "label": 1
                },
                {
                    "sent": "So this is so we have a data driven confidence set.",
                    "label": 0
                },
                {
                    "sent": "Now having a smaller confidence.",
                    "label": 0
                },
                {
                    "sent": "That means that the algorithm is going to be going to exploit Moran so it's regrets going to be smaller if you compare the regret of our algorithm with the results of Daniel.",
                    "label": 0
                },
                {
                    "sent": "Well, then you observe that in the worst case removal logarithmic term and in the problem dependent case we can remove logarithmic terms and also improve in dimensionality.",
                    "label": 0
                },
                {
                    "sent": "But notice that this results are like upper bounds, so they might not reveal the true relationship between these algorithms.",
                    "label": 0
                },
                {
                    "sent": "Now we did some.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiments to compare the regret bounds.",
                    "label": 0
                },
                {
                    "sent": "The blue curve is the algorithm that uses the old confidence set from Daniel Thorn and Black Curve, which might be a bit hard to see is the algorithm that uses the new confidence set and you can see that there is a huge difference in terms of regret, so lower is better now than you also.",
                    "label": 0
                },
                {
                    "sent": "The attribute this improvement to the fact that the confidence it is data driven and the constants are also much smaller and we also consider the another version of the algorithm that changes the action exponentially to save to save computation, and its regular is shown by the red curve and you can see that the regret is almost the same as the regret of the original algorithm, so we don't lose much.",
                    "label": 0
                },
                {
                    "sent": "The bottom figure is just.",
                    "label": 0
                },
                {
                    "sent": "The same result showing different view.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much and please see our post.",
                    "label": 0
                }
            ]
        }
    }
}