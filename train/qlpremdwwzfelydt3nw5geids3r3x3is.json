{
    "id": "qlpremdwwzfelydt3nw5geids3r3x3is",
    "title": "On the relation between Bayesian inference and certain solvable problems of stochastic control",
    "info": {
        "author": [
            "Manfred Opper, Department of Artificial Intelligence, TU Berlin"
        ],
        "published": "Oct. 9, 2008",
        "recorded": "September 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/bark08_opper_otrbbi/",
    "segmentation": [
        [
            "So probably I might not use the full time of 45 minutes and actually it's going to be a bit of a technical talks about why not.",
            "So you're all experts in in Bayesian inference, and so this is actually not about my own work, it's more about work of other people like bed like bed, cap and and and told her off.",
            "So I found that were quite interesting and I tried to understand it a little bit better, and that's sort of my personal interpretation of what they did.",
            "Is as inference problem, so probably.",
            "There are a lot of papers around by them and maybe they already have understood that, but this sort of my my own, my own approach and I want to share this with you and I found it simply some beautiful thing this."
        ],
        [
            "That they did so.",
            "This is about, you know, their approach is about analyzing a control problem.",
            "Specific types of stochastic control problems and they are solved.",
            "As you might remember from an AI course using belmans equality, you can solve these control problems, at least in principle.",
            "And then they find out going through the mathematics well that looks really like an inference problem for well in some cases like hidden Markov model or if in continuous time for stochastic differential equations.",
            "And that's what brought me into this problem, so that's their way of looking at it, and you really, really go to the mathematics and you're surprised while this comes out.",
            "And so my way is just if I come from an inference problem and look at it in a specific way and apply the variational method that we all know for approximate inference.",
            "Now the Kullback Leiber, variational approach for computing a posterior.",
            "Then you end up with a control problem.",
            "It's precisely the ones that that bed and.",
            "Manuel told her if we're studying so this is.",
            "This is the whole story.",
            "And then yeah, I don't know.",
            "I mean, they did a lot of things with this with this formulation.",
            "For me there were a few things that I could learn from them, and I also want to tell you those.",
            "And maybe there are some possible extensions and maybe you have some ideas too, so it's not really my work.",
            "I haven't done much on this, just a bit of understanding.",
            "So what's this all about?",
            "Let's start with something as simple discrete times, not just stochastic differential equations.",
            "Discrete time control problem.",
            "You could also call them Markov decision problems and."
        ],
        [
            "So let's assume we have a Markov process and we have well discrete times discrete states.",
            "For simplicity, we have transition probabilities going from states X into X prime, and we have some little control.",
            "That means we can change things and then these transition probabilities will also change and we want to change them in such a way that total expected cost over.",
            "A path over some finite horizon T is a minimum, so we have some loss function here that depends on the state that we are in.",
            "It depends on the control variable that we have at time T we will start the whole process at available at a position exit of State X and then we sum up all these costs and average them over the controlled transition probability.",
            "And now this thing should be minimized with respect.",
            "To that control so that each state and each time we have to do something in order to keep this whole sum the minimum.",
            "So technically this is solved by defining a value of a state X at time T, which is sort of the cost that will come up in the future.",
            "Sort of the expected cost for all times greater than T. And again we sum up up to the finite horizon T and then we all learn probably in.",
            "Maybe in an AI course that for this value function we can find a simple equation which is the so-called Bellman equation that says simply, well, the cost that we have at time T. We can write them at as the cost that we have now at the stage X plus the expected costs that we will have in the future.",
            "So it's relate.",
            "It relates this value of a state to the to the value at future time.",
            "So this is a so called belmans equality.",
            "And so yeah, we do this minimization here.",
            "So this is the standard approach for solving.",
            "These type of things."
        ],
        [
            "Right, so you can go to continuous times.",
            "That was actually the work for started by about Cup and so now we go away from discrete times into continuous times continuous states.",
            "So you think, well, you transition probabilities, they come from a dynamical system, so you have a continuous state X which is changed by some deterministic process.",
            "So the change of X is proportional to the infinitesimally change.",
            "In time and there's some noise added, so essentially those those transition probabilities are little Gaussians, so you had a little bit of Gaussian noise, so the conditional probabilities will be Gaussians.",
            "So the first part is usually called the drift of the process, and the second part is called the diffusion, and to introduce control here.",
            "So you have a kind of uncontrolled part which is sort of a prior drift and you have.",
            "A little control that you have to choose so you can really steer this whole thing, so this is what you want.",
            "You can control this part.",
            "You can't control the diffusion in this formulation, so this is the type of transitions that we consider for continuous time, and so if you want to get have a sort of practical meaning of this stochastic differential equation, you can again discretize it in time and then you say, well, this change of state is something that is proportional.",
            "Delta T + a little bit of Gaussian noise, which scales with the square root of Delta T and how general is these type of formulation?",
            "I think if you want to have continuous path continuous states continuous path, that's probably the only thing you can do.",
            "If you want to have a Markov process.",
            "So in that sense it's a fairly general thing.",
            "If you don't want to have jumps and so this is a nice description.",
            "Of a mark of world."
        ],
        [
            "So for this type of thing you can also write down a control problem.",
            "Now all the sums are replaced by integrals, so you start with T = 0 up to T. You integrate again.",
            "You have a loss function and you start at X 0 = X and U average over the controlled.",
            "Probabilities again you define the values of a state.",
            "X is sort of all the costs that you have in the future from time T up to the horizon capital T. So that's precisely the same type of thing.",
            "I don't give a derivation of that that suggested a technical thing, so you will have another type of Bellman equation relating costs at time T. An future costs, and it turns out that you get.",
            "A temporal change of that value function, and you play a bit with all these.",
            "Stochastic analysis thing and you just end up with a partial differential equation, so there should be you know, summation over overstate steps.",
            "You can go into should be replaced by sort of differential type of things.",
            "So one can do that.",
            "Yes.",
            "Fun.",
            "Yes, yes.",
            "It's here.",
            "It's in the loss function, so I haven't really said what what this loss will be.",
            "I'll come to the loss in a second.",
            "Oh, right.",
            "I know, yes, yes this is the uncontrolled sort of it appears.",
            "Yeah, it shouldn't come up here, I think.",
            "I think it's correct.",
            "I have to see that.",
            "OK, maybe maybe I was wrong.",
            "I'm a cop."
        ],
        [
            "In a wrong way.",
            "So what we do is now we we specialize to a very specific type of loss function, so which doesn't seem to be unreasonable.",
            "So you say, OK, there is a loss which only depends on the path.",
            "There's no control loss in the first part is the controller, so you say, well, OK, this you shouldn't make you controls too large because you burn too much energy if you just try to control the system strongly.",
            "So there will be a quadratic form in in the control, so that's the that's the idea.",
            "I think it seems also fairly general to choose to choose such type of.",
            "Loss function Now there's a very funny observation that that bad Captain had.",
            "So first of all, you know just you use this type of loss and go back into the Hamilton Jacobi Bellman equation.",
            "So you put this back."
        ],
        [
            "Into this equation and.",
            "You're absolutely right, there should be in.",
            "There should be a U.",
            "So you put this back in, solve for for you locally, and then you end up."
        ],
        [
            "With.",
            "And nonlinear PDE.",
            "So this is as far as you can get.",
            "You're absolutely right.",
            "OK, so so this is sort of the state of the art.",
            "Normally this is what you have to live with.",
            "You have to solve such an ugly equation and it's not even linear.",
            "It has all these nonlinear terms in it and so well that makes life complicated and now."
        ],
        [
            "It's back up and says OK.",
            "If we have a specific choice for the matrix R, remember the Matrix R's."
        ],
        [
            "Is defined in the in these losses here.",
            "This is the matrix that that tells you how to weight these."
        ],
        [
            "Control losses and make them inversely proportional.",
            "I mean, let's forget about proportionality.",
            "Make them just the inverse of the diffusion matrix.",
            "And then you do another thing.",
            "You make a variable transformation from loss from these values into log space and define in you variable and then just plug it in and calculate and calculate and calculate and all these nonlinearities disappear.",
            "Wow.",
            "If you see such a thing, you're getting really impressed and saying something is happening here.",
            "And yes, as I said, funny enough, you end up with a linear equation and linear equations are much nicer usually compared to non linear ones.",
            "And if you look at this and then you realize this operator is the so called bok bok backward operator for kind of a backward equation for for the underlying diffusion.",
            "And then if you know a little bit about these diffusion processes, you find out that this is actually.",
            "That solution to this equation can be represented as a path integral.",
            "Simply meaning path integral means, say you sum up, you take the expectation overall uncontrolled path, so the control is gone here and you get all these path costs in the exponent and so this is actually the solution to it.",
            "So you have a stochastic representation of this problem as an expectation over uncontrolled.",
            "Uncontrolled diffusions over something.",
            "Yeah, so this looks really like you know a sum over all possible paths, so that looks more or less like you know here we've got sort of a prior.",
            "You have an average and here is something like you might call a likelihood term and this is a partition function.",
            "That's why I called it said so its normalizer of some posterior probability.",
            "And what you can do is now you can apply all kinds of inference.",
            "Bayesian inference tricks, approximate inference tricks, Monte Carlo sampling.",
            "A mean field type of things so so bad has really no applied this to to agent planning type of problems where this is.",
            "Where you actually include some or even even some end costs.",
            "I mean, I haven't put in sort of there's costs at the end of the time horizon, so if you have such an object, you can say, oh, this is now easy and you have a whole bunch of techniques to deal with that, and if you have this function, then you can compute immediately your control."
        ],
        [
            "All.",
            "I I was mentioning that as a century, the gradient of that value.",
            "So this partition function gives the value.",
            "The value gives the control and everything is solved and so it's beautiful, I said.",
            "Wow, so you do a mathematical trick and outcomes something very simple.",
            "And yeah I didn't understand it for quite awhile."
        ],
        [
            "Time."
        ],
        [
            "And.",
            "There's a similar development, a parallel development from told her off, and it was actually a NIPS paper.",
            "I hopefully copied the right year, probably NIPS 2006.",
            "And so he was using a discrete time formulation and not the diffusion process, but the Markov decision problems.",
            "So he was coming up with a funny type of loss and it turns out that this loss is very much related to the previous one in continuous time and it actually teaches at a bit more where this simplification actually comes from.",
            "So you have losses that are actually depending only on the state, and there's a part of the loss that is the control loss.",
            "So this controllers looks like a cool book, Libra Divergent.",
            "It says you have some prior jump, some uncontrolled jump probabilities P, and the controlled ones.",
            "They they they lead to a loss, which is the kullback leibner between the controlled transition probability in the uncontrolled one.",
            "So that means you pay you pay as you know if you deviate from your prior probabilities, you pay with the cool math library loss.",
            "That's it.",
            "And then if you go through the mathematics again and again and again, I want to.",
            "Did you board with that and you make a similar type of logarithmic transformation, and then you end up with a with a linear equation again and filter or solves a couple of nice Markov decision processes for these type of losses is using linear methods.",
            "I mean here we have discrete time discrete state, everything is matrices, so you can compute.",
            "Yes, you have linear algebra and everything can be done, so it seems like there is a couple of control problems for which you can do nicely in your mathematics.",
            "Inference, types of mathematics, and that's what it is."
        ],
        [
            "So just to give the relation to the continuous case I was discussing before when we have a a diffusion problem, a stochastic differential equation and look at the transition probability for short times from going from a state X to X prime over a time interval of Delta T. Then it's a locally a Gaussian because you have just a deterministic drift and you add a bit of Gaussian noise to it.",
            "That means the change in the state.",
            "So the change in this state on average is equal to the drift and you have a fluctuation which is proportionate.",
            "You have a variance which is proportional to Delta T and this is just a quadratic form here.",
            "And if you compute the kullback Leiber divergent between two such probabilities transition probabilities, then you end up actually with a quadratic form.",
            "Especially the quadratic difference between this drift and that drift.",
            "So you can say, well, this year you interpret this whole thing as a controlled drift in this, as the uncontrolled drift.",
            "So essentially the continuous time.",
            "Probably."
        ],
        [
            "Um?",
            "That we had."
        ],
        [
            "Here, where we have a loss which is quadratic in the control term is essentially the same as a cool Buck libela loss between transition probabilities for a diffusion problem.",
            "So it's all cool, but Libra losses, so these solvable cases turn out to be Kovac library losses.",
            "So that's, well, we sort of discovered this independently with Cedric and then and Joshua Taylor now work on stick on inference for stochastic differential equations."
        ],
        [
            "And."
        ],
        [
            "That's where you can put these things now today."
        ],
        [
            "Either."
        ],
        [
            "Um, so why should kullback Leiber loss give you something simple?",
            "Well, probably now it's pretty obvious if you have a Markov process and you look at probabilities over entire paths.",
            "Now thinking discrete time for simplicity so you have paths.",
            "X from zero to T, so it's an entire multivariate object.",
            "You have two probabilities, and you're interested in the kullback Leiber divergences between one of these multivariate probabilities and another one.",
            "Both of them are Markov processes and then you can easily show because it's a Markov process that the kullback Leiber divergent between two of these probabilities is the sum of the kullback Leiber divergent.",
            "The expected Kullback Leiber divergent of the transition probabilities.",
            "That's the way of calculating things.",
            "For a Markov process, the log of a product is the sum of logs, and that's also there isn't much to be done there, simply the sum of individual, Kleiber losses is the total kullback Leiber loss, and that's all.",
            "So if you look."
        ],
        [
            "Get this problem that bad company in a Manuel Todorov are trying to solve then you can say well the total cost that you have.",
            "Is well, something I would call a variational free energy.",
            "It's a cool bar Kleiber, divergance between a controlled process and a prior uncontrolled process in a bit of loss.",
            "Expected loss that comes from that is a state dependent loss and not to control dependent loss, so it's just minimize the kullback Leiber, divergance plus some expectation over that, so that's essentially the type of.",
            "If you just summarize what they do, that's the problem that they try to solve a.",
            "We.",
            "Of course we know how to solve that.",
            "How to minimize such a sum of a cool but Libra divergance plus this?",
            "Well, this is essentially saying, here's a prior.",
            "And we looking for a Q such that this sum is minimum.",
            "Well, we can interpret this as a log likelihood term and then we know immediately the solution.",
            "Come to this optimization problem.",
            "Well, the Q the optimal probability Q over paths is just take the prior overpass and take E to the minus.",
            "This loss, which is sort of the likelihood term.",
            "It's just Bayes rule prior times likelihood and there's going to be a normalization so we can immediately write down the global solution to such a control problem.",
            "And it's just a Bayesian posterior sort of the control problem.",
            "Is a Bayesian posterior corresponding to a prior that we are given an E to the minus a loss over states?",
            "And if you plug back the this solution into the into this, what I would call the variational free energy, then you end up with the result that we also know this free energy is the negative log of these normalizer and the normalizer of course is.",
            "Well the normalizer is you take the expectation over the prior so you have to normalize this object.",
            "And you, you take the expectation over the prior.",
            "And here is the likelihood terms.",
            "So it's just just take your normal inference.",
            "Bayesian inference formulas write them down, and this is the solution to to this to this control problem.",
            "And the only thing is you have to sort of interpret E to the minus costs over state's type of a likelihood.",
            "So it's kind of a formal mathematical correspondence, but the mathematics is just.",
            "The same it's a Bayesian problem corresponding to a prior overpass and state.",
            "Likelihood term and you have the global solution, and that's actually what what bad happen and Emanuel Todorov get out.",
            "These are these formulas.",
            "And then what's this issue about linearity?",
            "So if you look at this type of object, this partition functions Ed WHI does it of a linear equation?",
            "Well, this is just you might remember you lecture on hidden Markov models.",
            "There are forward and backward equation.",
            "They essentially linear.",
            "Equations."
        ],
        [
            "These types of objects?",
            "Yeah, for hidden Markov models, you can show that this normalizing partition function is sort of.",
            "If you assume that this is, the likelihood is the probability of the future data given the state of your hidden Markov model at time T, and that obeys a backward equation and the backward equation is the linear equation that that you get in this analysis and.",
            "Yo, so it's all essentially the mathematics of hidden Markov models interpreting certain losses as is.",
            "Is likelihood."
        ],
        [
            "Right?",
            "So you might say, OK, this is all really just very formal stuff, you know.",
            "Is there a real would have some real interpretation in terms of data?",
            "Well, you can easily construct such a case.",
            "Let's say you take you take any homogeneous plus on process with the rate function.",
            "UXT&XT is an underlying Markov process or diffusion process, and the diffusion process is sort of the underlying.",
            "Prior and the the person process is sort of the observation process, then you will see that the probability that you don't have an event in the interval 0T is precisely equal to this type of thing.",
            "So the typical problem would be like that.",
            "Actually, I just learned this from from Ronnie may here, so you would have a problem where you think that.",
            "I'm.",
            "You you think in terms of Spike trains, you know this homogeneous person process is sort of generating mechanism for neural spike trains.",
            "And this variable XT is sort of dynamics of the underlying world.",
            "That is sort of observed by the brain.",
            "And so you have a stochastic dynamics for the underlying world in the underlying world.",
            "Sort of triggers the sort of.",
            "Tells you what what the rate for the for the for the spike emitting thing is, so that could be actually a real problem.",
            "Right, so there is a real application also kind of a Bayesian application for that if you if you want it for their formulism.",
            "And yeah, so this is sort of the first part of my talk, which is 20 minutes and the rest is just telling you what about Carbon and Emanuel Todorov did instead of in my personal interpretation.",
            "I feel sort of that makes sort of the proof of 1 liner right?",
            "So you say they have these free energy losses, it's a control problem and we know how to solve it.",
            "It's a Bayesian.",
            "There's a few more things that I learned which I found."
        ],
        [
            "Sort of.",
            "Problem is everybody says, yeah, that's trivial, right?",
            "But I didn't know it, so just you know.",
            "So this yeah, this relation between inference and control.",
            "I found this interesting.",
            "They could be used probably know all the Monte Carlo people know that already, but it could be used to to draw samples right?",
            "So the following the following inference problem is you know you have a you have a diffusion problem, just the free diffusion problem.",
            "You say?",
            "Well, I observe it, I observed it here.",
            "You know it went there at some point.",
            "How should I sample from those?",
            "Now you have a likelihood which is actually zero everywhere, but only at the last time.",
            "T it says yeah with infinite precision.",
            "I observe this process.",
            "Well, of course the simplest thing would be just to generate loads of diffusion paths, and if they don't hit your Killa mall and if they hit, you say that's the right one.",
            "OK, so it would be a bit stupid, but from what we just learned is, well, yeah, that's that.",
            "Problem can just be solved because I have this specific likelihood here and this is the same as a controlled diffusion process with this specific drift, which I can compute and."
        ],
        [
            "That's what we did, and so you have to solve this is to control.",
            "This is the control.",
            "This is the drift term and you this is a derivative of this partition function.",
            "The partition function is very simple, PD in this case.",
            "With this initial condition, you solve it backward.",
            "That's a solution.",
            "That's the drift, and that's how you just get these these controlled paths.",
            "Another thing which I haven't tried yet."
        ],
        [
            "But what I want to do I find also quite amusing if you want to have diffusions which state in a certain domain, so, like you know they should, that was actually motivated by by you student you.",
            "You want to have all these random walks in a ball, and they shouldn't go out.",
            "And yeah, so the idea would be that they have to stay in a certain domain and as soon as they hit the boundary, you know you have to take them away.",
            "So again, the method one would kill each trajectory.",
            "That hit the boundary for some time T, so they are all dead.",
            "That's of course a time consuming type of thing.",
            "Or you could do a Monte Carlo procedure where you put in kind of a high energy that you know if it hits the wall it has a becomes.",
            "Very yes, strongly penalized, but again with what we learned so far, you could come up with a specific drift.",
            "So the specific drift, again, I forgot the logarithm here.",
            "So the specific drift is the gradient of the logarithm of Z.",
            "And this said is this, so it's precisely.",
            "It says you know you take your expectation.",
            "Overall controlled uncontrolled paths and you penalize it with this type of likelihood term.",
            "We're just simply say you is infinite whenever you're at the boundary or beyond.",
            "If you're outside of your domain, and that should do the job, it just kills.",
            "This mathematical expression just kills all the trajectory's that leave the boundary right?",
            "So if U is 0 inside of inside of the domain in you is Infinity outside, then this is what you want, so it gives 0 probability to every random Walker to every diffuser that goes outside.",
            "So again you have this thing.",
            "Well, it obeys a linear equation.",
            "The linear equation is again a simple diffusion equation with the boundary condition.",
            "That you're there.",
            "You have a zero at at the boundary and I hope so.",
            "If you solve that when you get to the corresponding drift and you can simulate these guys with the first example.",
            "Is that what Golightly called the Brownian Bridge?",
            "Yeah, there's a brand new bridge, yes, so I don't know how they come up with that.",
            "How they saw my car, but I just seen them use it if you tried, but is it the case that what you're saying with?"
        ],
        [
            "Call methodology gives you a more general way of coming up, so this is a very different thing that spherical constraint.",
            "Yes, yeah.",
            "Is it mean that you can easily come up with these new sort of constraints?",
            "Yeah, well that's the question.",
            "The easy."
        ],
        [
            "The easy part is the easy part is.",
            "I mean you end up with a.",
            "You end up with such an object which you have to solve.",
            "I mean it's a linear partial differential equation in some of the cases you can solve them in for a spherical constraint I can solve them there, that's just you know, probably Bessel functions or whatever.",
            "And and yeah, so it depends.",
            "Yeah, that's the answer.",
            "I don't know if you know if you constrain.",
            "Have you seen this before?",
            "I don't know.",
            "I haven't seen.",
            "I mean, this is just more or less sort of last weeks where I thought about that.",
            "Doing it this way, I expect of course.",
            "I mean this the mathematical world is so huge and probably this is to stochastic analysis.",
            "Guys at your first semester, whatever I don't know.",
            "I mean I didn't know it, so it's just you know, I I stared at bed Coppens paper and say wow.",
            "And how do you get this?",
            "And then then?",
            "Then you do this half page of derivatives first derivative, then a secondary.",
            "Oh, I forgot this term.",
            "You know multiplication rule and you see how would it becomes linear.",
            "And so I just tried to simplify myself.",
            "So I think it's more than that.",
            "Yeah, but I I don't know.",
            "I don't know.",
            "I don't know if this is this is known or not, but probably it's known by somebody, right?",
            "So I thought it's a.",
            "It's a neat method to sample.",
            "OK, so the other thing is of course you know.",
            "Bet bet Karpinen Manuel told her if they have now lots of papers where they apply this relation between inference and control.",
            "But this is actually this holds only if we have this specific relation in the in the continuous time case between the noise that drives the system and the control cost.",
            "So there is this funny matrix relationship, so the costs the matrix appearing in the costs have to be the inverse of the of the.",
            "The driving noise, so you could say this is artificial and you would not always want this.",
            "Could you use whatever we know about inference in order to solve that problems?"
        ],
        [
            "Well, I mean, I thought of course I mean just we copy our our paper.",
            "So let's say we have this type of problem with the general matrix R, which is not the inverse D and then well, why not trying just to solve this problem using the stuff that we did with Cedric and and John Sean Taylor.",
            "Just you know you don't look for the most general process that approximates that, but you just look at a linear and optimal.",
            "A linear process that solves that minimizes this type of thing and just simply say, well, the control process should look like that, and in this case well, this as an approximation to that, and then you would say, well, in this case, the control is a linear part plus minus this.",
            "This prior uncontrolled part, and then you go through the mathematics in the same way as we did for our inference problem with stochastic differential equation.",
            "I mean, the only thing is just this matrix is different in this case, but why not just applying the same type of stuff to that and and and do the linear the Gaussian variational principle with this loss function it's no longer a callback libel loss anymore, but you could do it at least and you would end up with nonlinear ODS for moments rather than the linear PDE.",
            "So this is the first suggestion one could try that.",
            "Wouldn't be very expensive.",
            "I don't know how if it would make sense or not, then of course, can you think of other loss functions that you might be able to tackle in that formalism so?"
        ],
        [
            "I construct me one that might that you might be able to do something just motivated by our work on approximate inference with.",
            "You know, if you do approximate inference, we have these these gifts approximate Gibbs free energies.",
            "If somebody remembers these these type of things there Gibbs free energies for for all kinds of approximate inference processes and usually what you then have to minimize.",
            "Is an approximate free energy which is no longer a true free energy for an inference problem, and it has all kinds of things in it.",
            "Convex and concave things, and it makes life so hard.",
            "And there was an interesting development called the CCC thesis CP Algorithm, which says if I have costs which are combinations of sum of convex plus concave, I can use a neat trick to get kind of an iterative.",
            "Minimization procedure so my idea would be then, well, you could maybe play with the following losses.",
            "So this is too simple.",
            "The Kullback Leiber losses to simple.",
            "That's just normal inference that we do.",
            "We can write down the global solution.",
            "So what if we just take a bit of a callback, libel, Lausanne, subtract another cool work libel law, so that would say yeah, I penalize in the control problem.",
            "I penalize my process by being too far away from one prior.",
            "But I like it to be close to another one.",
            "No far away from another one, so I just subtract another cool but library.",
            "And then I say, well, I get in a similar style as these KPIs algorithms.",
            "I'll just keep that and always upper bound this part by something linear in Q and so you could get an iterative procedure which would always minimize something an upper bound to this type of thing.",
            "Until you get kind of a local minimum and actually, that brings me to the end of my my talk.",
            "I don't have really any conclusion, it's more something you know that came up to my mind when I was in Holidays and I thought to myself, what should I talk about?",
            "Should I talk about this stuff that I always talk about?",
            "Or then I said, OK, maybe this is something, yeah?",
            "That might amuse somebody or not.",
            "Thank you very much.",
            "Question.",
            "Yeah.",
            "The solution for the.",
            "Yes.",
            "Random weapon and we boundary that with what?",
            "Yes yes yes yes.",
            "Yeah, but the question is how to simulate that?",
            "Yeah, I mean you can calculate analytical solutions to it and stuff like that.",
            "To think that yeah.",
            "Standard transformation that people use to link various problems in physics like colors in random media.",
            "Yes, it's a cold hop transformation, and it's it's a relation between CDP and it's the same, yes, right?",
            "So you also brought me looking in a little bit into these hydrodynamic books than the Kohlhoff transformation relates relates to KPZ equation and the other thing I forgot the name.",
            "Yeah yeah, yeah yes precisely.",
            "I mean when can cook up now a physics version of that and say.",
            "It's all inference or what I did I didn't try this.",
            "How?",
            "I'm very sorry I couldn't comment on that.",
            "That's a different thing because what Amos and Mark did.",
            "Yes, it is very different.",
            "Yeah.",
            "Variety of different possible costs and it really is certain addition of just extending earlier work so that you can don't have a finite time horizon.",
            "Very space is using.",
            "Yeah, yeah.",
            "So so, uh, thing where this doesn't apply is the case where you have discounted costs and your case would nicely work.",
            "Work there because this discount is as soon as you put in a future.",
            "Costs are discounted by by an exponential in time.",
            "Then you know you have these individual costs that you add up together, but they don't add up to a global cool book library.",
            "And then you're not getting into a linear kind of thing.",
            "So even in a case where you have stationary problem, but in your algorithm would nicely deal with that.",
            "So it seems to be different application domains.",
            "One reason I really think this is.",
            "I really think that this stuff is exciting and a lot of the stuff that's doing well.",
            "It seems to touch on some of the stuff that Carl was saying yesterday, but this is really about decisions and it controls about decision.",
            "Yes, and how much cost you pay for doing things.",
            "So one thing that makes me nervous is like this.",
            "I think it's a terrible thing when people just take a likelihood and say or say they got a quadratic cost in a problem.",
            "So if if I'm selling lumber.",
            "And the demand is heavy tailed, but I pay a quadratic cost for MIS estimating the demand.",
            "If I if I do Bayesian inference with the quadratic cost, if I say my likelihood is a cost, I do extremely badly on.",
            "That's true yes practice, whereas if I do use the heavy tail thing then then I do very well despite not taking account the cost in the infant stage.",
            "How does this raise, I mean?",
            "But is this getting around?",
            "But somehow I uh?",
            "I mean, I think the danger is a little bit here that not every cost that you really believe in it.",
            "You think that the right ones are can be written as inference problems and it's not clear what to do then.",
            "But maybe you want to do real Bayesian inference on top of a control problem, so I don't know that as another layer I mean.",
            "It's a bit different, so at the moment this is Joni, just an interpretation of something is mathematically equivalent to something else, and there's something else is a Bayesian thing, so.",
            "So it's not deep on a philosophical level, only on a mathematical level, so.",
            "Can't make any conclusions beside that.",
            "I've got another yeah.",
            "For example, yes.",
            "Done just by saying OK you you can write if save the sample at the end has got value 0 yes?",
            "Yes, yeah.",
            "Do you expression?",
            "Oh, you can also go through the analysis.",
            "You look at the controlled diffusion equation and then you compute what the variance at time T is.",
            "I mean this this various things that you want to know.",
            "You can look at the covariance, but here I'm looking actually at the stochastic differential equation.",
            "If I want to draw samples.",
            "So this is a bit more the Brownian Bridge, you can say, OK, this is a Gaussian process.",
            "As such, has such and such covariance, and then you know it.",
            "But if you want to draw samples, if you want to represent it as a stochastic differential equation, then you have to use this.",
            "So this is different things and if you look at the moments of these things then you end up with the original expressions.",
            "You also know from the textbook, but the control diffusion is also known you for you.",
            "I mean this is a standard thing.",
            "You also find it textbooks if you want, you can use a non standalone back process again fix, fix the end point, then you get a controlled on standalone back process.",
            "Should be in on central bank bridge.",
            "Then also is possible.",
            "More questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So probably I might not use the full time of 45 minutes and actually it's going to be a bit of a technical talks about why not.",
                    "label": 0
                },
                {
                    "sent": "So you're all experts in in Bayesian inference, and so this is actually not about my own work, it's more about work of other people like bed like bed, cap and and and told her off.",
                    "label": 0
                },
                {
                    "sent": "So I found that were quite interesting and I tried to understand it a little bit better, and that's sort of my personal interpretation of what they did.",
                    "label": 0
                },
                {
                    "sent": "Is as inference problem, so probably.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of papers around by them and maybe they already have understood that, but this sort of my my own, my own approach and I want to share this with you and I found it simply some beautiful thing this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That they did so.",
                    "label": 0
                },
                {
                    "sent": "This is about, you know, their approach is about analyzing a control problem.",
                    "label": 0
                },
                {
                    "sent": "Specific types of stochastic control problems and they are solved.",
                    "label": 1
                },
                {
                    "sent": "As you might remember from an AI course using belmans equality, you can solve these control problems, at least in principle.",
                    "label": 0
                },
                {
                    "sent": "And then they find out going through the mathematics well that looks really like an inference problem for well in some cases like hidden Markov model or if in continuous time for stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "And that's what brought me into this problem, so that's their way of looking at it, and you really, really go to the mathematics and you're surprised while this comes out.",
                    "label": 0
                },
                {
                    "sent": "And so my way is just if I come from an inference problem and look at it in a specific way and apply the variational method that we all know for approximate inference.",
                    "label": 0
                },
                {
                    "sent": "Now the Kullback Leiber, variational approach for computing a posterior.",
                    "label": 0
                },
                {
                    "sent": "Then you end up with a control problem.",
                    "label": 1
                },
                {
                    "sent": "It's precisely the ones that that bed and.",
                    "label": 0
                },
                {
                    "sent": "Manuel told her if we're studying so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the whole story.",
                    "label": 0
                },
                {
                    "sent": "And then yeah, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I mean, they did a lot of things with this with this formulation.",
                    "label": 1
                },
                {
                    "sent": "For me there were a few things that I could learn from them, and I also want to tell you those.",
                    "label": 0
                },
                {
                    "sent": "And maybe there are some possible extensions and maybe you have some ideas too, so it's not really my work.",
                    "label": 0
                },
                {
                    "sent": "I haven't done much on this, just a bit of understanding.",
                    "label": 0
                },
                {
                    "sent": "So what's this all about?",
                    "label": 0
                },
                {
                    "sent": "Let's start with something as simple discrete times, not just stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "Discrete time control problem.",
                    "label": 0
                },
                {
                    "sent": "You could also call them Markov decision problems and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's assume we have a Markov process and we have well discrete times discrete states.",
                    "label": 0
                },
                {
                    "sent": "For simplicity, we have transition probabilities going from states X into X prime, and we have some little control.",
                    "label": 0
                },
                {
                    "sent": "That means we can change things and then these transition probabilities will also change and we want to change them in such a way that total expected cost over.",
                    "label": 0
                },
                {
                    "sent": "A path over some finite horizon T is a minimum, so we have some loss function here that depends on the state that we are in.",
                    "label": 0
                },
                {
                    "sent": "It depends on the control variable that we have at time T we will start the whole process at available at a position exit of State X and then we sum up all these costs and average them over the controlled transition probability.",
                    "label": 1
                },
                {
                    "sent": "And now this thing should be minimized with respect.",
                    "label": 0
                },
                {
                    "sent": "To that control so that each state and each time we have to do something in order to keep this whole sum the minimum.",
                    "label": 0
                },
                {
                    "sent": "So technically this is solved by defining a value of a state X at time T, which is sort of the cost that will come up in the future.",
                    "label": 0
                },
                {
                    "sent": "Sort of the expected cost for all times greater than T. And again we sum up up to the finite horizon T and then we all learn probably in.",
                    "label": 0
                },
                {
                    "sent": "Maybe in an AI course that for this value function we can find a simple equation which is the so-called Bellman equation that says simply, well, the cost that we have at time T. We can write them at as the cost that we have now at the stage X plus the expected costs that we will have in the future.",
                    "label": 0
                },
                {
                    "sent": "So it's relate.",
                    "label": 0
                },
                {
                    "sent": "It relates this value of a state to the to the value at future time.",
                    "label": 0
                },
                {
                    "sent": "So this is a so called belmans equality.",
                    "label": 0
                },
                {
                    "sent": "And so yeah, we do this minimization here.",
                    "label": 0
                },
                {
                    "sent": "So this is the standard approach for solving.",
                    "label": 0
                },
                {
                    "sent": "These type of things.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so you can go to continuous times.",
                    "label": 0
                },
                {
                    "sent": "That was actually the work for started by about Cup and so now we go away from discrete times into continuous times continuous states.",
                    "label": 0
                },
                {
                    "sent": "So you think, well, you transition probabilities, they come from a dynamical system, so you have a continuous state X which is changed by some deterministic process.",
                    "label": 0
                },
                {
                    "sent": "So the change of X is proportional to the infinitesimally change.",
                    "label": 0
                },
                {
                    "sent": "In time and there's some noise added, so essentially those those transition probabilities are little Gaussians, so you had a little bit of Gaussian noise, so the conditional probabilities will be Gaussians.",
                    "label": 0
                },
                {
                    "sent": "So the first part is usually called the drift of the process, and the second part is called the diffusion, and to introduce control here.",
                    "label": 0
                },
                {
                    "sent": "So you have a kind of uncontrolled part which is sort of a prior drift and you have.",
                    "label": 0
                },
                {
                    "sent": "A little control that you have to choose so you can really steer this whole thing, so this is what you want.",
                    "label": 0
                },
                {
                    "sent": "You can control this part.",
                    "label": 0
                },
                {
                    "sent": "You can't control the diffusion in this formulation, so this is the type of transitions that we consider for continuous time, and so if you want to get have a sort of practical meaning of this stochastic differential equation, you can again discretize it in time and then you say, well, this change of state is something that is proportional.",
                    "label": 1
                },
                {
                    "sent": "Delta T + a little bit of Gaussian noise, which scales with the square root of Delta T and how general is these type of formulation?",
                    "label": 0
                },
                {
                    "sent": "I think if you want to have continuous path continuous states continuous path, that's probably the only thing you can do.",
                    "label": 0
                },
                {
                    "sent": "If you want to have a Markov process.",
                    "label": 0
                },
                {
                    "sent": "So in that sense it's a fairly general thing.",
                    "label": 0
                },
                {
                    "sent": "If you don't want to have jumps and so this is a nice description.",
                    "label": 0
                },
                {
                    "sent": "Of a mark of world.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for this type of thing you can also write down a control problem.",
                    "label": 0
                },
                {
                    "sent": "Now all the sums are replaced by integrals, so you start with T = 0 up to T. You integrate again.",
                    "label": 0
                },
                {
                    "sent": "You have a loss function and you start at X 0 = X and U average over the controlled.",
                    "label": 0
                },
                {
                    "sent": "Probabilities again you define the values of a state.",
                    "label": 0
                },
                {
                    "sent": "X is sort of all the costs that you have in the future from time T up to the horizon capital T. So that's precisely the same type of thing.",
                    "label": 0
                },
                {
                    "sent": "I don't give a derivation of that that suggested a technical thing, so you will have another type of Bellman equation relating costs at time T. An future costs, and it turns out that you get.",
                    "label": 0
                },
                {
                    "sent": "A temporal change of that value function, and you play a bit with all these.",
                    "label": 0
                },
                {
                    "sent": "Stochastic analysis thing and you just end up with a partial differential equation, so there should be you know, summation over overstate steps.",
                    "label": 0
                },
                {
                    "sent": "You can go into should be replaced by sort of differential type of things.",
                    "label": 0
                },
                {
                    "sent": "So one can do that.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Fun.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "It's here.",
                    "label": 0
                },
                {
                    "sent": "It's in the loss function, so I haven't really said what what this loss will be.",
                    "label": 0
                },
                {
                    "sent": "I'll come to the loss in a second.",
                    "label": 0
                },
                {
                    "sent": "Oh, right.",
                    "label": 0
                },
                {
                    "sent": "I know, yes, yes this is the uncontrolled sort of it appears.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it shouldn't come up here, I think.",
                    "label": 0
                },
                {
                    "sent": "I think it's correct.",
                    "label": 0
                },
                {
                    "sent": "I have to see that.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe maybe I was wrong.",
                    "label": 0
                },
                {
                    "sent": "I'm a cop.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a wrong way.",
                    "label": 0
                },
                {
                    "sent": "So what we do is now we we specialize to a very specific type of loss function, so which doesn't seem to be unreasonable.",
                    "label": 0
                },
                {
                    "sent": "So you say, OK, there is a loss which only depends on the path.",
                    "label": 0
                },
                {
                    "sent": "There's no control loss in the first part is the controller, so you say, well, OK, this you shouldn't make you controls too large because you burn too much energy if you just try to control the system strongly.",
                    "label": 0
                },
                {
                    "sent": "So there will be a quadratic form in in the control, so that's the that's the idea.",
                    "label": 0
                },
                {
                    "sent": "I think it seems also fairly general to choose to choose such type of.",
                    "label": 0
                },
                {
                    "sent": "Loss function Now there's a very funny observation that that bad Captain had.",
                    "label": 0
                },
                {
                    "sent": "So first of all, you know just you use this type of loss and go back into the Hamilton Jacobi Bellman equation.",
                    "label": 0
                },
                {
                    "sent": "So you put this back.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into this equation and.",
                    "label": 0
                },
                {
                    "sent": "You're absolutely right, there should be in.",
                    "label": 0
                },
                {
                    "sent": "There should be a U.",
                    "label": 0
                },
                {
                    "sent": "So you put this back in, solve for for you locally, and then you end up.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "And nonlinear PDE.",
                    "label": 0
                },
                {
                    "sent": "So this is as far as you can get.",
                    "label": 0
                },
                {
                    "sent": "You're absolutely right.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this is sort of the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Normally this is what you have to live with.",
                    "label": 0
                },
                {
                    "sent": "You have to solve such an ugly equation and it's not even linear.",
                    "label": 0
                },
                {
                    "sent": "It has all these nonlinear terms in it and so well that makes life complicated and now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's back up and says OK.",
                    "label": 0
                },
                {
                    "sent": "If we have a specific choice for the matrix R, remember the Matrix R's.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is defined in the in these losses here.",
                    "label": 0
                },
                {
                    "sent": "This is the matrix that that tells you how to weight these.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Control losses and make them inversely proportional.",
                    "label": 0
                },
                {
                    "sent": "I mean, let's forget about proportionality.",
                    "label": 0
                },
                {
                    "sent": "Make them just the inverse of the diffusion matrix.",
                    "label": 0
                },
                {
                    "sent": "And then you do another thing.",
                    "label": 0
                },
                {
                    "sent": "You make a variable transformation from loss from these values into log space and define in you variable and then just plug it in and calculate and calculate and calculate and all these nonlinearities disappear.",
                    "label": 0
                },
                {
                    "sent": "Wow.",
                    "label": 0
                },
                {
                    "sent": "If you see such a thing, you're getting really impressed and saying something is happening here.",
                    "label": 0
                },
                {
                    "sent": "And yes, as I said, funny enough, you end up with a linear equation and linear equations are much nicer usually compared to non linear ones.",
                    "label": 0
                },
                {
                    "sent": "And if you look at this and then you realize this operator is the so called bok bok backward operator for kind of a backward equation for for the underlying diffusion.",
                    "label": 0
                },
                {
                    "sent": "And then if you know a little bit about these diffusion processes, you find out that this is actually.",
                    "label": 0
                },
                {
                    "sent": "That solution to this equation can be represented as a path integral.",
                    "label": 1
                },
                {
                    "sent": "Simply meaning path integral means, say you sum up, you take the expectation overall uncontrolled path, so the control is gone here and you get all these path costs in the exponent and so this is actually the solution to it.",
                    "label": 0
                },
                {
                    "sent": "So you have a stochastic representation of this problem as an expectation over uncontrolled.",
                    "label": 0
                },
                {
                    "sent": "Uncontrolled diffusions over something.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this looks really like you know a sum over all possible paths, so that looks more or less like you know here we've got sort of a prior.",
                    "label": 0
                },
                {
                    "sent": "You have an average and here is something like you might call a likelihood term and this is a partition function.",
                    "label": 0
                },
                {
                    "sent": "That's why I called it said so its normalizer of some posterior probability.",
                    "label": 1
                },
                {
                    "sent": "And what you can do is now you can apply all kinds of inference.",
                    "label": 1
                },
                {
                    "sent": "Bayesian inference tricks, approximate inference tricks, Monte Carlo sampling.",
                    "label": 0
                },
                {
                    "sent": "A mean field type of things so so bad has really no applied this to to agent planning type of problems where this is.",
                    "label": 0
                },
                {
                    "sent": "Where you actually include some or even even some end costs.",
                    "label": 0
                },
                {
                    "sent": "I mean, I haven't put in sort of there's costs at the end of the time horizon, so if you have such an object, you can say, oh, this is now easy and you have a whole bunch of techniques to deal with that, and if you have this function, then you can compute immediately your control.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All.",
                    "label": 0
                },
                {
                    "sent": "I I was mentioning that as a century, the gradient of that value.",
                    "label": 0
                },
                {
                    "sent": "So this partition function gives the value.",
                    "label": 0
                },
                {
                    "sent": "The value gives the control and everything is solved and so it's beautiful, I said.",
                    "label": 0
                },
                {
                    "sent": "Wow, so you do a mathematical trick and outcomes something very simple.",
                    "label": 0
                },
                {
                    "sent": "And yeah I didn't understand it for quite awhile.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "There's a similar development, a parallel development from told her off, and it was actually a NIPS paper.",
                    "label": 0
                },
                {
                    "sent": "I hopefully copied the right year, probably NIPS 2006.",
                    "label": 0
                },
                {
                    "sent": "And so he was using a discrete time formulation and not the diffusion process, but the Markov decision problems.",
                    "label": 0
                },
                {
                    "sent": "So he was coming up with a funny type of loss and it turns out that this loss is very much related to the previous one in continuous time and it actually teaches at a bit more where this simplification actually comes from.",
                    "label": 0
                },
                {
                    "sent": "So you have losses that are actually depending only on the state, and there's a part of the loss that is the control loss.",
                    "label": 0
                },
                {
                    "sent": "So this controllers looks like a cool book, Libra Divergent.",
                    "label": 0
                },
                {
                    "sent": "It says you have some prior jump, some uncontrolled jump probabilities P, and the controlled ones.",
                    "label": 0
                },
                {
                    "sent": "They they they lead to a loss, which is the kullback leibner between the controlled transition probability in the uncontrolled one.",
                    "label": 1
                },
                {
                    "sent": "So that means you pay you pay as you know if you deviate from your prior probabilities, you pay with the cool math library loss.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "And then if you go through the mathematics again and again and again, I want to.",
                    "label": 0
                },
                {
                    "sent": "Did you board with that and you make a similar type of logarithmic transformation, and then you end up with a with a linear equation again and filter or solves a couple of nice Markov decision processes for these type of losses is using linear methods.",
                    "label": 0
                },
                {
                    "sent": "I mean here we have discrete time discrete state, everything is matrices, so you can compute.",
                    "label": 0
                },
                {
                    "sent": "Yes, you have linear algebra and everything can be done, so it seems like there is a couple of control problems for which you can do nicely in your mathematics.",
                    "label": 0
                },
                {
                    "sent": "Inference, types of mathematics, and that's what it is.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to give the relation to the continuous case I was discussing before when we have a a diffusion problem, a stochastic differential equation and look at the transition probability for short times from going from a state X to X prime over a time interval of Delta T. Then it's a locally a Gaussian because you have just a deterministic drift and you add a bit of Gaussian noise to it.",
                    "label": 0
                },
                {
                    "sent": "That means the change in the state.",
                    "label": 0
                },
                {
                    "sent": "So the change in this state on average is equal to the drift and you have a fluctuation which is proportionate.",
                    "label": 0
                },
                {
                    "sent": "You have a variance which is proportional to Delta T and this is just a quadratic form here.",
                    "label": 0
                },
                {
                    "sent": "And if you compute the kullback Leiber divergent between two such probabilities transition probabilities, then you end up actually with a quadratic form.",
                    "label": 0
                },
                {
                    "sent": "Especially the quadratic difference between this drift and that drift.",
                    "label": 0
                },
                {
                    "sent": "So you can say, well, this year you interpret this whole thing as a controlled drift in this, as the uncontrolled drift.",
                    "label": 0
                },
                {
                    "sent": "So essentially the continuous time.",
                    "label": 0
                },
                {
                    "sent": "Probably.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "That we had.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, where we have a loss which is quadratic in the control term is essentially the same as a cool Buck libela loss between transition probabilities for a diffusion problem.",
                    "label": 0
                },
                {
                    "sent": "So it's all cool, but Libra losses, so these solvable cases turn out to be Kovac library losses.",
                    "label": 0
                },
                {
                    "sent": "So that's, well, we sort of discovered this independently with Cedric and then and Joshua Taylor now work on stick on inference for stochastic differential equations.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's where you can put these things now today.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, so why should kullback Leiber loss give you something simple?",
                    "label": 0
                },
                {
                    "sent": "Well, probably now it's pretty obvious if you have a Markov process and you look at probabilities over entire paths.",
                    "label": 1
                },
                {
                    "sent": "Now thinking discrete time for simplicity so you have paths.",
                    "label": 0
                },
                {
                    "sent": "X from zero to T, so it's an entire multivariate object.",
                    "label": 0
                },
                {
                    "sent": "You have two probabilities, and you're interested in the kullback Leiber divergences between one of these multivariate probabilities and another one.",
                    "label": 0
                },
                {
                    "sent": "Both of them are Markov processes and then you can easily show because it's a Markov process that the kullback Leiber divergent between two of these probabilities is the sum of the kullback Leiber divergent.",
                    "label": 1
                },
                {
                    "sent": "The expected Kullback Leiber divergent of the transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "That's the way of calculating things.",
                    "label": 0
                },
                {
                    "sent": "For a Markov process, the log of a product is the sum of logs, and that's also there isn't much to be done there, simply the sum of individual, Kleiber losses is the total kullback Leiber loss, and that's all.",
                    "label": 0
                },
                {
                    "sent": "So if you look.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get this problem that bad company in a Manuel Todorov are trying to solve then you can say well the total cost that you have.",
                    "label": 0
                },
                {
                    "sent": "Is well, something I would call a variational free energy.",
                    "label": 0
                },
                {
                    "sent": "It's a cool bar Kleiber, divergance between a controlled process and a prior uncontrolled process in a bit of loss.",
                    "label": 0
                },
                {
                    "sent": "Expected loss that comes from that is a state dependent loss and not to control dependent loss, so it's just minimize the kullback Leiber, divergance plus some expectation over that, so that's essentially the type of.",
                    "label": 0
                },
                {
                    "sent": "If you just summarize what they do, that's the problem that they try to solve a.",
                    "label": 0
                },
                {
                    "sent": "We.",
                    "label": 0
                },
                {
                    "sent": "Of course we know how to solve that.",
                    "label": 0
                },
                {
                    "sent": "How to minimize such a sum of a cool but Libra divergance plus this?",
                    "label": 0
                },
                {
                    "sent": "Well, this is essentially saying, here's a prior.",
                    "label": 0
                },
                {
                    "sent": "And we looking for a Q such that this sum is minimum.",
                    "label": 0
                },
                {
                    "sent": "Well, we can interpret this as a log likelihood term and then we know immediately the solution.",
                    "label": 0
                },
                {
                    "sent": "Come to this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Well, the Q the optimal probability Q over paths is just take the prior overpass and take E to the minus.",
                    "label": 1
                },
                {
                    "sent": "This loss, which is sort of the likelihood term.",
                    "label": 0
                },
                {
                    "sent": "It's just Bayes rule prior times likelihood and there's going to be a normalization so we can immediately write down the global solution to such a control problem.",
                    "label": 0
                },
                {
                    "sent": "And it's just a Bayesian posterior sort of the control problem.",
                    "label": 0
                },
                {
                    "sent": "Is a Bayesian posterior corresponding to a prior that we are given an E to the minus a loss over states?",
                    "label": 1
                },
                {
                    "sent": "And if you plug back the this solution into the into this, what I would call the variational free energy, then you end up with the result that we also know this free energy is the negative log of these normalizer and the normalizer of course is.",
                    "label": 0
                },
                {
                    "sent": "Well the normalizer is you take the expectation over the prior so you have to normalize this object.",
                    "label": 0
                },
                {
                    "sent": "And you, you take the expectation over the prior.",
                    "label": 0
                },
                {
                    "sent": "And here is the likelihood terms.",
                    "label": 0
                },
                {
                    "sent": "So it's just just take your normal inference.",
                    "label": 0
                },
                {
                    "sent": "Bayesian inference formulas write them down, and this is the solution to to this to this control problem.",
                    "label": 0
                },
                {
                    "sent": "And the only thing is you have to sort of interpret E to the minus costs over state's type of a likelihood.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of a formal mathematical correspondence, but the mathematics is just.",
                    "label": 1
                },
                {
                    "sent": "The same it's a Bayesian problem corresponding to a prior overpass and state.",
                    "label": 0
                },
                {
                    "sent": "Likelihood term and you have the global solution, and that's actually what what bad happen and Emanuel Todorov get out.",
                    "label": 0
                },
                {
                    "sent": "These are these formulas.",
                    "label": 0
                },
                {
                    "sent": "And then what's this issue about linearity?",
                    "label": 0
                },
                {
                    "sent": "So if you look at this type of object, this partition functions Ed WHI does it of a linear equation?",
                    "label": 0
                },
                {
                    "sent": "Well, this is just you might remember you lecture on hidden Markov models.",
                    "label": 0
                },
                {
                    "sent": "There are forward and backward equation.",
                    "label": 0
                },
                {
                    "sent": "They essentially linear.",
                    "label": 0
                },
                {
                    "sent": "Equations.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These types of objects?",
                    "label": 0
                },
                {
                    "sent": "Yeah, for hidden Markov models, you can show that this normalizing partition function is sort of.",
                    "label": 0
                },
                {
                    "sent": "If you assume that this is, the likelihood is the probability of the future data given the state of your hidden Markov model at time T, and that obeys a backward equation and the backward equation is the linear equation that that you get in this analysis and.",
                    "label": 0
                },
                {
                    "sent": "Yo, so it's all essentially the mathematics of hidden Markov models interpreting certain losses as is.",
                    "label": 0
                },
                {
                    "sent": "Is likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So you might say, OK, this is all really just very formal stuff, you know.",
                    "label": 0
                },
                {
                    "sent": "Is there a real would have some real interpretation in terms of data?",
                    "label": 1
                },
                {
                    "sent": "Well, you can easily construct such a case.",
                    "label": 0
                },
                {
                    "sent": "Let's say you take you take any homogeneous plus on process with the rate function.",
                    "label": 1
                },
                {
                    "sent": "UXT&XT is an underlying Markov process or diffusion process, and the diffusion process is sort of the underlying.",
                    "label": 0
                },
                {
                    "sent": "Prior and the the person process is sort of the observation process, then you will see that the probability that you don't have an event in the interval 0T is precisely equal to this type of thing.",
                    "label": 0
                },
                {
                    "sent": "So the typical problem would be like that.",
                    "label": 0
                },
                {
                    "sent": "Actually, I just learned this from from Ronnie may here, so you would have a problem where you think that.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "You you think in terms of Spike trains, you know this homogeneous person process is sort of generating mechanism for neural spike trains.",
                    "label": 0
                },
                {
                    "sent": "And this variable XT is sort of dynamics of the underlying world.",
                    "label": 0
                },
                {
                    "sent": "That is sort of observed by the brain.",
                    "label": 0
                },
                {
                    "sent": "And so you have a stochastic dynamics for the underlying world in the underlying world.",
                    "label": 0
                },
                {
                    "sent": "Sort of triggers the sort of.",
                    "label": 0
                },
                {
                    "sent": "Tells you what what the rate for the for the for the spike emitting thing is, so that could be actually a real problem.",
                    "label": 0
                },
                {
                    "sent": "Right, so there is a real application also kind of a Bayesian application for that if you if you want it for their formulism.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so this is sort of the first part of my talk, which is 20 minutes and the rest is just telling you what about Carbon and Emanuel Todorov did instead of in my personal interpretation.",
                    "label": 0
                },
                {
                    "sent": "I feel sort of that makes sort of the proof of 1 liner right?",
                    "label": 0
                },
                {
                    "sent": "So you say they have these free energy losses, it's a control problem and we know how to solve it.",
                    "label": 0
                },
                {
                    "sent": "It's a Bayesian.",
                    "label": 0
                },
                {
                    "sent": "There's a few more things that I learned which I found.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "Problem is everybody says, yeah, that's trivial, right?",
                    "label": 0
                },
                {
                    "sent": "But I didn't know it, so just you know.",
                    "label": 0
                },
                {
                    "sent": "So this yeah, this relation between inference and control.",
                    "label": 0
                },
                {
                    "sent": "I found this interesting.",
                    "label": 0
                },
                {
                    "sent": "They could be used probably know all the Monte Carlo people know that already, but it could be used to to draw samples right?",
                    "label": 0
                },
                {
                    "sent": "So the following the following inference problem is you know you have a you have a diffusion problem, just the free diffusion problem.",
                    "label": 0
                },
                {
                    "sent": "You say?",
                    "label": 0
                },
                {
                    "sent": "Well, I observe it, I observed it here.",
                    "label": 0
                },
                {
                    "sent": "You know it went there at some point.",
                    "label": 0
                },
                {
                    "sent": "How should I sample from those?",
                    "label": 0
                },
                {
                    "sent": "Now you have a likelihood which is actually zero everywhere, but only at the last time.",
                    "label": 0
                },
                {
                    "sent": "T it says yeah with infinite precision.",
                    "label": 0
                },
                {
                    "sent": "I observe this process.",
                    "label": 0
                },
                {
                    "sent": "Well, of course the simplest thing would be just to generate loads of diffusion paths, and if they don't hit your Killa mall and if they hit, you say that's the right one.",
                    "label": 0
                },
                {
                    "sent": "OK, so it would be a bit stupid, but from what we just learned is, well, yeah, that's that.",
                    "label": 0
                },
                {
                    "sent": "Problem can just be solved because I have this specific likelihood here and this is the same as a controlled diffusion process with this specific drift, which I can compute and.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's what we did, and so you have to solve this is to control.",
                    "label": 0
                },
                {
                    "sent": "This is the control.",
                    "label": 0
                },
                {
                    "sent": "This is the drift term and you this is a derivative of this partition function.",
                    "label": 0
                },
                {
                    "sent": "The partition function is very simple, PD in this case.",
                    "label": 0
                },
                {
                    "sent": "With this initial condition, you solve it backward.",
                    "label": 0
                },
                {
                    "sent": "That's a solution.",
                    "label": 0
                },
                {
                    "sent": "That's the drift, and that's how you just get these these controlled paths.",
                    "label": 0
                },
                {
                    "sent": "Another thing which I haven't tried yet.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what I want to do I find also quite amusing if you want to have diffusions which state in a certain domain, so, like you know they should, that was actually motivated by by you student you.",
                    "label": 0
                },
                {
                    "sent": "You want to have all these random walks in a ball, and they shouldn't go out.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so the idea would be that they have to stay in a certain domain and as soon as they hit the boundary, you know you have to take them away.",
                    "label": 0
                },
                {
                    "sent": "So again, the method one would kill each trajectory.",
                    "label": 0
                },
                {
                    "sent": "That hit the boundary for some time T, so they are all dead.",
                    "label": 0
                },
                {
                    "sent": "That's of course a time consuming type of thing.",
                    "label": 0
                },
                {
                    "sent": "Or you could do a Monte Carlo procedure where you put in kind of a high energy that you know if it hits the wall it has a becomes.",
                    "label": 0
                },
                {
                    "sent": "Very yes, strongly penalized, but again with what we learned so far, you could come up with a specific drift.",
                    "label": 0
                },
                {
                    "sent": "So the specific drift, again, I forgot the logarithm here.",
                    "label": 0
                },
                {
                    "sent": "So the specific drift is the gradient of the logarithm of Z.",
                    "label": 0
                },
                {
                    "sent": "And this said is this, so it's precisely.",
                    "label": 0
                },
                {
                    "sent": "It says you know you take your expectation.",
                    "label": 0
                },
                {
                    "sent": "Overall controlled uncontrolled paths and you penalize it with this type of likelihood term.",
                    "label": 0
                },
                {
                    "sent": "We're just simply say you is infinite whenever you're at the boundary or beyond.",
                    "label": 0
                },
                {
                    "sent": "If you're outside of your domain, and that should do the job, it just kills.",
                    "label": 0
                },
                {
                    "sent": "This mathematical expression just kills all the trajectory's that leave the boundary right?",
                    "label": 0
                },
                {
                    "sent": "So if U is 0 inside of inside of the domain in you is Infinity outside, then this is what you want, so it gives 0 probability to every random Walker to every diffuser that goes outside.",
                    "label": 0
                },
                {
                    "sent": "So again you have this thing.",
                    "label": 0
                },
                {
                    "sent": "Well, it obeys a linear equation.",
                    "label": 0
                },
                {
                    "sent": "The linear equation is again a simple diffusion equation with the boundary condition.",
                    "label": 0
                },
                {
                    "sent": "That you're there.",
                    "label": 0
                },
                {
                    "sent": "You have a zero at at the boundary and I hope so.",
                    "label": 0
                },
                {
                    "sent": "If you solve that when you get to the corresponding drift and you can simulate these guys with the first example.",
                    "label": 0
                },
                {
                    "sent": "Is that what Golightly called the Brownian Bridge?",
                    "label": 0
                },
                {
                    "sent": "Yeah, there's a brand new bridge, yes, so I don't know how they come up with that.",
                    "label": 0
                },
                {
                    "sent": "How they saw my car, but I just seen them use it if you tried, but is it the case that what you're saying with?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Call methodology gives you a more general way of coming up, so this is a very different thing that spherical constraint.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "Is it mean that you can easily come up with these new sort of constraints?",
                    "label": 0
                },
                {
                    "sent": "Yeah, well that's the question.",
                    "label": 0
                },
                {
                    "sent": "The easy.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The easy part is the easy part is.",
                    "label": 0
                },
                {
                    "sent": "I mean you end up with a.",
                    "label": 0
                },
                {
                    "sent": "You end up with such an object which you have to solve.",
                    "label": 0
                },
                {
                    "sent": "I mean it's a linear partial differential equation in some of the cases you can solve them in for a spherical constraint I can solve them there, that's just you know, probably Bessel functions or whatever.",
                    "label": 0
                },
                {
                    "sent": "And and yeah, so it depends.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's the answer.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you know if you constrain.",
                    "label": 0
                },
                {
                    "sent": "Have you seen this before?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I haven't seen.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is just more or less sort of last weeks where I thought about that.",
                    "label": 0
                },
                {
                    "sent": "Doing it this way, I expect of course.",
                    "label": 0
                },
                {
                    "sent": "I mean this the mathematical world is so huge and probably this is to stochastic analysis.",
                    "label": 0
                },
                {
                    "sent": "Guys at your first semester, whatever I don't know.",
                    "label": 0
                },
                {
                    "sent": "I mean I didn't know it, so it's just you know, I I stared at bed Coppens paper and say wow.",
                    "label": 0
                },
                {
                    "sent": "And how do you get this?",
                    "label": 0
                },
                {
                    "sent": "And then then?",
                    "label": 0
                },
                {
                    "sent": "Then you do this half page of derivatives first derivative, then a secondary.",
                    "label": 0
                },
                {
                    "sent": "Oh, I forgot this term.",
                    "label": 0
                },
                {
                    "sent": "You know multiplication rule and you see how would it becomes linear.",
                    "label": 0
                },
                {
                    "sent": "And so I just tried to simplify myself.",
                    "label": 0
                },
                {
                    "sent": "So I think it's more than that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but I I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't know if this is this is known or not, but probably it's known by somebody, right?",
                    "label": 0
                },
                {
                    "sent": "So I thought it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a neat method to sample.",
                    "label": 0
                },
                {
                    "sent": "OK, so the other thing is of course you know.",
                    "label": 0
                },
                {
                    "sent": "Bet bet Karpinen Manuel told her if they have now lots of papers where they apply this relation between inference and control.",
                    "label": 0
                },
                {
                    "sent": "But this is actually this holds only if we have this specific relation in the in the continuous time case between the noise that drives the system and the control cost.",
                    "label": 0
                },
                {
                    "sent": "So there is this funny matrix relationship, so the costs the matrix appearing in the costs have to be the inverse of the of the.",
                    "label": 0
                },
                {
                    "sent": "The driving noise, so you could say this is artificial and you would not always want this.",
                    "label": 0
                },
                {
                    "sent": "Could you use whatever we know about inference in order to solve that problems?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, I mean, I thought of course I mean just we copy our our paper.",
                    "label": 0
                },
                {
                    "sent": "So let's say we have this type of problem with the general matrix R, which is not the inverse D and then well, why not trying just to solve this problem using the stuff that we did with Cedric and and John Sean Taylor.",
                    "label": 1
                },
                {
                    "sent": "Just you know you don't look for the most general process that approximates that, but you just look at a linear and optimal.",
                    "label": 0
                },
                {
                    "sent": "A linear process that solves that minimizes this type of thing and just simply say, well, the control process should look like that, and in this case well, this as an approximation to that, and then you would say, well, in this case, the control is a linear part plus minus this.",
                    "label": 1
                },
                {
                    "sent": "This prior uncontrolled part, and then you go through the mathematics in the same way as we did for our inference problem with stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "I mean, the only thing is just this matrix is different in this case, but why not just applying the same type of stuff to that and and and do the linear the Gaussian variational principle with this loss function it's no longer a callback libel loss anymore, but you could do it at least and you would end up with nonlinear ODS for moments rather than the linear PDE.",
                    "label": 0
                },
                {
                    "sent": "So this is the first suggestion one could try that.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't be very expensive.",
                    "label": 0
                },
                {
                    "sent": "I don't know how if it would make sense or not, then of course, can you think of other loss functions that you might be able to tackle in that formalism so?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I construct me one that might that you might be able to do something just motivated by our work on approximate inference with.",
                    "label": 0
                },
                {
                    "sent": "You know, if you do approximate inference, we have these these gifts approximate Gibbs free energies.",
                    "label": 0
                },
                {
                    "sent": "If somebody remembers these these type of things there Gibbs free energies for for all kinds of approximate inference processes and usually what you then have to minimize.",
                    "label": 0
                },
                {
                    "sent": "Is an approximate free energy which is no longer a true free energy for an inference problem, and it has all kinds of things in it.",
                    "label": 0
                },
                {
                    "sent": "Convex and concave things, and it makes life so hard.",
                    "label": 0
                },
                {
                    "sent": "And there was an interesting development called the CCC thesis CP Algorithm, which says if I have costs which are combinations of sum of convex plus concave, I can use a neat trick to get kind of an iterative.",
                    "label": 0
                },
                {
                    "sent": "Minimization procedure so my idea would be then, well, you could maybe play with the following losses.",
                    "label": 0
                },
                {
                    "sent": "So this is too simple.",
                    "label": 0
                },
                {
                    "sent": "The Kullback Leiber losses to simple.",
                    "label": 0
                },
                {
                    "sent": "That's just normal inference that we do.",
                    "label": 0
                },
                {
                    "sent": "We can write down the global solution.",
                    "label": 0
                },
                {
                    "sent": "So what if we just take a bit of a callback, libel, Lausanne, subtract another cool work libel law, so that would say yeah, I penalize in the control problem.",
                    "label": 0
                },
                {
                    "sent": "I penalize my process by being too far away from one prior.",
                    "label": 0
                },
                {
                    "sent": "But I like it to be close to another one.",
                    "label": 0
                },
                {
                    "sent": "No far away from another one, so I just subtract another cool but library.",
                    "label": 0
                },
                {
                    "sent": "And then I say, well, I get in a similar style as these KPIs algorithms.",
                    "label": 0
                },
                {
                    "sent": "I'll just keep that and always upper bound this part by something linear in Q and so you could get an iterative procedure which would always minimize something an upper bound to this type of thing.",
                    "label": 0
                },
                {
                    "sent": "Until you get kind of a local minimum and actually, that brings me to the end of my my talk.",
                    "label": 0
                },
                {
                    "sent": "I don't have really any conclusion, it's more something you know that came up to my mind when I was in Holidays and I thought to myself, what should I talk about?",
                    "label": 0
                },
                {
                    "sent": "Should I talk about this stuff that I always talk about?",
                    "label": 0
                },
                {
                    "sent": "Or then I said, OK, maybe this is something, yeah?",
                    "label": 0
                },
                {
                    "sent": "That might amuse somebody or not.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The solution for the.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Random weapon and we boundary that with what?",
                    "label": 0
                },
                {
                    "sent": "Yes yes yes yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the question is how to simulate that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean you can calculate analytical solutions to it and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "To think that yeah.",
                    "label": 0
                },
                {
                    "sent": "Standard transformation that people use to link various problems in physics like colors in random media.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's a cold hop transformation, and it's it's a relation between CDP and it's the same, yes, right?",
                    "label": 0
                },
                {
                    "sent": "So you also brought me looking in a little bit into these hydrodynamic books than the Kohlhoff transformation relates relates to KPZ equation and the other thing I forgot the name.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, yeah yes precisely.",
                    "label": 0
                },
                {
                    "sent": "I mean when can cook up now a physics version of that and say.",
                    "label": 0
                },
                {
                    "sent": "It's all inference or what I did I didn't try this.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "I'm very sorry I couldn't comment on that.",
                    "label": 0
                },
                {
                    "sent": "That's a different thing because what Amos and Mark did.",
                    "label": 0
                },
                {
                    "sent": "Yes, it is very different.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Variety of different possible costs and it really is certain addition of just extending earlier work so that you can don't have a finite time horizon.",
                    "label": 0
                },
                {
                    "sent": "Very space is using.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So so, uh, thing where this doesn't apply is the case where you have discounted costs and your case would nicely work.",
                    "label": 0
                },
                {
                    "sent": "Work there because this discount is as soon as you put in a future.",
                    "label": 0
                },
                {
                    "sent": "Costs are discounted by by an exponential in time.",
                    "label": 0
                },
                {
                    "sent": "Then you know you have these individual costs that you add up together, but they don't add up to a global cool book library.",
                    "label": 0
                },
                {
                    "sent": "And then you're not getting into a linear kind of thing.",
                    "label": 0
                },
                {
                    "sent": "So even in a case where you have stationary problem, but in your algorithm would nicely deal with that.",
                    "label": 0
                },
                {
                    "sent": "So it seems to be different application domains.",
                    "label": 0
                },
                {
                    "sent": "One reason I really think this is.",
                    "label": 0
                },
                {
                    "sent": "I really think that this stuff is exciting and a lot of the stuff that's doing well.",
                    "label": 0
                },
                {
                    "sent": "It seems to touch on some of the stuff that Carl was saying yesterday, but this is really about decisions and it controls about decision.",
                    "label": 0
                },
                {
                    "sent": "Yes, and how much cost you pay for doing things.",
                    "label": 0
                },
                {
                    "sent": "So one thing that makes me nervous is like this.",
                    "label": 0
                },
                {
                    "sent": "I think it's a terrible thing when people just take a likelihood and say or say they got a quadratic cost in a problem.",
                    "label": 0
                },
                {
                    "sent": "So if if I'm selling lumber.",
                    "label": 0
                },
                {
                    "sent": "And the demand is heavy tailed, but I pay a quadratic cost for MIS estimating the demand.",
                    "label": 0
                },
                {
                    "sent": "If I if I do Bayesian inference with the quadratic cost, if I say my likelihood is a cost, I do extremely badly on.",
                    "label": 0
                },
                {
                    "sent": "That's true yes practice, whereas if I do use the heavy tail thing then then I do very well despite not taking account the cost in the infant stage.",
                    "label": 0
                },
                {
                    "sent": "How does this raise, I mean?",
                    "label": 0
                },
                {
                    "sent": "But is this getting around?",
                    "label": 0
                },
                {
                    "sent": "But somehow I uh?",
                    "label": 0
                },
                {
                    "sent": "I mean, I think the danger is a little bit here that not every cost that you really believe in it.",
                    "label": 0
                },
                {
                    "sent": "You think that the right ones are can be written as inference problems and it's not clear what to do then.",
                    "label": 0
                },
                {
                    "sent": "But maybe you want to do real Bayesian inference on top of a control problem, so I don't know that as another layer I mean.",
                    "label": 0
                },
                {
                    "sent": "It's a bit different, so at the moment this is Joni, just an interpretation of something is mathematically equivalent to something else, and there's something else is a Bayesian thing, so.",
                    "label": 0
                },
                {
                    "sent": "So it's not deep on a philosophical level, only on a mathematical level, so.",
                    "label": 0
                },
                {
                    "sent": "Can't make any conclusions beside that.",
                    "label": 0
                },
                {
                    "sent": "I've got another yeah.",
                    "label": 0
                },
                {
                    "sent": "For example, yes.",
                    "label": 0
                },
                {
                    "sent": "Done just by saying OK you you can write if save the sample at the end has got value 0 yes?",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "Do you expression?",
                    "label": 0
                },
                {
                    "sent": "Oh, you can also go through the analysis.",
                    "label": 0
                },
                {
                    "sent": "You look at the controlled diffusion equation and then you compute what the variance at time T is.",
                    "label": 0
                },
                {
                    "sent": "I mean this this various things that you want to know.",
                    "label": 0
                },
                {
                    "sent": "You can look at the covariance, but here I'm looking actually at the stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "If I want to draw samples.",
                    "label": 0
                },
                {
                    "sent": "So this is a bit more the Brownian Bridge, you can say, OK, this is a Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "As such, has such and such covariance, and then you know it.",
                    "label": 0
                },
                {
                    "sent": "But if you want to draw samples, if you want to represent it as a stochastic differential equation, then you have to use this.",
                    "label": 0
                },
                {
                    "sent": "So this is different things and if you look at the moments of these things then you end up with the original expressions.",
                    "label": 0
                },
                {
                    "sent": "You also know from the textbook, but the control diffusion is also known you for you.",
                    "label": 0
                },
                {
                    "sent": "I mean this is a standard thing.",
                    "label": 0
                },
                {
                    "sent": "You also find it textbooks if you want, you can use a non standalone back process again fix, fix the end point, then you get a controlled on standalone back process.",
                    "label": 0
                },
                {
                    "sent": "Should be in on central bank bridge.",
                    "label": 0
                },
                {
                    "sent": "Then also is possible.",
                    "label": 0
                },
                {
                    "sent": "More questions.",
                    "label": 0
                }
            ]
        }
    }
}