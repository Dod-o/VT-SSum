{
    "id": "3sglnvqbzdzwcw2q342aq33izfq3t535",
    "title": "A Generative Score Space for Statistical Dialog Characterization in social Signalling",
    "info": {
        "author": [
            "Marco Cristani, Department of Computer Science, University of Verona"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_cristani_gsss/",
    "segmentation": [
        [
            "So, um."
        ],
        [
            "Thank you for the introduction.",
            "The talk is organized as follow in the first part I will explain in a few words what's the aim of our approach.",
            "Then I will introduce the general framework in which our approach does lie and then I will detail the approach showing some experiments and concluding with summer."
        ],
        [
            "Marks so the goal is to model Dyadic conversation, which means conversation in which two persons are involved, taking into account for the audio data and the situation are characterized by the kind of subjects involved within.",
            "So we have people of different age, for example children and adults, and the predominant wood that holds.",
            "During all the conversation.",
            "So for example, we have flat conversation or Irving conversation.",
            "So I have here some example, maybe I can play for you later because we don't have.",
            "Just audio."
        ],
        [
            "Stuff, so the guidelines for the modeling is to take into account for the turn taking as blueprint for the conversation, and to disregard the actual speech recognition that that could be performed over the audio data.",
            "Just because we are not able to do that.",
            "So the contributes of our turkeys are two.",
            "The first is another kind of.",
            "Low level features to characterize the turn taking of conversation and 2nd is normal generative score pace, which means a novel, very simple way to use the generative models.",
            "So in practice we are able to model the turn taking, taking into account for the duration of the terms of silence and speech of each participant.",
            "And then.",
            "We use the generative models.",
            "As features for a discriminative classifier."
        ],
        [
            "Our approach can be cast in a social signaling framework where such a signal links is ideal.",
            "The ideal intersection between the social psychology and pattern recognition that tried to understand how people behave, taking into account for the social signals so you can see the definition of such as signals.",
            "And basically are.",
            "The expression of 1's attitude towards social interplay and he's such a senior is.",
            "Are built by behavioral cues that."
        ],
        [
            "Are these one can be grouped in these groups that are the behavioral cues of the forward posture of the hag of the mutual gaze gaster and interpersonal distance, so are a lot of signals that are not.",
            "Do not take into account for the content of social exchange.",
            "An so we are focusing on the vocal behavior that basically take into account the term taking mechanism of a conversation."
        ],
        [
            "So looking at these scheme, we can see two persons that are talking and we can see the audio signals.",
            "Basically we see in the first part we have the coordination at coordinated turn taking where a person talks the other.",
            "Remain in silence.",
            "The first person is inside us and then second person talks.",
            "So this means coordinated conversation.",
            "This is not coordinated conversation because the two people are talking together so message cannot pass from a person to the other and the actual approaches that take into account for the term taking our modeling this kind of.",
            "An effect if a conversation is coordinator or not.",
            "We are interested also in how much are along the terms of the conversation.",
            "Because psychological findings states that are important, even the periods of silence in a conversation are really important, so we want to take into account for all.",
            "The coordination and the timing of the coordination."
        ],
        [
            "So how to do that in a statistical way?",
            "The most straightforward is to change it to account for single audio signal performed by produced by a person and to sample it, considering that each sample the states of the signals could be talk or silence.",
            "OK, so in a statistical way we can model these personal audio signal using a Markov model.",
            "That is OK, is straightforward, and the formalisation is over here we have a set of states.",
            "In our case, torque and silence.",
            "We have a transition probability and we have initial state hypothesis that has how probably is to start with a torque or silent states."
        ],
        [
            "But this is get more interesting when we consider a conversation so different audio signals.",
            "So we want to model using a Markov reasoning and in order to do that we have to use coupled Markov model that take into account for different Markov chains.",
            "So basically we are interested in the transition probability that is written over here in which we have process C and process D. That are at time T in the state J an H given the previous states of the two processes.",
            "So if we take into account for this, all probability considering the combination of the two states, we basically.",
            "Have a novel.",
            "Structure states, which is more complex and the problem is that.",
            "If we have to learn such a transition probability among these structured states, the transition probability is very large and sparse, and this is not good for the modeling.",
            "So the problem is the computational burden.",
            "As you can see, for see processes the joint states that we can see also over here bring to a very large transition matrix."
        ],
        [
            "So the solution for this problem is to use the mix of memory Markov process or the influence the observed influence model that basically the couple the probability of a single process given the previous states of the two processes.",
            "As I waited.",
            "Combination of pairwise probabilities.",
            "As you can see here, we have the pairwise probability among two processes.",
            "Bye.",
            "Wait, which is called influence weight.",
            "So basically each single process choose the next state, not considering all.",
            "The core the coral effect of the system at the previous time step, but only take into account for each process for each person in the conversation at a time.",
            "So this is brings to losing something as modeling power, but is good.",
            "Compromise.",
            "These factors basically tells how much the states of a process are important for the siding.",
            "The states of all the other processes."
        ],
        [
            "So once we learn this model, considering always two person conversation, we have interchange transition that has how a single processor evolves.",
            "During time and Interchain transition that basically tells us how probably is that I choose, for example, a state of silence when the previous time step.",
            "The other processes was in speech or in silence, so the transition tables of these models are more, let's say, economic in computational."
        ],
        [
            "Arms.",
            "So get into the data we are.",
            "We focus on two person conversation.",
            "The conversation originates a couple of synchronized audio.",
            "See sample a certain rate.",
            "And what we do is to assign at each sample a state for each audio signal.",
            "So we have.",
            "Talk science, dog science and so on."
        ],
        [
            "If we fit the mixer memory process in this framework, we learned sort certain model but is not so informative just cause we can see here that the transition over the same states dominates.",
            "Over the transition that occurs between different states.",
            "So it turns out that the transition matrices are highly diagonal, so are not able to model very well a conversation and the length of the speech and silent segments is lost."
        ],
        [
            "Our contribution is to.",
            "Proposed steady conversational periods that basically say that whenever there is a change in the configuration of the whole conversation, we insert like a break over here and over here because there is a person that stops to talk.",
            "And begins to talk and so on.",
            "So.",
            "We can enumerate these intervals using TT then.",
            "Like in the figure, so we have at the end of these segmentation.",
            "TT them which is less than the time T of the conversation that introduce a synchronization between the two processes.",
            "So.",
            "The SCP our novel features is basically composed by two information.",
            "The one is the state of a single segment.",
            "For example, here we have SCP, which is characterized by silence States and the duration.",
            "Of this segment.",
            "So here for example, we have a segment South CP of state T and the duration the same of the first segment below."
        ],
        [
            "And this is what we obtain, so we can see the different as CP of the conversation.",
            "So we want to fit an influence model over this novel characterization.",
            "Problem is that in order to use a classical Markov model.",
            "We have two symbols, one symbols, the duration of the segment and the second the state of the segment.",
            "So we can produce state renaming.",
            "So basically saying that OK I have the segment that holds for one frame and is silent.",
            "So we have states number one.",
            "We have a segment that hold for one frame and is this is by a person that talks.",
            "So we have states number 2 and so on, so 4.",
            "This brings to a state run a huge state for naming that creates a lot of states, so even this creates a problem in the learning.",
            "So we have again very sparse transition metrics."
        ],
        [
            "What we do is to cluster.",
            "To quantized the duration.",
            "Off the segment.",
            "Enough with a set of Goshen in order to decrease the number of possible states."
        ],
        [
            "In this way.",
            "So.",
            "We have two kinds of quantization, one for the duration of the Silence segment and one for the duration of the speech segments.",
            "Using this quantization you can.",
            "We can rename each segment using very inferior number of.",
            "Symbols.",
            "Arriving to this situation in which we have.",
            "Such a renaming for the conversation.",
            "So once we have this novel characterization of dialogue, we can fit unobserved the flash mode."
        ],
        [
            "After the training we have two interchain matrices that tell how each agent produced a set of.",
            "SCP states.",
            "Two interchain matrices that tell how each SCP states of one person is conditioning on each state of the other chain, and an influence metrics that carries out the two chains influence each other.",
            "So basically this allows me to say, OK, I'm in the state of long silence.",
            "The probability of choose states of shorts.",
            "Which is given by the long silence of me and on the states of the other process.",
            "So this insert in the modeling the duration.",
            "Of the term."
        ],
        [
            "So how to use the model for classification?",
            "Let's suppose that we have different classes of conversation.",
            "We can model in a maximum likelihood wave, for example, using the training set, we learn a model.",
            "We do the same for all the classes are.",
            "Once we have a test sequence, we measured the likelihood of each of the model and we select the maximum one or in another way as feature.",
            "So we take.",
            "All the parameters of the servant influence model and we put these parameters in a feature space.",
            "So we use the parameters in this case is simplifying the modeling.",
            "Suppose that we have for each conversation two parameters.",
            "We can see each point over is over here, like a conversation.",
            "So we will have the points of the conversation of Class One and point of the conversation Class 2.",
            "Once we have a novel.",
            "Conversation we can learn and influence and observed influence model using the SPL Info, which is the class that model best that point."
        ],
        [
            "So in such space we can perform it's very interesting feature selection strategies to see which features which means which parameters are more important for that conversation.",
            "So in this way the feature selection help in understanding which portions of the models or which parameters are more important, important for discriminating among different classes?",
            "And this is just similar to the Fisher score approaches that are based on the derivative of the model log likelihood that are more complex and do not offer such direct understanding."
        ],
        [
            "Of the problem.",
            "So the data set that we use is formed by 41 dialogic conversation where we have 13 flat semi structured plus 5 flat unstructured dialogues where semi structured means that we have an operator that ask a set of questions to the other person involved in conversation.",
            "We have 14 flat semi structured dialogues between a child arranging for four to six years and an adult and we have 9 arguing unstructured dialogues between 2 adults and each conversation holds for 10 minutes theater.",
            "And we instantiate four classification tasks in order to discriminate between flat and this.",
            "Put conversation between flat and dispute, including also the class of the child conversation.",
            "We want to discover if a conversation has are not child and we perform also the old versus old classification task."
        ],
        [
            "Classification is validated using a live one out strategy, an different classifier in the feature in the generative score space are used.",
            "For example, color bays or K&N or piece parts and based the best being the color based.",
            "So.",
            "We perform the generative classical generative classification using the maximum likelihood parting.",
            "Obtaining these numbers, and we use the generative score space in these two cases without performing the feature selection.",
            "So keeping all the parameters in order to learn, for example South Machine and perform feature selection in order to have.",
            "Further, number of features and learning and SVM for each class and then performing the classification so that you as you can see the generative score space is able to boost the performance of classification in all the cases.",
            "And it's even better when you perform the feature selection, so you discard a lot of parameters that basically are similar for all two different classes.",
            "We tried also two augment the order of the Markov model that is the core of our observed influence Model 2 two and we observe that in general the performance are not superior to the ones we obtain using the 1st order reasoning and these.",
            "Reasonably be cause we do not too, with the 2nd order we have over fitting in the learning, but even in the 2nd order case, using the generative score space, so using the models as points in feature space we increased the classification performances.",
            "And this is even stronger using the feature selection."
        ],
        [
            "So concluding, we introduce a novel way to model dialogues as Markov processes.",
            "Where will we use another kind of features?",
            "Name of this TD conversation or periods, and another way to use the generative models as features.",
            "And the future improvements are too.",
            "Make the model more complex.",
            "Insert in taking into account, for example, two different different number of participants in the conversation.",
            "And from a practical point of view, using a larger data set and try to know to take into account for novel situation and actually we perform novel experiments on a public database of political debates where there are different number of person that are talking each other and sometimes that get angry and they fight and we are able actually using this framework to segment.",
            "All the conversation saying when the the two or more person are fighting or not and this is a very interesting results that I hope that will be published in the next future so."
        ],
        [
            "This concludes the talks, thank you and looking for questions.",
            "Are there questions?",
            "Yes, so when you have the waveforms there, have you considered also taking into account for instance features like the pitch?",
            "Very simple.",
            "Yeah, OK, we try to compare using prosody features like pitch and another.",
            "Another similar features.",
            "The problem is that when you have female and child's, they tend to be model as the in the in the same class, which means that using only browser they are classical audio features, is not enough to separate classes, maybe as a combination.",
            "Yeah yeah yeah, maybe at least for that dispute versus flat.",
            "Yeah, the problem is that you see during a dispute person tend to OK have higher pitch, for example, but this is not always the case.",
            "Sometimes is not so so easy to discover this kind of segmentation using only the pitch.",
            "So so I was.",
            "I was wondering in which way?",
            "Pencil in cultural background or on society background.",
            "So you had it for example.",
            "Or just make up an example.",
            "Some dispute in the Italian Parliament, OK?",
            "Yeah, actually the dispute in the in this data set are in the Italian language, while the the political debates are using are in French.",
            "So we are waiting for different really different.",
            "Data sets in different languages, but we think that we have more robustness using this mechanism instead of doing speech recognition in different languages because it's harder and.",
            "And so.",
            "Any further questions or comments or."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you for the introduction.",
                    "label": 0
                },
                {
                    "sent": "The talk is organized as follow in the first part I will explain in a few words what's the aim of our approach.",
                    "label": 1
                },
                {
                    "sent": "Then I will introduce the general framework in which our approach does lie and then I will detail the approach showing some experiments and concluding with summer.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Marks so the goal is to model Dyadic conversation, which means conversation in which two persons are involved, taking into account for the audio data and the situation are characterized by the kind of subjects involved within.",
                    "label": 1
                },
                {
                    "sent": "So we have people of different age, for example children and adults, and the predominant wood that holds.",
                    "label": 0
                },
                {
                    "sent": "During all the conversation.",
                    "label": 0
                },
                {
                    "sent": "So for example, we have flat conversation or Irving conversation.",
                    "label": 0
                },
                {
                    "sent": "So I have here some example, maybe I can play for you later because we don't have.",
                    "label": 0
                },
                {
                    "sent": "Just audio.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stuff, so the guidelines for the modeling is to take into account for the turn taking as blueprint for the conversation, and to disregard the actual speech recognition that that could be performed over the audio data.",
                    "label": 0
                },
                {
                    "sent": "Just because we are not able to do that.",
                    "label": 0
                },
                {
                    "sent": "So the contributes of our turkeys are two.",
                    "label": 0
                },
                {
                    "sent": "The first is another kind of.",
                    "label": 0
                },
                {
                    "sent": "Low level features to characterize the turn taking of conversation and 2nd is normal generative score pace, which means a novel, very simple way to use the generative models.",
                    "label": 1
                },
                {
                    "sent": "So in practice we are able to model the turn taking, taking into account for the duration of the terms of silence and speech of each participant.",
                    "label": 1
                },
                {
                    "sent": "And then.",
                    "label": 1
                },
                {
                    "sent": "We use the generative models.",
                    "label": 0
                },
                {
                    "sent": "As features for a discriminative classifier.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach can be cast in a social signaling framework where such a signal links is ideal.",
                    "label": 0
                },
                {
                    "sent": "The ideal intersection between the social psychology and pattern recognition that tried to understand how people behave, taking into account for the social signals so you can see the definition of such as signals.",
                    "label": 0
                },
                {
                    "sent": "And basically are.",
                    "label": 0
                },
                {
                    "sent": "The expression of 1's attitude towards social interplay and he's such a senior is.",
                    "label": 1
                },
                {
                    "sent": "Are built by behavioral cues that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are these one can be grouped in these groups that are the behavioral cues of the forward posture of the hag of the mutual gaze gaster and interpersonal distance, so are a lot of signals that are not.",
                    "label": 0
                },
                {
                    "sent": "Do not take into account for the content of social exchange.",
                    "label": 0
                },
                {
                    "sent": "An so we are focusing on the vocal behavior that basically take into account the term taking mechanism of a conversation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So looking at these scheme, we can see two persons that are talking and we can see the audio signals.",
                    "label": 0
                },
                {
                    "sent": "Basically we see in the first part we have the coordination at coordinated turn taking where a person talks the other.",
                    "label": 1
                },
                {
                    "sent": "Remain in silence.",
                    "label": 0
                },
                {
                    "sent": "The first person is inside us and then second person talks.",
                    "label": 0
                },
                {
                    "sent": "So this means coordinated conversation.",
                    "label": 0
                },
                {
                    "sent": "This is not coordinated conversation because the two people are talking together so message cannot pass from a person to the other and the actual approaches that take into account for the term taking our modeling this kind of.",
                    "label": 0
                },
                {
                    "sent": "An effect if a conversation is coordinator or not.",
                    "label": 0
                },
                {
                    "sent": "We are interested also in how much are along the terms of the conversation.",
                    "label": 0
                },
                {
                    "sent": "Because psychological findings states that are important, even the periods of silence in a conversation are really important, so we want to take into account for all.",
                    "label": 0
                },
                {
                    "sent": "The coordination and the timing of the coordination.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how to do that in a statistical way?",
                    "label": 0
                },
                {
                    "sent": "The most straightforward is to change it to account for single audio signal performed by produced by a person and to sample it, considering that each sample the states of the signals could be talk or silence.",
                    "label": 0
                },
                {
                    "sent": "OK, so in a statistical way we can model these personal audio signal using a Markov model.",
                    "label": 1
                },
                {
                    "sent": "That is OK, is straightforward, and the formalisation is over here we have a set of states.",
                    "label": 0
                },
                {
                    "sent": "In our case, torque and silence.",
                    "label": 0
                },
                {
                    "sent": "We have a transition probability and we have initial state hypothesis that has how probably is to start with a torque or silent states.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But this is get more interesting when we consider a conversation so different audio signals.",
                    "label": 0
                },
                {
                    "sent": "So we want to model using a Markov reasoning and in order to do that we have to use coupled Markov model that take into account for different Markov chains.",
                    "label": 0
                },
                {
                    "sent": "So basically we are interested in the transition probability that is written over here in which we have process C and process D. That are at time T in the state J an H given the previous states of the two processes.",
                    "label": 0
                },
                {
                    "sent": "So if we take into account for this, all probability considering the combination of the two states, we basically.",
                    "label": 0
                },
                {
                    "sent": "Have a novel.",
                    "label": 0
                },
                {
                    "sent": "Structure states, which is more complex and the problem is that.",
                    "label": 0
                },
                {
                    "sent": "If we have to learn such a transition probability among these structured states, the transition probability is very large and sparse, and this is not good for the modeling.",
                    "label": 1
                },
                {
                    "sent": "So the problem is the computational burden.",
                    "label": 1
                },
                {
                    "sent": "As you can see, for see processes the joint states that we can see also over here bring to a very large transition matrix.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the solution for this problem is to use the mix of memory Markov process or the influence the observed influence model that basically the couple the probability of a single process given the previous states of the two processes.",
                    "label": 0
                },
                {
                    "sent": "As I waited.",
                    "label": 0
                },
                {
                    "sent": "Combination of pairwise probabilities.",
                    "label": 0
                },
                {
                    "sent": "As you can see here, we have the pairwise probability among two processes.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "Wait, which is called influence weight.",
                    "label": 0
                },
                {
                    "sent": "So basically each single process choose the next state, not considering all.",
                    "label": 0
                },
                {
                    "sent": "The core the coral effect of the system at the previous time step, but only take into account for each process for each person in the conversation at a time.",
                    "label": 0
                },
                {
                    "sent": "So this is brings to losing something as modeling power, but is good.",
                    "label": 0
                },
                {
                    "sent": "Compromise.",
                    "label": 0
                },
                {
                    "sent": "These factors basically tells how much the states of a process are important for the siding.",
                    "label": 0
                },
                {
                    "sent": "The states of all the other processes.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So once we learn this model, considering always two person conversation, we have interchange transition that has how a single processor evolves.",
                    "label": 1
                },
                {
                    "sent": "During time and Interchain transition that basically tells us how probably is that I choose, for example, a state of silence when the previous time step.",
                    "label": 0
                },
                {
                    "sent": "The other processes was in speech or in silence, so the transition tables of these models are more, let's say, economic in computational.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Arms.",
                    "label": 0
                },
                {
                    "sent": "So get into the data we are.",
                    "label": 0
                },
                {
                    "sent": "We focus on two person conversation.",
                    "label": 0
                },
                {
                    "sent": "The conversation originates a couple of synchronized audio.",
                    "label": 1
                },
                {
                    "sent": "See sample a certain rate.",
                    "label": 0
                },
                {
                    "sent": "And what we do is to assign at each sample a state for each audio signal.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "Talk science, dog science and so on.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we fit the mixer memory process in this framework, we learned sort certain model but is not so informative just cause we can see here that the transition over the same states dominates.",
                    "label": 0
                },
                {
                    "sent": "Over the transition that occurs between different states.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that the transition matrices are highly diagonal, so are not able to model very well a conversation and the length of the speech and silent segments is lost.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our contribution is to.",
                    "label": 0
                },
                {
                    "sent": "Proposed steady conversational periods that basically say that whenever there is a change in the configuration of the whole conversation, we insert like a break over here and over here because there is a person that stops to talk.",
                    "label": 1
                },
                {
                    "sent": "And begins to talk and so on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We can enumerate these intervals using TT then.",
                    "label": 1
                },
                {
                    "sent": "Like in the figure, so we have at the end of these segmentation.",
                    "label": 1
                },
                {
                    "sent": "TT them which is less than the time T of the conversation that introduce a synchronization between the two processes.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The SCP our novel features is basically composed by two information.",
                    "label": 0
                },
                {
                    "sent": "The one is the state of a single segment.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have SCP, which is characterized by silence States and the duration.",
                    "label": 0
                },
                {
                    "sent": "Of this segment.",
                    "label": 0
                },
                {
                    "sent": "So here for example, we have a segment South CP of state T and the duration the same of the first segment below.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is what we obtain, so we can see the different as CP of the conversation.",
                    "label": 0
                },
                {
                    "sent": "So we want to fit an influence model over this novel characterization.",
                    "label": 0
                },
                {
                    "sent": "Problem is that in order to use a classical Markov model.",
                    "label": 0
                },
                {
                    "sent": "We have two symbols, one symbols, the duration of the segment and the second the state of the segment.",
                    "label": 0
                },
                {
                    "sent": "So we can produce state renaming.",
                    "label": 0
                },
                {
                    "sent": "So basically saying that OK I have the segment that holds for one frame and is silent.",
                    "label": 0
                },
                {
                    "sent": "So we have states number one.",
                    "label": 0
                },
                {
                    "sent": "We have a segment that hold for one frame and is this is by a person that talks.",
                    "label": 0
                },
                {
                    "sent": "So we have states number 2 and so on, so 4.",
                    "label": 0
                },
                {
                    "sent": "This brings to a state run a huge state for naming that creates a lot of states, so even this creates a problem in the learning.",
                    "label": 0
                },
                {
                    "sent": "So we have again very sparse transition metrics.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do is to cluster.",
                    "label": 0
                },
                {
                    "sent": "To quantized the duration.",
                    "label": 0
                },
                {
                    "sent": "Off the segment.",
                    "label": 0
                },
                {
                    "sent": "Enough with a set of Goshen in order to decrease the number of possible states.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this way.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have two kinds of quantization, one for the duration of the Silence segment and one for the duration of the speech segments.",
                    "label": 0
                },
                {
                    "sent": "Using this quantization you can.",
                    "label": 0
                },
                {
                    "sent": "We can rename each segment using very inferior number of.",
                    "label": 0
                },
                {
                    "sent": "Symbols.",
                    "label": 0
                },
                {
                    "sent": "Arriving to this situation in which we have.",
                    "label": 0
                },
                {
                    "sent": "Such a renaming for the conversation.",
                    "label": 0
                },
                {
                    "sent": "So once we have this novel characterization of dialogue, we can fit unobserved the flash mode.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After the training we have two interchain matrices that tell how each agent produced a set of.",
                    "label": 1
                },
                {
                    "sent": "SCP states.",
                    "label": 0
                },
                {
                    "sent": "Two interchain matrices that tell how each SCP states of one person is conditioning on each state of the other chain, and an influence metrics that carries out the two chains influence each other.",
                    "label": 1
                },
                {
                    "sent": "So basically this allows me to say, OK, I'm in the state of long silence.",
                    "label": 0
                },
                {
                    "sent": "The probability of choose states of shorts.",
                    "label": 0
                },
                {
                    "sent": "Which is given by the long silence of me and on the states of the other process.",
                    "label": 0
                },
                {
                    "sent": "So this insert in the modeling the duration.",
                    "label": 0
                },
                {
                    "sent": "Of the term.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how to use the model for classification?",
                    "label": 1
                },
                {
                    "sent": "Let's suppose that we have different classes of conversation.",
                    "label": 0
                },
                {
                    "sent": "We can model in a maximum likelihood wave, for example, using the training set, we learn a model.",
                    "label": 0
                },
                {
                    "sent": "We do the same for all the classes are.",
                    "label": 0
                },
                {
                    "sent": "Once we have a test sequence, we measured the likelihood of each of the model and we select the maximum one or in another way as feature.",
                    "label": 0
                },
                {
                    "sent": "So we take.",
                    "label": 1
                },
                {
                    "sent": "All the parameters of the servant influence model and we put these parameters in a feature space.",
                    "label": 1
                },
                {
                    "sent": "So we use the parameters in this case is simplifying the modeling.",
                    "label": 0
                },
                {
                    "sent": "Suppose that we have for each conversation two parameters.",
                    "label": 0
                },
                {
                    "sent": "We can see each point over is over here, like a conversation.",
                    "label": 0
                },
                {
                    "sent": "So we will have the points of the conversation of Class One and point of the conversation Class 2.",
                    "label": 0
                },
                {
                    "sent": "Once we have a novel.",
                    "label": 0
                },
                {
                    "sent": "Conversation we can learn and influence and observed influence model using the SPL Info, which is the class that model best that point.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in such space we can perform it's very interesting feature selection strategies to see which features which means which parameters are more important for that conversation.",
                    "label": 0
                },
                {
                    "sent": "So in this way the feature selection help in understanding which portions of the models or which parameters are more important, important for discriminating among different classes?",
                    "label": 1
                },
                {
                    "sent": "And this is just similar to the Fisher score approaches that are based on the derivative of the model log likelihood that are more complex and do not offer such direct understanding.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the problem.",
                    "label": 0
                },
                {
                    "sent": "So the data set that we use is formed by 41 dialogic conversation where we have 13 flat semi structured plus 5 flat unstructured dialogues where semi structured means that we have an operator that ask a set of questions to the other person involved in conversation.",
                    "label": 1
                },
                {
                    "sent": "We have 14 flat semi structured dialogues between a child arranging for four to six years and an adult and we have 9 arguing unstructured dialogues between 2 adults and each conversation holds for 10 minutes theater.",
                    "label": 1
                },
                {
                    "sent": "And we instantiate four classification tasks in order to discriminate between flat and this.",
                    "label": 0
                },
                {
                    "sent": "Put conversation between flat and dispute, including also the class of the child conversation.",
                    "label": 0
                },
                {
                    "sent": "We want to discover if a conversation has are not child and we perform also the old versus old classification task.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Classification is validated using a live one out strategy, an different classifier in the feature in the generative score space are used.",
                    "label": 1
                },
                {
                    "sent": "For example, color bays or K&N or piece parts and based the best being the color based.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We perform the generative classical generative classification using the maximum likelihood parting.",
                    "label": 0
                },
                {
                    "sent": "Obtaining these numbers, and we use the generative score space in these two cases without performing the feature selection.",
                    "label": 0
                },
                {
                    "sent": "So keeping all the parameters in order to learn, for example South Machine and perform feature selection in order to have.",
                    "label": 0
                },
                {
                    "sent": "Further, number of features and learning and SVM for each class and then performing the classification so that you as you can see the generative score space is able to boost the performance of classification in all the cases.",
                    "label": 0
                },
                {
                    "sent": "And it's even better when you perform the feature selection, so you discard a lot of parameters that basically are similar for all two different classes.",
                    "label": 0
                },
                {
                    "sent": "We tried also two augment the order of the Markov model that is the core of our observed influence Model 2 two and we observe that in general the performance are not superior to the ones we obtain using the 1st order reasoning and these.",
                    "label": 0
                },
                {
                    "sent": "Reasonably be cause we do not too, with the 2nd order we have over fitting in the learning, but even in the 2nd order case, using the generative score space, so using the models as points in feature space we increased the classification performances.",
                    "label": 0
                },
                {
                    "sent": "And this is even stronger using the feature selection.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So concluding, we introduce a novel way to model dialogues as Markov processes.",
                    "label": 1
                },
                {
                    "sent": "Where will we use another kind of features?",
                    "label": 0
                },
                {
                    "sent": "Name of this TD conversation or periods, and another way to use the generative models as features.",
                    "label": 1
                },
                {
                    "sent": "And the future improvements are too.",
                    "label": 0
                },
                {
                    "sent": "Make the model more complex.",
                    "label": 0
                },
                {
                    "sent": "Insert in taking into account, for example, two different different number of participants in the conversation.",
                    "label": 1
                },
                {
                    "sent": "And from a practical point of view, using a larger data set and try to know to take into account for novel situation and actually we perform novel experiments on a public database of political debates where there are different number of person that are talking each other and sometimes that get angry and they fight and we are able actually using this framework to segment.",
                    "label": 0
                },
                {
                    "sent": "All the conversation saying when the the two or more person are fighting or not and this is a very interesting results that I hope that will be published in the next future so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This concludes the talks, thank you and looking for questions.",
                    "label": 0
                },
                {
                    "sent": "Are there questions?",
                    "label": 0
                },
                {
                    "sent": "Yes, so when you have the waveforms there, have you considered also taking into account for instance features like the pitch?",
                    "label": 0
                },
                {
                    "sent": "Very simple.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, we try to compare using prosody features like pitch and another.",
                    "label": 0
                },
                {
                    "sent": "Another similar features.",
                    "label": 0
                },
                {
                    "sent": "The problem is that when you have female and child's, they tend to be model as the in the in the same class, which means that using only browser they are classical audio features, is not enough to separate classes, maybe as a combination.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah, maybe at least for that dispute versus flat.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the problem is that you see during a dispute person tend to OK have higher pitch, for example, but this is not always the case.",
                    "label": 0
                },
                {
                    "sent": "Sometimes is not so so easy to discover this kind of segmentation using only the pitch.",
                    "label": 0
                },
                {
                    "sent": "So so I was.",
                    "label": 0
                },
                {
                    "sent": "I was wondering in which way?",
                    "label": 0
                },
                {
                    "sent": "Pencil in cultural background or on society background.",
                    "label": 0
                },
                {
                    "sent": "So you had it for example.",
                    "label": 0
                },
                {
                    "sent": "Or just make up an example.",
                    "label": 0
                },
                {
                    "sent": "Some dispute in the Italian Parliament, OK?",
                    "label": 0
                },
                {
                    "sent": "Yeah, actually the dispute in the in this data set are in the Italian language, while the the political debates are using are in French.",
                    "label": 0
                },
                {
                    "sent": "So we are waiting for different really different.",
                    "label": 0
                },
                {
                    "sent": "Data sets in different languages, but we think that we have more robustness using this mechanism instead of doing speech recognition in different languages because it's harder and.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "Any further questions or comments or.",
                    "label": 0
                }
            ]
        }
    }
}