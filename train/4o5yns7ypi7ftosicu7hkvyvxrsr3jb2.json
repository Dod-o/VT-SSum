{
    "id": "4o5yns7ypi7ftosicu7hkvyvxrsr3jb2",
    "title": "Machine Learning and Signal Processing Tools for BCI",
    "info": {
        "author": [
            "Klaus-Robert M\u00fcller, Department of Software Engineering and Theoretical Computer Science, Technische Universit\u00e4t Berlin",
            "Benjamin Blankertz, Machine Learning and Intelligent Data Analysis Group, TU Berlin"
        ],
        "published": "Aug. 10, 2009",
        "recorded": "July 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bbci09_blankertz_muller_mlasp/",
    "segmentation": [
        [
            "Thank you Steve and of course you always have to ask the organizers for inviting so.",
            "So this is a joint.",
            "Talk with Benjamin and I think one or one of the points that I would like to make first is if you do a machine.",
            "If you do a BCI project, there's lots of people that should be on."
        ],
        [
            "Slide.",
            "And I put them on the slide.",
            "So we would like to thank all of them and all the collaborations and all the funders in particular EU being BF&FG as a starting point."
        ],
        [
            "Find.",
            "So as Gob little has been talking just before me.",
            "So you will recognize some of the slides.",
            "In fact, we have a very close collaboration.",
            "As you saw from the last slide and but.",
            "I I will just gently remind you of the content and I will put it in in different words and from a different perspective.",
            "So I think 11 important point to make is that I will be talking about machine learning methods for non invasive brain computer interfacing together with Benjamin and we will be mostly talking about this part.",
            "The part that Gabriel has left out.",
            "Just before we will.",
            "Really start and go into details so I'm just to to get your mindset ready for this while Gabriel was giving you the Physiology will give you the math, so this will be quite serious and lots of formulas.",
            "Just as a disclaimer, I mean Benyamin is shaking his head so so don't worry.",
            "So the formula translation of a BCI is.",
            "We translate human intentions into technical control signals without using muscle activity or peripheral nerve activity.",
            "I think we should be very clear with this statement, so we're not having EMG brain computer interfaces."
        ],
        [
            "So you've seen videos from Gabriel side.",
            "This is another video and.",
            "So this is a control of the game pong I'm controlling the pedal down there by thinking left and right.",
            "Alternatively, just in order to hit the ball as often as possible.",
            "And if you could see the full picture, you could see that there are lots of EMG electrodes put all over the place just to control whether I'm using EMG at all.",
            "OK, so I'm not using it.",
            "And also we put usually some electrodes here to measure the electrocardiogram.",
            "Also to rule out that we are controlling things with our eyes and their respective brain signals that come with our eyes signals with our eye movements.",
            "So as Gabriele also has mentioned.",
            "If you do noninvasive brain computer interfacing with human subjects, you can ask them how they felt in this kind of experiment, and I'm I'm ready to to tell you this is, I think, was my my second experiment ever, and.",
            "I was actually trying to control the the cursor by.",
            "Thinking about pulling a string to the left and to the right.",
            "So I was thinking about something physical.",
            "But I was not moving anything as you've seen from the from the video.",
            "I did this maybe for half an hour, deliberately relaxing.",
            "Focusing on the activity left and right movement.",
            "And after half an hour, I realized that I could place the cursor wherever I wanted on the screen.",
            "So all of a sudden this this cursor became like as a gobble.",
            "Pointed out, it became like a part of my body.",
            "It became like a tool like a tennis record.",
            "If I play tennis, I'm not thinking about, you know the extension of my arm.",
            "If I play tennis, so this was a very interesting experience and also this just to finish the story.",
            "After about one hour away I could absolutely control without.",
            "Deliberately thinking about, say, pulling a string.",
            "This changed again and I lost control in that manner and I had to resume pulling strings OK and I got tired in the meantime, so there was actually some nonstationarity going on.",
            "I will.",
            "We will discuss this part.",
            "Later in the talk."
        ],
        [
            "Rock.",
            "So, as was already pointed out.",
            "Clearly we are not the first to have invented brain computer interfacing.",
            "Just as a personal impression.",
            "When I got into this field, I'm actually.",
            "An expert in machine learning and signal processing so so I was always interested in e.g.",
            "So maybe I did my first papers on that in 95 an around 2000.",
            "I started thinking well if I can analyze e.g on a single trial basis why not use it to control things?",
            "And of course I realized that there was a community out there that did this already and I went.",
            "Two for trailers, Nappanee E Baum's lap and I went to Albany and talk to John and Teresa and they were actually very, very friendly and helped me a lot getting into this field because my view at that time was we shouldn't have the patience or the subjects learn, but the machines should do that otherwise.",
            "I mean, where's my contribution?",
            "OK, as a machine learner.",
            "OK, so."
        ],
        [
            "Um?",
            "Clearly EG is about Electra.",
            "Electrical signals that you can measure."
        ],
        [
            "We've seen that clearly.",
            "There's some problems, and you've seen this slide, but I added something.",
            "So there's this little drawing.",
            "So.",
            "In my in one of my former lives, I was very active in independent component analysis and independent component analyzes.",
            "You typically have the acoustic cocktail party problem where you have many speakers talking at the same time, and you've tried to filter out what the neighbor says that you're talking to.",
            "And as was pointed out in the by Gabriele, we have a very similar situation here.",
            "Because electromagnetic waves superimpose, in fact linearly.",
            "And what we have in the acoustic cocktail party problem is actually.",
            "A much more difficult problem to be precise because we have a convolution.",
            "You see that that's an echo, so if you do acoustic acoustic cocktail party problem, then you have to deal with these Echo Hall and long reverberations.",
            "So here you don't.",
            "So the idea in the first step is to focus on signals that we are.",
            "Able to hub harvest in the sense they are useful for decoding.",
            "There lots of things going on, but they are not useful for the decoding purpose, so we have to treat them as noise.",
            "In other words, we have to find some projection in sensor space and I'm actually a painting of drawing a very simple sensor space here.",
            "It's only two dimensional.",
            "Usually we have 64 dimensional sensor spaces and the data is lying there as as a cloud.",
            "And we would like to.",
            "Focus on some activity of some brain areas that we're interested in, meaning we have to find some projections in this 64 dimensional space that.",
            "Help us decoding and.",
            "To help us get rid of all the noise and I put noise in quotes here, OK.",
            "So ICA happens to be a method that can be used there, but other further methods that can be.",
            "I'm pleased like NGC and others.",
            "I will not go into this part."
        ],
        [
            "In details.",
            "So when when you saw me doing the brain pong game I was using one particular motor imaginary, which is pulling a string.",
            "There's lots of other possibilities, so our subjects they typically think about squeezing a ball, kicking a ball.",
            "Some Brazilian subjects would always kick a ball field touch field, sense they feel heat.",
            "Whatever, so this is some kind of imaginary that you would be."
        ],
        [
            "Using.",
            "An so.",
            "If you look at the slide.",
            "Gobble has pointed out that there's some desynchronization.",
            "If you so, if you close your eyes as I I'm doing here, this is a picture that cannot gave me.",
            "And so then there's some Alpha activity.",
            "If you.",
            "Open your eyes again.",
            "Then this Idol rhythm is suppressed.",
            "And this suppression of a rhythm.",
            "This is something that we will be using in most of what comes in in this talk, so now, but we will not be using the idle rhythm suppression because we have our eyes open.",
            "No?",
            "I mean we are actually using.",
            "The idle rhythm that we have when when we have some motor action or or motor imagery.",
            "So because if I place this arm at rest there's an Idol rhythm over the of the motor cortex which is lateralized if I move it, it's attenuated and the same thing is actually happening.",
            "If I'm just imagining this."
        ],
        [
            "So.",
            "Here's one view of the problem with variance.",
            "We see many signal trials.",
            "And I think for all of you, it's clear what the difference between single trial and averaging is.",
            "I mean, if you if it's not clear to you, then you can look at the slide.",
            "The solid lines are the averages, the not so solid lines are.",
            "The single trials."
        ],
        [
            "If you look at this from the map perspective.",
            "And you had an explanation from Gabriele what?",
            "You can actually see, so you if you imagine left hand then there should be some activity on the right hemisphere.",
            "If you look at this on several different trials, you can see that there's some considerable variation in this.",
            "This is 1 subject imagining across different single trials.",
            "This is right and left hand imagination, so it's quite a bit of a check."
        ],
        [
            "Twins.",
            "And this is.",
            "Some more subjects, but now an average.",
            "Of many trials and you know all these two plots are one subject and you can see that no subjects are like and they're all imagining left versus right.",
            "So I mean of course the conclusion from that is you have to deal with the variability and you have to use machine learning for that, because that's a primary tool that we have in our hands."
        ],
        [
            "I'm just.",
            "To to just spell out what we do.",
            "First of all, we have to tell the machine learning algorithm what the brain is doing.",
            "So in other words we have to do some kind of collaboration.",
            "An and so this means that that the subject tests to assume certain brain States and then we use that to do statistical inference.",
            "From what we have measured.",
            "Through different trials and.",
            "For example, try to infer what is the left Ness and the rightness of some certain brain activity.",
            "So this is the offline training part."
        ],
        [
            "And just.",
            "Two to clarify.",
            "So if you would come to the lab somebody put put the cap on your head, that would take some time.",
            "Maybe 30 minutes?",
            "We're not as good as the people in in Albany that they can do this in 10 minutes or 15 minutes.",
            "I was quite amazed by for their technician an."
        ],
        [
            "And then.",
            "Then you would do the following.",
            "So you.",
            "What the video says is that you should relax.",
            "And now you will see a letter on the screen, and while you see the letter, you should imagine the respective hand.",
            "So left.",
            "Stop.",
            "Relax left again.",
            "And right and so this could go on for about 1020 minutes.",
            "So some of us.",
            "Consider this extremely boring.",
            "And for example, I do and I sleep after 5 minutes.",
            "So for this reason we always had to find algorithms that can deal with few data points.",
            "So if you have 20 minutes of data, then we have about 100 trials on each side and you can actually also see or you actually have experienced how difficult it is to be relaxed.",
            "And focused at the same time.",
            "Because you really have to keep that timing."
        ],
        [
            "Now.",
            "You have done your imagination of left and right.",
            "We've recorded some brain signals and then the idea is to get some.",
            "Features some classifiers to infer what your brain has been up to, what your brain has been up to.",
            "So this it's about individual differences."
        ],
        [
            "OK, and so after we've done that, that's the upper part.",
            "We measure we have some label trials.",
            "We do feature extraction machine learning.",
            "Then we can go into the feedback session and we just take a window and classify whether this is left or right or or maybe nothing idle.",
            "OK.",
            "So it's an SM cronous PCI."
        ],
        [
            "And this is where Benjamin will take over to torture with torture.",
            "You with some mass."
        ],
        [
            "And let me just."
        ],
        [
            "Call my intention, of course it's not to torture you with mass and it said it's meant to be a very practical cost, so I will not introduce some fancy kernel algorithms or talk about in final feature space, but will be very practical and should be of real practical use to you and all the algorithms that I present.",
            "Very easy to implement.",
            "15 minutes or should be.",
            "Really something useful here.",
            "So in the first section I will talk about spatial temporal features and the classification of those, and in particular about shrinkage of the covariance matrix.",
            "And of course I will explain that and the application that I will demonstrate these algorithms is classification of single trial ERP's in the attention base."
        ],
        [
            "Stella and.",
            "Every shortly some some background that is needed to understand the application.",
            "So if a participant is.",
            "Presented versus sequence of stimuli, and there are two types of stimuli.",
            "One is frequently.",
            "Presented that is called standard stimuli and the other type is infrequently presented.",
            "That's called the deviant class, and if the subject is attending and awaiting this infrequent stimuli's and there will be specific components evoked, most prominently the P300 or P3, which is a positive peak approximately 300 milliseconds after stimulus presentation and it's.",
            "Located centrally and earlier, there's also a negative component and one, and on the other hand if there's visual stimulation and the participant focuses on this stimulus and the presentation of the stimulus elicits visual evoked potential, which is mainly two components 1st called P1 and the second N1, which is positive negative component.",
            "Like 100 milliseconds after stimulus presentation, and this is is a visual."
        ],
        [
            "Text occipitale so based on these components is very well known.",
            "Classical matrix Bella proposed by dimension that is used very much in BCI research.",
            "If you.",
            "Want to sell a letter B for example in this case and you concentrate on the letter B and then randomly rows and columns are flashed or intensified.",
            "And this is another kind of awkward experiment is a introduced before so so then the infrequent stimulus type is the presentation of the stimulus, where you pay attention tool.",
            "So in this case the column that contains the B&O that contains the B and the deviant stimuli.",
            "Our intensification of other rows and columns.",
            "So we expect the P300 only after presentation of the target Rowan Target column.",
            "And in one study is that you can find more details about in the poster W 7 by Materials Trader.",
            "Compared to classical speller with us, something new that.",
            "It's based on the hexose better idea, said Gabriel has introduced already, but now, in a visual attention based paradigm.",
            "So it's quite similar to this one.",
            "Again, if you want to spell the B of this works at 2 steps, you concentrate on the circle that contains the group.",
            "And then here's a circus are flashed in random sequence, and if this group is selected, then these 5 letters of."
        ],
        [
            "Group magnified to this layout and then in the next letter you can concentrate on the B and then the letter can be selected.",
            "And as I said please see this poster that compares these two.",
            "Spell designs and also compares other against."
        ],
        [
            "Cover detention.",
            "So this is the data set we used to illustrate.",
            "The algorithms for this axis, there based speller, and these are the ERP.",
            "So this is just average of e.g after stimulation of the target circle and the nontarget circle.",
            "Then here you see in the occipital area the P1 and then one.",
            "Component and also other visual components which are probably due to offset or systemless and also in central area.",
            "You see here 2 component."
        ],
        [
            "It looked like this P3.",
            "And.",
            "To get.",
            "Even better feeling for the data can look at it this space.",
            "So here you see again the earpiece for one centered channels.",
            "He said with solid line and with dashed line.",
            "Channel of visual cortex and then here you see corresponding to these intervals here that are shaded.",
            "So special map.",
            "This is for the target class and this is for the non target class.",
            "So you see here is a visual P1 component positive component in the occipital area, then one centrally the visual N1.",
            "The things they had two P3 components and we don't discuss the details.",
            "So we just name them according to the latency.",
            "So causes P250 and P400 and other components.",
            "So in all those intervals as a clear difference between the target class and so non target class.",
            "So this can be used to discriminate these two classes and.",
            "Then we use for classification.",
            "So this is a target feature."
        ],
        [
            "That we are aiming at, but we will proceed in several steps.",
            "So we will start very simple and classify.",
            "This is a classification on Raw Time series in this this intervals for single channels.",
            "So every very simple and just to get an idea of the distribution.",
            "So this is.",
            "Visualize the classification accuracy for the single channel classification so you see there are two areas where we achieve lower error.",
            "One is the visual area which in which we get a very low error rate already for the single channel classification about 17% and the other local minima of the errors centrally located.",
            "So this already gives some some feeling, so this of course is as it would be expected.",
            "This is the origin of the visual components insist."
        ],
        [
            "The cognitive components.",
            "So now we.",
            "We take another another view, and we want to exploit exploit the spatial structure and again we start very simple and we calculate spatial features from each trial.",
            "For this we take one interval where we expect a difference of the signals.",
            "So here we take the interval in which the PS3 and it is observed and then we calculate in this interval the average value in each channel.",
            "So then as a result we get.",
            "One value for each channel, one voltage value so we can visualize."
        ],
        [
            "This is a map.",
            "And we can do this for each single trial for each single trial we get a vector of the length of the number of channels, and it has just the voltage, so it's very."
        ],
        [
            "Very.",
            "Easy features, very simple features, but of course it's important.",
            "On which which intervals we calculate these and one good way to find out appropriate intervals where we can.",
            "Expect good discrimination between the conditions is to look at the square matrix.",
            "So this is a time cross channel matrix.",
            "And this is a biserial correlation coefficient, I think.",
            "For BCI, researchers was introduced by the by the Albany Group to look at spatial differences between different motor imagery conditions.",
            "And here we use this coefficient, which is essentially the difference between the two classes.",
            "The means of the two classes divided by the standard deviation and this reflects how well the two classes are discriminated in the respective.",
            "Sample so this can be visualized like this in a in a matrix time.",
            "Cross channels and then we see very nicely where the differences are.",
            "In time and how they are distributed in across the channels or then we can choose.",
            "So here I did it manually, but of course you can also have some algorithms to choose based on this matrix appropriate intervals, so here choose them manually and these are then these values and when value for each channel which shows these various Maps.",
            "So then we see here the differences for this.",
            "Visual P1 component.",
            "And here for the visual N1 and this is for the.",
            "P3 component.",
            "So this gives an idea what intervals are."
        ],
        [
            "Go to.",
            "To discriminate."
        ],
        [
            "OK, and so I guess I said first step is just to use one interval so we have purely failed special features.",
            "The features are one value for each each channel and if we train on such features, linear classifiers and the nice thing is that this classifier is a spatial filter.",
            "So if we have a for example as a linear classifier and train it on purely spatial features and we get a weight vector that has a.",
            "And the length of the loops.",
            "OK, do we have a backup for this?",
            "So maybe.",
            "Battery in.",
            "OK, so this is still very important that the classifier that was trained on this purely spatial features spatial filter, so we can apply it to the EG signals and then it waits the different channels and we get to filtered signals that emphasizes the difference between the conditions.",
            "And nice thing is that we can visualize this filter as a map so.",
            "So the classifier others, the filter is 1 weight value for each channel, so we can.",
            "Displayed as a map and see what this machine learning algorithm did learn from the data and what the discrimination is based on.",
            "So in this case, for the PS300 components spatial filters, you're focused centrally.",
            "Recipe 300 is evolved and test also other ways."
        ],
        [
            "In the visual area.",
            "And if if we use this simple classification or separately for each interval of the components that we.",
            "Detected as interesting components we get the following error rates as indicated here.",
            "So for each component we get different error rates ranging from 12 to 30.",
            "So here we already see that mostly the visual components are good for discrimination here, but also this P300 component.",
            "Give some contribution.",
            "So and then, of course we want not to stop here.",
            "We want to integrate this information from different temp."
        ],
        [
            "All intervals, so the next step is that we extract spatial temporal features.",
            "And that's again very, very simple.",
            "It's just the same as before, but now we do it for different intervals, so we have different intervals of interest.",
            "We calculate in each channel.",
            "The average value in each of these intervals, and now we get a bit longer feature vector in large feature vector because we get not only one value for each channel, but as many as we have intervals.",
            "So we can visualize those features as a map of.",
            "SA map of.",
            "As a theory."
        ],
        [
            "So, Scott Phipps.",
            "Well, we cannot also think of it as a as a matrix, of course, so we have the two dimension channel at the space and time.",
            "So, but then this features get already quite high dimensional.",
            "So if we have 59 e.g channels in the example and seven time intervals of interest, the dimensionality is."
        ],
        [
            "Find it 13.",
            "So if.",
            "This is as before and now I added here classification with ordinary LDA on this spatial temporal features and so this is of course disappointing.",
            "So here the result is 25%, so it's worse than the best single intervals.",
            "So we edit all the information together.",
            "But on this concatenated feature vectors, the classification become became worse, so.",
            "Most of you know what the problem is.",
            "If you have high dimensional data then there's some some overfitting.",
            "If we don't have enough training samples and the good thing in this situation is that it's not arbitrary overfitting or misestimation, but there's a systematic bias and that one can."
        ],
        [
            "Do something about it and so therefore.",
            "We need some formulas so this linear classifiers are based on the estimation of mean and covariance.",
            "So we have.",
            "So here we assume that we have some vectors drawn from a Gaussian distribution and in classification we need to estimate the mean and the covariance.",
            "So yeah, and this has a basic formulas to estimate mean and covariance, and the observation is that if we have high dimensional data and not.",
            "So many samples.",
            "Then there's a systematic bias in the empirical covariance matrix, and this systematic is it's a large eigenvalues of the estimated covariance are too large as a small eigenvalues are too small.",
            "So this is a misestimation and then of course LDA, which is simply this formula.",
            "The difference of the means multiplied by the inverse covariance matrix.",
            "It's not very good when these covariance."
        ],
        [
            "This badly estimated.",
            "So what does this mean?",
            "This with the eigenvalues?",
            "So this is a simple cartoon.",
            "We have true data distribution, so this data were generated.",
            "I took some distribution as the true distribution is indicated by the black ellipsoid and we draw some samples from the distribution.",
            "These are shown in blue and from based on these samples the empirical covariance matrix is calculated and this as a structure like.",
            "Thread ellipsoid, so the.",
            "Eigenvalue of the largest eigenvalue of the variance in the.",
            "The direction.",
            "Of largest variance.",
            "When you see in this direction which is a print first principle component.",
            "The variance is larger in this estimated covariance matrix, so the that is what was meant before the direction of the large large eigenvalues.",
            "They are estimated to large and the other way around in the direction of the.",
            "Eigenvector with low eigenvalues estimated too low, so our estimation is 2 ellipsoidal.",
            "The true wonders more spherical and this can easily be checked by by simulation, so you're generated 200 dimensional data.",
            "And this is a plot of the eigenvectors.",
            "In the 200 dimensions, if you do a principal component analysis, the Black one is a true one and this is the current lines are estimated eigenvalue spectrum with different number of samples.",
            "If you have only 50 samples in the purple colored line, see that.",
            "Yeah, that the lower item values are much too low.",
            "In particular, the first 150 or 0.",
            "And as estimated for the higher eigenvalues are estimated too high."
        ],
        [
            "So if we if we know this systematic in the bias, we can can do something about it.",
            "And this is this is called shrinkage.",
            "So if we have the empirical covariance matrix estimated from the data and we have to make it more spherical so we have seen that it's too elongated, so we have to make it more spherical and therefore we use a linear combination of the estimated covariance matrix and spherical covariance matrix, which is identity.",
            "And to have the correct size, it's multiplied by the average eigenvalue.",
            "So now we have a parimeter and an updated estimate depending on this parameter gamma, which is a linear."
        ],
        [
            "Combination between these two matrices.",
            "An interesting observation is is here the following week to see this one takes a Eigen value decomposition of the empirical covariance matrix like this.",
            "Then you have eigenvectors in Matrix V and the eigen various in the diagonal D. And you can easily check that the.",
            "I can value decomposition of this shrinked matrix.",
            "Looks like this here so we have the same.",
            "Eigenvectors we.",
            "And here just a modified diagonal matrix in the middle.",
            "And this diagonal matrix is a linear combination of the original.",
            "Diagonal matrix and identity with multiplaza average eigenvalue, so the original covariance S empirical covariance matrix and the shrink types assign eigenvectors so it does not turn somehow, but it stays in the same direction.",
            "And so extreme eigenvalues are shrunked or extended to the average.",
            "What you can see here.",
            "So that means we counterbalances systematic bias, and if we look at the extremes, if we set gamma to 0, then we have so original empirical covariance matrix.",
            "So that's original entity A and if we set gamma to one, then the first time cancels out.",
            "So we assume that the covariance matrix is very clear.",
            "So now we have."
        ],
        [
            "The problem that there's a free parameter gamma, and there are many different ways how to estimate it.",
            "One easy way is to."
        ],
        [
            "Use cross validation.",
            "So we do just try out different values and here in this simulation with.",
            "250 dimensional data.",
            "You'll see if you have few training data to under 50 training data, then you need a higher value for gamma to get the lowest error rate and with increasing number of samples you need a lower gamma or even gamma equals 0 if you have enough."
        ],
        [
            "Adding data, no shrinkage is needed.",
            "So did go more into detail here.",
            "This again, the formulas for LDA and shrinkage if we do complete shrinkage, gamma equals one.",
            "Then see covariance matrix that we use is just scaled identity, so this cancels hours.",
            "That means there's a classification.",
            "The classifier vectors just the difference of the two means.",
            "So then the spatial filter is just the difference of the of the earpiece."
        ],
        [
            "And on the other hand, if we don't use shrinkage, equals zero.",
            "We use a estimated covariance matrix and so.",
            "Here we get for gamma equals one.",
            "We have a very smooth filter spatially.",
            "And here we have a."
        ],
        [
            "More weekly one, but it's.",
            "So there's a continuous transition from the two extremes and the more I.",
            "Leave out the shrinkage.",
            "The lower scanner, the more we are accounting for the spatial structure."
        ],
        [
            "The noise.",
            "And to go into more detail here so.",
            "A simple model assumption for event related potentials is the following that we've the single trial fix case that we measure is a.",
            "Linear combination of of a true.",
            "Yeah P, that's constant for trials S and noise.",
            "Then in this scatter plot, 2 dimensional means that mean of one class.",
            "This is a phase locked activity, so this is just the ERP.",
            "Enter covariance matrix.",
            "Has all the rest also non phase locked activity?",
            "So which is considered noise?",
            "And to get an idea about what this noise that comes from, you can make a principal component analysis of this."
        ],
        [
            "Covariance matrix and the first 2 principal components of the noise.",
            "In this case, if this.",
            "Maps so the first is like flexor P300 map, so this is probably due to the fact that the model assumption is not correct.",
            "The ERP is not constant in each trial but there is variation depends on many factors that are different in each.",
            "So there's this is one source of variance at the PS3 is different in each trial and another strong source of variances visual Alpha.",
            "So it's from the visual area.",
            "We have some."
        ],
        [
            "Gradient.",
            "Proposing and so this is now very important to understand what this noise does and how it has to be accounted for in the classifier.",
            "So here this is artificially generated some.",
            "Not so much disturbed data, so we have the potential to electrodes F set at CP set in the two conditions target and non target so they have very nicely separated because they are quite clean.",
            "But we have seen that one source of noise, for example, comes from the Alpha rhythm from from Ozette.",
            "And now I added some to disk clean data, some Alpha rhythm from ozette with two different factors.",
            "So this is nearer or higher factor for CP set and."
        ],
        [
            "Lower factor for FC-2 and then we get this plot.",
            "Why is the classification here linear?",
            "Classification is 15% of error in the second case is.",
            "37% of error.",
            "But we in this case we know the source of the noise.",
            "So if we add this disturbing channel or set set introduces this noise and we classify on these three channels, then again we have a error of.",
            "16%.",
            "And so the important message here is that we need this, oh, that Channel for a good classification.",
            "Also in itself.",
            "It has no discriminative information.",
            "So the mean for the two conditions in Ozette is the same for both classes.",
            "But nevertheless we needed for classification so."
        ],
        [
            "Therefore you see that.",
            "In this case, equals one where we only use the difference between the two means as a classifier.",
            "This does not account for this this noise, so this this difference of the mean would have the weight 0 for the channel or that and would not make use of it only if we have a lower gamma then.",
            "We account for the noise and therefore so from the topography.",
            "Maybe you like more this smooth filters, but I hope I convinced you that this more complicated filters are important to account for the noise only.",
            "This way you can cancel out noise from this other electrodes.",
            "Here you see the error rates and you see in this case low gamma but non 0."
        ],
        [
            "What pizza is the best?",
            "So now I hope, hopefully convince you that it's the shrinkage is the nice thing, but so far there's a problem that is.",
            "The selection is time consuming with cross validation, but recently there was a analytical way to calculate the optimal gamma was published and we were pointed to this technique by Nicole Kramer."
        ],
        [
            "Part of either group.",
            "So this is a setting is again we have feature vectors.",
            "We estimate the mean and estimates.",
            "Covariance matrix and we want to find the best shrinkage here.",
            "To get the imp."
        ],
        [
            "Moved covariance matrix.",
            "And so you don't need to study this.",
            "But The thing is.",
            "We want to get some clothes, get as close as possible to the unknown true covariance matrix.",
            "So we want to minimize the norm of the our estimation and the true covariance matrix, and so this looks like hopeless to calculate it because this Sigma is a true covariance matrix is unknown.",
            "But it turns out if we restrict the search space to this form, then you can calculate the optimal gamma also in this.",
            "Calculation the true covariance matrix cancels out, and so optimal parameter gamma only depends on very simple values correlation coefficients.",
            "So variants of correlation coefficients across priors.",
            "So this is.",
            "Very simple to calculate and then."
        ],
        [
            "You have set optimal gamma for for shrinkage and now if we use this LDA with shrinkage of the covariance matrix, we get to drastically reduced error rate.",
            "So then only here is 4% of error.",
            "So this huge decrease was due to shrinkage."
        ],
        [
            "And so this this works.",
            "Very various not only for this particular data set.",
            "Here we had to have the results for the classical matrix speller with certain participants who were completely naive and so new to the paradigm.",
            "They were not preselected.",
            "And here's a classification accuracy for different numbers of repetitions of the.",
            "Stimulation, so this is accuracy in letter selection, so the chance level is at 3% and you see that with only very few intensifications we get very high classification accuracy.",
            "So if."
        ],
        [
            "Look at the mean across subjects you see.",
            "That was far intensifications where at median across subjects 100%.",
            "So just this is simple techniques I've just introduced, so if we want to see more details of this study, is he posted a W7 by my tears, trader and other applications where we use this classification technique?",
            "A tool where we can servings and W 10 by Jan this sooner?"
        ],
        [
            "So in summary, this linear classification with shrinkage is a very powerful method, and but of course whether a linear method is enough depends on the kind of features you have extracted.",
            "But if you can do it with a linear methods and it's very nice because you can visualize what was learned by the algorithm.",
            "So also for this spatial temporal features, the classifier weight vector can be visualized as a sequence of Maps."
        ],
        [
            "So this was for spatial temporal features.",
            "So now short section about spectral features."
        ],
        [
            "So this was already introduced Moreles bye bye Gallagher.",
            "So if we look at the Idol rhythm over the sensory motor area and then we see some peaks in the spectrum.",
            "If the handles address for example and we look at this electrode through this peaks though right?"
        ],
        [
            "Rhythms and if a movement is performed or just imagine, then these peaks are decreased, so this is a local blocking of the sensory motor rhythm and."
        ],
        [
            "This also."
        ],
        [
            "Yeah D skips it then.",
            "God bless also.",
            "Said that, this is very strong spatial smearing, so here I have calculated from one data set the correlation coefficient from electrodes.",
            "He said to all other electrodes and you see that.",
            "Correlation coefficient is almost .9 or above .944 all electrodes, so there's a very strong spatial smearing, and that means if you look at the data, you should first apply some spatial filter, and this is especially true for this differences in spectral content, yet so."
        ],
        [
            "Example that should illustrate this need.",
            "This is for left hand motor imagery and right hand motor imagery and we look at electrode CP four and then we should observe the decrease of spectral energy for left hand motor imagery for the black line.",
            "And if you look at the raw channel then we don't see any difference at all.",
            "If we make a bipolar apply bipolar filter you see a little bit.",
            "Common average reference.",
            "But only in this replacing filter we can see that this original peak is really composed of two peaks, and in fact the lower peak is from visual Alpha.",
            "So this has nothing to do with motor imagery and some modulation happens only in this.",
            "This upper peak and.",
            "So to look at it, you should always apply are placed in filter and then if you calculate CSP which I introduced next, which is a data driven method to optimize the spatial filters and you can strongly enhances discrimination."
        ],
        [
            "So, but for CSP, the first step is to find a frequency band, where can expect a difference of the two conditions, so you.",
            "Phil will take away now of this motor imagery data set for left hand and right hand motor imagery and plot Spectra for each channel.",
            "And yes, I."
        ],
        [
            "So that's quite useful.",
            "This color bar indicates the ask where value is assigned task for values, so that you see the significance of the difference.",
            "So then in this data set you see very easily that.",
            "Find 2.",
            "Frequency band have.",
            "Certain conditions are discriminable is then you can bandpass filters as your signals which is in this frequency band and look at the time cost.",
            "So this is average amplitude in this frequency band or also called DRD curves.",
            "And then you can see in which time interval is a discrimination is most prominent.",
            "So this is very different for are very not very but different for different subjects.",
            "So therefore it's important to select this specifically for each subject.",
            "So some have a very early yearly, but which does not last long and for others it takes 2 seconds to develop the ID, so can only have a good discrimination if you pin points is frequency band and time interval for each subject.",
            "And now."
        ],
        [
            "Auto.",
            "So the classification on this feature turned out this come special pattern algorithm is quite powerful and you can see it as such an algorithm in the middle years observed signals that you measure in EG.",
            "Well, it says this is.",
            "A mixture due to the special smearing from the sources and for our classification purpose we are interested in two kinds of sources.",
            "One is that minimizes the variance for right hand motor imagery and other sources that minimize the variance for left hand motor imagery.",
            "We are not interested in the other sources and so she is P. Estimates this mixing and this."
        ],
        [
            "Filters.",
            "So if you have successfully calculated the CSP then.",
            "It's also almost a whole problem, so here's a time causes of the AG filtered with this special filters.",
            "Here's PR and SSPL.",
            "You see, after right and motor imagery in this upper filter is the variance goes down very much.",
            "And then the other filters.",
            "The variance goes down after left hand motor imagery.",
            "So if you have probably.",
            "Optimize these filters and classification is very easy.",
            "You just calculate the variance in some time interval and just can compare where there's more variance.",
            "And here also in CSP, like with the linear classifiers and the spectral temporal features, it's nice that you can visualize them and see what was learned.",
            "So these are spatial filters, so you can visualize and check whether this makes sense.",
            "Then you can also detect when the subject, for example produced artifacts and controls.",
            "The."
        ],
        [
            "PCI was with different kind of signals.",
            "So in the calculation of CSP is also not very difficult.",
            "You concatenate on one hand or the trials for left hand motor imagery and from right hand motor imagery.",
            "So before you apply the bend pass filter so frequency band and then you solve for generalized eigenvalue problem.",
            "So.",
            "Like like this and.",
            "So here this is like a simuel tanias PCA of eigenvalue decomposition of the sub matrices.",
            "And then you can select from the Matrix V. Your special filters are the eigenvectors, so you can see that.",
            "Then if you choose Eigenvector VI that corresponds to a large eigenvalue diyan this decomposition then the variance if we.",
            "Take a left hand motor imagery data enterprise, a special filter, and this variance.",
            "Equals to the eigenvalue you to this equation, so then it is large and on the other hand if we apply the same spatial filter to right hand data then beauty other condition that you chose this conditions is eigenvalue sum up to one, then this must be 1 minus eigenvalue.",
            "So you have trains this spatial filter that at the same time maximize variance for one condition and minimize it for the other condition.",
            "And to calculate it in MATLAB is very easy.",
            "It's just one line 2."
        ],
        [
            "Sources."
        ],
        [
            "Area problem.",
            "And yeah, if you have applied this filters then you just calculate the variance and applies a logarithm and.",
            "In your single choice and get low dimensional features that can be.",
            "Classified Jasper."
        ],
        [
            "Yeah.",
            "Linear."
        ],
        [
            "Classifier, so here's a summary in pictures.",
            "So first is to determine the frequency band and then the time interval and based on these data you can apply CSP.",
            "And then you select appropriate CSP filters.",
            "For example according to this eigenvalue.",
            "And then you calculate variance and logarithm to get to."
        ],
        [
            "Features.",
            "And then in online operation you take the.",
            "Actually G that is measured applies.",
            "A spatial filter applies a bandpass filter and calculates the variance in a short window like the last half second and takes a logarithm and apply your classifier ways.",
            "So it's very easy linear procedure.",
            "And the nice thing about CSP is that you can change the length of this classification window in runtime, so this.",
            "Para meters that you estimate do not depend on the length, so you can train on very longer trials, but then in feedback apply it on short twice and make this trade off of.",
            "Short latency's and accuracies.",
            "So there's a tutorial on.",
            "CSP, where can I learn more?"
        ],
        [
            "So now the search section and so this.",
            "Up my my cross certain lost so.",
            "I hope I convinced you that machine learning algorithms can be very useful in single try e.g analysis.",
            "But there's also a problematic part and this is a validation of the methods and unfortunately can see in many.",
            "Manuscripts that are submitted to journals and even in published articles that many, many groups are not aware.",
            "Not many groups that some research labs are not aware of, or.",
            "Problems that there one has to take care of in the validation.",
            "So this is trying to.",
            "Give some some advice to make a proper.",
            "Validation so the.",
            "The principle of validating this this method is quite quite obvious, so for this machine learning methods you typically require one training data set.",
            "To tune your are your para meters on and test data set which is set in the real application.",
            "There the feedback data that is of course don't know in advance how it looks like.",
            "So the validation can only be proper if you don't use this test set in any way to determine some some of your para meters.",
            "And also if the samples in the test set are independent from the samples in the training set."
        ],
        [
            "And so these are more concrete.",
            "Some problems that may occur first is that there's a problem.",
            "Then if preprocessing methods, use statistics of the whole data set example.",
            "So in your validation your typically take one data set and want to validate the message on that.",
            "And if you first use the whole data set to compute some statistics.",
            "And pre process it and do the validation afterwards so that it's wrong and that's that's a problem.",
            "So for example, if you apply ICA to the whole data set in the beginning and only do the cross validation.",
            "For the classifier in the end.",
            "So then you use some statistics of the test set for pre processing and what you shouldn't.",
            "Or if you normalize the features based on including the samples from the from the test set.",
            "And this is a particular severe problem if your preprocessing methods use label information.",
            "For example the CSP as I've shown you before.",
            "If you calculate CSP first on the whole data set.",
            "And then do a cross validation only for the classifier part.",
            "You will severely underestimate the error.",
            "So in particular we have some several datasets.",
            "If you do that, you would get like 0% error because this special filters are somehow overfitted.",
            "And if you do a proper validation you get chance level.",
            "So instead yeah.",
            "So that means either you do this preprocessing within the cross validation, which is very time consuming, or you don't do cross validation, but just split the data once in training and test set.",
            "So which is more or less the same?",
            "So if you do feature selection on the whole data set.",
            "And only validates the classification.",
            "This will also be.",
            "Completely underestimating the perform overestimating the performance.",
            "So feature must be selected only based on the training set.",
            "Send if you if you would, select some some hyperparameters like the gamma of shrinkage.",
            "If you don't have the automatic way, but if you select the gamma is also a problem.",
            "If you do a.",
            "For each gamma, a proper cross validation and then say oh I see gamma equals .2 is the best best value and report this error as your generalization performance.",
            "So then the selection of the gamma dependent on the test set.",
            "So you have to select all these parameters also these hyperparameters.",
            "Based on the training set.",
            "Then another problem.",
            "If artifacts are outliers are removed from the whole data set, and then you do a cross validation because then you make your test set easier.",
            "So to say.",
            "So you're also exclude the.",
            "Artifacts from from the test set.",
            "So of course you can have methods for online detection of artifacts and reject them, But then you need a different performance measure.",
            "So I hope that these points were more less clear for the audience and one points I want to focus on.",
            "Remaining part and this is unsufficient validation in paradoxes block design."
        ],
        [
            "And this is what I mean by that.",
            "So the task is to discriminate between mental states in two different conditions and I call.",
            "So design a block design is a period for which there is no alteration between the two.",
            "Conditions are much longer than the switching should be in the real performance.",
            "In the online situation, so this can be may be best explained with this figure.",
            "So here we have different blocks, 7 seven blocks, and in the first block we only have tries according to condition, one.",
            "In the second block only.",
            "Trials according to condition two and so on.",
            "So this might be that the subject is continuously in one condition and you if you're just cut out smaller single trials here.",
            "Oh yeah, like LEXIS separated thing.",
            "So this kind of designs.",
            "Sometimes used if the condition is one that you can.",
            "Yeah, it's it's more easy to to.",
            "Keep keep up for a longer time.",
            "So for example, if you want to drive her BCI with.",
            "Say doing math or mathematics mentale or mental mental arithmetic, or composing a letter, then maybe it's not so easy to ever design to switch very rapidly in the training.",
            "To have like half a minute doing one condition half a minute or the other condition.",
            "But you may have saved the goal that in the feedback you learn how to switch quickly between the two conditions.",
            "So so that it's a problem if you.",
            "Take such a data set and then cut out these smaller segments and do a cross validation based on this."
        ],
        [
            "Smaller units.",
            "So the problem is due to the following facts.",
            "So here's a cartoon of how you would split 11 fold of the cross validation.",
            "It would take most.",
            "Epoxy for training and some for testing and the problem is that there are many features in in e.g that are due to background activity and that are slowly changing so this is a cartoon of such features like this is a time span of.",
            "Few minutes and then for example here this blue line is steadily increasing, so this could be increasing vigilance and as a as a variable.",
            "And.",
            "Also, so this these are variables that you really should should not be used in your classification because they're background activity.",
            "And but if you do do a classification based on this this these features may be may be used for the further classification and the problem is the validation is at training and test set are not independent.",
            "For example, if you look at this second block, there are three epochs put in the training set and one in the middle.",
            "In the test set.",
            "And so this slow changing features would be the same for for all and so they're not not independent if I learn.",
            "Since background activity in this training set based on these trees and I would correctly classify this.",
            "You spoke in the test set, although I didn't have a proper classification on the thing that discriminates between blue and green, but just because I recognize the signature of."
        ],
        [
            "Block based on background activity.",
            "And to demonstrate that this really needs leads can lead to severe.",
            "Misestimation of performance.",
            "I did this.",
            "Similar not simulation, but this validation.",
            "I took a true e.g data set and I assigned fake labels in the following way.",
            "So the first condition one block per class.",
            "Made two blocks and assign single trials for class one and one block and single phase of the other class.",
            "The other block and then in the next validation I took two blocks per class like this and here's three blocks and then I did cross validation based on these single."
        ],
        [
            "5.",
            "And this is a single trial set length of 1 second and this was done for 80 AG datasets.",
            "As he says, the results, so the labels were fake labels.",
            "They were just assigned in this schematic way and didn't have anything to do with the server mental state.",
            "So we should expect that the accuracy is at chance.",
            "So cause student to conditions it should be at 50% if you have in this strongest thing where we only have one block per class is so average error or the median error was at 8% and so this increases.",
            "If you have more blocks because then it's harder to find discriminative features.",
            "But yeah you see only here at 10 blocks it approximates the chance level, but it still will see even with the standard errors it.",
            "Lower chance level."
        ],
        [
            "So and what's a different validation method would be a leave one block out validation.",
            "So you don't have the normal cross validation but exclude one whole block from the training from the training train on the other blocks and tests, and on the holdout block.",
            "So in this case, if what's a classifier was learned is only based on this.",
            "Background features that should not generalize to this block that was not seen, and if I do this for the very same data, this kind of validation, you get the green boxes.",
            "So then this season medianus of all these cases is more or less at 50%.",
            "But as the price of a larger standard error, so then you have less variation and an shuffling, so this is a downside and sad to see reason why people like to do cross validation.",
            "OK, but in this case is I think it's mandatory to check this other validation, but this of course is not possible in the case where you only have two blocks and you would leave out one complete class for training, so there's nothing you can do here.",
            "So yeah, that two important messages here.",
            "One is if in the design of the experiment, if you.",
            "Can avoid block design.",
            "It's better to to avoid it or to have or if you need block design, at least try to have as many alterations between the conditions as possible and for the validation you should at least also check the leave one block out.",
            "So of course this is only validated the simulation done for one type of feature that I extracted an.",
            "If you have very simple features it might not be that your classification results are based on this, but at least there's always a danger."
        ],
        [
            "So the severeness of this underestimation of the true error depends on the complexity of the features and of the classifier.",
            "Um?",
            "Sorry it can be if you have.",
            "Simple, simple features and simple classifiers at the that you get to correct performance measures.",
            "So you cannot really say this is this is wrong, but at least you need some further evidence.",
            "Um?",
            "OK, and I already said that the downside is that the standard errors are larger in this validation.",
            "So and this is."
        ],
        [
            "Remarks I hand over to close again.",
            "So maybe I used the time to actually do what I failed to do because I'm Steven and I didn't properly talk about this.",
            "I namely introducing Benjamin.",
            "So Benjamin got his PhD in math in Munster and then moved to Berlin, and as you saw his driving figure also in the building brain computer interface.",
            "So OK, let me just.",
            "So in the remaining.",
            "1015 minutes Anne.",
            "I have"
        ],
        [
            "After just let me just get rid of this.",
            "M. So I think that the bottom line of what Benjamin said is so that 2, two or three messages here.",
            "So first of all.",
            "If you, even if you have a linear classifier.",
            "Then you can very easily overfit.",
            "If you have high dimensional feature spaces and you should do something about it and shrinkage is a very good idea and works very well.",
            "CSP is also a nice thing, so it's a one line metal up thing.",
            "Anne and.",
            "Any of the pitfalls that you've seen on the slides will lead to immediate rejection of the manuscript.",
            "If I'm the editor and the same holds for Benjamin, just to keep this in mind, and I think it also became clear why this is the case.",
            "And the block design can actually in the machine learning methods can make you seem do great things, whereas in truth you do something random.",
            "So I think this needs to be very carefully.",
            "Considered, and This is why we put it here in this tutorial, because most of you know, but it's always nice to look it up.",
            "Or to be able to look it up?",
            "OK so so basically set up of a BCI system would be some feature extractors.",
            "We've seen CSP.",
            "We can also think about some dynamical features like a are coefficients per channel."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you Steve and of course you always have to ask the organizers for inviting so.",
                    "label": 0
                },
                {
                    "sent": "So this is a joint.",
                    "label": 0
                },
                {
                    "sent": "Talk with Benjamin and I think one or one of the points that I would like to make first is if you do a machine.",
                    "label": 0
                },
                {
                    "sent": "If you do a BCI project, there's lots of people that should be on.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slide.",
                    "label": 0
                },
                {
                    "sent": "And I put them on the slide.",
                    "label": 0
                },
                {
                    "sent": "So we would like to thank all of them and all the collaborations and all the funders in particular EU being BF&FG as a starting point.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find.",
                    "label": 0
                },
                {
                    "sent": "So as Gob little has been talking just before me.",
                    "label": 0
                },
                {
                    "sent": "So you will recognize some of the slides.",
                    "label": 0
                },
                {
                    "sent": "In fact, we have a very close collaboration.",
                    "label": 0
                },
                {
                    "sent": "As you saw from the last slide and but.",
                    "label": 0
                },
                {
                    "sent": "I I will just gently remind you of the content and I will put it in in different words and from a different perspective.",
                    "label": 0
                },
                {
                    "sent": "So I think 11 important point to make is that I will be talking about machine learning methods for non invasive brain computer interfacing together with Benjamin and we will be mostly talking about this part.",
                    "label": 0
                },
                {
                    "sent": "The part that Gabriel has left out.",
                    "label": 0
                },
                {
                    "sent": "Just before we will.",
                    "label": 0
                },
                {
                    "sent": "Really start and go into details so I'm just to to get your mindset ready for this while Gabriel was giving you the Physiology will give you the math, so this will be quite serious and lots of formulas.",
                    "label": 0
                },
                {
                    "sent": "Just as a disclaimer, I mean Benyamin is shaking his head so so don't worry.",
                    "label": 0
                },
                {
                    "sent": "So the formula translation of a BCI is.",
                    "label": 0
                },
                {
                    "sent": "We translate human intentions into technical control signals without using muscle activity or peripheral nerve activity.",
                    "label": 0
                },
                {
                    "sent": "I think we should be very clear with this statement, so we're not having EMG brain computer interfaces.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you've seen videos from Gabriel side.",
                    "label": 0
                },
                {
                    "sent": "This is another video and.",
                    "label": 0
                },
                {
                    "sent": "So this is a control of the game pong I'm controlling the pedal down there by thinking left and right.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, just in order to hit the ball as often as possible.",
                    "label": 0
                },
                {
                    "sent": "And if you could see the full picture, you could see that there are lots of EMG electrodes put all over the place just to control whether I'm using EMG at all.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm not using it.",
                    "label": 0
                },
                {
                    "sent": "And also we put usually some electrodes here to measure the electrocardiogram.",
                    "label": 0
                },
                {
                    "sent": "Also to rule out that we are controlling things with our eyes and their respective brain signals that come with our eyes signals with our eye movements.",
                    "label": 0
                },
                {
                    "sent": "So as Gabriele also has mentioned.",
                    "label": 0
                },
                {
                    "sent": "If you do noninvasive brain computer interfacing with human subjects, you can ask them how they felt in this kind of experiment, and I'm I'm ready to to tell you this is, I think, was my my second experiment ever, and.",
                    "label": 0
                },
                {
                    "sent": "I was actually trying to control the the cursor by.",
                    "label": 0
                },
                {
                    "sent": "Thinking about pulling a string to the left and to the right.",
                    "label": 0
                },
                {
                    "sent": "So I was thinking about something physical.",
                    "label": 0
                },
                {
                    "sent": "But I was not moving anything as you've seen from the from the video.",
                    "label": 0
                },
                {
                    "sent": "I did this maybe for half an hour, deliberately relaxing.",
                    "label": 0
                },
                {
                    "sent": "Focusing on the activity left and right movement.",
                    "label": 0
                },
                {
                    "sent": "And after half an hour, I realized that I could place the cursor wherever I wanted on the screen.",
                    "label": 0
                },
                {
                    "sent": "So all of a sudden this this cursor became like as a gobble.",
                    "label": 0
                },
                {
                    "sent": "Pointed out, it became like a part of my body.",
                    "label": 0
                },
                {
                    "sent": "It became like a tool like a tennis record.",
                    "label": 0
                },
                {
                    "sent": "If I play tennis, I'm not thinking about, you know the extension of my arm.",
                    "label": 0
                },
                {
                    "sent": "If I play tennis, so this was a very interesting experience and also this just to finish the story.",
                    "label": 0
                },
                {
                    "sent": "After about one hour away I could absolutely control without.",
                    "label": 0
                },
                {
                    "sent": "Deliberately thinking about, say, pulling a string.",
                    "label": 0
                },
                {
                    "sent": "This changed again and I lost control in that manner and I had to resume pulling strings OK and I got tired in the meantime, so there was actually some nonstationarity going on.",
                    "label": 0
                },
                {
                    "sent": "I will.",
                    "label": 0
                },
                {
                    "sent": "We will discuss this part.",
                    "label": 0
                },
                {
                    "sent": "Later in the talk.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rock.",
                    "label": 0
                },
                {
                    "sent": "So, as was already pointed out.",
                    "label": 0
                },
                {
                    "sent": "Clearly we are not the first to have invented brain computer interfacing.",
                    "label": 0
                },
                {
                    "sent": "Just as a personal impression.",
                    "label": 0
                },
                {
                    "sent": "When I got into this field, I'm actually.",
                    "label": 0
                },
                {
                    "sent": "An expert in machine learning and signal processing so so I was always interested in e.g.",
                    "label": 0
                },
                {
                    "sent": "So maybe I did my first papers on that in 95 an around 2000.",
                    "label": 0
                },
                {
                    "sent": "I started thinking well if I can analyze e.g on a single trial basis why not use it to control things?",
                    "label": 0
                },
                {
                    "sent": "And of course I realized that there was a community out there that did this already and I went.",
                    "label": 0
                },
                {
                    "sent": "Two for trailers, Nappanee E Baum's lap and I went to Albany and talk to John and Teresa and they were actually very, very friendly and helped me a lot getting into this field because my view at that time was we shouldn't have the patience or the subjects learn, but the machines should do that otherwise.",
                    "label": 0
                },
                {
                    "sent": "I mean, where's my contribution?",
                    "label": 0
                },
                {
                    "sent": "OK, as a machine learner.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Clearly EG is about Electra.",
                    "label": 0
                },
                {
                    "sent": "Electrical signals that you can measure.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We've seen that clearly.",
                    "label": 0
                },
                {
                    "sent": "There's some problems, and you've seen this slide, but I added something.",
                    "label": 0
                },
                {
                    "sent": "So there's this little drawing.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In my in one of my former lives, I was very active in independent component analysis and independent component analyzes.",
                    "label": 0
                },
                {
                    "sent": "You typically have the acoustic cocktail party problem where you have many speakers talking at the same time, and you've tried to filter out what the neighbor says that you're talking to.",
                    "label": 0
                },
                {
                    "sent": "And as was pointed out in the by Gabriele, we have a very similar situation here.",
                    "label": 0
                },
                {
                    "sent": "Because electromagnetic waves superimpose, in fact linearly.",
                    "label": 0
                },
                {
                    "sent": "And what we have in the acoustic cocktail party problem is actually.",
                    "label": 1
                },
                {
                    "sent": "A much more difficult problem to be precise because we have a convolution.",
                    "label": 0
                },
                {
                    "sent": "You see that that's an echo, so if you do acoustic acoustic cocktail party problem, then you have to deal with these Echo Hall and long reverberations.",
                    "label": 0
                },
                {
                    "sent": "So here you don't.",
                    "label": 0
                },
                {
                    "sent": "So the idea in the first step is to focus on signals that we are.",
                    "label": 0
                },
                {
                    "sent": "Able to hub harvest in the sense they are useful for decoding.",
                    "label": 0
                },
                {
                    "sent": "There lots of things going on, but they are not useful for the decoding purpose, so we have to treat them as noise.",
                    "label": 0
                },
                {
                    "sent": "In other words, we have to find some projection in sensor space and I'm actually a painting of drawing a very simple sensor space here.",
                    "label": 0
                },
                {
                    "sent": "It's only two dimensional.",
                    "label": 0
                },
                {
                    "sent": "Usually we have 64 dimensional sensor spaces and the data is lying there as as a cloud.",
                    "label": 0
                },
                {
                    "sent": "And we would like to.",
                    "label": 0
                },
                {
                    "sent": "Focus on some activity of some brain areas that we're interested in, meaning we have to find some projections in this 64 dimensional space that.",
                    "label": 0
                },
                {
                    "sent": "Help us decoding and.",
                    "label": 0
                },
                {
                    "sent": "To help us get rid of all the noise and I put noise in quotes here, OK.",
                    "label": 0
                },
                {
                    "sent": "So ICA happens to be a method that can be used there, but other further methods that can be.",
                    "label": 0
                },
                {
                    "sent": "I'm pleased like NGC and others.",
                    "label": 0
                },
                {
                    "sent": "I will not go into this part.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In details.",
                    "label": 0
                },
                {
                    "sent": "So when when you saw me doing the brain pong game I was using one particular motor imaginary, which is pulling a string.",
                    "label": 0
                },
                {
                    "sent": "There's lots of other possibilities, so our subjects they typically think about squeezing a ball, kicking a ball.",
                    "label": 0
                },
                {
                    "sent": "Some Brazilian subjects would always kick a ball field touch field, sense they feel heat.",
                    "label": 0
                },
                {
                    "sent": "Whatever, so this is some kind of imaginary that you would be.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using.",
                    "label": 0
                },
                {
                    "sent": "An so.",
                    "label": 0
                },
                {
                    "sent": "If you look at the slide.",
                    "label": 0
                },
                {
                    "sent": "Gobble has pointed out that there's some desynchronization.",
                    "label": 0
                },
                {
                    "sent": "If you so, if you close your eyes as I I'm doing here, this is a picture that cannot gave me.",
                    "label": 0
                },
                {
                    "sent": "And so then there's some Alpha activity.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Open your eyes again.",
                    "label": 0
                },
                {
                    "sent": "Then this Idol rhythm is suppressed.",
                    "label": 0
                },
                {
                    "sent": "And this suppression of a rhythm.",
                    "label": 0
                },
                {
                    "sent": "This is something that we will be using in most of what comes in in this talk, so now, but we will not be using the idle rhythm suppression because we have our eyes open.",
                    "label": 0
                },
                {
                    "sent": "No?",
                    "label": 0
                },
                {
                    "sent": "I mean we are actually using.",
                    "label": 0
                },
                {
                    "sent": "The idle rhythm that we have when when we have some motor action or or motor imagery.",
                    "label": 0
                },
                {
                    "sent": "So because if I place this arm at rest there's an Idol rhythm over the of the motor cortex which is lateralized if I move it, it's attenuated and the same thing is actually happening.",
                    "label": 0
                },
                {
                    "sent": "If I'm just imagining this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here's one view of the problem with variance.",
                    "label": 1
                },
                {
                    "sent": "We see many signal trials.",
                    "label": 0
                },
                {
                    "sent": "And I think for all of you, it's clear what the difference between single trial and averaging is.",
                    "label": 1
                },
                {
                    "sent": "I mean, if you if it's not clear to you, then you can look at the slide.",
                    "label": 0
                },
                {
                    "sent": "The solid lines are the averages, the not so solid lines are.",
                    "label": 0
                },
                {
                    "sent": "The single trials.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at this from the map perspective.",
                    "label": 0
                },
                {
                    "sent": "And you had an explanation from Gabriele what?",
                    "label": 0
                },
                {
                    "sent": "You can actually see, so you if you imagine left hand then there should be some activity on the right hemisphere.",
                    "label": 0
                },
                {
                    "sent": "If you look at this on several different trials, you can see that there's some considerable variation in this.",
                    "label": 0
                },
                {
                    "sent": "This is 1 subject imagining across different single trials.",
                    "label": 0
                },
                {
                    "sent": "This is right and left hand imagination, so it's quite a bit of a check.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Twins.",
                    "label": 0
                },
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "Some more subjects, but now an average.",
                    "label": 0
                },
                {
                    "sent": "Of many trials and you know all these two plots are one subject and you can see that no subjects are like and they're all imagining left versus right.",
                    "label": 0
                },
                {
                    "sent": "So I mean of course the conclusion from that is you have to deal with the variability and you have to use machine learning for that, because that's a primary tool that we have in our hands.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm just.",
                    "label": 0
                },
                {
                    "sent": "To to just spell out what we do.",
                    "label": 0
                },
                {
                    "sent": "First of all, we have to tell the machine learning algorithm what the brain is doing.",
                    "label": 1
                },
                {
                    "sent": "So in other words we have to do some kind of collaboration.",
                    "label": 0
                },
                {
                    "sent": "An and so this means that that the subject tests to assume certain brain States and then we use that to do statistical inference.",
                    "label": 0
                },
                {
                    "sent": "From what we have measured.",
                    "label": 0
                },
                {
                    "sent": "Through different trials and.",
                    "label": 0
                },
                {
                    "sent": "For example, try to infer what is the left Ness and the rightness of some certain brain activity.",
                    "label": 0
                },
                {
                    "sent": "So this is the offline training part.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just.",
                    "label": 0
                },
                {
                    "sent": "Two to clarify.",
                    "label": 0
                },
                {
                    "sent": "So if you would come to the lab somebody put put the cap on your head, that would take some time.",
                    "label": 0
                },
                {
                    "sent": "Maybe 30 minutes?",
                    "label": 0
                },
                {
                    "sent": "We're not as good as the people in in Albany that they can do this in 10 minutes or 15 minutes.",
                    "label": 0
                },
                {
                    "sent": "I was quite amazed by for their technician an.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Then you would do the following.",
                    "label": 0
                },
                {
                    "sent": "So you.",
                    "label": 0
                },
                {
                    "sent": "What the video says is that you should relax.",
                    "label": 0
                },
                {
                    "sent": "And now you will see a letter on the screen, and while you see the letter, you should imagine the respective hand.",
                    "label": 0
                },
                {
                    "sent": "So left.",
                    "label": 0
                },
                {
                    "sent": "Stop.",
                    "label": 0
                },
                {
                    "sent": "Relax left again.",
                    "label": 0
                },
                {
                    "sent": "And right and so this could go on for about 1020 minutes.",
                    "label": 0
                },
                {
                    "sent": "So some of us.",
                    "label": 0
                },
                {
                    "sent": "Consider this extremely boring.",
                    "label": 0
                },
                {
                    "sent": "And for example, I do and I sleep after 5 minutes.",
                    "label": 0
                },
                {
                    "sent": "So for this reason we always had to find algorithms that can deal with few data points.",
                    "label": 0
                },
                {
                    "sent": "So if you have 20 minutes of data, then we have about 100 trials on each side and you can actually also see or you actually have experienced how difficult it is to be relaxed.",
                    "label": 0
                },
                {
                    "sent": "And focused at the same time.",
                    "label": 0
                },
                {
                    "sent": "Because you really have to keep that timing.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "You have done your imagination of left and right.",
                    "label": 0
                },
                {
                    "sent": "We've recorded some brain signals and then the idea is to get some.",
                    "label": 0
                },
                {
                    "sent": "Features some classifiers to infer what your brain has been up to, what your brain has been up to.",
                    "label": 0
                },
                {
                    "sent": "So this it's about individual differences.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so after we've done that, that's the upper part.",
                    "label": 0
                },
                {
                    "sent": "We measure we have some label trials.",
                    "label": 0
                },
                {
                    "sent": "We do feature extraction machine learning.",
                    "label": 1
                },
                {
                    "sent": "Then we can go into the feedback session and we just take a window and classify whether this is left or right or or maybe nothing idle.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So it's an SM cronous PCI.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is where Benjamin will take over to torture with torture.",
                    "label": 0
                },
                {
                    "sent": "You with some mass.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And let me just.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Call my intention, of course it's not to torture you with mass and it said it's meant to be a very practical cost, so I will not introduce some fancy kernel algorithms or talk about in final feature space, but will be very practical and should be of real practical use to you and all the algorithms that I present.",
                    "label": 0
                },
                {
                    "sent": "Very easy to implement.",
                    "label": 0
                },
                {
                    "sent": "15 minutes or should be.",
                    "label": 0
                },
                {
                    "sent": "Really something useful here.",
                    "label": 0
                },
                {
                    "sent": "So in the first section I will talk about spatial temporal features and the classification of those, and in particular about shrinkage of the covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "And of course I will explain that and the application that I will demonstrate these algorithms is classification of single trial ERP's in the attention base.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stella and.",
                    "label": 0
                },
                {
                    "sent": "Every shortly some some background that is needed to understand the application.",
                    "label": 0
                },
                {
                    "sent": "So if a participant is.",
                    "label": 0
                },
                {
                    "sent": "Presented versus sequence of stimuli, and there are two types of stimuli.",
                    "label": 0
                },
                {
                    "sent": "One is frequently.",
                    "label": 0
                },
                {
                    "sent": "Presented that is called standard stimuli and the other type is infrequently presented.",
                    "label": 1
                },
                {
                    "sent": "That's called the deviant class, and if the subject is attending and awaiting this infrequent stimuli's and there will be specific components evoked, most prominently the P300 or P3, which is a positive peak approximately 300 milliseconds after stimulus presentation and it's.",
                    "label": 0
                },
                {
                    "sent": "Located centrally and earlier, there's also a negative component and one, and on the other hand if there's visual stimulation and the participant focuses on this stimulus and the presentation of the stimulus elicits visual evoked potential, which is mainly two components 1st called P1 and the second N1, which is positive negative component.",
                    "label": 1
                },
                {
                    "sent": "Like 100 milliseconds after stimulus presentation, and this is is a visual.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Text occipitale so based on these components is very well known.",
                    "label": 0
                },
                {
                    "sent": "Classical matrix Bella proposed by dimension that is used very much in BCI research.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Want to sell a letter B for example in this case and you concentrate on the letter B and then randomly rows and columns are flashed or intensified.",
                    "label": 0
                },
                {
                    "sent": "And this is another kind of awkward experiment is a introduced before so so then the infrequent stimulus type is the presentation of the stimulus, where you pay attention tool.",
                    "label": 0
                },
                {
                    "sent": "So in this case the column that contains the B&O that contains the B and the deviant stimuli.",
                    "label": 0
                },
                {
                    "sent": "Our intensification of other rows and columns.",
                    "label": 0
                },
                {
                    "sent": "So we expect the P300 only after presentation of the target Rowan Target column.",
                    "label": 0
                },
                {
                    "sent": "And in one study is that you can find more details about in the poster W 7 by Materials Trader.",
                    "label": 0
                },
                {
                    "sent": "Compared to classical speller with us, something new that.",
                    "label": 0
                },
                {
                    "sent": "It's based on the hexose better idea, said Gabriel has introduced already, but now, in a visual attention based paradigm.",
                    "label": 0
                },
                {
                    "sent": "So it's quite similar to this one.",
                    "label": 0
                },
                {
                    "sent": "Again, if you want to spell the B of this works at 2 steps, you concentrate on the circle that contains the group.",
                    "label": 0
                },
                {
                    "sent": "And then here's a circus are flashed in random sequence, and if this group is selected, then these 5 letters of.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Group magnified to this layout and then in the next letter you can concentrate on the B and then the letter can be selected.",
                    "label": 0
                },
                {
                    "sent": "And as I said please see this poster that compares these two.",
                    "label": 0
                },
                {
                    "sent": "Spell designs and also compares other against.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cover detention.",
                    "label": 0
                },
                {
                    "sent": "So this is the data set we used to illustrate.",
                    "label": 0
                },
                {
                    "sent": "The algorithms for this axis, there based speller, and these are the ERP.",
                    "label": 0
                },
                {
                    "sent": "So this is just average of e.g after stimulation of the target circle and the nontarget circle.",
                    "label": 0
                },
                {
                    "sent": "Then here you see in the occipital area the P1 and then one.",
                    "label": 0
                },
                {
                    "sent": "Component and also other visual components which are probably due to offset or systemless and also in central area.",
                    "label": 0
                },
                {
                    "sent": "You see here 2 component.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It looked like this P3.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "To get.",
                    "label": 0
                },
                {
                    "sent": "Even better feeling for the data can look at it this space.",
                    "label": 0
                },
                {
                    "sent": "So here you see again the earpiece for one centered channels.",
                    "label": 0
                },
                {
                    "sent": "He said with solid line and with dashed line.",
                    "label": 0
                },
                {
                    "sent": "Channel of visual cortex and then here you see corresponding to these intervals here that are shaded.",
                    "label": 0
                },
                {
                    "sent": "So special map.",
                    "label": 0
                },
                {
                    "sent": "This is for the target class and this is for the non target class.",
                    "label": 0
                },
                {
                    "sent": "So you see here is a visual P1 component positive component in the occipital area, then one centrally the visual N1.",
                    "label": 0
                },
                {
                    "sent": "The things they had two P3 components and we don't discuss the details.",
                    "label": 0
                },
                {
                    "sent": "So we just name them according to the latency.",
                    "label": 0
                },
                {
                    "sent": "So causes P250 and P400 and other components.",
                    "label": 0
                },
                {
                    "sent": "So in all those intervals as a clear difference between the target class and so non target class.",
                    "label": 0
                },
                {
                    "sent": "So this can be used to discriminate these two classes and.",
                    "label": 1
                },
                {
                    "sent": "Then we use for classification.",
                    "label": 0
                },
                {
                    "sent": "So this is a target feature.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we are aiming at, but we will proceed in several steps.",
                    "label": 0
                },
                {
                    "sent": "So we will start very simple and classify.",
                    "label": 0
                },
                {
                    "sent": "This is a classification on Raw Time series in this this intervals for single channels.",
                    "label": 1
                },
                {
                    "sent": "So every very simple and just to get an idea of the distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Visualize the classification accuracy for the single channel classification so you see there are two areas where we achieve lower error.",
                    "label": 0
                },
                {
                    "sent": "One is the visual area which in which we get a very low error rate already for the single channel classification about 17% and the other local minima of the errors centrally located.",
                    "label": 0
                },
                {
                    "sent": "So this already gives some some feeling, so this of course is as it would be expected.",
                    "label": 0
                },
                {
                    "sent": "This is the origin of the visual components insist.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The cognitive components.",
                    "label": 0
                },
                {
                    "sent": "So now we.",
                    "label": 0
                },
                {
                    "sent": "We take another another view, and we want to exploit exploit the spatial structure and again we start very simple and we calculate spatial features from each trial.",
                    "label": 0
                },
                {
                    "sent": "For this we take one interval where we expect a difference of the signals.",
                    "label": 0
                },
                {
                    "sent": "So here we take the interval in which the PS3 and it is observed and then we calculate in this interval the average value in each channel.",
                    "label": 0
                },
                {
                    "sent": "So then as a result we get.",
                    "label": 0
                },
                {
                    "sent": "One value for each channel, one voltage value so we can visualize.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a map.",
                    "label": 0
                },
                {
                    "sent": "And we can do this for each single trial for each single trial we get a vector of the length of the number of channels, and it has just the voltage, so it's very.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very.",
                    "label": 0
                },
                {
                    "sent": "Easy features, very simple features, but of course it's important.",
                    "label": 0
                },
                {
                    "sent": "On which which intervals we calculate these and one good way to find out appropriate intervals where we can.",
                    "label": 0
                },
                {
                    "sent": "Expect good discrimination between the conditions is to look at the square matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is a time cross channel matrix.",
                    "label": 0
                },
                {
                    "sent": "And this is a biserial correlation coefficient, I think.",
                    "label": 0
                },
                {
                    "sent": "For BCI, researchers was introduced by the by the Albany Group to look at spatial differences between different motor imagery conditions.",
                    "label": 0
                },
                {
                    "sent": "And here we use this coefficient, which is essentially the difference between the two classes.",
                    "label": 0
                },
                {
                    "sent": "The means of the two classes divided by the standard deviation and this reflects how well the two classes are discriminated in the respective.",
                    "label": 1
                },
                {
                    "sent": "Sample so this can be visualized like this in a in a matrix time.",
                    "label": 0
                },
                {
                    "sent": "Cross channels and then we see very nicely where the differences are.",
                    "label": 0
                },
                {
                    "sent": "In time and how they are distributed in across the channels or then we can choose.",
                    "label": 0
                },
                {
                    "sent": "So here I did it manually, but of course you can also have some algorithms to choose based on this matrix appropriate intervals, so here choose them manually and these are then these values and when value for each channel which shows these various Maps.",
                    "label": 0
                },
                {
                    "sent": "So then we see here the differences for this.",
                    "label": 0
                },
                {
                    "sent": "Visual P1 component.",
                    "label": 0
                },
                {
                    "sent": "And here for the visual N1 and this is for the.",
                    "label": 0
                },
                {
                    "sent": "P3 component.",
                    "label": 0
                },
                {
                    "sent": "So this gives an idea what intervals are.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go to.",
                    "label": 0
                },
                {
                    "sent": "To discriminate.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so I guess I said first step is just to use one interval so we have purely failed special features.",
                    "label": 0
                },
                {
                    "sent": "The features are one value for each each channel and if we train on such features, linear classifiers and the nice thing is that this classifier is a spatial filter.",
                    "label": 1
                },
                {
                    "sent": "So if we have a for example as a linear classifier and train it on purely spatial features and we get a weight vector that has a.",
                    "label": 1
                },
                {
                    "sent": "And the length of the loops.",
                    "label": 0
                },
                {
                    "sent": "OK, do we have a backup for this?",
                    "label": 0
                },
                {
                    "sent": "So maybe.",
                    "label": 0
                },
                {
                    "sent": "Battery in.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is still very important that the classifier that was trained on this purely spatial features spatial filter, so we can apply it to the EG signals and then it waits the different channels and we get to filtered signals that emphasizes the difference between the conditions.",
                    "label": 1
                },
                {
                    "sent": "And nice thing is that we can visualize this filter as a map so.",
                    "label": 0
                },
                {
                    "sent": "So the classifier others, the filter is 1 weight value for each channel, so we can.",
                    "label": 0
                },
                {
                    "sent": "Displayed as a map and see what this machine learning algorithm did learn from the data and what the discrimination is based on.",
                    "label": 0
                },
                {
                    "sent": "So in this case, for the PS300 components spatial filters, you're focused centrally.",
                    "label": 0
                },
                {
                    "sent": "Recipe 300 is evolved and test also other ways.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the visual area.",
                    "label": 0
                },
                {
                    "sent": "And if if we use this simple classification or separately for each interval of the components that we.",
                    "label": 0
                },
                {
                    "sent": "Detected as interesting components we get the following error rates as indicated here.",
                    "label": 0
                },
                {
                    "sent": "So for each component we get different error rates ranging from 12 to 30.",
                    "label": 0
                },
                {
                    "sent": "So here we already see that mostly the visual components are good for discrimination here, but also this P300 component.",
                    "label": 0
                },
                {
                    "sent": "Give some contribution.",
                    "label": 0
                },
                {
                    "sent": "So and then, of course we want not to stop here.",
                    "label": 0
                },
                {
                    "sent": "We want to integrate this information from different temp.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All intervals, so the next step is that we extract spatial temporal features.",
                    "label": 0
                },
                {
                    "sent": "And that's again very, very simple.",
                    "label": 0
                },
                {
                    "sent": "It's just the same as before, but now we do it for different intervals, so we have different intervals of interest.",
                    "label": 0
                },
                {
                    "sent": "We calculate in each channel.",
                    "label": 0
                },
                {
                    "sent": "The average value in each of these intervals, and now we get a bit longer feature vector in large feature vector because we get not only one value for each channel, but as many as we have intervals.",
                    "label": 0
                },
                {
                    "sent": "So we can visualize those features as a map of.",
                    "label": 0
                },
                {
                    "sent": "SA map of.",
                    "label": 0
                },
                {
                    "sent": "As a theory.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, Scott Phipps.",
                    "label": 0
                },
                {
                    "sent": "Well, we cannot also think of it as a as a matrix, of course, so we have the two dimension channel at the space and time.",
                    "label": 0
                },
                {
                    "sent": "So, but then this features get already quite high dimensional.",
                    "label": 0
                },
                {
                    "sent": "So if we have 59 e.g channels in the example and seven time intervals of interest, the dimensionality is.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find it 13.",
                    "label": 0
                },
                {
                    "sent": "So if.",
                    "label": 0
                },
                {
                    "sent": "This is as before and now I added here classification with ordinary LDA on this spatial temporal features and so this is of course disappointing.",
                    "label": 0
                },
                {
                    "sent": "So here the result is 25%, so it's worse than the best single intervals.",
                    "label": 0
                },
                {
                    "sent": "So we edit all the information together.",
                    "label": 0
                },
                {
                    "sent": "But on this concatenated feature vectors, the classification become became worse, so.",
                    "label": 0
                },
                {
                    "sent": "Most of you know what the problem is.",
                    "label": 0
                },
                {
                    "sent": "If you have high dimensional data then there's some some overfitting.",
                    "label": 0
                },
                {
                    "sent": "If we don't have enough training samples and the good thing in this situation is that it's not arbitrary overfitting or misestimation, but there's a systematic bias and that one can.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do something about it and so therefore.",
                    "label": 0
                },
                {
                    "sent": "We need some formulas so this linear classifiers are based on the estimation of mean and covariance.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "So here we assume that we have some vectors drawn from a Gaussian distribution and in classification we need to estimate the mean and the covariance.",
                    "label": 1
                },
                {
                    "sent": "So yeah, and this has a basic formulas to estimate mean and covariance, and the observation is that if we have high dimensional data and not.",
                    "label": 0
                },
                {
                    "sent": "So many samples.",
                    "label": 0
                },
                {
                    "sent": "Then there's a systematic bias in the empirical covariance matrix, and this systematic is it's a large eigenvalues of the estimated covariance are too large as a small eigenvalues are too small.",
                    "label": 1
                },
                {
                    "sent": "So this is a misestimation and then of course LDA, which is simply this formula.",
                    "label": 0
                },
                {
                    "sent": "The difference of the means multiplied by the inverse covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "It's not very good when these covariance.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This badly estimated.",
                    "label": 0
                },
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "This with the eigenvalues?",
                    "label": 0
                },
                {
                    "sent": "So this is a simple cartoon.",
                    "label": 0
                },
                {
                    "sent": "We have true data distribution, so this data were generated.",
                    "label": 0
                },
                {
                    "sent": "I took some distribution as the true distribution is indicated by the black ellipsoid and we draw some samples from the distribution.",
                    "label": 0
                },
                {
                    "sent": "These are shown in blue and from based on these samples the empirical covariance matrix is calculated and this as a structure like.",
                    "label": 0
                },
                {
                    "sent": "Thread ellipsoid, so the.",
                    "label": 0
                },
                {
                    "sent": "Eigenvalue of the largest eigenvalue of the variance in the.",
                    "label": 0
                },
                {
                    "sent": "The direction.",
                    "label": 0
                },
                {
                    "sent": "Of largest variance.",
                    "label": 0
                },
                {
                    "sent": "When you see in this direction which is a print first principle component.",
                    "label": 0
                },
                {
                    "sent": "The variance is larger in this estimated covariance matrix, so the that is what was meant before the direction of the large large eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "They are estimated to large and the other way around in the direction of the.",
                    "label": 0
                },
                {
                    "sent": "Eigenvector with low eigenvalues estimated too low, so our estimation is 2 ellipsoidal.",
                    "label": 0
                },
                {
                    "sent": "The true wonders more spherical and this can easily be checked by by simulation, so you're generated 200 dimensional data.",
                    "label": 0
                },
                {
                    "sent": "And this is a plot of the eigenvectors.",
                    "label": 0
                },
                {
                    "sent": "In the 200 dimensions, if you do a principal component analysis, the Black one is a true one and this is the current lines are estimated eigenvalue spectrum with different number of samples.",
                    "label": 0
                },
                {
                    "sent": "If you have only 50 samples in the purple colored line, see that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that the lower item values are much too low.",
                    "label": 0
                },
                {
                    "sent": "In particular, the first 150 or 0.",
                    "label": 0
                },
                {
                    "sent": "And as estimated for the higher eigenvalues are estimated too high.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we if we know this systematic in the bias, we can can do something about it.",
                    "label": 1
                },
                {
                    "sent": "And this is this is called shrinkage.",
                    "label": 0
                },
                {
                    "sent": "So if we have the empirical covariance matrix estimated from the data and we have to make it more spherical so we have seen that it's too elongated, so we have to make it more spherical and therefore we use a linear combination of the estimated covariance matrix and spherical covariance matrix, which is identity.",
                    "label": 1
                },
                {
                    "sent": "And to have the correct size, it's multiplied by the average eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So now we have a parimeter and an updated estimate depending on this parameter gamma, which is a linear.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Combination between these two matrices.",
                    "label": 0
                },
                {
                    "sent": "An interesting observation is is here the following week to see this one takes a Eigen value decomposition of the empirical covariance matrix like this.",
                    "label": 1
                },
                {
                    "sent": "Then you have eigenvectors in Matrix V and the eigen various in the diagonal D. And you can easily check that the.",
                    "label": 0
                },
                {
                    "sent": "I can value decomposition of this shrinked matrix.",
                    "label": 0
                },
                {
                    "sent": "Looks like this here so we have the same.",
                    "label": 0
                },
                {
                    "sent": "Eigenvectors we.",
                    "label": 0
                },
                {
                    "sent": "And here just a modified diagonal matrix in the middle.",
                    "label": 0
                },
                {
                    "sent": "And this diagonal matrix is a linear combination of the original.",
                    "label": 1
                },
                {
                    "sent": "Diagonal matrix and identity with multiplaza average eigenvalue, so the original covariance S empirical covariance matrix and the shrink types assign eigenvectors so it does not turn somehow, but it stays in the same direction.",
                    "label": 1
                },
                {
                    "sent": "And so extreme eigenvalues are shrunked or extended to the average.",
                    "label": 0
                },
                {
                    "sent": "What you can see here.",
                    "label": 0
                },
                {
                    "sent": "So that means we counterbalances systematic bias, and if we look at the extremes, if we set gamma to 0, then we have so original empirical covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So that's original entity A and if we set gamma to one, then the first time cancels out.",
                    "label": 0
                },
                {
                    "sent": "So we assume that the covariance matrix is very clear.",
                    "label": 0
                },
                {
                    "sent": "So now we have.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem that there's a free parameter gamma, and there are many different ways how to estimate it.",
                    "label": 0
                },
                {
                    "sent": "One easy way is to.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use cross validation.",
                    "label": 0
                },
                {
                    "sent": "So we do just try out different values and here in this simulation with.",
                    "label": 0
                },
                {
                    "sent": "250 dimensional data.",
                    "label": 0
                },
                {
                    "sent": "You'll see if you have few training data to under 50 training data, then you need a higher value for gamma to get the lowest error rate and with increasing number of samples you need a lower gamma or even gamma equals 0 if you have enough.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding data, no shrinkage is needed.",
                    "label": 0
                },
                {
                    "sent": "So did go more into detail here.",
                    "label": 0
                },
                {
                    "sent": "This again, the formulas for LDA and shrinkage if we do complete shrinkage, gamma equals one.",
                    "label": 0
                },
                {
                    "sent": "Then see covariance matrix that we use is just scaled identity, so this cancels hours.",
                    "label": 0
                },
                {
                    "sent": "That means there's a classification.",
                    "label": 0
                },
                {
                    "sent": "The classifier vectors just the difference of the two means.",
                    "label": 0
                },
                {
                    "sent": "So then the spatial filter is just the difference of the of the earpiece.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on the other hand, if we don't use shrinkage, equals zero.",
                    "label": 0
                },
                {
                    "sent": "We use a estimated covariance matrix and so.",
                    "label": 0
                },
                {
                    "sent": "Here we get for gamma equals one.",
                    "label": 0
                },
                {
                    "sent": "We have a very smooth filter spatially.",
                    "label": 0
                },
                {
                    "sent": "And here we have a.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More weekly one, but it's.",
                    "label": 0
                },
                {
                    "sent": "So there's a continuous transition from the two extremes and the more I.",
                    "label": 0
                },
                {
                    "sent": "Leave out the shrinkage.",
                    "label": 0
                },
                {
                    "sent": "The lower scanner, the more we are accounting for the spatial structure.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The noise.",
                    "label": 0
                },
                {
                    "sent": "And to go into more detail here so.",
                    "label": 0
                },
                {
                    "sent": "A simple model assumption for event related potentials is the following that we've the single trial fix case that we measure is a.",
                    "label": 1
                },
                {
                    "sent": "Linear combination of of a true.",
                    "label": 1
                },
                {
                    "sent": "Yeah P, that's constant for trials S and noise.",
                    "label": 0
                },
                {
                    "sent": "Then in this scatter plot, 2 dimensional means that mean of one class.",
                    "label": 0
                },
                {
                    "sent": "This is a phase locked activity, so this is just the ERP.",
                    "label": 0
                },
                {
                    "sent": "Enter covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Has all the rest also non phase locked activity?",
                    "label": 0
                },
                {
                    "sent": "So which is considered noise?",
                    "label": 0
                },
                {
                    "sent": "And to get an idea about what this noise that comes from, you can make a principal component analysis of this.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Covariance matrix and the first 2 principal components of the noise.",
                    "label": 1
                },
                {
                    "sent": "In this case, if this.",
                    "label": 0
                },
                {
                    "sent": "Maps so the first is like flexor P300 map, so this is probably due to the fact that the model assumption is not correct.",
                    "label": 0
                },
                {
                    "sent": "The ERP is not constant in each trial but there is variation depends on many factors that are different in each.",
                    "label": 0
                },
                {
                    "sent": "So there's this is one source of variance at the PS3 is different in each trial and another strong source of variances visual Alpha.",
                    "label": 0
                },
                {
                    "sent": "So it's from the visual area.",
                    "label": 0
                },
                {
                    "sent": "We have some.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gradient.",
                    "label": 0
                },
                {
                    "sent": "Proposing and so this is now very important to understand what this noise does and how it has to be accounted for in the classifier.",
                    "label": 0
                },
                {
                    "sent": "So here this is artificially generated some.",
                    "label": 0
                },
                {
                    "sent": "Not so much disturbed data, so we have the potential to electrodes F set at CP set in the two conditions target and non target so they have very nicely separated because they are quite clean.",
                    "label": 0
                },
                {
                    "sent": "But we have seen that one source of noise, for example, comes from the Alpha rhythm from from Ozette.",
                    "label": 0
                },
                {
                    "sent": "And now I added some to disk clean data, some Alpha rhythm from ozette with two different factors.",
                    "label": 0
                },
                {
                    "sent": "So this is nearer or higher factor for CP set and.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lower factor for FC-2 and then we get this plot.",
                    "label": 0
                },
                {
                    "sent": "Why is the classification here linear?",
                    "label": 0
                },
                {
                    "sent": "Classification is 15% of error in the second case is.",
                    "label": 0
                },
                {
                    "sent": "37% of error.",
                    "label": 0
                },
                {
                    "sent": "But we in this case we know the source of the noise.",
                    "label": 0
                },
                {
                    "sent": "So if we add this disturbing channel or set set introduces this noise and we classify on these three channels, then again we have a error of.",
                    "label": 0
                },
                {
                    "sent": "16%.",
                    "label": 0
                },
                {
                    "sent": "And so the important message here is that we need this, oh, that Channel for a good classification.",
                    "label": 0
                },
                {
                    "sent": "Also in itself.",
                    "label": 0
                },
                {
                    "sent": "It has no discriminative information.",
                    "label": 0
                },
                {
                    "sent": "So the mean for the two conditions in Ozette is the same for both classes.",
                    "label": 0
                },
                {
                    "sent": "But nevertheless we needed for classification so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Therefore you see that.",
                    "label": 0
                },
                {
                    "sent": "In this case, equals one where we only use the difference between the two means as a classifier.",
                    "label": 0
                },
                {
                    "sent": "This does not account for this this noise, so this this difference of the mean would have the weight 0 for the channel or that and would not make use of it only if we have a lower gamma then.",
                    "label": 0
                },
                {
                    "sent": "We account for the noise and therefore so from the topography.",
                    "label": 0
                },
                {
                    "sent": "Maybe you like more this smooth filters, but I hope I convinced you that this more complicated filters are important to account for the noise only.",
                    "label": 0
                },
                {
                    "sent": "This way you can cancel out noise from this other electrodes.",
                    "label": 0
                },
                {
                    "sent": "Here you see the error rates and you see in this case low gamma but non 0.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What pizza is the best?",
                    "label": 0
                },
                {
                    "sent": "So now I hope, hopefully convince you that it's the shrinkage is the nice thing, but so far there's a problem that is.",
                    "label": 0
                },
                {
                    "sent": "The selection is time consuming with cross validation, but recently there was a analytical way to calculate the optimal gamma was published and we were pointed to this technique by Nicole Kramer.",
                    "label": 1
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part of either group.",
                    "label": 0
                },
                {
                    "sent": "So this is a setting is again we have feature vectors.",
                    "label": 0
                },
                {
                    "sent": "We estimate the mean and estimates.",
                    "label": 0
                },
                {
                    "sent": "Covariance matrix and we want to find the best shrinkage here.",
                    "label": 0
                },
                {
                    "sent": "To get the imp.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moved covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "And so you don't need to study this.",
                    "label": 0
                },
                {
                    "sent": "But The thing is.",
                    "label": 0
                },
                {
                    "sent": "We want to get some clothes, get as close as possible to the unknown true covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So we want to minimize the norm of the our estimation and the true covariance matrix, and so this looks like hopeless to calculate it because this Sigma is a true covariance matrix is unknown.",
                    "label": 1
                },
                {
                    "sent": "But it turns out if we restrict the search space to this form, then you can calculate the optimal gamma also in this.",
                    "label": 0
                },
                {
                    "sent": "Calculation the true covariance matrix cancels out, and so optimal parameter gamma only depends on very simple values correlation coefficients.",
                    "label": 0
                },
                {
                    "sent": "So variants of correlation coefficients across priors.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Very simple to calculate and then.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have set optimal gamma for for shrinkage and now if we use this LDA with shrinkage of the covariance matrix, we get to drastically reduced error rate.",
                    "label": 1
                },
                {
                    "sent": "So then only here is 4% of error.",
                    "label": 0
                },
                {
                    "sent": "So this huge decrease was due to shrinkage.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so this this works.",
                    "label": 0
                },
                {
                    "sent": "Very various not only for this particular data set.",
                    "label": 0
                },
                {
                    "sent": "Here we had to have the results for the classical matrix speller with certain participants who were completely naive and so new to the paradigm.",
                    "label": 1
                },
                {
                    "sent": "They were not preselected.",
                    "label": 0
                },
                {
                    "sent": "And here's a classification accuracy for different numbers of repetitions of the.",
                    "label": 0
                },
                {
                    "sent": "Stimulation, so this is accuracy in letter selection, so the chance level is at 3% and you see that with only very few intensifications we get very high classification accuracy.",
                    "label": 1
                },
                {
                    "sent": "So if.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look at the mean across subjects you see.",
                    "label": 0
                },
                {
                    "sent": "That was far intensifications where at median across subjects 100%.",
                    "label": 0
                },
                {
                    "sent": "So just this is simple techniques I've just introduced, so if we want to see more details of this study, is he posted a W7 by my tears, trader and other applications where we use this classification technique?",
                    "label": 0
                },
                {
                    "sent": "A tool where we can servings and W 10 by Jan this sooner?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, this linear classification with shrinkage is a very powerful method, and but of course whether a linear method is enough depends on the kind of features you have extracted.",
                    "label": 1
                },
                {
                    "sent": "But if you can do it with a linear methods and it's very nice because you can visualize what was learned by the algorithm.",
                    "label": 1
                },
                {
                    "sent": "So also for this spatial temporal features, the classifier weight vector can be visualized as a sequence of Maps.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was for spatial temporal features.",
                    "label": 0
                },
                {
                    "sent": "So now short section about spectral features.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was already introduced Moreles bye bye Gallagher.",
                    "label": 0
                },
                {
                    "sent": "So if we look at the Idol rhythm over the sensory motor area and then we see some peaks in the spectrum.",
                    "label": 0
                },
                {
                    "sent": "If the handles address for example and we look at this electrode through this peaks though right?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rhythms and if a movement is performed or just imagine, then these peaks are decreased, so this is a local blocking of the sensory motor rhythm and.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This also.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah D skips it then.",
                    "label": 0
                },
                {
                    "sent": "God bless also.",
                    "label": 0
                },
                {
                    "sent": "Said that, this is very strong spatial smearing, so here I have calculated from one data set the correlation coefficient from electrodes.",
                    "label": 0
                },
                {
                    "sent": "He said to all other electrodes and you see that.",
                    "label": 0
                },
                {
                    "sent": "Correlation coefficient is almost .9 or above .944 all electrodes, so there's a very strong spatial smearing, and that means if you look at the data, you should first apply some spatial filter, and this is especially true for this differences in spectral content, yet so.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example that should illustrate this need.",
                    "label": 0
                },
                {
                    "sent": "This is for left hand motor imagery and right hand motor imagery and we look at electrode CP four and then we should observe the decrease of spectral energy for left hand motor imagery for the black line.",
                    "label": 0
                },
                {
                    "sent": "And if you look at the raw channel then we don't see any difference at all.",
                    "label": 0
                },
                {
                    "sent": "If we make a bipolar apply bipolar filter you see a little bit.",
                    "label": 0
                },
                {
                    "sent": "Common average reference.",
                    "label": 0
                },
                {
                    "sent": "But only in this replacing filter we can see that this original peak is really composed of two peaks, and in fact the lower peak is from visual Alpha.",
                    "label": 0
                },
                {
                    "sent": "So this has nothing to do with motor imagery and some modulation happens only in this.",
                    "label": 0
                },
                {
                    "sent": "This upper peak and.",
                    "label": 0
                },
                {
                    "sent": "So to look at it, you should always apply are placed in filter and then if you calculate CSP which I introduced next, which is a data driven method to optimize the spatial filters and you can strongly enhances discrimination.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, but for CSP, the first step is to find a frequency band, where can expect a difference of the two conditions, so you.",
                    "label": 0
                },
                {
                    "sent": "Phil will take away now of this motor imagery data set for left hand and right hand motor imagery and plot Spectra for each channel.",
                    "label": 0
                },
                {
                    "sent": "And yes, I.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's quite useful.",
                    "label": 0
                },
                {
                    "sent": "This color bar indicates the ask where value is assigned task for values, so that you see the significance of the difference.",
                    "label": 0
                },
                {
                    "sent": "So then in this data set you see very easily that.",
                    "label": 0
                },
                {
                    "sent": "Find 2.",
                    "label": 0
                },
                {
                    "sent": "Frequency band have.",
                    "label": 0
                },
                {
                    "sent": "Certain conditions are discriminable is then you can bandpass filters as your signals which is in this frequency band and look at the time cost.",
                    "label": 1
                },
                {
                    "sent": "So this is average amplitude in this frequency band or also called DRD curves.",
                    "label": 0
                },
                {
                    "sent": "And then you can see in which time interval is a discrimination is most prominent.",
                    "label": 1
                },
                {
                    "sent": "So this is very different for are very not very but different for different subjects.",
                    "label": 0
                },
                {
                    "sent": "So therefore it's important to select this specifically for each subject.",
                    "label": 0
                },
                {
                    "sent": "So some have a very early yearly, but which does not last long and for others it takes 2 seconds to develop the ID, so can only have a good discrimination if you pin points is frequency band and time interval for each subject.",
                    "label": 0
                },
                {
                    "sent": "And now.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Auto.",
                    "label": 0
                },
                {
                    "sent": "So the classification on this feature turned out this come special pattern algorithm is quite powerful and you can see it as such an algorithm in the middle years observed signals that you measure in EG.",
                    "label": 1
                },
                {
                    "sent": "Well, it says this is.",
                    "label": 0
                },
                {
                    "sent": "A mixture due to the special smearing from the sources and for our classification purpose we are interested in two kinds of sources.",
                    "label": 0
                },
                {
                    "sent": "One is that minimizes the variance for right hand motor imagery and other sources that minimize the variance for left hand motor imagery.",
                    "label": 1
                },
                {
                    "sent": "We are not interested in the other sources and so she is P. Estimates this mixing and this.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Filters.",
                    "label": 0
                },
                {
                    "sent": "So if you have successfully calculated the CSP then.",
                    "label": 0
                },
                {
                    "sent": "It's also almost a whole problem, so here's a time causes of the AG filtered with this special filters.",
                    "label": 0
                },
                {
                    "sent": "Here's PR and SSPL.",
                    "label": 0
                },
                {
                    "sent": "You see, after right and motor imagery in this upper filter is the variance goes down very much.",
                    "label": 0
                },
                {
                    "sent": "And then the other filters.",
                    "label": 0
                },
                {
                    "sent": "The variance goes down after left hand motor imagery.",
                    "label": 0
                },
                {
                    "sent": "So if you have probably.",
                    "label": 0
                },
                {
                    "sent": "Optimize these filters and classification is very easy.",
                    "label": 0
                },
                {
                    "sent": "You just calculate the variance in some time interval and just can compare where there's more variance.",
                    "label": 0
                },
                {
                    "sent": "And here also in CSP, like with the linear classifiers and the spectral temporal features, it's nice that you can visualize them and see what was learned.",
                    "label": 0
                },
                {
                    "sent": "So these are spatial filters, so you can visualize and check whether this makes sense.",
                    "label": 0
                },
                {
                    "sent": "Then you can also detect when the subject, for example produced artifacts and controls.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "PCI was with different kind of signals.",
                    "label": 0
                },
                {
                    "sent": "So in the calculation of CSP is also not very difficult.",
                    "label": 0
                },
                {
                    "sent": "You concatenate on one hand or the trials for left hand motor imagery and from right hand motor imagery.",
                    "label": 0
                },
                {
                    "sent": "So before you apply the bend pass filter so frequency band and then you solve for generalized eigenvalue problem.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Like like this and.",
                    "label": 0
                },
                {
                    "sent": "So here this is like a simuel tanias PCA of eigenvalue decomposition of the sub matrices.",
                    "label": 0
                },
                {
                    "sent": "And then you can select from the Matrix V. Your special filters are the eigenvectors, so you can see that.",
                    "label": 0
                },
                {
                    "sent": "Then if you choose Eigenvector VI that corresponds to a large eigenvalue diyan this decomposition then the variance if we.",
                    "label": 0
                },
                {
                    "sent": "Take a left hand motor imagery data enterprise, a special filter, and this variance.",
                    "label": 0
                },
                {
                    "sent": "Equals to the eigenvalue you to this equation, so then it is large and on the other hand if we apply the same spatial filter to right hand data then beauty other condition that you chose this conditions is eigenvalue sum up to one, then this must be 1 minus eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "So you have trains this spatial filter that at the same time maximize variance for one condition and minimize it for the other condition.",
                    "label": 0
                },
                {
                    "sent": "And to calculate it in MATLAB is very easy.",
                    "label": 0
                },
                {
                    "sent": "It's just one line 2.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sources.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Area problem.",
                    "label": 0
                },
                {
                    "sent": "And yeah, if you have applied this filters then you just calculate the variance and applies a logarithm and.",
                    "label": 0
                },
                {
                    "sent": "In your single choice and get low dimensional features that can be.",
                    "label": 0
                },
                {
                    "sent": "Classified Jasper.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Linear.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classifier, so here's a summary in pictures.",
                    "label": 0
                },
                {
                    "sent": "So first is to determine the frequency band and then the time interval and based on these data you can apply CSP.",
                    "label": 0
                },
                {
                    "sent": "And then you select appropriate CSP filters.",
                    "label": 0
                },
                {
                    "sent": "For example according to this eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "And then you calculate variance and logarithm to get to.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Features.",
                    "label": 0
                },
                {
                    "sent": "And then in online operation you take the.",
                    "label": 1
                },
                {
                    "sent": "Actually G that is measured applies.",
                    "label": 0
                },
                {
                    "sent": "A spatial filter applies a bandpass filter and calculates the variance in a short window like the last half second and takes a logarithm and apply your classifier ways.",
                    "label": 1
                },
                {
                    "sent": "So it's very easy linear procedure.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about CSP is that you can change the length of this classification window in runtime, so this.",
                    "label": 1
                },
                {
                    "sent": "Para meters that you estimate do not depend on the length, so you can train on very longer trials, but then in feedback apply it on short twice and make this trade off of.",
                    "label": 0
                },
                {
                    "sent": "Short latency's and accuracies.",
                    "label": 0
                },
                {
                    "sent": "So there's a tutorial on.",
                    "label": 0
                },
                {
                    "sent": "CSP, where can I learn more?",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the search section and so this.",
                    "label": 0
                },
                {
                    "sent": "Up my my cross certain lost so.",
                    "label": 0
                },
                {
                    "sent": "I hope I convinced you that machine learning algorithms can be very useful in single try e.g analysis.",
                    "label": 0
                },
                {
                    "sent": "But there's also a problematic part and this is a validation of the methods and unfortunately can see in many.",
                    "label": 0
                },
                {
                    "sent": "Manuscripts that are submitted to journals and even in published articles that many, many groups are not aware.",
                    "label": 0
                },
                {
                    "sent": "Not many groups that some research labs are not aware of, or.",
                    "label": 0
                },
                {
                    "sent": "Problems that there one has to take care of in the validation.",
                    "label": 0
                },
                {
                    "sent": "So this is trying to.",
                    "label": 0
                },
                {
                    "sent": "Give some some advice to make a proper.",
                    "label": 0
                },
                {
                    "sent": "Validation so the.",
                    "label": 0
                },
                {
                    "sent": "The principle of validating this this method is quite quite obvious, so for this machine learning methods you typically require one training data set.",
                    "label": 0
                },
                {
                    "sent": "To tune your are your para meters on and test data set which is set in the real application.",
                    "label": 0
                },
                {
                    "sent": "There the feedback data that is of course don't know in advance how it looks like.",
                    "label": 0
                },
                {
                    "sent": "So the validation can only be proper if you don't use this test set in any way to determine some some of your para meters.",
                    "label": 1
                },
                {
                    "sent": "And also if the samples in the test set are independent from the samples in the training set.",
                    "label": 1
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so these are more concrete.",
                    "label": 0
                },
                {
                    "sent": "Some problems that may occur first is that there's a problem.",
                    "label": 0
                },
                {
                    "sent": "Then if preprocessing methods, use statistics of the whole data set example.",
                    "label": 1
                },
                {
                    "sent": "So in your validation your typically take one data set and want to validate the message on that.",
                    "label": 0
                },
                {
                    "sent": "And if you first use the whole data set to compute some statistics.",
                    "label": 0
                },
                {
                    "sent": "And pre process it and do the validation afterwards so that it's wrong and that's that's a problem.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you apply ICA to the whole data set in the beginning and only do the cross validation.",
                    "label": 1
                },
                {
                    "sent": "For the classifier in the end.",
                    "label": 0
                },
                {
                    "sent": "So then you use some statistics of the test set for pre processing and what you shouldn't.",
                    "label": 0
                },
                {
                    "sent": "Or if you normalize the features based on including the samples from the from the test set.",
                    "label": 0
                },
                {
                    "sent": "And this is a particular severe problem if your preprocessing methods use label information.",
                    "label": 0
                },
                {
                    "sent": "For example the CSP as I've shown you before.",
                    "label": 1
                },
                {
                    "sent": "If you calculate CSP first on the whole data set.",
                    "label": 0
                },
                {
                    "sent": "And then do a cross validation only for the classifier part.",
                    "label": 0
                },
                {
                    "sent": "You will severely underestimate the error.",
                    "label": 0
                },
                {
                    "sent": "So in particular we have some several datasets.",
                    "label": 0
                },
                {
                    "sent": "If you do that, you would get like 0% error because this special filters are somehow overfitted.",
                    "label": 0
                },
                {
                    "sent": "And if you do a proper validation you get chance level.",
                    "label": 0
                },
                {
                    "sent": "So instead yeah.",
                    "label": 0
                },
                {
                    "sent": "So that means either you do this preprocessing within the cross validation, which is very time consuming, or you don't do cross validation, but just split the data once in training and test set.",
                    "label": 1
                },
                {
                    "sent": "So which is more or less the same?",
                    "label": 0
                },
                {
                    "sent": "So if you do feature selection on the whole data set.",
                    "label": 0
                },
                {
                    "sent": "And only validates the classification.",
                    "label": 0
                },
                {
                    "sent": "This will also be.",
                    "label": 0
                },
                {
                    "sent": "Completely underestimating the perform overestimating the performance.",
                    "label": 0
                },
                {
                    "sent": "So feature must be selected only based on the training set.",
                    "label": 0
                },
                {
                    "sent": "Send if you if you would, select some some hyperparameters like the gamma of shrinkage.",
                    "label": 0
                },
                {
                    "sent": "If you don't have the automatic way, but if you select the gamma is also a problem.",
                    "label": 0
                },
                {
                    "sent": "If you do a.",
                    "label": 0
                },
                {
                    "sent": "For each gamma, a proper cross validation and then say oh I see gamma equals .2 is the best best value and report this error as your generalization performance.",
                    "label": 0
                },
                {
                    "sent": "So then the selection of the gamma dependent on the test set.",
                    "label": 0
                },
                {
                    "sent": "So you have to select all these parameters also these hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "Based on the training set.",
                    "label": 1
                },
                {
                    "sent": "Then another problem.",
                    "label": 1
                },
                {
                    "sent": "If artifacts are outliers are removed from the whole data set, and then you do a cross validation because then you make your test set easier.",
                    "label": 0
                },
                {
                    "sent": "So to say.",
                    "label": 0
                },
                {
                    "sent": "So you're also exclude the.",
                    "label": 0
                },
                {
                    "sent": "Artifacts from from the test set.",
                    "label": 0
                },
                {
                    "sent": "So of course you can have methods for online detection of artifacts and reject them, But then you need a different performance measure.",
                    "label": 0
                },
                {
                    "sent": "So I hope that these points were more less clear for the audience and one points I want to focus on.",
                    "label": 0
                },
                {
                    "sent": "Remaining part and this is unsufficient validation in paradoxes block design.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is what I mean by that.",
                    "label": 0
                },
                {
                    "sent": "So the task is to discriminate between mental states in two different conditions and I call.",
                    "label": 1
                },
                {
                    "sent": "So design a block design is a period for which there is no alteration between the two.",
                    "label": 0
                },
                {
                    "sent": "Conditions are much longer than the switching should be in the real performance.",
                    "label": 0
                },
                {
                    "sent": "In the online situation, so this can be may be best explained with this figure.",
                    "label": 0
                },
                {
                    "sent": "So here we have different blocks, 7 seven blocks, and in the first block we only have tries according to condition, one.",
                    "label": 0
                },
                {
                    "sent": "In the second block only.",
                    "label": 0
                },
                {
                    "sent": "Trials according to condition two and so on.",
                    "label": 0
                },
                {
                    "sent": "So this might be that the subject is continuously in one condition and you if you're just cut out smaller single trials here.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, like LEXIS separated thing.",
                    "label": 0
                },
                {
                    "sent": "So this kind of designs.",
                    "label": 0
                },
                {
                    "sent": "Sometimes used if the condition is one that you can.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's it's more easy to to.",
                    "label": 0
                },
                {
                    "sent": "Keep keep up for a longer time.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to drive her BCI with.",
                    "label": 0
                },
                {
                    "sent": "Say doing math or mathematics mentale or mental mental arithmetic, or composing a letter, then maybe it's not so easy to ever design to switch very rapidly in the training.",
                    "label": 0
                },
                {
                    "sent": "To have like half a minute doing one condition half a minute or the other condition.",
                    "label": 0
                },
                {
                    "sent": "But you may have saved the goal that in the feedback you learn how to switch quickly between the two conditions.",
                    "label": 1
                },
                {
                    "sent": "So so that it's a problem if you.",
                    "label": 0
                },
                {
                    "sent": "Take such a data set and then cut out these smaller segments and do a cross validation based on this.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Smaller units.",
                    "label": 0
                },
                {
                    "sent": "So the problem is due to the following facts.",
                    "label": 0
                },
                {
                    "sent": "So here's a cartoon of how you would split 11 fold of the cross validation.",
                    "label": 0
                },
                {
                    "sent": "It would take most.",
                    "label": 0
                },
                {
                    "sent": "Epoxy for training and some for testing and the problem is that there are many features in in e.g that are due to background activity and that are slowly changing so this is a cartoon of such features like this is a time span of.",
                    "label": 0
                },
                {
                    "sent": "Few minutes and then for example here this blue line is steadily increasing, so this could be increasing vigilance and as a as a variable.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Also, so this these are variables that you really should should not be used in your classification because they're background activity.",
                    "label": 0
                },
                {
                    "sent": "And but if you do do a classification based on this this these features may be may be used for the further classification and the problem is the validation is at training and test set are not independent.",
                    "label": 1
                },
                {
                    "sent": "For example, if you look at this second block, there are three epochs put in the training set and one in the middle.",
                    "label": 0
                },
                {
                    "sent": "In the test set.",
                    "label": 0
                },
                {
                    "sent": "And so this slow changing features would be the same for for all and so they're not not independent if I learn.",
                    "label": 0
                },
                {
                    "sent": "Since background activity in this training set based on these trees and I would correctly classify this.",
                    "label": 0
                },
                {
                    "sent": "You spoke in the test set, although I didn't have a proper classification on the thing that discriminates between blue and green, but just because I recognize the signature of.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Block based on background activity.",
                    "label": 0
                },
                {
                    "sent": "And to demonstrate that this really needs leads can lead to severe.",
                    "label": 1
                },
                {
                    "sent": "Misestimation of performance.",
                    "label": 0
                },
                {
                    "sent": "I did this.",
                    "label": 0
                },
                {
                    "sent": "Similar not simulation, but this validation.",
                    "label": 0
                },
                {
                    "sent": "I took a true e.g data set and I assigned fake labels in the following way.",
                    "label": 1
                },
                {
                    "sent": "So the first condition one block per class.",
                    "label": 1
                },
                {
                    "sent": "Made two blocks and assign single trials for class one and one block and single phase of the other class.",
                    "label": 0
                },
                {
                    "sent": "The other block and then in the next validation I took two blocks per class like this and here's three blocks and then I did cross validation based on these single.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "5.",
                    "label": 0
                },
                {
                    "sent": "And this is a single trial set length of 1 second and this was done for 80 AG datasets.",
                    "label": 0
                },
                {
                    "sent": "As he says, the results, so the labels were fake labels.",
                    "label": 0
                },
                {
                    "sent": "They were just assigned in this schematic way and didn't have anything to do with the server mental state.",
                    "label": 0
                },
                {
                    "sent": "So we should expect that the accuracy is at chance.",
                    "label": 0
                },
                {
                    "sent": "So cause student to conditions it should be at 50% if you have in this strongest thing where we only have one block per class is so average error or the median error was at 8% and so this increases.",
                    "label": 0
                },
                {
                    "sent": "If you have more blocks because then it's harder to find discriminative features.",
                    "label": 0
                },
                {
                    "sent": "But yeah you see only here at 10 blocks it approximates the chance level, but it still will see even with the standard errors it.",
                    "label": 0
                },
                {
                    "sent": "Lower chance level.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and what's a different validation method would be a leave one block out validation.",
                    "label": 0
                },
                {
                    "sent": "So you don't have the normal cross validation but exclude one whole block from the training from the training train on the other blocks and tests, and on the holdout block.",
                    "label": 0
                },
                {
                    "sent": "So in this case, if what's a classifier was learned is only based on this.",
                    "label": 0
                },
                {
                    "sent": "Background features that should not generalize to this block that was not seen, and if I do this for the very same data, this kind of validation, you get the green boxes.",
                    "label": 0
                },
                {
                    "sent": "So then this season medianus of all these cases is more or less at 50%.",
                    "label": 0
                },
                {
                    "sent": "But as the price of a larger standard error, so then you have less variation and an shuffling, so this is a downside and sad to see reason why people like to do cross validation.",
                    "label": 0
                },
                {
                    "sent": "OK, but in this case is I think it's mandatory to check this other validation, but this of course is not possible in the case where you only have two blocks and you would leave out one complete class for training, so there's nothing you can do here.",
                    "label": 0
                },
                {
                    "sent": "So yeah, that two important messages here.",
                    "label": 0
                },
                {
                    "sent": "One is if in the design of the experiment, if you.",
                    "label": 0
                },
                {
                    "sent": "Can avoid block design.",
                    "label": 0
                },
                {
                    "sent": "It's better to to avoid it or to have or if you need block design, at least try to have as many alterations between the conditions as possible and for the validation you should at least also check the leave one block out.",
                    "label": 0
                },
                {
                    "sent": "So of course this is only validated the simulation done for one type of feature that I extracted an.",
                    "label": 0
                },
                {
                    "sent": "If you have very simple features it might not be that your classification results are based on this, but at least there's always a danger.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the severeness of this underestimation of the true error depends on the complexity of the features and of the classifier.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Sorry it can be if you have.",
                    "label": 0
                },
                {
                    "sent": "Simple, simple features and simple classifiers at the that you get to correct performance measures.",
                    "label": 0
                },
                {
                    "sent": "So you cannot really say this is this is wrong, but at least you need some further evidence.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, and I already said that the downside is that the standard errors are larger in this validation.",
                    "label": 0
                },
                {
                    "sent": "So and this is.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remarks I hand over to close again.",
                    "label": 0
                },
                {
                    "sent": "So maybe I used the time to actually do what I failed to do because I'm Steven and I didn't properly talk about this.",
                    "label": 0
                },
                {
                    "sent": "I namely introducing Benjamin.",
                    "label": 0
                },
                {
                    "sent": "So Benjamin got his PhD in math in Munster and then moved to Berlin, and as you saw his driving figure also in the building brain computer interface.",
                    "label": 0
                },
                {
                    "sent": "So OK, let me just.",
                    "label": 0
                },
                {
                    "sent": "So in the remaining.",
                    "label": 0
                },
                {
                    "sent": "1015 minutes Anne.",
                    "label": 0
                },
                {
                    "sent": "I have",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After just let me just get rid of this.",
                    "label": 0
                },
                {
                    "sent": "M. So I think that the bottom line of what Benjamin said is so that 2, two or three messages here.",
                    "label": 0
                },
                {
                    "sent": "So first of all.",
                    "label": 0
                },
                {
                    "sent": "If you, even if you have a linear classifier.",
                    "label": 0
                },
                {
                    "sent": "Then you can very easily overfit.",
                    "label": 0
                },
                {
                    "sent": "If you have high dimensional feature spaces and you should do something about it and shrinkage is a very good idea and works very well.",
                    "label": 0
                },
                {
                    "sent": "CSP is also a nice thing, so it's a one line metal up thing.",
                    "label": 0
                },
                {
                    "sent": "Anne and.",
                    "label": 0
                },
                {
                    "sent": "Any of the pitfalls that you've seen on the slides will lead to immediate rejection of the manuscript.",
                    "label": 0
                },
                {
                    "sent": "If I'm the editor and the same holds for Benjamin, just to keep this in mind, and I think it also became clear why this is the case.",
                    "label": 0
                },
                {
                    "sent": "And the block design can actually in the machine learning methods can make you seem do great things, whereas in truth you do something random.",
                    "label": 0
                },
                {
                    "sent": "So I think this needs to be very carefully.",
                    "label": 0
                },
                {
                    "sent": "Considered, and This is why we put it here in this tutorial, because most of you know, but it's always nice to look it up.",
                    "label": 0
                },
                {
                    "sent": "Or to be able to look it up?",
                    "label": 0
                },
                {
                    "sent": "OK so so basically set up of a BCI system would be some feature extractors.",
                    "label": 0
                },
                {
                    "sent": "We've seen CSP.",
                    "label": 0
                },
                {
                    "sent": "We can also think about some dynamical features like a are coefficients per channel.",
                    "label": 0
                }
            ]
        }
    }
}