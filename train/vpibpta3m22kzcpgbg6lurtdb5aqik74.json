{
    "id": "vpibpta3m22kzcpgbg6lurtdb5aqik74",
    "title": "Extending functional dependency to detect abnormal data in rdf graphs",
    "info": {
        "author": [
            "Yang Yu, Lehigh University"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web->RDF - Resource Description Framework"
        ]
    },
    "url": "http://videolectures.net/iswc2011_yu_rdfgraphs/",
    "segmentation": [
        [
            "Today I would like to talk about our work of extending functional dependency to detect abnormal data in RDF graphs."
        ],
        [
            "So in this talk, first I will give the motivation and the background knowledge of functional dependency in the database.",
            "Then we introduce the concept of value clustered graph functional dependency and following it is the system and each component of the system finally is a conclusion and."
        ],
        [
            "Social work.",
            "So our goal of this work is to address some quality issues in the semantic web.",
            "On the web there are a number of motivations here, at least four of them, the first of them is that we know the load data quality is a pressing problem for information integration and the recent developments on the on.",
            "The semantic Web has suggested that it is possible to re sync the information integration, so we think the quality.",
            "Are there quality research on this matter?",
            "Web could also be promising for us to solve this.",
            "Some issues for the information integration and 2nd is motivation is that.",
            "Right now most of the semantic Web data are is converted from other forms of data by using a variety of tools and numerous problems could occur during this process.",
            "So can we find this problems?",
            "The third motivation of this research is that one of the exciting things of the semantic web is potential to move the web search web search to the document.",
            "Relevance to the.",
            "Query answering, however, given the numerous answers derived from various sources and statements.",
            "The quality assessment can be important criteria to filter out inaccurate or unreliable answers.",
            "The final motivation is that current trust most of the trusted research is based on the network and on these networks there's some atomic pairwise trust relationship given by users or third parties.",
            "So we think the quality assessment can be foundational input for that.",
            "To explain why it is trusted or not."
        ],
        [
            "So because the problem is very similar, similar to the data cleansing problem in the database, another data can be viewed as essentially as graph database.",
            "So we think we it is possible we learn some approaches from the domain of domain in the database and functional dependency has been shown promising in the database domain to.",
            "Address some quality issues and data dependency is by far the most common integrity constraints for the databases and it is devised to specify the missing semantics in mere syntactic definitions of database relations.",
            "Here I gave the definition of a functional dependency, so functional dependencies that, given the relation RA set of attributes X in R, is set to functional determine another attribute Y if and only if each X value is associated with precisely one.",
            "Why are value so here?",
            "I gave the two examples of functional dependency.",
            "Look at as a second example.",
            "Postal code determines the province which means.",
            "Given any specific value of Postal code, we can precisely know the province's property of the value of for the value for the property province.",
            "So here I highlighted four parts in the definition by the voting the fonts.",
            "They are all limitations or the challenges compared to the RDF graph we were talking to talk about it in the."
        ],
        [
            "Last night so given we remember just now the definition of functional dependency is based on a relation R in database.",
            "So however in other other graph can be viewed as extremely deep composed relational tables where each table is.",
            "Set of triples.",
            "Compose setup triples offer certain property, so the so the question is how we can group together group some properties or values into a.",
            "On corresponding a relation like set to for considering the functional dependency second high."
        ],
        [
            "And here we sat overseas a set of attributes X on the left hand side of the functional dependency.",
            "If actually we can see we can view this grouping as a set of attributes viewed as a.",
            "A combination of properties, so that's the only way of combining attributes in the database.",
            "In the functional dependencies."
        ],
        [
            "However, we know in the other data we have more forms to combine the properties and this combination is also conveys some latent semantics.",
            "So here I show we can combine the inverse properties and we can combine the properties through the composition property composition.",
            "So if considering this more from some combinations, we can compose exponential number of new attribute, a new properties based on the original properties.",
            "So that's another challenge we need to address here.",
            "The third."
        ],
        [
            "Challenger compared to the definition in the functional dependency is.",
            "Here we see in the definition of function density, each X value is associated with some other value, because in fact in the relational database, each value is put in a tuple and.",
            "It is cold here.",
            "Color paired with another value in a tuple, so that's cool.",
            "Appearance is determined by the tuple."
        ],
        [
            "Religion, however, in the RDF data, if we here we see example of property, City and province.",
            "For example, India Pedia, we don't have the constraint to say an instance can only use this property once.",
            "Well, considering an organization spanning over multiple cities or multiple provinces, the city, the value of city and valid value of problems could be converted to a curd in a setting.",
            "A group forms not in a single value, so that's a search challenger.",
            "We can we find the actual value correlation between these properties."
        ],
        [
            "Last challenge is that in the functional dependency the why the left the value on the right hand side is determined precisely by 1 value."
        ],
        [
            "However, in many cases we note as.",
            "We cannot determine exact precisely determine one value, but we can determine a group of values concerning the.",
            "Floating point numbers, for example, is it really different between this 1.001 and 1.0?",
            "And some for some strings they may contain conveys some other similar or actually the equivalent semantics.",
            "Honestly, the more general form some values is some group of values show the equivalent semantics.",
            "So for example, given a type of school, the upper ages will be in a small, very small range and then this show the logically similar semantics."
        ],
        [
            "So given these challenges, our system is trying to solve the each of them here give example of RDF graph, which is a directed labeled graph."
        ],
        [
            "We define the 1st way of combining property is complete property.",
            "Shown as a sequence of predicates."
        ],
        [
            "The art of graph and the value function will be valid function of given this property given the instance specific instance will be this value.",
            "Anne."
        ],
        [
            "Then the 2nd way to combine the property is.",
            "We called conjunctive property.",
            "It is essentially the same as.",
            "Grouping property together in the functional dependency.",
            "However, here the element of this conjunction property can be compensated properly with defined previously in previous slides."
        ],
        [
            "And as a functional and the value function of this complete conjunctive probably will be a tuple of values for each property involved.",
            "Last thing we want to emphasize that because of here the value function we give these specific value.",
            "Actually if we can find some cluster of values which shows consistent semantics so the value function could give return the cluster instead of the actual value."
        ],
        [
            "Then if we go in the other graphs, then we see the patterns that given any instance if they have the same value on the left hand side, then they have the same value on the right hand side property.",
            "So it could be a possible VFD.",
            "So in this sample we see the these two instances paper one Paper 2 have the same value on the left hand for the left hand side conjunctive property and they also has also have the.",
            "Same value for the right hand side property.",
            "So the goal is trying to find that such."
        ],
        [
            "The patterns in the other graph of this work.",
            "So first of all, if given this, given the two property and data about these two properties, how we can determine the true dependency between these two values?"
        ],
        [
            "In this example, we gave to practice one is Department number Department name.",
            "We're trying to find the dependency from the Department number to the different name.",
            "Then we first step is to compute the candidate value mappings and order them.",
            "Then we created we choose other optimum mappings."
        ],
        [
            "First we will choose this one, cause the value on the left side, the value one is only one has the largest account compared to the value 2 because value 2 has two equivalent mappings, both both of them has a maximum count."
        ],
        [
            "Then we will gradually choose this, this one, because there on the right hand side the value CS has the fewest mapping until so far.",
            "Where the intuition is trying to keep the variety of the mappings.",
            "If we sing."
        ],
        [
            "These two value mappings are more optimum than we can get the confidence of this VFD is the number of true mappings true matches divided by the number of usages.",
            "In this work, we set the confidence as .9 and after we get this VFD then we will.",
            "Meantime, I get the find the abnormal data because they had this instant D has mismatch on the values."
        ],
        [
            "The second challenge is that we we can we have more ways to combine properties in other data.",
            "So how to efficiently to prune out the impossible average FPS?",
            "Here we give four prosthetic pruning heuristics.",
            "They're based on two intuitions.",
            "The first intuition is that is it possible to compose, compose, compose properties together.",
            "And the second condition is that after the.",
            "Composed of properties and is it possible to use this property to determine another property which essentially is to find a functional mapping between values of two properties?",
            "So first, if you Ristic that insufficient overlap between the properties to be composed or between the left hand side on the right hand side.",
            "That's a straight forward, so if we cannot.",
            "If this is true, probably have don't have sufficient subject object object global overlap.",
            "It is impossible to compose to group them together.",
            "Can to compose a new property.",
            "For the second heuristic, we first define the disability of a property is equal to the number of distinct values divided by the size of proper extension.",
            "So and then, if the disability of the left hand side is less than that of the right hand side, it is impossible to consider the left hand side right hand side together in a VFD cause some values are multiple values of left hand side will be mapped to the same value on the right hand side, which is.",
            "Which is not a functional mapping.",
            "Then the circle Ristic is at the left side.",
            "Right side has too high disability, cause if the left side has two high disability, essentially it is like a super key property because we're trying to find the detector.",
            "I'm not more data by the checking the redundant value usages.",
            "So if the values used uniquely each time, so it is not helpful.",
            "In this scenario, the last.",
            "Here is the exact.",
            "To check how they discriminated, changed after the composition.",
            "So we see we see actually, for example, conjunctive properties essentially to doing.",
            "Addition products over the original property values, so the for conjunctive property.",
            "New property values will be definitely greater than the number of values will be greater than the each property values involved, so they can distribute it will be no less than that of that."
        ],
        [
            "We device a level level wise discovery process because the higher the communication are, the higher level can be reused on the lower level.",
            "Searching process.",
            "And here give I give example how this studying static pruning heuristics are useful to print out the.",
            "Unlikely.",
            "Which FD's?",
            "In this example?",
            "We suppose these three conditions?",
            "These three conditions are very common in a practical impractical datasets and then given this heuristics and this observation."
        ],
        [
            "It is straightforward to find such nodes will be impossible for considering a VFD and then on the 2nd."
        ],
        [
            "Of all these two groups of children's are thrown out due to the similar reason as their parent."
        ],
        [
            "And similarly other nodes can be thrown out due to the similar heuristics.",
            "In this example, we just want to show that the most of the nodes on the searching tree can be pruned out using just using this static pruning heuristics."
        ],
        [
            "After the prosthetic pruning, we still have a lot of VFD is to compute and we have seen the computation of each VFD is actually to find the optimal value mappings between property values, and we notice that in the information theory, mutual information is to compute the dependency between two variables and the entropy coefficient is to compute given the value given the variable value of Y.",
            "How likely we can know the value of the variable X?",
            "And if the value is close to one, which means given the value of variable one, we can definitely know the value of variable X.",
            "So we using this formula with sampling a subset of instances for VFD to compute the entropy coefficient, and if this value is far away from the weight predefined threshold.",
            "For true VFD, we can just Simply put."
        ],
        [
            "Out earlier, so we called it a runtime pruning.",
            "For the third, for the last challenge we mentioned previously is how we can find the group of values showing consistent semantics.",
            "We, we think the clustering is the general process.",
            "Doing that in our clustering process we have two phase.",
            "One is pre clustering which is designed to provide the minimum number of clusters and reserve expensive distance calculation for pairs of points within the same pre cluster.",
            "The general process is pick a point that is closest to the center and then class are points that are close to the center.",
            "Then repeat the steps.",
            "The intuition is intuition of choosing the point closest to center is that it can faster prune out of faster closely clustering points in early."
        ],
        [
            "Round.",
            "Then in the final grade classroom, we called it optimal.",
            "K means clustering.",
            "It is improved from existing work are called Gap statistic and so in this classroom process with without the input of K, we automatically find the optimal number of clusters for a prompt for the values of property.",
            "And in the variation of this, K means clustering.",
            "We restrict the distance calculation only on the pairs that within the same pre cluster."
        ],
        [
            "In our experiments we tested the system on the three datasets.",
            "One is as resistance, medical research corpus and the Pedia and our capital said we found a number of VFD's and here I show some examples there.",
            "In three groups, the first group in the first group, the Left Hand side, is single property and in the second group the Left Hand Side Composite Complex Properties by grouping.",
            "A combining properties and the third group shows which of these based on the value cluster?"
        ],
        [
            "Custard values and using this version of this we also detect a number of erroneous data in the real world data set, and here are some examples.",
            "And finally we give the system performance.",
            "Precision on three datasets we see the establecidas that has lowest precision.",
            "We think the reason is that the accuracy is.",
            "Relatively restricted domain, and it indeed has a higher quality."
        ],
        [
            "So conclusion, our system tries to find the data dependency patterns in the form of VFD and try to use them to detect abnormal data by checking conflicts with these patterns and experiments on the real world datasets validated the system.",
            "For future work, would like to further generalize VFD because in current system we are the which FD on the right hand side object, which FDR only the single property single original property.",
            "So it is definitely theoretically.",
            "Theoretically possible to extend the right hand side.",
            "Half of each empty into a compensated properly too.",
            "And we would like to apply in the system on the actual Knowledge acquisition areas to to detect the problems in that process."
        ],
        [
            "And I think that's thank you.",
            "So I would like to know how or if you are considering to relate this work with ongoing work on provenance representation and because it seems like data normally in RDF cross could be very related with understanding where the data comes from.",
            "Who has participated in generating the data and the transformation is it has gone through?",
            "Are you thinking on those lines or or not?",
            "Sorry, can you repeat what's really work?",
            "About provenance provenance representation vocabulary reasoning.",
            "Yeah actually yeah, we we indeed checked some really work on the Providence, but we think the one officer limitation of that approach is that needs problems, information and this information needs to import, you know, to input by the humans or users or given by some some places.",
            "Given some, you know some input.",
            "However, in many real world datasets we don't have such information to doing that to do that so.",
            "This I think that's one of the limitation.",
            "So yeah, I was wondering whether you have been looking into the summarize ability problem of aggregating data values like with sum or average, because there you always have to do sometimes have the problem that if you have certain dependencies, it doesn't make sense to summarize the data with certain aggregation functions.",
            "Now, I was wondering whether you have been looking into that.",
            "So let me rephrase your question so first, so you're talking about aggregating values for the considering the dependency.",
            "Um?",
            "Yeah, actually in our previous work we we try some approach using the summary graph to doing the summary to summarize the other graph to make the process finding the dependency more efficient.",
            "Um?",
            "But in that approach we.",
            "Because for the.",
            "Approach we only consider the object property values and easier to summarize object property values.",
            "However.",
            "We we we didn't find a solution to.",
            "How to aggregate the data type values?",
            "So that's why we designed this work design this approach so I just have one quick comment.",
            "Very interesting work, just trying this work to the work of the previous speaker, which is in the previous talk.",
            "It was about doing this classification, building classifiers and connecting to an RDF store, but it assumes that the data in the RDF store is correct, right?",
            "And you all work is about finding gaps in the data and also finding contradictions in the data.",
            "And so to the extent that you can use that and combine that with the previous work, you can probably improve the classifiers as well, but this is a comment, so yeah, essentially we can think of this.",
            "This system, also a classifier we know.",
            "Actually we classify the data into two groups.",
            "One is more likely correct when one group is more likely incorrect.",
            "Yeah, I think definitely we can.",
            "It is possible to think about combining these two works.",
            "Yeah, OK, thank you thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today I would like to talk about our work of extending functional dependency to detect abnormal data in RDF graphs.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this talk, first I will give the motivation and the background knowledge of functional dependency in the database.",
                    "label": 0
                },
                {
                    "sent": "Then we introduce the concept of value clustered graph functional dependency and following it is the system and each component of the system finally is a conclusion and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Social work.",
                    "label": 0
                },
                {
                    "sent": "So our goal of this work is to address some quality issues in the semantic web.",
                    "label": 0
                },
                {
                    "sent": "On the web there are a number of motivations here, at least four of them, the first of them is that we know the load data quality is a pressing problem for information integration and the recent developments on the on.",
                    "label": 1
                },
                {
                    "sent": "The semantic Web has suggested that it is possible to re sync the information integration, so we think the quality.",
                    "label": 0
                },
                {
                    "sent": "Are there quality research on this matter?",
                    "label": 0
                },
                {
                    "sent": "Web could also be promising for us to solve this.",
                    "label": 0
                },
                {
                    "sent": "Some issues for the information integration and 2nd is motivation is that.",
                    "label": 0
                },
                {
                    "sent": "Right now most of the semantic Web data are is converted from other forms of data by using a variety of tools and numerous problems could occur during this process.",
                    "label": 1
                },
                {
                    "sent": "So can we find this problems?",
                    "label": 0
                },
                {
                    "sent": "The third motivation of this research is that one of the exciting things of the semantic web is potential to move the web search web search to the document.",
                    "label": 0
                },
                {
                    "sent": "Relevance to the.",
                    "label": 0
                },
                {
                    "sent": "Query answering, however, given the numerous answers derived from various sources and statements.",
                    "label": 0
                },
                {
                    "sent": "The quality assessment can be important criteria to filter out inaccurate or unreliable answers.",
                    "label": 0
                },
                {
                    "sent": "The final motivation is that current trust most of the trusted research is based on the network and on these networks there's some atomic pairwise trust relationship given by users or third parties.",
                    "label": 0
                },
                {
                    "sent": "So we think the quality assessment can be foundational input for that.",
                    "label": 0
                },
                {
                    "sent": "To explain why it is trusted or not.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So because the problem is very similar, similar to the data cleansing problem in the database, another data can be viewed as essentially as graph database.",
                    "label": 0
                },
                {
                    "sent": "So we think we it is possible we learn some approaches from the domain of domain in the database and functional dependency has been shown promising in the database domain to.",
                    "label": 0
                },
                {
                    "sent": "Address some quality issues and data dependency is by far the most common integrity constraints for the databases and it is devised to specify the missing semantics in mere syntactic definitions of database relations.",
                    "label": 1
                },
                {
                    "sent": "Here I gave the definition of a functional dependency, so functional dependencies that, given the relation RA set of attributes X in R, is set to functional determine another attribute Y if and only if each X value is associated with precisely one.",
                    "label": 1
                },
                {
                    "sent": "Why are value so here?",
                    "label": 0
                },
                {
                    "sent": "I gave the two examples of functional dependency.",
                    "label": 0
                },
                {
                    "sent": "Look at as a second example.",
                    "label": 0
                },
                {
                    "sent": "Postal code determines the province which means.",
                    "label": 0
                },
                {
                    "sent": "Given any specific value of Postal code, we can precisely know the province's property of the value of for the value for the property province.",
                    "label": 0
                },
                {
                    "sent": "So here I highlighted four parts in the definition by the voting the fonts.",
                    "label": 0
                },
                {
                    "sent": "They are all limitations or the challenges compared to the RDF graph we were talking to talk about it in the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Last night so given we remember just now the definition of functional dependency is based on a relation R in database.",
                    "label": 0
                },
                {
                    "sent": "So however in other other graph can be viewed as extremely deep composed relational tables where each table is.",
                    "label": 1
                },
                {
                    "sent": "Set of triples.",
                    "label": 0
                },
                {
                    "sent": "Compose setup triples offer certain property, so the so the question is how we can group together group some properties or values into a.",
                    "label": 0
                },
                {
                    "sent": "On corresponding a relation like set to for considering the functional dependency second high.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we sat overseas a set of attributes X on the left hand side of the functional dependency.",
                    "label": 1
                },
                {
                    "sent": "If actually we can see we can view this grouping as a set of attributes viewed as a.",
                    "label": 0
                },
                {
                    "sent": "A combination of properties, so that's the only way of combining attributes in the database.",
                    "label": 0
                },
                {
                    "sent": "In the functional dependencies.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, we know in the other data we have more forms to combine the properties and this combination is also conveys some latent semantics.",
                    "label": 0
                },
                {
                    "sent": "So here I show we can combine the inverse properties and we can combine the properties through the composition property composition.",
                    "label": 0
                },
                {
                    "sent": "So if considering this more from some combinations, we can compose exponential number of new attribute, a new properties based on the original properties.",
                    "label": 0
                },
                {
                    "sent": "So that's another challenge we need to address here.",
                    "label": 0
                },
                {
                    "sent": "The third.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Challenger compared to the definition in the functional dependency is.",
                    "label": 0
                },
                {
                    "sent": "Here we see in the definition of function density, each X value is associated with some other value, because in fact in the relational database, each value is put in a tuple and.",
                    "label": 1
                },
                {
                    "sent": "It is cold here.",
                    "label": 0
                },
                {
                    "sent": "Color paired with another value in a tuple, so that's cool.",
                    "label": 0
                },
                {
                    "sent": "Appearance is determined by the tuple.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Religion, however, in the RDF data, if we here we see example of property, City and province.",
                    "label": 1
                },
                {
                    "sent": "For example, India Pedia, we don't have the constraint to say an instance can only use this property once.",
                    "label": 0
                },
                {
                    "sent": "Well, considering an organization spanning over multiple cities or multiple provinces, the city, the value of city and valid value of problems could be converted to a curd in a setting.",
                    "label": 0
                },
                {
                    "sent": "A group forms not in a single value, so that's a search challenger.",
                    "label": 0
                },
                {
                    "sent": "We can we find the actual value correlation between these properties.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last challenge is that in the functional dependency the why the left the value on the right hand side is determined precisely by 1 value.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, in many cases we note as.",
                    "label": 0
                },
                {
                    "sent": "We cannot determine exact precisely determine one value, but we can determine a group of values concerning the.",
                    "label": 0
                },
                {
                    "sent": "Floating point numbers, for example, is it really different between this 1.001 and 1.0?",
                    "label": 0
                },
                {
                    "sent": "And some for some strings they may contain conveys some other similar or actually the equivalent semantics.",
                    "label": 0
                },
                {
                    "sent": "Honestly, the more general form some values is some group of values show the equivalent semantics.",
                    "label": 0
                },
                {
                    "sent": "So for example, given a type of school, the upper ages will be in a small, very small range and then this show the logically similar semantics.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given these challenges, our system is trying to solve the each of them here give example of RDF graph, which is a directed labeled graph.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We define the 1st way of combining property is complete property.",
                    "label": 0
                },
                {
                    "sent": "Shown as a sequence of predicates.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The art of graph and the value function will be valid function of given this property given the instance specific instance will be this value.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the 2nd way to combine the property is.",
                    "label": 0
                },
                {
                    "sent": "We called conjunctive property.",
                    "label": 0
                },
                {
                    "sent": "It is essentially the same as.",
                    "label": 0
                },
                {
                    "sent": "Grouping property together in the functional dependency.",
                    "label": 0
                },
                {
                    "sent": "However, here the element of this conjunction property can be compensated properly with defined previously in previous slides.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as a functional and the value function of this complete conjunctive probably will be a tuple of values for each property involved.",
                    "label": 0
                },
                {
                    "sent": "Last thing we want to emphasize that because of here the value function we give these specific value.",
                    "label": 0
                },
                {
                    "sent": "Actually if we can find some cluster of values which shows consistent semantics so the value function could give return the cluster instead of the actual value.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then if we go in the other graphs, then we see the patterns that given any instance if they have the same value on the left hand side, then they have the same value on the right hand side property.",
                    "label": 0
                },
                {
                    "sent": "So it could be a possible VFD.",
                    "label": 1
                },
                {
                    "sent": "So in this sample we see the these two instances paper one Paper 2 have the same value on the left hand for the left hand side conjunctive property and they also has also have the.",
                    "label": 0
                },
                {
                    "sent": "Same value for the right hand side property.",
                    "label": 0
                },
                {
                    "sent": "So the goal is trying to find that such.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The patterns in the other graph of this work.",
                    "label": 0
                },
                {
                    "sent": "So first of all, if given this, given the two property and data about these two properties, how we can determine the true dependency between these two values?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this example, we gave to practice one is Department number Department name.",
                    "label": 0
                },
                {
                    "sent": "We're trying to find the dependency from the Department number to the different name.",
                    "label": 0
                },
                {
                    "sent": "Then we first step is to compute the candidate value mappings and order them.",
                    "label": 0
                },
                {
                    "sent": "Then we created we choose other optimum mappings.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First we will choose this one, cause the value on the left side, the value one is only one has the largest account compared to the value 2 because value 2 has two equivalent mappings, both both of them has a maximum count.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we will gradually choose this, this one, because there on the right hand side the value CS has the fewest mapping until so far.",
                    "label": 0
                },
                {
                    "sent": "Where the intuition is trying to keep the variety of the mappings.",
                    "label": 0
                },
                {
                    "sent": "If we sing.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These two value mappings are more optimum than we can get the confidence of this VFD is the number of true mappings true matches divided by the number of usages.",
                    "label": 0
                },
                {
                    "sent": "In this work, we set the confidence as .9 and after we get this VFD then we will.",
                    "label": 0
                },
                {
                    "sent": "Meantime, I get the find the abnormal data because they had this instant D has mismatch on the values.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second challenge is that we we can we have more ways to combine properties in other data.",
                    "label": 0
                },
                {
                    "sent": "So how to efficiently to prune out the impossible average FPS?",
                    "label": 0
                },
                {
                    "sent": "Here we give four prosthetic pruning heuristics.",
                    "label": 1
                },
                {
                    "sent": "They're based on two intuitions.",
                    "label": 0
                },
                {
                    "sent": "The first intuition is that is it possible to compose, compose, compose properties together.",
                    "label": 1
                },
                {
                    "sent": "And the second condition is that after the.",
                    "label": 0
                },
                {
                    "sent": "Composed of properties and is it possible to use this property to determine another property which essentially is to find a functional mapping between values of two properties?",
                    "label": 0
                },
                {
                    "sent": "So first, if you Ristic that insufficient overlap between the properties to be composed or between the left hand side on the right hand side.",
                    "label": 1
                },
                {
                    "sent": "That's a straight forward, so if we cannot.",
                    "label": 0
                },
                {
                    "sent": "If this is true, probably have don't have sufficient subject object object global overlap.",
                    "label": 0
                },
                {
                    "sent": "It is impossible to compose to group them together.",
                    "label": 0
                },
                {
                    "sent": "Can to compose a new property.",
                    "label": 1
                },
                {
                    "sent": "For the second heuristic, we first define the disability of a property is equal to the number of distinct values divided by the size of proper extension.",
                    "label": 0
                },
                {
                    "sent": "So and then, if the disability of the left hand side is less than that of the right hand side, it is impossible to consider the left hand side right hand side together in a VFD cause some values are multiple values of left hand side will be mapped to the same value on the right hand side, which is.",
                    "label": 0
                },
                {
                    "sent": "Which is not a functional mapping.",
                    "label": 0
                },
                {
                    "sent": "Then the circle Ristic is at the left side.",
                    "label": 0
                },
                {
                    "sent": "Right side has too high disability, cause if the left side has two high disability, essentially it is like a super key property because we're trying to find the detector.",
                    "label": 0
                },
                {
                    "sent": "I'm not more data by the checking the redundant value usages.",
                    "label": 0
                },
                {
                    "sent": "So if the values used uniquely each time, so it is not helpful.",
                    "label": 0
                },
                {
                    "sent": "In this scenario, the last.",
                    "label": 0
                },
                {
                    "sent": "Here is the exact.",
                    "label": 0
                },
                {
                    "sent": "To check how they discriminated, changed after the composition.",
                    "label": 0
                },
                {
                    "sent": "So we see we see actually, for example, conjunctive properties essentially to doing.",
                    "label": 0
                },
                {
                    "sent": "Addition products over the original property values, so the for conjunctive property.",
                    "label": 1
                },
                {
                    "sent": "New property values will be definitely greater than the number of values will be greater than the each property values involved, so they can distribute it will be no less than that of that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We device a level level wise discovery process because the higher the communication are, the higher level can be reused on the lower level.",
                    "label": 0
                },
                {
                    "sent": "Searching process.",
                    "label": 0
                },
                {
                    "sent": "And here give I give example how this studying static pruning heuristics are useful to print out the.",
                    "label": 0
                },
                {
                    "sent": "Unlikely.",
                    "label": 0
                },
                {
                    "sent": "Which FD's?",
                    "label": 0
                },
                {
                    "sent": "In this example?",
                    "label": 0
                },
                {
                    "sent": "We suppose these three conditions?",
                    "label": 0
                },
                {
                    "sent": "These three conditions are very common in a practical impractical datasets and then given this heuristics and this observation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is straightforward to find such nodes will be impossible for considering a VFD and then on the 2nd.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of all these two groups of children's are thrown out due to the similar reason as their parent.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And similarly other nodes can be thrown out due to the similar heuristics.",
                    "label": 0
                },
                {
                    "sent": "In this example, we just want to show that the most of the nodes on the searching tree can be pruned out using just using this static pruning heuristics.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After the prosthetic pruning, we still have a lot of VFD is to compute and we have seen the computation of each VFD is actually to find the optimal value mappings between property values, and we notice that in the information theory, mutual information is to compute the dependency between two variables and the entropy coefficient is to compute given the value given the variable value of Y.",
                    "label": 0
                },
                {
                    "sent": "How likely we can know the value of the variable X?",
                    "label": 0
                },
                {
                    "sent": "And if the value is close to one, which means given the value of variable one, we can definitely know the value of variable X.",
                    "label": 0
                },
                {
                    "sent": "So we using this formula with sampling a subset of instances for VFD to compute the entropy coefficient, and if this value is far away from the weight predefined threshold.",
                    "label": 1
                },
                {
                    "sent": "For true VFD, we can just Simply put.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out earlier, so we called it a runtime pruning.",
                    "label": 0
                },
                {
                    "sent": "For the third, for the last challenge we mentioned previously is how we can find the group of values showing consistent semantics.",
                    "label": 0
                },
                {
                    "sent": "We, we think the clustering is the general process.",
                    "label": 0
                },
                {
                    "sent": "Doing that in our clustering process we have two phase.",
                    "label": 0
                },
                {
                    "sent": "One is pre clustering which is designed to provide the minimum number of clusters and reserve expensive distance calculation for pairs of points within the same pre cluster.",
                    "label": 1
                },
                {
                    "sent": "The general process is pick a point that is closest to the center and then class are points that are close to the center.",
                    "label": 0
                },
                {
                    "sent": "Then repeat the steps.",
                    "label": 0
                },
                {
                    "sent": "The intuition is intuition of choosing the point closest to center is that it can faster prune out of faster closely clustering points in early.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Round.",
                    "label": 0
                },
                {
                    "sent": "Then in the final grade classroom, we called it optimal.",
                    "label": 0
                },
                {
                    "sent": "K means clustering.",
                    "label": 0
                },
                {
                    "sent": "It is improved from existing work are called Gap statistic and so in this classroom process with without the input of K, we automatically find the optimal number of clusters for a prompt for the values of property.",
                    "label": 1
                },
                {
                    "sent": "And in the variation of this, K means clustering.",
                    "label": 0
                },
                {
                    "sent": "We restrict the distance calculation only on the pairs that within the same pre cluster.",
                    "label": 1
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our experiments we tested the system on the three datasets.",
                    "label": 0
                },
                {
                    "sent": "One is as resistance, medical research corpus and the Pedia and our capital said we found a number of VFD's and here I show some examples there.",
                    "label": 0
                },
                {
                    "sent": "In three groups, the first group in the first group, the Left Hand side, is single property and in the second group the Left Hand Side Composite Complex Properties by grouping.",
                    "label": 0
                },
                {
                    "sent": "A combining properties and the third group shows which of these based on the value cluster?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Custard values and using this version of this we also detect a number of erroneous data in the real world data set, and here are some examples.",
                    "label": 0
                },
                {
                    "sent": "And finally we give the system performance.",
                    "label": 1
                },
                {
                    "sent": "Precision on three datasets we see the establecidas that has lowest precision.",
                    "label": 0
                },
                {
                    "sent": "We think the reason is that the accuracy is.",
                    "label": 0
                },
                {
                    "sent": "Relatively restricted domain, and it indeed has a higher quality.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So conclusion, our system tries to find the data dependency patterns in the form of VFD and try to use them to detect abnormal data by checking conflicts with these patterns and experiments on the real world datasets validated the system.",
                    "label": 1
                },
                {
                    "sent": "For future work, would like to further generalize VFD because in current system we are the which FD on the right hand side object, which FDR only the single property single original property.",
                    "label": 0
                },
                {
                    "sent": "So it is definitely theoretically.",
                    "label": 0
                },
                {
                    "sent": "Theoretically possible to extend the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Half of each empty into a compensated properly too.",
                    "label": 0
                },
                {
                    "sent": "And we would like to apply in the system on the actual Knowledge acquisition areas to to detect the problems in that process.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I think that's thank you.",
                    "label": 0
                },
                {
                    "sent": "So I would like to know how or if you are considering to relate this work with ongoing work on provenance representation and because it seems like data normally in RDF cross could be very related with understanding where the data comes from.",
                    "label": 0
                },
                {
                    "sent": "Who has participated in generating the data and the transformation is it has gone through?",
                    "label": 0
                },
                {
                    "sent": "Are you thinking on those lines or or not?",
                    "label": 0
                },
                {
                    "sent": "Sorry, can you repeat what's really work?",
                    "label": 0
                },
                {
                    "sent": "About provenance provenance representation vocabulary reasoning.",
                    "label": 0
                },
                {
                    "sent": "Yeah actually yeah, we we indeed checked some really work on the Providence, but we think the one officer limitation of that approach is that needs problems, information and this information needs to import, you know, to input by the humans or users or given by some some places.",
                    "label": 0
                },
                {
                    "sent": "Given some, you know some input.",
                    "label": 0
                },
                {
                    "sent": "However, in many real world datasets we don't have such information to doing that to do that so.",
                    "label": 0
                },
                {
                    "sent": "This I think that's one of the limitation.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I was wondering whether you have been looking into the summarize ability problem of aggregating data values like with sum or average, because there you always have to do sometimes have the problem that if you have certain dependencies, it doesn't make sense to summarize the data with certain aggregation functions.",
                    "label": 0
                },
                {
                    "sent": "Now, I was wondering whether you have been looking into that.",
                    "label": 0
                },
                {
                    "sent": "So let me rephrase your question so first, so you're talking about aggregating values for the considering the dependency.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, actually in our previous work we we try some approach using the summary graph to doing the summary to summarize the other graph to make the process finding the dependency more efficient.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But in that approach we.",
                    "label": 0
                },
                {
                    "sent": "Because for the.",
                    "label": 0
                },
                {
                    "sent": "Approach we only consider the object property values and easier to summarize object property values.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "We we we didn't find a solution to.",
                    "label": 0
                },
                {
                    "sent": "How to aggregate the data type values?",
                    "label": 0
                },
                {
                    "sent": "So that's why we designed this work design this approach so I just have one quick comment.",
                    "label": 0
                },
                {
                    "sent": "Very interesting work, just trying this work to the work of the previous speaker, which is in the previous talk.",
                    "label": 0
                },
                {
                    "sent": "It was about doing this classification, building classifiers and connecting to an RDF store, but it assumes that the data in the RDF store is correct, right?",
                    "label": 0
                },
                {
                    "sent": "And you all work is about finding gaps in the data and also finding contradictions in the data.",
                    "label": 0
                },
                {
                    "sent": "And so to the extent that you can use that and combine that with the previous work, you can probably improve the classifiers as well, but this is a comment, so yeah, essentially we can think of this.",
                    "label": 0
                },
                {
                    "sent": "This system, also a classifier we know.",
                    "label": 0
                },
                {
                    "sent": "Actually we classify the data into two groups.",
                    "label": 0
                },
                {
                    "sent": "One is more likely correct when one group is more likely incorrect.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think definitely we can.",
                    "label": 0
                },
                {
                    "sent": "It is possible to think about combining these two works.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, thank you thanks.",
                    "label": 1
                }
            ]
        }
    }
}