{
    "id": "ayhes3o4ifjd5rk62wcssg7c3aozvvao",
    "title": "Applying Syntactic Similarity Algorithms for Enterprise Information Management",
    "info": {
        "author": [
            "Ludmila Cherkasova, Hewlet Packard"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Enterprise & Finance"
        ]
    },
    "url": "http://videolectures.net/kdd09_cherkasova_assaeim/",
    "segmentation": [
        [
            "This is a joint work with colleagues of Mine, Carrie, actually bred Mare Joseph Classic and Alister Wage."
        ],
        [
            "So many enterprises currently implement knew information management solutions because of the applications which came to enterprise, and in particular there are many application related to data compliance.",
            "So document compliance and E Discovery or litigation issues.",
            "So the example of the first new application in the enterprise would be related to this document compliance often.",
            "Certain documents are sensitive and need to be deleted after certain time period, so but at the same time, when these documents are distributed across the enterprise, they might be altered or slightly modified or edited, and in this case, how do we identify all these users who might have a copy of this slightly different file?",
            "In case of ediscovery where enterprise US youth with certain legal cases, the problem would be to identify a complete set of related documents not only semantically related documents but also somewhat syntactically related documents.",
            "All the version earlier or later of the same documents, so it's almost related to this document provenance problem and at the same time when the expert would receive the large pool of.",
            "All these related documents.",
            "This is a manual process.",
            "He has to go through the set of documents and some would decide whether these documents related to the case or whether there are bunch of somewhat not relevant documents in this pool and it would be really nice to simplify or to automate or help this expert to navigate through this pool of documents.",
            "And if we create this syntactically kind of similar documents which are versions of the same or.",
            "Earlier or later, versions of the documents.",
            "It would be easier for the expert to just pick the representative copy of this syntactically similar cluster and decide whether the whole cluster has sense for this legal case.",
            "And finally, the enterprise is they have huge repositories of technical documentation and you know that overtime the products get updated, modified.",
            "Often the new products have very little to do with the product, which we had five, 7 say years ago.",
            "But all these repositories accumulate this somewhat polluted technical solution or help, and the new application would be related.",
            "How do we filter out this outdated versions of the technical documentation and have good quality?",
            "Collections, so all these three examples which I brought to you in the enterprise setting somewhat realize."
        ],
        [
            "That we have documents with large textual intersection.",
            "An syntactic similarity is useful exactly for this.",
            "My documents with large textual intersection and syntactical similarity algorithms, the entirely defined by the syntactic or checks properties of the document.",
            "There's no really any semantic in the definition, and you will see later it's not a new problem, so educated go broader and group of his colleagues came up with shingling technique to identify near duplicates on the web and this problem.",
            "Truly was severe, like there was 30% of near duplicates identified on the web because of mirrored site and so on.",
            "So they really wanted to come up with the relatively efficient algorithm to identify this near duplicates and under this approach the document is represented by the set of shingles and single.",
            "It's a sequence of adjacent words anile."
        ],
        [
            "Show you some wood smoke.",
            "Pictorial representation.",
            "How this technique works.",
            "So here we have a document and typically this document is a set of tokens.",
            "It's a text, right and?",
            "In the original shingling technique, each token or this cubic in this document was award and you can pick the shingles of different size and after that you just go through this document and cover the whole document set and you get the shingles of all all the shingles of this document A and exactly this representation is used to compare different documents and there is a parameter here you can see for example, I showed the single of size 6.",
            "Right, and as I mentioned, traditionally they used words as.",
            "As a as a as a token.",
            "In this work, we will use bytes because I'll show you some other approaches which we want to put in unified framework."
        ],
        [
            "And typically there are two metrics which people might be interested in.",
            "The one is similarity metric.",
            "It's exactly where we would like to understand whether these documents are similar and it defines what would be fraction of common shingles in the union of those documents, right?",
            "And the second metric is a containment metric, and this is where we would be interested whether the document A is contained in Document B and which fraction of this document is contained."
        ],
        [
            "And in order to make this approach more efficient, because you clearly could clearly see that if you take just even 1000 bytes documents, an 100 bytes shingles.",
            "There is a lot of comparison for the shingles you need to do so.",
            "First of all, it would be much easier to compare, not these sequences of words, right?",
            "But hashes of those sequences, and this is what done by using 64 bit.",
            "The Prince, which have very fast software implementation an in order to simplify further the computation of similarity metric one can sample infects Windows.",
            "We don't need to compare all of them, we can really sample this set of shingles and see how this sample set of shingles from 2 documents similar or one, contain another one, and in this case instead of 1000 shingles.",
            "If you sample each 10th right, we only need to compare 100 shingles, but this is where we have different ways of sampling.",
            "Right and."
        ],
        [
            "This is where you could find in the literature different algorithms and they all related to this different way of how people sample shingles and the question for us was which algorithm do we pick for our enterprise problems, and in fact we are particularly will fund in.",
            "We really like this chunking based algorithm.",
            "This was our somewhat primary motivation and this algorithms very different from the shingling algorithm and appeared much later.",
            "Some would last, maybe five years, and they used actively in duplication.",
            "In storage solution and our intent was really to see how good this algorithms and whether we can have really unified again framework both for the application technique and for using the same data structures in similarity algorithms."
        ],
        [
            "So these free shingling based algorithms only different, by the way how they sample shingles and built the document signature.",
            "So here you can see again that we have this set of all the shingles right?",
            "And this algorithm mean just select others, all the shingles of the documents and select say first 100 and defines what is the number of this minimal minimal set which you select as a signature.",
            "What you need to kind of remember for this algorithm that it's fixed size once we set and here we fixed the size of the signature independent on the side."
        ],
        [
            "Of the document.",
            "So the old algorithm word here.",
            "Someone behaves, it takes the same set of whole fingerprinted shingles, but picks every, say, 100.",
            "Again, it defined by this end.",
            "We set the end and after that we say approximately.",
            "I mean it should be saved fingerprints those values module N is 0, so but intuitively it's really like you decide to pick every 100th fingerprints.",
            "If you set it to 100."
        ],
        [
            "Right?",
            "And finally, this is was somewhat.",
            "Effect used by Yahoo algorithm and it called sketch because there was several papers written by Yahoo people and in fact Google people using this sketch algorithm and instead of using a single hash and shingles with this fingerprinted had here we have a set of functions.",
            "So we go through the document and the somewhat.",
            "Create different fingerprints by using a family of independent hash functions, but at the end we would pick for each of these functions a single value, right?",
            "So here if I take hundred of these hash functions and pick for each of those functions minimal value again, I would have fixed size signature which would represent this document.",
            "And this is exactly the sketch algorithm an for this algorithm.",
            "Andre Brother gave a very nice theoretical justification that the percentage of common interest in sketches and be accurately approximate the percentage of common shingles in India."
        ],
        [
            "And finally, this basic sliding window algorithm, which is completely from different family of the algorithms.",
            "Its so called chunking based algorithm.",
            "But the idea is somewhat very similar.",
            "First we use this fingerprinted shingles, but we find the chunks boundary so we have this again North which would define for us the chunk chunks which document will be represented through.",
            "But for each of those chunks.",
            "Within it, we would pick the minimal 1 instead of like there is approach where you can take the hash of the whole chunk, but in this case even tiny modification within the chunk would make documents very different and This is why we have a modified version here where we just take one of those minimal windows within the chunk.",
            "And again in this case, if you have documents represented by variable size, so the documents would be, the signature would be proportional to the."
        ],
        [
            "Human size.",
            "And here few somewhat almost obvious properties of these algorithms.",
            "We have two algorithm which are fixed size, right?",
            "So this fixed size algorithms would not be good for containment problem because if you have even document which prefix of the larger one and you take for this document, minimal subset of extreme goals, it might have nothing to do with the minimal shingles.",
            "In the total in the whole entire document.",
            "So This is why this and the same for the sketch.",
            "So This is why this fixed size algorithm or signatures.",
            "They are not good for containment problem.",
            "And if in your Enterprise Sanyu application which you're trying to write, it would be important to show the provenance of documents that this say document was the first part of this entire document or version of this entire document.",
            "Then you have to pick either mode document or this basic sliding window which covers both of those problems.",
            "And the way how we defined the algorithm, you can see that there are two main parameters.",
            "There are sliding window size.",
            "This is exactly this shingle size which we moved right and there is also this sampling frequency.",
            "The way how we sample how many of these.",
            "Thus, we put in our signature, and in fact this this is unified somewhat framework pull this for algorithms.",
            "You can see the same parameters for all this for algorithms and it was interesting to see that all the published papers which in different way use this algorithm.",
            "They had very different values.",
            "So again we ask ourselves whether we could identify useful range of useful values for this new enterprise applications.",
            "And also we wanted to compare this for algorithms."
        ],
        [
            "But the question after that, how do we compare this algorithm fairly?",
            "Object ively.",
            "Because often if you take the real kind of document subset, it might favor one of the algorithm.",
            "And if you take the other ones then you often find that the the other algorithm was better.",
            "So how do we really build a framework which could be used for a fair comparison of the algorithm?",
            "And the question was whether we can use the same framework for sensitivity analysis of the parameters."
        ],
        [
            "And we came up with the control set of modifications.",
            "So we we were picking up a special set of documents in which we would introduce in controlled way modification.",
            "We can add words like.",
            "I have this small example here where you have the text and after that you delete for example a certain.",
            "Set of words from the document and for the collection.",
            "We will do it in the."
        ],
        [
            "Controlled.",
            "Well defined manner.",
            "So we picked 100 different H collapse reports.",
            "So in the beginning we had for sure 100 different documents.",
            "They were not similar.",
            "And after that we had this program which would be able to add or remove words.",
            "To the document in predefined number of times.",
            "So we could insert for example this small word A and it has no meaning.",
            "It just you know that it's a tiny modification.",
            "This is why most of the results I will show you with this very small kind of additional the word a certain number of times and in this case we would use this notation that we had original corpus.",
            "Where we had hundred different documents an in this subset we would have.",
            "This word, in certain certain number of times a number of times would be shown as I hear.",
            "And we would compute the average similarity metric between the original and modified document, and we will compare in such a way different parameters and the algorithms.",
            "This is the."
        ],
        [
            "Intent.",
            "And first of all, we clearly saw that the window size makes a big difference here.",
            "We would expect that for I need to explain.",
            "This is the number of modifications, so it's how many times we inserted this small letter A in this hundred different documents, right?",
            "And we computed after that similarity metric and so the higher is the better, because we know that they are truly near duplicates.",
            "So we expect to see the high similarity metrics for this modified documents.",
            "And so the best results here you can see for the window size 5 bytes, right and divorce results.",
            "This was the range of parameters would be for the window of 100 bytes, but does it mean that we need to pick the window of five?",
            "In fact, there is a second metric which is shown on the right, and this is where we took this original research corpus where we know for sure that all the documents different and if you take a very small window of five bytes, it's.",
            "Practically, if you let us that, you can see that these different documents suddenly might exhibit A lot of similarity, because you could really sample this free letters from this documents and clearly could find a lot of similarity where it does not exist.",
            "So from these two pictures you somewhat clearly see that this window of 20 bytes is a good choice.",
            "It's about four words and we did see also in the literature some of the.",
            "Work where people used for tokens forwards as a as a as a parameter."
        ],
        [
            "So frequency sampling somewhat has the same effect from one side, the average is the average similarity metric for different frequency numbers.",
            "Here we had 110, right, so 10 would be what means that you sample very.",
            "Only few few symbols, like the whole signature, would be 10 entries independent on the document size and hundred certainly would be.",
            "100 entries to represent the document and you can see that in fact, clearly by increasing the signature or representation of the shingles in the signature, you have much more predictable results.",
            "If you have only few samples then you often miss any difference and this is where we had 100% similarity between documents.",
            "They did not see any difference or you might be unlucky and you see a lot of this modification.",
            "In your signature and your similarity metric gets again impacted."
        ],
        [
            "And finally I want to show this comparison of the four similarity algorithms an here somewhat.",
            "We found that sketch and basic sliding window will more sensitive.",
            "This is the bottom 2 lines to the number of changes and the mode algorithm was clear winner and.",
            "And agree it was unexpected, right?",
            "So we will really put in a lot of hopes for this basic sliding window because it's interesting technology and.",
            "Somewhat unexpected, it did not show as good results as we hoped.",
            "And also we verified on different distributions like I mentioned in the beginning that what does it mean to compare this algorithm?",
            "Maybe it's problem with your research corpus which we use which showed that this algorithm is just works better for this subset and This is why we round VRAM.",
            "The same comparison on a very different modification set where we removed words at random men and we had in fact this somewhat workload.",
            "Generator of the way.",
            "How we insert modification written in very flexible way.",
            "You could really enforce different distribution.",
            "They could be closer, they could be random, they could be unified, but the results were somewhat consistent through different set of experiments which we performed and the somewhat mode algorithm was a clear winner in all the case."
        ],
        [
            "Have you also performed the case study using 2 enterprise collection?",
            "Here you could see the size distribution.",
            "I did not mention the fact size distribution for this hundred documents which we use and the 100 documents which we use the from 10 kilobytes to 500 kilobytes so you always see the range of the somewhat different documents and.",
            "Almost done so in this enterprise collection.",
            "We specially picked the second one, which would have somewhat longer documents so you could see that this was a logical action, but it was.",
            "It had a lot of short, very short documents, right?",
            "And this is the log scale and the green one had slightly smaller number of documents, but."
        ],
        [
            "It was longer ones.",
            "And he and the results.",
            "They somewhat very consistent with what we found in our framework.",
            "You could say that MoD algorithm identify the largest number of similar documents, but it also had this.",
            "False alarm so it had.",
            "Relatively high percentage of false positive.",
            "The other algorithms they identify much smaller set of near duplicates or similar documents, but they also did not practically didn't have the false positive.",
            "The interesting observation that for longer documents this gap really was much small between the algorithms and certainly our favorite basic sliding window algorithm perform much better.",
            "And we hope that for larger documents it could be still."
        ],
        [
            "About their choice.",
            "We also perform the comparisons.",
            "What would it take?",
            "How much?",
            "What which algorithm is more expensive compared to the other ones in the execution of processing power?",
            "And here you could see that computing hundreds a hash function clearly would be much more expensive compared to the other methods which was using just a single hash function.",
            "The somewhat unexpected, but really easily explainable observation was that this 100 hash function also had their higher much higher sensitivity to the.",
            "Window size."
        ],
        [
            "So I'm conclusion is clearly that syntactic similarity is very useful to identify documents with large textual intersection, and there are many of new enterprise applications which require support.",
            "Such document and we design somewhat fair framework framework for comparison of the algorithm.",
            "Identify useful parameters and compare the documents and for future.",
            "I still believe we could modify, refine, and optimize this basic sliding window algorithm.",
            "We have preliminary results and it would be really attractive to have a unified framework on the back of our storage solution.",
            "Because this champion based algorithms are used.",
            "Currently for deduplication very actively.",
            "OK, I'm done."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a joint work with colleagues of Mine, Carrie, actually bred Mare Joseph Classic and Alister Wage.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So many enterprises currently implement knew information management solutions because of the applications which came to enterprise, and in particular there are many application related to data compliance.",
                    "label": 0
                },
                {
                    "sent": "So document compliance and E Discovery or litigation issues.",
                    "label": 0
                },
                {
                    "sent": "So the example of the first new application in the enterprise would be related to this document compliance often.",
                    "label": 0
                },
                {
                    "sent": "Certain documents are sensitive and need to be deleted after certain time period, so but at the same time, when these documents are distributed across the enterprise, they might be altered or slightly modified or edited, and in this case, how do we identify all these users who might have a copy of this slightly different file?",
                    "label": 1
                },
                {
                    "sent": "In case of ediscovery where enterprise US youth with certain legal cases, the problem would be to identify a complete set of related documents not only semantically related documents but also somewhat syntactically related documents.",
                    "label": 0
                },
                {
                    "sent": "All the version earlier or later of the same documents, so it's almost related to this document provenance problem and at the same time when the expert would receive the large pool of.",
                    "label": 0
                },
                {
                    "sent": "All these related documents.",
                    "label": 0
                },
                {
                    "sent": "This is a manual process.",
                    "label": 0
                },
                {
                    "sent": "He has to go through the set of documents and some would decide whether these documents related to the case or whether there are bunch of somewhat not relevant documents in this pool and it would be really nice to simplify or to automate or help this expert to navigate through this pool of documents.",
                    "label": 0
                },
                {
                    "sent": "And if we create this syntactically kind of similar documents which are versions of the same or.",
                    "label": 1
                },
                {
                    "sent": "Earlier or later, versions of the documents.",
                    "label": 0
                },
                {
                    "sent": "It would be easier for the expert to just pick the representative copy of this syntactically similar cluster and decide whether the whole cluster has sense for this legal case.",
                    "label": 0
                },
                {
                    "sent": "And finally, the enterprise is they have huge repositories of technical documentation and you know that overtime the products get updated, modified.",
                    "label": 0
                },
                {
                    "sent": "Often the new products have very little to do with the product, which we had five, 7 say years ago.",
                    "label": 0
                },
                {
                    "sent": "But all these repositories accumulate this somewhat polluted technical solution or help, and the new application would be related.",
                    "label": 0
                },
                {
                    "sent": "How do we filter out this outdated versions of the technical documentation and have good quality?",
                    "label": 0
                },
                {
                    "sent": "Collections, so all these three examples which I brought to you in the enterprise setting somewhat realize.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we have documents with large textual intersection.",
                    "label": 0
                },
                {
                    "sent": "An syntactic similarity is useful exactly for this.",
                    "label": 1
                },
                {
                    "sent": "My documents with large textual intersection and syntactical similarity algorithms, the entirely defined by the syntactic or checks properties of the document.",
                    "label": 1
                },
                {
                    "sent": "There's no really any semantic in the definition, and you will see later it's not a new problem, so educated go broader and group of his colleagues came up with shingling technique to identify near duplicates on the web and this problem.",
                    "label": 1
                },
                {
                    "sent": "Truly was severe, like there was 30% of near duplicates identified on the web because of mirrored site and so on.",
                    "label": 0
                },
                {
                    "sent": "So they really wanted to come up with the relatively efficient algorithm to identify this near duplicates and under this approach the document is represented by the set of shingles and single.",
                    "label": 0
                },
                {
                    "sent": "It's a sequence of adjacent words anile.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show you some wood smoke.",
                    "label": 0
                },
                {
                    "sent": "Pictorial representation.",
                    "label": 0
                },
                {
                    "sent": "How this technique works.",
                    "label": 0
                },
                {
                    "sent": "So here we have a document and typically this document is a set of tokens.",
                    "label": 0
                },
                {
                    "sent": "It's a text, right and?",
                    "label": 0
                },
                {
                    "sent": "In the original shingling technique, each token or this cubic in this document was award and you can pick the shingles of different size and after that you just go through this document and cover the whole document set and you get the shingles of all all the shingles of this document A and exactly this representation is used to compare different documents and there is a parameter here you can see for example, I showed the single of size 6.",
                    "label": 1
                },
                {
                    "sent": "Right, and as I mentioned, traditionally they used words as.",
                    "label": 0
                },
                {
                    "sent": "As a as a as a token.",
                    "label": 0
                },
                {
                    "sent": "In this work, we will use bytes because I'll show you some other approaches which we want to put in unified framework.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And typically there are two metrics which people might be interested in.",
                    "label": 0
                },
                {
                    "sent": "The one is similarity metric.",
                    "label": 0
                },
                {
                    "sent": "It's exactly where we would like to understand whether these documents are similar and it defines what would be fraction of common shingles in the union of those documents, right?",
                    "label": 0
                },
                {
                    "sent": "And the second metric is a containment metric, and this is where we would be interested whether the document A is contained in Document B and which fraction of this document is contained.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in order to make this approach more efficient, because you clearly could clearly see that if you take just even 1000 bytes documents, an 100 bytes shingles.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of comparison for the shingles you need to do so.",
                    "label": 0
                },
                {
                    "sent": "First of all, it would be much easier to compare, not these sequences of words, right?",
                    "label": 1
                },
                {
                    "sent": "But hashes of those sequences, and this is what done by using 64 bit.",
                    "label": 0
                },
                {
                    "sent": "The Prince, which have very fast software implementation an in order to simplify further the computation of similarity metric one can sample infects Windows.",
                    "label": 1
                },
                {
                    "sent": "We don't need to compare all of them, we can really sample this set of shingles and see how this sample set of shingles from 2 documents similar or one, contain another one, and in this case instead of 1000 shingles.",
                    "label": 1
                },
                {
                    "sent": "If you sample each 10th right, we only need to compare 100 shingles, but this is where we have different ways of sampling.",
                    "label": 0
                },
                {
                    "sent": "Right and.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is where you could find in the literature different algorithms and they all related to this different way of how people sample shingles and the question for us was which algorithm do we pick for our enterprise problems, and in fact we are particularly will fund in.",
                    "label": 0
                },
                {
                    "sent": "We really like this chunking based algorithm.",
                    "label": 0
                },
                {
                    "sent": "This was our somewhat primary motivation and this algorithms very different from the shingling algorithm and appeared much later.",
                    "label": 0
                },
                {
                    "sent": "Some would last, maybe five years, and they used actively in duplication.",
                    "label": 0
                },
                {
                    "sent": "In storage solution and our intent was really to see how good this algorithms and whether we can have really unified again framework both for the application technique and for using the same data structures in similarity algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these free shingling based algorithms only different, by the way how they sample shingles and built the document signature.",
                    "label": 0
                },
                {
                    "sent": "So here you can see again that we have this set of all the shingles right?",
                    "label": 0
                },
                {
                    "sent": "And this algorithm mean just select others, all the shingles of the documents and select say first 100 and defines what is the number of this minimal minimal set which you select as a signature.",
                    "label": 0
                },
                {
                    "sent": "What you need to kind of remember for this algorithm that it's fixed size once we set and here we fixed the size of the signature independent on the side.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the document.",
                    "label": 0
                },
                {
                    "sent": "So the old algorithm word here.",
                    "label": 0
                },
                {
                    "sent": "Someone behaves, it takes the same set of whole fingerprinted shingles, but picks every, say, 100.",
                    "label": 0
                },
                {
                    "sent": "Again, it defined by this end.",
                    "label": 0
                },
                {
                    "sent": "We set the end and after that we say approximately.",
                    "label": 0
                },
                {
                    "sent": "I mean it should be saved fingerprints those values module N is 0, so but intuitively it's really like you decide to pick every 100th fingerprints.",
                    "label": 0
                },
                {
                    "sent": "If you set it to 100.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And finally, this is was somewhat.",
                    "label": 0
                },
                {
                    "sent": "Effect used by Yahoo algorithm and it called sketch because there was several papers written by Yahoo people and in fact Google people using this sketch algorithm and instead of using a single hash and shingles with this fingerprinted had here we have a set of functions.",
                    "label": 0
                },
                {
                    "sent": "So we go through the document and the somewhat.",
                    "label": 0
                },
                {
                    "sent": "Create different fingerprints by using a family of independent hash functions, but at the end we would pick for each of these functions a single value, right?",
                    "label": 1
                },
                {
                    "sent": "So here if I take hundred of these hash functions and pick for each of those functions minimal value again, I would have fixed size signature which would represent this document.",
                    "label": 1
                },
                {
                    "sent": "And this is exactly the sketch algorithm an for this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Andre Brother gave a very nice theoretical justification that the percentage of common interest in sketches and be accurately approximate the percentage of common shingles in India.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, this basic sliding window algorithm, which is completely from different family of the algorithms.",
                    "label": 1
                },
                {
                    "sent": "Its so called chunking based algorithm.",
                    "label": 0
                },
                {
                    "sent": "But the idea is somewhat very similar.",
                    "label": 0
                },
                {
                    "sent": "First we use this fingerprinted shingles, but we find the chunks boundary so we have this again North which would define for us the chunk chunks which document will be represented through.",
                    "label": 0
                },
                {
                    "sent": "But for each of those chunks.",
                    "label": 0
                },
                {
                    "sent": "Within it, we would pick the minimal 1 instead of like there is approach where you can take the hash of the whole chunk, but in this case even tiny modification within the chunk would make documents very different and This is why we have a modified version here where we just take one of those minimal windows within the chunk.",
                    "label": 0
                },
                {
                    "sent": "And again in this case, if you have documents represented by variable size, so the documents would be, the signature would be proportional to the.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Human size.",
                    "label": 0
                },
                {
                    "sent": "And here few somewhat almost obvious properties of these algorithms.",
                    "label": 0
                },
                {
                    "sent": "We have two algorithm which are fixed size, right?",
                    "label": 0
                },
                {
                    "sent": "So this fixed size algorithms would not be good for containment problem because if you have even document which prefix of the larger one and you take for this document, minimal subset of extreme goals, it might have nothing to do with the minimal shingles.",
                    "label": 0
                },
                {
                    "sent": "In the total in the whole entire document.",
                    "label": 0
                },
                {
                    "sent": "So This is why this and the same for the sketch.",
                    "label": 0
                },
                {
                    "sent": "So This is why this fixed size algorithm or signatures.",
                    "label": 0
                },
                {
                    "sent": "They are not good for containment problem.",
                    "label": 0
                },
                {
                    "sent": "And if in your Enterprise Sanyu application which you're trying to write, it would be important to show the provenance of documents that this say document was the first part of this entire document or version of this entire document.",
                    "label": 0
                },
                {
                    "sent": "Then you have to pick either mode document or this basic sliding window which covers both of those problems.",
                    "label": 0
                },
                {
                    "sent": "And the way how we defined the algorithm, you can see that there are two main parameters.",
                    "label": 0
                },
                {
                    "sent": "There are sliding window size.",
                    "label": 1
                },
                {
                    "sent": "This is exactly this shingle size which we moved right and there is also this sampling frequency.",
                    "label": 0
                },
                {
                    "sent": "The way how we sample how many of these.",
                    "label": 0
                },
                {
                    "sent": "Thus, we put in our signature, and in fact this this is unified somewhat framework pull this for algorithms.",
                    "label": 0
                },
                {
                    "sent": "You can see the same parameters for all this for algorithms and it was interesting to see that all the published papers which in different way use this algorithm.",
                    "label": 1
                },
                {
                    "sent": "They had very different values.",
                    "label": 0
                },
                {
                    "sent": "So again we ask ourselves whether we could identify useful range of useful values for this new enterprise applications.",
                    "label": 0
                },
                {
                    "sent": "And also we wanted to compare this for algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But the question after that, how do we compare this algorithm fairly?",
                    "label": 0
                },
                {
                    "sent": "Object ively.",
                    "label": 0
                },
                {
                    "sent": "Because often if you take the real kind of document subset, it might favor one of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And if you take the other ones then you often find that the the other algorithm was better.",
                    "label": 0
                },
                {
                    "sent": "So how do we really build a framework which could be used for a fair comparison of the algorithm?",
                    "label": 1
                },
                {
                    "sent": "And the question was whether we can use the same framework for sensitivity analysis of the parameters.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we came up with the control set of modifications.",
                    "label": 1
                },
                {
                    "sent": "So we we were picking up a special set of documents in which we would introduce in controlled way modification.",
                    "label": 0
                },
                {
                    "sent": "We can add words like.",
                    "label": 0
                },
                {
                    "sent": "I have this small example here where you have the text and after that you delete for example a certain.",
                    "label": 0
                },
                {
                    "sent": "Set of words from the document and for the collection.",
                    "label": 1
                },
                {
                    "sent": "We will do it in the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Controlled.",
                    "label": 0
                },
                {
                    "sent": "Well defined manner.",
                    "label": 0
                },
                {
                    "sent": "So we picked 100 different H collapse reports.",
                    "label": 1
                },
                {
                    "sent": "So in the beginning we had for sure 100 different documents.",
                    "label": 0
                },
                {
                    "sent": "They were not similar.",
                    "label": 0
                },
                {
                    "sent": "And after that we had this program which would be able to add or remove words.",
                    "label": 1
                },
                {
                    "sent": "To the document in predefined number of times.",
                    "label": 1
                },
                {
                    "sent": "So we could insert for example this small word A and it has no meaning.",
                    "label": 0
                },
                {
                    "sent": "It just you know that it's a tiny modification.",
                    "label": 0
                },
                {
                    "sent": "This is why most of the results I will show you with this very small kind of additional the word a certain number of times and in this case we would use this notation that we had original corpus.",
                    "label": 0
                },
                {
                    "sent": "Where we had hundred different documents an in this subset we would have.",
                    "label": 1
                },
                {
                    "sent": "This word, in certain certain number of times a number of times would be shown as I hear.",
                    "label": 0
                },
                {
                    "sent": "And we would compute the average similarity metric between the original and modified document, and we will compare in such a way different parameters and the algorithms.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Intent.",
                    "label": 0
                },
                {
                    "sent": "And first of all, we clearly saw that the window size makes a big difference here.",
                    "label": 0
                },
                {
                    "sent": "We would expect that for I need to explain.",
                    "label": 0
                },
                {
                    "sent": "This is the number of modifications, so it's how many times we inserted this small letter A in this hundred different documents, right?",
                    "label": 0
                },
                {
                    "sent": "And we computed after that similarity metric and so the higher is the better, because we know that they are truly near duplicates.",
                    "label": 0
                },
                {
                    "sent": "So we expect to see the high similarity metrics for this modified documents.",
                    "label": 0
                },
                {
                    "sent": "And so the best results here you can see for the window size 5 bytes, right and divorce results.",
                    "label": 0
                },
                {
                    "sent": "This was the range of parameters would be for the window of 100 bytes, but does it mean that we need to pick the window of five?",
                    "label": 0
                },
                {
                    "sent": "In fact, there is a second metric which is shown on the right, and this is where we took this original research corpus where we know for sure that all the documents different and if you take a very small window of five bytes, it's.",
                    "label": 0
                },
                {
                    "sent": "Practically, if you let us that, you can see that these different documents suddenly might exhibit A lot of similarity, because you could really sample this free letters from this documents and clearly could find a lot of similarity where it does not exist.",
                    "label": 0
                },
                {
                    "sent": "So from these two pictures you somewhat clearly see that this window of 20 bytes is a good choice.",
                    "label": 1
                },
                {
                    "sent": "It's about four words and we did see also in the literature some of the.",
                    "label": 0
                },
                {
                    "sent": "Work where people used for tokens forwards as a as a as a parameter.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So frequency sampling somewhat has the same effect from one side, the average is the average similarity metric for different frequency numbers.",
                    "label": 1
                },
                {
                    "sent": "Here we had 110, right, so 10 would be what means that you sample very.",
                    "label": 1
                },
                {
                    "sent": "Only few few symbols, like the whole signature, would be 10 entries independent on the document size and hundred certainly would be.",
                    "label": 0
                },
                {
                    "sent": "100 entries to represent the document and you can see that in fact, clearly by increasing the signature or representation of the shingles in the signature, you have much more predictable results.",
                    "label": 0
                },
                {
                    "sent": "If you have only few samples then you often miss any difference and this is where we had 100% similarity between documents.",
                    "label": 0
                },
                {
                    "sent": "They did not see any difference or you might be unlucky and you see a lot of this modification.",
                    "label": 0
                },
                {
                    "sent": "In your signature and your similarity metric gets again impacted.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally I want to show this comparison of the four similarity algorithms an here somewhat.",
                    "label": 1
                },
                {
                    "sent": "We found that sketch and basic sliding window will more sensitive.",
                    "label": 0
                },
                {
                    "sent": "This is the bottom 2 lines to the number of changes and the mode algorithm was clear winner and.",
                    "label": 1
                },
                {
                    "sent": "And agree it was unexpected, right?",
                    "label": 0
                },
                {
                    "sent": "So we will really put in a lot of hopes for this basic sliding window because it's interesting technology and.",
                    "label": 0
                },
                {
                    "sent": "Somewhat unexpected, it did not show as good results as we hoped.",
                    "label": 0
                },
                {
                    "sent": "And also we verified on different distributions like I mentioned in the beginning that what does it mean to compare this algorithm?",
                    "label": 0
                },
                {
                    "sent": "Maybe it's problem with your research corpus which we use which showed that this algorithm is just works better for this subset and This is why we round VRAM.",
                    "label": 0
                },
                {
                    "sent": "The same comparison on a very different modification set where we removed words at random men and we had in fact this somewhat workload.",
                    "label": 0
                },
                {
                    "sent": "Generator of the way.",
                    "label": 0
                },
                {
                    "sent": "How we insert modification written in very flexible way.",
                    "label": 0
                },
                {
                    "sent": "You could really enforce different distribution.",
                    "label": 0
                },
                {
                    "sent": "They could be closer, they could be random, they could be unified, but the results were somewhat consistent through different set of experiments which we performed and the somewhat mode algorithm was a clear winner in all the case.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have you also performed the case study using 2 enterprise collection?",
                    "label": 0
                },
                {
                    "sent": "Here you could see the size distribution.",
                    "label": 0
                },
                {
                    "sent": "I did not mention the fact size distribution for this hundred documents which we use and the 100 documents which we use the from 10 kilobytes to 500 kilobytes so you always see the range of the somewhat different documents and.",
                    "label": 0
                },
                {
                    "sent": "Almost done so in this enterprise collection.",
                    "label": 0
                },
                {
                    "sent": "We specially picked the second one, which would have somewhat longer documents so you could see that this was a logical action, but it was.",
                    "label": 0
                },
                {
                    "sent": "It had a lot of short, very short documents, right?",
                    "label": 0
                },
                {
                    "sent": "And this is the log scale and the green one had slightly smaller number of documents, but.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It was longer ones.",
                    "label": 0
                },
                {
                    "sent": "And he and the results.",
                    "label": 0
                },
                {
                    "sent": "They somewhat very consistent with what we found in our framework.",
                    "label": 0
                },
                {
                    "sent": "You could say that MoD algorithm identify the largest number of similar documents, but it also had this.",
                    "label": 1
                },
                {
                    "sent": "False alarm so it had.",
                    "label": 1
                },
                {
                    "sent": "Relatively high percentage of false positive.",
                    "label": 0
                },
                {
                    "sent": "The other algorithms they identify much smaller set of near duplicates or similar documents, but they also did not practically didn't have the false positive.",
                    "label": 0
                },
                {
                    "sent": "The interesting observation that for longer documents this gap really was much small between the algorithms and certainly our favorite basic sliding window algorithm perform much better.",
                    "label": 1
                },
                {
                    "sent": "And we hope that for larger documents it could be still.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About their choice.",
                    "label": 0
                },
                {
                    "sent": "We also perform the comparisons.",
                    "label": 0
                },
                {
                    "sent": "What would it take?",
                    "label": 0
                },
                {
                    "sent": "How much?",
                    "label": 0
                },
                {
                    "sent": "What which algorithm is more expensive compared to the other ones in the execution of processing power?",
                    "label": 1
                },
                {
                    "sent": "And here you could see that computing hundreds a hash function clearly would be much more expensive compared to the other methods which was using just a single hash function.",
                    "label": 0
                },
                {
                    "sent": "The somewhat unexpected, but really easily explainable observation was that this 100 hash function also had their higher much higher sensitivity to the.",
                    "label": 0
                },
                {
                    "sent": "Window size.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm conclusion is clearly that syntactic similarity is very useful to identify documents with large textual intersection, and there are many of new enterprise applications which require support.",
                    "label": 1
                },
                {
                    "sent": "Such document and we design somewhat fair framework framework for comparison of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Identify useful parameters and compare the documents and for future.",
                    "label": 1
                },
                {
                    "sent": "I still believe we could modify, refine, and optimize this basic sliding window algorithm.",
                    "label": 1
                },
                {
                    "sent": "We have preliminary results and it would be really attractive to have a unified framework on the back of our storage solution.",
                    "label": 1
                },
                {
                    "sent": "Because this champion based algorithms are used.",
                    "label": 0
                },
                {
                    "sent": "Currently for deduplication very actively.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm done.",
                    "label": 0
                }
            ]
        }
    }
}