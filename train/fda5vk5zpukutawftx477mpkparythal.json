{
    "id": "fda5vk5zpukutawftx477mpkparythal",
    "title": "Semantic Sitemaps: Efficient and Flexible Access to Datasets on the Semantic Web",
    "info": {
        "author": [
            "Richard Cyganiak, DERI Galway, National University of Ireland, Galway"
        ],
        "published": "Aug. 15, 2008",
        "recorded": "June 2008",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc08_cyganiak_ss/",
    "segmentation": [
        [
            "One thing we see at the moment is.",
            "The emergence of I would call it a new web that's we can call it the web of data.",
            "The semantic Web Rep 3.0 there are different terms, but what we mean by this term is that web."
        ],
        [
            "Is to be about documents for web browsers and now it moves more towards structured data for from mashup an for integration between applications.",
            "And so this new web is still very very small compared to the existing web.",
            "And it's kind of growing in the cracks of the of the existing web so, but it's very interesting and there's a bunch of technologies involved in this new web.",
            "I want to focus on RDF here.",
            "There are some little bit less structured technologies like microformats.",
            "There are more structured technologies like like ontologies, but so RDF is kind of might be the middle ground too.",
            "Two to making this new web of data work.",
            "And.",
            "So one observation about this, this new web, especially with regard to RDF.",
            "The costs of dealing with structured data here is are shifting."
        ],
        [
            "The big problem used to be actually getting access to RDF data.",
            "If you go a few years back, the large RDF datasets that used to be available where things like the open directory, the demos data dump things like the Musicbrainz data dump and getting them to work and doing anything with that works really hard.",
            "The demos data dump.",
            "It turns out that you know if you work with it, it's actually not quite proper RDF so you have to do some post processing to fix some some syntax issues to Musicbrainz.",
            "Dump you actually had to install a database and Perl script that generates the RDF from the database.",
            "There was no other way to get it, so a lot of work until you have the first triple to do anything with it, but this has changed.",
            "Now today we have to Sparkle protocol.",
            "We have things like linked data.",
            "There are generic clients like like tabulator and all of this means that developers aren't with fairly simple tools like a sparkler client and a little bit of knowledge of sparkle can get.",
            "Get access to RDF data very easily.",
            "And at the same time, this allows us to kind of.",
            "Choose data sources on the fly and as I start with my project, I don't have to spend a lot of time gathering data from all over the place, but I can kind of even at query time like when I want to answer to solve one particular little problem, it might be feasible to automatically find all the relevant pieces of data.",
            "We also have much more data out there now with for example, 4th has millions of millions of 4th profiles.",
            "Now in RDF format the linking Open Data Project has produced a lot of a lot of quite interesting datasets, so the problem is no longer getting access to this data, but finding finding those bits that are relevant.",
            "And.",
            "So this means."
        ],
        [
            "Today we want a map of this new web and there's quite a number of projects that and groups that work towards this goal struggles with the semantic web search engine.",
            "Falcons Watson Cindy Cindy tries to project where I'm working, and so they're quite so.",
            "The goal is always to collect as much as possible of this data out there, and there's a little bit of a friendly race between these different groups.",
            "And like who can?",
            "Who is the biggest index who can?",
            "Who got the most data?",
            "The fresh data and so on and there are quite a number of challenges in making this work and getting getting all of this into into an index or a store, and I want to talk about some of these challenges and then how then I want to propose something that might help us to overcome these challenges."
        ],
        [
            "So.",
            "And there are three three challenges in particular."
        ],
        [
            "The first one is.",
            "Even though we have a number of standards now to access RDF data, there are still several different access methods that are very popular and if you want to access all the interesting data out there you can't do.",
            "You can't limit yourself to just one of them.",
            "And there was no agreement.",
            "Which is the best of these different access methods simply because it depends on the scenario.",
            "So one approach is linked data.",
            "Basically it means you have an identifier UI and if you look at if you look up that UI on the web you get a little description of that particular of the resource identified by this particular UI.",
            "This is great for browsing for crawling, but it has the problem that to get all of the data you need to spend a lot of time to.",
            "To fetch many many many many small small pieces of data from the web.",
            "RDF dumps are kind of the opposite.",
            "It's one big thing that contains all the descriptions in a particular data set.",
            "But yeah, they can be very large.",
            "Very, very very unwieldy.",
            "So working with them can also be kind of difficult.",
            "And then we have sparkle endpoints which are great if you have a specific query.",
            "So if you want to know very specific like you want to extract one particular small piece of information out of a large data set, but.",
            "Again, it's kind of hard to hear.",
            "It's kind of hard to get all of the data out of the sparkle endpoint if you want to index it in an external and external source, and also a problem with SPARQL endpoint is that they are basically invisible on the web.",
            "You need to know the UI of the sparkle endpoint and if you and basically if a crawler an automated agent encounters a sparkle endpoint and it's really hard for the for the for the crawler to know that it actually is that.",
            "This this UI supports this market protocol, so this might be an oversight in this market standards that that no such discovery mechanism was defined.",
            "So yeah, just just a short example."
        ],
        [
            "Here, DB Pedia is available in all three of these formats, so you can do an HTTP look up on HTTP deep dark resource Teneriffe and you will get a description of Teneriffe and from DB Pedia.",
            "You can download the damn from thepedia.org huge file compressed and so on.",
            "Or you can send request to the sparkle endpoint to get specific information and it's the same data in all of these same data behind all of these access methods.",
            "But yeah.",
            "The interesting question is how would we know, like how would an automated system know that there's the same data behind all of these?",
            "So the next challenge is if we crawl data.",
            "If you call RDF."
        ],
        [
            "Um?",
            "There are some performance issues.",
            "One big problem is the service that people use to put RDF on the web are currently often kind of a little bit, they're not.",
            "Not often, not very strong machines of not very very very highly optimized so an aggressive crawler can quite easily bring down such a server.",
            "We have seen a couple of these incidents already, like there was one thing quite widely published when when the swissy crawler hits geonames with like 10 machines crawling as fast as they could and the server caught fire immediately.",
            "Basically and just last week we saw a similar thing with the metadata site for SWC.",
            "And the Falcons team wanted to get this data very quickly, so they ran a very aggressive crawl against it and the other server is just a little virtual machine hidden somewhere and like it fell over instantly.",
            "So these things happen.",
            "And just so the solution.",
            "Of course you could say, yeah, space out your request a little bit.",
            "Don't be so aggressive with your crawler, but if we do the math you do 11 request per second.",
            "That's 2 1/2 million requests per month approximately.",
            "And there are lots of interesting datasets out there.",
            "Geo names for example that has more than 6 million entities.",
            "So it means if I want all of it and then yeah it will take Me 2 months to get all of it.",
            "And then if I want to update it again to refresh in it and that will take another two months and that's kind of not very satisfying.",
            "So the solution could be in both the cases I mentioned with two names end with the SWC data set.",
            "There are actually RDF dumps available, so the.",
            "The the folks who want the data could just use the RDF dump downloaded couple of couple of megabytes, whatever.",
            "No big, no big deal and then process it locally instead of doing this expensive crawl.",
            "But The thing is, how would an automated system know about these terms?",
            "That data dump is available for particular data set.",
            "Third challenge provenance.",
            "Provenance is extremely."
        ],
        [
            "Important on the semantic web.",
            "Anyone anybody, anybody can say anything about anything, so you really want to know who said any.",
            "Who stated any particular effect?",
            "Fortunately, provenance is a built in feature of the web we have because the UI is where you actually get the data are based on the DNS, so they sold in the DNS.",
            "You have DNS records, so you know who owns the domain, so you kind of have a chain where you can see who actually who is in the end responsible for making this information available.",
            "So there are two very, very important concepts here.",
            "First, UI ownership, HDP your eyes have an owner.",
            "They have a person who is.",
            "Who is responsible for configuring the UI and deciding what data gets published there?",
            "And then there's the notion of authoritative information.",
            "This means if you have a UI and you do a request on it, you get back some information.",
            "Then you get back some information that is basically authorized by the owner of the UI because he has set up the UI to return this particular information, and so this is different from information that you could find somewhere else about the same UI.",
            "Which would be non authoritative.",
            "Yeah, with the system like outcome that would be.",
            "This this issue wouldn't matter so much because yeah, essentially the identifiers would be neutral and we would already know what they, what they refer to.",
            "But at the moment we don't have that yet, so we need to kind of rely on this distributed mechanism where everybody can mind their own UI's.",
            "And the problem here is that often UI space is delegated.",
            "This means that there is under a single domain.",
            "There might be lots of different.",
            "Like parts of the UI space might be delegated to other people, you often have something like site slash user name and then this particular user is responsible for all the stuff that's going on there, and this is not visible from the outside, so it's hard to know for an external agent for an external automated system that wants to make decisions about should I trust this information?",
            "Should I use it or not?",
            "It's hard to make that decision because it's really hard to know who actually kind of trace it back to to to an authority.",
            "So the proposed solution that we have is our semantic sitemaps."
        ],
        [
            "The main idea is that."
        ],
        [
            "Publishers data publisher who put RDF on the web, tell us where they put it.",
            "And it's based on the on Google Sitemap protocol, which is a fairly widely accepted standard that was originally proposed by Google and is now supported by all the major search engines.",
            "And essentially what you have to do is put a simple XML file on your server, usually just a couple of lines and that will quite nicely address the issues I've presented before.",
            "So the Google that's a Google Sitemap.",
            "Basically it's a set of UI."
        ],
        [
            "Sales.",
            "And each of them can be annotated with some pieces of information, and this essentially a web crawler can find this and can and will know.",
            "OK, so here's this UI.",
            "It changes once a month, for example here, with approximately once a month here with this example.",
            "And so we extend the Sitemap protocol.",
            "With a couple of elements.",
            "So basically we add this and."
        ],
        [
            "One or more SC datasets see is the prefix for the four hour extension.",
            "Um?",
            "And then with within."
        ],
        [
            "The datasets we you can provide several pieces of information linked data prefix.",
            "This simply says resources that begin with this prefix.",
            "There's link data available, so you could look that look them up and get RDF back.",
            "There can be a data dump location, so this is the UI of a big file that contains all the information in the data set.",
            "And there could be a SPARQL endpoint location where you can send queries over this data set.",
            "And you can also use existing existing annotations from the Google Sitemap protocol, like to change frequency."
        ],
        [
            "As a couple of other elements, you can provide a label for that."
        ],
        [
            "Dataset, just a human."
        ],
        [
            "Label this."
        ],
        [
            "Just yes SWC.",
            "2008 metadata set.",
            "You can provide a data set UI that's a hook where you could provide additional metadata like an RDF.",
            "Additional RDF information like who has actually published this, what's the license and so on.",
            "So anything not covered by by the by the site map by the semantic sitemaps could be provided there in an external file.",
            "Same foresty authority where you can provide additional information about the publisher.",
            "And sample UI where you can just add some information, some kind of representative.",
            "You arise from the data set which is useful for user agents and so on for people who just want to kind of test this and see.",
            "OK, So what happens when I dereference this?"
        ],
        [
            "Why did we choose this XML format instead of putting everything into RDF?",
            "That's mostly because there because webmasters are conservative, they have to put up these sitemaps and so they already know they are familiar with the site map protocol and adding this extension is probably less threatening to them, or like they can more easily understand what's going on then working with RDF complete RDF files.",
            "So this is from discussion with potential users.",
            "They raised this concern and so we decided not to go for an RDF format, but with XML.",
            "And also well, it keeps it fairly simple and straightforward, so that's also a plus.",
            "So.",
            "There."
        ],
        [
            "Yes, so sitemap discovery.",
            "This is about if you start with the domain, how can you find the site map for the domain?",
            "Basically this relies on robots.",
            "TXT, another well established feature that tells Crawlers where they can go and not go.",
            "There's the Google Sitemap protocol introduces a\nThat you add to the robots TXT which basically points to the sitemap and so a crawler or any agent can know where to find the site map.",
            "So it's kind of easy to see how this solves how this how this can solved."
        ],
        [
            "The three challenges I've presented earlier the different access methods where you know there's one data set.",
            "It is available as linked data in a data dump, or it is a sparkle endpoint.",
            "So if you have these three elements in the in the in the in the description in the data set description, then you're fine and you can choose the most appropriate.",
            "So for example, a crawler could see I am.",
            "I have a UI in this linked data prefix here, so I will.",
            "I will actually not dereference it, but instead I will go for the whole dump."
        ],
        [
            "The core performance.",
            "Yeah, it's the it's clear how how a crawler can find the dump.",
            "We ran an experiment to kind of see see the see the effect of this.",
            "If downloading and processing a dump is really is really better than doing a crawl and it turns out that the problem is that if you have a big dump, you still need to slice it into back into these smart small pieces that you would find on the web and then index them.",
            "Or do whatever post processing you want to do and in our in our experiment it turned out that uniprot, which will take around five months to call.",
            "Basically, we could download and.",
            "Process the entire dump and do the same thing in about 25 hours, and so it's a.",
            "It's a big improvement and it can be parallelized on a cluster quite easily, so that's quite nice."
        ],
        [
            "Provenance there is one more feature in the Sitemap I haven't mentioned before.",
            "You can have sub sitemaps and parent site Maps which basically allows you to delegate a part of the UI space to someone else or to join a part of UI space from a different domain into into the one described by the site map.",
            "This is useful because in practice it turns out that sometimes the sparkle endpoint is located on a different domain that dumps are hosted on a different domain, so we wanted to address this.",
            "Yeah, and it's also like this SC authority hook allows us to describe more about the publishers who so clients can make smarter decisions about about.",
            "Yeah, rather data comes from and if they should trust or use it.",
            "So at the moment."
        ],
        [
            "Um?",
            "Most of the large linking open data datasets have his heightmap.",
            "Sitemaps are supported by this industry and switch the search engine's semantic search, semantic web, or web data search engine's.",
            "We have found so far that publishers are usually quite receptive to the idea, because, well, it's kind of it's easy to do.",
            "It's easy to publish such a site map and what harm can it do?",
            "So they say, yeah, OK.",
            "If it helps, you will do it no problem.",
            "However, they want to validate or because yeah, sometimes they are not quite true.",
            "Have I done it the right way?",
            "And it turns out sometimes they don't because there's something despaired and so on, so.",
            "So this is a request we have seen quite often and the best place to to talk about semantic sitemaps.",
            "That's a public elody mailing list at WCC.",
            "So the main list of the linking Open Data project.",
            "Next steps an updated draft."
        ],
        [
            "This forthcoming that incorporates some additional feedback that we received recently.",
            "We want to have a simple sitemap creator and the aforementioned validator, and we want to move towards this, actually describing more of the content of the data set.",
            "As in what's actually in there, so we have addressed how to find it or to find it and how to access it in different ways, but not really at what data you can find in there, and so there is one kind of proposal or initial.",
            "Initial project going on now that actually started here at the SWC called Void.",
            "And so we had.",
            "This is one thing that we hope to produce like a draft or something like a proposal in the next couple of weeks.",
            "So to summarize."
        ],
        [
            "Semantic sitemaps.",
            "Our proposal for enabling better RDF discovery.",
            "They allow publishers to announce what RDF data they have and they allow RDF consumers like web crawlers and so on to efficiently find it and semantic.",
            "Sitemaps also have hooks for describing the content and authority in more detail, which can be used to build set probably 2 to build interesting, more advanced applications.",
            "On top of this."
        ],
        [
            "So yeah, that's it.",
            "Thank you very much.",
            "Questions."
        ],
        [
            "I have to say that this is really great, is probably the best and most immediately useful proposal that I heard on this whole conference.",
            "Well, I'm just wondering.",
            "You said you were already talking to some publishers.",
            "Can you name some more or something like that?",
            "Yeah, that's so the people we have talked talked to mostly are people in the linking Open data project, so it's people who publish RDF who converts existing open datasets to RDF and publish this on the web.",
            "So the things.",
            "So some things that come to mind.",
            "Dbpedia Geonames has one the the data published by Hugh at.",
            "In Southampton, they all have site.",
            "All of these sites are described inside Maps and so on.",
            "There we don't really have any like big names web to all companies also or because they usually don't publish RDF on focus.",
            "More on microformats or web kind of more traditional web APIs.",
            "XML based and so on.",
            "And we don't really address this so much because they like crawling them.",
            "It works a little bit differently.",
            "We probably should do something about about microformats also, but.",
            "So we haven't done this because kind of the background, the people who started this archive from the RDF field, and so this is where we started.",
            "But microformats RDF eight.",
            "It's definitely something we want to.",
            "We want to figure out how this fits into all of this and then also time to talk to talk to all publishers of any sort of structured data on the web.",
            "Rather questions.",
            "So I have one.",
            "So what happens in case they give multiple ways of writing data?",
            "What happens if, for example, the data dump differs from from the linked data?",
            "Is there a way to provide a preference?",
            "No.",
            "So basically our thinking is that as a data publisher, you shouldn't do that because well, yes, because you actually want to want to provide that.",
            "I want everyone to get a consistent view of what data you have and if it happens where.",
            "So I can just say in the case of synergy when we find the dump and we process the dump, then yeah, we will see whatever data is in the dump.",
            "And if you actually have some slightly different or more up to date.",
            "Data available through the link data interface, then yeah, OK, we will not see this and actually it's kind of common that the dump is just produced once a week, and so on and.",
            "Yeah, so at the moment we say that yeah, we will just kind of.",
            "Hopefully it doesn't matter so much like I think this is true for most of the RDF datasets that we have right now.",
            "It might change in the future when we have really frequently updating RDF datasets that are of high value and well, then you could hopefully still make a decision based on the last modified date or this change frequency data.",
            "OK, thank you thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One thing we see at the moment is.",
                    "label": 0
                },
                {
                    "sent": "The emergence of I would call it a new web that's we can call it the web of data.",
                    "label": 0
                },
                {
                    "sent": "The semantic Web Rep 3.0 there are different terms, but what we mean by this term is that web.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is to be about documents for web browsers and now it moves more towards structured data for from mashup an for integration between applications.",
                    "label": 1
                },
                {
                    "sent": "And so this new web is still very very small compared to the existing web.",
                    "label": 0
                },
                {
                    "sent": "And it's kind of growing in the cracks of the of the existing web so, but it's very interesting and there's a bunch of technologies involved in this new web.",
                    "label": 0
                },
                {
                    "sent": "I want to focus on RDF here.",
                    "label": 0
                },
                {
                    "sent": "There are some little bit less structured technologies like microformats.",
                    "label": 0
                },
                {
                    "sent": "There are more structured technologies like like ontologies, but so RDF is kind of might be the middle ground too.",
                    "label": 1
                },
                {
                    "sent": "Two to making this new web of data work.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So one observation about this, this new web, especially with regard to RDF.",
                    "label": 0
                },
                {
                    "sent": "The costs of dealing with structured data here is are shifting.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The big problem used to be actually getting access to RDF data.",
                    "label": 0
                },
                {
                    "sent": "If you go a few years back, the large RDF datasets that used to be available where things like the open directory, the demos data dump things like the Musicbrainz data dump and getting them to work and doing anything with that works really hard.",
                    "label": 0
                },
                {
                    "sent": "The demos data dump.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you know if you work with it, it's actually not quite proper RDF so you have to do some post processing to fix some some syntax issues to Musicbrainz.",
                    "label": 0
                },
                {
                    "sent": "Dump you actually had to install a database and Perl script that generates the RDF from the database.",
                    "label": 0
                },
                {
                    "sent": "There was no other way to get it, so a lot of work until you have the first triple to do anything with it, but this has changed.",
                    "label": 0
                },
                {
                    "sent": "Now today we have to Sparkle protocol.",
                    "label": 0
                },
                {
                    "sent": "We have things like linked data.",
                    "label": 0
                },
                {
                    "sent": "There are generic clients like like tabulator and all of this means that developers aren't with fairly simple tools like a sparkler client and a little bit of knowledge of sparkle can get.",
                    "label": 0
                },
                {
                    "sent": "Get access to RDF data very easily.",
                    "label": 0
                },
                {
                    "sent": "And at the same time, this allows us to kind of.",
                    "label": 0
                },
                {
                    "sent": "Choose data sources on the fly and as I start with my project, I don't have to spend a lot of time gathering data from all over the place, but I can kind of even at query time like when I want to answer to solve one particular little problem, it might be feasible to automatically find all the relevant pieces of data.",
                    "label": 0
                },
                {
                    "sent": "We also have much more data out there now with for example, 4th has millions of millions of 4th profiles.",
                    "label": 0
                },
                {
                    "sent": "Now in RDF format the linking Open Data Project has produced a lot of a lot of quite interesting datasets, so the problem is no longer getting access to this data, but finding finding those bits that are relevant.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So this means.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today we want a map of this new web and there's quite a number of projects that and groups that work towards this goal struggles with the semantic web search engine.",
                    "label": 1
                },
                {
                    "sent": "Falcons Watson Cindy Cindy tries to project where I'm working, and so they're quite so.",
                    "label": 0
                },
                {
                    "sent": "The goal is always to collect as much as possible of this data out there, and there's a little bit of a friendly race between these different groups.",
                    "label": 0
                },
                {
                    "sent": "And like who can?",
                    "label": 0
                },
                {
                    "sent": "Who is the biggest index who can?",
                    "label": 0
                },
                {
                    "sent": "Who got the most data?",
                    "label": 0
                },
                {
                    "sent": "The fresh data and so on and there are quite a number of challenges in making this work and getting getting all of this into into an index or a store, and I want to talk about some of these challenges and then how then I want to propose something that might help us to overcome these challenges.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And there are three three challenges in particular.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first one is.",
                    "label": 0
                },
                {
                    "sent": "Even though we have a number of standards now to access RDF data, there are still several different access methods that are very popular and if you want to access all the interesting data out there you can't do.",
                    "label": 0
                },
                {
                    "sent": "You can't limit yourself to just one of them.",
                    "label": 0
                },
                {
                    "sent": "And there was no agreement.",
                    "label": 0
                },
                {
                    "sent": "Which is the best of these different access methods simply because it depends on the scenario.",
                    "label": 1
                },
                {
                    "sent": "So one approach is linked data.",
                    "label": 0
                },
                {
                    "sent": "Basically it means you have an identifier UI and if you look at if you look up that UI on the web you get a little description of that particular of the resource identified by this particular UI.",
                    "label": 0
                },
                {
                    "sent": "This is great for browsing for crawling, but it has the problem that to get all of the data you need to spend a lot of time to.",
                    "label": 0
                },
                {
                    "sent": "To fetch many many many many small small pieces of data from the web.",
                    "label": 0
                },
                {
                    "sent": "RDF dumps are kind of the opposite.",
                    "label": 0
                },
                {
                    "sent": "It's one big thing that contains all the descriptions in a particular data set.",
                    "label": 0
                },
                {
                    "sent": "But yeah, they can be very large.",
                    "label": 0
                },
                {
                    "sent": "Very, very very unwieldy.",
                    "label": 0
                },
                {
                    "sent": "So working with them can also be kind of difficult.",
                    "label": 0
                },
                {
                    "sent": "And then we have sparkle endpoints which are great if you have a specific query.",
                    "label": 0
                },
                {
                    "sent": "So if you want to know very specific like you want to extract one particular small piece of information out of a large data set, but.",
                    "label": 0
                },
                {
                    "sent": "Again, it's kind of hard to hear.",
                    "label": 0
                },
                {
                    "sent": "It's kind of hard to get all of the data out of the sparkle endpoint if you want to index it in an external and external source, and also a problem with SPARQL endpoint is that they are basically invisible on the web.",
                    "label": 0
                },
                {
                    "sent": "You need to know the UI of the sparkle endpoint and if you and basically if a crawler an automated agent encounters a sparkle endpoint and it's really hard for the for the for the crawler to know that it actually is that.",
                    "label": 0
                },
                {
                    "sent": "This this UI supports this market protocol, so this might be an oversight in this market standards that that no such discovery mechanism was defined.",
                    "label": 0
                },
                {
                    "sent": "So yeah, just just a short example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here, DB Pedia is available in all three of these formats, so you can do an HTTP look up on HTTP deep dark resource Teneriffe and you will get a description of Teneriffe and from DB Pedia.",
                    "label": 0
                },
                {
                    "sent": "You can download the damn from thepedia.org huge file compressed and so on.",
                    "label": 0
                },
                {
                    "sent": "Or you can send request to the sparkle endpoint to get specific information and it's the same data in all of these same data behind all of these access methods.",
                    "label": 0
                },
                {
                    "sent": "But yeah.",
                    "label": 0
                },
                {
                    "sent": "The interesting question is how would we know, like how would an automated system know that there's the same data behind all of these?",
                    "label": 1
                },
                {
                    "sent": "So the next challenge is if we crawl data.",
                    "label": 0
                },
                {
                    "sent": "If you call RDF.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There are some performance issues.",
                    "label": 0
                },
                {
                    "sent": "One big problem is the service that people use to put RDF on the web are currently often kind of a little bit, they're not.",
                    "label": 0
                },
                {
                    "sent": "Not often, not very strong machines of not very very very highly optimized so an aggressive crawler can quite easily bring down such a server.",
                    "label": 0
                },
                {
                    "sent": "We have seen a couple of these incidents already, like there was one thing quite widely published when when the swissy crawler hits geonames with like 10 machines crawling as fast as they could and the server caught fire immediately.",
                    "label": 0
                },
                {
                    "sent": "Basically and just last week we saw a similar thing with the metadata site for SWC.",
                    "label": 0
                },
                {
                    "sent": "And the Falcons team wanted to get this data very quickly, so they ran a very aggressive crawl against it and the other server is just a little virtual machine hidden somewhere and like it fell over instantly.",
                    "label": 0
                },
                {
                    "sent": "So these things happen.",
                    "label": 0
                },
                {
                    "sent": "And just so the solution.",
                    "label": 0
                },
                {
                    "sent": "Of course you could say, yeah, space out your request a little bit.",
                    "label": 0
                },
                {
                    "sent": "Don't be so aggressive with your crawler, but if we do the math you do 11 request per second.",
                    "label": 1
                },
                {
                    "sent": "That's 2 1/2 million requests per month approximately.",
                    "label": 0
                },
                {
                    "sent": "And there are lots of interesting datasets out there.",
                    "label": 0
                },
                {
                    "sent": "Geo names for example that has more than 6 million entities.",
                    "label": 0
                },
                {
                    "sent": "So it means if I want all of it and then yeah it will take Me 2 months to get all of it.",
                    "label": 0
                },
                {
                    "sent": "And then if I want to update it again to refresh in it and that will take another two months and that's kind of not very satisfying.",
                    "label": 0
                },
                {
                    "sent": "So the solution could be in both the cases I mentioned with two names end with the SWC data set.",
                    "label": 0
                },
                {
                    "sent": "There are actually RDF dumps available, so the.",
                    "label": 0
                },
                {
                    "sent": "The the folks who want the data could just use the RDF dump downloaded couple of couple of megabytes, whatever.",
                    "label": 0
                },
                {
                    "sent": "No big, no big deal and then process it locally instead of doing this expensive crawl.",
                    "label": 0
                },
                {
                    "sent": "But The thing is, how would an automated system know about these terms?",
                    "label": 0
                },
                {
                    "sent": "That data dump is available for particular data set.",
                    "label": 1
                },
                {
                    "sent": "Third challenge provenance.",
                    "label": 0
                },
                {
                    "sent": "Provenance is extremely.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important on the semantic web.",
                    "label": 0
                },
                {
                    "sent": "Anyone anybody, anybody can say anything about anything, so you really want to know who said any.",
                    "label": 0
                },
                {
                    "sent": "Who stated any particular effect?",
                    "label": 0
                },
                {
                    "sent": "Fortunately, provenance is a built in feature of the web we have because the UI is where you actually get the data are based on the DNS, so they sold in the DNS.",
                    "label": 0
                },
                {
                    "sent": "You have DNS records, so you know who owns the domain, so you kind of have a chain where you can see who actually who is in the end responsible for making this information available.",
                    "label": 0
                },
                {
                    "sent": "So there are two very, very important concepts here.",
                    "label": 0
                },
                {
                    "sent": "First, UI ownership, HDP your eyes have an owner.",
                    "label": 0
                },
                {
                    "sent": "They have a person who is.",
                    "label": 0
                },
                {
                    "sent": "Who is responsible for configuring the UI and deciding what data gets published there?",
                    "label": 0
                },
                {
                    "sent": "And then there's the notion of authoritative information.",
                    "label": 0
                },
                {
                    "sent": "This means if you have a UI and you do a request on it, you get back some information.",
                    "label": 0
                },
                {
                    "sent": "Then you get back some information that is basically authorized by the owner of the UI because he has set up the UI to return this particular information, and so this is different from information that you could find somewhere else about the same UI.",
                    "label": 0
                },
                {
                    "sent": "Which would be non authoritative.",
                    "label": 0
                },
                {
                    "sent": "Yeah, with the system like outcome that would be.",
                    "label": 0
                },
                {
                    "sent": "This this issue wouldn't matter so much because yeah, essentially the identifiers would be neutral and we would already know what they, what they refer to.",
                    "label": 0
                },
                {
                    "sent": "But at the moment we don't have that yet, so we need to kind of rely on this distributed mechanism where everybody can mind their own UI's.",
                    "label": 0
                },
                {
                    "sent": "And the problem here is that often UI space is delegated.",
                    "label": 0
                },
                {
                    "sent": "This means that there is under a single domain.",
                    "label": 0
                },
                {
                    "sent": "There might be lots of different.",
                    "label": 0
                },
                {
                    "sent": "Like parts of the UI space might be delegated to other people, you often have something like site slash user name and then this particular user is responsible for all the stuff that's going on there, and this is not visible from the outside, so it's hard to know for an external agent for an external automated system that wants to make decisions about should I trust this information?",
                    "label": 0
                },
                {
                    "sent": "Should I use it or not?",
                    "label": 0
                },
                {
                    "sent": "It's hard to make that decision because it's really hard to know who actually kind of trace it back to to to an authority.",
                    "label": 0
                },
                {
                    "sent": "So the proposed solution that we have is our semantic sitemaps.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The main idea is that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Publishers data publisher who put RDF on the web, tell us where they put it.",
                    "label": 0
                },
                {
                    "sent": "And it's based on the on Google Sitemap protocol, which is a fairly widely accepted standard that was originally proposed by Google and is now supported by all the major search engines.",
                    "label": 0
                },
                {
                    "sent": "And essentially what you have to do is put a simple XML file on your server, usually just a couple of lines and that will quite nicely address the issues I've presented before.",
                    "label": 0
                },
                {
                    "sent": "So the Google that's a Google Sitemap.",
                    "label": 0
                },
                {
                    "sent": "Basically it's a set of UI.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sales.",
                    "label": 0
                },
                {
                    "sent": "And each of them can be annotated with some pieces of information, and this essentially a web crawler can find this and can and will know.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's this UI.",
                    "label": 0
                },
                {
                    "sent": "It changes once a month, for example here, with approximately once a month here with this example.",
                    "label": 0
                },
                {
                    "sent": "And so we extend the Sitemap protocol.",
                    "label": 1
                },
                {
                    "sent": "With a couple of elements.",
                    "label": 0
                },
                {
                    "sent": "So basically we add this and.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One or more SC datasets see is the prefix for the four hour extension.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then with within.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The datasets we you can provide several pieces of information linked data prefix.",
                    "label": 0
                },
                {
                    "sent": "This simply says resources that begin with this prefix.",
                    "label": 0
                },
                {
                    "sent": "There's link data available, so you could look that look them up and get RDF back.",
                    "label": 0
                },
                {
                    "sent": "There can be a data dump location, so this is the UI of a big file that contains all the information in the data set.",
                    "label": 0
                },
                {
                    "sent": "And there could be a SPARQL endpoint location where you can send queries over this data set.",
                    "label": 0
                },
                {
                    "sent": "And you can also use existing existing annotations from the Google Sitemap protocol, like to change frequency.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a couple of other elements, you can provide a label for that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dataset, just a human.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Label this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just yes SWC.",
                    "label": 0
                },
                {
                    "sent": "2008 metadata set.",
                    "label": 0
                },
                {
                    "sent": "You can provide a data set UI that's a hook where you could provide additional metadata like an RDF.",
                    "label": 1
                },
                {
                    "sent": "Additional RDF information like who has actually published this, what's the license and so on.",
                    "label": 0
                },
                {
                    "sent": "So anything not covered by by the by the site map by the semantic sitemaps could be provided there in an external file.",
                    "label": 0
                },
                {
                    "sent": "Same foresty authority where you can provide additional information about the publisher.",
                    "label": 1
                },
                {
                    "sent": "And sample UI where you can just add some information, some kind of representative.",
                    "label": 0
                },
                {
                    "sent": "You arise from the data set which is useful for user agents and so on for people who just want to kind of test this and see.",
                    "label": 0
                },
                {
                    "sent": "OK, So what happens when I dereference this?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why did we choose this XML format instead of putting everything into RDF?",
                    "label": 0
                },
                {
                    "sent": "That's mostly because there because webmasters are conservative, they have to put up these sitemaps and so they already know they are familiar with the site map protocol and adding this extension is probably less threatening to them, or like they can more easily understand what's going on then working with RDF complete RDF files.",
                    "label": 0
                },
                {
                    "sent": "So this is from discussion with potential users.",
                    "label": 0
                },
                {
                    "sent": "They raised this concern and so we decided not to go for an RDF format, but with XML.",
                    "label": 0
                },
                {
                    "sent": "And also well, it keeps it fairly simple and straightforward, so that's also a plus.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so sitemap discovery.",
                    "label": 0
                },
                {
                    "sent": "This is about if you start with the domain, how can you find the site map for the domain?",
                    "label": 0
                },
                {
                    "sent": "Basically this relies on robots.",
                    "label": 0
                },
                {
                    "sent": "TXT, another well established feature that tells Crawlers where they can go and not go.",
                    "label": 0
                },
                {
                    "sent": "There's the Google Sitemap protocol introduces a\nThat you add to the robots TXT which basically points to the sitemap and so a crawler or any agent can know where to find the site map.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of easy to see how this solves how this how this can solved.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The three challenges I've presented earlier the different access methods where you know there's one data set.",
                    "label": 1
                },
                {
                    "sent": "It is available as linked data in a data dump, or it is a sparkle endpoint.",
                    "label": 0
                },
                {
                    "sent": "So if you have these three elements in the in the in the in the description in the data set description, then you're fine and you can choose the most appropriate.",
                    "label": 0
                },
                {
                    "sent": "So for example, a crawler could see I am.",
                    "label": 0
                },
                {
                    "sent": "I have a UI in this linked data prefix here, so I will.",
                    "label": 0
                },
                {
                    "sent": "I will actually not dereference it, but instead I will go for the whole dump.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The core performance.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's the it's clear how how a crawler can find the dump.",
                    "label": 1
                },
                {
                    "sent": "We ran an experiment to kind of see see the see the effect of this.",
                    "label": 1
                },
                {
                    "sent": "If downloading and processing a dump is really is really better than doing a crawl and it turns out that the problem is that if you have a big dump, you still need to slice it into back into these smart small pieces that you would find on the web and then index them.",
                    "label": 0
                },
                {
                    "sent": "Or do whatever post processing you want to do and in our in our experiment it turned out that uniprot, which will take around five months to call.",
                    "label": 0
                },
                {
                    "sent": "Basically, we could download and.",
                    "label": 0
                },
                {
                    "sent": "Process the entire dump and do the same thing in about 25 hours, and so it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a big improvement and it can be parallelized on a cluster quite easily, so that's quite nice.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Provenance there is one more feature in the Sitemap I haven't mentioned before.",
                    "label": 0
                },
                {
                    "sent": "You can have sub sitemaps and parent site Maps which basically allows you to delegate a part of the UI space to someone else or to join a part of UI space from a different domain into into the one described by the site map.",
                    "label": 0
                },
                {
                    "sent": "This is useful because in practice it turns out that sometimes the sparkle endpoint is located on a different domain that dumps are hosted on a different domain, so we wanted to address this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and it's also like this SC authority hook allows us to describe more about the publishers who so clients can make smarter decisions about about.",
                    "label": 0
                },
                {
                    "sent": "Yeah, rather data comes from and if they should trust or use it.",
                    "label": 0
                },
                {
                    "sent": "So at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Most of the large linking open data datasets have his heightmap.",
                    "label": 1
                },
                {
                    "sent": "Sitemaps are supported by this industry and switch the search engine's semantic search, semantic web, or web data search engine's.",
                    "label": 0
                },
                {
                    "sent": "We have found so far that publishers are usually quite receptive to the idea, because, well, it's kind of it's easy to do.",
                    "label": 0
                },
                {
                    "sent": "It's easy to publish such a site map and what harm can it do?",
                    "label": 0
                },
                {
                    "sent": "So they say, yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "If it helps, you will do it no problem.",
                    "label": 1
                },
                {
                    "sent": "However, they want to validate or because yeah, sometimes they are not quite true.",
                    "label": 0
                },
                {
                    "sent": "Have I done it the right way?",
                    "label": 0
                },
                {
                    "sent": "And it turns out sometimes they don't because there's something despaired and so on, so.",
                    "label": 0
                },
                {
                    "sent": "So this is a request we have seen quite often and the best place to to talk about semantic sitemaps.",
                    "label": 0
                },
                {
                    "sent": "That's a public elody mailing list at WCC.",
                    "label": 1
                },
                {
                    "sent": "So the main list of the linking Open Data project.",
                    "label": 0
                },
                {
                    "sent": "Next steps an updated draft.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This forthcoming that incorporates some additional feedback that we received recently.",
                    "label": 0
                },
                {
                    "sent": "We want to have a simple sitemap creator and the aforementioned validator, and we want to move towards this, actually describing more of the content of the data set.",
                    "label": 1
                },
                {
                    "sent": "As in what's actually in there, so we have addressed how to find it or to find it and how to access it in different ways, but not really at what data you can find in there, and so there is one kind of proposal or initial.",
                    "label": 0
                },
                {
                    "sent": "Initial project going on now that actually started here at the SWC called Void.",
                    "label": 0
                },
                {
                    "sent": "And so we had.",
                    "label": 0
                },
                {
                    "sent": "This is one thing that we hope to produce like a draft or something like a proposal in the next couple of weeks.",
                    "label": 0
                },
                {
                    "sent": "So to summarize.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Semantic sitemaps.",
                    "label": 0
                },
                {
                    "sent": "Our proposal for enabling better RDF discovery.",
                    "label": 1
                },
                {
                    "sent": "They allow publishers to announce what RDF data they have and they allow RDF consumers like web crawlers and so on to efficiently find it and semantic.",
                    "label": 1
                },
                {
                    "sent": "Sitemaps also have hooks for describing the content and authority in more detail, which can be used to build set probably 2 to build interesting, more advanced applications.",
                    "label": 0
                },
                {
                    "sent": "On top of this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So yeah, that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have to say that this is really great, is probably the best and most immediately useful proposal that I heard on this whole conference.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm just wondering.",
                    "label": 0
                },
                {
                    "sent": "You said you were already talking to some publishers.",
                    "label": 0
                },
                {
                    "sent": "Can you name some more or something like that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's so the people we have talked talked to mostly are people in the linking Open data project, so it's people who publish RDF who converts existing open datasets to RDF and publish this on the web.",
                    "label": 0
                },
                {
                    "sent": "So the things.",
                    "label": 0
                },
                {
                    "sent": "So some things that come to mind.",
                    "label": 0
                },
                {
                    "sent": "Dbpedia Geonames has one the the data published by Hugh at.",
                    "label": 0
                },
                {
                    "sent": "In Southampton, they all have site.",
                    "label": 0
                },
                {
                    "sent": "All of these sites are described inside Maps and so on.",
                    "label": 0
                },
                {
                    "sent": "There we don't really have any like big names web to all companies also or because they usually don't publish RDF on focus.",
                    "label": 0
                },
                {
                    "sent": "More on microformats or web kind of more traditional web APIs.",
                    "label": 0
                },
                {
                    "sent": "XML based and so on.",
                    "label": 0
                },
                {
                    "sent": "And we don't really address this so much because they like crawling them.",
                    "label": 0
                },
                {
                    "sent": "It works a little bit differently.",
                    "label": 0
                },
                {
                    "sent": "We probably should do something about about microformats also, but.",
                    "label": 0
                },
                {
                    "sent": "So we haven't done this because kind of the background, the people who started this archive from the RDF field, and so this is where we started.",
                    "label": 0
                },
                {
                    "sent": "But microformats RDF eight.",
                    "label": 0
                },
                {
                    "sent": "It's definitely something we want to.",
                    "label": 0
                },
                {
                    "sent": "We want to figure out how this fits into all of this and then also time to talk to talk to all publishers of any sort of structured data on the web.",
                    "label": 0
                },
                {
                    "sent": "Rather questions.",
                    "label": 0
                },
                {
                    "sent": "So I have one.",
                    "label": 0
                },
                {
                    "sent": "So what happens in case they give multiple ways of writing data?",
                    "label": 0
                },
                {
                    "sent": "What happens if, for example, the data dump differs from from the linked data?",
                    "label": 0
                },
                {
                    "sent": "Is there a way to provide a preference?",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "So basically our thinking is that as a data publisher, you shouldn't do that because well, yes, because you actually want to want to provide that.",
                    "label": 0
                },
                {
                    "sent": "I want everyone to get a consistent view of what data you have and if it happens where.",
                    "label": 0
                },
                {
                    "sent": "So I can just say in the case of synergy when we find the dump and we process the dump, then yeah, we will see whatever data is in the dump.",
                    "label": 0
                },
                {
                    "sent": "And if you actually have some slightly different or more up to date.",
                    "label": 0
                },
                {
                    "sent": "Data available through the link data interface, then yeah, OK, we will not see this and actually it's kind of common that the dump is just produced once a week, and so on and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so at the moment we say that yeah, we will just kind of.",
                    "label": 0
                },
                {
                    "sent": "Hopefully it doesn't matter so much like I think this is true for most of the RDF datasets that we have right now.",
                    "label": 0
                },
                {
                    "sent": "It might change in the future when we have really frequently updating RDF datasets that are of high value and well, then you could hopefully still make a decision based on the last modified date or this change frequency data.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you thanks.",
                    "label": 0
                }
            ]
        }
    }
}