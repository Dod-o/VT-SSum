{
    "id": "o5shf6tdxcl57ygbmwrandzjiyvxmwn2",
    "title": "Relational Latent Class Models",
    "info": {
        "author": [
            "Volker Tresp, Siemens AG"
        ],
        "published": "Feb. 7, 2008",
        "recorded": "January 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Principal Component Analysis"
        ]
    },
    "url": "http://videolectures.net/psm08_tresp_rlc/",
    "segmentation": [
        [
            "And interesting noises for letting me speak at this.",
            "Great location this great occasion.",
            "So the title is relational latent class models.",
            "The collaborators Joshua and a lot of this is her dissertation work.",
            "Then Steven lack of REM rettinger.",
            "Matthias Nicolls Cayuse shipping you and Hanspeter Krieger."
        ],
        [
            "So the tool.",
            "Basic messages I'm trying to convey the 1st morning that domains are quite important and interesting, which might not be big news to many of you.",
            "Segmentation methods can be quite effective in modeling relational domains."
        ],
        [
            "So in some sense, relational problems are about networks.",
            "So here we see the World Wide Web consisting of hyperlinked web pages and we know that the linkage information is quite relevant to determine the relevance of a web page.",
            "Another example down here is a social network of people.",
            "And as you know.",
            "This is around 1900 and these people are very influential in the course of history of.",
            "Europe in the 20th century, and if these people would not have been related, so we might have been quite different.",
            "Social network analysis difficult.",
            "Definitely one very interesting area which falls under."
        ],
        [
            "And here we see gene interaction networks.",
            "Which were interacting genes are quite relevant for biological function.",
            "In some in some domains we only have one type of nodes.",
            "One type of relationship.",
            "But of course domains can be so much richer.",
            "So here in the typical recommendation engine setting, we have two types of entities, users and items and web link matrix which shows us which user has bought which item or which user has rated which item.",
            "So here we have two entities and one type of relationship.",
            "Of course, we can also have attributes, but in most experiments the link matrix is more informative about future ratings and future interactions than the attributes.",
            "On the right side we see a medical domain.",
            "There we have patients, physicians, nurses, hospitals, medication, diagnosis procedures, interactions, medication and so on.",
            "So many, many different types of entities.",
            "Many different types of interactions, and if you want to predict the outcome, for example for patient, many of those things will play a role in this highly interconnected domain.",
            "Yeah, this is to indicate that maybe even the brain uses some form of relational presentation anyway, racial representations are obviously very useful from a technical point of view, and maybe also from a biological point of view here on the left bottom we see the semantic web or the RDF part of the semantic Web.",
            "So RDF stands for Resource Description framework and the base.",
            "There is a very simple statement of subject predicate object.",
            "Giving information about subjects about objects and their relationships.",
            "And since these relations are binary, you can easily draw them as a graph.",
            "And of course, here again, many types of entities, many types of relationships.",
            "On the bottom here we see text and information extraction text where you extract entities from your text you want to extract relationships from your text, which gives you some basic understanding about the content of the text.",
            "So these are some examples where relation information is quite important to solve the problem."
        ],
        [
            "So I tried to relate it to John Donne.",
            "Who is famous for this statement that no man is an island entire of itself?",
            "Every man is a piece of the continent apart of the main.",
            "So this was also an epigraph of Hemingway's novel, for whom the Bell Tolls, which conveys quite nicely that in a relational world in some sense.",
            "Everything depends on everything."
        ],
        [
            "Yes, some overview about work in this domain, of course incomplete it statistics.",
            "There's the area of social network analysis.",
            "The tradition here of course, that is that it's quite difficult to get relational data if you do a field study.",
            "You have to meant maybe interview actors and actors and squared possible relationships.",
            "So it's quite difficult to obtain this data.",
            "And typically in the history I think these networks were relatively small and the analysis was mostly descriptive, deterministic algorithms.",
            "So who is central?",
            "Who is a central function?",
            "Where some clusters in the in the network and so on.",
            "But in recent years, there's increasing focus on statistical inference.",
            "There was a network, a workshop at Nips last year on Statistical Network analysis with a lot of contributions from leading statisticians.",
            "But of course they are more driven by the problem at hand.",
            "Small datasets.",
            "What can we do with them?",
            "Often they approach problems with one type of actor and one type of relation.",
            "Then of course there are specialized algorithms like page rank algorithm, collaborative filtering algorithms and so on, which.",
            "People might not even think about that.",
            "This is a relational problem.",
            "Then in our area there is inductive logic programming that's based on 1st order.",
            "Logic focuses on the generality of the approach.",
            "Sometimes you have the feeling that they are a little bit lost in generality.",
            "They are learning typically rules for prediction of predicates.",
            "Relationships and attributes mostly or they started off trying to find deterministic rules, but their recent extensions towards also probabilistic approaches to this.",
            "And the last group I want to address is statistical relational learning.",
            "Which starts off as a principled probabilistic approach from machine learning and AI to these type of problems, there's focus on uncertainty in relational domains, and the focus on analysis of dependencies, prediction of attributes and relations, and the work today is."
        ],
        [
            "So I think in the last class and statistical relational learning domain.",
            "So if you take a closer look at this domain.",
            "Other famous probabilistic relational models.",
            "PRM models from Carla Freedman.",
            "Get your FIFA and other people.",
            "They combined a relational description with components from frame based systems and Bayesian networks.",
            "Couple years later, that upper model was brought up, sensor directed basically probabilistic entity relationship model from Heckerman, Meek and color.",
            "It's based on the entity relationship description known from database design in combination with Bayesian networks.",
            "So the first 2 approaches can be shown to be equivalent of the PRM model is slightly extended.",
            "And in this presentation I will focus on this DARPA representation.",
            "A few others, to name our relational dependency networks of Neville and Jensen relational Markov networks of task and coworkers and Markov logic networks of Richardson and Domingos."
        ],
        [
            "So what we do we do in this work, we apply a nonparametric hierarchical Bayesian modeling to relational learning and achieve nonparametric relational base in form of an infinite hidden relational model and also touch on related approaches.",
            "So we take two very difficult things and get something out.",
            "Which is, I think not more difficult.",
            "Then either of them there's some basic advantages are straightforward to apply to relational domain without extensive structure, learning attributes relationships, but also the identity of entities can have predictive power, so the latter one is typically important for collaborative filtering type of applications where attributes are often very weak.",
            "We have obtained a cluster analysis of relational domains.",
            "We can analyze the clusters.",
            "We have found multi relational clustering.",
            "For example, identify the role to factors.",
            "So in a lot of network analysis you see a network composed into highly interconnected subnetworks, but sometimes.",
            "Actors which are similar are not in the same network, they just played the same role because they're both teachers, but in very different schools.",
            "Or they're both managers or workers or students and so on.",
            "So you don't, you can detect it from the dependency structure in the network, but it's not necessarily a cluster in the network.",
            "So it's very interesting."
        ],
        [
            "Problem I think.",
            "So before relation learning, so this is nobody you should know, but you might have left around here 50,000 years ago."
        ],
        [
            "So we all love the matrix, of course, so the larger structure is ignored and flat representation is applied.",
            "The standard assumption is that data points are sampled independently, so we have patients.",
            "Here is an example of a patient in hospital with patient properties, and you want to predict outcome.",
            "So RO is a data point or patient and a column is a SIM attribute.",
            "And here's a simple data model describing this situation.",
            "So the entity classes, patients and.",
            "Patient has associated attributes the patient property and the outcome, and this error indicates that we want to predict the outcome from the patient property.",
            "Also, there's the parameters involved and maybe even hyperparameters, so so this is describing the situation from Beijing Pilot point of view and then you can do learning or inference in this in this model.",
            "And we know very well how to do that.",
            "But we also."
        ],
        [
            "Already you have touched into relational learning in some ways.",
            "Here's one example time series modeling.",
            "I mean, the time series is typically still displayed as a matrix, but temporal ordering of the Rose is important, so if you scramble the order of the data points, you typically get a different result.",
            "Often we use a simple template for the model, where we assume there's some stationary to that.",
            "If you predict something based on the recent past, this model of the stationary, it doesn't change too drastically, at least overtime.",
            "And although the model might factorize the complete data is one time series in some sense one data point.",
            "And also here everything depends on everything.",
            "So in this hidden Markov model, even if we know all the data points and all the parameters, the hidden state of the hidden variables will depend on all of the measurements, not just on the ones in the same.",
            "Row, so this is already giving a flavor of how relational modeling works.",
            "Give this interconnectivity.",
            "You have this template where this global dependencies."
        ],
        [
            "Another one, which is also important for this presentation, is hierarchical Bayesian modeling.",
            "So here we see stochastic sampling in on the logical hierarchical Bayesian model."
        ],
        [
            "So what is the difference?",
            "If you look at this patient model again, we have a patient with outcome in property and the dependency here, but now a patient is in a hospital, so it's associated with with another entity.",
            "And of course the outcome might depend on hospital properties we don't know about.",
            "For example training of staff.",
            "Mixture of the patient where the hospital is located or what the patient mixes with the age of the patients are, and so on.",
            "And if we don't have that information, we still might be interested to say, OK.",
            "Hospitals are sort of similar, but they are also differences, so that one extreme, of course, is to say the hospital doesn't matter, so we pull all the data in one model, the other the other one.",
            "The other extreme is shown here.",
            "The hospital ID should be an input, but this would probably lead to bad generalization because essentially you can only use the.",
            "Patient data for this particular hospital to train the model.",
            "So we want to sort of inherit some knowledge across the hospitals and this is how, of course, how hierarchical Bayesian modeling works.",
            "OK, so this one."
        ],
        [
            "So in hierarchical Bayesian models, we still say the parameter for predicting outcome from patient property is still owned by the hospital, so each hospital can have its own dependency, but.",
            "But the parameters are tide together by the same prior distribution.",
            "And by sort of adapting the parameters in the prior distribution, we learn a common prior model which allows that.",
            "For example, a new hospital model can inherit the prior distribution from the previous learned hospitals, and also the strength of the Pristiq modeling between the hospitals is shared.",
            "So we have this sharing strings effect.",
            "And we can go to the extreme and say the prior distribution comes from a nonparametric priors solution from Additionally process which is indicated at the bottom there indicating that the the prior distribution is a sample from additional process based distributions do not and concentration parameter or not.",
            "And so why is this a good idea to go to a non parametric hierarchical represent?"
        ],
        [
            "So this is my slide to explain that.",
            "So on the left top we see our indicates on prior distribution for parameter Theta.",
            "So it's not informative, maybe isotropic Gaussian distribution?",
            "Then when we Start learning, we get more and more data and the posterior distribution becomes more and more focused.",
            "At the end we get a point distribution.",
            "So we have many, many data points.",
            "We can identify the two parameters in the model, and if you do that now for many many different hospitals, we get one parameter set for each of those hospitals and then end up with a distribution of of maximum likelihood but about parameters.",
            "And an if this distribution shown here can be modeled by just tuning parameters in the prior distribution.",
            "For example, this is already also Gaussian with some new covariance matrix and a note and another mean.",
            "Then this is perfect for hierarchical parameterized hierarchical basian modeling.",
            "But in many cases this distribution might be odd, shared, maybe like a banana on the bottom right or multimodal and cannot be represented well.",
            "We're just tuning parameters in the prior distribution.",
            "And to be really flexible, we should then go to a nonparametric prior distribution, which is a sample from Additionally process.",
            "So this is the motivation to either Michael combinations.",
            "You have a very high dimensional representation which is very flexible by itself, or you should go nonparametric.",
            "Parametric has some problems maybe."
        ],
        [
            "OK, there's another view on the same thing, so we said we want to have personalized parameters for patient outcome prediction.",
            "We can also assume that a hospital becomes belongs to a cluster and all hospitals, all data or hospitals in the same cluster should share data.",
            "And of course you make it sort of probabilistic.",
            "So it's later in class model.",
            "So in Adapa framework it looks like this so associated with each hospital, we now have a latent variable.",
            "Steve and the state of Z determines which parameter to take to model this dependency here.",
            "Now of course we let the number of states in this latent variable to go to Infinity and obtain additional process mixture model DPM and it turns out that this DPM is exactly the same as a non parameter hierarchical Bayesian approach with the judicial process prior.",
            "So in some sense it's.",
            "I mean it's the same thing but sometimes this is much easier to think about because now we can think about latent class models and don't have to think about this strange infinite.",
            "This stuff anymore just in our in our mind we just let the have infinitely many states.",
            "Otherwise it's the same as a mixture model.",
            "And if we do Gibbs sampling in this model.",
            "Then of course only a limited number of clusters of these infinite states can be occupied.",
            "I mean, up are limited by the number of data points, obviously, but in general or most cases, the actual number of occupied states is much less than number of data points, and we can interpret this number as the number of.",
            "True, true clusters in the in the domain.",
            "It's an interpretation.",
            "I think it's not a true statistical inference, because actually the infinite number of components are always there.",
            "But this is very important, in particular in relational modeling, because now we don't have to do all this exhaustive whatever.",
            "Optimization of the structure of this thing because we have many different entities with different cluster variables and if we have to tune the optimal number of States and all of these, this would be quite difficult.",
            "And of course the hospital can form of a large cluster if they're all the same, or if a hospital is very unique, alternative medicine or whatever.",
            "Or magical treatments.",
            "Then they can also form their own cluster.",
            "So you have this personalization to the extreme.",
            "If the model is sites that this is.",
            "Useful."
        ],
        [
            "OK, now we go to relational learning.",
            "Yeah, we're in the middle of the statistical relational revolution."
        ],
        [
            "So, not surprisingly, relational data off is stored in a relational database, and both the relational model and the entity relationship model ER are useful description of the structure of a database."
        ],
        [
            "So this is an entity relationship.",
            "Model is typically used in the design phase of a database.",
            "So the main components are entity classes.",
            "In this case, students and courses.",
            "A relationship class student takes a course and the attribute classes student as the attribute.",
            "IQ course has the attribute difficulty and the relationship class take has the attribute.",
            "Existor ranking or something like that.",
            "Great, great for example, might be a good attribute.",
            "And based on this you are model then the relational tables are constructed and relational database can be formed."
        ],
        [
            "We can look at something like a network here describing the ground facts.",
            "So if our database consists of Mary, Jack and John, the database might contain information about that.",
            "Mary's IQ is high, and so on.",
            "We have caused this math and physics down here and they are have high difficulty, intermediate difficulty, and here's the information about.",
            "Which person took which class?",
            "So this can be thought of in social network analysis.",
            "This would be called associate Gram.",
            "In semantic web it would be called Resource description Framework graph, RDF graph.",
            "Of course, this only works so easily if the relationships are binary, otherwise you could hypergraphs and so on.",
            "But unfortunately RDF is limited by their relationship, so there we have no problem."
        ],
        [
            "OK, so so this is the ER is about database design.",
            "The DARPA model privacy constraints are formulated at the level of the ER model and act as template for forming the ground deck.",
            "So we have to introduce additional classes.",
            "The art class which indicates which.",
            "The dependencies between the attributes.",
            "So here we indicate that the grade depends on the IQ of the student and the difficulty of the class.",
            "Then we have the local distribution class, which indicates that we model this, maybe as a multinomial distribution, and we have the constraint class, for example, that the greatest influence by the student who took the class or not by the other students.",
            "But there might be more complex constraints then these constraints.",
            "Of course, very important if you logically oriented but not so focused in the probabilistic modeling.",
            "And of course we have parameters describing the dependencies here."
        ],
        [
            "But we should be aware that based on this template and then the actual objects in the domain, we have to form the ground Bayesian network which shows you the dependencies between the actual attributes in the ground paging network.",
            "So here the IQ of the first person depend determines the grade on the left side that upgrades and so on.",
            "So this shows you the real dependencies and the real ground based network.",
            "And we have to do inference and learning in this ground Bayesian network.",
            "And you see that this is highly.",
            "Easily, highly connected and if some variables are unknown, inference and learning becomes difficult, and but the implication is that parameters that are shared in this network.",
            "So dependency of grade on IQ and difficulty is the same everywhere.",
            "So all this madness."
        ],
        [
            "Heritage sharing in the this is an example of a PRM model.",
            "So many applications.",
            "It is unreasonable to assume that the progressive dependency structure is known and for example, in the PZM consider work has been invested in modeling and learning the structural dependencies.",
            "Unfortunately, the structure learning here is even more involved than in non relational Bayesian networks due to the explosion possible attribute candidates as parents.",
            "Typically, evasion scores optimized using some reasonable sets.",
            "Such strategy is an example of HIV and patient properties.",
            "Strains of HIV context the person had, and so on."
        ],
        [
            "So now we combine infinite hidden relational model and I mean relational learning was not provided correct equation learning which is the IRM model which in some way does not need this extensional extensive structural."
        ],
        [
            "Running so probabilistic relational models provide template template into parameter sharing in the ground paging networks, and as we discussed in the non relational case, this might be too stiff for many applications, so you want to soften this by doing some type of hierarchical Bayesian modeling.",
            "Because then promise can be personalized and sensible way.",
            "Patient outcome could have some hospital specific effects, so the natural question is how it will generalize hierarchical Bayesian modeling to relational learning.",
            "If the parameter dependencies, relational, parametric, hierarchical, basian version, relational version with the parameter representation, I found very difficult to think about becausw, we have to define a distribution whose hyperparameters depend on two or more entities.",
            "But the nonparametric hierarchical Bayesian approach is much easier to generalize.",
            "So despite the fact that it's essentially."
        ],
        [
            "Difficult.",
            "It becomes more simple and here's the basic idea.",
            "Again, using this simple example of user and movie, having user attributes for the user movie attributes for the movie and the rating.",
            "If a user watches a movie and writes a movie.",
            "So if the user attributes and the movie attributes be informative and very strong and very good, then this might be a reasonable model.",
            "Now we can predict the rating just if you know the person very well.",
            "And if you know the movie very well.",
            "But in most cases we have to assume that we don't have so much info."
        ],
        [
            "Patient about the user, so reasonable thing is to assume let's use the ZU variable to represent all the stuff we should know about the user.",
            "But we don't know about the user, so it's a latent variable and the actual user attributes are now children of this children of this variable.",
            "And now we have the effect that yeah, OK, there's some hidden information if you would know it, we would be able to do a perfect prediction for the rating.",
            "And we can do the same thing for for the movie.",
            "Let's say we don't have enough movie information, so we should introduce another latent variable for the movie and obtain this structure.",
            "And of course, now since we like this infinite stuff, we let the number of States and these latent variables go to Infinity Infinity.",
            "And this is exactly the way this is more."
        ],
        [
            "So we end up with.",
            "This is a hidden, infinite hidden relational model, so we have simply introduce latent variables for the entities and couple them whether we are the relations and have attributes as children."
        ],
        [
            "So this is the same thing with all the parameters involved based distributions.",
            "Concentration parameters and so on, but these are just technical details.",
            "Just think of it as a latent variables with many many states."
        ],
        [
            "So the recipe is simple to each entity in infinite latent variable specific to each entity classes assigned.",
            "This latent variable is the parent of the remaining attributes of the entity is sort of also an attribute, and it's apparent of the relationships these entities are involved in.",
            "One question might be isn't this too limited?",
            "Because now we have very limited.",
            "I mean very local dependencies following the relationship structure.",
            "Not necessarily, I mean, remember the PRM we had to do this very involved structure learning to really know which variable was influenced by which, and this is a very simple recipe.",
            "So argument is not necessarily very limited, because information can propagate through the network of latent variables."
        ],
        [
            "So this is this would be a sort of an image like ground network without the latent variables.",
            "So we would have the attributes A and the relations are and in this page and network information is very local and blocked right?",
            "So because a is not a Collider so it blocks information if A is known and R is is a Collider and if the relationship is known it's open.",
            "So but a is blocking everything else.",
            "Talking everything because it's known.",
            "So this is the case.",
            "We do movie recommendation with very good attributes."
        ],
        [
            "Now introduce the latent variable C and we.",
            "Now we have a network where information can globally flow because the latent variables are unknown and open up, the connections are are is a Collider, so it's open.",
            "So information can propagate in this information quite freely, and this looks like an image ring structure.",
            "I made it also to look at like in this way.",
            "So in an image Reconstruction Z would be the unknown true pixel value.",
            "They would be the noisy measurement of the pixel and are would indicate if two pixels are neighbors or not.",
            "So you can relate it to this type of problems.",
            "And we see also that everything depends on everything because information flows through the network of latency."
        ],
        [
            "So that yes, I hear some groups which have worked on this type of networks.",
            "The first one is the group at MIT.",
            "Ken Griffey Tenenbaum and coworkers.",
            "So they worked more on our relational description, but the models are mathematically quite similar.",
            "We have a slightly different treatment of attribute values, but the difference is probably not major.",
            "We have done two models.",
            "One is that usually enhanced relation learning model.",
            "The down model and the second one is the model I present today.",
            "The infinite hidden relational model.",
            "Then previously to this they have been finite versions of this people with side know Vicki and Snyder's for this, and there has been a recent finite version with mean field approximation at the workshop at NIPS.",
            "Another interesting work is the MSP work mix memberships to ask block model of reality Bly find back in thinking it's a finite model and then there's another infinite model by a Finnish group sync on an alkene kusky inferring vertex properties from topology in large networks.",
            "I'm so I want to briefly.",
            "Tell you a little bit about these things.",
            "Maybe it's getting a little too complicated so you can sleep 2 minutes or so, so this is some way of looking at the, uh."
        ],
        [
            "So model in a, let's say homogeneous network, only one type of nodes, one type of relationship.",
            "So each node.",
            "Assorted associated with each node is a state of a latent variable.",
            "So each node belongs to one cluster in the ground.",
            "Truth exactly.",
            "Based on this assignment to a cluster of the tool.",
            "In both nodes, the corresponding parameter is picked, for example, for Vandalia distribution, and then this determines the probability that this relationship exists between North high and low J.",
            "But the ground truth is that we know this."
        ],
        [
            "Assignment in the MSB model an additional layer is introduced so each node owns parameter vector of multinomial parameters and based on this if we want to determine if the node of the link RIJ exists, we sample once from this distribution, the latent state of this variable based on this parameter within these parameters do that for both nodes and based based on this on the notes, we end up on the states we end up with.",
            "We pick the corresponding parameter.",
            "To determine the probability so the new thing here is that for each relation we want to predict for each link we want to predict, we do a new sampling of the latent variable.",
            "This means that each node can be in several modes on several different.",
            "Topics or something?",
            "It's like a topic model.",
            "Now we say we don't limit a note in the ground truth to be part of 1 cluster, it can become part of the member of different clusters if it's useful.",
            "In some applications, this might give you added flexibility, which is necessary, but I think it's quite complex if you do that, it looks like the LDA model in some sense."
        ],
        [
            "So this is, uh, our previous model, the Dell model, where we ascentia Lee assign some of the source of the link to one cluster, so only one note is involved.",
            "Then we pick a parameter vector based on this assignment with the cluster and then repeatedly generate links with this link as an origin and the state of this selection variable determines to which.",
            "Note this is pointing to.",
            "So this we have introduced previously."
        ],
        [
            "And there's some generalization, but this can also do this with the mixed membership, but."
        ],
        [
            "Maybe not too interesting.",
            "Then there's this finish group which assigns a cluster variable to each.",
            "So it's an infinite model.",
            "They assign a cluster model variable to each link, not to each node, but which link based on this cluster assignment, the corresponding multinomial parameter vector is picked and then two.",
            "Two latent variables are sampled based on this parameter vector, and if Emma samples you never sampled here, then we make a link between M&N.",
            "So this is quite interesting and it's I think the direct innovation of appeal is a model.",
            "Appeal as a model differ members from Hoffman and coworkers dependencies between documents and words, and if you replace both by nodes.",
            "In the network you pretty much end up with this model.",
            "But we see quite a lot of advantages for the IRM model, in particular that we have no problem modeling multiple relationships, complex types of entities and also attributes are easily handed in.",
            "I think most of the other problems have more difficulties there."
        ],
        [
            "So now let's talk about the hard part learning influence experiments.",
            "So we derived and compared various inference and learning approaches first.",
            "Gibbs sampler derived from the Chinese restaurant process representation.",
            "Then the Gibbs sampler derived from a finite approximation to the stick breaking representation to seek representation that usually multi normal allocation of the truncated usually process to mean field approximations based on these and memory based empirical approximation."
        ],
        [
            "The first experiment is on movie prediction rating prediction on using movie length daytime.",
            "So we have user with user properties movie with movie properties and we want to would like to predict the rating of a user for movie."
        ],
        [
            "Here the attributes the users attributes are age, class, gender and occupation and the movie Class I movie attributes at genre and year."
        ],
        [
            "So this is a showing the results.",
            "We have been.",
            "We have obtained.",
            "So the 1st three rows are Gibbs samplers.",
            "Chinese restaurant process truncated usually and usually multinomial.",
            "Then we have the two mean field approximation and the empirical approximation and is the prediction accuracy given 5 ratings for the test user 10 given 15 given 20 ratings for the test user we see here that Gibbs samplers are slightly better than the mean field approximations and the mean field approximations are slightly better than the empirical approximation.",
            "In terms of accuracy, but in terms of speed, the Gibbs samplers are quite slow compared to the mean field approximation, which is an order of 10 faster than the Gibbs sampler and empirical is even faster than that.",
            "Interesting also to look at the number of components we have obtained, so the Gibbs samplers have obtained converge to more components than the mean field approximations.",
            "But if we look at the number of really occupied classes then they are quite similar.",
            "Oh, this is this is the number of computers components for the user in here for the movie because they have two 2 cluster variables."
        ],
        [
            "Here's an example of clusters we have found.",
            "So the first number here.",
            "So this is using the Gibbs sampler, so the first one is the number of stable movies in this cluster, and the second number is the number of typical movies in the cluster.",
            "So the first one we decide at that time, so I think it was the data where from 1998 or something very new and popular movies then old non US and drama and comedy and children's.",
            "Oriented movies or comedies.",
            "New action movies.",
            "Old action movies or drama and Harrison Ford.",
            "He needs his own cluster.",
            "So yeah, so there's a distribution of cluster occupancy and this is what we meant.",
            "Now if you go."
        ],
        [
            "To more than 10, so the brownish one is a mean field solution and.",
            "Blue and green are Gibbs samplers, so the occupation drops down drastically if you go to larger cluster numbers and the Gibbs samplers have longer tails."
        ],
        [
            "The mean field solutions.",
            "You can then use a different cluster properties so the age distribution is different in the different clusters for users and you have different gender distributions in the clusters."
        ],
        [
            "You can look at the movies.",
            "You can look at the classification of the movies, how they are distributed across the clusters, and you can use look in the bottom here at the distribution of idea of occupations, different clusters and you can also look at the."
        ],
        [
            "The crossover the matrix between the movie clusters and the user clusters where we found interesting when we left the attributes away.",
            "The cross matrix for example didn't change too drastically because one reviewer once complained that.",
            "We just recovered the.",
            "The movie classification, which is not quite sure it was even stable when we took that information away.",
            "But the relation again, relationship information is quite interesting for this application."
        ],
        [
            "So the second one is concerned with gene interaction and gene function.",
            "The task is a cluster analysis and the prediction of gene function.",
            "Given other information.",
            "We used to see why GD data comprehensive used genome database from Munich 1000 genes and attributes.",
            "Chromosone motive essential class phenotype, complexin function and interaction data from the from dip."
        ],
        [
            "So in the top left you see the IRM model for this application.",
            "So we have one entity class gene which might interact with another gene.",
            "So jeans might interact with each other.",
            "Then we have here the latent variable Z and then we have all the other attributes.",
            "So we have gene functions, which is cell growth, cell organization, transport and so on.",
            "Genes might interact with one another for gene, one or more phenotypes are observed in the Organism.",
            "Gene kind of complex with others to form larger larger proteins.",
            "Protein coded belongs to one or more structure categories.",
            "A gene might contain one or more character characteristic motives and gene attributes are essential, and the chromosome and so on.",
            "So if you look at this again, the template on the left and the right you see an indication of how the ground network will look like.",
            "So we have the latent variables here which interact.",
            "So this indicates an interaction between the corresponding genes.",
            "And the latent variable, again, is the parent node of all the other attributes of the gene."
        ],
        [
            "So this is a result we got out from the clustering analysis.",
            "So the colors correspond to clusters.",
            "The nodes are the jeans and the links are the interactions, so the clustering pretty much followed the linkage structure in this problem.",
            "So we show the largest cluster, see only the interactions happening between the genes in those clusters.",
            "Otherwise that would be too cluttered and you see that again the interaction information is exploited quite heavily.",
            "So in this case we see that not so much.",
            "Maybe the role of a gene.",
            "IS has been extracted, but the sort of into highly interconnected activity in a cluster in a local cluster domain.",
            "So we see clusters in the network itself here.",
            "And we can even label them with informative labels.",
            "Some of them mean something to a biologist."
        ],
        [
            "This indicates how much the performance drops when we remove an information, and so it means that if we remove complex, the.",
            "Prediction accuracy drops most, so this is the most important information and interaction is the second highest gives you the second eyes information.",
            "So interaction complex are the most critical ones.",
            "We also try."
        ],
        [
            "To include ontological knowledge.",
            "Shown over here, and it's very important for semantic web applications and other things.",
            "So we had an ontology for complex.",
            "And wanted to use this to improve the prediction for function.",
            "So the way we did that we use the variables in the taxonomy ontology as additional variables for the gene.",
            "But we also took into account the constraints in the taxonomy.",
            "So if you assign to a particular node then you also assign to all parent nodes and so on.",
            "So this was also employed."
        ],
        [
            "Painted and if we do that, we can improve the prediction accuracy for function if we use the ontology for complex.",
            "So here we see our C curves and the other one is the one which we exploited the ontology, the lower one is the one we didn't do that.",
            "Also there the clustering changed and become became more stable and we're still in the process of analyzing this.",
            "So we can."
        ],
        [
            "Extend the model in many different ways.",
            "Because it's a probabilistic model.",
            "See.",
            "We started late.",
            "Can I go a little bit on here?",
            "OK, so this is an application to clinical decision support patient.",
            "In a clinic with diagnosis and procedures, relationship classes make a diagnosis.",
            "Take a procedure.",
            "The patient typically has multiple diagnosis and procedures.",
            "Patient attributes are age, gender, primary, complaint, and diagnostic attributes are classes and ICD 9 and procedures and CPT 4 code.",
            "So this is how the."
        ],
        [
            "ISI model looks for for the decision support problem, showing the entities, patient procedure and diagnosis.",
            "So we didn't take many other things into account.",
            "Taken makossa relationship classes and."
        ],
        [
            "I said here we are.",
            "10 best results using the IRM.",
            "So here we want to predict the procedure.",
            "So this is sort of a recommendation system for physician.",
            "So what should we do next given the first procedure, and given the prime complaint, another patient information and again we see RC curves and the top one is the full HRM model, then we took the attributes away, which only used relationships which dropped made the performance drop to here.",
            "We made it a 1 sided problem, which is probably a bad idea because this gave you the worst thing here.",
            "Did a pure content based approach, removing the relational information, which is this one here.",
            "This one here.",
            "So it shows you when we take information away either attribute information in relation information performance becomes becomes worse.",
            "So doing relational modeling in these domains is quite important."
        ],
        [
            "So the final experiment is about trust learning.",
            "Who do you trust and when do you trust him has been accepted for the Amos conference this year?",
            "So the need for revelation of trustworthiness of agents in future encounters is getting increasingly important in distributed systems.",
            "Since contemporary contemporary developments, such as Semantic web service oriented architectures, pervasive computing, ubiquitous computing, and grid computing are applied mainly to open and dynamic systems within with interacting autonomous agents and most existing statistical customers do not perform well when there is no long history of interactions in a predefined and consistent environment.",
            "So we want to implement and learn context sensitive trust model from past experience using a probabilistic relational models.",
            "So seller might be trustworthy if offering a specific product, but not offering another product.",
            "And we used eBay data 'cause this is real world data and it's a serious fraud is a serious issue here.",
            "And eBay users leave feedback about their experiences."
        ],
        [
            "So this is the IHRA model in this application so we have an agent.",
            "He's the person he wants to buy something.",
            "I don't know, he said one who sells something, sorry, sell something and they actually could see our percentage of positive ratings has obtained the eBay feedback score more than X number of positive ratings and membership.",
            "How long this person has been a member then?",
            "The item information is the top eBay Category 47 of them and the condition new or used.",
            "Then we have two relationships here.",
            "One is indicating final price.",
            "Of the item and number of bits which have been done, and then the other one is the feedback and we're interested in predicting feedback for new interactions."
        ],
        [
            "So we had 47 sellers, 631 different items and 1800 rated sales.",
            "Of a much larger number of possible sales.",
            "Here the top one shows you the 47 agents and therefore agent clusters and the bottom matrix shows you how the agent clusters and the item clusters are assigned to each other we.",
            "Did not quite so we did not do random sampling be cause I guess most writings are positive, so we try to balance that we get enough negative.",
            "And problematic cases in there that the probabilistic model had an easier time to do that.",
            "So if you look at some comparison here, so the ratio means I think we just take the majority or something or something trivial decision.",
            "And since it's 50% that just reflects that the data are balanced, we have as many positives negatives then SVM decision tree are purely content based approaches.",
            "Then there was some way of introducing some relation information and.",
            "Then we did the IRM and last one gave you the best accuracy.",
            "So the relation information and taking care of this in a principled ways quite relevant in this domain, and I think it's quite new to this problem of trust learning and people got quite excited about this.",
            "I will not.",
            "Bet on that we can keep this 10% advantage on the IRM.",
            "I think if we do a better job in the other models using the relation information, this score would probably also go up there and we are in the process of doing that.",
            "But it's definitely an indication that relational approach is quite useful here.",
            "And not just content based approach."
        ],
        [
            "OK, so we conclude we have introduced the IRM to realize nonparametric relational base and suggest that it might be an interesting model for number of relational problems.",
            "For relational domain, its advantages are that we don't have extensive structure learning, so the recipe is quite straightforward to apply.",
            "We have expressive coupling, I mean extensibility via coupling between heterogeneous relationships and heterogeneous entities.",
            "The model can decide itself about the number of optimal optimal number of states of the latent variables.",
            "And of course the clustering structure can be analyzed and can lead to a better understanding of the relational domain.",
            "Other many interesting extensions we already talked about ontologies.",
            "We also can cluster relations by sort of making relation just another attribute of a more general class of relations.",
            "Compaine coworkers have done that, so there are interesting extensions to this.",
            "I think the advantages are the simplicity and easily applicability Ann.",
            "And the great variety of models you can work with do using these models.",
            "OK, thank you very much."
        ],
        [
            "So in the.",
            "Experiments you when you were doing the IHRA.",
            "That was the one which we are using something that.",
            "Which one is the last one?",
            "And the last one we did, Gibbs sampling.",
            "But in the experiment, so I showed you for the movie data was a mean field.",
            "So just the two different people did that and we haven't applied.",
            "Mean field here, but it should be all set clickable.",
            "We close in those first experiments you showed me and you expect me because in the other, yes, I mean the number of clusters are typically smaller and smaller number now.",
            "But interpretation of the larger clusters is compareable and there's a consumer speed up.",
            "The mean field approximation.",
            "And but I trust the results there as well.",
            "Going to large datasets, I mean how?",
            "Yeah, that's what we're working on right now.",
            "We want to we are involved in this big German project on.",
            "Yeah, search and semantic web things and then we want to explore this into explore mother scalability issues here.",
            "I think it scales pretty much proportional to the number of known relationships.",
            "So if there's an imbalance, big imbalance there's, there's a lot of relations of one kind, like small number of existing links and a large number of non existing links.",
            "Then we should be able to exploit that.",
            "The finish group approach scales quite well.",
            "They've applied it to 100 thousands of entities and relationships, so I'm a little cautious.",
            "Tiltil port number in our approach, but we hope hopefully by using some tricks we can also speed it up quite well, and there was also at NIPS Workshop contribution from the group at MIT who is working on scaling up.",
            "Model 2 large problems.",
            "The method is really trying to exploit the sparsity or you I mean.",
            "Yeah, I think sparsity is the key, is there?",
            "'cause if you have a strong default relationship, you can.",
            "Used to exploit that inference into learning.",
            "I'm doing that quite recall what the MIT's approach was.",
            "He did a lot of smart data management.",
            "Sort of things there.",
            "Project.",
            "Yeah.",
            "Scenario you're following there or trying to solve.",
            "Teachers is concerned general with six use cases different by mostly by industry.",
            "And so one of them, ones humans is leading is called medical, which is applying semantic technologies to imaging problems.",
            "So you want to have a sensually such facilities for physicians to find the right images for the right case to compare 20.",
            "Also to find the same region in the image and in a longitudinal study, you want to see if this.",
            "For example, if this lesion has grown or shrunk.",
            "In some cases you want to see comperable images from other patients and previous patients to see how the outcome was there and how to compare it.",
            "Then the other use cases like.",
            "Yeah service not service.",
            "The web services and services on the web.",
            "To organize business applications on the web in some inner portal version and they need semantic annotation and so they have to have to be able to search in these semantic annotations.",
            "But your task is likely to extend this technology also images.",
            "Yeah images, image annotations, but also the textual information which goes with the images 'cause we don't just have the images but also a patient records and so on.",
            "And the combination of both is relevant there, but also mean obtaining a better understanding of relational domain.",
            "We're cluster analysis is 1 big issue there as well.",
            "Do you have cookies for the Lego spacemen problem?",
            "I mean, it doesn't affect the predictions, of course, but but interpretation of the puzzles?",
            "Yeah.",
            "I mean sometimes, as I showed in the movie, they were quite interpretable, for example.",
            "Do you have problems in the sampling that?",
            "Items may switch to different.",
            "Yeah, I mean that's why I showed you these two numbers.",
            "Now the first one is the.",
            "The movies which are stable in this cluster and the ones.",
            "And this is the number of plus the number of movies in a cluster.",
            "So you see there's some fluctuation.",
            "Some movies move around, but the cluster stays stable.",
            "Into something that's really cool.",
            "Cluster parameters with places to lay into indexes.",
            "I think in it's possible.",
            "No, we didn't observe it because you run out of patience, I, but of course, if you sample infinitely long time then.",
            "Things should switch around because they're exchangeable or something, and.",
            "But I think it's probably I mean it shouldn't happen.",
            "Any clustering problem now that if you if you do Bayesian clustering and you wait infinitely long, then the identity of the clusters, probably at some point will change.",
            "Very unlikely, but.",
            "Typically you don't observe that, I guess.",
            "With normal clothes.",
            "Now you have some indication about when you when you're clustering this table.",
            "I mean you have some plus some functions, and if it's a flat thing then you don't.",
            "I mean, I think it's more theoretical thing that eventually if you do infinite number of clustering and inference, there's some probability that suddenly all is like, yeah, so unlikely that it probably never happens, but.",
            "You cannot exclude it, probably from a principle point of view, because the there's nothing special about one class and the other classes, they could just flip all the data and.",
            "Rename each other and then.",
            "This will also be a valid solution, but this is so unlikely to happen that you don't observe it.",
            "We don't.",
            "We didn't observe this as a practical problem.",
            "Because after I mean it really converged and the indicators we plotted were very stable.",
            "The graph of the movie movies.",
            "This.",
            "Are there?",
            "That's a pretty dramatic drop.",
            "Results to show 60 to 70.",
            "How are the numbers OK?",
            "Pre election very impressive so.",
            "No, they're not.",
            "You experimenting with different methods.",
            "The other slide before you had your method versus the other numbers with your.",
            "The movies.",
            "Oh the eBay or the email or the 70%, yeah.",
            "I mean.",
            "EBay.",
            "Yep.",
            "So 50% is the trivial true one.",
            "What happened to you?",
            "But it is essentially the movie model.",
            "Now the only thing is that we have two types or maybe even three types of relationships we are considering.",
            "So it's a very similar similar model.",
            "If you look up the model at the trust that you can pull it out.",
            "Build the two clusters independently.",
            "Stabilizing men.",
            "Think back in, you know building.",
            "I'm just wondering that's the comparison.",
            "Yeah, we we often did that.",
            "I mean, just look at the performance now.",
            "The when we report purely content based prediction.",
            "That's pretty much what we did.",
            "But.",
            "We had, I think, in all the data we have, the relationships are very important for to determine the clustering structure.",
            "But the experiment you were just mentioning, I also told the student to do that, but I haven't seen the results yet.",
            "But I believe that the clustering would be quite different from the ones using.",
            "Yeah.",
            "OK, but make a pun."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And interesting noises for letting me speak at this.",
                    "label": 0
                },
                {
                    "sent": "Great location this great occasion.",
                    "label": 0
                },
                {
                    "sent": "So the title is relational latent class models.",
                    "label": 1
                },
                {
                    "sent": "The collaborators Joshua and a lot of this is her dissertation work.",
                    "label": 0
                },
                {
                    "sent": "Then Steven lack of REM rettinger.",
                    "label": 1
                },
                {
                    "sent": "Matthias Nicolls Cayuse shipping you and Hanspeter Krieger.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the tool.",
                    "label": 0
                },
                {
                    "sent": "Basic messages I'm trying to convey the 1st morning that domains are quite important and interesting, which might not be big news to many of you.",
                    "label": 0
                },
                {
                    "sent": "Segmentation methods can be quite effective in modeling relational domains.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in some sense, relational problems are about networks.",
                    "label": 1
                },
                {
                    "sent": "So here we see the World Wide Web consisting of hyperlinked web pages and we know that the linkage information is quite relevant to determine the relevance of a web page.",
                    "label": 0
                },
                {
                    "sent": "Another example down here is a social network of people.",
                    "label": 0
                },
                {
                    "sent": "And as you know.",
                    "label": 0
                },
                {
                    "sent": "This is around 1900 and these people are very influential in the course of history of.",
                    "label": 0
                },
                {
                    "sent": "Europe in the 20th century, and if these people would not have been related, so we might have been quite different.",
                    "label": 0
                },
                {
                    "sent": "Social network analysis difficult.",
                    "label": 0
                },
                {
                    "sent": "Definitely one very interesting area which falls under.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we see gene interaction networks.",
                    "label": 0
                },
                {
                    "sent": "Which were interacting genes are quite relevant for biological function.",
                    "label": 0
                },
                {
                    "sent": "In some in some domains we only have one type of nodes.",
                    "label": 0
                },
                {
                    "sent": "One type of relationship.",
                    "label": 0
                },
                {
                    "sent": "But of course domains can be so much richer.",
                    "label": 0
                },
                {
                    "sent": "So here in the typical recommendation engine setting, we have two types of entities, users and items and web link matrix which shows us which user has bought which item or which user has rated which item.",
                    "label": 0
                },
                {
                    "sent": "So here we have two entities and one type of relationship.",
                    "label": 0
                },
                {
                    "sent": "Of course, we can also have attributes, but in most experiments the link matrix is more informative about future ratings and future interactions than the attributes.",
                    "label": 0
                },
                {
                    "sent": "On the right side we see a medical domain.",
                    "label": 0
                },
                {
                    "sent": "There we have patients, physicians, nurses, hospitals, medication, diagnosis procedures, interactions, medication and so on.",
                    "label": 0
                },
                {
                    "sent": "So many, many different types of entities.",
                    "label": 0
                },
                {
                    "sent": "Many different types of interactions, and if you want to predict the outcome, for example for patient, many of those things will play a role in this highly interconnected domain.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is to indicate that maybe even the brain uses some form of relational presentation anyway, racial representations are obviously very useful from a technical point of view, and maybe also from a biological point of view here on the left bottom we see the semantic web or the RDF part of the semantic Web.",
                    "label": 0
                },
                {
                    "sent": "So RDF stands for Resource Description framework and the base.",
                    "label": 0
                },
                {
                    "sent": "There is a very simple statement of subject predicate object.",
                    "label": 0
                },
                {
                    "sent": "Giving information about subjects about objects and their relationships.",
                    "label": 0
                },
                {
                    "sent": "And since these relations are binary, you can easily draw them as a graph.",
                    "label": 0
                },
                {
                    "sent": "And of course, here again, many types of entities, many types of relationships.",
                    "label": 0
                },
                {
                    "sent": "On the bottom here we see text and information extraction text where you extract entities from your text you want to extract relationships from your text, which gives you some basic understanding about the content of the text.",
                    "label": 0
                },
                {
                    "sent": "So these are some examples where relation information is quite important to solve the problem.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I tried to relate it to John Donne.",
                    "label": 0
                },
                {
                    "sent": "Who is famous for this statement that no man is an island entire of itself?",
                    "label": 1
                },
                {
                    "sent": "Every man is a piece of the continent apart of the main.",
                    "label": 1
                },
                {
                    "sent": "So this was also an epigraph of Hemingway's novel, for whom the Bell Tolls, which conveys quite nicely that in a relational world in some sense.",
                    "label": 0
                },
                {
                    "sent": "Everything depends on everything.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, some overview about work in this domain, of course incomplete it statistics.",
                    "label": 0
                },
                {
                    "sent": "There's the area of social network analysis.",
                    "label": 0
                },
                {
                    "sent": "The tradition here of course, that is that it's quite difficult to get relational data if you do a field study.",
                    "label": 0
                },
                {
                    "sent": "You have to meant maybe interview actors and actors and squared possible relationships.",
                    "label": 0
                },
                {
                    "sent": "So it's quite difficult to obtain this data.",
                    "label": 0
                },
                {
                    "sent": "And typically in the history I think these networks were relatively small and the analysis was mostly descriptive, deterministic algorithms.",
                    "label": 0
                },
                {
                    "sent": "So who is central?",
                    "label": 0
                },
                {
                    "sent": "Who is a central function?",
                    "label": 0
                },
                {
                    "sent": "Where some clusters in the in the network and so on.",
                    "label": 0
                },
                {
                    "sent": "But in recent years, there's increasing focus on statistical inference.",
                    "label": 1
                },
                {
                    "sent": "There was a network, a workshop at Nips last year on Statistical Network analysis with a lot of contributions from leading statisticians.",
                    "label": 1
                },
                {
                    "sent": "But of course they are more driven by the problem at hand.",
                    "label": 0
                },
                {
                    "sent": "Small datasets.",
                    "label": 1
                },
                {
                    "sent": "What can we do with them?",
                    "label": 0
                },
                {
                    "sent": "Often they approach problems with one type of actor and one type of relation.",
                    "label": 0
                },
                {
                    "sent": "Then of course there are specialized algorithms like page rank algorithm, collaborative filtering algorithms and so on, which.",
                    "label": 0
                },
                {
                    "sent": "People might not even think about that.",
                    "label": 0
                },
                {
                    "sent": "This is a relational problem.",
                    "label": 0
                },
                {
                    "sent": "Then in our area there is inductive logic programming that's based on 1st order.",
                    "label": 0
                },
                {
                    "sent": "Logic focuses on the generality of the approach.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you have the feeling that they are a little bit lost in generality.",
                    "label": 0
                },
                {
                    "sent": "They are learning typically rules for prediction of predicates.",
                    "label": 1
                },
                {
                    "sent": "Relationships and attributes mostly or they started off trying to find deterministic rules, but their recent extensions towards also probabilistic approaches to this.",
                    "label": 0
                },
                {
                    "sent": "And the last group I want to address is statistical relational learning.",
                    "label": 0
                },
                {
                    "sent": "Which starts off as a principled probabilistic approach from machine learning and AI to these type of problems, there's focus on uncertainty in relational domains, and the focus on analysis of dependencies, prediction of attributes and relations, and the work today is.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I think in the last class and statistical relational learning domain.",
                    "label": 0
                },
                {
                    "sent": "So if you take a closer look at this domain.",
                    "label": 0
                },
                {
                    "sent": "Other famous probabilistic relational models.",
                    "label": 0
                },
                {
                    "sent": "PRM models from Carla Freedman.",
                    "label": 0
                },
                {
                    "sent": "Get your FIFA and other people.",
                    "label": 0
                },
                {
                    "sent": "They combined a relational description with components from frame based systems and Bayesian networks.",
                    "label": 1
                },
                {
                    "sent": "Couple years later, that upper model was brought up, sensor directed basically probabilistic entity relationship model from Heckerman, Meek and color.",
                    "label": 0
                },
                {
                    "sent": "It's based on the entity relationship description known from database design in combination with Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "So the first 2 approaches can be shown to be equivalent of the PRM model is slightly extended.",
                    "label": 0
                },
                {
                    "sent": "And in this presentation I will focus on this DARPA representation.",
                    "label": 1
                },
                {
                    "sent": "A few others, to name our relational dependency networks of Neville and Jensen relational Markov networks of task and coworkers and Markov logic networks of Richardson and Domingos.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we do we do in this work, we apply a nonparametric hierarchical Bayesian modeling to relational learning and achieve nonparametric relational base in form of an infinite hidden relational model and also touch on related approaches.",
                    "label": 1
                },
                {
                    "sent": "So we take two very difficult things and get something out.",
                    "label": 0
                },
                {
                    "sent": "Which is, I think not more difficult.",
                    "label": 0
                },
                {
                    "sent": "Then either of them there's some basic advantages are straightforward to apply to relational domain without extensive structure, learning attributes relationships, but also the identity of entities can have predictive power, so the latter one is typically important for collaborative filtering type of applications where attributes are often very weak.",
                    "label": 0
                },
                {
                    "sent": "We have obtained a cluster analysis of relational domains.",
                    "label": 0
                },
                {
                    "sent": "We can analyze the clusters.",
                    "label": 0
                },
                {
                    "sent": "We have found multi relational clustering.",
                    "label": 0
                },
                {
                    "sent": "For example, identify the role to factors.",
                    "label": 0
                },
                {
                    "sent": "So in a lot of network analysis you see a network composed into highly interconnected subnetworks, but sometimes.",
                    "label": 0
                },
                {
                    "sent": "Actors which are similar are not in the same network, they just played the same role because they're both teachers, but in very different schools.",
                    "label": 0
                },
                {
                    "sent": "Or they're both managers or workers or students and so on.",
                    "label": 0
                },
                {
                    "sent": "So you don't, you can detect it from the dependency structure in the network, but it's not necessarily a cluster in the network.",
                    "label": 0
                },
                {
                    "sent": "So it's very interesting.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem I think.",
                    "label": 0
                },
                {
                    "sent": "So before relation learning, so this is nobody you should know, but you might have left around here 50,000 years ago.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we all love the matrix, of course, so the larger structure is ignored and flat representation is applied.",
                    "label": 1
                },
                {
                    "sent": "The standard assumption is that data points are sampled independently, so we have patients.",
                    "label": 1
                },
                {
                    "sent": "Here is an example of a patient in hospital with patient properties, and you want to predict outcome.",
                    "label": 0
                },
                {
                    "sent": "So RO is a data point or patient and a column is a SIM attribute.",
                    "label": 0
                },
                {
                    "sent": "And here's a simple data model describing this situation.",
                    "label": 0
                },
                {
                    "sent": "So the entity classes, patients and.",
                    "label": 0
                },
                {
                    "sent": "Patient has associated attributes the patient property and the outcome, and this error indicates that we want to predict the outcome from the patient property.",
                    "label": 0
                },
                {
                    "sent": "Also, there's the parameters involved and maybe even hyperparameters, so so this is describing the situation from Beijing Pilot point of view and then you can do learning or inference in this in this model.",
                    "label": 0
                },
                {
                    "sent": "And we know very well how to do that.",
                    "label": 0
                },
                {
                    "sent": "But we also.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Already you have touched into relational learning in some ways.",
                    "label": 0
                },
                {
                    "sent": "Here's one example time series modeling.",
                    "label": 0
                },
                {
                    "sent": "I mean, the time series is typically still displayed as a matrix, but temporal ordering of the Rose is important, so if you scramble the order of the data points, you typically get a different result.",
                    "label": 1
                },
                {
                    "sent": "Often we use a simple template for the model, where we assume there's some stationary to that.",
                    "label": 0
                },
                {
                    "sent": "If you predict something based on the recent past, this model of the stationary, it doesn't change too drastically, at least overtime.",
                    "label": 1
                },
                {
                    "sent": "And although the model might factorize the complete data is one time series in some sense one data point.",
                    "label": 0
                },
                {
                    "sent": "And also here everything depends on everything.",
                    "label": 0
                },
                {
                    "sent": "So in this hidden Markov model, even if we know all the data points and all the parameters, the hidden state of the hidden variables will depend on all of the measurements, not just on the ones in the same.",
                    "label": 0
                },
                {
                    "sent": "Row, so this is already giving a flavor of how relational modeling works.",
                    "label": 0
                },
                {
                    "sent": "Give this interconnectivity.",
                    "label": 0
                },
                {
                    "sent": "You have this template where this global dependencies.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another one, which is also important for this presentation, is hierarchical Bayesian modeling.",
                    "label": 0
                },
                {
                    "sent": "So here we see stochastic sampling in on the logical hierarchical Bayesian model.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the difference?",
                    "label": 0
                },
                {
                    "sent": "If you look at this patient model again, we have a patient with outcome in property and the dependency here, but now a patient is in a hospital, so it's associated with with another entity.",
                    "label": 0
                },
                {
                    "sent": "And of course the outcome might depend on hospital properties we don't know about.",
                    "label": 1
                },
                {
                    "sent": "For example training of staff.",
                    "label": 1
                },
                {
                    "sent": "Mixture of the patient where the hospital is located or what the patient mixes with the age of the patients are, and so on.",
                    "label": 0
                },
                {
                    "sent": "And if we don't have that information, we still might be interested to say, OK.",
                    "label": 0
                },
                {
                    "sent": "Hospitals are sort of similar, but they are also differences, so that one extreme, of course, is to say the hospital doesn't matter, so we pull all the data in one model, the other the other one.",
                    "label": 1
                },
                {
                    "sent": "The other extreme is shown here.",
                    "label": 0
                },
                {
                    "sent": "The hospital ID should be an input, but this would probably lead to bad generalization because essentially you can only use the.",
                    "label": 0
                },
                {
                    "sent": "Patient data for this particular hospital to train the model.",
                    "label": 0
                },
                {
                    "sent": "So we want to sort of inherit some knowledge across the hospitals and this is how, of course, how hierarchical Bayesian modeling works.",
                    "label": 0
                },
                {
                    "sent": "OK, so this one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in hierarchical Bayesian models, we still say the parameter for predicting outcome from patient property is still owned by the hospital, so each hospital can have its own dependency, but.",
                    "label": 0
                },
                {
                    "sent": "But the parameters are tide together by the same prior distribution.",
                    "label": 1
                },
                {
                    "sent": "And by sort of adapting the parameters in the prior distribution, we learn a common prior model which allows that.",
                    "label": 0
                },
                {
                    "sent": "For example, a new hospital model can inherit the prior distribution from the previous learned hospitals, and also the strength of the Pristiq modeling between the hospitals is shared.",
                    "label": 1
                },
                {
                    "sent": "So we have this sharing strings effect.",
                    "label": 0
                },
                {
                    "sent": "And we can go to the extreme and say the prior distribution comes from a nonparametric priors solution from Additionally process which is indicated at the bottom there indicating that the the prior distribution is a sample from additional process based distributions do not and concentration parameter or not.",
                    "label": 0
                },
                {
                    "sent": "And so why is this a good idea to go to a non parametric hierarchical represent?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is my slide to explain that.",
                    "label": 0
                },
                {
                    "sent": "So on the left top we see our indicates on prior distribution for parameter Theta.",
                    "label": 0
                },
                {
                    "sent": "So it's not informative, maybe isotropic Gaussian distribution?",
                    "label": 0
                },
                {
                    "sent": "Then when we Start learning, we get more and more data and the posterior distribution becomes more and more focused.",
                    "label": 1
                },
                {
                    "sent": "At the end we get a point distribution.",
                    "label": 0
                },
                {
                    "sent": "So we have many, many data points.",
                    "label": 0
                },
                {
                    "sent": "We can identify the two parameters in the model, and if you do that now for many many different hospitals, we get one parameter set for each of those hospitals and then end up with a distribution of of maximum likelihood but about parameters.",
                    "label": 0
                },
                {
                    "sent": "And an if this distribution shown here can be modeled by just tuning parameters in the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "For example, this is already also Gaussian with some new covariance matrix and a note and another mean.",
                    "label": 0
                },
                {
                    "sent": "Then this is perfect for hierarchical parameterized hierarchical basian modeling.",
                    "label": 0
                },
                {
                    "sent": "But in many cases this distribution might be odd, shared, maybe like a banana on the bottom right or multimodal and cannot be represented well.",
                    "label": 1
                },
                {
                    "sent": "We're just tuning parameters in the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "And to be really flexible, we should then go to a nonparametric prior distribution, which is a sample from Additionally process.",
                    "label": 1
                },
                {
                    "sent": "So this is the motivation to either Michael combinations.",
                    "label": 0
                },
                {
                    "sent": "You have a very high dimensional representation which is very flexible by itself, or you should go nonparametric.",
                    "label": 0
                },
                {
                    "sent": "Parametric has some problems maybe.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, there's another view on the same thing, so we said we want to have personalized parameters for patient outcome prediction.",
                    "label": 0
                },
                {
                    "sent": "We can also assume that a hospital becomes belongs to a cluster and all hospitals, all data or hospitals in the same cluster should share data.",
                    "label": 0
                },
                {
                    "sent": "And of course you make it sort of probabilistic.",
                    "label": 0
                },
                {
                    "sent": "So it's later in class model.",
                    "label": 0
                },
                {
                    "sent": "So in Adapa framework it looks like this so associated with each hospital, we now have a latent variable.",
                    "label": 0
                },
                {
                    "sent": "Steve and the state of Z determines which parameter to take to model this dependency here.",
                    "label": 0
                },
                {
                    "sent": "Now of course we let the number of states in this latent variable to go to Infinity and obtain additional process mixture model DPM and it turns out that this DPM is exactly the same as a non parameter hierarchical Bayesian approach with the judicial process prior.",
                    "label": 1
                },
                {
                    "sent": "So in some sense it's.",
                    "label": 0
                },
                {
                    "sent": "I mean it's the same thing but sometimes this is much easier to think about because now we can think about latent class models and don't have to think about this strange infinite.",
                    "label": 0
                },
                {
                    "sent": "This stuff anymore just in our in our mind we just let the have infinitely many states.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it's the same as a mixture model.",
                    "label": 0
                },
                {
                    "sent": "And if we do Gibbs sampling in this model.",
                    "label": 0
                },
                {
                    "sent": "Then of course only a limited number of clusters of these infinite states can be occupied.",
                    "label": 0
                },
                {
                    "sent": "I mean, up are limited by the number of data points, obviously, but in general or most cases, the actual number of occupied states is much less than number of data points, and we can interpret this number as the number of.",
                    "label": 0
                },
                {
                    "sent": "True, true clusters in the in the domain.",
                    "label": 0
                },
                {
                    "sent": "It's an interpretation.",
                    "label": 0
                },
                {
                    "sent": "I think it's not a true statistical inference, because actually the infinite number of components are always there.",
                    "label": 0
                },
                {
                    "sent": "But this is very important, in particular in relational modeling, because now we don't have to do all this exhaustive whatever.",
                    "label": 0
                },
                {
                    "sent": "Optimization of the structure of this thing because we have many different entities with different cluster variables and if we have to tune the optimal number of States and all of these, this would be quite difficult.",
                    "label": 0
                },
                {
                    "sent": "And of course the hospital can form of a large cluster if they're all the same, or if a hospital is very unique, alternative medicine or whatever.",
                    "label": 0
                },
                {
                    "sent": "Or magical treatments.",
                    "label": 0
                },
                {
                    "sent": "Then they can also form their own cluster.",
                    "label": 0
                },
                {
                    "sent": "So you have this personalization to the extreme.",
                    "label": 0
                },
                {
                    "sent": "If the model is sites that this is.",
                    "label": 0
                },
                {
                    "sent": "Useful.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now we go to relational learning.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we're in the middle of the statistical relational revolution.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, not surprisingly, relational data off is stored in a relational database, and both the relational model and the entity relationship model ER are useful description of the structure of a database.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is an entity relationship.",
                    "label": 0
                },
                {
                    "sent": "Model is typically used in the design phase of a database.",
                    "label": 1
                },
                {
                    "sent": "So the main components are entity classes.",
                    "label": 0
                },
                {
                    "sent": "In this case, students and courses.",
                    "label": 0
                },
                {
                    "sent": "A relationship class student takes a course and the attribute classes student as the attribute.",
                    "label": 1
                },
                {
                    "sent": "IQ course has the attribute difficulty and the relationship class take has the attribute.",
                    "label": 0
                },
                {
                    "sent": "Existor ranking or something like that.",
                    "label": 0
                },
                {
                    "sent": "Great, great for example, might be a good attribute.",
                    "label": 0
                },
                {
                    "sent": "And based on this you are model then the relational tables are constructed and relational database can be formed.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can look at something like a network here describing the ground facts.",
                    "label": 0
                },
                {
                    "sent": "So if our database consists of Mary, Jack and John, the database might contain information about that.",
                    "label": 0
                },
                {
                    "sent": "Mary's IQ is high, and so on.",
                    "label": 0
                },
                {
                    "sent": "We have caused this math and physics down here and they are have high difficulty, intermediate difficulty, and here's the information about.",
                    "label": 0
                },
                {
                    "sent": "Which person took which class?",
                    "label": 0
                },
                {
                    "sent": "So this can be thought of in social network analysis.",
                    "label": 1
                },
                {
                    "sent": "This would be called associate Gram.",
                    "label": 1
                },
                {
                    "sent": "In semantic web it would be called Resource description Framework graph, RDF graph.",
                    "label": 0
                },
                {
                    "sent": "Of course, this only works so easily if the relationships are binary, otherwise you could hypergraphs and so on.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately RDF is limited by their relationship, so there we have no problem.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so this is the ER is about database design.",
                    "label": 0
                },
                {
                    "sent": "The DARPA model privacy constraints are formulated at the level of the ER model and act as template for forming the ground deck.",
                    "label": 1
                },
                {
                    "sent": "So we have to introduce additional classes.",
                    "label": 0
                },
                {
                    "sent": "The art class which indicates which.",
                    "label": 0
                },
                {
                    "sent": "The dependencies between the attributes.",
                    "label": 0
                },
                {
                    "sent": "So here we indicate that the grade depends on the IQ of the student and the difficulty of the class.",
                    "label": 0
                },
                {
                    "sent": "Then we have the local distribution class, which indicates that we model this, maybe as a multinomial distribution, and we have the constraint class, for example, that the greatest influence by the student who took the class or not by the other students.",
                    "label": 0
                },
                {
                    "sent": "But there might be more complex constraints then these constraints.",
                    "label": 0
                },
                {
                    "sent": "Of course, very important if you logically oriented but not so focused in the probabilistic modeling.",
                    "label": 0
                },
                {
                    "sent": "And of course we have parameters describing the dependencies here.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we should be aware that based on this template and then the actual objects in the domain, we have to form the ground Bayesian network which shows you the dependencies between the actual attributes in the ground paging network.",
                    "label": 0
                },
                {
                    "sent": "So here the IQ of the first person depend determines the grade on the left side that upgrades and so on.",
                    "label": 0
                },
                {
                    "sent": "So this shows you the real dependencies and the real ground based network.",
                    "label": 0
                },
                {
                    "sent": "And we have to do inference and learning in this ground Bayesian network.",
                    "label": 1
                },
                {
                    "sent": "And you see that this is highly.",
                    "label": 0
                },
                {
                    "sent": "Easily, highly connected and if some variables are unknown, inference and learning becomes difficult, and but the implication is that parameters that are shared in this network.",
                    "label": 0
                },
                {
                    "sent": "So dependency of grade on IQ and difficulty is the same everywhere.",
                    "label": 0
                },
                {
                    "sent": "So all this madness.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Heritage sharing in the this is an example of a PRM model.",
                    "label": 0
                },
                {
                    "sent": "So many applications.",
                    "label": 0
                },
                {
                    "sent": "It is unreasonable to assume that the progressive dependency structure is known and for example, in the PZM consider work has been invested in modeling and learning the structural dependencies.",
                    "label": 1
                },
                {
                    "sent": "Unfortunately, the structure learning here is even more involved than in non relational Bayesian networks due to the explosion possible attribute candidates as parents.",
                    "label": 0
                },
                {
                    "sent": "Typically, evasion scores optimized using some reasonable sets.",
                    "label": 0
                },
                {
                    "sent": "Such strategy is an example of HIV and patient properties.",
                    "label": 0
                },
                {
                    "sent": "Strains of HIV context the person had, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we combine infinite hidden relational model and I mean relational learning was not provided correct equation learning which is the IRM model which in some way does not need this extensional extensive structural.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Running so probabilistic relational models provide template template into parameter sharing in the ground paging networks, and as we discussed in the non relational case, this might be too stiff for many applications, so you want to soften this by doing some type of hierarchical Bayesian modeling.",
                    "label": 1
                },
                {
                    "sent": "Because then promise can be personalized and sensible way.",
                    "label": 1
                },
                {
                    "sent": "Patient outcome could have some hospital specific effects, so the natural question is how it will generalize hierarchical Bayesian modeling to relational learning.",
                    "label": 1
                },
                {
                    "sent": "If the parameter dependencies, relational, parametric, hierarchical, basian version, relational version with the parameter representation, I found very difficult to think about becausw, we have to define a distribution whose hyperparameters depend on two or more entities.",
                    "label": 0
                },
                {
                    "sent": "But the nonparametric hierarchical Bayesian approach is much easier to generalize.",
                    "label": 0
                },
                {
                    "sent": "So despite the fact that it's essentially.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Difficult.",
                    "label": 0
                },
                {
                    "sent": "It becomes more simple and here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "Again, using this simple example of user and movie, having user attributes for the user movie attributes for the movie and the rating.",
                    "label": 1
                },
                {
                    "sent": "If a user watches a movie and writes a movie.",
                    "label": 0
                },
                {
                    "sent": "So if the user attributes and the movie attributes be informative and very strong and very good, then this might be a reasonable model.",
                    "label": 0
                },
                {
                    "sent": "Now we can predict the rating just if you know the person very well.",
                    "label": 0
                },
                {
                    "sent": "And if you know the movie very well.",
                    "label": 0
                },
                {
                    "sent": "But in most cases we have to assume that we don't have so much info.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patient about the user, so reasonable thing is to assume let's use the ZU variable to represent all the stuff we should know about the user.",
                    "label": 0
                },
                {
                    "sent": "But we don't know about the user, so it's a latent variable and the actual user attributes are now children of this children of this variable.",
                    "label": 0
                },
                {
                    "sent": "And now we have the effect that yeah, OK, there's some hidden information if you would know it, we would be able to do a perfect prediction for the rating.",
                    "label": 0
                },
                {
                    "sent": "And we can do the same thing for for the movie.",
                    "label": 0
                },
                {
                    "sent": "Let's say we don't have enough movie information, so we should introduce another latent variable for the movie and obtain this structure.",
                    "label": 0
                },
                {
                    "sent": "And of course, now since we like this infinite stuff, we let the number of States and these latent variables go to Infinity Infinity.",
                    "label": 0
                },
                {
                    "sent": "And this is exactly the way this is more.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we end up with.",
                    "label": 0
                },
                {
                    "sent": "This is a hidden, infinite hidden relational model, so we have simply introduce latent variables for the entities and couple them whether we are the relations and have attributes as children.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the same thing with all the parameters involved based distributions.",
                    "label": 0
                },
                {
                    "sent": "Concentration parameters and so on, but these are just technical details.",
                    "label": 0
                },
                {
                    "sent": "Just think of it as a latent variables with many many states.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the recipe is simple to each entity in infinite latent variable specific to each entity classes assigned.",
                    "label": 1
                },
                {
                    "sent": "This latent variable is the parent of the remaining attributes of the entity is sort of also an attribute, and it's apparent of the relationships these entities are involved in.",
                    "label": 1
                },
                {
                    "sent": "One question might be isn't this too limited?",
                    "label": 1
                },
                {
                    "sent": "Because now we have very limited.",
                    "label": 0
                },
                {
                    "sent": "I mean very local dependencies following the relationship structure.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily, I mean, remember the PRM we had to do this very involved structure learning to really know which variable was influenced by which, and this is a very simple recipe.",
                    "label": 1
                },
                {
                    "sent": "So argument is not necessarily very limited, because information can propagate through the network of latent variables.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is this would be a sort of an image like ground network without the latent variables.",
                    "label": 0
                },
                {
                    "sent": "So we would have the attributes A and the relations are and in this page and network information is very local and blocked right?",
                    "label": 0
                },
                {
                    "sent": "So because a is not a Collider so it blocks information if A is known and R is is a Collider and if the relationship is known it's open.",
                    "label": 0
                },
                {
                    "sent": "So but a is blocking everything else.",
                    "label": 0
                },
                {
                    "sent": "Talking everything because it's known.",
                    "label": 0
                },
                {
                    "sent": "So this is the case.",
                    "label": 0
                },
                {
                    "sent": "We do movie recommendation with very good attributes.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now introduce the latent variable C and we.",
                    "label": 0
                },
                {
                    "sent": "Now we have a network where information can globally flow because the latent variables are unknown and open up, the connections are are is a Collider, so it's open.",
                    "label": 1
                },
                {
                    "sent": "So information can propagate in this information quite freely, and this looks like an image ring structure.",
                    "label": 0
                },
                {
                    "sent": "I made it also to look at like in this way.",
                    "label": 1
                },
                {
                    "sent": "So in an image Reconstruction Z would be the unknown true pixel value.",
                    "label": 1
                },
                {
                    "sent": "They would be the noisy measurement of the pixel and are would indicate if two pixels are neighbors or not.",
                    "label": 0
                },
                {
                    "sent": "So you can relate it to this type of problems.",
                    "label": 0
                },
                {
                    "sent": "And we see also that everything depends on everything because information flows through the network of latency.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that yes, I hear some groups which have worked on this type of networks.",
                    "label": 0
                },
                {
                    "sent": "The first one is the group at MIT.",
                    "label": 0
                },
                {
                    "sent": "Ken Griffey Tenenbaum and coworkers.",
                    "label": 0
                },
                {
                    "sent": "So they worked more on our relational description, but the models are mathematically quite similar.",
                    "label": 0
                },
                {
                    "sent": "We have a slightly different treatment of attribute values, but the difference is probably not major.",
                    "label": 0
                },
                {
                    "sent": "We have done two models.",
                    "label": 0
                },
                {
                    "sent": "One is that usually enhanced relation learning model.",
                    "label": 0
                },
                {
                    "sent": "The down model and the second one is the model I present today.",
                    "label": 0
                },
                {
                    "sent": "The infinite hidden relational model.",
                    "label": 1
                },
                {
                    "sent": "Then previously to this they have been finite versions of this people with side know Vicki and Snyder's for this, and there has been a recent finite version with mean field approximation at the workshop at NIPS.",
                    "label": 0
                },
                {
                    "sent": "Another interesting work is the MSP work mix memberships to ask block model of reality Bly find back in thinking it's a finite model and then there's another infinite model by a Finnish group sync on an alkene kusky inferring vertex properties from topology in large networks.",
                    "label": 1
                },
                {
                    "sent": "I'm so I want to briefly.",
                    "label": 0
                },
                {
                    "sent": "Tell you a little bit about these things.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's getting a little too complicated so you can sleep 2 minutes or so, so this is some way of looking at the, uh.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So model in a, let's say homogeneous network, only one type of nodes, one type of relationship.",
                    "label": 0
                },
                {
                    "sent": "So each node.",
                    "label": 0
                },
                {
                    "sent": "Assorted associated with each node is a state of a latent variable.",
                    "label": 0
                },
                {
                    "sent": "So each node belongs to one cluster in the ground.",
                    "label": 1
                },
                {
                    "sent": "Truth exactly.",
                    "label": 1
                },
                {
                    "sent": "Based on this assignment to a cluster of the tool.",
                    "label": 0
                },
                {
                    "sent": "In both nodes, the corresponding parameter is picked, for example, for Vandalia distribution, and then this determines the probability that this relationship exists between North high and low J.",
                    "label": 0
                },
                {
                    "sent": "But the ground truth is that we know this.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assignment in the MSB model an additional layer is introduced so each node owns parameter vector of multinomial parameters and based on this if we want to determine if the node of the link RIJ exists, we sample once from this distribution, the latent state of this variable based on this parameter within these parameters do that for both nodes and based based on this on the notes, we end up on the states we end up with.",
                    "label": 0
                },
                {
                    "sent": "We pick the corresponding parameter.",
                    "label": 0
                },
                {
                    "sent": "To determine the probability so the new thing here is that for each relation we want to predict for each link we want to predict, we do a new sampling of the latent variable.",
                    "label": 1
                },
                {
                    "sent": "This means that each node can be in several modes on several different.",
                    "label": 0
                },
                {
                    "sent": "Topics or something?",
                    "label": 0
                },
                {
                    "sent": "It's like a topic model.",
                    "label": 1
                },
                {
                    "sent": "Now we say we don't limit a note in the ground truth to be part of 1 cluster, it can become part of the member of different clusters if it's useful.",
                    "label": 0
                },
                {
                    "sent": "In some applications, this might give you added flexibility, which is necessary, but I think it's quite complex if you do that, it looks like the LDA model in some sense.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is, uh, our previous model, the Dell model, where we ascentia Lee assign some of the source of the link to one cluster, so only one note is involved.",
                    "label": 1
                },
                {
                    "sent": "Then we pick a parameter vector based on this assignment with the cluster and then repeatedly generate links with this link as an origin and the state of this selection variable determines to which.",
                    "label": 1
                },
                {
                    "sent": "Note this is pointing to.",
                    "label": 0
                },
                {
                    "sent": "So this we have introduced previously.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there's some generalization, but this can also do this with the mixed membership, but.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe not too interesting.",
                    "label": 0
                },
                {
                    "sent": "Then there's this finish group which assigns a cluster variable to each.",
                    "label": 0
                },
                {
                    "sent": "So it's an infinite model.",
                    "label": 0
                },
                {
                    "sent": "They assign a cluster model variable to each link, not to each node, but which link based on this cluster assignment, the corresponding multinomial parameter vector is picked and then two.",
                    "label": 1
                },
                {
                    "sent": "Two latent variables are sampled based on this parameter vector, and if Emma samples you never sampled here, then we make a link between M&N.",
                    "label": 0
                },
                {
                    "sent": "So this is quite interesting and it's I think the direct innovation of appeal is a model.",
                    "label": 0
                },
                {
                    "sent": "Appeal as a model differ members from Hoffman and coworkers dependencies between documents and words, and if you replace both by nodes.",
                    "label": 0
                },
                {
                    "sent": "In the network you pretty much end up with this model.",
                    "label": 0
                },
                {
                    "sent": "But we see quite a lot of advantages for the IRM model, in particular that we have no problem modeling multiple relationships, complex types of entities and also attributes are easily handed in.",
                    "label": 0
                },
                {
                    "sent": "I think most of the other problems have more difficulties there.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's talk about the hard part learning influence experiments.",
                    "label": 0
                },
                {
                    "sent": "So we derived and compared various inference and learning approaches first.",
                    "label": 1
                },
                {
                    "sent": "Gibbs sampler derived from the Chinese restaurant process representation.",
                    "label": 0
                },
                {
                    "sent": "Then the Gibbs sampler derived from a finite approximation to the stick breaking representation to seek representation that usually multi normal allocation of the truncated usually process to mean field approximations based on these and memory based empirical approximation.",
                    "label": 1
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first experiment is on movie prediction rating prediction on using movie length daytime.",
                    "label": 0
                },
                {
                    "sent": "So we have user with user properties movie with movie properties and we want to would like to predict the rating of a user for movie.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here the attributes the users attributes are age, class, gender and occupation and the movie Class I movie attributes at genre and year.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a showing the results.",
                    "label": 0
                },
                {
                    "sent": "We have been.",
                    "label": 0
                },
                {
                    "sent": "We have obtained.",
                    "label": 0
                },
                {
                    "sent": "So the 1st three rows are Gibbs samplers.",
                    "label": 0
                },
                {
                    "sent": "Chinese restaurant process truncated usually and usually multinomial.",
                    "label": 0
                },
                {
                    "sent": "Then we have the two mean field approximation and the empirical approximation and is the prediction accuracy given 5 ratings for the test user 10 given 15 given 20 ratings for the test user we see here that Gibbs samplers are slightly better than the mean field approximations and the mean field approximations are slightly better than the empirical approximation.",
                    "label": 0
                },
                {
                    "sent": "In terms of accuracy, but in terms of speed, the Gibbs samplers are quite slow compared to the mean field approximation, which is an order of 10 faster than the Gibbs sampler and empirical is even faster than that.",
                    "label": 0
                },
                {
                    "sent": "Interesting also to look at the number of components we have obtained, so the Gibbs samplers have obtained converge to more components than the mean field approximations.",
                    "label": 0
                },
                {
                    "sent": "But if we look at the number of really occupied classes then they are quite similar.",
                    "label": 0
                },
                {
                    "sent": "Oh, this is this is the number of computers components for the user in here for the movie because they have two 2 cluster variables.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's an example of clusters we have found.",
                    "label": 0
                },
                {
                    "sent": "So the first number here.",
                    "label": 0
                },
                {
                    "sent": "So this is using the Gibbs sampler, so the first one is the number of stable movies in this cluster, and the second number is the number of typical movies in the cluster.",
                    "label": 0
                },
                {
                    "sent": "So the first one we decide at that time, so I think it was the data where from 1998 or something very new and popular movies then old non US and drama and comedy and children's.",
                    "label": 0
                },
                {
                    "sent": "Oriented movies or comedies.",
                    "label": 0
                },
                {
                    "sent": "New action movies.",
                    "label": 0
                },
                {
                    "sent": "Old action movies or drama and Harrison Ford.",
                    "label": 0
                },
                {
                    "sent": "He needs his own cluster.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so there's a distribution of cluster occupancy and this is what we meant.",
                    "label": 0
                },
                {
                    "sent": "Now if you go.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To more than 10, so the brownish one is a mean field solution and.",
                    "label": 0
                },
                {
                    "sent": "Blue and green are Gibbs samplers, so the occupation drops down drastically if you go to larger cluster numbers and the Gibbs samplers have longer tails.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The mean field solutions.",
                    "label": 0
                },
                {
                    "sent": "You can then use a different cluster properties so the age distribution is different in the different clusters for users and you have different gender distributions in the clusters.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can look at the movies.",
                    "label": 0
                },
                {
                    "sent": "You can look at the classification of the movies, how they are distributed across the clusters, and you can use look in the bottom here at the distribution of idea of occupations, different clusters and you can also look at the.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The crossover the matrix between the movie clusters and the user clusters where we found interesting when we left the attributes away.",
                    "label": 1
                },
                {
                    "sent": "The cross matrix for example didn't change too drastically because one reviewer once complained that.",
                    "label": 0
                },
                {
                    "sent": "We just recovered the.",
                    "label": 0
                },
                {
                    "sent": "The movie classification, which is not quite sure it was even stable when we took that information away.",
                    "label": 0
                },
                {
                    "sent": "But the relation again, relationship information is quite interesting for this application.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the second one is concerned with gene interaction and gene function.",
                    "label": 1
                },
                {
                    "sent": "The task is a cluster analysis and the prediction of gene function.",
                    "label": 1
                },
                {
                    "sent": "Given other information.",
                    "label": 1
                },
                {
                    "sent": "We used to see why GD data comprehensive used genome database from Munich 1000 genes and attributes.",
                    "label": 0
                },
                {
                    "sent": "Chromosone motive essential class phenotype, complexin function and interaction data from the from dip.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the top left you see the IRM model for this application.",
                    "label": 0
                },
                {
                    "sent": "So we have one entity class gene which might interact with another gene.",
                    "label": 0
                },
                {
                    "sent": "So jeans might interact with each other.",
                    "label": 0
                },
                {
                    "sent": "Then we have here the latent variable Z and then we have all the other attributes.",
                    "label": 0
                },
                {
                    "sent": "So we have gene functions, which is cell growth, cell organization, transport and so on.",
                    "label": 1
                },
                {
                    "sent": "Genes might interact with one another for gene, one or more phenotypes are observed in the Organism.",
                    "label": 1
                },
                {
                    "sent": "Gene kind of complex with others to form larger larger proteins.",
                    "label": 1
                },
                {
                    "sent": "Protein coded belongs to one or more structure categories.",
                    "label": 1
                },
                {
                    "sent": "A gene might contain one or more character characteristic motives and gene attributes are essential, and the chromosome and so on.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this again, the template on the left and the right you see an indication of how the ground network will look like.",
                    "label": 0
                },
                {
                    "sent": "So we have the latent variables here which interact.",
                    "label": 0
                },
                {
                    "sent": "So this indicates an interaction between the corresponding genes.",
                    "label": 0
                },
                {
                    "sent": "And the latent variable, again, is the parent node of all the other attributes of the gene.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a result we got out from the clustering analysis.",
                    "label": 0
                },
                {
                    "sent": "So the colors correspond to clusters.",
                    "label": 0
                },
                {
                    "sent": "The nodes are the jeans and the links are the interactions, so the clustering pretty much followed the linkage structure in this problem.",
                    "label": 0
                },
                {
                    "sent": "So we show the largest cluster, see only the interactions happening between the genes in those clusters.",
                    "label": 1
                },
                {
                    "sent": "Otherwise that would be too cluttered and you see that again the interaction information is exploited quite heavily.",
                    "label": 0
                },
                {
                    "sent": "So in this case we see that not so much.",
                    "label": 0
                },
                {
                    "sent": "Maybe the role of a gene.",
                    "label": 0
                },
                {
                    "sent": "IS has been extracted, but the sort of into highly interconnected activity in a cluster in a local cluster domain.",
                    "label": 1
                },
                {
                    "sent": "So we see clusters in the network itself here.",
                    "label": 0
                },
                {
                    "sent": "And we can even label them with informative labels.",
                    "label": 0
                },
                {
                    "sent": "Some of them mean something to a biologist.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This indicates how much the performance drops when we remove an information, and so it means that if we remove complex, the.",
                    "label": 0
                },
                {
                    "sent": "Prediction accuracy drops most, so this is the most important information and interaction is the second highest gives you the second eyes information.",
                    "label": 0
                },
                {
                    "sent": "So interaction complex are the most critical ones.",
                    "label": 0
                },
                {
                    "sent": "We also try.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To include ontological knowledge.",
                    "label": 0
                },
                {
                    "sent": "Shown over here, and it's very important for semantic web applications and other things.",
                    "label": 0
                },
                {
                    "sent": "So we had an ontology for complex.",
                    "label": 0
                },
                {
                    "sent": "And wanted to use this to improve the prediction for function.",
                    "label": 0
                },
                {
                    "sent": "So the way we did that we use the variables in the taxonomy ontology as additional variables for the gene.",
                    "label": 0
                },
                {
                    "sent": "But we also took into account the constraints in the taxonomy.",
                    "label": 0
                },
                {
                    "sent": "So if you assign to a particular node then you also assign to all parent nodes and so on.",
                    "label": 0
                },
                {
                    "sent": "So this was also employed.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Painted and if we do that, we can improve the prediction accuracy for function if we use the ontology for complex.",
                    "label": 0
                },
                {
                    "sent": "So here we see our C curves and the other one is the one which we exploited the ontology, the lower one is the one we didn't do that.",
                    "label": 0
                },
                {
                    "sent": "Also there the clustering changed and become became more stable and we're still in the process of analyzing this.",
                    "label": 0
                },
                {
                    "sent": "So we can.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Extend the model in many different ways.",
                    "label": 0
                },
                {
                    "sent": "Because it's a probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "We started late.",
                    "label": 0
                },
                {
                    "sent": "Can I go a little bit on here?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is an application to clinical decision support patient.",
                    "label": 1
                },
                {
                    "sent": "In a clinic with diagnosis and procedures, relationship classes make a diagnosis.",
                    "label": 1
                },
                {
                    "sent": "Take a procedure.",
                    "label": 0
                },
                {
                    "sent": "The patient typically has multiple diagnosis and procedures.",
                    "label": 0
                },
                {
                    "sent": "Patient attributes are age, gender, primary, complaint, and diagnostic attributes are classes and ICD 9 and procedures and CPT 4 code.",
                    "label": 1
                },
                {
                    "sent": "So this is how the.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "ISI model looks for for the decision support problem, showing the entities, patient procedure and diagnosis.",
                    "label": 0
                },
                {
                    "sent": "So we didn't take many other things into account.",
                    "label": 0
                },
                {
                    "sent": "Taken makossa relationship classes and.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I said here we are.",
                    "label": 0
                },
                {
                    "sent": "10 best results using the IRM.",
                    "label": 0
                },
                {
                    "sent": "So here we want to predict the procedure.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of a recommendation system for physician.",
                    "label": 0
                },
                {
                    "sent": "So what should we do next given the first procedure, and given the prime complaint, another patient information and again we see RC curves and the top one is the full HRM model, then we took the attributes away, which only used relationships which dropped made the performance drop to here.",
                    "label": 1
                },
                {
                    "sent": "We made it a 1 sided problem, which is probably a bad idea because this gave you the worst thing here.",
                    "label": 0
                },
                {
                    "sent": "Did a pure content based approach, removing the relational information, which is this one here.",
                    "label": 1
                },
                {
                    "sent": "This one here.",
                    "label": 0
                },
                {
                    "sent": "So it shows you when we take information away either attribute information in relation information performance becomes becomes worse.",
                    "label": 0
                },
                {
                    "sent": "So doing relational modeling in these domains is quite important.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the final experiment is about trust learning.",
                    "label": 0
                },
                {
                    "sent": "Who do you trust and when do you trust him has been accepted for the Amos conference this year?",
                    "label": 0
                },
                {
                    "sent": "So the need for revelation of trustworthiness of agents in future encounters is getting increasingly important in distributed systems.",
                    "label": 1
                },
                {
                    "sent": "Since contemporary contemporary developments, such as Semantic web service oriented architectures, pervasive computing, ubiquitous computing, and grid computing are applied mainly to open and dynamic systems within with interacting autonomous agents and most existing statistical customers do not perform well when there is no long history of interactions in a predefined and consistent environment.",
                    "label": 1
                },
                {
                    "sent": "So we want to implement and learn context sensitive trust model from past experience using a probabilistic relational models.",
                    "label": 0
                },
                {
                    "sent": "So seller might be trustworthy if offering a specific product, but not offering another product.",
                    "label": 0
                },
                {
                    "sent": "And we used eBay data 'cause this is real world data and it's a serious fraud is a serious issue here.",
                    "label": 0
                },
                {
                    "sent": "And eBay users leave feedback about their experiences.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the IHRA model in this application so we have an agent.",
                    "label": 0
                },
                {
                    "sent": "He's the person he wants to buy something.",
                    "label": 0
                },
                {
                    "sent": "I don't know, he said one who sells something, sorry, sell something and they actually could see our percentage of positive ratings has obtained the eBay feedback score more than X number of positive ratings and membership.",
                    "label": 1
                },
                {
                    "sent": "How long this person has been a member then?",
                    "label": 0
                },
                {
                    "sent": "The item information is the top eBay Category 47 of them and the condition new or used.",
                    "label": 0
                },
                {
                    "sent": "Then we have two relationships here.",
                    "label": 0
                },
                {
                    "sent": "One is indicating final price.",
                    "label": 0
                },
                {
                    "sent": "Of the item and number of bits which have been done, and then the other one is the feedback and we're interested in predicting feedback for new interactions.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we had 47 sellers, 631 different items and 1800 rated sales.",
                    "label": 1
                },
                {
                    "sent": "Of a much larger number of possible sales.",
                    "label": 1
                },
                {
                    "sent": "Here the top one shows you the 47 agents and therefore agent clusters and the bottom matrix shows you how the agent clusters and the item clusters are assigned to each other we.",
                    "label": 0
                },
                {
                    "sent": "Did not quite so we did not do random sampling be cause I guess most writings are positive, so we try to balance that we get enough negative.",
                    "label": 0
                },
                {
                    "sent": "And problematic cases in there that the probabilistic model had an easier time to do that.",
                    "label": 0
                },
                {
                    "sent": "So if you look at some comparison here, so the ratio means I think we just take the majority or something or something trivial decision.",
                    "label": 0
                },
                {
                    "sent": "And since it's 50% that just reflects that the data are balanced, we have as many positives negatives then SVM decision tree are purely content based approaches.",
                    "label": 0
                },
                {
                    "sent": "Then there was some way of introducing some relation information and.",
                    "label": 0
                },
                {
                    "sent": "Then we did the IRM and last one gave you the best accuracy.",
                    "label": 0
                },
                {
                    "sent": "So the relation information and taking care of this in a principled ways quite relevant in this domain, and I think it's quite new to this problem of trust learning and people got quite excited about this.",
                    "label": 0
                },
                {
                    "sent": "I will not.",
                    "label": 0
                },
                {
                    "sent": "Bet on that we can keep this 10% advantage on the IRM.",
                    "label": 0
                },
                {
                    "sent": "I think if we do a better job in the other models using the relation information, this score would probably also go up there and we are in the process of doing that.",
                    "label": 0
                },
                {
                    "sent": "But it's definitely an indication that relational approach is quite useful here.",
                    "label": 0
                },
                {
                    "sent": "And not just content based approach.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we conclude we have introduced the IRM to realize nonparametric relational base and suggest that it might be an interesting model for number of relational problems.",
                    "label": 1
                },
                {
                    "sent": "For relational domain, its advantages are that we don't have extensive structure learning, so the recipe is quite straightforward to apply.",
                    "label": 0
                },
                {
                    "sent": "We have expressive coupling, I mean extensibility via coupling between heterogeneous relationships and heterogeneous entities.",
                    "label": 1
                },
                {
                    "sent": "The model can decide itself about the number of optimal optimal number of states of the latent variables.",
                    "label": 0
                },
                {
                    "sent": "And of course the clustering structure can be analyzed and can lead to a better understanding of the relational domain.",
                    "label": 0
                },
                {
                    "sent": "Other many interesting extensions we already talked about ontologies.",
                    "label": 0
                },
                {
                    "sent": "We also can cluster relations by sort of making relation just another attribute of a more general class of relations.",
                    "label": 0
                },
                {
                    "sent": "Compaine coworkers have done that, so there are interesting extensions to this.",
                    "label": 0
                },
                {
                    "sent": "I think the advantages are the simplicity and easily applicability Ann.",
                    "label": 0
                },
                {
                    "sent": "And the great variety of models you can work with do using these models.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the.",
                    "label": 0
                },
                {
                    "sent": "Experiments you when you were doing the IHRA.",
                    "label": 0
                },
                {
                    "sent": "That was the one which we are using something that.",
                    "label": 0
                },
                {
                    "sent": "Which one is the last one?",
                    "label": 0
                },
                {
                    "sent": "And the last one we did, Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "But in the experiment, so I showed you for the movie data was a mean field.",
                    "label": 0
                },
                {
                    "sent": "So just the two different people did that and we haven't applied.",
                    "label": 0
                },
                {
                    "sent": "Mean field here, but it should be all set clickable.",
                    "label": 0
                },
                {
                    "sent": "We close in those first experiments you showed me and you expect me because in the other, yes, I mean the number of clusters are typically smaller and smaller number now.",
                    "label": 0
                },
                {
                    "sent": "But interpretation of the larger clusters is compareable and there's a consumer speed up.",
                    "label": 0
                },
                {
                    "sent": "The mean field approximation.",
                    "label": 0
                },
                {
                    "sent": "And but I trust the results there as well.",
                    "label": 0
                },
                {
                    "sent": "Going to large datasets, I mean how?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's what we're working on right now.",
                    "label": 0
                },
                {
                    "sent": "We want to we are involved in this big German project on.",
                    "label": 0
                },
                {
                    "sent": "Yeah, search and semantic web things and then we want to explore this into explore mother scalability issues here.",
                    "label": 0
                },
                {
                    "sent": "I think it scales pretty much proportional to the number of known relationships.",
                    "label": 0
                },
                {
                    "sent": "So if there's an imbalance, big imbalance there's, there's a lot of relations of one kind, like small number of existing links and a large number of non existing links.",
                    "label": 0
                },
                {
                    "sent": "Then we should be able to exploit that.",
                    "label": 0
                },
                {
                    "sent": "The finish group approach scales quite well.",
                    "label": 0
                },
                {
                    "sent": "They've applied it to 100 thousands of entities and relationships, so I'm a little cautious.",
                    "label": 0
                },
                {
                    "sent": "Tiltil port number in our approach, but we hope hopefully by using some tricks we can also speed it up quite well, and there was also at NIPS Workshop contribution from the group at MIT who is working on scaling up.",
                    "label": 0
                },
                {
                    "sent": "Model 2 large problems.",
                    "label": 0
                },
                {
                    "sent": "The method is really trying to exploit the sparsity or you I mean.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think sparsity is the key, is there?",
                    "label": 0
                },
                {
                    "sent": "'cause if you have a strong default relationship, you can.",
                    "label": 0
                },
                {
                    "sent": "Used to exploit that inference into learning.",
                    "label": 0
                },
                {
                    "sent": "I'm doing that quite recall what the MIT's approach was.",
                    "label": 0
                },
                {
                    "sent": "He did a lot of smart data management.",
                    "label": 0
                },
                {
                    "sent": "Sort of things there.",
                    "label": 0
                },
                {
                    "sent": "Project.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Scenario you're following there or trying to solve.",
                    "label": 0
                },
                {
                    "sent": "Teachers is concerned general with six use cases different by mostly by industry.",
                    "label": 0
                },
                {
                    "sent": "And so one of them, ones humans is leading is called medical, which is applying semantic technologies to imaging problems.",
                    "label": 0
                },
                {
                    "sent": "So you want to have a sensually such facilities for physicians to find the right images for the right case to compare 20.",
                    "label": 0
                },
                {
                    "sent": "Also to find the same region in the image and in a longitudinal study, you want to see if this.",
                    "label": 0
                },
                {
                    "sent": "For example, if this lesion has grown or shrunk.",
                    "label": 0
                },
                {
                    "sent": "In some cases you want to see comperable images from other patients and previous patients to see how the outcome was there and how to compare it.",
                    "label": 0
                },
                {
                    "sent": "Then the other use cases like.",
                    "label": 0
                },
                {
                    "sent": "Yeah service not service.",
                    "label": 0
                },
                {
                    "sent": "The web services and services on the web.",
                    "label": 0
                },
                {
                    "sent": "To organize business applications on the web in some inner portal version and they need semantic annotation and so they have to have to be able to search in these semantic annotations.",
                    "label": 0
                },
                {
                    "sent": "But your task is likely to extend this technology also images.",
                    "label": 0
                },
                {
                    "sent": "Yeah images, image annotations, but also the textual information which goes with the images 'cause we don't just have the images but also a patient records and so on.",
                    "label": 0
                },
                {
                    "sent": "And the combination of both is relevant there, but also mean obtaining a better understanding of relational domain.",
                    "label": 1
                },
                {
                    "sent": "We're cluster analysis is 1 big issue there as well.",
                    "label": 0
                },
                {
                    "sent": "Do you have cookies for the Lego spacemen problem?",
                    "label": 1
                },
                {
                    "sent": "I mean, it doesn't affect the predictions, of course, but but interpretation of the puzzles?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean sometimes, as I showed in the movie, they were quite interpretable, for example.",
                    "label": 0
                },
                {
                    "sent": "Do you have problems in the sampling that?",
                    "label": 0
                },
                {
                    "sent": "Items may switch to different.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean that's why I showed you these two numbers.",
                    "label": 0
                },
                {
                    "sent": "Now the first one is the.",
                    "label": 0
                },
                {
                    "sent": "The movies which are stable in this cluster and the ones.",
                    "label": 0
                },
                {
                    "sent": "And this is the number of plus the number of movies in a cluster.",
                    "label": 1
                },
                {
                    "sent": "So you see there's some fluctuation.",
                    "label": 0
                },
                {
                    "sent": "Some movies move around, but the cluster stays stable.",
                    "label": 0
                },
                {
                    "sent": "Into something that's really cool.",
                    "label": 0
                },
                {
                    "sent": "Cluster parameters with places to lay into indexes.",
                    "label": 0
                },
                {
                    "sent": "I think in it's possible.",
                    "label": 0
                },
                {
                    "sent": "No, we didn't observe it because you run out of patience, I, but of course, if you sample infinitely long time then.",
                    "label": 0
                },
                {
                    "sent": "Things should switch around because they're exchangeable or something, and.",
                    "label": 0
                },
                {
                    "sent": "But I think it's probably I mean it shouldn't happen.",
                    "label": 0
                },
                {
                    "sent": "Any clustering problem now that if you if you do Bayesian clustering and you wait infinitely long, then the identity of the clusters, probably at some point will change.",
                    "label": 0
                },
                {
                    "sent": "Very unlikely, but.",
                    "label": 0
                },
                {
                    "sent": "Typically you don't observe that, I guess.",
                    "label": 0
                },
                {
                    "sent": "With normal clothes.",
                    "label": 0
                },
                {
                    "sent": "Now you have some indication about when you when you're clustering this table.",
                    "label": 0
                },
                {
                    "sent": "I mean you have some plus some functions, and if it's a flat thing then you don't.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think it's more theoretical thing that eventually if you do infinite number of clustering and inference, there's some probability that suddenly all is like, yeah, so unlikely that it probably never happens, but.",
                    "label": 0
                },
                {
                    "sent": "You cannot exclude it, probably from a principle point of view, because the there's nothing special about one class and the other classes, they could just flip all the data and.",
                    "label": 0
                },
                {
                    "sent": "Rename each other and then.",
                    "label": 0
                },
                {
                    "sent": "This will also be a valid solution, but this is so unlikely to happen that you don't observe it.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We didn't observe this as a practical problem.",
                    "label": 0
                },
                {
                    "sent": "Because after I mean it really converged and the indicators we plotted were very stable.",
                    "label": 0
                },
                {
                    "sent": "The graph of the movie movies.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Are there?",
                    "label": 0
                },
                {
                    "sent": "That's a pretty dramatic drop.",
                    "label": 0
                },
                {
                    "sent": "Results to show 60 to 70.",
                    "label": 0
                },
                {
                    "sent": "How are the numbers OK?",
                    "label": 0
                },
                {
                    "sent": "Pre election very impressive so.",
                    "label": 0
                },
                {
                    "sent": "No, they're not.",
                    "label": 0
                },
                {
                    "sent": "You experimenting with different methods.",
                    "label": 0
                },
                {
                    "sent": "The other slide before you had your method versus the other numbers with your.",
                    "label": 0
                },
                {
                    "sent": "The movies.",
                    "label": 0
                },
                {
                    "sent": "Oh the eBay or the email or the 70%, yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "EBay.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So 50% is the trivial true one.",
                    "label": 1
                },
                {
                    "sent": "What happened to you?",
                    "label": 0
                },
                {
                    "sent": "But it is essentially the movie model.",
                    "label": 0
                },
                {
                    "sent": "Now the only thing is that we have two types or maybe even three types of relationships we are considering.",
                    "label": 1
                },
                {
                    "sent": "So it's a very similar similar model.",
                    "label": 0
                },
                {
                    "sent": "If you look up the model at the trust that you can pull it out.",
                    "label": 0
                },
                {
                    "sent": "Build the two clusters independently.",
                    "label": 0
                },
                {
                    "sent": "Stabilizing men.",
                    "label": 0
                },
                {
                    "sent": "Think back in, you know building.",
                    "label": 0
                },
                {
                    "sent": "I'm just wondering that's the comparison.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we we often did that.",
                    "label": 0
                },
                {
                    "sent": "I mean, just look at the performance now.",
                    "label": 0
                },
                {
                    "sent": "The when we report purely content based prediction.",
                    "label": 0
                },
                {
                    "sent": "That's pretty much what we did.",
                    "label": 0
                },
                {
                    "sent": "But.",
                    "label": 0
                },
                {
                    "sent": "We had, I think, in all the data we have, the relationships are very important for to determine the clustering structure.",
                    "label": 0
                },
                {
                    "sent": "But the experiment you were just mentioning, I also told the student to do that, but I haven't seen the results yet.",
                    "label": 0
                },
                {
                    "sent": "But I believe that the clustering would be quite different from the ones using.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, but make a pun.",
                    "label": 0
                }
            ]
        }
    }
}