{
    "id": "qdh5dkf6ohvjcdndoiajmfit23o43nzg",
    "title": "Discovering Missing Semantic Relations between Entities in Wikipedia",
    "info": {
        "author": [
            "Zhichun Wang, Beijing Normal University"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Information Extraction",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2013_wang_semantic_relations/",
    "segmentation": [
        [
            "Hello everybody, my name is Justin Wong from Beijing Normal University.",
            "The work I'm going to present is discovering missing semantic relationship relations between entities in Wikipedia."
        ],
        [
            "We all know Wikipedia is a very large online encyclopedia.",
            "It has a huge number of articles.",
            "It is much legal.",
            "It contain rich, structured information about various kinds of entities such as such as infoboxes categories, many inner an external links.",
            "Therefore, Wikipedia has become very important resource for building not basis projects like Jago, DB Pedia, Freebase, an extra or makes use of the.",
            "Information from Wikipedia.",
            "Among."
        ],
        [
            "Various kinds of information in Wikipedia most valuable information are contained in the info boxes.",
            "Here is an example Infoboxes info box from the wiki page about Barack Obama is summarized very important facts about him.",
            "As a table of the attribute and value pairs, this information are structured so they can be very easily converted to RDF triples, so that is what has already been done by DB pedia.",
            "So this table shows the information in DB pedia, which was extracted from the info box of Obama.",
            "We see that there are some links in the DB pedia in the infobox.",
            "It should be in values.",
            "For example the residents attribute of Obama is a link to the wiki page of White House, so we can just extract it this.",
            "Attributes as an object property and we can establish a link between the instance of Obama and the White House.",
            "But sometimes for the same for the same attribute.",
            "There might be no links in its value.",
            "For example, we take a look at the info box of Tim Berners Lee.",
            "Also have the attribute residence there.",
            "Just text information.",
            "United States and United Kingdom.",
            "But there is no links, so we cannot just directly extract the relations between Tim Berners Lee and the United States and United Kingdom.",
            "So we cannot find such information in DB pedia."
        ],
        [
            "So we can see that anti links in infoboxes are very important for.",
            "Defining semantic relations between entities.",
            "However, there are a lot of entity links are missing infoboxes.",
            "We did."
        ],
        [
            "Some analysis about the number of links in the info boxes.",
            "Here are two figures show the formation about English and Chinese attribute values in person infoboxes.",
            "The height of the bar shows the number of times that the attribute appears infoboxes.",
            "The blue part tell us how many times there are links in their value and the red part tell us how many times there are.",
            "There are no links in their value, so we can see that many of these.",
            "Most of these attributes can be converted to object properties because there are many links already.",
            "Many links in their values, but there are cases.",
            "The links just missing in their values too, so.",
            "What we study is how to automatically add these anti links in the infobox and so we can get additional relations between entities."
        ],
        [
            "There are two groups of research work related to our work.",
            "The first group is NT.",
            "Linking NT linking is to identify entities in documents and linking them to a knowledge base such as Wikipedia and DV Pedia.",
            "We have some approaches published right now, for example the first one, two identical link documents to Wikipedia might be wikify and.",
            "In 2008, Milan Witten proposed a learning based approach for anti linking and we also have a tour DVD spotlight which can add DUI eyes in a document.",
            "But the all this approach is.",
            "Take the plant documents as inputs.",
            "They're not designed for adding links for in the infoboxes, although we can use them for this purpose, but the results is not so good.",
            "Just as I will show you later and the other groups of research work is instance matching, instance matching is to find equivalent instances between RDF datasets.",
            "They actually add the same as link among already updated, but what what we want to do is add arbitrary type relations between entities.",
            "So we just cannot directly apply instance matching approaches for this problem."
        ],
        [
            "So we proposed approach that specifically used for adding links in infoboxes.",
            "It works in two steps.",
            "The first step is mention identification and enter link prediction.",
            "In the first step our approach identify first identifies some candidate, mentions info boxes and then we in the next step which end model to predict most possible entities that this mention might.",
            "Refer to.",
            "So in this."
        ],
        [
            "Above mentioned identification.",
            "We first viewed mention entity vocabulary here mentioned.",
            "We mean the anchor text of hyperlink for example.",
            "There is sentence from the wiki page of Beijing.",
            "There are five hyperlinks.",
            "The mentions are include urban population, Shanghai political, cultural, educational center.",
            "Due to the ambiguity of the natural language dimension, we see might not the same.",
            "As the name of the entities refer to, so here is the South text of the first sentence in Wikipedia.",
            "Editors use double brackets to annotate a hyperlink."
        ],
        [
            "The entity's name is not is different from the mention.",
            "We can use a vertical line to separate them in the brackets if they are the same.",
            "We do not have the vertical lines, so here for example, the political mention actually links to the Wiki page of politics of the People's Republic of China.",
            "So we process all the source code of the wiki articles to extract all the mentions and record the.",
            "Entities they links to."
        ],
        [
            "After get this vocabulary, we use them to identify mentions in Infoboxes.",
            "So given the infoboxes infobox an we just do perform the N gram matching between the text in the attribute values an all dimensions.",
            "So we can for the attribute values that have not link.",
            "We can get a set of mentions and associated with the destiny possible destination entities with it.",
            "So the next step we have to do is to decide which entity the mention actually refers to so."
        ],
        [
            "Go to the next step, being prediction.",
            "Here we define several features for each mention and entity pair.",
            "We compute these features and just combine these features to buy a weighted sum to get a score and forgiving mention we select the entity that have maximum scores with it as a destination destination entity of it.",
            "So we have to figure out two problems here.",
            "The first one is what kind of features are useful for this task?",
            "Link prediction and the second one is how to decide the weights of different features."
        ],
        [
            "The first problem we define 7 features here.",
            "The first feature is we called entity occurrence.",
            "If it is if it's.",
            "It a candidate.",
            "Entity have already been linked in the same article.",
            "Then this features value will be set to 1, otherwise will be 0.",
            "The second feature is link probability.",
            "It is computed by this formula.",
            "Here the count me is the number of times that mention M links to an entity E and the counter M is the total number of times that mention appears.",
            "The rest of."
        ],
        [
            "5 features are all computed based based on semantic relatedness metric.",
            "While it is proposed it is published in 2008 by Mu.",
            "Given two entities in Wikipedia, we can compute their similarity relatedness by comparing the overlap of there in links.",
            "The bigger overlap we got, higher relatedness.",
            "So we define another metrics based on this semantic relatedness.",
            "Where you compute one entity, the really nice between one entity and a set of entities.",
            "So let's a be a entity and BA set of entities.",
            "Or it is computed by the average of their name, this between A and every element in B.",
            "Soap."
        ],
        [
            "Based on the religious metric, we define the rest features.",
            "Here we have assumption that we assume that the predicted entity in the infobox should have higher relatedness between the other already linked entities in the same article we just divide this already linked entities into three groups.",
            "The entities linked in the abstract in the infobox and in the whole article.",
            "Then we just compute the.",
            "Candidate Entity, computer relatedness between the candidate entity and these three groups of entities and we get 3 features here."
        ],
        [
            "And we have another assumption that the predicted entity should have also should have related to the entities appear in the domain and range of that attribute.",
            "So for each attribute we connect all the entities that described by it and appears in the value of it, and we compute the candidate entities relatedness between these two sets entities and we get the last two.",
            "Attributes features"
        ],
        [
            "So after getting all the features, we have to decide the optimal weights up, then to combine them.",
            "Here we according to the prediction rule I just introduced the optimal entity istar should have.",
            "Bigger score than all the other entities, so we.",
            "Just to have this statement that the feature vector scores the score of the star minus the score of other entity should larger than 0.",
            "So we put this difference between into a sigmoid function.",
            "We just found it fit the logistic logistic regression model.",
            "So what we do in the next is to generate data set from the training data.",
            "Set of existing entity links to train a logistic regression model to find the optimal."
        ],
        [
            "So for each knowing links we just generate.",
            "Set a positive example and negative example and we make positive an active the same number to avoid imbalanced classification problem and we try to logistic regression model to get the weight."
        ],
        [
            "So that's all about our approach.",
            "In order to evaluate it, we randomly select 100 infoboxes from English Wikipedia and there are 630 entity links and we just separated into two parts with choose 50% of them as a ground truth, and we further divide the ground truth into two parts.",
            "40% of the for training and 60%.",
            "For testing."
        ],
        [
            "And we compare our approach with the wikify.",
            "The approach of Milan Witten and we also replace the learning method in our approach by SVM classifier and we get another baseline method."
        ],
        [
            "So here is a result and from the left to the right is the result of wikify approach of Milan Whitham SVM and the our proposed approach so."
        ],
        [
            "So we can find that our approach get the best precision and recall, and we just want to do a little analysis about it.",
            "So for the week, if I we just called its API to test, it is a performance, so we do not feed any training data to it for the right for the three approach in the right, they all use the training data, so we just think maybe training with existing anti links is an important factor for better performance."
        ],
        [
            "And.",
            "For the three learning based approaches, approaches and.",
            "Approaches of the approach of Milan written the just use 3 features and they actually used for anti linking for the documents and for the right to approaches.",
            "We all use 7 features we defined so these seven features we use some structure information in the info boxes so we just think specially designed features for the NT.",
            "Links for for the info boxes may help the to improve the results.",
            "And last, the SVM approach treat the Entity link prediction as a classification based method problem, but."
        ],
        [
            "Our approach treated as a waiting, waiting the futures and ranked mentioned ranked entities for each mention, so we also we use a classification model to learn the weights, but we predict the links in a different way so."
        ],
        [
            "We just think our learning method is more effective here."
        ],
        [
            "We also analyze the contribution of each attribute we run our approach 7 times and each time we just remove one features here and we record the document of the F1 score and as shown in this figure and we according to the document, we just rank the importance of these features.",
            "We found that the entity occurrence contributes most to our approach and then the attribute range and infobox context.",
            "And attribute demand tends to be the least important one."
        ],
        [
            "So here Council conclusion in this work we just propose approach to automatically find any links in Wikipedia infoboxes and we define the swimming features for predicting the anti links and we use a new method for learning the weights to predict the links and we do experiments to evaluate our approach on the Wikipedia data and it seems that our approach outperforms baseline methods.",
            "And the future work may include extending our work to discover incorrect anti links in infoboxes and also discovering new RDF links between RDF datasets, so that is all about our work thing."
        ],
        [
            "Parents."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, my name is Justin Wong from Beijing Normal University.",
                    "label": 0
                },
                {
                    "sent": "The work I'm going to present is discovering missing semantic relationship relations between entities in Wikipedia.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We all know Wikipedia is a very large online encyclopedia.",
                    "label": 0
                },
                {
                    "sent": "It has a huge number of articles.",
                    "label": 0
                },
                {
                    "sent": "It is much legal.",
                    "label": 0
                },
                {
                    "sent": "It contain rich, structured information about various kinds of entities such as such as infoboxes categories, many inner an external links.",
                    "label": 1
                },
                {
                    "sent": "Therefore, Wikipedia has become very important resource for building not basis projects like Jago, DB Pedia, Freebase, an extra or makes use of the.",
                    "label": 0
                },
                {
                    "sent": "Information from Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Among.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Various kinds of information in Wikipedia most valuable information are contained in the info boxes.",
                    "label": 1
                },
                {
                    "sent": "Here is an example Infoboxes info box from the wiki page about Barack Obama is summarized very important facts about him.",
                    "label": 0
                },
                {
                    "sent": "As a table of the attribute and value pairs, this information are structured so they can be very easily converted to RDF triples, so that is what has already been done by DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So this table shows the information in DB pedia, which was extracted from the info box of Obama.",
                    "label": 0
                },
                {
                    "sent": "We see that there are some links in the DB pedia in the infobox.",
                    "label": 0
                },
                {
                    "sent": "It should be in values.",
                    "label": 0
                },
                {
                    "sent": "For example the residents attribute of Obama is a link to the wiki page of White House, so we can just extract it this.",
                    "label": 0
                },
                {
                    "sent": "Attributes as an object property and we can establish a link between the instance of Obama and the White House.",
                    "label": 0
                },
                {
                    "sent": "But sometimes for the same for the same attribute.",
                    "label": 0
                },
                {
                    "sent": "There might be no links in its value.",
                    "label": 0
                },
                {
                    "sent": "For example, we take a look at the info box of Tim Berners Lee.",
                    "label": 0
                },
                {
                    "sent": "Also have the attribute residence there.",
                    "label": 0
                },
                {
                    "sent": "Just text information.",
                    "label": 0
                },
                {
                    "sent": "United States and United Kingdom.",
                    "label": 0
                },
                {
                    "sent": "But there is no links, so we cannot just directly extract the relations between Tim Berners Lee and the United States and United Kingdom.",
                    "label": 0
                },
                {
                    "sent": "So we cannot find such information in DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can see that anti links in infoboxes are very important for.",
                    "label": 0
                },
                {
                    "sent": "Defining semantic relations between entities.",
                    "label": 1
                },
                {
                    "sent": "However, there are a lot of entity links are missing infoboxes.",
                    "label": 1
                },
                {
                    "sent": "We did.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some analysis about the number of links in the info boxes.",
                    "label": 0
                },
                {
                    "sent": "Here are two figures show the formation about English and Chinese attribute values in person infoboxes.",
                    "label": 1
                },
                {
                    "sent": "The height of the bar shows the number of times that the attribute appears infoboxes.",
                    "label": 0
                },
                {
                    "sent": "The blue part tell us how many times there are links in their value and the red part tell us how many times there are.",
                    "label": 0
                },
                {
                    "sent": "There are no links in their value, so we can see that many of these.",
                    "label": 0
                },
                {
                    "sent": "Most of these attributes can be converted to object properties because there are many links already.",
                    "label": 0
                },
                {
                    "sent": "Many links in their values, but there are cases.",
                    "label": 0
                },
                {
                    "sent": "The links just missing in their values too, so.",
                    "label": 0
                },
                {
                    "sent": "What we study is how to automatically add these anti links in the infobox and so we can get additional relations between entities.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are two groups of research work related to our work.",
                    "label": 0
                },
                {
                    "sent": "The first group is NT.",
                    "label": 0
                },
                {
                    "sent": "Linking NT linking is to identify entities in documents and linking them to a knowledge base such as Wikipedia and DV Pedia.",
                    "label": 1
                },
                {
                    "sent": "We have some approaches published right now, for example the first one, two identical link documents to Wikipedia might be wikify and.",
                    "label": 0
                },
                {
                    "sent": "In 2008, Milan Witten proposed a learning based approach for anti linking and we also have a tour DVD spotlight which can add DUI eyes in a document.",
                    "label": 0
                },
                {
                    "sent": "But the all this approach is.",
                    "label": 0
                },
                {
                    "sent": "Take the plant documents as inputs.",
                    "label": 0
                },
                {
                    "sent": "They're not designed for adding links for in the infoboxes, although we can use them for this purpose, but the results is not so good.",
                    "label": 0
                },
                {
                    "sent": "Just as I will show you later and the other groups of research work is instance matching, instance matching is to find equivalent instances between RDF datasets.",
                    "label": 0
                },
                {
                    "sent": "They actually add the same as link among already updated, but what what we want to do is add arbitrary type relations between entities.",
                    "label": 0
                },
                {
                    "sent": "So we just cannot directly apply instance matching approaches for this problem.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we proposed approach that specifically used for adding links in infoboxes.",
                    "label": 1
                },
                {
                    "sent": "It works in two steps.",
                    "label": 0
                },
                {
                    "sent": "The first step is mention identification and enter link prediction.",
                    "label": 1
                },
                {
                    "sent": "In the first step our approach identify first identifies some candidate, mentions info boxes and then we in the next step which end model to predict most possible entities that this mention might.",
                    "label": 0
                },
                {
                    "sent": "Refer to.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Above mentioned identification.",
                    "label": 0
                },
                {
                    "sent": "We first viewed mention entity vocabulary here mentioned.",
                    "label": 1
                },
                {
                    "sent": "We mean the anchor text of hyperlink for example.",
                    "label": 1
                },
                {
                    "sent": "There is sentence from the wiki page of Beijing.",
                    "label": 0
                },
                {
                    "sent": "There are five hyperlinks.",
                    "label": 1
                },
                {
                    "sent": "The mentions are include urban population, Shanghai political, cultural, educational center.",
                    "label": 1
                },
                {
                    "sent": "Due to the ambiguity of the natural language dimension, we see might not the same.",
                    "label": 0
                },
                {
                    "sent": "As the name of the entities refer to, so here is the South text of the first sentence in Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "Editors use double brackets to annotate a hyperlink.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The entity's name is not is different from the mention.",
                    "label": 0
                },
                {
                    "sent": "We can use a vertical line to separate them in the brackets if they are the same.",
                    "label": 0
                },
                {
                    "sent": "We do not have the vertical lines, so here for example, the political mention actually links to the Wiki page of politics of the People's Republic of China.",
                    "label": 0
                },
                {
                    "sent": "So we process all the source code of the wiki articles to extract all the mentions and record the.",
                    "label": 0
                },
                {
                    "sent": "Entities they links to.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After get this vocabulary, we use them to identify mentions in Infoboxes.",
                    "label": 1
                },
                {
                    "sent": "So given the infoboxes infobox an we just do perform the N gram matching between the text in the attribute values an all dimensions.",
                    "label": 1
                },
                {
                    "sent": "So we can for the attribute values that have not link.",
                    "label": 0
                },
                {
                    "sent": "We can get a set of mentions and associated with the destiny possible destination entities with it.",
                    "label": 0
                },
                {
                    "sent": "So the next step we have to do is to decide which entity the mention actually refers to so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go to the next step, being prediction.",
                    "label": 0
                },
                {
                    "sent": "Here we define several features for each mention and entity pair.",
                    "label": 0
                },
                {
                    "sent": "We compute these features and just combine these features to buy a weighted sum to get a score and forgiving mention we select the entity that have maximum scores with it as a destination destination entity of it.",
                    "label": 0
                },
                {
                    "sent": "So we have to figure out two problems here.",
                    "label": 0
                },
                {
                    "sent": "The first one is what kind of features are useful for this task?",
                    "label": 1
                },
                {
                    "sent": "Link prediction and the second one is how to decide the weights of different features.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first problem we define 7 features here.",
                    "label": 0
                },
                {
                    "sent": "The first feature is we called entity occurrence.",
                    "label": 0
                },
                {
                    "sent": "If it is if it's.",
                    "label": 0
                },
                {
                    "sent": "It a candidate.",
                    "label": 0
                },
                {
                    "sent": "Entity have already been linked in the same article.",
                    "label": 0
                },
                {
                    "sent": "Then this features value will be set to 1, otherwise will be 0.",
                    "label": 0
                },
                {
                    "sent": "The second feature is link probability.",
                    "label": 0
                },
                {
                    "sent": "It is computed by this formula.",
                    "label": 0
                },
                {
                    "sent": "Here the count me is the number of times that mention M links to an entity E and the counter M is the total number of times that mention appears.",
                    "label": 1
                },
                {
                    "sent": "The rest of.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "5 features are all computed based based on semantic relatedness metric.",
                    "label": 0
                },
                {
                    "sent": "While it is proposed it is published in 2008 by Mu.",
                    "label": 0
                },
                {
                    "sent": "Given two entities in Wikipedia, we can compute their similarity relatedness by comparing the overlap of there in links.",
                    "label": 1
                },
                {
                    "sent": "The bigger overlap we got, higher relatedness.",
                    "label": 0
                },
                {
                    "sent": "So we define another metrics based on this semantic relatedness.",
                    "label": 0
                },
                {
                    "sent": "Where you compute one entity, the really nice between one entity and a set of entities.",
                    "label": 1
                },
                {
                    "sent": "So let's a be a entity and BA set of entities.",
                    "label": 0
                },
                {
                    "sent": "Or it is computed by the average of their name, this between A and every element in B.",
                    "label": 0
                },
                {
                    "sent": "Soap.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Based on the religious metric, we define the rest features.",
                    "label": 0
                },
                {
                    "sent": "Here we have assumption that we assume that the predicted entity in the infobox should have higher relatedness between the other already linked entities in the same article we just divide this already linked entities into three groups.",
                    "label": 0
                },
                {
                    "sent": "The entities linked in the abstract in the infobox and in the whole article.",
                    "label": 0
                },
                {
                    "sent": "Then we just compute the.",
                    "label": 0
                },
                {
                    "sent": "Candidate Entity, computer relatedness between the candidate entity and these three groups of entities and we get 3 features here.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have another assumption that the predicted entity should have also should have related to the entities appear in the domain and range of that attribute.",
                    "label": 0
                },
                {
                    "sent": "So for each attribute we connect all the entities that described by it and appears in the value of it, and we compute the candidate entities relatedness between these two sets entities and we get the last two.",
                    "label": 1
                },
                {
                    "sent": "Attributes features",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So after getting all the features, we have to decide the optimal weights up, then to combine them.",
                    "label": 0
                },
                {
                    "sent": "Here we according to the prediction rule I just introduced the optimal entity istar should have.",
                    "label": 0
                },
                {
                    "sent": "Bigger score than all the other entities, so we.",
                    "label": 0
                },
                {
                    "sent": "Just to have this statement that the feature vector scores the score of the star minus the score of other entity should larger than 0.",
                    "label": 0
                },
                {
                    "sent": "So we put this difference between into a sigmoid function.",
                    "label": 0
                },
                {
                    "sent": "We just found it fit the logistic logistic regression model.",
                    "label": 0
                },
                {
                    "sent": "So what we do in the next is to generate data set from the training data.",
                    "label": 0
                },
                {
                    "sent": "Set of existing entity links to train a logistic regression model to find the optimal.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for each knowing links we just generate.",
                    "label": 0
                },
                {
                    "sent": "Set a positive example and negative example and we make positive an active the same number to avoid imbalanced classification problem and we try to logistic regression model to get the weight.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's all about our approach.",
                    "label": 0
                },
                {
                    "sent": "In order to evaluate it, we randomly select 100 infoboxes from English Wikipedia and there are 630 entity links and we just separated into two parts with choose 50% of them as a ground truth, and we further divide the ground truth into two parts.",
                    "label": 1
                },
                {
                    "sent": "40% of the for training and 60%.",
                    "label": 0
                },
                {
                    "sent": "For testing.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we compare our approach with the wikify.",
                    "label": 0
                },
                {
                    "sent": "The approach of Milan Witten and we also replace the learning method in our approach by SVM classifier and we get another baseline method.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is a result and from the left to the right is the result of wikify approach of Milan Whitham SVM and the our proposed approach so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can find that our approach get the best precision and recall, and we just want to do a little analysis about it.",
                    "label": 0
                },
                {
                    "sent": "So for the week, if I we just called its API to test, it is a performance, so we do not feed any training data to it for the right for the three approach in the right, they all use the training data, so we just think maybe training with existing anti links is an important factor for better performance.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "For the three learning based approaches, approaches and.",
                    "label": 0
                },
                {
                    "sent": "Approaches of the approach of Milan written the just use 3 features and they actually used for anti linking for the documents and for the right to approaches.",
                    "label": 0
                },
                {
                    "sent": "We all use 7 features we defined so these seven features we use some structure information in the info boxes so we just think specially designed features for the NT.",
                    "label": 1
                },
                {
                    "sent": "Links for for the info boxes may help the to improve the results.",
                    "label": 0
                },
                {
                    "sent": "And last, the SVM approach treat the Entity link prediction as a classification based method problem, but.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our approach treated as a waiting, waiting the futures and ranked mentioned ranked entities for each mention, so we also we use a classification model to learn the weights, but we predict the links in a different way so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We just think our learning method is more effective here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also analyze the contribution of each attribute we run our approach 7 times and each time we just remove one features here and we record the document of the F1 score and as shown in this figure and we according to the document, we just rank the importance of these features.",
                    "label": 0
                },
                {
                    "sent": "We found that the entity occurrence contributes most to our approach and then the attribute range and infobox context.",
                    "label": 1
                },
                {
                    "sent": "And attribute demand tends to be the least important one.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here Council conclusion in this work we just propose approach to automatically find any links in Wikipedia infoboxes and we define the swimming features for predicting the anti links and we use a new method for learning the weights to predict the links and we do experiments to evaluate our approach on the Wikipedia data and it seems that our approach outperforms baseline methods.",
                    "label": 0
                },
                {
                    "sent": "And the future work may include extending our work to discover incorrect anti links in infoboxes and also discovering new RDF links between RDF datasets, so that is all about our work thing.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parents.",
                    "label": 0
                }
            ]
        }
    }
}