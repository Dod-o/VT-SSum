{
    "id": "bxgudnfilqutb2umfnkardkrwsc4s5hw",
    "title": "Supervised Clustering",
    "info": {
        "author": [
            "Reza Bosagh Zadeh, Institute for Computational and Mathematical Engineering, Stanford University"
        ],
        "published": "March 25, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/nips2010_zadeh_sc/",
    "segmentation": [
        [
            "OK, so most people in this room think of clustering as an inherently super unsupervised task, and we're immediately going to depart from that.",
            "And we're working in the model introduced by Balcan Blum in 2008, where there is a little bit of supervision given to us by a teacher.",
            "And we're going to use this supervision to remove ambiguity in clustering, so we all know that.",
            "A clustering is a little bit subjective and a teacher can help us remove this ambiguity.",
            "So for example, consider the data set on the slide.",
            "It has many two clusterings and there are two of them.",
            "Anne will use the teacher to help us remove any ambiguity in the answer."
        ],
        [
            "So what does the model look like?",
            "An algorithm is allowed to present a particular clustering as a candidate.",
            "Clustering and the teacher will respond with exactly one of two things.",
            "It will either point to a single cluster and say.",
            "That cluster is impure.",
            "It won't say how it's impure, so they won't.",
            "There won't be any information about how to split the cluster, only that it is impure.",
            "Or it could say that these two clusters need to be merged together.",
            "That's all the information that we can get from the teacher.",
            "So we tried not to not to make it too easy for the algorithm, and that's why there isn't a.",
            "There isn't too much information when you're told to split.",
            "So we're working with worst case bounds, and we're assuming that the teacher is adversary.",
            "So for any.",
            "Concept Class C Balkan emblems."
        ],
        [
            "Note that you can cluster perfectly using KQ blog C queries and we improve that bound to keylog C. The C can be replaced with VC dimension.",
            "In the case of infinite size.",
            "Hypothesis Class is an you may be confused about why I'm talking about VC dimension, an hypothesis classes when we're talking about clustering, and the reason for that is.",
            "You can think of every cluster as exactly determined by one hypothesis, so that every the points inside a cluster are given by those labeled as one.",
            "Now.",
            "We also introduce noise in the model, so again, working with worst case scenario, an noise, so it's quite quite challenging, but we still managed to get some interesting results there.",
            "And.",
            "We also look at geometric concept classes so rectangles and other nice shapes and then we further go deep, deeper and say what if the data set had some nice properties.",
            "So let's say that our data set."
        ],
        [
            "Well, we're separated by a margin of gamma, meaning that between any pair of clusters there is distance, gamma separation.",
            "In that case, we have a fairly nice bound, but unfortunately it does suffer from a curse of dimensionality.",
            "We're obviously working on improving that.",
            "The other two properties that you see on this slide are even further separation, so the data set is even better separated, and therefore you would expect to do better, and indeed you do.",
            "And.",
            "So so, so we're obviously open to any criticism of this model.",
            "It's new, and an we hope to have your questions and an.",
            "We hope you will answer them at slide I poster W. 52.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so most people in this room think of clustering as an inherently super unsupervised task, and we're immediately going to depart from that.",
                    "label": 0
                },
                {
                    "sent": "And we're working in the model introduced by Balcan Blum in 2008, where there is a little bit of supervision given to us by a teacher.",
                    "label": 0
                },
                {
                    "sent": "And we're going to use this supervision to remove ambiguity in clustering, so we all know that.",
                    "label": 0
                },
                {
                    "sent": "A clustering is a little bit subjective and a teacher can help us remove this ambiguity.",
                    "label": 1
                },
                {
                    "sent": "So for example, consider the data set on the slide.",
                    "label": 0
                },
                {
                    "sent": "It has many two clusterings and there are two of them.",
                    "label": 0
                },
                {
                    "sent": "Anne will use the teacher to help us remove any ambiguity in the answer.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what does the model look like?",
                    "label": 1
                },
                {
                    "sent": "An algorithm is allowed to present a particular clustering as a candidate.",
                    "label": 1
                },
                {
                    "sent": "Clustering and the teacher will respond with exactly one of two things.",
                    "label": 0
                },
                {
                    "sent": "It will either point to a single cluster and say.",
                    "label": 0
                },
                {
                    "sent": "That cluster is impure.",
                    "label": 0
                },
                {
                    "sent": "It won't say how it's impure, so they won't.",
                    "label": 0
                },
                {
                    "sent": "There won't be any information about how to split the cluster, only that it is impure.",
                    "label": 0
                },
                {
                    "sent": "Or it could say that these two clusters need to be merged together.",
                    "label": 1
                },
                {
                    "sent": "That's all the information that we can get from the teacher.",
                    "label": 1
                },
                {
                    "sent": "So we tried not to not to make it too easy for the algorithm, and that's why there isn't a.",
                    "label": 0
                },
                {
                    "sent": "There isn't too much information when you're told to split.",
                    "label": 0
                },
                {
                    "sent": "So we're working with worst case bounds, and we're assuming that the teacher is adversary.",
                    "label": 0
                },
                {
                    "sent": "So for any.",
                    "label": 0
                },
                {
                    "sent": "Concept Class C Balkan emblems.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Note that you can cluster perfectly using KQ blog C queries and we improve that bound to keylog C. The C can be replaced with VC dimension.",
                    "label": 1
                },
                {
                    "sent": "In the case of infinite size.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis Class is an you may be confused about why I'm talking about VC dimension, an hypothesis classes when we're talking about clustering, and the reason for that is.",
                    "label": 0
                },
                {
                    "sent": "You can think of every cluster as exactly determined by one hypothesis, so that every the points inside a cluster are given by those labeled as one.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "We also introduce noise in the model, so again, working with worst case scenario, an noise, so it's quite quite challenging, but we still managed to get some interesting results there.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We also look at geometric concept classes so rectangles and other nice shapes and then we further go deep, deeper and say what if the data set had some nice properties.",
                    "label": 1
                },
                {
                    "sent": "So let's say that our data set.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, we're separated by a margin of gamma, meaning that between any pair of clusters there is distance, gamma separation.",
                    "label": 0
                },
                {
                    "sent": "In that case, we have a fairly nice bound, but unfortunately it does suffer from a curse of dimensionality.",
                    "label": 0
                },
                {
                    "sent": "We're obviously working on improving that.",
                    "label": 0
                },
                {
                    "sent": "The other two properties that you see on this slide are even further separation, so the data set is even better separated, and therefore you would expect to do better, and indeed you do.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So so, so we're obviously open to any criticism of this model.",
                    "label": 0
                },
                {
                    "sent": "It's new, and an we hope to have your questions and an.",
                    "label": 0
                },
                {
                    "sent": "We hope you will answer them at slide I poster W. 52.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}