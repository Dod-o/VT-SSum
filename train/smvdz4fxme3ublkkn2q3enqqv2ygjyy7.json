{
    "id": "smvdz4fxme3ublkkn2q3enqqv2ygjyy7",
    "title": "Stretching the Life of Twitter Classifiers with Time-Stamped Semantic Graphs",
    "info": {
        "author": [
            "Amparo Elizabeth Cano Besave, Knowledge Media Institute (KMI), Open University (OU)"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_cano_semantic_graphs/",
    "segmentation": [
        [
            "I'm a research associate from the Knowledge Media Institute at the Open University and I'm going to be presenting a work that was done in collaboration with EULA.",
            "He from Boston University and Harry Delaney from KMI."
        ],
        [
            "So social media and particularly Twitter has proven to be a very powerful tool for sharing opinions and spreading the world on trans Am current topic.",
            "So currently different research works have been focusing on understanding what is being discussed on social media.",
            "Such works include, for example, event detection, topic classification and so on."
        ],
        [
            "But one persistent challenge faced by these works is to be able to assign a topic label to a tweet, which is a core stepping topic classification.",
            "However, existing approaches for topic classification depend on labeled data, so that means that existing topic models are very sensitive to the evolution of topics.",
            "So if you take, for example, the case of violence topic, and there are some words that they don't change their violence connotations, so for example.",
            "Protest or security or death.",
            "They have these violence connotation overtime.",
            "Words that they acquired the violence connotation as they these words are involved in different events.",
            "So if you take, for example, 2011 the word Egypt started to become related with violence after the Egyptian revolution.",
            "But if you take that work three years later, Egypt is not as relevant to violence as it is now ISIS, for example."
        ],
        [
            "So in order to keep topic classifiers up-to-date, it is necessary to regularly retune these models.",
            "However, this is at the expense of using manually annotated information, which is very costly, so in this work we focus on understanding the stability of a topic representation and how existing features can help us to maintain the stability of the representation of the topic overtime."
        ],
        [
            "So there are different ways in which you can provide a representation of a tweet, and some of the existing features have been focusing on on features that you can extract directly from a tweet.",
            "So, for example, you can use bag of words, representation bag of entity, or you can use syntactic features like part of speech tagging.",
            "And there are other approaches that have proposed to use external knowledge sources so you can use for example categories derived from entities included in a tweet.",
            "Or you can use.",
            "Existing Wikipedia resources that are relevant to a particular tweet.",
            "Or you could use features that you can extract from Freebase so from DB pedia."
        ],
        [
            "But yet we still have this kind of challenge of how can we keep track of the recharacterization of a topic?",
            "So how can we know which are the tweets?",
            "Sorry, which are the features that are starting to fade out in a topic representation and which are the features that are starting to become relevant for representing a particular topic."
        ],
        [
            "So it's important that we also notice that it is not just that the topics are changing, but also the entities that are involved in a topic are evolving.",
            "So take for example the case of Obama, so we can kind of track this evolution by checking different semantic representation of Obama extracted from different DB pedia dumps.",
            "So while there are some triples that do not change in time like for example birthplace, there are other triples that start to be added to there.",
            "This semantic graph that can provide information about current, future or past context of Obama."
        ],
        [
            "So in this work we have the definition of a time dependent resource meta graph, which is basically to take a snapshot of all the triples that are relevant to a particular resource in a point in time.",
            "So we want to use this entity representation to be able to enhance the representation of a tweet and the way we're doing."
        ],
        [
            "It is that they, for example, this tweet usually consists of a series of lexical features and some of which are entities, and some of these entities can have a resource in DB pedia.",
            "So in this case we have Mubarak, Egypt, CNN, Barack Obama."
        ],
        [
            "So if we go on an query DB pedia, we can extract features such as Mubarak is our office Holder or Barack Obama is a Nobel Peace Prize laureate."
        ],
        [
            "Or you can take other type of features like properties so we can know that CNN has a property headquar."
        ],
        [
            "Orders or categories so you can use that.",
            "Barack Obama is categorized as president of the United States."
        ],
        [
            "Well, in the same way you can use the resources related to a particular entity, so now."
        ],
        [
            "Or you can end up with a bunch of different features that represent this entity in different points in time, but Now the question is, which are the features that you should be using to characterize a particular topic.",
            "So how can we know, for example, that birthplace is a good feature to characterize Obama in the context of violence?",
            "Or how can you know that?",
            "Maybe it would be better to use debt of Osama bin Laden as a good feature for representing dentity Obama for the topic violence."
        ],
        [
            "So in this work we introduce a series of strategies which are based on the fact of topic relevance.",
            "So imagine that you take us a graph of the DB pedia graph that is relevant to a particular topic.",
            "So, for example, if you choose were in conflict, you can take all categories of categories of war and conflict as well as all resources relevant to these categories and subcategories.",
            "So then you can check what is.",
            "Appearance of a particular feature within this sub graph and compare it to the appearance of this feature in the fully.",
            "Graph.",
            "So we."
        ],
        [
            "Prepare well, we introduce different strategies based on these kind of idea for classes, properties, categories and resources and."
        ],
        [
            "The way that we are integrating these weights into the tweet representation is basically using a frequency with loveless is moving, so in this case you take all the semantic features are well for a particular semantic feature.",
            "You check how many times this feature can be derived from entities included in the tweet, and then you multiply that by the weighted strategy that correspond to that type of feature."
        ],
        [
            "So where we are trying to check in our experiment is to see if these deep ideographs can help us to provide a topic representation and to check if this topic representation is stable overtime.",
            "So the way."
        ],
        [
            "We started our experiments is that we we had two different datasets, one of microposts and the other one of DB pedia dumps."
        ],
        [
            "And we started to build our data set.",
            "So we started with a collection of over 1 million tweets.",
            "For these three different books, 2010, eleven and 13.",
            "And then we started using the open column service, which is basically a service that returns a label for a particular trait taken from a pool of 10 different categories.",
            "And in these experiments we focus on the violence related topics.",
            "So we took disaster an accident, low on crime and war and conflict.",
            "So we.",
            "To be lower gold standard we did a manual re annotation of all the tweets that were labeled with any of these three classes and we kept 1000 tweets per topic per year and to build a negative data set we took all tweets that were not labeled with any of these three different topics.",
            "And we did a manual re annotation, so we ended up with 12,000 annotated tweets.",
            "So."
        ],
        [
            "Next step was to check which are the resources that are contained in a tweet.",
            "So for that we use alchemy and alchemy returns you resources well, entities mapped to a resource in DB pedia."
        ],
        [
            "So once we got these different resources from the period contained in a tweet, we built the semantic graph representing each of these entities depending on the availability of the DV pedia dump at the moment in which the tweet was generated."
        ],
        [
            "From there, we continue doing the using the weighted strategies that we introduce with that information we built different topic classifier."
        ],
        [
            "So we had different topic classifiers.",
            "For these three different topics, and for each of the epochs, our baseline was.",
            "Lexical features, which was basically bag of word features and we were comparing it with four different semantic features, category property, resources on class."
        ],
        [
            "So as I mentioned, we build a topical classifiers for the different books.",
            "So now what we wanted to check was to compare to different scenarios."
        ],
        [
            "So the first scenario we call it same epic scenario.",
            "In this case you are training on data belonging to their pochti and you test it on data from from the same airport."
        ],
        [
            "And in this case is not surprising.",
            "To see that the bag of words representation was outperforming the semantic feature representation, because the words in which you were training your model are still appearing on the test set.",
            "But what happened?"
        ],
        [
            "When we were checking the cross epochs scenario, so in this case we trained on data from time at AT and we test on data that is coming from future epochs."
        ],
        [
            "So for that case, we found that the back of word representation drop in performance, but the more interesting part is that the category all the semantic features, feature representation, outperform the bag of words.",
            "That means that the semantic features are providing a more stable representation of a topic overtime.",
            "Ugh."
        ],
        [
            "When we do, the average of.",
            "Performance of these cross eyed book scenarios.",
            "We found that for day three different topics the class feature was the one that consistently outperformed the.",
            "The bag of words representation for different topics so.",
            "Um?"
        ],
        [
            "Yeah, we can conclude that the semantic features are much more slower to decade and lexical features, and that the semantic representation can improve performance in cross times at in scenarios.",
            "And we also found out that the class feature can provide a more stable representation overtime, and that on average it has a gain of over 7%.",
            "In performance."
        ],
        [
            "In our future work includes the study of concept drift tracking for transfer learning using linked data sources and the study cross app transfer learning approaches using semantic features."
        ],
        [
            "Do you have any questions?",
            "Thank you.",
            "Hi, I just wanted to ask you if you can very shortly explain the intuition behind the formula you show.",
            "So this is a very basic formula But basically this this first section.",
            "Then it's just a frequency with Laplace smoothing, so is counting how many times the feature is appearing on a trip.",
            "But in this case, because it's a feature that is derived from the entities that are appearing on a tweet, that means that we were doing that.",
            "So imagine if you have an in this case on the tweet that I was showing you have Egypt and you have Mubarak and then you have Obama.",
            "So if in any of these features you were able to derive the resource al Qaeda.",
            "Then that means that you are counting straight times because you were able to get to al Qaeda through these different 3 three entities.",
            "So that counts arcada kind of three times within this first section, and then the second section is the weighting strategy.",
            "So that is basically using in this case.",
            "If it's resource we are using our resource strategy for waiting.",
            "And basically here we are using a square root, which is basically kind of helping, helping you to boost the weight when the weight is very small.",
            "So for example.",
            "The square root of your points here one is 0.1 as your points here 2 is by point 1414 and so on.",
            "So you are kind of boosting the part where the weight is very small, so so you are building your negative examples from all the other for the topic.",
            "The other four topics, or three topics that you have.",
            "And I was wondering whether you consider the possible semantic overlap between.",
            "The topics that you are taking is negative examples and whether this actually biases your result.",
            "So for example, here I was mentioning that we started to kind of filter on this one.",
            "Million tweets from our data, first data set using open colors.",
            "Open column gives you labels from 10 different categories which include these three ones that we're trying to model, plus also the ones like economic, sports, entertainment and so on.",
            "So yes, it's true that you might have a entities relevant to, for example, Obama in the context of.",
            "Economics for example.",
            "But then when you go to the.",
            "No, no, what do you say when you go to the semantic feature representation of Obama?",
            "Here what we're doing with these strategies that we're introducing is we're filtering out features that are not relevant to that entity in a particular context, which means that we would be filtering out.",
            "All the features that are not relevant in the context of violence.",
            "So if we're if we're waiting.",
            "To represent the topic.",
            "Economics we will find.",
            "That the representation of Obama will include different features that are related with politics.",
            "Perhaps economics, maybe Nobel Prize, but those features are not representative of Obama in the context of violence.",
            "So that's the way we're kind of.",
            "Thank you once again, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm a research associate from the Knowledge Media Institute at the Open University and I'm going to be presenting a work that was done in collaboration with EULA.",
                    "label": 0
                },
                {
                    "sent": "He from Boston University and Harry Delaney from KMI.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So social media and particularly Twitter has proven to be a very powerful tool for sharing opinions and spreading the world on trans Am current topic.",
                    "label": 0
                },
                {
                    "sent": "So currently different research works have been focusing on understanding what is being discussed on social media.",
                    "label": 1
                },
                {
                    "sent": "Such works include, for example, event detection, topic classification and so on.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But one persistent challenge faced by these works is to be able to assign a topic label to a tweet, which is a core stepping topic classification.",
                    "label": 0
                },
                {
                    "sent": "However, existing approaches for topic classification depend on labeled data, so that means that existing topic models are very sensitive to the evolution of topics.",
                    "label": 1
                },
                {
                    "sent": "So if you take, for example, the case of violence topic, and there are some words that they don't change their violence connotations, so for example.",
                    "label": 0
                },
                {
                    "sent": "Protest or security or death.",
                    "label": 0
                },
                {
                    "sent": "They have these violence connotation overtime.",
                    "label": 0
                },
                {
                    "sent": "Words that they acquired the violence connotation as they these words are involved in different events.",
                    "label": 0
                },
                {
                    "sent": "So if you take, for example, 2011 the word Egypt started to become related with violence after the Egyptian revolution.",
                    "label": 0
                },
                {
                    "sent": "But if you take that work three years later, Egypt is not as relevant to violence as it is now ISIS, for example.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to keep topic classifiers up-to-date, it is necessary to regularly retune these models.",
                    "label": 0
                },
                {
                    "sent": "However, this is at the expense of using manually annotated information, which is very costly, so in this work we focus on understanding the stability of a topic representation and how existing features can help us to maintain the stability of the representation of the topic overtime.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are different ways in which you can provide a representation of a tweet, and some of the existing features have been focusing on on features that you can extract directly from a tweet.",
                    "label": 0
                },
                {
                    "sent": "So, for example, you can use bag of words, representation bag of entity, or you can use syntactic features like part of speech tagging.",
                    "label": 1
                },
                {
                    "sent": "And there are other approaches that have proposed to use external knowledge sources so you can use for example categories derived from entities included in a tweet.",
                    "label": 0
                },
                {
                    "sent": "Or you can use.",
                    "label": 0
                },
                {
                    "sent": "Existing Wikipedia resources that are relevant to a particular tweet.",
                    "label": 0
                },
                {
                    "sent": "Or you could use features that you can extract from Freebase so from DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But yet we still have this kind of challenge of how can we keep track of the recharacterization of a topic?",
                    "label": 0
                },
                {
                    "sent": "So how can we know which are the tweets?",
                    "label": 0
                },
                {
                    "sent": "Sorry, which are the features that are starting to fade out in a topic representation and which are the features that are starting to become relevant for representing a particular topic.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's important that we also notice that it is not just that the topics are changing, but also the entities that are involved in a topic are evolving.",
                    "label": 0
                },
                {
                    "sent": "So take for example the case of Obama, so we can kind of track this evolution by checking different semantic representation of Obama extracted from different DB pedia dumps.",
                    "label": 0
                },
                {
                    "sent": "So while there are some triples that do not change in time like for example birthplace, there are other triples that start to be added to there.",
                    "label": 0
                },
                {
                    "sent": "This semantic graph that can provide information about current, future or past context of Obama.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this work we have the definition of a time dependent resource meta graph, which is basically to take a snapshot of all the triples that are relevant to a particular resource in a point in time.",
                    "label": 0
                },
                {
                    "sent": "So we want to use this entity representation to be able to enhance the representation of a tweet and the way we're doing.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is that they, for example, this tweet usually consists of a series of lexical features and some of which are entities, and some of these entities can have a resource in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So in this case we have Mubarak, Egypt, CNN, Barack Obama.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we go on an query DB pedia, we can extract features such as Mubarak is our office Holder or Barack Obama is a Nobel Peace Prize laureate.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or you can take other type of features like properties so we can know that CNN has a property headquar.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Orders or categories so you can use that.",
                    "label": 0
                },
                {
                    "sent": "Barack Obama is categorized as president of the United States.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, in the same way you can use the resources related to a particular entity, so now.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or you can end up with a bunch of different features that represent this entity in different points in time, but Now the question is, which are the features that you should be using to characterize a particular topic.",
                    "label": 0
                },
                {
                    "sent": "So how can we know, for example, that birthplace is a good feature to characterize Obama in the context of violence?",
                    "label": 0
                },
                {
                    "sent": "Or how can you know that?",
                    "label": 0
                },
                {
                    "sent": "Maybe it would be better to use debt of Osama bin Laden as a good feature for representing dentity Obama for the topic violence.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this work we introduce a series of strategies which are based on the fact of topic relevance.",
                    "label": 0
                },
                {
                    "sent": "So imagine that you take us a graph of the DB pedia graph that is relevant to a particular topic.",
                    "label": 1
                },
                {
                    "sent": "So, for example, if you choose were in conflict, you can take all categories of categories of war and conflict as well as all resources relevant to these categories and subcategories.",
                    "label": 0
                },
                {
                    "sent": "So then you can check what is.",
                    "label": 1
                },
                {
                    "sent": "Appearance of a particular feature within this sub graph and compare it to the appearance of this feature in the fully.",
                    "label": 0
                },
                {
                    "sent": "Graph.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prepare well, we introduce different strategies based on these kind of idea for classes, properties, categories and resources and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The way that we are integrating these weights into the tweet representation is basically using a frequency with loveless is moving, so in this case you take all the semantic features are well for a particular semantic feature.",
                    "label": 0
                },
                {
                    "sent": "You check how many times this feature can be derived from entities included in the tweet, and then you multiply that by the weighted strategy that correspond to that type of feature.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So where we are trying to check in our experiment is to see if these deep ideographs can help us to provide a topic representation and to check if this topic representation is stable overtime.",
                    "label": 0
                },
                {
                    "sent": "So the way.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We started our experiments is that we we had two different datasets, one of microposts and the other one of DB pedia dumps.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we started to build our data set.",
                    "label": 0
                },
                {
                    "sent": "So we started with a collection of over 1 million tweets.",
                    "label": 1
                },
                {
                    "sent": "For these three different books, 2010, eleven and 13.",
                    "label": 0
                },
                {
                    "sent": "And then we started using the open column service, which is basically a service that returns a label for a particular trait taken from a pool of 10 different categories.",
                    "label": 1
                },
                {
                    "sent": "And in these experiments we focus on the violence related topics.",
                    "label": 1
                },
                {
                    "sent": "So we took disaster an accident, low on crime and war and conflict.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                },
                {
                    "sent": "To be lower gold standard we did a manual re annotation of all the tweets that were labeled with any of these three classes and we kept 1000 tweets per topic per year and to build a negative data set we took all tweets that were not labeled with any of these three different topics.",
                    "label": 0
                },
                {
                    "sent": "And we did a manual re annotation, so we ended up with 12,000 annotated tweets.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next step was to check which are the resources that are contained in a tweet.",
                    "label": 0
                },
                {
                    "sent": "So for that we use alchemy and alchemy returns you resources well, entities mapped to a resource in DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once we got these different resources from the period contained in a tweet, we built the semantic graph representing each of these entities depending on the availability of the DV pedia dump at the moment in which the tweet was generated.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From there, we continue doing the using the weighted strategies that we introduce with that information we built different topic classifier.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we had different topic classifiers.",
                    "label": 0
                },
                {
                    "sent": "For these three different topics, and for each of the epochs, our baseline was.",
                    "label": 0
                },
                {
                    "sent": "Lexical features, which was basically bag of word features and we were comparing it with four different semantic features, category property, resources on class.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I mentioned, we build a topical classifiers for the different books.",
                    "label": 0
                },
                {
                    "sent": "So now what we wanted to check was to compare to different scenarios.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first scenario we call it same epic scenario.",
                    "label": 0
                },
                {
                    "sent": "In this case you are training on data belonging to their pochti and you test it on data from from the same airport.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this case is not surprising.",
                    "label": 0
                },
                {
                    "sent": "To see that the bag of words representation was outperforming the semantic feature representation, because the words in which you were training your model are still appearing on the test set.",
                    "label": 0
                },
                {
                    "sent": "But what happened?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we were checking the cross epochs scenario, so in this case we trained on data from time at AT and we test on data that is coming from future epochs.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for that case, we found that the back of word representation drop in performance, but the more interesting part is that the category all the semantic features, feature representation, outperform the bag of words.",
                    "label": 0
                },
                {
                    "sent": "That means that the semantic features are providing a more stable representation of a topic overtime.",
                    "label": 0
                },
                {
                    "sent": "Ugh.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we do, the average of.",
                    "label": 0
                },
                {
                    "sent": "Performance of these cross eyed book scenarios.",
                    "label": 0
                },
                {
                    "sent": "We found that for day three different topics the class feature was the one that consistently outperformed the.",
                    "label": 0
                },
                {
                    "sent": "The bag of words representation for different topics so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, we can conclude that the semantic features are much more slower to decade and lexical features, and that the semantic representation can improve performance in cross times at in scenarios.",
                    "label": 1
                },
                {
                    "sent": "And we also found out that the class feature can provide a more stable representation overtime, and that on average it has a gain of over 7%.",
                    "label": 0
                },
                {
                    "sent": "In performance.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our future work includes the study of concept drift tracking for transfer learning using linked data sources and the study cross app transfer learning approaches using semantic features.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do you have any questions?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Hi, I just wanted to ask you if you can very shortly explain the intuition behind the formula you show.",
                    "label": 0
                },
                {
                    "sent": "So this is a very basic formula But basically this this first section.",
                    "label": 0
                },
                {
                    "sent": "Then it's just a frequency with Laplace smoothing, so is counting how many times the feature is appearing on a trip.",
                    "label": 0
                },
                {
                    "sent": "But in this case, because it's a feature that is derived from the entities that are appearing on a tweet, that means that we were doing that.",
                    "label": 0
                },
                {
                    "sent": "So imagine if you have an in this case on the tweet that I was showing you have Egypt and you have Mubarak and then you have Obama.",
                    "label": 0
                },
                {
                    "sent": "So if in any of these features you were able to derive the resource al Qaeda.",
                    "label": 0
                },
                {
                    "sent": "Then that means that you are counting straight times because you were able to get to al Qaeda through these different 3 three entities.",
                    "label": 0
                },
                {
                    "sent": "So that counts arcada kind of three times within this first section, and then the second section is the weighting strategy.",
                    "label": 0
                },
                {
                    "sent": "So that is basically using in this case.",
                    "label": 0
                },
                {
                    "sent": "If it's resource we are using our resource strategy for waiting.",
                    "label": 0
                },
                {
                    "sent": "And basically here we are using a square root, which is basically kind of helping, helping you to boost the weight when the weight is very small.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "The square root of your points here one is 0.1 as your points here 2 is by point 1414 and so on.",
                    "label": 0
                },
                {
                    "sent": "So you are kind of boosting the part where the weight is very small, so so you are building your negative examples from all the other for the topic.",
                    "label": 0
                },
                {
                    "sent": "The other four topics, or three topics that you have.",
                    "label": 0
                },
                {
                    "sent": "And I was wondering whether you consider the possible semantic overlap between.",
                    "label": 0
                },
                {
                    "sent": "The topics that you are taking is negative examples and whether this actually biases your result.",
                    "label": 0
                },
                {
                    "sent": "So for example, here I was mentioning that we started to kind of filter on this one.",
                    "label": 0
                },
                {
                    "sent": "Million tweets from our data, first data set using open colors.",
                    "label": 0
                },
                {
                    "sent": "Open column gives you labels from 10 different categories which include these three ones that we're trying to model, plus also the ones like economic, sports, entertainment and so on.",
                    "label": 0
                },
                {
                    "sent": "So yes, it's true that you might have a entities relevant to, for example, Obama in the context of.",
                    "label": 0
                },
                {
                    "sent": "Economics for example.",
                    "label": 0
                },
                {
                    "sent": "But then when you go to the.",
                    "label": 0
                },
                {
                    "sent": "No, no, what do you say when you go to the semantic feature representation of Obama?",
                    "label": 0
                },
                {
                    "sent": "Here what we're doing with these strategies that we're introducing is we're filtering out features that are not relevant to that entity in a particular context, which means that we would be filtering out.",
                    "label": 0
                },
                {
                    "sent": "All the features that are not relevant in the context of violence.",
                    "label": 0
                },
                {
                    "sent": "So if we're if we're waiting.",
                    "label": 0
                },
                {
                    "sent": "To represent the topic.",
                    "label": 0
                },
                {
                    "sent": "Economics we will find.",
                    "label": 0
                },
                {
                    "sent": "That the representation of Obama will include different features that are related with politics.",
                    "label": 0
                },
                {
                    "sent": "Perhaps economics, maybe Nobel Prize, but those features are not representative of Obama in the context of violence.",
                    "label": 0
                },
                {
                    "sent": "So that's the way we're kind of.",
                    "label": 0
                },
                {
                    "sent": "Thank you once again, thanks.",
                    "label": 0
                }
            ]
        }
    }
}