{
    "id": "7r7x6tbgc2b6ov6rhq4qw6q7mzhgwvq2",
    "title": "Transfer Metric Learning by Learning Task Relationships",
    "info": {
        "author": [
            "Yu Zhang, The Hong Kong University of Science and Technology"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/kdd2010_zhang_tmlltr/",
    "segmentation": [
        [
            "So I'm John from Hong Kong University of Science and Technology.",
            "This is joint work with my supervisor, Divi Young.",
            "My talk is about transform metric learning by learning task relationship."
        ],
        [
            "So."
        ],
        [
            "Distance metric learning plan very important role in many data mining algorithms such as K means clustering can use neighbor classifiers.",
            "But when we just given only limited labeled data, the metric number is often unsatisfactory.",
            "So there are some solutions to deal with this situation.",
            "For example, one way is to utilize the information in the unlabeled data, which is same size metric learning.",
            "Another way is to utilize the information in other related tasks, which refers to the transfer metric learning.",
            "So in this paper we just focus on transfer metric learning."
        ],
        [
            "So what is transform transfer?",
            "Learning transfer learning is learning framework which wants to improve the performance of some target task with the help of other related task resource tasks.",
            "So in transfer learning the tasks are divided into two types, the target task and also the source task.",
            "So transfer learning is inspired by the human learning ability.",
            "For example, if you can ride bicycle, then the knowledge will transfer.",
            "Will help you to learn right that recycle."
        ],
        [
            "So for the transfer metric learning.",
            "There only one existing work which published in 2009, but this work has some limitations.",
            "For example, with only model the task positive task coordination and the optimizing problem is nonconvex.",
            "So in our paper, we propose a convex formulation for transform metric learning, and we can model the pairwise task relationships.",
            "Stone younger the convex recognition framework.",
            "So in our framework we can model the positive test, correlation, negative task and task unrelated in unified.",
            "My."
        ],
        [
            "So we first introduce a multi task matching learning which is useful for the transformer."
        ],
        [
            "So we assume we are given.",
            "I am learning tasks T1 to TM and the training set in the eyes task consists of NI data points XIGNYG.",
            "Here the superscript refers to the index of the task and subscripting refers to the instance index of each task.",
            "So we assume each data point.",
            "Nice seeing the dimension and each each cloud each learning task.",
            "It's just a multiclass classification problem."
        ],
        [
            "So the objective function for multi task metric learning is formed as this one.",
            "So the objective function has three parts.",
            "So for the first part these days just to measure the empirical loss.",
            "Here G is used.",
            "Is adopted as his loss here.",
            "The second part is to measure is recognizing term on each metric metric metric Sigma.",
            "I hear another term is to measure the task relationships based on tiled Sigma and Omega here.",
            "So Becausw on Sigma is metric metric, so there is a constraint on PST constraint on Sigma I.",
            "And styled Sigma is the big matrix.",
            "Each column of tiled Sigma related to the metric of each task.",
            "Becausw Omega here is defined as the task covariance matrix, so there is also a PSD metric PST constraint.",
            "And to prevent a degeneration solution of of Omega, we replace the constraint on the trace of the Omega here.",
            "So from the proper business view.",
            "So this object function is related to the map solution of public model.",
            "So the North is defined the knighthood.",
            "The the second part is defined a normal prior on each Sigma here and then.",
            "Last part is.",
            "Define matrix variate normal distribution.",
            "And in our paper we can prove this optimizing problem is a convex problem, so.",
            "We propose a alternating method to solve this problem, so the detailed optimization procedure is can be found in our paper."
        ],
        [
            "Then we will introduce the transfer metric learning."
        ],
        [
            "So in transfer metric name is, suppose we are given N minus one source tasks until 1 two team team Mimit strong and one target task TM.",
            "So we assume it starts Calvin update up neighbor data so we can then accurate model within without help of other source tasks.",
            "So we also assume the metric matrix Sigma.",
            "I has been learned independently."
        ],
        [
            "So based on the multi task metric learning we can format the objective function.",
            "Ask this one so this is to measure the empirical loss.",
            "This is the recognizing term to penalize the complexity of Sigma M. This is too long the task relationship.",
            "So different from the maultasch metric, learning that I'll damn here in is also a big matrix, but the first N -- 1 columns are given.",
            "So since we are now, we assume the source tasks are independent and of equal importance.",
            "So we can express Omega as block matrix.",
            "So from the block structure of Omega, so we can find the covariance between the source tasks is proposing to identity matrix and Omega M is to measure the.",
            "Task covariance between the source task and target task and Omega here is to measure the task variance of the target task."
        ],
        [
            "So similar to the multitask metric learning and we can also prove this problem is joint convex resolve variables, but it is not easy to optimize.",
            "This is not with respect to all variables simultaneously, so we still using an alternating method to solve it."
        ],
        [
            "In the first step we want to solve it as solve.",
            "So what we want to obtain the system.",
            "I am here so.",
            "The optimizing problem is similar to the recognizing distance metric learning method except and last term, so this term is to also empirical loss.",
            "This is recognizing term.",
            "And we similar to the recognize distance metric learning we using online algorithm to solve this problem."
        ],
        [
            "So this is a algorithm.",
            "Outlier for the this algorithm."
        ],
        [
            "So when.",
            "We solve with respect to the Omega.",
            "I am an Omega law original optimization problem is formed like this one.",
            "This problem is not very easy to solve things if they involve inverse of block matrix here.",
            "So we can reformulate as second order cone problem and then we can using standard solver to solve it."
        ],
        [
            "So for the experiments we compare with three baseline methods.",
            "My information theoretical metric learning recognizing distance metric.",
            "Learning these two methods are conventional magic learning methods and the only one existing transform transfer metric learning method LDL.",
            "So we're using the civic server and the learning rate.",
            "It are in.",
            "The online algorithm is set to be .01.",
            "So."
        ],
        [
            "The first application is the wine quality classification, so this is to classify one in two different queries from one to 10.",
            "There are two tasks, no one is for red wine classification, the other is for white wine classification.",
            "So in our experiment, each task is treated as a target.",
            "Ask another as source tasks.",
            "So we also we want to.",
            "We also want to see the effect of varying size or training set.",
            "So we just wearing the training data percentage from one 5% to 20% and each configuration just if it."
        ],
        [
            "10 times so this is.",
            "This is the experimental results.",
            "So the horizontal axis is the percentage of the training data set and the vertical axis is classification error and then left.",
            "Bigger is about the first task is corresponding to the first situation that the first task is used as the target task and the second task is used as the source task and then the next one is similar, right?",
            "One is similar, so from the results we can find our method is compatible in a better perform better than other methods."
        ],
        [
            "So on another application is just a handwritten letter classification and this application consists of seven tasks.",
            "So each task is binary classification problem to distinguish 2 letters.",
            "For example, the first task is to want to classify the letters into C or E in later and for each task we have.",
            "No, 1000 and 1000 positive and 1000 negative data points."
        ],
        [
            "So this is the experimental results in on the different situations.",
            "Find a job because find all method in some cases better than other methods and in some cases compatible with.",
            "Angle with existing website."
        ],
        [
            "So this is another application USPS digital classification.",
            "So each task in digital in this application is corresponding to classification or two successive digits."
        ],
        [
            "So this is the result."
        ],
        [
            "So in conclusion, on down we have proposed transfer metric learning, which is anyway to the neighbor data deficiency problem, and in our method the distance metric and the task relationship.",
            "Can be formed on the convex recognizing framework.",
            "In all future work we are interested in extending our method to satisfy setting by using some information contained in the unlabeled data.",
            "OK, thank you for a 10."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm John from Hong Kong University of Science and Technology.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with my supervisor, Divi Young.",
                    "label": 0
                },
                {
                    "sent": "My talk is about transform metric learning by learning task relationship.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distance metric learning plan very important role in many data mining algorithms such as K means clustering can use neighbor classifiers.",
                    "label": 1
                },
                {
                    "sent": "But when we just given only limited labeled data, the metric number is often unsatisfactory.",
                    "label": 1
                },
                {
                    "sent": "So there are some solutions to deal with this situation.",
                    "label": 1
                },
                {
                    "sent": "For example, one way is to utilize the information in the unlabeled data, which is same size metric learning.",
                    "label": 0
                },
                {
                    "sent": "Another way is to utilize the information in other related tasks, which refers to the transfer metric learning.",
                    "label": 0
                },
                {
                    "sent": "So in this paper we just focus on transfer metric learning.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is transform transfer?",
                    "label": 0
                },
                {
                    "sent": "Learning transfer learning is learning framework which wants to improve the performance of some target task with the help of other related task resource tasks.",
                    "label": 1
                },
                {
                    "sent": "So in transfer learning the tasks are divided into two types, the target task and also the source task.",
                    "label": 0
                },
                {
                    "sent": "So transfer learning is inspired by the human learning ability.",
                    "label": 0
                },
                {
                    "sent": "For example, if you can ride bicycle, then the knowledge will transfer.",
                    "label": 0
                },
                {
                    "sent": "Will help you to learn right that recycle.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the transfer metric learning.",
                    "label": 1
                },
                {
                    "sent": "There only one existing work which published in 2009, but this work has some limitations.",
                    "label": 0
                },
                {
                    "sent": "For example, with only model the task positive task coordination and the optimizing problem is nonconvex.",
                    "label": 0
                },
                {
                    "sent": "So in our paper, we propose a convex formulation for transform metric learning, and we can model the pairwise task relationships.",
                    "label": 1
                },
                {
                    "sent": "Stone younger the convex recognition framework.",
                    "label": 0
                },
                {
                    "sent": "So in our framework we can model the positive test, correlation, negative task and task unrelated in unified.",
                    "label": 0
                },
                {
                    "sent": "My.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we first introduce a multi task matching learning which is useful for the transformer.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we assume we are given.",
                    "label": 0
                },
                {
                    "sent": "I am learning tasks T1 to TM and the training set in the eyes task consists of NI data points XIGNYG.",
                    "label": 1
                },
                {
                    "sent": "Here the superscript refers to the index of the task and subscripting refers to the instance index of each task.",
                    "label": 0
                },
                {
                    "sent": "So we assume each data point.",
                    "label": 0
                },
                {
                    "sent": "Nice seeing the dimension and each each cloud each learning task.",
                    "label": 0
                },
                {
                    "sent": "It's just a multiclass classification problem.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the objective function for multi task metric learning is formed as this one.",
                    "label": 1
                },
                {
                    "sent": "So the objective function has three parts.",
                    "label": 0
                },
                {
                    "sent": "So for the first part these days just to measure the empirical loss.",
                    "label": 0
                },
                {
                    "sent": "Here G is used.",
                    "label": 0
                },
                {
                    "sent": "Is adopted as his loss here.",
                    "label": 0
                },
                {
                    "sent": "The second part is to measure is recognizing term on each metric metric metric Sigma.",
                    "label": 1
                },
                {
                    "sent": "I hear another term is to measure the task relationships based on tiled Sigma and Omega here.",
                    "label": 0
                },
                {
                    "sent": "So Becausw on Sigma is metric metric, so there is a constraint on PST constraint on Sigma I.",
                    "label": 0
                },
                {
                    "sent": "And styled Sigma is the big matrix.",
                    "label": 0
                },
                {
                    "sent": "Each column of tiled Sigma related to the metric of each task.",
                    "label": 0
                },
                {
                    "sent": "Becausw Omega here is defined as the task covariance matrix, so there is also a PSD metric PST constraint.",
                    "label": 0
                },
                {
                    "sent": "And to prevent a degeneration solution of of Omega, we replace the constraint on the trace of the Omega here.",
                    "label": 0
                },
                {
                    "sent": "So from the proper business view.",
                    "label": 0
                },
                {
                    "sent": "So this object function is related to the map solution of public model.",
                    "label": 0
                },
                {
                    "sent": "So the North is defined the knighthood.",
                    "label": 0
                },
                {
                    "sent": "The the second part is defined a normal prior on each Sigma here and then.",
                    "label": 0
                },
                {
                    "sent": "Last part is.",
                    "label": 1
                },
                {
                    "sent": "Define matrix variate normal distribution.",
                    "label": 0
                },
                {
                    "sent": "And in our paper we can prove this optimizing problem is a convex problem, so.",
                    "label": 0
                },
                {
                    "sent": "We propose a alternating method to solve this problem, so the detailed optimization procedure is can be found in our paper.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we will introduce the transfer metric learning.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in transfer metric name is, suppose we are given N minus one source tasks until 1 two team team Mimit strong and one target task TM.",
                    "label": 1
                },
                {
                    "sent": "So we assume it starts Calvin update up neighbor data so we can then accurate model within without help of other source tasks.",
                    "label": 0
                },
                {
                    "sent": "So we also assume the metric matrix Sigma.",
                    "label": 1
                },
                {
                    "sent": "I has been learned independently.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So based on the multi task metric learning we can format the objective function.",
                    "label": 1
                },
                {
                    "sent": "Ask this one so this is to measure the empirical loss.",
                    "label": 0
                },
                {
                    "sent": "This is the recognizing term to penalize the complexity of Sigma M. This is too long the task relationship.",
                    "label": 0
                },
                {
                    "sent": "So different from the maultasch metric, learning that I'll damn here in is also a big matrix, but the first N -- 1 columns are given.",
                    "label": 0
                },
                {
                    "sent": "So since we are now, we assume the source tasks are independent and of equal importance.",
                    "label": 1
                },
                {
                    "sent": "So we can express Omega as block matrix.",
                    "label": 0
                },
                {
                    "sent": "So from the block structure of Omega, so we can find the covariance between the source tasks is proposing to identity matrix and Omega M is to measure the.",
                    "label": 0
                },
                {
                    "sent": "Task covariance between the source task and target task and Omega here is to measure the task variance of the target task.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So similar to the multitask metric learning and we can also prove this problem is joint convex resolve variables, but it is not easy to optimize.",
                    "label": 0
                },
                {
                    "sent": "This is not with respect to all variables simultaneously, so we still using an alternating method to solve it.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the first step we want to solve it as solve.",
                    "label": 0
                },
                {
                    "sent": "So what we want to obtain the system.",
                    "label": 0
                },
                {
                    "sent": "I am here so.",
                    "label": 0
                },
                {
                    "sent": "The optimizing problem is similar to the recognizing distance metric learning method except and last term, so this term is to also empirical loss.",
                    "label": 0
                },
                {
                    "sent": "This is recognizing term.",
                    "label": 0
                },
                {
                    "sent": "And we similar to the recognize distance metric learning we using online algorithm to solve this problem.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a algorithm.",
                    "label": 0
                },
                {
                    "sent": "Outlier for the this algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when.",
                    "label": 0
                },
                {
                    "sent": "We solve with respect to the Omega.",
                    "label": 1
                },
                {
                    "sent": "I am an Omega law original optimization problem is formed like this one.",
                    "label": 0
                },
                {
                    "sent": "This problem is not very easy to solve things if they involve inverse of block matrix here.",
                    "label": 0
                },
                {
                    "sent": "So we can reformulate as second order cone problem and then we can using standard solver to solve it.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the experiments we compare with three baseline methods.",
                    "label": 1
                },
                {
                    "sent": "My information theoretical metric learning recognizing distance metric.",
                    "label": 1
                },
                {
                    "sent": "Learning these two methods are conventional magic learning methods and the only one existing transform transfer metric learning method LDL.",
                    "label": 1
                },
                {
                    "sent": "So we're using the civic server and the learning rate.",
                    "label": 0
                },
                {
                    "sent": "It are in.",
                    "label": 1
                },
                {
                    "sent": "The online algorithm is set to be .01.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first application is the wine quality classification, so this is to classify one in two different queries from one to 10.",
                    "label": 1
                },
                {
                    "sent": "There are two tasks, no one is for red wine classification, the other is for white wine classification.",
                    "label": 1
                },
                {
                    "sent": "So in our experiment, each task is treated as a target.",
                    "label": 1
                },
                {
                    "sent": "Ask another as source tasks.",
                    "label": 0
                },
                {
                    "sent": "So we also we want to.",
                    "label": 1
                },
                {
                    "sent": "We also want to see the effect of varying size or training set.",
                    "label": 0
                },
                {
                    "sent": "So we just wearing the training data percentage from one 5% to 20% and each configuration just if it.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "10 times so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the experimental results.",
                    "label": 0
                },
                {
                    "sent": "So the horizontal axis is the percentage of the training data set and the vertical axis is classification error and then left.",
                    "label": 0
                },
                {
                    "sent": "Bigger is about the first task is corresponding to the first situation that the first task is used as the target task and the second task is used as the source task and then the next one is similar, right?",
                    "label": 0
                },
                {
                    "sent": "One is similar, so from the results we can find our method is compatible in a better perform better than other methods.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So on another application is just a handwritten letter classification and this application consists of seven tasks.",
                    "label": 1
                },
                {
                    "sent": "So each task is binary classification problem to distinguish 2 letters.",
                    "label": 0
                },
                {
                    "sent": "For example, the first task is to want to classify the letters into C or E in later and for each task we have.",
                    "label": 0
                },
                {
                    "sent": "No, 1000 and 1000 positive and 1000 negative data points.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the experimental results in on the different situations.",
                    "label": 0
                },
                {
                    "sent": "Find a job because find all method in some cases better than other methods and in some cases compatible with.",
                    "label": 0
                },
                {
                    "sent": "Angle with existing website.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is another application USPS digital classification.",
                    "label": 0
                },
                {
                    "sent": "So each task in digital in this application is corresponding to classification or two successive digits.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the result.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, on down we have proposed transfer metric learning, which is anyway to the neighbor data deficiency problem, and in our method the distance metric and the task relationship.",
                    "label": 1
                },
                {
                    "sent": "Can be formed on the convex recognizing framework.",
                    "label": 0
                },
                {
                    "sent": "In all future work we are interested in extending our method to satisfy setting by using some information contained in the unlabeled data.",
                    "label": 1
                },
                {
                    "sent": "OK, thank you for a 10.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}