{
    "id": "4fjzm64b3xka5qqewnbeamohea55qlpx",
    "title": "Spot On: Action Localization from Pointly-Supervised Proposals",
    "info": {
        "author": [
            "Pascal Mettes, University of Amsterdam"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_mettes_action_localization/",
    "segmentation": [
        [
            "I want to discuss our work on actual localization."
        ],
        [
            "Where we're not only interested in specifying whether a certain action occurs in a video, but also we want to specify when and where they occur within the video by drawing a bounding box around action.",
            "If you look at."
        ],
        [
            "Current landscape of action localization.",
            "For a test video, what people typically do if they propose a set of action proposals in a video, or you can choose your own flavor, whether it be super forecastles, trajectories, tracking, detection, whatever you want, and they all yield the set of hypothesis and then given a trained classifier, we're going to select."
        ],
        [
            "The one that best represents the action.",
            "How do we go about training these things?",
            "Or current methods require that?"
        ],
        [
            "Owning books is annotated on every frame of every video.",
            "As annotation apriori.",
            "So there we have a precise location of of the action or.",
            "This creates in very small sparse datasets.",
            "But more importantly, also very short, so we make the problem very limited.",
            "Towards the end of the presentation I will discuss the new datasets which already much longer and therefore much more complex.",
            "But I first want to point out our main apophysis."
        ],
        [
            "Which is that?",
            "Training on these bounding boxes is not required.",
            "So these dense and very strict annotations are not required.",
            "It's our notion that training on proposals guided by a few points on the action is enough information to train classifiers that are effective well.",
            "Of course, being much faster to annotate."
        ],
        [
            "So how do we go about this?",
            "We start from point annotations on every video.",
            "Then we're going to introduce a new measure between points and proposals.",
            "Affinity measure of prior knowledge about these proposals, and in the end we're going to find the best proposal to train our classifier on."
        ],
        [
            "I want to 1st talk about this this mining procedure which can be cast as a form of multiple instance learning.",
            "So what do we want?",
            "We want a classifier trained on the best proposals for each video.",
            "Typically there's a block gradient descent optimization where first we fixed the classifier select the best proposal and we would vice versa.",
            "So we fixed the proposal selection.",
            "We're going to train the classifier or in our case that's not enough information.",
            "We're going to need something extra to make it as effective."
        ],
        [
            "Training on these bounding boxes, so we're going to do is we're going to add some extra information.",
            "Few point annotations on the video.",
            "Which provides some prior quality of the proposals.",
            "And during our optimization, when we select the best proposals, we change from maximum likelihoods, selecting using best classifier to a maximum posteriori where we include this prior knowledge from the points.",
            "And the main."
        ],
        [
            "Challenge we have left this.",
            "How do we compute this overlap?",
            "Inherently this is Anil defined problem because action proposal these tubes through space and time while points have only a spatial location but not a spatial extent.",
            "What's our notion that given a proposal in a set of points?",
            "The the point should go through the center of the proposal.",
            "So if you have example on the left here at the tube goes through another part of the video and we're not interested in the middle one.",
            "Well, the points are on the proposal, but not near the center, so small overlap in the more the centers align, the better it is for us."
        ],
        [
            "So overall, this equation looks as follows.",
            "We simply have a match between proposals and points.",
            "And we have to add some regularization so first."
        ],
        [
            "The match.",
            "Few more details.",
            "So for every point we're going to look at the books of the proposal in the same frame.",
            "If the box is outside, if the point is outside the box, no match.",
            "And if it's insight if it's under center, it's a match of 1 and we have a linear decreasing score.",
            "The more you go towards the edge of the of the box, we simply compute this score for every point, average them, and we have a match between points and proposal.",
            "One problem though."
        ],
        [
            "Actions tend to happen in the center of the action of the video.",
            "And the same holds for very large proposal.",
            "So proposal that take up most of the video.",
            "Are very very, very big and their sensors are also then in the center of the video.",
            "So we simply add a regularization term that says we subtract the square of the relative size of the proposal from this from this match.",
            "To alleviate this center bias of proposals."
        ],
        [
            "To recap, optimization simply selects the best proposal to train on unsupervised proposals, and we're going to include these scores.",
            "We compute before hand for every proposal as extra information.",
            "To train your classifiers.",
            "So it's quite a big step."
        ],
        [
            "We're going from very dense, incorrect bounding boxes to unsupervised proposals, and the question is can we maintain performance simply by having sparse point annotations?",
            "And Furthermore, how much speedup the weekend?",
            "So we did experiments on two datasets.",
            "And we took Standard state of the art unsupervised method, so no supervision in the proposal step.",
            "And the first."
        ],
        [
            "Question we want to answer it.",
            "Is this step to watch proposals viable one.",
            "So we took the best possible proposal.",
            "So in upper bounds, and we compared it to training underground truth directly.",
            "So this as you see overlap thresholds on the.",
            "On the X axis, which means the match between proposals and ground truth.",
            "During testing.",
            "If you look at the standard overlap threshold 0.2 indeed roughly aligns.",
            "I'll"
        ],
        [
            "For us, it's holds across all overlap threshold, so indeed it is possible to train on proposals and be as effective.",
            "We have additional constraints.",
            "We don't.",
            "We just want to have been guided by a few points.",
            "So what happens if we move to watch mining on proposals with a few points annotations?"
        ],
        [
            "And across all operations, we see that the performance is maintained.",
            "Just because they are similar performance doesn't mean they're from the same tubes."
        ],
        [
            "On the left is seen example.",
            "If there's static backgrounds, indeed, you're going to have roughly the same locations you're going to rain, so that one is the usual annotated ground truth and the blue one is the proposal that we've been using for training.",
            "Doesn't always need to be the case.",
            "Example on the right is one of a horse where the human annotator drawing books only around the human or in our case you only have points, so we don't know the spatial extents.",
            "And of course, within a classifier found out that's having this worse information is very, very useful, so it's a bit bigger.",
            "So it's not because they have the same precise locations.",
            "OK."
        ],
        [
            "Now we know we can get the same performance.",
            "What do we get in speed?",
            "So we didn't experiment where we compared the annotation speed up compared to annotating all bounding boxes versus the performance.",
            "As you see on these axis.",
            "So the grey dot is annotating every books.",
            "Of course, speed up one, and we're roughly 15 times faster if we just draw a point on every frame.",
            "However, in our method is not required that we draw every on every frame just video.",
            "Simply computer score for every point that has been annotated, and then we average them.",
            "So what happens if we just start analyzing less frames?"
        ],
        [
            "As you can see, we can retain performance for quite a long time, actually, roughly.",
            "Potential we skipped roughly 90 percent.",
            "90% of the frames.",
            "We still maintain performance.",
            "Which means we can get a speedup almost 50 times simply by once every 10th frame drawing a point.",
            "Well, this is for one data set for one thresholds."
        ],
        [
            "Luckily for us, this holds across all datasets and thresholds, so we can conclude from these experiments that we can first of all be as effective as drawing on bounding boxes.",
            "With just a few sparse point annotations about achieving a speedup of roughly 50 times.",
            "To demonstrate."
        ],
        [
            "How easy it becomes to create a new data set with a few points annotations.",
            "We took the videos from a Hollywood 2 datasets.",
            "Normally used for action classification.",
            "An we started integrating them, so this is an example from the test sets where we do need bounding boxes in this data set contains a number of actions and instances that are very challenging for action localization.",
            "First of all, there much longer to showed before.",
            "We also have multi label videos, so different actions within the same same video actions defined by context.",
            "So we see here driving a car which in terms of action not much happening.",
            "For example, also group interactions.",
            "And if you plug this."
        ],
        [
            "Proposal methods the standard proposals on this data set we see.",
            "That performance is not as good.",
            "This is the best possible action overall which at higher overlap threshold is already quite problematic.",
            "So fighting a person which typically take a large part of the of the video in Hollywood movies.",
            "This is an example of the worst."
        ],
        [
            "Possible action getting out of a car which you can see is very low thresholds already going towards 0 which is not so surprising because they are very short actions, so it's very hard to localize them.",
            "And also there how you define by contexts.",
            "So if you just are you standing up or getting out of a card predefined so on, what kind of context you are in.",
            "Plus there's some occlusion going on.",
            "And overall we can see."
        ],
        [
            "That, across all actions, that performance is very low, which means there's a lot of stuff still for us to do, so moving towards these large videos, more challenging datasets means that in action localization there's a lot of stuff for us to do.",
            "Overall to conclude."
        ],
        [
            "Our main point is that we don't need bounding boxes to train our classifiers.",
            "If we just take unsupervised proposals and we guide them by a few points annotations, we can train classifiers that are as effective or being much faster.",
            "For human annotators, we have a new data set that corroborates this, so we can move on with this.",
            "It is online.",
            "Maybe it's better to post or we can.",
            "I have the link so you can.",
            "You can come in for downloads.",
            "That is it.",
            "Thank you guys."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to discuss our work on actual localization.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where we're not only interested in specifying whether a certain action occurs in a video, but also we want to specify when and where they occur within the video by drawing a bounding box around action.",
                    "label": 0
                },
                {
                    "sent": "If you look at.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Current landscape of action localization.",
                    "label": 0
                },
                {
                    "sent": "For a test video, what people typically do if they propose a set of action proposals in a video, or you can choose your own flavor, whether it be super forecastles, trajectories, tracking, detection, whatever you want, and they all yield the set of hypothesis and then given a trained classifier, we're going to select.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The one that best represents the action.",
                    "label": 0
                },
                {
                    "sent": "How do we go about training these things?",
                    "label": 0
                },
                {
                    "sent": "Or current methods require that?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Owning books is annotated on every frame of every video.",
                    "label": 1
                },
                {
                    "sent": "As annotation apriori.",
                    "label": 0
                },
                {
                    "sent": "So there we have a precise location of of the action or.",
                    "label": 0
                },
                {
                    "sent": "This creates in very small sparse datasets.",
                    "label": 0
                },
                {
                    "sent": "But more importantly, also very short, so we make the problem very limited.",
                    "label": 0
                },
                {
                    "sent": "Towards the end of the presentation I will discuss the new datasets which already much longer and therefore much more complex.",
                    "label": 0
                },
                {
                    "sent": "But I first want to point out our main apophysis.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is that?",
                    "label": 0
                },
                {
                    "sent": "Training on these bounding boxes is not required.",
                    "label": 1
                },
                {
                    "sent": "So these dense and very strict annotations are not required.",
                    "label": 0
                },
                {
                    "sent": "It's our notion that training on proposals guided by a few points on the action is enough information to train classifiers that are effective well.",
                    "label": 0
                },
                {
                    "sent": "Of course, being much faster to annotate.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we go about this?",
                    "label": 0
                },
                {
                    "sent": "We start from point annotations on every video.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to introduce a new measure between points and proposals.",
                    "label": 0
                },
                {
                    "sent": "Affinity measure of prior knowledge about these proposals, and in the end we're going to find the best proposal to train our classifier on.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to 1st talk about this this mining procedure which can be cast as a form of multiple instance learning.",
                    "label": 1
                },
                {
                    "sent": "So what do we want?",
                    "label": 1
                },
                {
                    "sent": "We want a classifier trained on the best proposals for each video.",
                    "label": 0
                },
                {
                    "sent": "Typically there's a block gradient descent optimization where first we fixed the classifier select the best proposal and we would vice versa.",
                    "label": 0
                },
                {
                    "sent": "So we fixed the proposal selection.",
                    "label": 0
                },
                {
                    "sent": "We're going to train the classifier or in our case that's not enough information.",
                    "label": 0
                },
                {
                    "sent": "We're going to need something extra to make it as effective.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Training on these bounding boxes, so we're going to do is we're going to add some extra information.",
                    "label": 0
                },
                {
                    "sent": "Few point annotations on the video.",
                    "label": 1
                },
                {
                    "sent": "Which provides some prior quality of the proposals.",
                    "label": 0
                },
                {
                    "sent": "And during our optimization, when we select the best proposals, we change from maximum likelihoods, selecting using best classifier to a maximum posteriori where we include this prior knowledge from the points.",
                    "label": 1
                },
                {
                    "sent": "And the main.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Challenge we have left this.",
                    "label": 0
                },
                {
                    "sent": "How do we compute this overlap?",
                    "label": 0
                },
                {
                    "sent": "Inherently this is Anil defined problem because action proposal these tubes through space and time while points have only a spatial location but not a spatial extent.",
                    "label": 0
                },
                {
                    "sent": "What's our notion that given a proposal in a set of points?",
                    "label": 0
                },
                {
                    "sent": "The the point should go through the center of the proposal.",
                    "label": 0
                },
                {
                    "sent": "So if you have example on the left here at the tube goes through another part of the video and we're not interested in the middle one.",
                    "label": 0
                },
                {
                    "sent": "Well, the points are on the proposal, but not near the center, so small overlap in the more the centers align, the better it is for us.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So overall, this equation looks as follows.",
                    "label": 0
                },
                {
                    "sent": "We simply have a match between proposals and points.",
                    "label": 0
                },
                {
                    "sent": "And we have to add some regularization so first.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The match.",
                    "label": 0
                },
                {
                    "sent": "Few more details.",
                    "label": 0
                },
                {
                    "sent": "So for every point we're going to look at the books of the proposal in the same frame.",
                    "label": 1
                },
                {
                    "sent": "If the box is outside, if the point is outside the box, no match.",
                    "label": 0
                },
                {
                    "sent": "And if it's insight if it's under center, it's a match of 1 and we have a linear decreasing score.",
                    "label": 0
                },
                {
                    "sent": "The more you go towards the edge of the of the box, we simply compute this score for every point, average them, and we have a match between points and proposal.",
                    "label": 0
                },
                {
                    "sent": "One problem though.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actions tend to happen in the center of the action of the video.",
                    "label": 0
                },
                {
                    "sent": "And the same holds for very large proposal.",
                    "label": 0
                },
                {
                    "sent": "So proposal that take up most of the video.",
                    "label": 0
                },
                {
                    "sent": "Are very very, very big and their sensors are also then in the center of the video.",
                    "label": 0
                },
                {
                    "sent": "So we simply add a regularization term that says we subtract the square of the relative size of the proposal from this from this match.",
                    "label": 1
                },
                {
                    "sent": "To alleviate this center bias of proposals.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To recap, optimization simply selects the best proposal to train on unsupervised proposals, and we're going to include these scores.",
                    "label": 0
                },
                {
                    "sent": "We compute before hand for every proposal as extra information.",
                    "label": 0
                },
                {
                    "sent": "To train your classifiers.",
                    "label": 0
                },
                {
                    "sent": "So it's quite a big step.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're going from very dense, incorrect bounding boxes to unsupervised proposals, and the question is can we maintain performance simply by having sparse point annotations?",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, how much speedup the weekend?",
                    "label": 0
                },
                {
                    "sent": "So we did experiments on two datasets.",
                    "label": 0
                },
                {
                    "sent": "And we took Standard state of the art unsupervised method, so no supervision in the proposal step.",
                    "label": 0
                },
                {
                    "sent": "And the first.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Question we want to answer it.",
                    "label": 0
                },
                {
                    "sent": "Is this step to watch proposals viable one.",
                    "label": 0
                },
                {
                    "sent": "So we took the best possible proposal.",
                    "label": 1
                },
                {
                    "sent": "So in upper bounds, and we compared it to training underground truth directly.",
                    "label": 0
                },
                {
                    "sent": "So this as you see overlap thresholds on the.",
                    "label": 0
                },
                {
                    "sent": "On the X axis, which means the match between proposals and ground truth.",
                    "label": 0
                },
                {
                    "sent": "During testing.",
                    "label": 0
                },
                {
                    "sent": "If you look at the standard overlap threshold 0.2 indeed roughly aligns.",
                    "label": 0
                },
                {
                    "sent": "I'll",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For us, it's holds across all overlap threshold, so indeed it is possible to train on proposals and be as effective.",
                    "label": 0
                },
                {
                    "sent": "We have additional constraints.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We just want to have been guided by a few points.",
                    "label": 0
                },
                {
                    "sent": "So what happens if we move to watch mining on proposals with a few points annotations?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And across all operations, we see that the performance is maintained.",
                    "label": 0
                },
                {
                    "sent": "Just because they are similar performance doesn't mean they're from the same tubes.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the left is seen example.",
                    "label": 0
                },
                {
                    "sent": "If there's static backgrounds, indeed, you're going to have roughly the same locations you're going to rain, so that one is the usual annotated ground truth and the blue one is the proposal that we've been using for training.",
                    "label": 0
                },
                {
                    "sent": "Doesn't always need to be the case.",
                    "label": 0
                },
                {
                    "sent": "Example on the right is one of a horse where the human annotator drawing books only around the human or in our case you only have points, so we don't know the spatial extents.",
                    "label": 0
                },
                {
                    "sent": "And of course, within a classifier found out that's having this worse information is very, very useful, so it's a bit bigger.",
                    "label": 0
                },
                {
                    "sent": "So it's not because they have the same precise locations.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we know we can get the same performance.",
                    "label": 0
                },
                {
                    "sent": "What do we get in speed?",
                    "label": 0
                },
                {
                    "sent": "So we didn't experiment where we compared the annotation speed up compared to annotating all bounding boxes versus the performance.",
                    "label": 1
                },
                {
                    "sent": "As you see on these axis.",
                    "label": 0
                },
                {
                    "sent": "So the grey dot is annotating every books.",
                    "label": 0
                },
                {
                    "sent": "Of course, speed up one, and we're roughly 15 times faster if we just draw a point on every frame.",
                    "label": 0
                },
                {
                    "sent": "However, in our method is not required that we draw every on every frame just video.",
                    "label": 0
                },
                {
                    "sent": "Simply computer score for every point that has been annotated, and then we average them.",
                    "label": 0
                },
                {
                    "sent": "So what happens if we just start analyzing less frames?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As you can see, we can retain performance for quite a long time, actually, roughly.",
                    "label": 0
                },
                {
                    "sent": "Potential we skipped roughly 90 percent.",
                    "label": 0
                },
                {
                    "sent": "90% of the frames.",
                    "label": 0
                },
                {
                    "sent": "We still maintain performance.",
                    "label": 0
                },
                {
                    "sent": "Which means we can get a speedup almost 50 times simply by once every 10th frame drawing a point.",
                    "label": 1
                },
                {
                    "sent": "Well, this is for one data set for one thresholds.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Luckily for us, this holds across all datasets and thresholds, so we can conclude from these experiments that we can first of all be as effective as drawing on bounding boxes.",
                    "label": 0
                },
                {
                    "sent": "With just a few sparse point annotations about achieving a speedup of roughly 50 times.",
                    "label": 0
                },
                {
                    "sent": "To demonstrate.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How easy it becomes to create a new data set with a few points annotations.",
                    "label": 1
                },
                {
                    "sent": "We took the videos from a Hollywood 2 datasets.",
                    "label": 1
                },
                {
                    "sent": "Normally used for action classification.",
                    "label": 0
                },
                {
                    "sent": "An we started integrating them, so this is an example from the test sets where we do need bounding boxes in this data set contains a number of actions and instances that are very challenging for action localization.",
                    "label": 1
                },
                {
                    "sent": "First of all, there much longer to showed before.",
                    "label": 0
                },
                {
                    "sent": "We also have multi label videos, so different actions within the same same video actions defined by context.",
                    "label": 0
                },
                {
                    "sent": "So we see here driving a car which in terms of action not much happening.",
                    "label": 1
                },
                {
                    "sent": "For example, also group interactions.",
                    "label": 0
                },
                {
                    "sent": "And if you plug this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proposal methods the standard proposals on this data set we see.",
                    "label": 0
                },
                {
                    "sent": "That performance is not as good.",
                    "label": 0
                },
                {
                    "sent": "This is the best possible action overall which at higher overlap threshold is already quite problematic.",
                    "label": 0
                },
                {
                    "sent": "So fighting a person which typically take a large part of the of the video in Hollywood movies.",
                    "label": 0
                },
                {
                    "sent": "This is an example of the worst.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Possible action getting out of a car which you can see is very low thresholds already going towards 0 which is not so surprising because they are very short actions, so it's very hard to localize them.",
                    "label": 0
                },
                {
                    "sent": "And also there how you define by contexts.",
                    "label": 0
                },
                {
                    "sent": "So if you just are you standing up or getting out of a card predefined so on, what kind of context you are in.",
                    "label": 0
                },
                {
                    "sent": "Plus there's some occlusion going on.",
                    "label": 0
                },
                {
                    "sent": "And overall we can see.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That, across all actions, that performance is very low, which means there's a lot of stuff still for us to do, so moving towards these large videos, more challenging datasets means that in action localization there's a lot of stuff for us to do.",
                    "label": 0
                },
                {
                    "sent": "Overall to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our main point is that we don't need bounding boxes to train our classifiers.",
                    "label": 0
                },
                {
                    "sent": "If we just take unsupervised proposals and we guide them by a few points annotations, we can train classifiers that are as effective or being much faster.",
                    "label": 1
                },
                {
                    "sent": "For human annotators, we have a new data set that corroborates this, so we can move on with this.",
                    "label": 0
                },
                {
                    "sent": "It is online.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's better to post or we can.",
                    "label": 0
                },
                {
                    "sent": "I have the link so you can.",
                    "label": 0
                },
                {
                    "sent": "You can come in for downloads.",
                    "label": 0
                },
                {
                    "sent": "That is it.",
                    "label": 0
                },
                {
                    "sent": "Thank you guys.",
                    "label": 0
                }
            ]
        }
    }
}