{
    "id": "5kyqkmfzbiuhnbowlr64vuahmurtucak",
    "title": "Poster Spotlights",
    "info": {
        "author": [
            "Gang Wang, Shanghai Jiao Tong University",
            "Aleix M. Martinez, Department of Electrical and Computer Engineering, Ohio State University",
            "Andrea Vedaldi, Department of Engineering Science, University of Oxford",
            "Minwoo Park, Department of Computer Science and Engineering, Pennsylvania State University",
            "Shenghua Gao, Nanyang Technological University",
            "Shuicheng Yan, Department of Electrical and Computer Engineering, National University of Singapore",
            "Amir Saffari, Institute of Computer Graphics and Vision, Graz University of Technology",
            "Fei Wu, Microsoft Research Asia, Microsoft Research",
            "Tat-Jun Chin, School of Computer Science, University of Adelaide",
            "Fabrice Michel, \u00c9cole Centrale Paris",
            "Karim T. Abou-Moustafa, Department of Electrical and Computer Engineering, McGill University",
            "Alex Shyr, Department of Electrical Engineering and Computer Sciences, UC Berkeley",
            "Jia-Bin Huang, Department of Electrical Engineering and Computer Science, University of California Merced"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_spotlights11/",
    "segmentation": [
        [
            "Hello I'm going privacy so I've been told you so worker using opportune similarity for English with fewer noting examples.",
            "This is with David full size that direct Hoyle."
        ],
        [
            "It seems that the humans can do English with a few of those examples because there is a lot of other information that can be used to help identify objects.",
            "So one very important, similar, but even accusing the similarity so many people may have this in the animal server before.",
            "But if their total that it's more similar to an airport and CAD, then two other categories like Person Peak, so they are very likely to identify the throw instances from test images.",
            "So in the paper we exploit such similarity statements in a computational framework, so we trained up your classifiers.",
            "We first classifiers to respond most strongly to the examples from the similar categories.",
            "Examples from the December categories.",
            "So in this way we can learn from fuel training examples.",
            "We also experimentally show that the all measured achieves better object classifiers that method without using any similarity information.",
            "Please visit our poster for more details, thanks.",
            "Alright, this allows Martinez from the heist."
        ],
        [
            "University and this is work with my student du who unfortunately couldn't make it here today."
        ],
        [
            "The paper deals with finding a subspace that gives you the base optimal representation for discrimination, and as you will know, the famous linear discriminant analysis originally proposed by Fisher in the 30s gives the base optimal solution for the two class problem and when these two classes have the same covariance matrix which is known as homoscedastic distributions, in 2008 under him sishyan I proposed a solution for the C class problem for the C Class homoscedastic problem.",
            "And that was in Pammy 08 this paper here what we're proposing at a solution for the C Class HETEROSCEDASTIC solution, meaning the coverage metrics do not need to be the same, and the way we solve this is by defining a base error function or an approximation.",
            "I should say after base error function in the original space, calculating how this function should be calculated in the kernel space and that minimize that function using.",
            "Agreed in the sand, we showed that the function is convex and therefore you can get the global minimum of this solution, giving you the best optimal solution for C classes with different convention messages.",
            "Thank you."
        ],
        [
            "Hello, I'm interested in presenting a work in collaboration with Android System and."
        ],
        [
            "OK, thank you.",
            "So SVM classifiers that use kernel, such as an intersection K squared Jensen, Shannon.",
            "Well, they're very popular because they are very accurate and at the same time they're very fast to test.",
            "However, training them is not as fast, because you still have to rely to nonlinear SVM solvers.",
            "Instead, linear SVM's are much better in this sense.",
            "So what can you do about it?",
            "Well, you might know that all positive definite kernels are actually can actually be seen as we're kernels into an appropriate feature space.",
            "So assuming that you can compute the feature map, then you should be able to still use your fast linear solvers instead.",
            "So the contribution of this work is to show that for this important class of kernels, including Jensen, Shannon, Square intersection, and so on, it is actually possible to compute feature Maps in close form.",
            "Not only this, but it is also possible to find approximations which are very efficient, very low dimensional, very fast to compute.",
            "So my take home message here is that if you want to train say, a chi square SVM, there is no need to use your slow nonlinear SVM solver anymore.",
            "What you can do is instead download our bill fit toolbox, process your data by using one model instruction, and then run your fast and large scale SVM solver instead.",
            "So we want to know more details how this is possible.",
            "Please come to see my poster.",
            "Thank you."
        ],
        [
            "Hi, I'm in a park.",
            "This is joint work with so much cash app and my advisor Doctor Robert Collins and."
        ],
        [
            "Still you.",
            "We introduce a novel method for map estimation in continuous, longer Chanel reps. We call this data driven mean ship propagation or DSP people showed with the aid of scale space theory optimization becomes less sensitive to the local Maxima.",
            "Theoretically, we have proven that iterations of GDM, SBP, follow the gradient descent directions of the joint density in Goshen reps and computation time can be made by linear in the number of nodes.",
            "And samples when pairwise potentials are Gaussian and in this case our approach has the same component condition as Gaussian BP.",
            "And actually there's a typo in here the the covariance should be red inverse covariance to provide practical justification, we run GDM SPP.",
            "On simulations on Goshen continuous MRF and show its various performance to the state of the art algorithm in terms of accuracy and speed and application on 3D problem.",
            "Name is restoration confirms that DMSVP is faster and more accurate than the previous state of the art algorithm.",
            "So you at our poster section, there is basement HA."
        ],
        [
            "Good afternoon everyone.",
            "I'm Supergirl.",
            "From NTU Singapore.",
            "My paper title is local.",
            "Features are not only applies in sparse coding for image classification."
        ],
        [
            "Special coding has shown its state of the art performance for image for future conversation in backward model.",
            "However, in sparse coding, features are dealt separately, so the similarity between local features are lost.",
            "To preserve similarity, we add sparse constraint to the objective.",
            "Other similarity laugh, laughing.",
            "Constraint to the objective of sparse coding and our method can preserve similarity between local features.",
            "Our measure exactly exhibits excellent performance on publicly available datasets contribution our paper can be summarized as follows.",
            "We propose a new sparse coding framework for future colonization and similar, and the similarity between local features can be kept.",
            "Feature condensation can also be increased.",
            "He created our method, enhance the robustness of sparse coding.",
            "If you want to know more details, come to my poster, thank you."
        ],
        [
            "Hello everyone, my name is Sunshine from National University of Singapore.",
            "This is joint work with my supervisor situation in until song."
        ],
        [
            "Traditionally, data is open in classification task, data is open, the composed by nonnegative matrix factorization for dimension reduction purpose.",
            "Before going through a classifier.",
            "In this work, we propose a novel formulation to learn multiclass classifier directly through supervised non negative matrix factorization process in the formulation and the data matrix decomposed as product the product over.",
            "Non active basis matrix and Co.",
            "Efficient matrix the the basis matrix is learned super wisely so that it can be further decomposed as some common basis and settled class specific basis and the coalition vector of each data is assumed to be transferred from a map kernel space under the L2 norm of the class space.",
            "Specific coefficient reviews the relative competence of each class.",
            "So that it naturally resulting classifier our experiments on face recognition had post estimation and digital recognition shows the effectiveness of our method.",
            "Thank you very much and welcome to our question."
        ],
        [
            "So good afternoon, ladies and gentlemen.",
            "My name is Amir Safari and with my colleagues from grad school rituals technology, we're presenting our paper titled Online Multiclass LP Boost."
        ],
        [
            "So the good news about paper is that in this work we propose a system that works well in practice.",
            "The bad news is that we don't have a single poster, so this is all you're going to get from our paper.",
            "So in many applications in vision, online learning is necessary.",
            "For example, when you deal with large scale datasets or when you.",
            "For example, do object tracking music data comes over time and then you have to do an online learning step.",
            "So many of the algorithms that exist for online learning in fact focus on binary problems.",
            "So in this work we extend the LP Boost, which is linear programming boosting algorithm to be able to work with on line and multiclass data.",
            "In order to do that, we propose an efficient primal dual algorithm which allows us to access both primal variables, which are the weights of the weak learners and.",
            "Do all variables which are the rates of examples at the same time, so we apply our algorithm to Veritiv tasks such as object, category, conclusion or object tracking for both single and multi target and in fact also introduced tracking with ritual classes for binary classifier binary tracking problems which increases the robustness.",
            "You don't see it here, but you have also code online which you could easily get an try out yourself.",
            "The algorithm problem.",
            "You guess that I was lying about the single poster thing at the beginning, but in fact we have two posters and one poster, so you couldn't come to our host around and I'll give you more details.",
            "Thank you."
        ],
        [
            "Hello everyone, my name is Phil from the young University.",
            "This is joint work by Professor.",
            "Rating John at John University and professor switching year in USA."
        ],
        [
            "The motivation of our paper is how to perform image classification by a physically interpretable approach.",
            "In order to achieve this goal, our proposed approach consists of three step at the 1st.",
            "At the first step, given one of text image for classification and the number of class we train the regression model for each class in order to make the regression model.",
            "More interpretable, or we end both L1 norm and non negative constraint into the regression coefficients.",
            "This step we called Kurds records means we train different regression model independently.",
            "At the second step we can buy all of trained regression model together and we also and one normal and non active content into the new regression model.",
            "This step we will call the Kurds.",
            "We at the next step we can classify the text image into suitable good class based on the sparse core inflation's.",
            "The advantage of this approach is integration of supervised learning, sparse coding and non negative matrix decomposition.",
            "Together we compare our approach with traditional Nassau and goodness or this.",
            "This approach will achieve better results.",
            "For more detail, please go into our people.",
            "Thank you."
        ],
        [
            "Hi good afternoon everyone.",
            "My name is touch and Gene as you can see there.",
            "So the general problem we try."
        ],
        [
            "To tackle in North Paper is fitting multiple instances of a geometric model, also called structures, into noisy data.",
            "The specific question we ask in this paper is how many structures do we have in the data.",
            "So for example, in the problem of multiple emotions segmentation we would like to know how many emotions do we have in the observation matrix.",
            "So this is, this question sounds very simple, but deceptively.",
            "It's a deceptively very difficult problem.",
            "An hour approach begins by over segmenting the data into.",
            "Many classes, and then we optimize discriminative kernels pairwise between all clusters in a data.",
            "This is used to drive an accurate multi structure model selection scheme whereby the output just tells us the estimate of the number of structures existing in a data.",
            "If you're interested to drop by the poster and I'll be happy to describe everything in detail so you."
        ],
        [
            "Hello everyone I am fabulous Michelle.",
            "I'm presenting you today, joint work between technical and in this actually on data Fusion through cross."
        ],
        [
            "Parity metric learning in a wide range of application one encounters the problem of comparing data coming from different modalities, different representations or different versions.",
            "In an image retrieval, there are often situations where we need to query a new version of an image descriptor in an old version database.",
            "In medical applications, as you can see on the upper left.",
            "Various image imaging modalities provide different information about the tissues.",
            "Fusion of such information requires performing multimodal image alignment whose core is measuring similarity between local batches of multimodal Lee majors.",
            "In many cases, multimodal data are different in the dimensions structure an statistiques.",
            "So the problem is very challenging re propose on the upper right.",
            "A multimodal metric learning framework based on the embedding of multimodal data into a common metric space seeking to preserve known similarity relations on the training set.",
            "A particular choice of the Hamming space results in the multimale similarity sensitive hashing where similar data points are likely to collide.",
            "We are excited about different users of multiple metric learning.",
            "Come to our poster in H14 to see how it works and to discuss different applications."
        ],
        [
            "Good afternoon, I'm Kareem Abu Mustafa from McGill University.",
            "This is a joint work with Fernando de la Torre from."
        ],
        [
            "Here we address the masking problem in the multiclass setting of discriminate analysis.",
            "This problem occurs when one of the classes are far away from all other classes in the input space.",
            "In terms of care divergent in the projected, while all other classes are relatively close to each other in the projected low dimensional subspace, the distant class gets even further while nearby classes get even closer and closer.",
            "As we've shown our paper, this is due to the formulation of current DNA techniques that encourage maximizing the largest scale divergent among all other classes.",
            "What we are proposing here is to simultaneously maximize the care diversions between all pairs of classes.",
            "However, this creates an optimization problem.",
            "Position problem with more than one objective function that needs to be simultaneously maximized as well.",
            "The optimal solution in this case is the one that has maximal agreement between all possibly conflicting objective functions, and this is known to be Pareto optimal.",
            "If you are interested in more details, you are invited to read our paper, or you can join us for poster at 15 H. Thank you."
        ],
        [
            "Everybody, my name is Alex here.",
            "This work is an sufficient dimension reduction on sequence classification and this is joint work with Professor Tyson and Fasten My Jordan."
        ],
        [
            "Um?",
            "So are the tasks that we care about is sequence classification and we're taking a dimensionality reduction approach.",
            "As the title suggests, we're using SDR or sufficient dimension reduction.",
            "The framework which tries to find a latent space Z such that given this lens space, your data, why is conditionally independent to your data labels, labels Y and then data X labels.",
            "Why data access and then?",
            "A specific instance of STR kernel dimension reduction or KDR characterizes this conditional independence by minimizing the trace of the cross covariance operator, resulting in that final objective function.",
            "This approach has two main advantages.",
            "One is supervised and two.",
            "It doesn't impose any assumption on the data distribution, so the problem now becomes how to build kernel so that we can classify sequences so extend.",
            "KTR to the temporal domain in two ways.",
            "One is 2.",
            "Via kernel design.",
            "So engineer multiple kernel are based on observation dynamics and the face formation, which is useful in periodic motion.",
            "The second approach is through dynamic time warping and we infuse this alignment information into the kernel in those two ways.",
            "And finally, we demonstrate effectiveness of our approach on four different datasets.",
            "Come to our poster."
        ],
        [
            "Hello everyone, my name is dropping hunt.",
            "This is joint work with mention young at the University of California Merced.",
            "So sparse."
        ],
        [
            "Presentation has wide range of applications, so sparse coding is at the core of the at the core of the sparse modeling of signals it is shown that one minimization can recover the true sparse sparse solution of the linear system.",
            "However, the computational load is still high, so so we propose a method that, without without, without design, instead of designing a sparse coding algorithm, we.",
            "Is that explored that redundancy in the data, so it is not well known that the natural signals can be well approximated by a sparse linear combinations of prototype signals.",
            "So if we so by using this we can replace the original problems into into the solve instead solve much simpler problems there, but we can gain a significant speedup with similar performance, so we.",
            "We various applications.",
            "We show that in in face recognition, object recognition, super resolutions, human parts in various applications.",
            "So we achieved double digit speed up with similar performance.",
            "So come to see our poster in at the basement H 17.",
            "Thank you.",
            "So I'd like to thank all the speakers and Spotlight presenters."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello I'm going privacy so I've been told you so worker using opportune similarity for English with fewer noting examples.",
                    "label": 0
                },
                {
                    "sent": "This is with David full size that direct Hoyle.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It seems that the humans can do English with a few of those examples because there is a lot of other information that can be used to help identify objects.",
                    "label": 0
                },
                {
                    "sent": "So one very important, similar, but even accusing the similarity so many people may have this in the animal server before.",
                    "label": 0
                },
                {
                    "sent": "But if their total that it's more similar to an airport and CAD, then two other categories like Person Peak, so they are very likely to identify the throw instances from test images.",
                    "label": 0
                },
                {
                    "sent": "So in the paper we exploit such similarity statements in a computational framework, so we trained up your classifiers.",
                    "label": 0
                },
                {
                    "sent": "We first classifiers to respond most strongly to the examples from the similar categories.",
                    "label": 1
                },
                {
                    "sent": "Examples from the December categories.",
                    "label": 0
                },
                {
                    "sent": "So in this way we can learn from fuel training examples.",
                    "label": 0
                },
                {
                    "sent": "We also experimentally show that the all measured achieves better object classifiers that method without using any similarity information.",
                    "label": 0
                },
                {
                    "sent": "Please visit our poster for more details, thanks.",
                    "label": 0
                },
                {
                    "sent": "Alright, this allows Martinez from the heist.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "University and this is work with my student du who unfortunately couldn't make it here today.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The paper deals with finding a subspace that gives you the base optimal representation for discrimination, and as you will know, the famous linear discriminant analysis originally proposed by Fisher in the 30s gives the base optimal solution for the two class problem and when these two classes have the same covariance matrix which is known as homoscedastic distributions, in 2008 under him sishyan I proposed a solution for the C class problem for the C Class homoscedastic problem.",
                    "label": 1
                },
                {
                    "sent": "And that was in Pammy 08 this paper here what we're proposing at a solution for the C Class HETEROSCEDASTIC solution, meaning the coverage metrics do not need to be the same, and the way we solve this is by defining a base error function or an approximation.",
                    "label": 0
                },
                {
                    "sent": "I should say after base error function in the original space, calculating how this function should be calculated in the kernel space and that minimize that function using.",
                    "label": 0
                },
                {
                    "sent": "Agreed in the sand, we showed that the function is convex and therefore you can get the global minimum of this solution, giving you the best optimal solution for C classes with different convention messages.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, I'm interested in presenting a work in collaboration with Android System and.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "So SVM classifiers that use kernel, such as an intersection K squared Jensen, Shannon.",
                    "label": 0
                },
                {
                    "sent": "Well, they're very popular because they are very accurate and at the same time they're very fast to test.",
                    "label": 0
                },
                {
                    "sent": "However, training them is not as fast, because you still have to rely to nonlinear SVM solvers.",
                    "label": 0
                },
                {
                    "sent": "Instead, linear SVM's are much better in this sense.",
                    "label": 0
                },
                {
                    "sent": "So what can you do about it?",
                    "label": 0
                },
                {
                    "sent": "Well, you might know that all positive definite kernels are actually can actually be seen as we're kernels into an appropriate feature space.",
                    "label": 1
                },
                {
                    "sent": "So assuming that you can compute the feature map, then you should be able to still use your fast linear solvers instead.",
                    "label": 1
                },
                {
                    "sent": "So the contribution of this work is to show that for this important class of kernels, including Jensen, Shannon, Square intersection, and so on, it is actually possible to compute feature Maps in close form.",
                    "label": 0
                },
                {
                    "sent": "Not only this, but it is also possible to find approximations which are very efficient, very low dimensional, very fast to compute.",
                    "label": 0
                },
                {
                    "sent": "So my take home message here is that if you want to train say, a chi square SVM, there is no need to use your slow nonlinear SVM solver anymore.",
                    "label": 0
                },
                {
                    "sent": "What you can do is instead download our bill fit toolbox, process your data by using one model instruction, and then run your fast and large scale SVM solver instead.",
                    "label": 0
                },
                {
                    "sent": "So we want to know more details how this is possible.",
                    "label": 0
                },
                {
                    "sent": "Please come to see my poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm in a park.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with so much cash app and my advisor Doctor Robert Collins and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Still you.",
                    "label": 0
                },
                {
                    "sent": "We introduce a novel method for map estimation in continuous, longer Chanel reps. We call this data driven mean ship propagation or DSP people showed with the aid of scale space theory optimization becomes less sensitive to the local Maxima.",
                    "label": 1
                },
                {
                    "sent": "Theoretically, we have proven that iterations of GDM, SBP, follow the gradient descent directions of the joint density in Goshen reps and computation time can be made by linear in the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "And samples when pairwise potentials are Gaussian and in this case our approach has the same component condition as Gaussian BP.",
                    "label": 0
                },
                {
                    "sent": "And actually there's a typo in here the the covariance should be red inverse covariance to provide practical justification, we run GDM SPP.",
                    "label": 0
                },
                {
                    "sent": "On simulations on Goshen continuous MRF and show its various performance to the state of the art algorithm in terms of accuracy and speed and application on 3D problem.",
                    "label": 0
                },
                {
                    "sent": "Name is restoration confirms that DMSVP is faster and more accurate than the previous state of the art algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you at our poster section, there is basement HA.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm Supergirl.",
                    "label": 0
                },
                {
                    "sent": "From NTU Singapore.",
                    "label": 0
                },
                {
                    "sent": "My paper title is local.",
                    "label": 0
                },
                {
                    "sent": "Features are not only applies in sparse coding for image classification.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Special coding has shown its state of the art performance for image for future conversation in backward model.",
                    "label": 0
                },
                {
                    "sent": "However, in sparse coding, features are dealt separately, so the similarity between local features are lost.",
                    "label": 1
                },
                {
                    "sent": "To preserve similarity, we add sparse constraint to the objective.",
                    "label": 0
                },
                {
                    "sent": "Other similarity laugh, laughing.",
                    "label": 1
                },
                {
                    "sent": "Constraint to the objective of sparse coding and our method can preserve similarity between local features.",
                    "label": 0
                },
                {
                    "sent": "Our measure exactly exhibits excellent performance on publicly available datasets contribution our paper can be summarized as follows.",
                    "label": 1
                },
                {
                    "sent": "We propose a new sparse coding framework for future colonization and similar, and the similarity between local features can be kept.",
                    "label": 1
                },
                {
                    "sent": "Feature condensation can also be increased.",
                    "label": 1
                },
                {
                    "sent": "He created our method, enhance the robustness of sparse coding.",
                    "label": 0
                },
                {
                    "sent": "If you want to know more details, come to my poster, thank you.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is Sunshine from National University of Singapore.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my supervisor situation in until song.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Traditionally, data is open in classification task, data is open, the composed by nonnegative matrix factorization for dimension reduction purpose.",
                    "label": 0
                },
                {
                    "sent": "Before going through a classifier.",
                    "label": 1
                },
                {
                    "sent": "In this work, we propose a novel formulation to learn multiclass classifier directly through supervised non negative matrix factorization process in the formulation and the data matrix decomposed as product the product over.",
                    "label": 1
                },
                {
                    "sent": "Non active basis matrix and Co.",
                    "label": 0
                },
                {
                    "sent": "Efficient matrix the the basis matrix is learned super wisely so that it can be further decomposed as some common basis and settled class specific basis and the coalition vector of each data is assumed to be transferred from a map kernel space under the L2 norm of the class space.",
                    "label": 0
                },
                {
                    "sent": "Specific coefficient reviews the relative competence of each class.",
                    "label": 0
                },
                {
                    "sent": "So that it naturally resulting classifier our experiments on face recognition had post estimation and digital recognition shows the effectiveness of our method.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much and welcome to our question.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So good afternoon, ladies and gentlemen.",
                    "label": 0
                },
                {
                    "sent": "My name is Amir Safari and with my colleagues from grad school rituals technology, we're presenting our paper titled Online Multiclass LP Boost.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the good news about paper is that in this work we propose a system that works well in practice.",
                    "label": 0
                },
                {
                    "sent": "The bad news is that we don't have a single poster, so this is all you're going to get from our paper.",
                    "label": 0
                },
                {
                    "sent": "So in many applications in vision, online learning is necessary.",
                    "label": 0
                },
                {
                    "sent": "For example, when you deal with large scale datasets or when you.",
                    "label": 0
                },
                {
                    "sent": "For example, do object tracking music data comes over time and then you have to do an online learning step.",
                    "label": 1
                },
                {
                    "sent": "So many of the algorithms that exist for online learning in fact focus on binary problems.",
                    "label": 1
                },
                {
                    "sent": "So in this work we extend the LP Boost, which is linear programming boosting algorithm to be able to work with on line and multiclass data.",
                    "label": 0
                },
                {
                    "sent": "In order to do that, we propose an efficient primal dual algorithm which allows us to access both primal variables, which are the weights of the weak learners and.",
                    "label": 0
                },
                {
                    "sent": "Do all variables which are the rates of examples at the same time, so we apply our algorithm to Veritiv tasks such as object, category, conclusion or object tracking for both single and multi target and in fact also introduced tracking with ritual classes for binary classifier binary tracking problems which increases the robustness.",
                    "label": 0
                },
                {
                    "sent": "You don't see it here, but you have also code online which you could easily get an try out yourself.",
                    "label": 0
                },
                {
                    "sent": "The algorithm problem.",
                    "label": 0
                },
                {
                    "sent": "You guess that I was lying about the single poster thing at the beginning, but in fact we have two posters and one poster, so you couldn't come to our host around and I'll give you more details.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is Phil from the young University.",
                    "label": 0
                },
                {
                    "sent": "This is joint work by Professor.",
                    "label": 0
                },
                {
                    "sent": "Rating John at John University and professor switching year in USA.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The motivation of our paper is how to perform image classification by a physically interpretable approach.",
                    "label": 0
                },
                {
                    "sent": "In order to achieve this goal, our proposed approach consists of three step at the 1st.",
                    "label": 0
                },
                {
                    "sent": "At the first step, given one of text image for classification and the number of class we train the regression model for each class in order to make the regression model.",
                    "label": 0
                },
                {
                    "sent": "More interpretable, or we end both L1 norm and non negative constraint into the regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "This step we called Kurds records means we train different regression model independently.",
                    "label": 0
                },
                {
                    "sent": "At the second step we can buy all of trained regression model together and we also and one normal and non active content into the new regression model.",
                    "label": 0
                },
                {
                    "sent": "This step we will call the Kurds.",
                    "label": 0
                },
                {
                    "sent": "We at the next step we can classify the text image into suitable good class based on the sparse core inflation's.",
                    "label": 0
                },
                {
                    "sent": "The advantage of this approach is integration of supervised learning, sparse coding and non negative matrix decomposition.",
                    "label": 0
                },
                {
                    "sent": "Together we compare our approach with traditional Nassau and goodness or this.",
                    "label": 0
                },
                {
                    "sent": "This approach will achieve better results.",
                    "label": 0
                },
                {
                    "sent": "For more detail, please go into our people.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is touch and Gene as you can see there.",
                    "label": 0
                },
                {
                    "sent": "So the general problem we try.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To tackle in North Paper is fitting multiple instances of a geometric model, also called structures, into noisy data.",
                    "label": 1
                },
                {
                    "sent": "The specific question we ask in this paper is how many structures do we have in the data.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the problem of multiple emotions segmentation we would like to know how many emotions do we have in the observation matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is, this question sounds very simple, but deceptively.",
                    "label": 0
                },
                {
                    "sent": "It's a deceptively very difficult problem.",
                    "label": 0
                },
                {
                    "sent": "An hour approach begins by over segmenting the data into.",
                    "label": 0
                },
                {
                    "sent": "Many classes, and then we optimize discriminative kernels pairwise between all clusters in a data.",
                    "label": 1
                },
                {
                    "sent": "This is used to drive an accurate multi structure model selection scheme whereby the output just tells us the estimate of the number of structures existing in a data.",
                    "label": 0
                },
                {
                    "sent": "If you're interested to drop by the poster and I'll be happy to describe everything in detail so you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone I am fabulous Michelle.",
                    "label": 0
                },
                {
                    "sent": "I'm presenting you today, joint work between technical and in this actually on data Fusion through cross.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parity metric learning in a wide range of application one encounters the problem of comparing data coming from different modalities, different representations or different versions.",
                    "label": 0
                },
                {
                    "sent": "In an image retrieval, there are often situations where we need to query a new version of an image descriptor in an old version database.",
                    "label": 0
                },
                {
                    "sent": "In medical applications, as you can see on the upper left.",
                    "label": 0
                },
                {
                    "sent": "Various image imaging modalities provide different information about the tissues.",
                    "label": 0
                },
                {
                    "sent": "Fusion of such information requires performing multimodal image alignment whose core is measuring similarity between local batches of multimodal Lee majors.",
                    "label": 0
                },
                {
                    "sent": "In many cases, multimodal data are different in the dimensions structure an statistiques.",
                    "label": 0
                },
                {
                    "sent": "So the problem is very challenging re propose on the upper right.",
                    "label": 0
                },
                {
                    "sent": "A multimodal metric learning framework based on the embedding of multimodal data into a common metric space seeking to preserve known similarity relations on the training set.",
                    "label": 1
                },
                {
                    "sent": "A particular choice of the Hamming space results in the multimale similarity sensitive hashing where similar data points are likely to collide.",
                    "label": 0
                },
                {
                    "sent": "We are excited about different users of multiple metric learning.",
                    "label": 0
                },
                {
                    "sent": "Come to our poster in H14 to see how it works and to discuss different applications.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I'm Kareem Abu Mustafa from McGill University.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with Fernando de la Torre from.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we address the masking problem in the multiclass setting of discriminate analysis.",
                    "label": 1
                },
                {
                    "sent": "This problem occurs when one of the classes are far away from all other classes in the input space.",
                    "label": 0
                },
                {
                    "sent": "In terms of care divergent in the projected, while all other classes are relatively close to each other in the projected low dimensional subspace, the distant class gets even further while nearby classes get even closer and closer.",
                    "label": 0
                },
                {
                    "sent": "As we've shown our paper, this is due to the formulation of current DNA techniques that encourage maximizing the largest scale divergent among all other classes.",
                    "label": 0
                },
                {
                    "sent": "What we are proposing here is to simultaneously maximize the care diversions between all pairs of classes.",
                    "label": 0
                },
                {
                    "sent": "However, this creates an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Position problem with more than one objective function that needs to be simultaneously maximized as well.",
                    "label": 0
                },
                {
                    "sent": "The optimal solution in this case is the one that has maximal agreement between all possibly conflicting objective functions, and this is known to be Pareto optimal.",
                    "label": 1
                },
                {
                    "sent": "If you are interested in more details, you are invited to read our paper, or you can join us for poster at 15 H. Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody, my name is Alex here.",
                    "label": 0
                },
                {
                    "sent": "This work is an sufficient dimension reduction on sequence classification and this is joint work with Professor Tyson and Fasten My Jordan.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So are the tasks that we care about is sequence classification and we're taking a dimensionality reduction approach.",
                    "label": 1
                },
                {
                    "sent": "As the title suggests, we're using SDR or sufficient dimension reduction.",
                    "label": 1
                },
                {
                    "sent": "The framework which tries to find a latent space Z such that given this lens space, your data, why is conditionally independent to your data labels, labels Y and then data X labels.",
                    "label": 0
                },
                {
                    "sent": "Why data access and then?",
                    "label": 0
                },
                {
                    "sent": "A specific instance of STR kernel dimension reduction or KDR characterizes this conditional independence by minimizing the trace of the cross covariance operator, resulting in that final objective function.",
                    "label": 0
                },
                {
                    "sent": "This approach has two main advantages.",
                    "label": 0
                },
                {
                    "sent": "One is supervised and two.",
                    "label": 0
                },
                {
                    "sent": "It doesn't impose any assumption on the data distribution, so the problem now becomes how to build kernel so that we can classify sequences so extend.",
                    "label": 0
                },
                {
                    "sent": "KTR to the temporal domain in two ways.",
                    "label": 0
                },
                {
                    "sent": "One is 2.",
                    "label": 1
                },
                {
                    "sent": "Via kernel design.",
                    "label": 0
                },
                {
                    "sent": "So engineer multiple kernel are based on observation dynamics and the face formation, which is useful in periodic motion.",
                    "label": 1
                },
                {
                    "sent": "The second approach is through dynamic time warping and we infuse this alignment information into the kernel in those two ways.",
                    "label": 0
                },
                {
                    "sent": "And finally, we demonstrate effectiveness of our approach on four different datasets.",
                    "label": 0
                },
                {
                    "sent": "Come to our poster.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is dropping hunt.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with mention young at the University of California Merced.",
                    "label": 0
                },
                {
                    "sent": "So sparse.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Presentation has wide range of applications, so sparse coding is at the core of the at the core of the sparse modeling of signals it is shown that one minimization can recover the true sparse sparse solution of the linear system.",
                    "label": 1
                },
                {
                    "sent": "However, the computational load is still high, so so we propose a method that, without without, without design, instead of designing a sparse coding algorithm, we.",
                    "label": 1
                },
                {
                    "sent": "Is that explored that redundancy in the data, so it is not well known that the natural signals can be well approximated by a sparse linear combinations of prototype signals.",
                    "label": 0
                },
                {
                    "sent": "So if we so by using this we can replace the original problems into into the solve instead solve much simpler problems there, but we can gain a significant speedup with similar performance, so we.",
                    "label": 0
                },
                {
                    "sent": "We various applications.",
                    "label": 1
                },
                {
                    "sent": "We show that in in face recognition, object recognition, super resolutions, human parts in various applications.",
                    "label": 0
                },
                {
                    "sent": "So we achieved double digit speed up with similar performance.",
                    "label": 0
                },
                {
                    "sent": "So come to see our poster in at the basement H 17.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So I'd like to thank all the speakers and Spotlight presenters.",
                    "label": 0
                }
            ]
        }
    }
}