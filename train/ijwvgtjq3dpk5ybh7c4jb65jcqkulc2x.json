{
    "id": "ijwvgtjq3dpk5ybh7c4jb65jcqkulc2x",
    "title": "Linear Programming Boosting for Classi\ufb01cation of Musical Genre",
    "info": {
        "author": [
            "Tom Diethe, Department of Computer Science, University College London"
        ],
        "published": "Dec. 29, 2007",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Arts->Music",
            "Top->Computer Science->Machine Learning->Boosting"
        ]
    },
    "url": "http://videolectures.net/mbc07_diethe_lpb/",
    "segmentation": [
        [
            "OK, so.",
            "Genre classification is pretty well known within the field, and when I first started working on it seemed like a sort of neat problem to, you know, quite easily packaged, and we could apply some nice machine learning techniques to it.",
            "And you know, there's some.",
            "Suffer case, or maybe it's valuable when you can make some money out of it.",
            "That kind of stuff this chance to try out different feature extraction.",
            "Signal processing methods get up to speed with it, but I very quickly realized that it wasn't quite so simple.",
            "That is sort of a quote here by one of the guys who has worked in the field for awhile.",
            "Pretty serious doubts about genre classification in the 1st place, because it's a seemingly arbitrary nature of classes and how they were assigned.",
            "And then and genres themselves are not necessarily the most natural groupings for pieces of music, and humans don't perform that well on the task when they you know they have a group of humans are asked to perform it, and you take the average of there.",
            "What they say, then you know they come out quite low, so it's it's a bit of a.",
            "It's a bit of a minefield really, but at the same time there's still being some valuable work in hands and I think.",
            "Anne."
        ],
        [
            "And good insights from it so so each year there's at the Ismir conference, the music Information Retrieval Conference.",
            "There's there's a mirex, which is a kind of yearly competition, and they have sort of a set of different.",
            "So competitions and in 2005 they had a genre classification, one they didn't have in 2006.",
            "And then they did again this year, but so so I was looking at the 2005 results and.",
            "Adaboost based on an aggregated feature set will talk about that in a minute came top not by a huge amount, but sort of still look like quite good result.",
            "And so this is kind of the basis for this."
        ],
        [
            "So as far as the features.",
            "Last Speaker mentioned MFCC, so that's one of the one of the features we looked at.",
            "So these are effective.",
            "Effectively you chop the the song up into small slices and then you do kind of various spectral analysis techniques.",
            "Signal processing techniques on these small slices.",
            "So these come from speech perception, signal processing theory, that kind of thing.",
            "And.",
            "Then we basically you say you have a set of features for these small socks song segments and then you have to aggregate somewhere over there over there over the full set.",
            "So the simplest way of doing this is just to fit a single Gaussian over it.",
            "Other other people have tried things like mixtures of Gaussians and I think that's a promising approach, but.",
            "But this this method sort of as a baseline, seems to perform quite well.",
            "So we end up with.",
            "Say a feature vector of just over 800.",
            "Features person."
        ],
        [
            "So.",
            "I don't know how many people are aware of boosting or went to the tutorial at the beginning of the week, which was quite nice.",
            "Linear program boosting was it wasn't really mentioned that database was talked about a lot, so the idea is that you have.",
            "A a week a week learner, which is any classifier that can perform better than 50% on your data set and a very simple one of these is to use what's called decision Stump, where effectively you just put a threshold in your data and everything to one side is positive and everything to the other side is negative and that you will always have a classifier better than 50% with that, because if it's worth worse than 50%, you flip it around and you have the opposite which is always greater than or equal to 50%.",
            "And by taking a whole series of these and having a weighted sum of them, you can then produce a strong classifier.",
            "Now LP boost actually comes from a slightly different setting.",
            "It's it's basically similar to the CM optimization, except you have a one norm instead of the two norm and then because.",
            "And in this case we have rather my inputs.",
            "We have the hypothesis matrix based on these weak learners.",
            "And then because we have a very large linear program to solve, we use a technique which is a very old technique from Danzig.",
            "Called Column Generation, which is basically a way of splitting up at Lincoln program into a master problem.",
            "Anna subproblem.",
            "And then when you do that, the the algorithm looks very much like a boosting algorithm and effectively you're picking out weak learners and waiting them in the same way that you would with Adaboost.",
            "The nice thing about this is that.",
            "You are actually converging to the global optimum solution within your hypothesis space so.",
            "And and each step you can actually calculate how far away you are from that that global solution.",
            "So you have the choice of stopping early as well so.",
            "Without a boost you have this this parameter T which is your number of iterations, and it's sort of not always clear how you choose that and we know it's fairly robust to overfitting, so you just run it for a long time basically, but LP Boost is is nice because you know you know when to stop, so typically the iterations are much slower because you're having to solve this linear program at each step, but it converges much more quickly and overall the running time.",
            "I mean it's of the same order of magnitude anyway, but it seems that LP's is slightly quicker."
        ],
        [
            "So the data sets were used that one of the main problems in this field is availability of datasets.",
            "Because music has Copyright on it and.",
            "And large databases that are freely available just do not exist really.",
            "So there is this.",
            "One from the marks two 2005 competition isn't freely available.",
            "There was one from the 2004 competition that is available on the net.",
            "It's bit hard to find, but the links in my paper now so if anyone else wants it.",
            "And also managed to get a data set off a fellow researcher and dismang.",
            "And he's published a couple of results based on that data set, so at least they had something to compare to."
        ],
        [
            "So this is just a quick summary of the results.",
            "You can come and chat to me more about it if you like.",
            "Basically what we showed that.",
            "The LP boost results are very similar to Adaboost, but the numbers in the parentheses here are the number of wheat learners in the final solution, so you can see that effectively you know with more than an order of magnitude less here, so.",
            "This is nice because it's so much faster solution effectively.",
            "These results look quite low, but actually.",
            "The best reported performance on this data set was 44%, so we're roughly at that and human evaluation on the data set was only at 52%, so this is over 4 classes rather than over two sets."
        ],
        [
            "I'm.",
            "OK, so just to conclude.",
            "There's there are many different approaches and this approach based on a big aggregated feature set seems to work quite well.",
            "Boosting is quite a nice choice for that particular type of feature set, but in kind of shows that we don't really know what we're doing because these features are not really musical in some sense, and you might imagine that humans do this in a very different way to that so.",
            "It is further work definitely, and trying to maybe identify more musical feature set.",
            "One thing I didn't touch on is that the multiple class implementation of LP Boost that I used was very very simplistic, similar to the way that you Ada Boost.",
            "Is done, but I don't think it's the most optimal way of doing it, but that's that's.",
            "Kind of by the boy ready.",
            "Thank you.",
            "Thanks a lot.",
            "OK.",
            "Right now we're working with.",
            "Hello OK. Rock and pop yeah.",
            "They don't make any sense.",
            "Sure, yeah, yeah.",
            "Yes.",
            "That's a good question.",
            "I think I'd have to get back back to you on that.",
            "Yeah, I think there could be a problem there.",
            "I think that could be from.",
            "I mean, one thing I've I've thought that you know that that really we should be doing some kind of filtering of the yeah.",
            "And the other thing is that maybe rather than so the big problem, really.",
            "I can see is constructing this hypothesis matrix is going to be absolutely huge, so if there's a way of just picking out the weak learners.",
            "Outside of online, without having to struggle entire matrix."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Genre classification is pretty well known within the field, and when I first started working on it seemed like a sort of neat problem to, you know, quite easily packaged, and we could apply some nice machine learning techniques to it.",
                    "label": 0
                },
                {
                    "sent": "And you know, there's some.",
                    "label": 0
                },
                {
                    "sent": "Suffer case, or maybe it's valuable when you can make some money out of it.",
                    "label": 0
                },
                {
                    "sent": "That kind of stuff this chance to try out different feature extraction.",
                    "label": 0
                },
                {
                    "sent": "Signal processing methods get up to speed with it, but I very quickly realized that it wasn't quite so simple.",
                    "label": 0
                },
                {
                    "sent": "That is sort of a quote here by one of the guys who has worked in the field for awhile.",
                    "label": 0
                },
                {
                    "sent": "Pretty serious doubts about genre classification in the 1st place, because it's a seemingly arbitrary nature of classes and how they were assigned.",
                    "label": 0
                },
                {
                    "sent": "And then and genres themselves are not necessarily the most natural groupings for pieces of music, and humans don't perform that well on the task when they you know they have a group of humans are asked to perform it, and you take the average of there.",
                    "label": 0
                },
                {
                    "sent": "What they say, then you know they come out quite low, so it's it's a bit of a.",
                    "label": 0
                },
                {
                    "sent": "It's a bit of a minefield really, but at the same time there's still being some valuable work in hands and I think.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And good insights from it so so each year there's at the Ismir conference, the music Information Retrieval Conference.",
                    "label": 1
                },
                {
                    "sent": "There's there's a mirex, which is a kind of yearly competition, and they have sort of a set of different.",
                    "label": 1
                },
                {
                    "sent": "So competitions and in 2005 they had a genre classification, one they didn't have in 2006.",
                    "label": 0
                },
                {
                    "sent": "And then they did again this year, but so so I was looking at the 2005 results and.",
                    "label": 0
                },
                {
                    "sent": "Adaboost based on an aggregated feature set will talk about that in a minute came top not by a huge amount, but sort of still look like quite good result.",
                    "label": 1
                },
                {
                    "sent": "And so this is kind of the basis for this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as far as the features.",
                    "label": 0
                },
                {
                    "sent": "Last Speaker mentioned MFCC, so that's one of the one of the features we looked at.",
                    "label": 0
                },
                {
                    "sent": "So these are effective.",
                    "label": 0
                },
                {
                    "sent": "Effectively you chop the the song up into small slices and then you do kind of various spectral analysis techniques.",
                    "label": 0
                },
                {
                    "sent": "Signal processing techniques on these small slices.",
                    "label": 0
                },
                {
                    "sent": "So these come from speech perception, signal processing theory, that kind of thing.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then we basically you say you have a set of features for these small socks song segments and then you have to aggregate somewhere over there over there over the full set.",
                    "label": 0
                },
                {
                    "sent": "So the simplest way of doing this is just to fit a single Gaussian over it.",
                    "label": 0
                },
                {
                    "sent": "Other other people have tried things like mixtures of Gaussians and I think that's a promising approach, but.",
                    "label": 0
                },
                {
                    "sent": "But this this method sort of as a baseline, seems to perform quite well.",
                    "label": 0
                },
                {
                    "sent": "So we end up with.",
                    "label": 0
                },
                {
                    "sent": "Say a feature vector of just over 800.",
                    "label": 0
                },
                {
                    "sent": "Features person.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many people are aware of boosting or went to the tutorial at the beginning of the week, which was quite nice.",
                    "label": 0
                },
                {
                    "sent": "Linear program boosting was it wasn't really mentioned that database was talked about a lot, so the idea is that you have.",
                    "label": 0
                },
                {
                    "sent": "A a week a week learner, which is any classifier that can perform better than 50% on your data set and a very simple one of these is to use what's called decision Stump, where effectively you just put a threshold in your data and everything to one side is positive and everything to the other side is negative and that you will always have a classifier better than 50% with that, because if it's worth worse than 50%, you flip it around and you have the opposite which is always greater than or equal to 50%.",
                    "label": 0
                },
                {
                    "sent": "And by taking a whole series of these and having a weighted sum of them, you can then produce a strong classifier.",
                    "label": 0
                },
                {
                    "sent": "Now LP boost actually comes from a slightly different setting.",
                    "label": 0
                },
                {
                    "sent": "It's it's basically similar to the CM optimization, except you have a one norm instead of the two norm and then because.",
                    "label": 0
                },
                {
                    "sent": "And in this case we have rather my inputs.",
                    "label": 0
                },
                {
                    "sent": "We have the hypothesis matrix based on these weak learners.",
                    "label": 0
                },
                {
                    "sent": "And then because we have a very large linear program to solve, we use a technique which is a very old technique from Danzig.",
                    "label": 0
                },
                {
                    "sent": "Called Column Generation, which is basically a way of splitting up at Lincoln program into a master problem.",
                    "label": 0
                },
                {
                    "sent": "Anna subproblem.",
                    "label": 0
                },
                {
                    "sent": "And then when you do that, the the algorithm looks very much like a boosting algorithm and effectively you're picking out weak learners and waiting them in the same way that you would with Adaboost.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about this is that.",
                    "label": 0
                },
                {
                    "sent": "You are actually converging to the global optimum solution within your hypothesis space so.",
                    "label": 0
                },
                {
                    "sent": "And and each step you can actually calculate how far away you are from that that global solution.",
                    "label": 0
                },
                {
                    "sent": "So you have the choice of stopping early as well so.",
                    "label": 0
                },
                {
                    "sent": "Without a boost you have this this parameter T which is your number of iterations, and it's sort of not always clear how you choose that and we know it's fairly robust to overfitting, so you just run it for a long time basically, but LP Boost is is nice because you know you know when to stop, so typically the iterations are much slower because you're having to solve this linear program at each step, but it converges much more quickly and overall the running time.",
                    "label": 0
                },
                {
                    "sent": "I mean it's of the same order of magnitude anyway, but it seems that LP's is slightly quicker.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the data sets were used that one of the main problems in this field is availability of datasets.",
                    "label": 0
                },
                {
                    "sent": "Because music has Copyright on it and.",
                    "label": 0
                },
                {
                    "sent": "And large databases that are freely available just do not exist really.",
                    "label": 0
                },
                {
                    "sent": "So there is this.",
                    "label": 0
                },
                {
                    "sent": "One from the marks two 2005 competition isn't freely available.",
                    "label": 0
                },
                {
                    "sent": "There was one from the 2004 competition that is available on the net.",
                    "label": 0
                },
                {
                    "sent": "It's bit hard to find, but the links in my paper now so if anyone else wants it.",
                    "label": 0
                },
                {
                    "sent": "And also managed to get a data set off a fellow researcher and dismang.",
                    "label": 0
                },
                {
                    "sent": "And he's published a couple of results based on that data set, so at least they had something to compare to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is just a quick summary of the results.",
                    "label": 0
                },
                {
                    "sent": "You can come and chat to me more about it if you like.",
                    "label": 0
                },
                {
                    "sent": "Basically what we showed that.",
                    "label": 0
                },
                {
                    "sent": "The LP boost results are very similar to Adaboost, but the numbers in the parentheses here are the number of wheat learners in the final solution, so you can see that effectively you know with more than an order of magnitude less here, so.",
                    "label": 0
                },
                {
                    "sent": "This is nice because it's so much faster solution effectively.",
                    "label": 0
                },
                {
                    "sent": "These results look quite low, but actually.",
                    "label": 0
                },
                {
                    "sent": "The best reported performance on this data set was 44%, so we're roughly at that and human evaluation on the data set was only at 52%, so this is over 4 classes rather than over two sets.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to conclude.",
                    "label": 0
                },
                {
                    "sent": "There's there are many different approaches and this approach based on a big aggregated feature set seems to work quite well.",
                    "label": 0
                },
                {
                    "sent": "Boosting is quite a nice choice for that particular type of feature set, but in kind of shows that we don't really know what we're doing because these features are not really musical in some sense, and you might imagine that humans do this in a very different way to that so.",
                    "label": 0
                },
                {
                    "sent": "It is further work definitely, and trying to maybe identify more musical feature set.",
                    "label": 0
                },
                {
                    "sent": "One thing I didn't touch on is that the multiple class implementation of LP Boost that I used was very very simplistic, similar to the way that you Ada Boost.",
                    "label": 0
                },
                {
                    "sent": "Is done, but I don't think it's the most optimal way of doing it, but that's that's.",
                    "label": 0
                },
                {
                    "sent": "Kind of by the boy ready.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Right now we're working with.",
                    "label": 0
                },
                {
                    "sent": "Hello OK. Rock and pop yeah.",
                    "label": 0
                },
                {
                    "sent": "They don't make any sense.",
                    "label": 0
                },
                {
                    "sent": "Sure, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "I think I'd have to get back back to you on that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think there could be a problem there.",
                    "label": 0
                },
                {
                    "sent": "I think that could be from.",
                    "label": 0
                },
                {
                    "sent": "I mean, one thing I've I've thought that you know that that really we should be doing some kind of filtering of the yeah.",
                    "label": 0
                },
                {
                    "sent": "And the other thing is that maybe rather than so the big problem, really.",
                    "label": 0
                },
                {
                    "sent": "I can see is constructing this hypothesis matrix is going to be absolutely huge, so if there's a way of just picking out the weak learners.",
                    "label": 0
                },
                {
                    "sent": "Outside of online, without having to struggle entire matrix.",
                    "label": 0
                }
            ]
        }
    }
}