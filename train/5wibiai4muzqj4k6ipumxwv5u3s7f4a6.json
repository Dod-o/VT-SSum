{
    "id": "5wibiai4muzqj4k6ipumxwv5u3s7f4a6",
    "title": "Sparse Subspace Clustering",
    "info": {
        "author": [
            "Yingzhen Yang, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_yang_subspace_clustering/",
    "segmentation": [
        [
            "This is eternal.",
            "Walk away with UIUC and National University of Singapore and Microsoft Research and also Snapchat Research.",
            "So basically"
        ],
        [
            "Basic assumption of high dimensional data is that it's nine in the Union of low dimensional subspaces.",
            "So in order to explore the substrate structure, substitution method try to partition the data according to the underlying subspaces, and in this figure you can.",
            "You can see example of subspace clustering.",
            "We can see two subspace S1 and S2 and we can see the blackboard standards.",
            "One to two substrates respectively."
        ],
        [
            "Among different subspaces crossing methods as possible because it is kind of very effective in terms that it uses a sparse reputation to find the data that's in the in the same subspace.",
            "There are two versions of specific pricing, SSE and it's robust version.",
            "As I say, try to solve the basis pursuit problem here.",
            "The 1st and the second option is for robots.",
            "Ring essentially allows for sound better noise and try to solve those type of problem.",
            "Here I under the very fundamental element of subspace costing method is that on the certain assumptions on the data and online spaces we have this subspace dimension property, which means that the sparse code zero elements of the source code actually indicated the data that's nine in the sense of space as the data point in question so.",
            "So."
        ],
        [
            "In this sense, we can build the severity matrix such that data from different sources have zero similarity, and in this finger you can see the severity matrix build over the entire data set.",
            "We have two spaces as well as two because of the substitution property there are the similarity between data from several similarity, which means that we have a blog or some other metrics.",
            "If we apply special clustering, fairly good clustering results.",
            "So this is the basic motivation of.",
            "On sparse across ring but allow you or we try to improve the existing sparsification sparsification method by using LO loan to impose the sparsity and willing our method LO as I see so you can see the formulation here essentially also kind of very similar to the basis pursuit problem, except that it tried to minimize the LO along which is fire Oringinal formulation of sparsity.",
            "The little slides I will explain the theoretical advantage of LOSC.",
            "So you."
        ],
        [
            "To analyze the sparse substitution property we I want to introduce the basic models for industry church or we have two types of models.",
            "Deterministic model and randomized model.",
            "In deterministic model, both both subspaces and the data fixed in randomized model.",
            "We have two times, the first time with semi random model which means that the subspace figures but the data in each space generally generated.",
            "The second model is fully random for random model which means that.",
            "Both subspaces and the data already generated."
        ],
        [
            "On there are a lot of theoretical lattices in the motion detector and also in the computer, so we try to analyze the sparse.",
            "Small stickers on property and also on the search results are in the phone that under certain assumptions on the subspace and sound geometrical properties we can achieve space station property.",
            "But assumptions are very difficult to check and also another important question is that.",
            "To do, not to mention the fundamental problem we are really caring about, which is what's the relationship between sparsity and substitution property, because this is very important.",
            "How to most significant theoretical result of LOSC proposal in this work is that we establish the almost surely equivalence between LO sparsity and also the substitution property under the mighty assumption.",
            "To the best of our knowledge, this is very important cause to the best of our knowledge most existing myself try to establish SDP on the assumptions on the geometric properties.",
            "Of data and the subspace.",
            "But a lot of this work mentioned the question in the other side or in the other direction which is.",
            "So the SDP indicated some sparsity.",
            "Or is it really necessary to use sparsity to achieve SDP?",
            "So so theory one indicates the first direction, which means that?",
            "If we can solve with LO spots reputation problem then we can achieve SDP.",
            "So the result is that under under the randomized models.",
            "I suppose the data in this space are randomly generated from any continuous distribution.",
            "Then we can achieve SDP.",
            "Note that in this theoretical result we don't require any any assumptions required by the existing methods, such as the ingredients and also the subsurface incoherence.",
            "We do not need these magic conditions, we do not need this complex geometric condition which are difficult to check."
        ],
        [
            "I understand and I want to also want to mention some basic elements in the proof of this important steering so the key element is the Intercept hyperplane here, and indeed this finger you can see.",
            "An example of the intercepting.",
            "We have S1 and S2 as two subspaces XI from XYXG for S2.",
            "So the so the hyperplane spend by XI an extra actually intercepting where the confusion comes from.",
            "So the key observation of our result is that the probability measure of the intersection of the intercepting and any associated subspace is zero, which means that with probability one we can achieve SDP."
        ],
        [
            "And we want to emphasize either ourselves or can be Spanish on the far less restrictive assumptions and disable an at least.",
            "Although although required assumptions by by the subspace clustering methods, and this assumptions are classified into two groups, the first group is about the submission on the subspace, second group is about the assumptions on the data generation.",
            "We have four options on the subspace S1 to S4 and.",
            "And this is this assumptions are dealing with the independent destroid and overlap and also distinct subspaces.",
            "And our assumption is is the least restrictive assumption and also the similar thing happens for the assumption that a generation we previous message you got all the data ID generated from from the uniform distribution on the sphere.",
            "But our method only requires that data ID from an arbitrary continuous situation.",
            "I think of, you know, sort of examples of of subspaces, which is which are independent and destroying space is actually actually this case are very realistic goal to happen because in here that it is really impossible or very difficult to make assumptions holds.",
            "No.",
            "We"
        ],
        [
            "We can do the weekend with the other direction, which is.",
            "Which is to really need to solve the very difficult LO.",
            "Spot reputation problem to achieve SDP because I'm serious.",
            "Problem is NP hard.",
            "So this result shows that there is no better deal which means that if we want to achieve SDP on the on the hour very mild condition.",
            "We have to solve LO sparsity problems.",
            "Which also means that under this mild conditions.",
            "FTPS is at least as difficult as the NP hard LO on specialization problem.",
            "Because so."
        ],
        [
            "To function of accuracy is because because optimization problems arise.",
            "He is NP hard, so we formulated on approximately LOSE problem.",
            "We can use a method to find the optimal solutions, so the formulation is fire Center for possibilities and the first step is try to perform decent on the differential power and the second step we tried to use the House ready operator of the final solution to the approximal mapping."
        ],
        [
            "Now we found from the common classes we can see that it's over value decrease, but we don't know if the variable sequences will converge alot.",
            "And also even the variable sequence converge and we have no idea.",
            "How far how far the optimal solution is from the global optimal solution?",
            "So you want to be submissive?"
        ],
        [
            "And between the sub optimal solution at the globally optimal solution we have sound.",
            "We did the definition of sparse over the data matrix and the insurgency we established the bond between actually actually."
        ],
        [
            "We show that the distance between the sub optimal solution obtained by possibly decent and the global open solution is actually bounded by.",
            "This boundary is in terms of the parameters number for the sparsity of the Elder Law and also some other parameters using our theoretical lattice.",
            "Please refer to our paper and post for more details."
        ],
        [
            "And also important or important problem of any sparse subspace crossing messages at this capability is a problem because because because because we have we have to use the data dictionary to find the source code.",
            "But this is not a problem for LOSCB called because we because suppose because if we use a reasonably large step size in the in the green dissent step, we have this very lies.",
            "Support, shrinkage property so that the.",
            "Original formulation is equivalent to.",
            "Reduce the formulation I show in this equation because in the original formulation we have used the Intel Data Dictionary for for operating the source code, but now we only need to use a submatrix of the original matrix, and this submatrix is specified by the larger elements of the initial point.",
            "So this capability has been significantly improved by our bodies, various theoretical property."
        ],
        [
            "On the data crossing by approximately, I see it listed here also for the first step is to find the sub optimal solution using possibility center.",
            "The second step is to build builders or some other metrics and cellcept is applying special class interaction.",
            "Result is very kind of procedure of four specifically in this literature."
        ],
        [
            "And in this paper we perform we probably sensitive results on various image data sets, and we show the comparison to other competing methods including Cummings, Special Clustering, SSE SMC stats for sparse manifold cost and embedding, which is also dealing with the manifold structure of the data.",
            "And also we compare our method to SCOMP which is used to also.",
            "So imagine pursue a software error problem."
        ],
        [
            "And also we investigated the parameter sensitivity and and we we change the value of Lambda which is away for their own on two datasets.",
            "Our extended lobby and also the coin translator, and we said our method can always be better than other baselines.",
            "Methods across a wide range of the permit number.",
            "Now I want to give up."
        ],
        [
            "Moreover, this method and in terms of the theory we establish is almost fully equivalence between LO sparsity and subdivision properties, and to the best of our knowledge this is the first time we build equivalence and 2nd perspective that we implement our method by both matter matter and could see plus for extremely efficiently cause we found that algorithm is highly parallelizable.",
            "Call the before for downloading.",
            "So this is my."
        ],
        [
            "Thank you very much for this presentation."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is eternal.",
                    "label": 0
                },
                {
                    "sent": "Walk away with UIUC and National University of Singapore and Microsoft Research and also Snapchat Research.",
                    "label": 1
                },
                {
                    "sent": "So basically",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basic assumption of high dimensional data is that it's nine in the Union of low dimensional subspaces.",
                    "label": 0
                },
                {
                    "sent": "So in order to explore the substrate structure, substitution method try to partition the data according to the underlying subspaces, and in this figure you can.",
                    "label": 1
                },
                {
                    "sent": "You can see example of subspace clustering.",
                    "label": 1
                },
                {
                    "sent": "We can see two subspace S1 and S2 and we can see the blackboard standards.",
                    "label": 0
                },
                {
                    "sent": "One to two substrates respectively.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Among different subspaces crossing methods as possible because it is kind of very effective in terms that it uses a sparse reputation to find the data that's in the in the same subspace.",
                    "label": 0
                },
                {
                    "sent": "There are two versions of specific pricing, SSE and it's robust version.",
                    "label": 1
                },
                {
                    "sent": "As I say, try to solve the basis pursuit problem here.",
                    "label": 1
                },
                {
                    "sent": "The 1st and the second option is for robots.",
                    "label": 0
                },
                {
                    "sent": "Ring essentially allows for sound better noise and try to solve those type of problem.",
                    "label": 0
                },
                {
                    "sent": "Here I under the very fundamental element of subspace costing method is that on the certain assumptions on the data and online spaces we have this subspace dimension property, which means that the sparse code zero elements of the source code actually indicated the data that's nine in the sense of space as the data point in question so.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this sense, we can build the severity matrix such that data from different sources have zero similarity, and in this finger you can see the severity matrix build over the entire data set.",
                    "label": 0
                },
                {
                    "sent": "We have two spaces as well as two because of the substitution property there are the similarity between data from several similarity, which means that we have a blog or some other metrics.",
                    "label": 0
                },
                {
                    "sent": "If we apply special clustering, fairly good clustering results.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic motivation of.",
                    "label": 0
                },
                {
                    "sent": "On sparse across ring but allow you or we try to improve the existing sparsification sparsification method by using LO loan to impose the sparsity and willing our method LO as I see so you can see the formulation here essentially also kind of very similar to the basis pursuit problem, except that it tried to minimize the LO along which is fire Oringinal formulation of sparsity.",
                    "label": 0
                },
                {
                    "sent": "The little slides I will explain the theoretical advantage of LOSC.",
                    "label": 0
                },
                {
                    "sent": "So you.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To analyze the sparse substitution property we I want to introduce the basic models for industry church or we have two types of models.",
                    "label": 0
                },
                {
                    "sent": "Deterministic model and randomized model.",
                    "label": 0
                },
                {
                    "sent": "In deterministic model, both both subspaces and the data fixed in randomized model.",
                    "label": 1
                },
                {
                    "sent": "We have two times, the first time with semi random model which means that the subspace figures but the data in each space generally generated.",
                    "label": 1
                },
                {
                    "sent": "The second model is fully random for random model which means that.",
                    "label": 0
                },
                {
                    "sent": "Both subspaces and the data already generated.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On there are a lot of theoretical lattices in the motion detector and also in the computer, so we try to analyze the sparse.",
                    "label": 0
                },
                {
                    "sent": "Small stickers on property and also on the search results are in the phone that under certain assumptions on the subspace and sound geometrical properties we can achieve space station property.",
                    "label": 0
                },
                {
                    "sent": "But assumptions are very difficult to check and also another important question is that.",
                    "label": 0
                },
                {
                    "sent": "To do, not to mention the fundamental problem we are really caring about, which is what's the relationship between sparsity and substitution property, because this is very important.",
                    "label": 0
                },
                {
                    "sent": "How to most significant theoretical result of LOSC proposal in this work is that we establish the almost surely equivalence between LO sparsity and also the substitution property under the mighty assumption.",
                    "label": 0
                },
                {
                    "sent": "To the best of our knowledge, this is very important cause to the best of our knowledge most existing myself try to establish SDP on the assumptions on the geometric properties.",
                    "label": 0
                },
                {
                    "sent": "Of data and the subspace.",
                    "label": 0
                },
                {
                    "sent": "But a lot of this work mentioned the question in the other side or in the other direction which is.",
                    "label": 0
                },
                {
                    "sent": "So the SDP indicated some sparsity.",
                    "label": 0
                },
                {
                    "sent": "Or is it really necessary to use sparsity to achieve SDP?",
                    "label": 0
                },
                {
                    "sent": "So so theory one indicates the first direction, which means that?",
                    "label": 0
                },
                {
                    "sent": "If we can solve with LO spots reputation problem then we can achieve SDP.",
                    "label": 0
                },
                {
                    "sent": "So the result is that under under the randomized models.",
                    "label": 0
                },
                {
                    "sent": "I suppose the data in this space are randomly generated from any continuous distribution.",
                    "label": 0
                },
                {
                    "sent": "Then we can achieve SDP.",
                    "label": 0
                },
                {
                    "sent": "Note that in this theoretical result we don't require any any assumptions required by the existing methods, such as the ingredients and also the subsurface incoherence.",
                    "label": 0
                },
                {
                    "sent": "We do not need these magic conditions, we do not need this complex geometric condition which are difficult to check.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I understand and I want to also want to mention some basic elements in the proof of this important steering so the key element is the Intercept hyperplane here, and indeed this finger you can see.",
                    "label": 0
                },
                {
                    "sent": "An example of the intercepting.",
                    "label": 0
                },
                {
                    "sent": "We have S1 and S2 as two subspaces XI from XYXG for S2.",
                    "label": 0
                },
                {
                    "sent": "So the so the hyperplane spend by XI an extra actually intercepting where the confusion comes from.",
                    "label": 0
                },
                {
                    "sent": "So the key observation of our result is that the probability measure of the intersection of the intercepting and any associated subspace is zero, which means that with probability one we can achieve SDP.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we want to emphasize either ourselves or can be Spanish on the far less restrictive assumptions and disable an at least.",
                    "label": 0
                },
                {
                    "sent": "Although although required assumptions by by the subspace clustering methods, and this assumptions are classified into two groups, the first group is about the submission on the subspace, second group is about the assumptions on the data generation.",
                    "label": 0
                },
                {
                    "sent": "We have four options on the subspace S1 to S4 and.",
                    "label": 0
                },
                {
                    "sent": "And this is this assumptions are dealing with the independent destroid and overlap and also distinct subspaces.",
                    "label": 0
                },
                {
                    "sent": "And our assumption is is the least restrictive assumption and also the similar thing happens for the assumption that a generation we previous message you got all the data ID generated from from the uniform distribution on the sphere.",
                    "label": 0
                },
                {
                    "sent": "But our method only requires that data ID from an arbitrary continuous situation.",
                    "label": 0
                },
                {
                    "sent": "I think of, you know, sort of examples of of subspaces, which is which are independent and destroying space is actually actually this case are very realistic goal to happen because in here that it is really impossible or very difficult to make assumptions holds.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can do the weekend with the other direction, which is.",
                    "label": 0
                },
                {
                    "sent": "Which is to really need to solve the very difficult LO.",
                    "label": 0
                },
                {
                    "sent": "Spot reputation problem to achieve SDP because I'm serious.",
                    "label": 0
                },
                {
                    "sent": "Problem is NP hard.",
                    "label": 0
                },
                {
                    "sent": "So this result shows that there is no better deal which means that if we want to achieve SDP on the on the hour very mild condition.",
                    "label": 0
                },
                {
                    "sent": "We have to solve LO sparsity problems.",
                    "label": 0
                },
                {
                    "sent": "Which also means that under this mild conditions.",
                    "label": 0
                },
                {
                    "sent": "FTPS is at least as difficult as the NP hard LO on specialization problem.",
                    "label": 0
                },
                {
                    "sent": "Because so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To function of accuracy is because because optimization problems arise.",
                    "label": 0
                },
                {
                    "sent": "He is NP hard, so we formulated on approximately LOSE problem.",
                    "label": 0
                },
                {
                    "sent": "We can use a method to find the optimal solutions, so the formulation is fire Center for possibilities and the first step is try to perform decent on the differential power and the second step we tried to use the House ready operator of the final solution to the approximal mapping.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we found from the common classes we can see that it's over value decrease, but we don't know if the variable sequences will converge alot.",
                    "label": 0
                },
                {
                    "sent": "And also even the variable sequence converge and we have no idea.",
                    "label": 0
                },
                {
                    "sent": "How far how far the optimal solution is from the global optimal solution?",
                    "label": 0
                },
                {
                    "sent": "So you want to be submissive?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And between the sub optimal solution at the globally optimal solution we have sound.",
                    "label": 0
                },
                {
                    "sent": "We did the definition of sparse over the data matrix and the insurgency we established the bond between actually actually.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We show that the distance between the sub optimal solution obtained by possibly decent and the global open solution is actually bounded by.",
                    "label": 0
                },
                {
                    "sent": "This boundary is in terms of the parameters number for the sparsity of the Elder Law and also some other parameters using our theoretical lattice.",
                    "label": 0
                },
                {
                    "sent": "Please refer to our paper and post for more details.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also important or important problem of any sparse subspace crossing messages at this capability is a problem because because because because we have we have to use the data dictionary to find the source code.",
                    "label": 0
                },
                {
                    "sent": "But this is not a problem for LOSCB called because we because suppose because if we use a reasonably large step size in the in the green dissent step, we have this very lies.",
                    "label": 0
                },
                {
                    "sent": "Support, shrinkage property so that the.",
                    "label": 0
                },
                {
                    "sent": "Original formulation is equivalent to.",
                    "label": 0
                },
                {
                    "sent": "Reduce the formulation I show in this equation because in the original formulation we have used the Intel Data Dictionary for for operating the source code, but now we only need to use a submatrix of the original matrix, and this submatrix is specified by the larger elements of the initial point.",
                    "label": 0
                },
                {
                    "sent": "So this capability has been significantly improved by our bodies, various theoretical property.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the data crossing by approximately, I see it listed here also for the first step is to find the sub optimal solution using possibility center.",
                    "label": 0
                },
                {
                    "sent": "The second step is to build builders or some other metrics and cellcept is applying special class interaction.",
                    "label": 0
                },
                {
                    "sent": "Result is very kind of procedure of four specifically in this literature.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in this paper we perform we probably sensitive results on various image data sets, and we show the comparison to other competing methods including Cummings, Special Clustering, SSE SMC stats for sparse manifold cost and embedding, which is also dealing with the manifold structure of the data.",
                    "label": 0
                },
                {
                    "sent": "And also we compare our method to SCOMP which is used to also.",
                    "label": 0
                },
                {
                    "sent": "So imagine pursue a software error problem.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we investigated the parameter sensitivity and and we we change the value of Lambda which is away for their own on two datasets.",
                    "label": 0
                },
                {
                    "sent": "Our extended lobby and also the coin translator, and we said our method can always be better than other baselines.",
                    "label": 0
                },
                {
                    "sent": "Methods across a wide range of the permit number.",
                    "label": 0
                },
                {
                    "sent": "Now I want to give up.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moreover, this method and in terms of the theory we establish is almost fully equivalence between LO sparsity and subdivision properties, and to the best of our knowledge this is the first time we build equivalence and 2nd perspective that we implement our method by both matter matter and could see plus for extremely efficiently cause we found that algorithm is highly parallelizable.",
                    "label": 1
                },
                {
                    "sent": "Call the before for downloading.",
                    "label": 0
                },
                {
                    "sent": "So this is my.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for this presentation.",
                    "label": 0
                }
            ]
        }
    }
}