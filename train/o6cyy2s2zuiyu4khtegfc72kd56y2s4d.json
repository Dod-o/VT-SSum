{
    "id": "o6cyy2s2zuiyu4khtegfc72kd56y2s4d",
    "title": "Deciphering the Face",
    "info": {
        "author": [
            "Aleix M. Martinez, Department of Electrical and Computer Engineering, Ohio State University"
        ],
        "published": "Aug. 24, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/gesturerecognition2011_martinez_deciphering/",
    "segmentation": [
        [
            "So one of the problems is to understand the variability among different subjects, and the question is how are we going to solve this?",
            "One classical solution is you gather lots and lots and lots of data and then you just tried to solve the problem by using pattern recognition or machine learning algorithms that can extrapolate or generalize to new subjects.",
            "That's work.",
            "So so, because if you have a subject that it's very different from the rest that you've used from turning doesn't work.",
            "And because you need tremendous amount of data that, as has been pointed out before, it's not usually the case.",
            "So my approach is completely different.",
            "My approach is I will try to decipher what the perception to human face perception does, or your brain.",
            "In other words, does when it looks at faces.",
            "So."
        ],
        [
            "Just a brief introduction of why this is important.",
            "Why am I interested in decoding how human perception works and this is because it has multiple applications?",
            "Human computer Interaction is a classical example.",
            "We want to build computers and interact with humans much better than the ones we have right now.",
            "Basically, not wanting to kill your computer be a good thing, but also has applications in many other things and in many other domain sign language.",
            "If you've heard, and we've done a lot of work on that, we are doing a lot of work on that.",
            "Computer vision, obviously it has applications in politics and the analysis of art and cognitive science as well, both for the modeling of computational models of the brain or the cognitive processes and for understanding different disorders like autism and others."
        ],
        [
            "At any rate.",
            "What do we know already about face recognition in humans?",
            "Well, we know that we have to decipher two things in order to understand human face perception.",
            "The first one is what are the features that are used by the human visual system to recognize faces?",
            "And we don't really know, but two classical possibilities are either shape features or texture features, and those has have been also used in computer vision consistently, mostly texture in the so call appearance based approach, but also shape.",
            "And then you can also do 2D or 3D which we don't need.",
            "We don't know either if we're using one or the other or two and a half D. And the other problem that you have to address is what is the form of this computational space that human perception uses?",
            "And there are two living theories here.",
            "When it's called the continuous approach which is shown here on your left.",
            "And that assumes that the features that we have defined before big it's shape, features, texture, features or combination of them are or define a multidimensional space, each feature being one of these dimensions of data space, and then a phase is represented.",
            "As a feature vector or a point in that multi dimensional space.",
            "Alternatively, you can have the so called categorical model in which you build a set of classifiers to identify a certain number of classes, be it identity, John versus Joe or expressions, happy versus sad or in some language different types of expressions.",
            "WH questions versus yes, no questions."
        ],
        [
            "So here's what I'm going to show you today.",
            "I'm going to propose a new form of the computational space, which is a hybrid model which is nothing else than the linear combination of continuous representations of certain.",
            "Categories so it's a categorical, a space in a way that it has and different categories.",
            "But each of these categories is represented as a continuous representation and by a linear combining them you create this supposed linear space that people have observed with human subjects.",
            "I'm going to show that the dimensions or features of these continuous space are based on what's called configurable features and configure features to give a quick definition or features that give relationships between different components of the face.",
            "So first order relationships would be browsing tops of the eyes and tops of the nodes and tops of the mouth.",
            "2nd order features should be the distances between these different features, different facial components, or they ratios.",
            "Finally, I'm going to make a big argument here for a big discussion which.",
            "Excuse me, which I think is very important, which if you follow these two or this particular model that I'm defining here, then the next big thing that we need to do in computer vision is to propose methods that achieve a precise and detailed detection of these facial components rather than the classical appearance based or shape based model that has been used in the past."
        ],
        [
            "So to give you a sense of how easy or how difficult face perception is in humans, I'm going to show you a couple of images in each slide I'm going to show you a sequences of slides, and for each couple of images I want you to tell me whether these two faces that are in the picture are the same.",
            "From the same individual or different individual OK?",
            "Be ready, you need to tell me."
        ],
        [
            "Several different."
        ],
        [
            "Same or different?"
        ],
        [
            "Same or different?",
            "Come on.",
            "So why is that some everyone finds these two faces which I selected from the web page of the workshop?",
            "Why do we find that these two phases are so easy to?"
        ],
        [
            "Sify and these ones are not."
        ],
        [
            "Well, because we're extremely tune at these and we're extremely too.",
            "And even though these two images, if you pay close attention, they have pretty much the same background.",
            "They both were the same glasses, or close enough similar hairstyle, similar clothing, even the same tie, or close enough anyways.",
            "Yet we have absolutely no problem identifying them as different people.",
            "Well, the reason is because we have to learn to recognize specifically human faces very reliably.",
            "Ships, on the other hand, are very good at recognizing ship faces.",
            "They can actually recognize their friends after six months or longer in isolation.",
            "Bees, for that matter, can recognize human faces very reliably, so I'm not interested on how bees solve the problem.",
            "I'm not interested on how ships of the problem, which may be very different from how humans solve the problem.",
            "I'm interested in solving the question of how do we do it?",
            "And it's not only identity, of course we can recognize from these two pictures, identity, expression, gender, etc.",
            "But let me show you very quickly yet another case before we think too much about ourselves and tell me whether this is the same or a different individ."
        ],
        [
            "Speak lovely.",
            "So what's going on here?",
            "Yes, this images are indeed of the same individual, but they look different to you because the configural there's been a configural change added to the three different images, so the image in the middle it's the original 1, the one on the left has a larger distance between eyes and mouth, and the one on the right has a wider distance between the center of the eyes.",
            "So these are called configural changes as I've defined before.",
            "And the thinking is that when we look at these things, and when you showed this to human subjects, people tend to perceive these faces as different individuals because.",
            "We believe in face recognition in human face perception.",
            "That configural features are the most important features to recognize."
        ],
        [
            "People.",
            "Not for other, or it's not know if it's for other.",
            "Classifications, but for identity now.",
            "If that were the case, if it's indeed configurable features, how do you build the form of the computation of a space to make this system work?",
            "And here there are two other leading models.",
            "The one showed on the left.",
            "It's called the exemplar model and The One Show on your bottom right corner.",
            "It's the norm based model.",
            "So here on the exemplar based model, what you would have would have the I where you take your picture or your images coming in.",
            "You do first image processing of this in this image as you will know from computer vision called low level vision.",
            "Then you organize this information into a so-called mid level vision and subways at V2.",
            "Before we whatever.",
            "And then you finally move this to the IT an FFA area for some gyrus where there are cells are specifically tuned to face recognition.",
            "And then each identity is recognized here, so itself would be.",
            "Exclusively dedicated to recognize the specific identity so you can see a cell as a Gaussian distribution, shown here.",
            "So whenever I see a picture face that corresponds to this subject, this cell will activate when I see these other subject, these others I will activate.",
            "So in that way I have exemplar that are used to recognize the identity, the other model it's shown here the norm based model and what this says is I first compute the so called.",
            "Average or normal face, which is the average of all the faces I've seen in my life or in a long period of time and then each other phase is represented as a deviation from the norm.",
            "And that model actually explained a few more things than the previous one.",
            "The previous one can explain pretty much everything that has been shown in the literature.",
            "If you change or tune the parameters of the model is likely, but the norm based model explains one particular case better, and that is the effect of caricaturing images.",
            "So if you are familiar with caricaturing that you see in all the newspapers, specially on politicians, they'll create these caricature of the politician.",
            "If the petition has a big nose or make it even larger if he has a big chain, even larger, and so on, and that actually facilitates recognition of that individual.",
            "That is very well explained in this non base model because since I'm moving away from the mean as I'm showing here with the mouth from the main phase to this phase whoops, there goes to this phase if I actually."
        ],
        [
            "Move even further away."
        ],
        [
            "OK, if I actually move further away, I make the recognition easier, Whereas in this exemplar model, if I move away I made recognition more difficult, so that's more difficult to explain with the exemplar based model.",
            "On the other hand, the problem is that there are some other applications where you have an exemplar case or an exemplar model that works better.",
            "For recognition, and that's been the case for recognition of facial expressions of emotion officials.",
            "Official expressions of emotion you or people have shown that were very tuned to a certain number of categories of emotions.",
            "For example, were."
        ],
        [
            "Very good at recognizing there's six emotions shown here.",
            "Starting right here.",
            "This is happiness.",
            "This is sadness, fear.",
            "This is angry, surprise and disgust.",
            "An for comparison, this is the neutral face.",
            "Neutral face can be defined as a face that involved no muscle movement, so it does not express any emotion.",
            "So it turns out that if you run experiments with human subjects, for example, you create a morphing continuum between a neutral face and a happy face, or then a happy face, an angry face.",
            "People don't see more and more and more and more happier, more and more, and more angry what they see is happy, happy, happy, Happy, happy, and then.",
            "Angry and angry, angry, angry, angry.",
            "So it's very categorical.",
            "So there is better explained by the categorical model.",
            "So how can we put all these things together and recognize this?",
            "So I'm going to be talking for the next few minutes about facial expression of emotion to justify the model that I'm."
        ],
        [
            "Going to propose here.",
            "So how do first of all, how do you actually produce facial expressions of emotion?",
            "So the theory goes that if you have an internal emotion, sometimes you will express these externally and you will do that by moving your facial muscles.",
            "And here you should as shown in the left there are variety of large number actually official muscles on the face that you can move not totally individually, although you can be trained to move each one of them individually, it's very hard to learn that.",
            "But good actors still learn to do that, not the ones in Hollywood.",
            "But you know good ones.",
            "So once you learn some of this individual muscles or demman combinations, you can express different concepts to your audience."
        ],
        [
            "So the theory goes, the living models go that to recognize identity.",
            "You use configure features as I've shown you before, but to recognize facial expressions of emotion you actually use.",
            "You actually interpret the movement of the muscles in order to extrapolate.",
            "What is the actual expression that is being expressed to you?",
            "That is very odd, because why you the brain do or use two different completely different algorithms?",
            "I mean, they're not even.",
            "Slightly similar, completely different algorithms.",
            "While the brain just completely different algorithms to solve 2 problems in face perception, so the very first thing that I want to do is to trust this second claim about the muscle movement, and to do that I'm going to show you 2 images and I want you to look at them very attentively and tell me whether the 1st or the 2nd looks sadder, which of the two is soldered to you.",
            "Be ready."
        ],
        [
            "At first a second.",
            "Or do you think speak loudly?",
            "Second, yes, everyone says the second OK?"
        ],
        [
            "So here's what's going on.",
            "The first one, this one.",
            "It's a real neutral face that's is a picture from the AR database neutral image there.",
            "This is what we call a sad face, sad looking face and all we did is we increase the distance between the baseline of the eyebrows and the baseline of the mouth.",
            "Now if you do the reverse, you decrease that distance.",
            "You create what we call an angry looking face.",
            "Now the most striking thing about this is that does not involve.",
            "Any muscle movement.",
            "This is chasser configural distribution.",
            "Based on your bonus structure, you happen to have a short distance between brows and mouth an you basically all your friends think you're always mad.",
            "You happen to have a long one.",
            "Everyone thinks you are really sad and I'm sure you've all heard the famous expression what a long face you have today when you look sad.",
            "Well, you do so this is work with publishing Journal of Vision in 2009.",
            "Demonstrating that actually the brain does use also configure of features to recognize facial."
        ],
        [
            "Questions of emotion and to prove that with human subjects where we did, we created this continuum of this deformation distance between the browsing the mouth and we increase it by the first one.",
            "I showed you 100% distance, so 25% fifty percent 70."
        ],
        [
            "500% and then we create this classical psychophysical experiment where we show a cross to alert subjects of where the image is going to be displayed.",
            "You display the first image, then you go into a blank screen.",
            "You show another cross at another location you show the second image and then you are subjects is the first inside the second image less same or more sad or angry on the other one?"
        ],
        [
            "So here are the results.",
            "As you can see in this plot at in the middle at 0%.",
            "That means that the two images that are shown at the same percentage, either 2525 or 0 zero or a hundred 125.",
            "It means that the difference between the two it's 25, so zero to 2525 to 50 or 75200 and so on.",
            "And 7575 difference 100.",
            "There's only one choice from zero to 100, right?",
            "And what you can see?",
            "This yellow bars, which correspond to the more for the second.",
            "There is a linear increase in the perception of sadness, so the more you increase the distance between the baseline of the browser and the mouth, this other the face looks.",
            "And it's actually linear.",
            "What you know, right?"
        ],
        [
            "When you do this with angry faces, so you decrease.",
            "Now the distance the same effect.",
            "It's also linear, and the more you decrease the distance, the angry looks.",
            "And I'm going to switch between sad and angry.",
            "Sad, angry, sad, angry and you can see there basically the same plots.",
            "So this is basically a dimension of your competition or space that you're using to interpret."
        ],
        [
            "Facial expressions of emotion.",
            "So here's the model that we proposed.",
            "It's a norm based model, not a categorical model that, as it had been proposed for facial expressions of emotion only, that in that case the dimensions are configurable and they can define different interval or different intensities.",
            "Excuse me, different intensities of the emotion.",
            "So for sadness you can go from less sad, which is closer to the moon phase and more and more and more and more sad as you increase the distance or more more more more angry as you decrease the distance.",
            "Income."
        ],
        [
            "Anne, I'm sure you're all familiar with the classical painting American Gothic by would, so this is the male character in that painting, and the most striking thing is that everyone tells me, oh, this guys look so sad.",
            "And if you ever go to Chicago, I highly recommend you go to the Institute to see the actual painting an I look at this and it was like.",
            "He has a neutral expression and actually he does.",
            "If you look very closely.",
            "He is non expressive but what happens is that he has a really uncanny large distance between his brows and his mouth and that creates the impression of a sad face.",
            "So what we did with the morphing software we decrease that distance an now.",
            "If you showed this image to human subjects, most tend to say it looks kind of angry at this point."
        ],
        [
            "So this is the competition of the space that you can create with this.",
            "This is not with real facial expressions of emotion on the left.",
            "You have real sad faces on the right, real angry faces and the corresponding this horizontal dimension here corresponds to the distance between the browser and the mouth.",
            "In this real images of sad and angry, which are from the eggmen set.",
            "And then these different representative vectors here feature vectors.",
            "Correspond to the angry faces in blue and the sad faces in pink.",
            "And now you can see that if I draw bar about the average distance between browse and mouth, I get 100% recognition rate between angry and sad face.",
            "So let me repeat this again 100% using just one dimensional feature space.",
            "Come on, that's a wild woman alright?",
            "So what are other dimensions that can influence the perception of your sad and angry face?"
        ],
        [
            "Other one that we found I don't have time here to go through the details, but this isn't a follow up paper in vision research.",
            "It's the ratio between the width of the face in the height of the face, so you can actually see that sad faces tend to be longer faces, so thinner faces and angry faces tend to be wider faces.",
            "And actually if you create an angry expression, you tend to shorten your face and move and created wider expression.",
            "Whereas if you are sad, you tend to actually.",
            "Anyone get the face and by dropping this jaw and making it thinner?"
        ],
        [
            "So if you now go to the American Gothic painting and not only you decrease the distance between the mouse and the brows, but you make these guys face, why there?",
            "Now he really looks angry."
        ],
        [
            "So the question is, why do we use Configural features?",
            "Why should we care right?",
            "Why do we just configure features an the class?",
            "The reason is because this allows us to be robust to multiple things.",
            "In phase variation.",
            "One of them, as I said it right at the beginning is multiple individuals, right?",
            "We can recognize sadness and anger from everyone, but the second thing is we can recognize it under a lot of noisy conditions.",
            "Let me show you one other image.",
            "This is another test.",
            "This is a fun.",
            "Presentation, isn't it?",
            "You have to be alert all the time.",
            "Alright?",
            "So I'm going to show you another image very quickly and I want you to tell me what's official.",
            "Expression of emotion in that image ready."
        ],
        [
            "What is it?",
            "Happy yes, happy it is so wow, how can we recognize happiness from this?"
        ],
        [
            "Image this is 15 by 10 pixels now 15 by 10 it's a whole image.",
            "The face is probably I know 7 by 5 something like this and we still have no problem recognizing happiness.",
            "Now if you look at the two points where the errors are with the eyes are there is a configural change that is very easy to detect, which is the size of the eyes have reduced because a good smile involves the eyes.",
            "As you know the corners of the eyes and the mouth has been open, which is another configure.",
            "Change the distance between.",
            "The upper lip and the lower lip.",
            "Easy to detect by humans.",
            "Still not buy computers, but we're getting there, but we're very robust.",
            "It is to detecting this even at this low."
        ],
        [
            "Very low resolution.",
            "The same for angry.",
            "An inset faces that I showed you earlier.",
            "Again the center image is a neutral face and what I've done, I've aligned all these faces with the baseline of the mouth and now you can see on the left the eyebrows of the sad face are above the baseline of the eyebrows of the neutral and the angry eyebrows are below the baseline.",
            "Easy to detect if you can detect where the mouth is and the eyebrows are.",
            "You are set to recognize sadness and angry expressions even at this low quality image or in this low quality images.",
            "OK."
        ],
        [
            "So here's the model that I'm proposing to wrap up all these things that I've been climbing until now.",
            "I propose that each facial expression of emotion.",
            "Or is is represented by a continuous representation and norm based representation?",
            "As I showed you and that allows you to recognize where robustly all the facial expressions of emotion that are most common in our society.",
            "This is very good, but this is the claim that continuous model continues modelist with be saying at this point how am I going to recognize new facial expressions of emotion that don't have their own category?",
            "Because here I have.",
            "Say six or seven or eight categories, one for Happy, one for sad.",
            "When for angry, and so on, right?",
            "But now I get a new official expression of emotion that is not in one of these cultures.",
            "How is the recognition of that?",
            "I linearly combine them and now I can create happily surprised or angry surprise, and this is very recent work that we are developing in our lab.",
            "So I really encourage you to keep checking our web page in the next few months.",
            "I was surprised by the previous speaker that the student didn't want to.",
            "The describe the things that he was doing at that point or at this point in time.",
            "I always encourage people to talk about what you're doing now and the things that has not have not been published, because that's the best way for you to make sure that no one is going to publish it before you.",
            "You've already said it alright, so this is defining the CVR paper anyways that it's associated to this workshop, so you can read more about this."
        ],
        [
            "Later.",
            "So the question is, if we want to build computer vision algorithms that solve this problem, we have to be able to detect facial components very accurately because humans are very accurate as you can see, we are very sensitive to these small changes in distance between browsing eyes.",
            "Distances between upper lip and lower lip and so on.",
            "And these are very small differences.",
            "Sometimes it's two pixels, one pixel and we're still sensitive to that.",
            "So the question is for or in general, how sensitive are we to?",
            "Give an answer to this question.",
            "We choose three graduate students from my lap.",
            "And yes, that's what it takes to do a PhD these days and we ask them to manually annotate almost 4000 images.",
            "Now when I say manually notate 4000 images, I don't mean to do a simple annotation, but to provide this in-depth annotation that you see here of the eyebrows, eyes, inner circles of the of the.",
            "This is the narrows, industrials the mouth, and so on.",
            "So now the task is, can we build computer vision algorithms that are as accurate of this as this one?",
            "And this is work defining Pammy.",
            "And as you may have seen before, I'm going to show you this image and you have to find the face."
        ],
        [
            "Can you find the face?",
            "OK, I don't have time, it's here.",
            "So this this is hard, isn't it?",
            "Well, this is what computers are supposed to do.",
            "We give them an image and say find a face as if that were that simple.",
            "It's not simple, it's very difficult.",
            "And if you do that, you're going to have two problems.",
            "The first problem is you don't know where to look, so you have to scan the whole image right?",
            "Which is where you were probably doing.",
            "And the second thing is if you have a template that's going to scan through the image at the end is going to give you.",
            "A lot of results around the actual face.",
            "Not only were the faces, but here and here and here and here at different sizes, because that template matches imprecisely detected faces, and that's what worries me.",
            "This imprecise word, so I'm going to have to try to resolve this problem right here.",
            "How can we do that?",
            "There are multiple ways, but here's a."
        ],
        [
            "A way to do this which we define in Pammy in a recent paper in 2008, actually with early presented us in CPR.",
            "So basically what we do is we collect a large number of faces, well detected faces at different orientations if eliminations, what have you, and then we.",
            "Automatically extract miss detected faces from that set so you can see on the top row these are perfectly detected faces in the bottom row.",
            "These are the not so well detected faces and this week all the context of the face because it contains all the context information that helps you detect the face.",
            "At this point you can use a mixture of gases to represent the actual faces and mixture of Gaussians to represent non not well detected faces and now what you do when you detect the faces.",
            "You move toward the correctly detected faces away from the miss detected faces and that pushes you to improve the recognition of your face.",
            "But normally you can do that for faces.",
            "You can do it for groups."
        ],
        [
            "Alright, you can do it for eyes, corners of the eyes."
        ],
        [
            "Gnosis corners of the Gnosis map."
        ],
        [
            "This corner of the mouth and so on, and we use subclasses Kim analysis to do this learning means basically because it's a method that gives you the IT automatically gives you the number of Gaussians that you need, and that's in a payment paper represented."
        ],
        [
            "Six and these are the results.",
            "We have a sequence of in American Sign Language sequence and you can see that we can achieve very accurate, very precisely detections of all the major facial components."
        ],
        [
            "In the groups well with them in it."
        ],
        [
            "And the recognition excuse me, the detection error was in a very large in the same number of images.",
            "Acosta 4000 images that we had in the database, about 6.2 pixels or 2% of the image, which is not as good as humans, but pretty close.",
            "So we're getting close goes to humans."
        ],
        [
            "Here's something that you can do.",
            "Once you have these detection.",
            "This is again another sequence of American Sign Language.",
            "You can use non richiede structure from motion and recovered the three dimensional phase and as it deforms and then you can use this to model American Sign Language, facial expressions of emotions and just this hybrid model that I proposed here and I encourage you to go Wednesday to see my students poster who is here and I promise I really could push there alright."
        ],
        [
            "And to conclude, very quickly just a the repeat.",
            "My take home messages.",
            "I have proposed a linear combination of categorical models.",
            "Each categorical models represented as a continuous model in a norm based representation.",
            "The features of these models are configurable mostly and to achieve or emulate this in computers we need to move toward precise detection of."
        ],
        [
            "Special features and thank you so much for listening, but I do very much my students, which are the ones that really did all these work.",
            "And here they are.",
            "And obviously I have to acknowledge the National Institutes of Health or they support.",
            "It's been great over the years and also the National Science Foundation.",
            "Thanks so much.",
            "To detect the emotion, how do you get the norm face to begin with?",
            "For sad, it's like longer than the norm face an angry's.",
            "Short term, that's that's a very good question.",
            "So to repeat the question to make sure I understand you correctly is how do you know what's the average distance between the browser and the mouth, right?",
            "For a specific person, right?",
            "It can't be so.",
            "It's not for a specific person, it's generally in a population.",
            "So, have you notice that some of your friends obviously look happier or angrier or sadder, which is.",
            "Because that's how they are.",
            "That's because their phase deviates more from the norm phase than the others, right?",
            "So what you do is with experience.",
            "You tune the average distance between browser mouth an what we've done in the vision Research paper.",
            "We actually have an experiment where we have Caucasian subjects, rate location faces an Asian faces, and what happens is that Asian faces tend to be shorter in height and why they are so you actually get an effect.",
            "Of the what's called the other race effect, which is caused by your norm representation of the distance between the.",
            "I'm sorry the mouth and they browse right which is different in agents and I guess for different applications if it's necessary to get a subject based norm, you can probably do that.",
            "Also you could do that.",
            "Definitely.",
            "Yes I completely agree, right?",
            "If you want it to be subject specific in a human computer interaction application, yes indeed, that's a very good point, thanks, thank you.",
            "Hi very nice talking.",
            "How does the this idea of absolute distance for across all people for you know baseline?",
            "Of, say, emotion compared to or square with the research on after images of widening, or narrowing or lengthening the face because their people adapt very quickly if they see a lot of tall fat space.",
            "That's a great question too.",
            "So let me go back here very quickly if I can.",
            "You OK?",
            "And getting there, yeah, OK, so here's what's going on.",
            "You have compute this mean distance between browsing mouth, right?",
            "And now you show a image that has a really long distance between browser mouth and you show it and you ask the subject to a stair to that image for three minutes and then in in cognitive psychology that's called adaptation.",
            "Your visual system adapts to this new perception and what happens is that mean phase?",
            "If I get my mouth here?",
            "This mean face Move tour that knew the new image that newest stimulus, OK, and now your mean face is right here.",
            "So when you show this phase at 25%, it doesn't look sad or angry anymore, right?",
            "It looks the angry ones would look even angrier in a way because you have adapted toward that new norm.",
            "OK thanks sure.",
            "Yes, risk crossing.",
            "Yeah, very nice talk.",
            "I like very much your approach because it's like what we're trying to do is like you're trying to find the manifold of expressions, right?",
            "What is the least set of parameters that make you think this is smiling?",
            "So I think you can.",
            "I think for formalized a lot more.",
            "Another question I have is.",
            "You show a little bit exaggerated expressions like are you working with normal or across cultures because?",
            "That's a classical question.",
            "It's a good question, so here's the problem and we have to acknowledge this in the community.",
            "The problem in facial expressions of emotion that's very difficult.",
            "Not the same possible to collect real emotions, real facial expressions of emotion because you cannot go around while people are expressing emotions and just be taking pictures of the time right?",
            "So it's very hard and most of the databases in.",
            "99% of the databases 30 matches you find out there are from post emotions and imposed emotions.",
            "You have these exaggerated expressions right?",
            "And some people are more expressive than others, but in general you tend to exaggerate this a little.",
            "Overall, I think that for now this is OK because we are right at the beginning of all this research and so little is known about how facial expressions of emotion or about how facial expressions of grammar in ASL.",
            "Work so it's OK to work with this, but in the near future to 3 four years from now, we definitely need to start going to wear and more realistic setting an for that which has have to somehow find a mechanism that is IRB approval and allows us to collect data of facial expression of emotion in Israel.",
            "Farmers were trying do something.",
            "Also.",
            "Another thing we're trying to do is not just start faces, but like movies like the whole expression, so indeed.",
            "And there has been some data collection on movies an there are Eva receiving database.",
            "I'm aware of that has a 3 dimensional movie, meaning that it's 3D in movie in time.",
            "So all these things are coming.",
            "But again, they're all post emotions, right?",
            "Another another thing that I want to make clear is that even with this post emotions I'm gonna see if I can find this very quickly even with this post emotions, the recognition grade that you get from humans, it's actually not that good so.",
            "This is at maximum resolution, so you see that we are extremely good.",
            "Humans are extremely good at recognizing happiness.",
            "We are very good at recognizing surprise.",
            "We are in blue right here in red.",
            "We are OK at recognizing anger and what is it?",
            "Oh yeah, anger and sadness and we're very bad actually, in general at recognizing fear and disgust, we're not good at this.",
            "Although most evolutionary psychologists who tell you that fear, it's this primal facial expression that we are also good at recognizing that where we found is that we're not.",
            "We're definitely not.",
            "Best at surprised an happiness.",
            "Alright, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one of the problems is to understand the variability among different subjects, and the question is how are we going to solve this?",
                    "label": 0
                },
                {
                    "sent": "One classical solution is you gather lots and lots and lots of data and then you just tried to solve the problem by using pattern recognition or machine learning algorithms that can extrapolate or generalize to new subjects.",
                    "label": 0
                },
                {
                    "sent": "That's work.",
                    "label": 0
                },
                {
                    "sent": "So so, because if you have a subject that it's very different from the rest that you've used from turning doesn't work.",
                    "label": 0
                },
                {
                    "sent": "And because you need tremendous amount of data that, as has been pointed out before, it's not usually the case.",
                    "label": 0
                },
                {
                    "sent": "So my approach is completely different.",
                    "label": 0
                },
                {
                    "sent": "My approach is I will try to decipher what the perception to human face perception does, or your brain.",
                    "label": 0
                },
                {
                    "sent": "In other words, does when it looks at faces.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a brief introduction of why this is important.",
                    "label": 0
                },
                {
                    "sent": "Why am I interested in decoding how human perception works and this is because it has multiple applications?",
                    "label": 0
                },
                {
                    "sent": "Human computer Interaction is a classical example.",
                    "label": 0
                },
                {
                    "sent": "We want to build computers and interact with humans much better than the ones we have right now.",
                    "label": 0
                },
                {
                    "sent": "Basically, not wanting to kill your computer be a good thing, but also has applications in many other things and in many other domain sign language.",
                    "label": 0
                },
                {
                    "sent": "If you've heard, and we've done a lot of work on that, we are doing a lot of work on that.",
                    "label": 0
                },
                {
                    "sent": "Computer vision, obviously it has applications in politics and the analysis of art and cognitive science as well, both for the modeling of computational models of the brain or the cognitive processes and for understanding different disorders like autism and others.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At any rate.",
                    "label": 0
                },
                {
                    "sent": "What do we know already about face recognition in humans?",
                    "label": 0
                },
                {
                    "sent": "Well, we know that we have to decipher two things in order to understand human face perception.",
                    "label": 1
                },
                {
                    "sent": "The first one is what are the features that are used by the human visual system to recognize faces?",
                    "label": 0
                },
                {
                    "sent": "And we don't really know, but two classical possibilities are either shape features or texture features, and those has have been also used in computer vision consistently, mostly texture in the so call appearance based approach, but also shape.",
                    "label": 0
                },
                {
                    "sent": "And then you can also do 2D or 3D which we don't need.",
                    "label": 0
                },
                {
                    "sent": "We don't know either if we're using one or the other or two and a half D. And the other problem that you have to address is what is the form of this computational space that human perception uses?",
                    "label": 1
                },
                {
                    "sent": "And there are two living theories here.",
                    "label": 0
                },
                {
                    "sent": "When it's called the continuous approach which is shown here on your left.",
                    "label": 0
                },
                {
                    "sent": "And that assumes that the features that we have defined before big it's shape, features, texture, features or combination of them are or define a multidimensional space, each feature being one of these dimensions of data space, and then a phase is represented.",
                    "label": 0
                },
                {
                    "sent": "As a feature vector or a point in that multi dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, you can have the so called categorical model in which you build a set of classifiers to identify a certain number of classes, be it identity, John versus Joe or expressions, happy versus sad or in some language different types of expressions.",
                    "label": 0
                },
                {
                    "sent": "WH questions versus yes, no questions.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's what I'm going to show you today.",
                    "label": 1
                },
                {
                    "sent": "I'm going to propose a new form of the computational space, which is a hybrid model which is nothing else than the linear combination of continuous representations of certain.",
                    "label": 1
                },
                {
                    "sent": "Categories so it's a categorical, a space in a way that it has and different categories.",
                    "label": 0
                },
                {
                    "sent": "But each of these categories is represented as a continuous representation and by a linear combining them you create this supposed linear space that people have observed with human subjects.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show that the dimensions or features of these continuous space are based on what's called configurable features and configure features to give a quick definition or features that give relationships between different components of the face.",
                    "label": 0
                },
                {
                    "sent": "So first order relationships would be browsing tops of the eyes and tops of the nodes and tops of the mouth.",
                    "label": 0
                },
                {
                    "sent": "2nd order features should be the distances between these different features, different facial components, or they ratios.",
                    "label": 0
                },
                {
                    "sent": "Finally, I'm going to make a big argument here for a big discussion which.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, which I think is very important, which if you follow these two or this particular model that I'm defining here, then the next big thing that we need to do in computer vision is to propose methods that achieve a precise and detailed detection of these facial components rather than the classical appearance based or shape based model that has been used in the past.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to give you a sense of how easy or how difficult face perception is in humans, I'm going to show you a couple of images in each slide I'm going to show you a sequences of slides, and for each couple of images I want you to tell me whether these two faces that are in the picture are the same.",
                    "label": 0
                },
                {
                    "sent": "From the same individual or different individual OK?",
                    "label": 0
                },
                {
                    "sent": "Be ready, you need to tell me.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Several different.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same or different?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same or different?",
                    "label": 0
                },
                {
                    "sent": "Come on.",
                    "label": 0
                },
                {
                    "sent": "So why is that some everyone finds these two faces which I selected from the web page of the workshop?",
                    "label": 0
                },
                {
                    "sent": "Why do we find that these two phases are so easy to?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sify and these ones are not.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, because we're extremely tune at these and we're extremely too.",
                    "label": 0
                },
                {
                    "sent": "And even though these two images, if you pay close attention, they have pretty much the same background.",
                    "label": 0
                },
                {
                    "sent": "They both were the same glasses, or close enough similar hairstyle, similar clothing, even the same tie, or close enough anyways.",
                    "label": 0
                },
                {
                    "sent": "Yet we have absolutely no problem identifying them as different people.",
                    "label": 0
                },
                {
                    "sent": "Well, the reason is because we have to learn to recognize specifically human faces very reliably.",
                    "label": 0
                },
                {
                    "sent": "Ships, on the other hand, are very good at recognizing ship faces.",
                    "label": 0
                },
                {
                    "sent": "They can actually recognize their friends after six months or longer in isolation.",
                    "label": 0
                },
                {
                    "sent": "Bees, for that matter, can recognize human faces very reliably, so I'm not interested on how bees solve the problem.",
                    "label": 0
                },
                {
                    "sent": "I'm not interested on how ships of the problem, which may be very different from how humans solve the problem.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in solving the question of how do we do it?",
                    "label": 0
                },
                {
                    "sent": "And it's not only identity, of course we can recognize from these two pictures, identity, expression, gender, etc.",
                    "label": 1
                },
                {
                    "sent": "But let me show you very quickly yet another case before we think too much about ourselves and tell me whether this is the same or a different individ.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speak lovely.",
                    "label": 0
                },
                {
                    "sent": "So what's going on here?",
                    "label": 0
                },
                {
                    "sent": "Yes, this images are indeed of the same individual, but they look different to you because the configural there's been a configural change added to the three different images, so the image in the middle it's the original 1, the one on the left has a larger distance between eyes and mouth, and the one on the right has a wider distance between the center of the eyes.",
                    "label": 0
                },
                {
                    "sent": "So these are called configural changes as I've defined before.",
                    "label": 0
                },
                {
                    "sent": "And the thinking is that when we look at these things, and when you showed this to human subjects, people tend to perceive these faces as different individuals because.",
                    "label": 0
                },
                {
                    "sent": "We believe in face recognition in human face perception.",
                    "label": 0
                },
                {
                    "sent": "That configural features are the most important features to recognize.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People.",
                    "label": 0
                },
                {
                    "sent": "Not for other, or it's not know if it's for other.",
                    "label": 0
                },
                {
                    "sent": "Classifications, but for identity now.",
                    "label": 0
                },
                {
                    "sent": "If that were the case, if it's indeed configurable features, how do you build the form of the computation of a space to make this system work?",
                    "label": 1
                },
                {
                    "sent": "And here there are two other leading models.",
                    "label": 0
                },
                {
                    "sent": "The one showed on the left.",
                    "label": 0
                },
                {
                    "sent": "It's called the exemplar model and The One Show on your bottom right corner.",
                    "label": 0
                },
                {
                    "sent": "It's the norm based model.",
                    "label": 0
                },
                {
                    "sent": "So here on the exemplar based model, what you would have would have the I where you take your picture or your images coming in.",
                    "label": 1
                },
                {
                    "sent": "You do first image processing of this in this image as you will know from computer vision called low level vision.",
                    "label": 0
                },
                {
                    "sent": "Then you organize this information into a so-called mid level vision and subways at V2.",
                    "label": 0
                },
                {
                    "sent": "Before we whatever.",
                    "label": 0
                },
                {
                    "sent": "And then you finally move this to the IT an FFA area for some gyrus where there are cells are specifically tuned to face recognition.",
                    "label": 0
                },
                {
                    "sent": "And then each identity is recognized here, so itself would be.",
                    "label": 0
                },
                {
                    "sent": "Exclusively dedicated to recognize the specific identity so you can see a cell as a Gaussian distribution, shown here.",
                    "label": 0
                },
                {
                    "sent": "So whenever I see a picture face that corresponds to this subject, this cell will activate when I see these other subject, these others I will activate.",
                    "label": 0
                },
                {
                    "sent": "So in that way I have exemplar that are used to recognize the identity, the other model it's shown here the norm based model and what this says is I first compute the so called.",
                    "label": 0
                },
                {
                    "sent": "Average or normal face, which is the average of all the faces I've seen in my life or in a long period of time and then each other phase is represented as a deviation from the norm.",
                    "label": 0
                },
                {
                    "sent": "And that model actually explained a few more things than the previous one.",
                    "label": 0
                },
                {
                    "sent": "The previous one can explain pretty much everything that has been shown in the literature.",
                    "label": 0
                },
                {
                    "sent": "If you change or tune the parameters of the model is likely, but the norm based model explains one particular case better, and that is the effect of caricaturing images.",
                    "label": 0
                },
                {
                    "sent": "So if you are familiar with caricaturing that you see in all the newspapers, specially on politicians, they'll create these caricature of the politician.",
                    "label": 0
                },
                {
                    "sent": "If the petition has a big nose or make it even larger if he has a big chain, even larger, and so on, and that actually facilitates recognition of that individual.",
                    "label": 0
                },
                {
                    "sent": "That is very well explained in this non base model because since I'm moving away from the mean as I'm showing here with the mouth from the main phase to this phase whoops, there goes to this phase if I actually.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move even further away.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, if I actually move further away, I make the recognition easier, Whereas in this exemplar model, if I move away I made recognition more difficult, so that's more difficult to explain with the exemplar based model.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, the problem is that there are some other applications where you have an exemplar case or an exemplar model that works better.",
                    "label": 0
                },
                {
                    "sent": "For recognition, and that's been the case for recognition of facial expressions of emotion officials.",
                    "label": 0
                },
                {
                    "sent": "Official expressions of emotion you or people have shown that were very tuned to a certain number of categories of emotions.",
                    "label": 0
                },
                {
                    "sent": "For example, were.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very good at recognizing there's six emotions shown here.",
                    "label": 0
                },
                {
                    "sent": "Starting right here.",
                    "label": 0
                },
                {
                    "sent": "This is happiness.",
                    "label": 0
                },
                {
                    "sent": "This is sadness, fear.",
                    "label": 0
                },
                {
                    "sent": "This is angry, surprise and disgust.",
                    "label": 0
                },
                {
                    "sent": "An for comparison, this is the neutral face.",
                    "label": 0
                },
                {
                    "sent": "Neutral face can be defined as a face that involved no muscle movement, so it does not express any emotion.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that if you run experiments with human subjects, for example, you create a morphing continuum between a neutral face and a happy face, or then a happy face, an angry face.",
                    "label": 0
                },
                {
                    "sent": "People don't see more and more and more and more happier, more and more, and more angry what they see is happy, happy, happy, Happy, happy, and then.",
                    "label": 0
                },
                {
                    "sent": "Angry and angry, angry, angry, angry.",
                    "label": 0
                },
                {
                    "sent": "So it's very categorical.",
                    "label": 0
                },
                {
                    "sent": "So there is better explained by the categorical model.",
                    "label": 0
                },
                {
                    "sent": "So how can we put all these things together and recognize this?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to be talking for the next few minutes about facial expression of emotion to justify the model that I'm.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to propose here.",
                    "label": 0
                },
                {
                    "sent": "So how do first of all, how do you actually produce facial expressions of emotion?",
                    "label": 0
                },
                {
                    "sent": "So the theory goes that if you have an internal emotion, sometimes you will express these externally and you will do that by moving your facial muscles.",
                    "label": 0
                },
                {
                    "sent": "And here you should as shown in the left there are variety of large number actually official muscles on the face that you can move not totally individually, although you can be trained to move each one of them individually, it's very hard to learn that.",
                    "label": 0
                },
                {
                    "sent": "But good actors still learn to do that, not the ones in Hollywood.",
                    "label": 0
                },
                {
                    "sent": "But you know good ones.",
                    "label": 0
                },
                {
                    "sent": "So once you learn some of this individual muscles or demman combinations, you can express different concepts to your audience.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the theory goes, the living models go that to recognize identity.",
                    "label": 0
                },
                {
                    "sent": "You use configure features as I've shown you before, but to recognize facial expressions of emotion you actually use.",
                    "label": 0
                },
                {
                    "sent": "You actually interpret the movement of the muscles in order to extrapolate.",
                    "label": 0
                },
                {
                    "sent": "What is the actual expression that is being expressed to you?",
                    "label": 0
                },
                {
                    "sent": "That is very odd, because why you the brain do or use two different completely different algorithms?",
                    "label": 0
                },
                {
                    "sent": "I mean, they're not even.",
                    "label": 0
                },
                {
                    "sent": "Slightly similar, completely different algorithms.",
                    "label": 0
                },
                {
                    "sent": "While the brain just completely different algorithms to solve 2 problems in face perception, so the very first thing that I want to do is to trust this second claim about the muscle movement, and to do that I'm going to show you 2 images and I want you to look at them very attentively and tell me whether the 1st or the 2nd looks sadder, which of the two is soldered to you.",
                    "label": 0
                },
                {
                    "sent": "Be ready.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At first a second.",
                    "label": 0
                },
                {
                    "sent": "Or do you think speak loudly?",
                    "label": 0
                },
                {
                    "sent": "Second, yes, everyone says the second OK?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what's going on.",
                    "label": 0
                },
                {
                    "sent": "The first one, this one.",
                    "label": 0
                },
                {
                    "sent": "It's a real neutral face that's is a picture from the AR database neutral image there.",
                    "label": 0
                },
                {
                    "sent": "This is what we call a sad face, sad looking face and all we did is we increase the distance between the baseline of the eyebrows and the baseline of the mouth.",
                    "label": 0
                },
                {
                    "sent": "Now if you do the reverse, you decrease that distance.",
                    "label": 0
                },
                {
                    "sent": "You create what we call an angry looking face.",
                    "label": 0
                },
                {
                    "sent": "Now the most striking thing about this is that does not involve.",
                    "label": 0
                },
                {
                    "sent": "Any muscle movement.",
                    "label": 0
                },
                {
                    "sent": "This is chasser configural distribution.",
                    "label": 0
                },
                {
                    "sent": "Based on your bonus structure, you happen to have a short distance between brows and mouth an you basically all your friends think you're always mad.",
                    "label": 0
                },
                {
                    "sent": "You happen to have a long one.",
                    "label": 0
                },
                {
                    "sent": "Everyone thinks you are really sad and I'm sure you've all heard the famous expression what a long face you have today when you look sad.",
                    "label": 0
                },
                {
                    "sent": "Well, you do so this is work with publishing Journal of Vision in 2009.",
                    "label": 0
                },
                {
                    "sent": "Demonstrating that actually the brain does use also configure of features to recognize facial.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Questions of emotion and to prove that with human subjects where we did, we created this continuum of this deformation distance between the browsing the mouth and we increase it by the first one.",
                    "label": 0
                },
                {
                    "sent": "I showed you 100% distance, so 25% fifty percent 70.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "500% and then we create this classical psychophysical experiment where we show a cross to alert subjects of where the image is going to be displayed.",
                    "label": 0
                },
                {
                    "sent": "You display the first image, then you go into a blank screen.",
                    "label": 0
                },
                {
                    "sent": "You show another cross at another location you show the second image and then you are subjects is the first inside the second image less same or more sad or angry on the other one?",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are the results.",
                    "label": 0
                },
                {
                    "sent": "As you can see in this plot at in the middle at 0%.",
                    "label": 0
                },
                {
                    "sent": "That means that the two images that are shown at the same percentage, either 2525 or 0 zero or a hundred 125.",
                    "label": 0
                },
                {
                    "sent": "It means that the difference between the two it's 25, so zero to 2525 to 50 or 75200 and so on.",
                    "label": 0
                },
                {
                    "sent": "And 7575 difference 100.",
                    "label": 0
                },
                {
                    "sent": "There's only one choice from zero to 100, right?",
                    "label": 0
                },
                {
                    "sent": "And what you can see?",
                    "label": 0
                },
                {
                    "sent": "This yellow bars, which correspond to the more for the second.",
                    "label": 0
                },
                {
                    "sent": "There is a linear increase in the perception of sadness, so the more you increase the distance between the baseline of the browser and the mouth, this other the face looks.",
                    "label": 0
                },
                {
                    "sent": "And it's actually linear.",
                    "label": 0
                },
                {
                    "sent": "What you know, right?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you do this with angry faces, so you decrease.",
                    "label": 0
                },
                {
                    "sent": "Now the distance the same effect.",
                    "label": 0
                },
                {
                    "sent": "It's also linear, and the more you decrease the distance, the angry looks.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to switch between sad and angry.",
                    "label": 0
                },
                {
                    "sent": "Sad, angry, sad, angry and you can see there basically the same plots.",
                    "label": 0
                },
                {
                    "sent": "So this is basically a dimension of your competition or space that you're using to interpret.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Facial expressions of emotion.",
                    "label": 0
                },
                {
                    "sent": "So here's the model that we proposed.",
                    "label": 0
                },
                {
                    "sent": "It's a norm based model, not a categorical model that, as it had been proposed for facial expressions of emotion only, that in that case the dimensions are configurable and they can define different interval or different intensities.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, different intensities of the emotion.",
                    "label": 0
                },
                {
                    "sent": "So for sadness you can go from less sad, which is closer to the moon phase and more and more and more and more sad as you increase the distance or more more more more angry as you decrease the distance.",
                    "label": 0
                },
                {
                    "sent": "Income.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne, I'm sure you're all familiar with the classical painting American Gothic by would, so this is the male character in that painting, and the most striking thing is that everyone tells me, oh, this guys look so sad.",
                    "label": 0
                },
                {
                    "sent": "And if you ever go to Chicago, I highly recommend you go to the Institute to see the actual painting an I look at this and it was like.",
                    "label": 0
                },
                {
                    "sent": "He has a neutral expression and actually he does.",
                    "label": 0
                },
                {
                    "sent": "If you look very closely.",
                    "label": 0
                },
                {
                    "sent": "He is non expressive but what happens is that he has a really uncanny large distance between his brows and his mouth and that creates the impression of a sad face.",
                    "label": 0
                },
                {
                    "sent": "So what we did with the morphing software we decrease that distance an now.",
                    "label": 0
                },
                {
                    "sent": "If you showed this image to human subjects, most tend to say it looks kind of angry at this point.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the competition of the space that you can create with this.",
                    "label": 0
                },
                {
                    "sent": "This is not with real facial expressions of emotion on the left.",
                    "label": 0
                },
                {
                    "sent": "You have real sad faces on the right, real angry faces and the corresponding this horizontal dimension here corresponds to the distance between the browser and the mouth.",
                    "label": 0
                },
                {
                    "sent": "In this real images of sad and angry, which are from the eggmen set.",
                    "label": 0
                },
                {
                    "sent": "And then these different representative vectors here feature vectors.",
                    "label": 0
                },
                {
                    "sent": "Correspond to the angry faces in blue and the sad faces in pink.",
                    "label": 0
                },
                {
                    "sent": "And now you can see that if I draw bar about the average distance between browse and mouth, I get 100% recognition rate between angry and sad face.",
                    "label": 0
                },
                {
                    "sent": "So let me repeat this again 100% using just one dimensional feature space.",
                    "label": 0
                },
                {
                    "sent": "Come on, that's a wild woman alright?",
                    "label": 0
                },
                {
                    "sent": "So what are other dimensions that can influence the perception of your sad and angry face?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other one that we found I don't have time here to go through the details, but this isn't a follow up paper in vision research.",
                    "label": 1
                },
                {
                    "sent": "It's the ratio between the width of the face in the height of the face, so you can actually see that sad faces tend to be longer faces, so thinner faces and angry faces tend to be wider faces.",
                    "label": 0
                },
                {
                    "sent": "And actually if you create an angry expression, you tend to shorten your face and move and created wider expression.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you are sad, you tend to actually.",
                    "label": 0
                },
                {
                    "sent": "Anyone get the face and by dropping this jaw and making it thinner?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you now go to the American Gothic painting and not only you decrease the distance between the mouse and the brows, but you make these guys face, why there?",
                    "label": 0
                },
                {
                    "sent": "Now he really looks angry.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the question is, why do we use Configural features?",
                    "label": 0
                },
                {
                    "sent": "Why should we care right?",
                    "label": 0
                },
                {
                    "sent": "Why do we just configure features an the class?",
                    "label": 0
                },
                {
                    "sent": "The reason is because this allows us to be robust to multiple things.",
                    "label": 0
                },
                {
                    "sent": "In phase variation.",
                    "label": 0
                },
                {
                    "sent": "One of them, as I said it right at the beginning is multiple individuals, right?",
                    "label": 0
                },
                {
                    "sent": "We can recognize sadness and anger from everyone, but the second thing is we can recognize it under a lot of noisy conditions.",
                    "label": 0
                },
                {
                    "sent": "Let me show you one other image.",
                    "label": 0
                },
                {
                    "sent": "This is another test.",
                    "label": 0
                },
                {
                    "sent": "This is a fun.",
                    "label": 0
                },
                {
                    "sent": "Presentation, isn't it?",
                    "label": 0
                },
                {
                    "sent": "You have to be alert all the time.",
                    "label": 0
                },
                {
                    "sent": "Alright?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to show you another image very quickly and I want you to tell me what's official.",
                    "label": 0
                },
                {
                    "sent": "Expression of emotion in that image ready.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is it?",
                    "label": 0
                },
                {
                    "sent": "Happy yes, happy it is so wow, how can we recognize happiness from this?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Image this is 15 by 10 pixels now 15 by 10 it's a whole image.",
                    "label": 0
                },
                {
                    "sent": "The face is probably I know 7 by 5 something like this and we still have no problem recognizing happiness.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at the two points where the errors are with the eyes are there is a configural change that is very easy to detect, which is the size of the eyes have reduced because a good smile involves the eyes.",
                    "label": 0
                },
                {
                    "sent": "As you know the corners of the eyes and the mouth has been open, which is another configure.",
                    "label": 0
                },
                {
                    "sent": "Change the distance between.",
                    "label": 0
                },
                {
                    "sent": "The upper lip and the lower lip.",
                    "label": 0
                },
                {
                    "sent": "Easy to detect by humans.",
                    "label": 0
                },
                {
                    "sent": "Still not buy computers, but we're getting there, but we're very robust.",
                    "label": 0
                },
                {
                    "sent": "It is to detecting this even at this low.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very low resolution.",
                    "label": 0
                },
                {
                    "sent": "The same for angry.",
                    "label": 0
                },
                {
                    "sent": "An inset faces that I showed you earlier.",
                    "label": 0
                },
                {
                    "sent": "Again the center image is a neutral face and what I've done, I've aligned all these faces with the baseline of the mouth and now you can see on the left the eyebrows of the sad face are above the baseline of the eyebrows of the neutral and the angry eyebrows are below the baseline.",
                    "label": 0
                },
                {
                    "sent": "Easy to detect if you can detect where the mouth is and the eyebrows are.",
                    "label": 0
                },
                {
                    "sent": "You are set to recognize sadness and angry expressions even at this low quality image or in this low quality images.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the model that I'm proposing to wrap up all these things that I've been climbing until now.",
                    "label": 0
                },
                {
                    "sent": "I propose that each facial expression of emotion.",
                    "label": 0
                },
                {
                    "sent": "Or is is represented by a continuous representation and norm based representation?",
                    "label": 0
                },
                {
                    "sent": "As I showed you and that allows you to recognize where robustly all the facial expressions of emotion that are most common in our society.",
                    "label": 0
                },
                {
                    "sent": "This is very good, but this is the claim that continuous model continues modelist with be saying at this point how am I going to recognize new facial expressions of emotion that don't have their own category?",
                    "label": 0
                },
                {
                    "sent": "Because here I have.",
                    "label": 0
                },
                {
                    "sent": "Say six or seven or eight categories, one for Happy, one for sad.",
                    "label": 0
                },
                {
                    "sent": "When for angry, and so on, right?",
                    "label": 0
                },
                {
                    "sent": "But now I get a new official expression of emotion that is not in one of these cultures.",
                    "label": 0
                },
                {
                    "sent": "How is the recognition of that?",
                    "label": 0
                },
                {
                    "sent": "I linearly combine them and now I can create happily surprised or angry surprise, and this is very recent work that we are developing in our lab.",
                    "label": 0
                },
                {
                    "sent": "So I really encourage you to keep checking our web page in the next few months.",
                    "label": 0
                },
                {
                    "sent": "I was surprised by the previous speaker that the student didn't want to.",
                    "label": 0
                },
                {
                    "sent": "The describe the things that he was doing at that point or at this point in time.",
                    "label": 0
                },
                {
                    "sent": "I always encourage people to talk about what you're doing now and the things that has not have not been published, because that's the best way for you to make sure that no one is going to publish it before you.",
                    "label": 0
                },
                {
                    "sent": "You've already said it alright, so this is defining the CVR paper anyways that it's associated to this workshop, so you can read more about this.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Later.",
                    "label": 0
                },
                {
                    "sent": "So the question is, if we want to build computer vision algorithms that solve this problem, we have to be able to detect facial components very accurately because humans are very accurate as you can see, we are very sensitive to these small changes in distance between browsing eyes.",
                    "label": 0
                },
                {
                    "sent": "Distances between upper lip and lower lip and so on.",
                    "label": 0
                },
                {
                    "sent": "And these are very small differences.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's two pixels, one pixel and we're still sensitive to that.",
                    "label": 0
                },
                {
                    "sent": "So the question is for or in general, how sensitive are we to?",
                    "label": 0
                },
                {
                    "sent": "Give an answer to this question.",
                    "label": 0
                },
                {
                    "sent": "We choose three graduate students from my lap.",
                    "label": 0
                },
                {
                    "sent": "And yes, that's what it takes to do a PhD these days and we ask them to manually annotate almost 4000 images.",
                    "label": 0
                },
                {
                    "sent": "Now when I say manually notate 4000 images, I don't mean to do a simple annotation, but to provide this in-depth annotation that you see here of the eyebrows, eyes, inner circles of the of the.",
                    "label": 0
                },
                {
                    "sent": "This is the narrows, industrials the mouth, and so on.",
                    "label": 0
                },
                {
                    "sent": "So now the task is, can we build computer vision algorithms that are as accurate of this as this one?",
                    "label": 0
                },
                {
                    "sent": "And this is work defining Pammy.",
                    "label": 0
                },
                {
                    "sent": "And as you may have seen before, I'm going to show you this image and you have to find the face.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can you find the face?",
                    "label": 0
                },
                {
                    "sent": "OK, I don't have time, it's here.",
                    "label": 0
                },
                {
                    "sent": "So this this is hard, isn't it?",
                    "label": 0
                },
                {
                    "sent": "Well, this is what computers are supposed to do.",
                    "label": 0
                },
                {
                    "sent": "We give them an image and say find a face as if that were that simple.",
                    "label": 0
                },
                {
                    "sent": "It's not simple, it's very difficult.",
                    "label": 0
                },
                {
                    "sent": "And if you do that, you're going to have two problems.",
                    "label": 0
                },
                {
                    "sent": "The first problem is you don't know where to look, so you have to scan the whole image right?",
                    "label": 0
                },
                {
                    "sent": "Which is where you were probably doing.",
                    "label": 0
                },
                {
                    "sent": "And the second thing is if you have a template that's going to scan through the image at the end is going to give you.",
                    "label": 0
                },
                {
                    "sent": "A lot of results around the actual face.",
                    "label": 0
                },
                {
                    "sent": "Not only were the faces, but here and here and here and here at different sizes, because that template matches imprecisely detected faces, and that's what worries me.",
                    "label": 0
                },
                {
                    "sent": "This imprecise word, so I'm going to have to try to resolve this problem right here.",
                    "label": 0
                },
                {
                    "sent": "How can we do that?",
                    "label": 0
                },
                {
                    "sent": "There are multiple ways, but here's a.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A way to do this which we define in Pammy in a recent paper in 2008, actually with early presented us in CPR.",
                    "label": 0
                },
                {
                    "sent": "So basically what we do is we collect a large number of faces, well detected faces at different orientations if eliminations, what have you, and then we.",
                    "label": 0
                },
                {
                    "sent": "Automatically extract miss detected faces from that set so you can see on the top row these are perfectly detected faces in the bottom row.",
                    "label": 0
                },
                {
                    "sent": "These are the not so well detected faces and this week all the context of the face because it contains all the context information that helps you detect the face.",
                    "label": 0
                },
                {
                    "sent": "At this point you can use a mixture of gases to represent the actual faces and mixture of Gaussians to represent non not well detected faces and now what you do when you detect the faces.",
                    "label": 0
                },
                {
                    "sent": "You move toward the correctly detected faces away from the miss detected faces and that pushes you to improve the recognition of your face.",
                    "label": 0
                },
                {
                    "sent": "But normally you can do that for faces.",
                    "label": 0
                },
                {
                    "sent": "You can do it for groups.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, you can do it for eyes, corners of the eyes.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gnosis corners of the Gnosis map.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This corner of the mouth and so on, and we use subclasses Kim analysis to do this learning means basically because it's a method that gives you the IT automatically gives you the number of Gaussians that you need, and that's in a payment paper represented.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Six and these are the results.",
                    "label": 0
                },
                {
                    "sent": "We have a sequence of in American Sign Language sequence and you can see that we can achieve very accurate, very precisely detections of all the major facial components.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the groups well with them in it.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the recognition excuse me, the detection error was in a very large in the same number of images.",
                    "label": 0
                },
                {
                    "sent": "Acosta 4000 images that we had in the database, about 6.2 pixels or 2% of the image, which is not as good as humans, but pretty close.",
                    "label": 0
                },
                {
                    "sent": "So we're getting close goes to humans.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's something that you can do.",
                    "label": 0
                },
                {
                    "sent": "Once you have these detection.",
                    "label": 0
                },
                {
                    "sent": "This is again another sequence of American Sign Language.",
                    "label": 0
                },
                {
                    "sent": "You can use non richiede structure from motion and recovered the three dimensional phase and as it deforms and then you can use this to model American Sign Language, facial expressions of emotions and just this hybrid model that I proposed here and I encourage you to go Wednesday to see my students poster who is here and I promise I really could push there alright.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to conclude, very quickly just a the repeat.",
                    "label": 0
                },
                {
                    "sent": "My take home messages.",
                    "label": 0
                },
                {
                    "sent": "I have proposed a linear combination of categorical models.",
                    "label": 1
                },
                {
                    "sent": "Each categorical models represented as a continuous model in a norm based representation.",
                    "label": 1
                },
                {
                    "sent": "The features of these models are configurable mostly and to achieve or emulate this in computers we need to move toward precise detection of.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Special features and thank you so much for listening, but I do very much my students, which are the ones that really did all these work.",
                    "label": 0
                },
                {
                    "sent": "And here they are.",
                    "label": 0
                },
                {
                    "sent": "And obviously I have to acknowledge the National Institutes of Health or they support.",
                    "label": 1
                },
                {
                    "sent": "It's been great over the years and also the National Science Foundation.",
                    "label": 0
                },
                {
                    "sent": "Thanks so much.",
                    "label": 0
                },
                {
                    "sent": "To detect the emotion, how do you get the norm face to begin with?",
                    "label": 0
                },
                {
                    "sent": "For sad, it's like longer than the norm face an angry's.",
                    "label": 0
                },
                {
                    "sent": "Short term, that's that's a very good question.",
                    "label": 0
                },
                {
                    "sent": "So to repeat the question to make sure I understand you correctly is how do you know what's the average distance between the browser and the mouth, right?",
                    "label": 0
                },
                {
                    "sent": "For a specific person, right?",
                    "label": 0
                },
                {
                    "sent": "It can't be so.",
                    "label": 0
                },
                {
                    "sent": "It's not for a specific person, it's generally in a population.",
                    "label": 0
                },
                {
                    "sent": "So, have you notice that some of your friends obviously look happier or angrier or sadder, which is.",
                    "label": 0
                },
                {
                    "sent": "Because that's how they are.",
                    "label": 0
                },
                {
                    "sent": "That's because their phase deviates more from the norm phase than the others, right?",
                    "label": 0
                },
                {
                    "sent": "So what you do is with experience.",
                    "label": 0
                },
                {
                    "sent": "You tune the average distance between browser mouth an what we've done in the vision Research paper.",
                    "label": 0
                },
                {
                    "sent": "We actually have an experiment where we have Caucasian subjects, rate location faces an Asian faces, and what happens is that Asian faces tend to be shorter in height and why they are so you actually get an effect.",
                    "label": 0
                },
                {
                    "sent": "Of the what's called the other race effect, which is caused by your norm representation of the distance between the.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry the mouth and they browse right which is different in agents and I guess for different applications if it's necessary to get a subject based norm, you can probably do that.",
                    "label": 0
                },
                {
                    "sent": "Also you could do that.",
                    "label": 0
                },
                {
                    "sent": "Definitely.",
                    "label": 0
                },
                {
                    "sent": "Yes I completely agree, right?",
                    "label": 0
                },
                {
                    "sent": "If you want it to be subject specific in a human computer interaction application, yes indeed, that's a very good point, thanks, thank you.",
                    "label": 0
                },
                {
                    "sent": "Hi very nice talking.",
                    "label": 0
                },
                {
                    "sent": "How does the this idea of absolute distance for across all people for you know baseline?",
                    "label": 0
                },
                {
                    "sent": "Of, say, emotion compared to or square with the research on after images of widening, or narrowing or lengthening the face because their people adapt very quickly if they see a lot of tall fat space.",
                    "label": 0
                },
                {
                    "sent": "That's a great question too.",
                    "label": 0
                },
                {
                    "sent": "So let me go back here very quickly if I can.",
                    "label": 0
                },
                {
                    "sent": "You OK?",
                    "label": 0
                },
                {
                    "sent": "And getting there, yeah, OK, so here's what's going on.",
                    "label": 0
                },
                {
                    "sent": "You have compute this mean distance between browsing mouth, right?",
                    "label": 0
                },
                {
                    "sent": "And now you show a image that has a really long distance between browser mouth and you show it and you ask the subject to a stair to that image for three minutes and then in in cognitive psychology that's called adaptation.",
                    "label": 0
                },
                {
                    "sent": "Your visual system adapts to this new perception and what happens is that mean phase?",
                    "label": 0
                },
                {
                    "sent": "If I get my mouth here?",
                    "label": 0
                },
                {
                    "sent": "This mean face Move tour that knew the new image that newest stimulus, OK, and now your mean face is right here.",
                    "label": 0
                },
                {
                    "sent": "So when you show this phase at 25%, it doesn't look sad or angry anymore, right?",
                    "label": 0
                },
                {
                    "sent": "It looks the angry ones would look even angrier in a way because you have adapted toward that new norm.",
                    "label": 0
                },
                {
                    "sent": "OK thanks sure.",
                    "label": 0
                },
                {
                    "sent": "Yes, risk crossing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, very nice talk.",
                    "label": 0
                },
                {
                    "sent": "I like very much your approach because it's like what we're trying to do is like you're trying to find the manifold of expressions, right?",
                    "label": 0
                },
                {
                    "sent": "What is the least set of parameters that make you think this is smiling?",
                    "label": 0
                },
                {
                    "sent": "So I think you can.",
                    "label": 0
                },
                {
                    "sent": "I think for formalized a lot more.",
                    "label": 0
                },
                {
                    "sent": "Another question I have is.",
                    "label": 0
                },
                {
                    "sent": "You show a little bit exaggerated expressions like are you working with normal or across cultures because?",
                    "label": 0
                },
                {
                    "sent": "That's a classical question.",
                    "label": 0
                },
                {
                    "sent": "It's a good question, so here's the problem and we have to acknowledge this in the community.",
                    "label": 0
                },
                {
                    "sent": "The problem in facial expressions of emotion that's very difficult.",
                    "label": 0
                },
                {
                    "sent": "Not the same possible to collect real emotions, real facial expressions of emotion because you cannot go around while people are expressing emotions and just be taking pictures of the time right?",
                    "label": 0
                },
                {
                    "sent": "So it's very hard and most of the databases in.",
                    "label": 0
                },
                {
                    "sent": "99% of the databases 30 matches you find out there are from post emotions and imposed emotions.",
                    "label": 0
                },
                {
                    "sent": "You have these exaggerated expressions right?",
                    "label": 0
                },
                {
                    "sent": "And some people are more expressive than others, but in general you tend to exaggerate this a little.",
                    "label": 0
                },
                {
                    "sent": "Overall, I think that for now this is OK because we are right at the beginning of all this research and so little is known about how facial expressions of emotion or about how facial expressions of grammar in ASL.",
                    "label": 0
                },
                {
                    "sent": "Work so it's OK to work with this, but in the near future to 3 four years from now, we definitely need to start going to wear and more realistic setting an for that which has have to somehow find a mechanism that is IRB approval and allows us to collect data of facial expression of emotion in Israel.",
                    "label": 0
                },
                {
                    "sent": "Farmers were trying do something.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "Another thing we're trying to do is not just start faces, but like movies like the whole expression, so indeed.",
                    "label": 0
                },
                {
                    "sent": "And there has been some data collection on movies an there are Eva receiving database.",
                    "label": 0
                },
                {
                    "sent": "I'm aware of that has a 3 dimensional movie, meaning that it's 3D in movie in time.",
                    "label": 0
                },
                {
                    "sent": "So all these things are coming.",
                    "label": 0
                },
                {
                    "sent": "But again, they're all post emotions, right?",
                    "label": 0
                },
                {
                    "sent": "Another another thing that I want to make clear is that even with this post emotions I'm gonna see if I can find this very quickly even with this post emotions, the recognition grade that you get from humans, it's actually not that good so.",
                    "label": 0
                },
                {
                    "sent": "This is at maximum resolution, so you see that we are extremely good.",
                    "label": 0
                },
                {
                    "sent": "Humans are extremely good at recognizing happiness.",
                    "label": 0
                },
                {
                    "sent": "We are very good at recognizing surprise.",
                    "label": 0
                },
                {
                    "sent": "We are in blue right here in red.",
                    "label": 0
                },
                {
                    "sent": "We are OK at recognizing anger and what is it?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, anger and sadness and we're very bad actually, in general at recognizing fear and disgust, we're not good at this.",
                    "label": 0
                },
                {
                    "sent": "Although most evolutionary psychologists who tell you that fear, it's this primal facial expression that we are also good at recognizing that where we found is that we're not.",
                    "label": 0
                },
                {
                    "sent": "We're definitely not.",
                    "label": 0
                },
                {
                    "sent": "Best at surprised an happiness.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you.",
                    "label": 0
                }
            ]
        }
    }
}