{
    "id": "bbfi7jlwsygthg4s5fpcq2wma4mdsklr",
    "title": "FedX: Optimization Techniques for Federated Query Processing on Linked Data",
    "info": {
        "author": [
            "Andreas Schwarte, fluid Operations AG"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Search",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2011_schwarte_fedx/",
    "segmentation": [
        [
            "My name is Andreas Roger and in this talk I will present Noel optimization techniques for Federated query processing on linked data.",
            "This research was a joint work between fluid operations and the Max Planck Institute in Sutton and let's have a short look at the outline of today's talk."
        ],
        [
            "I will start with the motivation of the topic, then introduce Federated query processing.",
            "And next I will shortly elaborate on the query processing metric model of FedEx and present our novel optimization techniques.",
            "Finally, I will present our evaluation of the benchmark results before I conclude and give some remarks on future work and the current."
        ],
        [
            "Status.",
            "So as a motivation, more and more publicly available link datasets arise.",
            "And this success is best illustrated in the well known linked open data Cloud diagram.",
            "I'm feeling dumb.",
            "Doubt Link data cloud diagram represents we have various datasets ranging for media datasets, governmental data.",
            "Cost domain data or life science data.",
            "So having the idea of linked data in mind.",
            "The goal should be to allow for query processing which involves multiple distributed data sources.",
            "There's an enormous potential for this.",
            "One particular scenario could be that we might be interested in news contextualized with general information, so having a look at the link data cloud, we might find the DBPR data set as strange central data with Central as a structural knowledge base, and then also the New York Times data collection as a news provider.",
            "M. The goal obviously is to query both data collections in an integrated way."
        ],
        [
            "And how this can be done?",
            "This is one option.",
            "One solution is Federated query processing.",
            "The typical architecture is such that we have a Federation mediator at the server and this mediator takes care for the virtual integration of a set of remote data sources.",
            "Virtual integration in this sense means that.",
            "Their data sources are integrated and that they grow.",
            "E is evaluated transparently as if the data resides in the in a single database.",
            "In the context of Link data, the communication is done with the Spark Reporter call."
        ],
        [
            "So coming back to our concrete example, we have the DPD and New York Times datasets as endpoints.",
            "And we might be interested in finding United States presidents and short associated news articles.",
            "Well, the query is basically consists of four triple patterns.",
            "The first one computes all the instances of presidents from the DBPR database, then the second one collects or links in the New York Times.",
            "Yes, using same as representations.",
            "Then the search triple pattern computes the party for each president and the final one computes the actual news page."
        ],
        [
            "And in the following I will illustrate how Federated query processing is done in a naive approach to see the challenges that arrive.",
            "So.",
            "Basically we have again the Federated architecture with the Federation Mediator, and in our case the two sparkle endpoints, DB PEDIA and New York Times.",
            "I'm in and I Federated query processing engine.",
            "The evaluation is typically done in the pattern by pattern, using a nested loop join.",
            "So we start with the first triple pattern.",
            "That ripple pattern is sent to both endpoints.",
            "At the end points, it gets evaluated and we see that at the DPS Parkland point at the database we get a set of instances for president, including Barack Obama and George W Bush.",
            "This results."
        ],
        [
            "I returned to the Federation Mediator and well, this is basically the now.",
            "Basically we have dealt with the first triple pattern.",
            "So now we have to deal with the 2nd paper pattern.",
            "As I've mentioned, the processing is done in in a nested loop fashion, so each of the already computed intermediate mappings is used one by one in a nested loop join to further process the query.",
            "We know."
        ],
        [
            "Gets a second triple pattern, takes the first input Barack Obama and the triple pattern is evaluated at both databases.",
            "Again.",
            "In this case, both databases yield a result.",
            "These results are returned to the Federation Mediator.",
            "And add it to the output and I had to choose the output queue.",
            "Note in particular that we have to form the Union of results since we are in a Federated setting, then we have to deal with the next input, which is George W Bush, and in that it loses a query sent to both data, puts the data sources again.",
            "The query gets evaluated at the data sources and we weave through resides in the Federation mediator appended to the output.",
            "So in the same fashion it continues until all intermediate bindings are resolved, and Moreover it until all triple patterns of the complete query I evaluated.",
            "Well, we immediately see that there are many remote requests involved in evaluating such a query in a remote setting, and in the following I will present optimization techniques that try to reduce the number of remote requests."
        ],
        [
            "Let's first have a look at the credit processing model.",
            "We want to use.",
            "We use in FedEx.",
            "Basically, the overall goal is to establish a query processing engine that is capable of efficiently evaluating queries on multiple distributed data sources.",
            "In our scenario, the data sources are known in advance and they are accessible as sparkle endpoints.",
            "So to be compliant with today's endpoints, we designed FedEx to be fully compatible with Sparkle 1.0.",
            "In addition, we do not need any prior knowledge about the data sources.",
            "So we do not need any preprocessing of the data sources, and neither do we need any pre computed statistics about the data sources.",
            "And this allows for on-demand Federation setup, meaning that we can add or remove.",
            "New data sources at one time.",
            "Coming back to the challenges of Federated credit processing, as we have seen before in the illustration in Federated Query processing, we have to deal with a lot of remote requests resulting from nested loop time processing.",
            "So the first challenge is to involve only the relevant sources in the evaluation.",
            "Formulated in a different way, but you want to avoid sending subqueries to sources that are not relevant and do not yield results.",
            "The second challenge is that we want to compute joints as close as possible to the data sources.",
            "The problem here is that in a naive approach, all joints are executed locally in a nested loop fashion.",
            "The short challenge is that we want to reduce remote communication, in particular, the number of requests.",
            "The problem the main problem is set the nested loops I'm processing, which causes some any."
        ],
        [
            "Request so in FedEx the credit pool setting workflow looks as follows.",
            "We start with a Sparkle query, pass it into an internal representation.",
            "Then we perform source selection using sparkle.",
            "Asked requests in conjunction with the local cache.",
            "Next, we apply some global optimizations.",
            "Which includes groupings and join our optimizing optimization and then we execute the optimized query.",
            "Using our technique, which we call bound joints at the relevant sources and finally the result is returned to the client.",
            "In this process we address all the challenges, namely the first one is addressed in source selection, where we determine the relevant sources for each triple pattern.",
            "The second one is addressed in our global optimization steps veriform groupings to reduce the number of local joints and the third one is addressed during credit query evaluation where we use our bound joint techniques and the details to the optimization techniques were presented."
        ],
        [
            "Presented now.",
            "Namely, we start with our selection approach.",
            "The overall idea is that we annotate each triple pattern with its well, event sources.",
            "The relevant sources are those sources that contribute information for a particular pattern.",
            "We determine the relevant sources by sending Sparkle, ask requests to the endpoints to each Federation member, and maintain the results in the local cache.",
            "So after some time the cache learns the capabilities of the endpoints of the data sources and after some time we can do the complete source selection, possibly locally.",
            "The second optimization is called exclusive groups, and with this optimization we group those triple patterns which have the same single relevant source.",
            "By grouping these 12 patterns, we push joints to the endpoints by evaluating.",
            "Group travel patterns in a single subquery."
        ],
        [
            "An illustration.",
            "Of these techniques, in our running example.",
            "We first perform source selection, meaning that we sent to each Federation member ask queries for each tribal pattern, and we determined that for the first three pattern DVDs relevant source.",
            "For the second triple pattern TBD.",
            "As relevant as well.",
            "For the third pattern, DBPR and New York Times are relevant.",
            "This is because it's slightly more general statement.",
            "Then for the final one, only New York Times is relevant, so in this source selection approach, we notice that the 1st two triple patterns are to be the only relevant source of the first 2 triple patterns is the DBPR data source.",
            "Meaning that no other data source can influence results of these two patterns, so.",
            "We group those tribal patterns in an exclusive group.",
            "And we can evaluate them in a single subquery.",
            "The advantages are obvious, so on the one hand we avoid sending sub queries to sources that are not relevant at all.",
            "For instance, for the first triple pattern we do not have to send it through New York Times.",
            "And on the other hand, we can delegate joints to the endpoints by forming these exclusive groups.",
            "Which means that we find this in this example execute the 1st two triple patterns.",
            "In one subquery and push to join through the endpoint."
        ],
        [
            "Well, we have more optimization techniques.",
            "Um?",
            "One that regards the join order for optimizing the join order in the Federated setting, we use count heuristic, we count the number of three variables in groups and triple patterns.",
            "And all of them appropriately.",
            "This technique works really amazingly good in the Federated setting.",
            "Then the final optimization I want to present here is the bound joints technique as we have seen, many remote requests are caused by the nested loop join processing of the queries.",
            "So we introduced bound joins technique to process joints in a block nested loop fashion.",
            "We do reduce member requests of requests by avec shot evaluation of a set of input bindings again."
        ],
        [
            "An example we assume for this example that the 1st three triple patterns have been evaluated already.",
            "And that we have for the first triple pattern.",
            "A block input including values Barack Obama and George W Bush etc.",
            "So with the traditional approach in a nested loop fashion, we would have to send.",
            "One subquery for each intermediate mapping.",
            "No, was about joints technique.",
            "Or was Victor evaluation?",
            "We use we evaluate the query in a single remote requests and to be compatible with sparkle under zero endpoints.",
            "We introduce a special sparkle union construct.",
            "In addition with some local post processing.",
            "However, now that Sparkle 1.1 endpoints become more available in on the on the web, we can also use the bindings clause to send the block input mappings as constraints in the query."
        ],
        [
            "So.",
            "I want to show an optimization example of our benchmarks.",
            "We have a life science query which deals with the data sources, direct bank and cake and it computes all micronutrients.",
            "And the first triple pattern of the query basically computes all macro nutrients from the Drug bank data source and the second one computes some identifier for the drugs.",
            "Then the next triple pattern computes all tracks in the cat namespace.",
            "The foster pattern performed the join Y as a computed ID and then the title is returned for the drug.",
            "So in a non optimized execution plan we have a chain of for local joints meaning.",
            "That we have four times a nested loop shine.",
            "However, after optimization, after applying our optimizations.",
            "We have a much more simplified version of the execution plan.",
            "Namely, we could reduce the execution of the number of joints to just two local joints.",
            "'cause we have two exclusive groups.",
            "Which we can evaluate at the Drug Bank data source and the other one is the correct data source.",
            "So we push joins.",
            "To the endpoints.",
            "And these optimizations immediately effect performance, as we will see in the evaluation, which I will present now."
        ],
        [
            "So our evaluation is on the is based on the Fed branch Benchmark Suit.",
            "I do not want to go into too much detail about the benchmarks suit 'cause we have further concerns a major details in the previous talk by Michael.",
            "But well, we basically selected 14 queries from the cross domain and the life science domain collections.",
            "And while they are based on real world data from the linked data cloud and vary in complexity, size, structure and resources involved."
        ],
        [
            "So here are our evaluation results.",
            "And in the diagram we see the evaluation times of the cross domain queries and our life science queries.",
            "And well, the Y axis depicts the evaluation times in seconds in the log scale and the X axis depicts.",
            "The queries starting from cross domain query run to life science query 7.",
            "And in our evaluation, we compared the state of the art systems Dark and Alibaba against our approach.",
            "FedEx.",
            "The overall results are such that we could reduce could improve the performance significantly in almost all queries in most queries, in the order of more than one magnitude, and for instance in the cross domain query suite, which is basically a variation of the running example I showed earlier.",
            "Both Alibaba and Dark ran into a timeout of of more than 10 minutes, and FedEx was able to evaluate this query in just the whole .1 seconds.",
            "Another example is sea life science query.",
            "Sweet, complex, more complex life science query with many intermediate results.",
            "It computes basically some drugs and the some interaction effects of these two X so.",
            "Alibaba again ran into a timeout of 10 minutes.",
            "Doc was able to evaluate this query in about 2 minutes and FedEx could do so in.",
            "Just one point, 4 seconds.",
            "So All in all an improvement and a significant improvement of query performance.",
            "And."
        ],
        [
            "When we have a look at our a closer look at our experimental exact experimental results, we can see why we and how we could improve the query performance in this way.",
            "Again, for the adjust shown, just highlighted queries cost a main number three in the case of Alibaba, which went into a time out, 100,000 requests were sent to the end points in that time, and in the case of dark even my 170,000 requests were sent in their time.",
            "So in contrast, FedEx answered the query in just 0.1 seconds, needing 23 requests.",
            "For the other example of the Lifesense query 3.",
            "Yeah, Doc needed two minutes for the evaluation and sent about 100,000 requests in the time during the evaluation, mainly caused due to the many caused by the nested loop join evaluation.",
            "So and we could reduce the number of requests in this case to 2000 and evaluated the query in 1.4 seconds."
        ],
        [
            "So.",
            "What is the bigger picture of FedEx?",
            "Well, we have basically three tier architecture consisting of an application layer of virtualization layer and a data layer, and in our case the application layer is comprised by the information workbench.",
            "See information workbenches a linked data platform which has a semantic Vicky and provides provides functionality for collaboration for reporting.",
            "For analytics and for visual exploration of the data.",
            "Then in the virtualization layer, our FedEx tool comes into place.",
            "And FedEx takes care for virtual integration of a set of data sources.",
            "Virtual integration here means again that queries are evaluated transparently as if the data resides in a single database.",
            "And since FedEx is able to this capable of on-demand integration of data sources, we allow to add or remove data sources dynamically at runtime.",
            "The data layer is comprised by the actual data sources, and these can be, for instance explored using common data registries such as seacon or the data.gov, and also it is possible to include enterprise data."
        ],
        [
            "So to conclude, this talk and to summarize this, talk.",
            "We have presented FedEx and FedEx is greatly engine which is capable of efficient SPARQL query processing in their Federated setting.",
            "FedEx is available as open source on our home page.",
            "And it is implemented as a sesame sale.",
            "So in FedEx we introduced an contributed novel join processing strategies, grouping techniques and source selection approach, and with these optimization techniques.",
            "We are able to significantly improve query performance compared to the state of the art systems.",
            "One remark is that we are capable of on-demand Federation set up because we do not need any pre processing of the data sources, so we do not need any knowledge about the data sources, just the endpoint URL.",
            "Um?",
            "Also, FedEx is compatible with all existing Sparkle 1.0 in points.",
            "SN outlook on the current work and future work.",
            "We contributed the Sparkle 1.1 federations extensions to Sesame 2.6 and there is an ongoing integration of the optimization techniques into sesame.",
            "Well also into FedEx.",
            "We want to integrate their Federation extensions, namely the service keyword as an optional way for the user to improve source selection.",
            "And the bindings clauses too.",
            "Improve the bound joints processing.",
            "For Sparkle 1.1 points also, we are planning to use remote statistics to improve the joint order.",
            "Here we want to use the support statistics."
        ],
        [
            "Well, that's it for my side and.",
            "If you want to see some life demonstration or if you want to have some offline discussion, we invite you to visit us at our exhibitor booths.",
            "And if you have some question now, I'm glad to welcome.",
            "I'm glad to answer this question.",
            "Thank you for your interest.",
            "I think this is interesting in that Federated Database concept is has been popular was very popular in 80s and 90s.",
            "Lot of work on multi database, query processing, optimization.",
            "All that and you brought it to the.",
            "Add of semantic web and brought it in that context.",
            "I wonder whether there is a possibility of really exploiting the unique aspects of semantic web and semantics as such, as opposed to database aspects of taking query and dividing it and and the language aspects of it in particular in the semantic web.",
            "Either we have some uniqueness in terms of link semantics whenever you are doing fair queries as a data element in this database, determine other databases.",
            "There is a.",
            "There is a perspective on what what links are available or what new links can be inferred and potentially that knowledge can be obtained by the relevant ontology or whatever may have been the output of the alignments that may be relevant that you can use in query Federation.",
            "So I'm wondering whether you can go far beyond what you have done which is necessary.",
            "To make it even more powerful by having more richer use of semantics, both in terms of links description as well as external knowledge that is available to be applied when you do ferret queries on two or more sources.",
            "If I understood correctly, you are striving a good point, namely that.",
            "The data alignment in different sources, like that you mean that.",
            "The vocabulary across the data sources is not aligned.",
            "So in FedEx we do not do any alignment of the data at the moment.",
            "However, in future this might be dealt with.",
            "So not only do you, I don't think you should do the alignment, I think you should use the alignments and or.",
            "I think we should use the external knowledge that is available.",
            "One of the fundamental thing between the database world and the semantic Web world is the fact that you have database.",
            "We have schema and database.",
            "Here we do have our schema.",
            "And database, but we often have separately created knowledge base is available to be applied on the data sources.",
            "OK, and I think that is a huge power that we have that really changes the game or should change.",
            "The game is much more than what we have done so far.",
            "I think that is a good.",
            "This is a good point for future work, but for the moment we focus on evaluating queries as if to virtual integrate a set of data sources to appear such at such sets of data appears to be virtually integrated that we have.",
            "All the data is if it were in a single data store, that's the goal of this project for the moment.",
            "So for future work it is a good.",
            "Start to do some alignment or some mappings of data.",
            "I was I was looking actually at the experiment setup that I have and I notice that you have a very small number of sources.",
            "So in your case because so you don't have statistics.",
            "Which basically means you have to go to every source to see which sources can answer what sort of better.",
            "I wonder like if you move from five sources, 200 sources or $500.",
            "So that's the reason why people have statistically computers.",
            "So I understand you opt for not going for that.",
            "But now how are you going to cope with more more sources?",
            "For this set of benchmarks, we focused on practical scenarios including only a few sources, namely up to five.",
            "So this has to be evaluated in a different setting, so there are different challenges when even more sources are involved.",
            "We focused actually really on practical settings with few sources.",
            "Does this answer your question?",
            "OK, that's depends on the use case, of course yeah.",
            "So what I can say, FedEx works also with well at 100 sources, but we didn't evaluate it.",
            "No, we didn't evaluate it, but it works in the same fashion, but we didn't perform any experiments.",
            "You explained your better performance results by sending.",
            "Smaller amount of your request to them to the endpoints now than than the understand the concurrent systems and darken Alibaba.",
            "Can you repeat this again?",
            "You explained your better performance results.",
            "By the by that that your system FedEx is sending less requests to the endpoints than the concurrent systems.",
            "Doesn't exactly OK an I wonder why do they send so many requests?",
            "What are they doing?",
            "Well, basically the nested loops on processing causes many requests and the requests are sent always to all the Federation members.",
            "So also to the sources that are not relevant in the final result.",
            "So they are sent Subqueries which do not yield.",
            "With which we yield an empty result and these.",
            "The money that they send this up curious to datasets that are not exactly the sub queries are sent to all the datasets.",
            "It natural to do, I mean you send correct ripple pattern to the correct data and with our selection approach we can find the relevant sources and send it all new to the relevant sources.",
            "So let's thank our speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Andreas Roger and in this talk I will present Noel optimization techniques for Federated query processing on linked data.",
                    "label": 0
                },
                {
                    "sent": "This research was a joint work between fluid operations and the Max Planck Institute in Sutton and let's have a short look at the outline of today's talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will start with the motivation of the topic, then introduce Federated query processing.",
                    "label": 1
                },
                {
                    "sent": "And next I will shortly elaborate on the query processing metric model of FedEx and present our novel optimization techniques.",
                    "label": 0
                },
                {
                    "sent": "Finally, I will present our evaluation of the benchmark results before I conclude and give some remarks on future work and the current.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Status.",
                    "label": 0
                },
                {
                    "sent": "So as a motivation, more and more publicly available link datasets arise.",
                    "label": 0
                },
                {
                    "sent": "And this success is best illustrated in the well known linked open data Cloud diagram.",
                    "label": 0
                },
                {
                    "sent": "I'm feeling dumb.",
                    "label": 0
                },
                {
                    "sent": "Doubt Link data cloud diagram represents we have various datasets ranging for media datasets, governmental data.",
                    "label": 0
                },
                {
                    "sent": "Cost domain data or life science data.",
                    "label": 0
                },
                {
                    "sent": "So having the idea of linked data in mind.",
                    "label": 0
                },
                {
                    "sent": "The goal should be to allow for query processing which involves multiple distributed data sources.",
                    "label": 1
                },
                {
                    "sent": "There's an enormous potential for this.",
                    "label": 0
                },
                {
                    "sent": "One particular scenario could be that we might be interested in news contextualized with general information, so having a look at the link data cloud, we might find the DBPR data set as strange central data with Central as a structural knowledge base, and then also the New York Times data collection as a news provider.",
                    "label": 0
                },
                {
                    "sent": "M. The goal obviously is to query both data collections in an integrated way.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And how this can be done?",
                    "label": 0
                },
                {
                    "sent": "This is one option.",
                    "label": 0
                },
                {
                    "sent": "One solution is Federated query processing.",
                    "label": 1
                },
                {
                    "sent": "The typical architecture is such that we have a Federation mediator at the server and this mediator takes care for the virtual integration of a set of remote data sources.",
                    "label": 1
                },
                {
                    "sent": "Virtual integration in this sense means that.",
                    "label": 0
                },
                {
                    "sent": "Their data sources are integrated and that they grow.",
                    "label": 0
                },
                {
                    "sent": "E is evaluated transparently as if the data resides in the in a single database.",
                    "label": 0
                },
                {
                    "sent": "In the context of Link data, the communication is done with the Spark Reporter call.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So coming back to our concrete example, we have the DPD and New York Times datasets as endpoints.",
                    "label": 0
                },
                {
                    "sent": "And we might be interested in finding United States presidents and short associated news articles.",
                    "label": 1
                },
                {
                    "sent": "Well, the query is basically consists of four triple patterns.",
                    "label": 0
                },
                {
                    "sent": "The first one computes all the instances of presidents from the DBPR database, then the second one collects or links in the New York Times.",
                    "label": 0
                },
                {
                    "sent": "Yes, using same as representations.",
                    "label": 0
                },
                {
                    "sent": "Then the search triple pattern computes the party for each president and the final one computes the actual news page.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in the following I will illustrate how Federated query processing is done in a naive approach to see the challenges that arrive.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Basically we have again the Federated architecture with the Federation Mediator, and in our case the two sparkle endpoints, DB PEDIA and New York Times.",
                    "label": 0
                },
                {
                    "sent": "I'm in and I Federated query processing engine.",
                    "label": 1
                },
                {
                    "sent": "The evaluation is typically done in the pattern by pattern, using a nested loop join.",
                    "label": 0
                },
                {
                    "sent": "So we start with the first triple pattern.",
                    "label": 0
                },
                {
                    "sent": "That ripple pattern is sent to both endpoints.",
                    "label": 1
                },
                {
                    "sent": "At the end points, it gets evaluated and we see that at the DPS Parkland point at the database we get a set of instances for president, including Barack Obama and George W Bush.",
                    "label": 0
                },
                {
                    "sent": "This results.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I returned to the Federation Mediator and well, this is basically the now.",
                    "label": 0
                },
                {
                    "sent": "Basically we have dealt with the first triple pattern.",
                    "label": 0
                },
                {
                    "sent": "So now we have to deal with the 2nd paper pattern.",
                    "label": 0
                },
                {
                    "sent": "As I've mentioned, the processing is done in in a nested loop fashion, so each of the already computed intermediate mappings is used one by one in a nested loop join to further process the query.",
                    "label": 0
                },
                {
                    "sent": "We know.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gets a second triple pattern, takes the first input Barack Obama and the triple pattern is evaluated at both databases.",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "In this case, both databases yield a result.",
                    "label": 0
                },
                {
                    "sent": "These results are returned to the Federation Mediator.",
                    "label": 0
                },
                {
                    "sent": "And add it to the output and I had to choose the output queue.",
                    "label": 0
                },
                {
                    "sent": "Note in particular that we have to form the Union of results since we are in a Federated setting, then we have to deal with the next input, which is George W Bush, and in that it loses a query sent to both data, puts the data sources again.",
                    "label": 0
                },
                {
                    "sent": "The query gets evaluated at the data sources and we weave through resides in the Federation mediator appended to the output.",
                    "label": 0
                },
                {
                    "sent": "So in the same fashion it continues until all intermediate bindings are resolved, and Moreover it until all triple patterns of the complete query I evaluated.",
                    "label": 0
                },
                {
                    "sent": "Well, we immediately see that there are many remote requests involved in evaluating such a query in a remote setting, and in the following I will present optimization techniques that try to reduce the number of remote requests.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's first have a look at the credit processing model.",
                    "label": 0
                },
                {
                    "sent": "We want to use.",
                    "label": 0
                },
                {
                    "sent": "We use in FedEx.",
                    "label": 0
                },
                {
                    "sent": "Basically, the overall goal is to establish a query processing engine that is capable of efficiently evaluating queries on multiple distributed data sources.",
                    "label": 1
                },
                {
                    "sent": "In our scenario, the data sources are known in advance and they are accessible as sparkle endpoints.",
                    "label": 1
                },
                {
                    "sent": "So to be compliant with today's endpoints, we designed FedEx to be fully compatible with Sparkle 1.0.",
                    "label": 0
                },
                {
                    "sent": "In addition, we do not need any prior knowledge about the data sources.",
                    "label": 0
                },
                {
                    "sent": "So we do not need any preprocessing of the data sources, and neither do we need any pre computed statistics about the data sources.",
                    "label": 0
                },
                {
                    "sent": "And this allows for on-demand Federation setup, meaning that we can add or remove.",
                    "label": 0
                },
                {
                    "sent": "New data sources at one time.",
                    "label": 0
                },
                {
                    "sent": "Coming back to the challenges of Federated credit processing, as we have seen before in the illustration in Federated Query processing, we have to deal with a lot of remote requests resulting from nested loop time processing.",
                    "label": 0
                },
                {
                    "sent": "So the first challenge is to involve only the relevant sources in the evaluation.",
                    "label": 0
                },
                {
                    "sent": "Formulated in a different way, but you want to avoid sending subqueries to sources that are not relevant and do not yield results.",
                    "label": 0
                },
                {
                    "sent": "The second challenge is that we want to compute joints as close as possible to the data sources.",
                    "label": 0
                },
                {
                    "sent": "The problem here is that in a naive approach, all joints are executed locally in a nested loop fashion.",
                    "label": 0
                },
                {
                    "sent": "The short challenge is that we want to reduce remote communication, in particular, the number of requests.",
                    "label": 0
                },
                {
                    "sent": "The problem the main problem is set the nested loops I'm processing, which causes some any.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Request so in FedEx the credit pool setting workflow looks as follows.",
                    "label": 0
                },
                {
                    "sent": "We start with a Sparkle query, pass it into an internal representation.",
                    "label": 0
                },
                {
                    "sent": "Then we perform source selection using sparkle.",
                    "label": 0
                },
                {
                    "sent": "Asked requests in conjunction with the local cache.",
                    "label": 0
                },
                {
                    "sent": "Next, we apply some global optimizations.",
                    "label": 0
                },
                {
                    "sent": "Which includes groupings and join our optimizing optimization and then we execute the optimized query.",
                    "label": 0
                },
                {
                    "sent": "Using our technique, which we call bound joints at the relevant sources and finally the result is returned to the client.",
                    "label": 1
                },
                {
                    "sent": "In this process we address all the challenges, namely the first one is addressed in source selection, where we determine the relevant sources for each triple pattern.",
                    "label": 0
                },
                {
                    "sent": "The second one is addressed in our global optimization steps veriform groupings to reduce the number of local joints and the third one is addressed during credit query evaluation where we use our bound joint techniques and the details to the optimization techniques were presented.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Presented now.",
                    "label": 0
                },
                {
                    "sent": "Namely, we start with our selection approach.",
                    "label": 0
                },
                {
                    "sent": "The overall idea is that we annotate each triple pattern with its well, event sources.",
                    "label": 0
                },
                {
                    "sent": "The relevant sources are those sources that contribute information for a particular pattern.",
                    "label": 1
                },
                {
                    "sent": "We determine the relevant sources by sending Sparkle, ask requests to the endpoints to each Federation member, and maintain the results in the local cache.",
                    "label": 1
                },
                {
                    "sent": "So after some time the cache learns the capabilities of the endpoints of the data sources and after some time we can do the complete source selection, possibly locally.",
                    "label": 1
                },
                {
                    "sent": "The second optimization is called exclusive groups, and with this optimization we group those triple patterns which have the same single relevant source.",
                    "label": 0
                },
                {
                    "sent": "By grouping these 12 patterns, we push joints to the endpoints by evaluating.",
                    "label": 0
                },
                {
                    "sent": "Group travel patterns in a single subquery.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An illustration.",
                    "label": 0
                },
                {
                    "sent": "Of these techniques, in our running example.",
                    "label": 0
                },
                {
                    "sent": "We first perform source selection, meaning that we sent to each Federation member ask queries for each tribal pattern, and we determined that for the first three pattern DVDs relevant source.",
                    "label": 0
                },
                {
                    "sent": "For the second triple pattern TBD.",
                    "label": 0
                },
                {
                    "sent": "As relevant as well.",
                    "label": 0
                },
                {
                    "sent": "For the third pattern, DBPR and New York Times are relevant.",
                    "label": 0
                },
                {
                    "sent": "This is because it's slightly more general statement.",
                    "label": 0
                },
                {
                    "sent": "Then for the final one, only New York Times is relevant, so in this source selection approach, we notice that the 1st two triple patterns are to be the only relevant source of the first 2 triple patterns is the DBPR data source.",
                    "label": 0
                },
                {
                    "sent": "Meaning that no other data source can influence results of these two patterns, so.",
                    "label": 0
                },
                {
                    "sent": "We group those tribal patterns in an exclusive group.",
                    "label": 1
                },
                {
                    "sent": "And we can evaluate them in a single subquery.",
                    "label": 1
                },
                {
                    "sent": "The advantages are obvious, so on the one hand we avoid sending sub queries to sources that are not relevant at all.",
                    "label": 1
                },
                {
                    "sent": "For instance, for the first triple pattern we do not have to send it through New York Times.",
                    "label": 0
                },
                {
                    "sent": "And on the other hand, we can delegate joints to the endpoints by forming these exclusive groups.",
                    "label": 0
                },
                {
                    "sent": "Which means that we find this in this example execute the 1st two triple patterns.",
                    "label": 0
                },
                {
                    "sent": "In one subquery and push to join through the endpoint.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, we have more optimization techniques.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "One that regards the join order for optimizing the join order in the Federated setting, we use count heuristic, we count the number of three variables in groups and triple patterns.",
                    "label": 1
                },
                {
                    "sent": "And all of them appropriately.",
                    "label": 0
                },
                {
                    "sent": "This technique works really amazingly good in the Federated setting.",
                    "label": 0
                },
                {
                    "sent": "Then the final optimization I want to present here is the bound joints technique as we have seen, many remote requests are caused by the nested loop join processing of the queries.",
                    "label": 0
                },
                {
                    "sent": "So we introduced bound joins technique to process joints in a block nested loop fashion.",
                    "label": 1
                },
                {
                    "sent": "We do reduce member requests of requests by avec shot evaluation of a set of input bindings again.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An example we assume for this example that the 1st three triple patterns have been evaluated already.",
                    "label": 0
                },
                {
                    "sent": "And that we have for the first triple pattern.",
                    "label": 0
                },
                {
                    "sent": "A block input including values Barack Obama and George W Bush etc.",
                    "label": 1
                },
                {
                    "sent": "So with the traditional approach in a nested loop fashion, we would have to send.",
                    "label": 0
                },
                {
                    "sent": "One subquery for each intermediate mapping.",
                    "label": 0
                },
                {
                    "sent": "No, was about joints technique.",
                    "label": 0
                },
                {
                    "sent": "Or was Victor evaluation?",
                    "label": 0
                },
                {
                    "sent": "We use we evaluate the query in a single remote requests and to be compatible with sparkle under zero endpoints.",
                    "label": 0
                },
                {
                    "sent": "We introduce a special sparkle union construct.",
                    "label": 0
                },
                {
                    "sent": "In addition with some local post processing.",
                    "label": 0
                },
                {
                    "sent": "However, now that Sparkle 1.1 endpoints become more available in on the on the web, we can also use the bindings clause to send the block input mappings as constraints in the query.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I want to show an optimization example of our benchmarks.",
                    "label": 0
                },
                {
                    "sent": "We have a life science query which deals with the data sources, direct bank and cake and it computes all micronutrients.",
                    "label": 0
                },
                {
                    "sent": "And the first triple pattern of the query basically computes all macro nutrients from the Drug bank data source and the second one computes some identifier for the drugs.",
                    "label": 0
                },
                {
                    "sent": "Then the next triple pattern computes all tracks in the cat namespace.",
                    "label": 0
                },
                {
                    "sent": "The foster pattern performed the join Y as a computed ID and then the title is returned for the drug.",
                    "label": 0
                },
                {
                    "sent": "So in a non optimized execution plan we have a chain of for local joints meaning.",
                    "label": 0
                },
                {
                    "sent": "That we have four times a nested loop shine.",
                    "label": 0
                },
                {
                    "sent": "However, after optimization, after applying our optimizations.",
                    "label": 0
                },
                {
                    "sent": "We have a much more simplified version of the execution plan.",
                    "label": 0
                },
                {
                    "sent": "Namely, we could reduce the execution of the number of joints to just two local joints.",
                    "label": 0
                },
                {
                    "sent": "'cause we have two exclusive groups.",
                    "label": 0
                },
                {
                    "sent": "Which we can evaluate at the Drug Bank data source and the other one is the correct data source.",
                    "label": 0
                },
                {
                    "sent": "So we push joins.",
                    "label": 0
                },
                {
                    "sent": "To the endpoints.",
                    "label": 0
                },
                {
                    "sent": "And these optimizations immediately effect performance, as we will see in the evaluation, which I will present now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our evaluation is on the is based on the Fed branch Benchmark Suit.",
                    "label": 0
                },
                {
                    "sent": "I do not want to go into too much detail about the benchmarks suit 'cause we have further concerns a major details in the previous talk by Michael.",
                    "label": 0
                },
                {
                    "sent": "But well, we basically selected 14 queries from the cross domain and the life science domain collections.",
                    "label": 1
                },
                {
                    "sent": "And while they are based on real world data from the linked data cloud and vary in complexity, size, structure and resources involved.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are our evaluation results.",
                    "label": 0
                },
                {
                    "sent": "And in the diagram we see the evaluation times of the cross domain queries and our life science queries.",
                    "label": 1
                },
                {
                    "sent": "And well, the Y axis depicts the evaluation times in seconds in the log scale and the X axis depicts.",
                    "label": 0
                },
                {
                    "sent": "The queries starting from cross domain query run to life science query 7.",
                    "label": 0
                },
                {
                    "sent": "And in our evaluation, we compared the state of the art systems Dark and Alibaba against our approach.",
                    "label": 0
                },
                {
                    "sent": "FedEx.",
                    "label": 0
                },
                {
                    "sent": "The overall results are such that we could reduce could improve the performance significantly in almost all queries in most queries, in the order of more than one magnitude, and for instance in the cross domain query suite, which is basically a variation of the running example I showed earlier.",
                    "label": 0
                },
                {
                    "sent": "Both Alibaba and Dark ran into a timeout of of more than 10 minutes, and FedEx was able to evaluate this query in just the whole .1 seconds.",
                    "label": 0
                },
                {
                    "sent": "Another example is sea life science query.",
                    "label": 0
                },
                {
                    "sent": "Sweet, complex, more complex life science query with many intermediate results.",
                    "label": 0
                },
                {
                    "sent": "It computes basically some drugs and the some interaction effects of these two X so.",
                    "label": 0
                },
                {
                    "sent": "Alibaba again ran into a timeout of 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "Doc was able to evaluate this query in about 2 minutes and FedEx could do so in.",
                    "label": 0
                },
                {
                    "sent": "Just one point, 4 seconds.",
                    "label": 0
                },
                {
                    "sent": "So All in all an improvement and a significant improvement of query performance.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When we have a look at our a closer look at our experimental exact experimental results, we can see why we and how we could improve the query performance in this way.",
                    "label": 0
                },
                {
                    "sent": "Again, for the adjust shown, just highlighted queries cost a main number three in the case of Alibaba, which went into a time out, 100,000 requests were sent to the end points in that time, and in the case of dark even my 170,000 requests were sent in their time.",
                    "label": 0
                },
                {
                    "sent": "So in contrast, FedEx answered the query in just 0.1 seconds, needing 23 requests.",
                    "label": 0
                },
                {
                    "sent": "For the other example of the Lifesense query 3.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Doc needed two minutes for the evaluation and sent about 100,000 requests in the time during the evaluation, mainly caused due to the many caused by the nested loop join evaluation.",
                    "label": 0
                },
                {
                    "sent": "So and we could reduce the number of requests in this case to 2000 and evaluated the query in 1.4 seconds.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What is the bigger picture of FedEx?",
                    "label": 1
                },
                {
                    "sent": "Well, we have basically three tier architecture consisting of an application layer of virtualization layer and a data layer, and in our case the application layer is comprised by the information workbench.",
                    "label": 1
                },
                {
                    "sent": "See information workbenches a linked data platform which has a semantic Vicky and provides provides functionality for collaboration for reporting.",
                    "label": 0
                },
                {
                    "sent": "For analytics and for visual exploration of the data.",
                    "label": 0
                },
                {
                    "sent": "Then in the virtualization layer, our FedEx tool comes into place.",
                    "label": 0
                },
                {
                    "sent": "And FedEx takes care for virtual integration of a set of data sources.",
                    "label": 0
                },
                {
                    "sent": "Virtual integration here means again that queries are evaluated transparently as if the data resides in a single database.",
                    "label": 0
                },
                {
                    "sent": "And since FedEx is able to this capable of on-demand integration of data sources, we allow to add or remove data sources dynamically at runtime.",
                    "label": 1
                },
                {
                    "sent": "The data layer is comprised by the actual data sources, and these can be, for instance explored using common data registries such as seacon or the data.gov, and also it is possible to include enterprise data.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, this talk and to summarize this, talk.",
                    "label": 0
                },
                {
                    "sent": "We have presented FedEx and FedEx is greatly engine which is capable of efficient SPARQL query processing in their Federated setting.",
                    "label": 1
                },
                {
                    "sent": "FedEx is available as open source on our home page.",
                    "label": 1
                },
                {
                    "sent": "And it is implemented as a sesame sale.",
                    "label": 0
                },
                {
                    "sent": "So in FedEx we introduced an contributed novel join processing strategies, grouping techniques and source selection approach, and with these optimization techniques.",
                    "label": 1
                },
                {
                    "sent": "We are able to significantly improve query performance compared to the state of the art systems.",
                    "label": 0
                },
                {
                    "sent": "One remark is that we are capable of on-demand Federation set up because we do not need any pre processing of the data sources, so we do not need any knowledge about the data sources, just the endpoint URL.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Also, FedEx is compatible with all existing Sparkle 1.0 in points.",
                    "label": 1
                },
                {
                    "sent": "SN outlook on the current work and future work.",
                    "label": 1
                },
                {
                    "sent": "We contributed the Sparkle 1.1 federations extensions to Sesame 2.6 and there is an ongoing integration of the optimization techniques into sesame.",
                    "label": 0
                },
                {
                    "sent": "Well also into FedEx.",
                    "label": 0
                },
                {
                    "sent": "We want to integrate their Federation extensions, namely the service keyword as an optional way for the user to improve source selection.",
                    "label": 0
                },
                {
                    "sent": "And the bindings clauses too.",
                    "label": 0
                },
                {
                    "sent": "Improve the bound joints processing.",
                    "label": 0
                },
                {
                    "sent": "For Sparkle 1.1 points also, we are planning to use remote statistics to improve the joint order.",
                    "label": 0
                },
                {
                    "sent": "Here we want to use the support statistics.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, that's it for my side and.",
                    "label": 0
                },
                {
                    "sent": "If you want to see some life demonstration or if you want to have some offline discussion, we invite you to visit us at our exhibitor booths.",
                    "label": 0
                },
                {
                    "sent": "And if you have some question now, I'm glad to welcome.",
                    "label": 0
                },
                {
                    "sent": "I'm glad to answer this question.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your interest.",
                    "label": 1
                },
                {
                    "sent": "I think this is interesting in that Federated Database concept is has been popular was very popular in 80s and 90s.",
                    "label": 0
                },
                {
                    "sent": "Lot of work on multi database, query processing, optimization.",
                    "label": 0
                },
                {
                    "sent": "All that and you brought it to the.",
                    "label": 0
                },
                {
                    "sent": "Add of semantic web and brought it in that context.",
                    "label": 0
                },
                {
                    "sent": "I wonder whether there is a possibility of really exploiting the unique aspects of semantic web and semantics as such, as opposed to database aspects of taking query and dividing it and and the language aspects of it in particular in the semantic web.",
                    "label": 0
                },
                {
                    "sent": "Either we have some uniqueness in terms of link semantics whenever you are doing fair queries as a data element in this database, determine other databases.",
                    "label": 0
                },
                {
                    "sent": "There is a.",
                    "label": 0
                },
                {
                    "sent": "There is a perspective on what what links are available or what new links can be inferred and potentially that knowledge can be obtained by the relevant ontology or whatever may have been the output of the alignments that may be relevant that you can use in query Federation.",
                    "label": 0
                },
                {
                    "sent": "So I'm wondering whether you can go far beyond what you have done which is necessary.",
                    "label": 0
                },
                {
                    "sent": "To make it even more powerful by having more richer use of semantics, both in terms of links description as well as external knowledge that is available to be applied when you do ferret queries on two or more sources.",
                    "label": 0
                },
                {
                    "sent": "If I understood correctly, you are striving a good point, namely that.",
                    "label": 0
                },
                {
                    "sent": "The data alignment in different sources, like that you mean that.",
                    "label": 0
                },
                {
                    "sent": "The vocabulary across the data sources is not aligned.",
                    "label": 0
                },
                {
                    "sent": "So in FedEx we do not do any alignment of the data at the moment.",
                    "label": 0
                },
                {
                    "sent": "However, in future this might be dealt with.",
                    "label": 0
                },
                {
                    "sent": "So not only do you, I don't think you should do the alignment, I think you should use the alignments and or.",
                    "label": 0
                },
                {
                    "sent": "I think we should use the external knowledge that is available.",
                    "label": 0
                },
                {
                    "sent": "One of the fundamental thing between the database world and the semantic Web world is the fact that you have database.",
                    "label": 0
                },
                {
                    "sent": "We have schema and database.",
                    "label": 0
                },
                {
                    "sent": "Here we do have our schema.",
                    "label": 0
                },
                {
                    "sent": "And database, but we often have separately created knowledge base is available to be applied on the data sources.",
                    "label": 0
                },
                {
                    "sent": "OK, and I think that is a huge power that we have that really changes the game or should change.",
                    "label": 0
                },
                {
                    "sent": "The game is much more than what we have done so far.",
                    "label": 0
                },
                {
                    "sent": "I think that is a good.",
                    "label": 0
                },
                {
                    "sent": "This is a good point for future work, but for the moment we focus on evaluating queries as if to virtual integrate a set of data sources to appear such at such sets of data appears to be virtually integrated that we have.",
                    "label": 0
                },
                {
                    "sent": "All the data is if it were in a single data store, that's the goal of this project for the moment.",
                    "label": 0
                },
                {
                    "sent": "So for future work it is a good.",
                    "label": 0
                },
                {
                    "sent": "Start to do some alignment or some mappings of data.",
                    "label": 0
                },
                {
                    "sent": "I was I was looking actually at the experiment setup that I have and I notice that you have a very small number of sources.",
                    "label": 0
                },
                {
                    "sent": "So in your case because so you don't have statistics.",
                    "label": 0
                },
                {
                    "sent": "Which basically means you have to go to every source to see which sources can answer what sort of better.",
                    "label": 0
                },
                {
                    "sent": "I wonder like if you move from five sources, 200 sources or $500.",
                    "label": 0
                },
                {
                    "sent": "So that's the reason why people have statistically computers.",
                    "label": 0
                },
                {
                    "sent": "So I understand you opt for not going for that.",
                    "label": 0
                },
                {
                    "sent": "But now how are you going to cope with more more sources?",
                    "label": 0
                },
                {
                    "sent": "For this set of benchmarks, we focused on practical scenarios including only a few sources, namely up to five.",
                    "label": 0
                },
                {
                    "sent": "So this has to be evaluated in a different setting, so there are different challenges when even more sources are involved.",
                    "label": 0
                },
                {
                    "sent": "We focused actually really on practical settings with few sources.",
                    "label": 0
                },
                {
                    "sent": "Does this answer your question?",
                    "label": 0
                },
                {
                    "sent": "OK, that's depends on the use case, of course yeah.",
                    "label": 0
                },
                {
                    "sent": "So what I can say, FedEx works also with well at 100 sources, but we didn't evaluate it.",
                    "label": 0
                },
                {
                    "sent": "No, we didn't evaluate it, but it works in the same fashion, but we didn't perform any experiments.",
                    "label": 0
                },
                {
                    "sent": "You explained your better performance results by sending.",
                    "label": 0
                },
                {
                    "sent": "Smaller amount of your request to them to the endpoints now than than the understand the concurrent systems and darken Alibaba.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat this again?",
                    "label": 0
                },
                {
                    "sent": "You explained your better performance results.",
                    "label": 0
                },
                {
                    "sent": "By the by that that your system FedEx is sending less requests to the endpoints than the concurrent systems.",
                    "label": 0
                },
                {
                    "sent": "Doesn't exactly OK an I wonder why do they send so many requests?",
                    "label": 0
                },
                {
                    "sent": "What are they doing?",
                    "label": 0
                },
                {
                    "sent": "Well, basically the nested loops on processing causes many requests and the requests are sent always to all the Federation members.",
                    "label": 0
                },
                {
                    "sent": "So also to the sources that are not relevant in the final result.",
                    "label": 0
                },
                {
                    "sent": "So they are sent Subqueries which do not yield.",
                    "label": 0
                },
                {
                    "sent": "With which we yield an empty result and these.",
                    "label": 0
                },
                {
                    "sent": "The money that they send this up curious to datasets that are not exactly the sub queries are sent to all the datasets.",
                    "label": 0
                },
                {
                    "sent": "It natural to do, I mean you send correct ripple pattern to the correct data and with our selection approach we can find the relevant sources and send it all new to the relevant sources.",
                    "label": 0
                },
                {
                    "sent": "So let's thank our speaker again.",
                    "label": 0
                }
            ]
        }
    }
}