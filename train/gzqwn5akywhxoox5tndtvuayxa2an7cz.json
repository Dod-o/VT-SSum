{
    "id": "gzqwn5akywhxoox5tndtvuayxa2an7cz",
    "title": "Semantic Enrichment and Analysis of Legal Domain Documents",
    "info": {
        "author": [
            "Besher Massri, Institut \"Jo\u017eef Stefan\""
        ],
        "published": "Nov. 25, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2019_massri_legal_domain_documents/",
    "segmentation": [
        [
            "So yeah hello everyone.",
            "My name is Bisher and I'm going to present our joint work like with Sarah.",
            "Early can claim an which is called like semantic enrichment analysis of legal domain documents.",
            "So basically this work was part of the invariants project and."
        ],
        [
            "OK, so the motivation behind this project is basically like we have the lawyers and they had like we have a lot of like legal domain documents, but we want to run away like to help the lawyers access to information about the legal document and efficient way so that if they want like OK we want some documents about certain topics, certain locations so on to provide some mechanism or pipeline to enable them search that efficiently.",
            "And also one of the second goal will also want like to enable cross lingual set of results.",
            "So for example if someone like German like.",
            "It can be.",
            "It can be searching about like documents or legal documents for in French, on so on.",
            "And finally like to undertake the leg until the legal document with the relevant categories.",
            "So you'll have some kind of categorization, specifically like to little area of the legal documents and so on.",
            "So basically our main contribution is like we tried to work on environmental legal document, which is basically like a legal document and the environmental area for European Union and we did some non leases and we.",
            "Provide some results based on those analysis."
        ],
        [
            "So there are the outline of the talk would be the following.",
            "We start with the data or explain what is the data or what is our data that we use and then we'll start with the methodology.",
            "What are they like?",
            "What are the annotation syntactic semantic analysis that we did and then what are the primary results that we got?",
            "And what's the future work?",
            "So."
        ],
        [
            "With the data.",
            "So basically like the data source was the ehrlichs data, which is basically like an online service that provides like legal domain legal domain documents in the European Union.",
            "Information about each document where like title text like an some descriptors which are basically keywords like for example like a keyword, can be either location German or something or like some top level like environment or some top level categories.",
            "So based on those descriptors and the language we extracted like extracted and clean.",
            "After cleaning we got like a 2072 thousand documents in English about environments.",
            "Basically like we got the.",
            "Where the descriptor we're talking about environments, those are the ones that we've chosen and out of those documents, either wear like English natively in English, or where professional, translated by like expert to English language."
        ],
        [
            "So for methodology.",
            "So basically like we have the data and now like in order to extract some information we do we need to do some things like annotation pipeline out of it.",
            "So we start with the standard ones like standard MLB annotation which we used like for that one with the Stanford core NLP and out of the document we extracted like first.",
            "Like have the document tokenizer so extracted the tokenized words like removed from the punctuation, and so on, and then out of each word we got like the lemma or the dictionary form.",
            "And then like you got the part of speech tagging.",
            "And finally like out of each word, we use the word net lexical database.",
            "So for each word we got the list of synonyms.",
            "So which can be provided alternative and so on.",
            "We are going to see or going to use it."
        ],
        [
            "This is the first one and then like we used named entity recognition to like get the entities.",
            "So there were three classes of entities.",
            "We have the named entities, the famous ones like personal organization and location.",
            "The mask is basically like anyone that is like can be cured or abstract that does not fit in any one of those like personal location, organization for numerical entity classes like number, money or general.",
            "Our percent for the temporal date, time and duration.",
            "Oh"
        ],
        [
            "OK, so after that like we then like this is we got like OK this is the basic semantic and syntactic.",
            "But then OK we need to go cross lingual for crossing word.",
            "We used like GSI Rectifier which is like a service to extract the relevant relevant Wikipedia concept.",
            "So out of the document where exactly Wikipedia concept which can be in any language like for the document in any language.",
            "Exactly the concept that important for that document.",
            "So for each concept we got like the annotation name, which is basically like connected with the Wikipedia page and its URL, and one important feature that we use is actually like the Wikidata classes, which is basically the category that this document that this annotation falls into, and also like the page rank score and the cosine similarity between the documents and the Wikipedia page.",
            "So that was for the rectification."
        ],
        [
            "Uh, for the after that like, OK, we did the semantic analysis.",
            "We did work ification for Christian quality but OK we need to link the document somehow with the with some ontology related to environments.",
            "In this case we're working with environment.",
            "So we got this informing ontology which is basically like a set of terms like ontology about like mainly in the environment topic.",
            "So examples of it can be seen here."
        ],
        [
            "Like this is one part of it we have like the chemical and then we get like those by product and chemical and so on.",
            "So it's more like some kind of categorization of determine one of those environmental terms for the full.",
            "Like for the photos you can check here like maybe we can see it later at the end of the presentation."
        ],
        [
            "Oh yeah, for those terms like we tried to match, we tried to match for.",
            "What are the terms in the document?",
            "What are the?",
            "How the document is much with ontology.",
            "So basically we used.",
            "We used the terms that we extracted before and the other extracted before.",
            "Basically we used the lemmatized words which is basically the dictionary form of the words we use towards synonyms and we use the Wikidata classes from the relevant.",
            "Superior concepts why you.",
            "For example, we used like they were kicked out of classes are not looked at a concept actually, although we tried that before.",
            "What we didn't get any matches because like the ontology is more like the ontology terms is more like top level or category or topic things.",
            "So whereas like the concept something so specific.",
            "So when you got the concept itself or the named entity were so specific, that's why we're not matched with the ontology term.",
            "Whereas like if we go to the.",
            "To the Wikidata classes, which is the category that those annotation falls into.",
            "We try to find some matches actually."
        ],
        [
            "So those are the steps that we used like this used for understanding the documents.",
            "Now we after that we did some kind of preliminary analysis on that.",
            "So first we started with the content analysis.",
            "So we got all the words we calculated the TF, IDF of them.",
            "And then we projected toward the cloud.",
            "For example, here we can see some of the like some of the important ones like Commission, European regulation and so on.",
            "One one problem might notice probably like for example the existence of some of these top words.",
            "I expected, like the reason behind that.",
            "And it turns out like this is kind of common problem because like it's, it's like each tool has a set of stop words at you just sit with it and like it stop or somewhere in the cannot complete.",
            "Either go too far or you either got too short.",
            "So in a way, like in a way that you might get OK, some of those as like as a byproduct it can.",
            "It can be removed like manually later.",
            "But yeah, this is more like one of the byproduct of having some like static set of Star Wars.",
            "The problem with.",
            "So rare in English nowadays, accepting legal documents that people don't bother, including it in lists of stop words.",
            "Yeah, maybe that's one of the reasons.",
            "Because like, OK, otherwise like it didn't have the ones like this like that and so on.",
            "But we get Shell which is now at.",
            "This is not really really used and listen very formal topics."
        ],
        [
            "So that was like for the content.",
            "Then we tried to check like what are the Wikipedia concept that we matched like and we listed the top ones here.",
            "So basically we got something like European Union.",
            "Europe, a sovereign state treaty and law, and so on.",
            "So basically out of those like we got like 157 unique Wikipedia concepts.",
            "And out of those actually 50K concepts appeared only in one document.",
            "So like off of each one of documents like have some like have some unique concepts and only.",
            "Like one 100K of their arpitan up to three documents and only like 20.",
            "Two of them appeared in the lock and 10,000 documents is like OK, this is not.",
            "So much distinctive the reason why did some analysis?",
            "Because this showed that we can, in a way use the documents to distinct values.",
            "The Wikipedia annotation that to distinguish between documents because like if we have like, for example, 50K concept like each one or exist in one document.",
            "So we can use it as a distinctive feature in some classification and so on.",
            "So it's not like a common like most of the Wikipedia concept were not so common that it cannot be distinguished.",
            "But whereas like the comma, this document has its own set of Wikipedia.",
            "Except.",
            "Is this where we keep it?"
        ],
        [
            "Yeah, and for the named entities like the extracted name was in a way similar to those one that the one with Wiki Fire, because like we're still dealing with English, but we try to like we try to see the categorisation of those introduced the categories we extracted.",
            "Obviously like the top one was like the number as we see here because like usually integration like we have this like up there based on lower number something or they like usually have numbers like.",
            "Low numbers or the document numbers and so on.",
            "So we got like 18 million, 18 million entities around 1 million of them were actually distinct ones, but obviously the majority were numbered after moving.",
            "Then after removing the number entity we got like around 500,000 entity entities.",
            "So like most of them like after number we have the organisations which seems like reasonable and the date usually mentioning the dates.",
            "Of the documents at some pier personals and location.",
            "The location was important like to know like what is the weather?",
            "Where is the document like a specified?",
            "Like this document for legalization in France or and so on.",
            "So this is for the named entities and.",
            "You have so many.",
            "Organizations right so how many?",
            "We're actually spotted by Wiki Fire where they mostly non.",
            "Wikipedia concepts I yeah yeah.",
            "Mostly yeah yeah, but probably like the difference.",
            "The difference between the Wikipedia and named entity process will make more effective with dealt with non English documents, whereas like we learn English documents, most of the named entity recognition like system is not that good where it's like OK we can extract without a key file.",
            "We can extract some things were not extracted otherwise.",
            "That's why we like we wanted to use Wiki fire so.",
            "Yeah."
        ],
        [
            "For so for the Formula Ontology mapping, we got like those are the list of the most the 20 most frequent ones that we can see.",
            "OK, the committee, because like usually in every version like the committee decides on so on.",
            "But we can get some most of them related to legal terms like this scission annex, but we can see something like interesting like transport.",
            "We can see like management here or waste like this is more like related to environment trade an fund.",
            "So.",
            "Those were the most important in Formula anthology terms that we got."
        ],
        [
            "Finally, like this was more likely starting with the word, so this was more like a preliminary like the memory work on it, but based on that OK, like this is the first step we want to do after that.",
            "So first like with like for the rectification we found actually some of the matches were not that really matches like we found them are totally irrelevant, but which is like which is like can happen of course, because like some errors can occur and so and so we want to expect more and try to find a way to resolve them.",
            "And also like for the named entity specifically.",
            "Actually location like, because now it's like this like this.",
            "Phrases like representing a location.",
            "But OK, we want to go one step further, like more specific geospatial location may be in this area or in this area because this is important as this information is important for lawyers like we want the legalization on this area specifically.",
            "So yeah, this is 1 important thing direction to go on and also like for informing.",
            "In terms of the matching process, were actually like a simple string matching, so it's not some classifiers and so on, so that was more like a baseline, so we are intending to improve on it and also like.",
            "OK, part of this like we got for each document, a set of annotations, an information that can be used as like a feature vector in like building any type of classifiers so we can build classifiers for the legal domain documents to use it in any way of also and one of the use cases we're gonna use.",
            "Actually, for invariants project like is a query expansion, so whatever the user search for some squarely we can analyze and extract like similar word, like other words Wikipedia concept so we can enhance the result of this search so."
        ],
        [
            "Oh yeah, that was like that.",
            "Was it like it was part of environment and this still Terminator work and.",
            "Yeah, that's it.",
            "I would be happy to activate question."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yeah hello everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Bisher and I'm going to present our joint work like with Sarah.",
                    "label": 0
                },
                {
                    "sent": "Early can claim an which is called like semantic enrichment analysis of legal domain documents.",
                    "label": 1
                },
                {
                    "sent": "So basically this work was part of the invariants project and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the motivation behind this project is basically like we have the lawyers and they had like we have a lot of like legal domain documents, but we want to run away like to help the lawyers access to information about the legal document and efficient way so that if they want like OK we want some documents about certain topics, certain locations so on to provide some mechanism or pipeline to enable them search that efficiently.",
                    "label": 0
                },
                {
                    "sent": "And also one of the second goal will also want like to enable cross lingual set of results.",
                    "label": 0
                },
                {
                    "sent": "So for example if someone like German like.",
                    "label": 0
                },
                {
                    "sent": "It can be.",
                    "label": 0
                },
                {
                    "sent": "It can be searching about like documents or legal documents for in French, on so on.",
                    "label": 1
                },
                {
                    "sent": "And finally like to undertake the leg until the legal document with the relevant categories.",
                    "label": 1
                },
                {
                    "sent": "So you'll have some kind of categorization, specifically like to little area of the legal documents and so on.",
                    "label": 0
                },
                {
                    "sent": "So basically our main contribution is like we tried to work on environmental legal document, which is basically like a legal document and the environmental area for European Union and we did some non leases and we.",
                    "label": 1
                },
                {
                    "sent": "Provide some results based on those analysis.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are the outline of the talk would be the following.",
                    "label": 0
                },
                {
                    "sent": "We start with the data or explain what is the data or what is our data that we use and then we'll start with the methodology.",
                    "label": 0
                },
                {
                    "sent": "What are they like?",
                    "label": 0
                },
                {
                    "sent": "What are the annotation syntactic semantic analysis that we did and then what are the primary results that we got?",
                    "label": 0
                },
                {
                    "sent": "And what's the future work?",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With the data.",
                    "label": 0
                },
                {
                    "sent": "So basically like the data source was the ehrlichs data, which is basically like an online service that provides like legal domain legal domain documents in the European Union.",
                    "label": 0
                },
                {
                    "sent": "Information about each document where like title text like an some descriptors which are basically keywords like for example like a keyword, can be either location German or something or like some top level like environment or some top level categories.",
                    "label": 0
                },
                {
                    "sent": "So based on those descriptors and the language we extracted like extracted and clean.",
                    "label": 0
                },
                {
                    "sent": "After cleaning we got like a 2072 thousand documents in English about environments.",
                    "label": 0
                },
                {
                    "sent": "Basically like we got the.",
                    "label": 0
                },
                {
                    "sent": "Where the descriptor we're talking about environments, those are the ones that we've chosen and out of those documents, either wear like English natively in English, or where professional, translated by like expert to English language.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for methodology.",
                    "label": 0
                },
                {
                    "sent": "So basically like we have the data and now like in order to extract some information we do we need to do some things like annotation pipeline out of it.",
                    "label": 0
                },
                {
                    "sent": "So we start with the standard ones like standard MLB annotation which we used like for that one with the Stanford core NLP and out of the document we extracted like first.",
                    "label": 0
                },
                {
                    "sent": "Like have the document tokenizer so extracted the tokenized words like removed from the punctuation, and so on, and then out of each word we got like the lemma or the dictionary form.",
                    "label": 1
                },
                {
                    "sent": "And then like you got the part of speech tagging.",
                    "label": 1
                },
                {
                    "sent": "And finally like out of each word, we use the word net lexical database.",
                    "label": 1
                },
                {
                    "sent": "So for each word we got the list of synonyms.",
                    "label": 0
                },
                {
                    "sent": "So which can be provided alternative and so on.",
                    "label": 0
                },
                {
                    "sent": "We are going to see or going to use it.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the first one and then like we used named entity recognition to like get the entities.",
                    "label": 1
                },
                {
                    "sent": "So there were three classes of entities.",
                    "label": 1
                },
                {
                    "sent": "We have the named entities, the famous ones like personal organization and location.",
                    "label": 1
                },
                {
                    "sent": "The mask is basically like anyone that is like can be cured or abstract that does not fit in any one of those like personal location, organization for numerical entity classes like number, money or general.",
                    "label": 0
                },
                {
                    "sent": "Our percent for the temporal date, time and duration.",
                    "label": 1
                },
                {
                    "sent": "Oh",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so after that like we then like this is we got like OK this is the basic semantic and syntactic.",
                    "label": 0
                },
                {
                    "sent": "But then OK we need to go cross lingual for crossing word.",
                    "label": 0
                },
                {
                    "sent": "We used like GSI Rectifier which is like a service to extract the relevant relevant Wikipedia concept.",
                    "label": 0
                },
                {
                    "sent": "So out of the document where exactly Wikipedia concept which can be in any language like for the document in any language.",
                    "label": 0
                },
                {
                    "sent": "Exactly the concept that important for that document.",
                    "label": 0
                },
                {
                    "sent": "So for each concept we got like the annotation name, which is basically like connected with the Wikipedia page and its URL, and one important feature that we use is actually like the Wikidata classes, which is basically the category that this document that this annotation falls into, and also like the page rank score and the cosine similarity between the documents and the Wikipedia page.",
                    "label": 1
                },
                {
                    "sent": "So that was for the rectification.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uh, for the after that like, OK, we did the semantic analysis.",
                    "label": 0
                },
                {
                    "sent": "We did work ification for Christian quality but OK we need to link the document somehow with the with some ontology related to environments.",
                    "label": 0
                },
                {
                    "sent": "In this case we're working with environment.",
                    "label": 0
                },
                {
                    "sent": "So we got this informing ontology which is basically like a set of terms like ontology about like mainly in the environment topic.",
                    "label": 0
                },
                {
                    "sent": "So examples of it can be seen here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like this is one part of it we have like the chemical and then we get like those by product and chemical and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's more like some kind of categorization of determine one of those environmental terms for the full.",
                    "label": 0
                },
                {
                    "sent": "Like for the photos you can check here like maybe we can see it later at the end of the presentation.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh yeah, for those terms like we tried to match, we tried to match for.",
                    "label": 0
                },
                {
                    "sent": "What are the terms in the document?",
                    "label": 0
                },
                {
                    "sent": "What are the?",
                    "label": 0
                },
                {
                    "sent": "How the document is much with ontology.",
                    "label": 0
                },
                {
                    "sent": "So basically we used.",
                    "label": 0
                },
                {
                    "sent": "We used the terms that we extracted before and the other extracted before.",
                    "label": 0
                },
                {
                    "sent": "Basically we used the lemmatized words which is basically the dictionary form of the words we use towards synonyms and we use the Wikidata classes from the relevant.",
                    "label": 1
                },
                {
                    "sent": "Superior concepts why you.",
                    "label": 0
                },
                {
                    "sent": "For example, we used like they were kicked out of classes are not looked at a concept actually, although we tried that before.",
                    "label": 0
                },
                {
                    "sent": "What we didn't get any matches because like the ontology is more like the ontology terms is more like top level or category or topic things.",
                    "label": 0
                },
                {
                    "sent": "So whereas like the concept something so specific.",
                    "label": 1
                },
                {
                    "sent": "So when you got the concept itself or the named entity were so specific, that's why we're not matched with the ontology term.",
                    "label": 1
                },
                {
                    "sent": "Whereas like if we go to the.",
                    "label": 0
                },
                {
                    "sent": "To the Wikidata classes, which is the category that those annotation falls into.",
                    "label": 0
                },
                {
                    "sent": "We try to find some matches actually.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So those are the steps that we used like this used for understanding the documents.",
                    "label": 0
                },
                {
                    "sent": "Now we after that we did some kind of preliminary analysis on that.",
                    "label": 0
                },
                {
                    "sent": "So first we started with the content analysis.",
                    "label": 1
                },
                {
                    "sent": "So we got all the words we calculated the TF, IDF of them.",
                    "label": 0
                },
                {
                    "sent": "And then we projected toward the cloud.",
                    "label": 0
                },
                {
                    "sent": "For example, here we can see some of the like some of the important ones like Commission, European regulation and so on.",
                    "label": 0
                },
                {
                    "sent": "One one problem might notice probably like for example the existence of some of these top words.",
                    "label": 0
                },
                {
                    "sent": "I expected, like the reason behind that.",
                    "label": 0
                },
                {
                    "sent": "And it turns out like this is kind of common problem because like it's, it's like each tool has a set of stop words at you just sit with it and like it stop or somewhere in the cannot complete.",
                    "label": 0
                },
                {
                    "sent": "Either go too far or you either got too short.",
                    "label": 0
                },
                {
                    "sent": "So in a way, like in a way that you might get OK, some of those as like as a byproduct it can.",
                    "label": 0
                },
                {
                    "sent": "It can be removed like manually later.",
                    "label": 0
                },
                {
                    "sent": "But yeah, this is more like one of the byproduct of having some like static set of Star Wars.",
                    "label": 0
                },
                {
                    "sent": "The problem with.",
                    "label": 0
                },
                {
                    "sent": "So rare in English nowadays, accepting legal documents that people don't bother, including it in lists of stop words.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe that's one of the reasons.",
                    "label": 0
                },
                {
                    "sent": "Because like, OK, otherwise like it didn't have the ones like this like that and so on.",
                    "label": 0
                },
                {
                    "sent": "But we get Shell which is now at.",
                    "label": 0
                },
                {
                    "sent": "This is not really really used and listen very formal topics.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that was like for the content.",
                    "label": 0
                },
                {
                    "sent": "Then we tried to check like what are the Wikipedia concept that we matched like and we listed the top ones here.",
                    "label": 0
                },
                {
                    "sent": "So basically we got something like European Union.",
                    "label": 0
                },
                {
                    "sent": "Europe, a sovereign state treaty and law, and so on.",
                    "label": 0
                },
                {
                    "sent": "So basically out of those like we got like 157 unique Wikipedia concepts.",
                    "label": 1
                },
                {
                    "sent": "And out of those actually 50K concepts appeared only in one document.",
                    "label": 1
                },
                {
                    "sent": "So like off of each one of documents like have some like have some unique concepts and only.",
                    "label": 0
                },
                {
                    "sent": "Like one 100K of their arpitan up to three documents and only like 20.",
                    "label": 1
                },
                {
                    "sent": "Two of them appeared in the lock and 10,000 documents is like OK, this is not.",
                    "label": 0
                },
                {
                    "sent": "So much distinctive the reason why did some analysis?",
                    "label": 0
                },
                {
                    "sent": "Because this showed that we can, in a way use the documents to distinct values.",
                    "label": 0
                },
                {
                    "sent": "The Wikipedia annotation that to distinguish between documents because like if we have like, for example, 50K concept like each one or exist in one document.",
                    "label": 0
                },
                {
                    "sent": "So we can use it as a distinctive feature in some classification and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's not like a common like most of the Wikipedia concept were not so common that it cannot be distinguished.",
                    "label": 0
                },
                {
                    "sent": "But whereas like the comma, this document has its own set of Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Except.",
                    "label": 0
                },
                {
                    "sent": "Is this where we keep it?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, and for the named entities like the extracted name was in a way similar to those one that the one with Wiki Fire, because like we're still dealing with English, but we try to like we try to see the categorisation of those introduced the categories we extracted.",
                    "label": 0
                },
                {
                    "sent": "Obviously like the top one was like the number as we see here because like usually integration like we have this like up there based on lower number something or they like usually have numbers like.",
                    "label": 0
                },
                {
                    "sent": "Low numbers or the document numbers and so on.",
                    "label": 0
                },
                {
                    "sent": "So we got like 18 million, 18 million entities around 1 million of them were actually distinct ones, but obviously the majority were numbered after moving.",
                    "label": 0
                },
                {
                    "sent": "Then after removing the number entity we got like around 500,000 entity entities.",
                    "label": 1
                },
                {
                    "sent": "So like most of them like after number we have the organisations which seems like reasonable and the date usually mentioning the dates.",
                    "label": 0
                },
                {
                    "sent": "Of the documents at some pier personals and location.",
                    "label": 0
                },
                {
                    "sent": "The location was important like to know like what is the weather?",
                    "label": 0
                },
                {
                    "sent": "Where is the document like a specified?",
                    "label": 0
                },
                {
                    "sent": "Like this document for legalization in France or and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is for the named entities and.",
                    "label": 0
                },
                {
                    "sent": "You have so many.",
                    "label": 0
                },
                {
                    "sent": "Organizations right so how many?",
                    "label": 0
                },
                {
                    "sent": "We're actually spotted by Wiki Fire where they mostly non.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia concepts I yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Mostly yeah yeah, but probably like the difference.",
                    "label": 0
                },
                {
                    "sent": "The difference between the Wikipedia and named entity process will make more effective with dealt with non English documents, whereas like we learn English documents, most of the named entity recognition like system is not that good where it's like OK we can extract without a key file.",
                    "label": 0
                },
                {
                    "sent": "We can extract some things were not extracted otherwise.",
                    "label": 0
                },
                {
                    "sent": "That's why we like we wanted to use Wiki fire so.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For so for the Formula Ontology mapping, we got like those are the list of the most the 20 most frequent ones that we can see.",
                    "label": 1
                },
                {
                    "sent": "OK, the committee, because like usually in every version like the committee decides on so on.",
                    "label": 0
                },
                {
                    "sent": "But we can get some most of them related to legal terms like this scission annex, but we can see something like interesting like transport.",
                    "label": 0
                },
                {
                    "sent": "We can see like management here or waste like this is more like related to environment trade an fund.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Those were the most important in Formula anthology terms that we got.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, like this was more likely starting with the word, so this was more like a preliminary like the memory work on it, but based on that OK, like this is the first step we want to do after that.",
                    "label": 0
                },
                {
                    "sent": "So first like with like for the rectification we found actually some of the matches were not that really matches like we found them are totally irrelevant, but which is like which is like can happen of course, because like some errors can occur and so and so we want to expect more and try to find a way to resolve them.",
                    "label": 1
                },
                {
                    "sent": "And also like for the named entity specifically.",
                    "label": 0
                },
                {
                    "sent": "Actually location like, because now it's like this like this.",
                    "label": 0
                },
                {
                    "sent": "Phrases like representing a location.",
                    "label": 0
                },
                {
                    "sent": "But OK, we want to go one step further, like more specific geospatial location may be in this area or in this area because this is important as this information is important for lawyers like we want the legalization on this area specifically.",
                    "label": 0
                },
                {
                    "sent": "So yeah, this is 1 important thing direction to go on and also like for informing.",
                    "label": 1
                },
                {
                    "sent": "In terms of the matching process, were actually like a simple string matching, so it's not some classifiers and so on, so that was more like a baseline, so we are intending to improve on it and also like.",
                    "label": 0
                },
                {
                    "sent": "OK, part of this like we got for each document, a set of annotations, an information that can be used as like a feature vector in like building any type of classifiers so we can build classifiers for the legal domain documents to use it in any way of also and one of the use cases we're gonna use.",
                    "label": 0
                },
                {
                    "sent": "Actually, for invariants project like is a query expansion, so whatever the user search for some squarely we can analyze and extract like similar word, like other words Wikipedia concept so we can enhance the result of this search so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh yeah, that was like that.",
                    "label": 0
                },
                {
                    "sent": "Was it like it was part of environment and this still Terminator work and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's it.",
                    "label": 0
                },
                {
                    "sent": "I would be happy to activate question.",
                    "label": 0
                }
            ]
        }
    }
}