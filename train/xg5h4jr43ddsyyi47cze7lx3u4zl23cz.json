{
    "id": "xg5h4jr43ddsyyi47cze7lx3u4zl23cz",
    "title": "Poster Spotlights",
    "info": {
        "author": [
            "Senjian An, University of Western Australia",
            "Gabriel Takacs, Stanford University",
            "Minh-Tri Pham, Surrey Space Centre, University of Surrey",
            "Alexander Toshev, Department of Computer and Information Science, University of Pennsylvania",
            "Xavier Perrotton, European Aeronautic Defence and Space Company",
            "Richard Socher, Computer Science Department, Stanford University",
            "Worapan Kusakunniran, School of Computer Science and Engineering, University of New South Wales",
            "Markus Enzweiler, Department of Mathematics and Computer Science, University of Heidelberg",
            "Bertram Drost, MVTec Software GmbH",
            "Sudheendra Vijayanarasimhan, Department of Computer Science, University of Texas at Austin",
            "Timothee Cour, WILLOW, INRIA",
            "Christoph Lampert, Max Planck Institute for Biological Cybernetics, Max Planck Institute",
            "Stefan Walk, Department of Computer Science, Darmstadt University of Technology",
            "Michael Alejandro Villamizar Vergel, Institut de Robotica i Informatica Industria (IRI), Technical University of Catalonia",
            "David Aldavert, Computer Vision Center, Autonomous University of Barcelona",
            "Oisin Mac Aodha, Department of Computer Science, University College London",
            "Leo Zhu, Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, MIT",
            "Olga Russakovsky, Computer Science Department, Stanford University",
            "Piotr Doll\u00e1r, Computational Vision, CalTech",
            "Zhiqi Zhang, Department of Computer Science and Engineering, University of South Carolina",
            "Josip Krapac, INRIA Grenoble Rh\u00f4ne-Alpes"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Natural Language Processing",
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_spotlights4a/",
    "segmentation": [
        [
            "My name is Cindy Ann from cutting University of Technology in Australia.",
            "This is joint work with Patrick one once weather and."
        ],
        [
            "Show me.",
            "So someone in search appears in object detection when we use sliding window method to optimize the quality function.",
            "So this problem can be formulated as finding the maximum entry of four dimensional area.",
            "So by exhaustive search and will take all into the powerful time for embodying images.",
            "So in this people will show that for special type of nonlinear quality functions called submodular function.",
            "So the 40 area has some 2 dimensional merge sabarish so we use this property so can reduce the time complexity to be quick.",
            "So however in practice cubic term solution is still too complex so we develop an approximate quadratic time.",
            "So for more details please come to see the Post, thank you.",
            "Hello."
        ],
        [
            "My name is Gabriel Takac and you see the rest of the authors up there so I won't read them all off.",
            "Our paper is called Unified Tracking and Recognition."
        ],
        [
            "With rotation invariant, fast features and the idea is that we want to do mobile augmented reality sort of application where we've got a video stream coming in.",
            "He said you removed the animations.",
            "And all the contents.",
            "OK. Oh, there it is.",
            "So the idea is we want to track frame to frame.",
            "You can just go all the way home.",
            "And then periodically you want to query the image to see what is in the video screen and then you want to augment the frame with the results of that.",
            "So typically this is done using some tracking algorithm and some image recognition algorithm and the novelty of our approach is that we're going to use the same feature descriptors for both and we can do this because they are fast enough to do it in real time on a mobile phone.",
            "So if you come by, we have both a demo and a poster and I'll give you all the details.",
            "I just want to set up the problem for you guys, thank you.",
            "Hi, I miss you."
        ],
        [
            "I'm from the University of Surrey in England.",
            "This is joint work with young cow funded with zone and touch and jam nowadays."
        ],
        [
            "The integral image is widely used in computer vision.",
            "Highlight features, integral into histograms, spatial pyramid matching, serve and bilateral filtering are among many applications of the integral image.",
            "This is because we can quickly integrate over a rectangular rectangular region using the integral image.",
            "However, the integral image imposes a rectilinear constraint on the integration on the region of integration.",
            "In other words, it's impossible to quickly integrate over a non rectilinear Polygon using the integral image.",
            "For example a triangle.",
            "So in this work we present a method that removes this rectilinear constraint and allows to integrate over a Polygon in time only linear to the number of vertice.",
            "Is.",
            "This is done by changing the core idea of the integral image.",
            "Instead of precomputing rectangular integrals, we precompute right triangular integrals and use the trips are the rule to do the integration.",
            "Example of an example application we applied this work to improve the Viola Jones object detection framework by extending highlight features with polygonal highlight features and obtained better results do come to our poster and find out more about the method.",
            "Thank you."
        ],
        [
            "Hello, my name is Alexander Joseph and I would like to kindly invite you to our poster object."
        ],
        [
            "Action via boundary structure segmentation.",
            "In this work we address the problems of object detection and segmentation using shape as a representation.",
            "Our most important contribution is an Oval shape descriptor called Cardiogram which captures the shape of an object in holistic global manner.",
            "Inject is capable of dealing robustly with interior clutter and background clutter.",
            "To achieve this, we couple the shape descriptor cardiogram with the process of segment and bounding grouping in aerial image, which allows us to perform global in holistic shape.",
            "Detection in real images simultaneously with object segmentation.",
            "We propose a simple one step optimization for our approach and we achieve state of the art results on established object recognition datasets.",
            "Thank you."
        ],
        [
            "Hello, my name is zany Belton.",
            "It's a dream.",
            "Work with Macs yourself.",
            "From here, there's an Michelle from Tekken Paratek."
        ],
        [
            "In this work, we present a new boosting sliding window approach to build a multi view weekly object detector.",
            "Without choosing specific view annotation.",
            "In order.",
            "Contrary to classical approach, where one classify your purview is build is used or divide, divide and conquer strategy is used with purpose here to to use a single cascade of weak classifiers.",
            "But to introduce into an implicit theoretical structure.",
            "In order.",
            "To do that, we introduce a week petition concept.",
            "This week petition concept enables to divide positive samples at each boosting stage.",
            "Which enables to select a descriptor per view and consequently to build efficient material weak classifiers.",
            "It's interesting to notice that the petition doesn't need to be perfect, since it is done at each boosting stage.",
            "Experimental results show the efficiency of air pressure.",
            "Please come to see us at a poster for more data is think."
        ],
        [
            "Hello everybody, I like the spotlight presentations but there are so many great ideas flowing around here that it's easy to have a buffer overflow, so I will."
        ],
        [
            "Focus on three takeaway messages of our paper connecting modalities.",
            "The first is that we only need a small amount of supervised data.",
            "We take advantage of the similarity between the statistics of nouns in text corpora such as New York Times and object regions in scene images from Flickr, we only need a total of five annotated images to outperform other methods.",
            "Other annotation methods that used hundreds of images.",
            "How do we do this?",
            "And this leads me to the second point.",
            "Our image representation reintroduce Flexibel new region based image representation.",
            "Unique visual words.",
            "It allows us to trade off how often a visual word occurs, with how many different object category it overlaps with.",
            "Thirdly, visual words, an normal textual words are then input to our learning method.",
            "We assume that there are these somewhat platonic ideas or latent concepts and they can be instantiated either images or text, and in both cases they will be embedded in a context we use kernelized Canonical correlation analysis or CCA.",
            "To find which visual word corresponds to textual words, we add these concepts.",
            "CCA is a statistical technique similar to in spirit to PCA, but it works with pairs of random vectors instead of just one random vector.",
            "So if you're interested in annotation segmentation or how images and text corpora relate, feel free to stop by my poster a 9 and you can also learn about using CCA.",
            "How do you say can be used to connect from modalities?",
            "Thank you."
        ],
        [
            "Hi my name is Laura Banku school and um, I'm from the University of New South Wales from Sydney.",
            "In this paper we."
        ],
        [
            "Try to recognize the human identity formed by using the gate feature that capture form values views.",
            "Actually the feature is like well recognized biometric feature that can use to identify The Walking human from the farthest end.",
            "However, the performance of the K recognition can be significantly dropped if the camera viewpoint or the.",
            "Walking direction of the human is change, so we try to follow the VTM order view transformation model based approach to tackle with this problem.",
            "The VTM in our proposed technique is built up from the local motion regression by using the SVR of the gate energy email or the GI alser care feature.",
            "So.",
            "Basically, the GIS form the valleys view can be normalized into a common view by using a set of pre construct V teams and then the case similarity measurement of the T of the two T eyes from two that originally come from there.",
            "Two different views can be carried out by using the standard measurement method and please come to my poster For more information.",
            "Thank you.",
            "Kate."
        ],
        [
            "Hi there, my name is Marcus and Spider and this work on pedestrian classification orientation estimation is joint work with Yoga Villa from Diner research."
        ],
        [
            "So in this work, we're going to focus on pedestrian classification orientation estimation from single to the images.",
            "Besides the actual classification, the orientation estimation part is an important aspect for many applications and as opposed to previous work, we're going to use exactly the same model for both tasks, which means we have the same model and the same datasets to solve for both problems in more detail of framework consists of a set of post specific mixture of experts classifiers, which consists of two parts.",
            "The first parts are body orientation priors which we derive from shape matching, and the second part are actual discriminative classifiers which use texture based features.",
            "I'm fermentation estimation, we approximate the continuous density of body orientation using a Gaussian mixture models.",
            "No experiments, we use a large pedestrian, real world datasets and our results show 50% less errors for both classification and orientation estimation versus state of the art.",
            "So please come to see your poster and some video clips in section A, thanks.",
            "Yeah."
        ],
        [
            "And the second of sticking paper we have here is actually on integrating a model for."
        ],
        [
            "Partial occlusion and pedestrian classification, and this is joint work with underlying Strata, Banshee land area gorilla.",
            "So typically, most pedestrian classifieds assume full visibility of the profession in the image.",
            "As a result, that simplification performance does not does not degrade gracefully when partial occlusions are present.",
            "So here in our approach we explicitly integrate model of partial occlusions into a multi queue component based classification framework.",
            "And occlusion typically manifest in discontinuity's in motion space and depth.",
            "So so called occlusion boundaries.",
            "So in first step we tried to examine those occlusion boundaries to recover visibility information about certain pedestrian body components.",
            "In the second step we use this exact information to fusar multiqueue component classifiers within a combined mixture of expert framework and our component based classifiers use features derived from intensity, depth and motion and our results show that occlusion handling reduces false positives that constant detection rate levels.",
            "By a factor of two, add an additional factor of two.",
            "Performance improvement comes from the Magic you classification, so thanks a lot and please come see your posters."
        ],
        [
            "Hello everybody, I'm bottom roast and this is joint work with Marcus already from VTech.",
            "Nothing Robin Slobodan Ilic from the Technical University of Munich."
        ],
        [
            "What we're doing is 3D object detection, so we have some sort of object.",
            "We say freeform objects or can have really any shape you want, and we have some 3D scene which was taken with any 3D sensor that's out there.",
            "And what we want to do is we want to find that object in the scene going too fast, stable, accurate of course.",
            "And I think we can do that.",
            "Our main applications are robotics and industrial applications such as inspecting the object or grasping it for example.",
            "Yeah, so if you're interested in that step by the post so we can show you a small video with a robot that is really using the algorithm in a very nice demonstration, thanks."
        ],
        [
            "Hi, I'm so the Norwegian are Seaman from UT Austin and this is joint work with Ashish Kapoor at MSR Redmond on visual recognition and detection and are bounded computational."
        ],
        [
            "Current approaches for recognition and detection ignore computational constraints during recognition, and therefore they need to be run to completion in order to provide a useful answer in our.",
            "In this paper work we explore an approach that reasons about available computational resources and try ages appropriate actions to take so that the best possible result can be obtained under time constraints.",
            "In particular, our detection approach actively determines both the best location and also the best feature type to extract, given the computational cost of the features.",
            "We do this by calculating the value of information of all image locations using our normal grid based model and choose a feature and update our model iteratively.",
            "By doing this, our approach can target informative image locations as seen on the figure on the right in comparison to current methods, which are passive.",
            "On 2 popular detection datasets, we show that our approach exhibits better anytime behavior than passive approaches.",
            "In other words, it can be stopped at anytime to provide the best possible result or the best possible detection result.",
            "If you are interested, interested in active detection, or if you want to know how to pronounce my last name, please visit our poster."
        ],
        [
            "Hi, I'm Timothy Cord from inria.",
            "This is joint work with my colleagues on Talking Pictures.",
            "There's."
        ],
        [
            "Love recent interests in automatically tagging people in videos.",
            "In current work, there is no need for extraneous supervision.",
            "For example, using a screenplay as in our previous CPR work.",
            "This dependence quickly, however, really limits the applicability of those methods.",
            "In our work, we present the first fully automatic system for automatically tagging people in videos.",
            "In this work, their only source of supervision is naturally occurring dialogue cues such as hay Jack, indicating that Jack is somewhere in the scene, whereas Jack left would indicate the opposite.",
            "We integrate those dialogue cues using novel convex formulation for multiple instance learning and we further improve our results using grouping constraints and general constraints.",
            "To this end, we propose a novel model for integrating non non just beyond pairwise grouping cues and it has both tractable inference and tractable learning.",
            "We further show excellent performance on automatically naming people in the white diversity of TV shows and TV series with the state of the art performance for both grouping and naming.",
            "So please come to our poster."
        ],
        [
            "Hi my name is Christopher Lambert from the new Institute for Science and Technology Nir in Vienna.",
            "Um?"
        ],
        [
            "The work that I'm presenting is on the acceleration of object detection cascades, so most of you will be familiar with object detection cascades from the Viola Jones face detector, for example, so detection cascade works by classifying many regions in an image, whether they contain an object or not.",
            "By evaluating multiple classification functions and for positive detection or the individual classifier stages must have a positive response and you can see in a toy example here.",
            "Have a cascade of two stages.",
            "So it's a good idea to use such a cascade for two reasons.",
            "One of them is that if you have multiple easy classifiers, you can learn a better decision than with just one simple classifier.",
            "But the main reason is that it's faster to use it at Cascade because you have early stopping if one of the stages says this is not an object, you can immediately stop and you don't have to go to the later stages.",
            "But this is smart in the early stopping way in the Cascade stages, but it's still an exhaustive search if you go.",
            "Sliding window over all possibilities in the in the image, so the contents of my work is to make the system also smart in this search within each stage and do a divide and conquer procedure that works by not evaluating each position in the image separately and deciding to accept auto reject.",
            "But to decide for whole sets of region at a time and thereby speed up the cascade."
        ],
        [
            "Hello everyone, my name is Steven Wagon.",
            "This is joint work with nicotine Maya connections and burn Sheila.",
            "So our works on pedestrian detection."
        ],
        [
            "And we're introducing a new feature called Color Self Similarity or CSS that is complimentary to Hawken.",
            "Histograms are flow and leads to a significant improvement of performance on the category and data set on in real person and onto the process.",
            "So what this feature does is it is computes similarity coefficients between colors across different regions of the classification window.",
            "So the classification can learn something about color without running into problems because of.",
            "Different cameras or different lighting or the variability in clothing.",
            "And we're also looking at some issues that can prevent repeatability.",
            "For example, the evaluation protocol.",
            "So if you just state that you're using the Pascal criterium to evaluate if it detects matches or not, this is not enough.",
            "So yes, the room for interpretation, especially if you have a late on only subbranch of pedestrians, like only pedestrians off this height or unusual pedestrians.",
            "A similar issue occurs for training where the particles of an unspecified to unstable.",
            "And on the example of SVM bootstrapping, we show that some popular choices can lead to on repeat and repeat the presents.",
            "OK, thanks."
        ],
        [
            "My name is Michael Jamison.",
            "I am from the Robotics Institute in Barcelona and here in this work we address the detection of object."
        ],
        [
            "That may appear on the rotation in the image plane.",
            "Our contribution is to use boosting random furs in combination with the couple approach in order to have a simple but efficient detection methods.",
            "Randall and firms are local random binary feature that are used for classification.",
            "And but in this case, our binary feature or random fares are computed over local histogram of oriented gradients.",
            "By the other hand, our D couple approach consisting of an orientation step an on object classification step allows to reduce the computational cost of evaluating this object classifier for different orientation.",
            "So in this way the orientation estimator is evaluated over the input images to Jill potential.",
            "Hypothesis dannard invalidated, but rotating and classy.",
            "Anne Anne testing the Object Classifier both estimator and the classifier are computed using a boosting algorithm with the end of finding the most discriminative and robust feature for larger classification.",
            "These methods have been validated for standard and new data sets, showing remarkable results.",
            "Thank you.",
            "And."
        ],
        [
            "Afternoon in the middle level from the Computer Vision Center in Barcelona, an in over poster.",
            "We are going to show you our segmentation method which is able to process."
        ],
        [
            "Several images per second, which is based on back of features.",
            "We use the back of features to a single pixel level category to every picture of the image, so we need it to work as fast as possible.",
            "Therefore we use tensor features to extract information from the image.",
            "An super linear complexity classifiers to contest them into visual words.",
            "I'm with this with our words.",
            "We can create an integral image with the weights of the linear classifier, which it allows us to calculate the classification score of any rectangular region of the image in Constantine, independently of the region of or the codebook size.",
            "We use this method.",
            "Combine it with a mid shift imitation method to obtain the final segmentation.",
            "We have evaluated this method with the Pascal challenge or the red segmentation data set, obtained similar results to their state of their methods, but with a much lower computational cost.",
            "Thank you for your attention and if you have any questions concerning poster like.",
            "I."
        ],
        [
            "Hi, my name is Sasha McKay from the University College of London and this is joint work with my advisor, gave Robusto and my qualifies so given sequence of images in a set of algae."
        ],
        [
            "Items, which ones should you use to perform feature matching or to compute optical flow?",
            "You could just look at the performance evaluation table and pick the single best performing algorithm, but it's not clear if that will generalize well for your sequence.",
            "Take the example of computing optical flow in the image in the top price, where Algorithme does best overall indicated by more areas of white in the less areas, avoiding the endpoint error image.",
            "It doesn't do the best in every single location, so if you look at the circular region to the right of the teddy bear, algorithm B does better we propose that the single best algorithm for each location can be predicted to the supervised training of a classifier.",
            "So come to your poster and will show you results for both feature matching experience and experiments and optical flow and will also show you how we can compute realistic looking correspondence data for training purposes.",
            "Thanks very much."
        ],
        [
            "I'm Leo coming from MRG.",
            "It's a joint work with Chen Yuan Freeman."
        ],
        [
            "OK, we starting object detection problem.",
            "Basically in this work we try to ask what a good structures represent object in this work.",
            "Particularly we propose a very simple hierarchical structure so you can see in left figure.",
            "Here we propose a three layer.",
            "Regular great structure to represent object and object paths in three layers, so we will show that this very simple three layer structure is able to achieve state of the art performance on Pascal data set.",
            "So we also show that three layer structure is better than two layer structure.",
            "So the learning of this model can be formulated.",
            "As a latent structure as well, problem in this case learning can be solved by concave and convex procedure which guaranteed to find the local optimal.",
            "So we will show that the details of the hierarchical learning in our post.",
            "Thanks for attention."
        ],
        [
            "A Steiner tree approach to efficient object detection.",
            "I'm agora sakowski.",
            "This is joint work with and ring from Stanford.",
            "So the goal of our work is to efficiently."
        ],
        [
            "Detect multiple object classes within a scene.",
            "So for example, you know trash bins and ski boots, coffee mugs, whatever have you.",
            "So the standard approach is to run sliding windows once per object class, which is extremely inefficient.",
            "We developed an object detection pipeline that avoids using sliding windows by instead using unsupervised segmentation to propose candidate regions that are likely to contain objects.",
            "However, different segmentations are needed for different types of objects.",
            "Overall, we present a pipeline that consists of five steps for proposing these regions, and each step is controlled by parameter that needs to be tuned individually for each object class.",
            "And at the core of our approach is the observation that actually we can reuse parts of this pipeline for between the different object classes, thus amortizing the cost of proposing these regions.",
            "To do this, we develop a Steiner tree optimization framework that allows for efficient sharing of the parameters of the pipeline, thus further speeding up object detection an.",
            "In practice, our method obtains about a 10 to 15 times speedup compared to sliding windows approach when detecting multiple object classes within cluttered scenes.",
            "Thank you."
        ],
        [
            "Hi, my name is Scott Dollar.",
            "This is joint work with Peter Welander and Pietro Perona.",
            "Three Peter paper.",
            "So what work?"
        ],
        [
            "On here is a lot of the previous spotlights and talks you've seen or about object detection.",
            "Finding objects in the 1st place where we're interested in is given that you've actually found the object estimating its pose.",
            "So what it's what's outlined is or what not.",
            "And this could be formulated as a structured output prediction problem or a regression problem.",
            "The difference here is though, that it's not just an arbitrary output, it's actually an output that suppose an observation we make is that based on an estimate of the pose we can actually query new features from the image based on our current estimate of the pose, and so the idea is we can come up with a very nice principle algorithm to exploit this, where as we refine our estimate of the pose we can actually get new features and we use random Fern features which are very fast.",
            "And so we can prove some nice things about this algorithm, but maybe the best proof is that it actually works quite well that a lot of the times that actually matches or outperforms human performance.",
            "Peter and I both will work both Peters, but Peter and I both labels some images and we trained algorithm using Peters annotations and then compared to my annotations and actually the algorithm is better than me.",
            "So it actually works quite well.",
            "But I'll give you the details if you come to my poster, thank you.",
            "I."
        ],
        [
            "Junk images young.",
            "I'm from the University of South Carolina.",
            "The title of."
        ],
        [
            "Our paper is free shapes of windows.",
            "Search for object localization.",
            "As we know, backup your words along with the server.",
            "Windows Search method is widely used in the object localization method.",
            "As shown.",
            "I've shown in this figures blue points represent negative features and red points represent positive features.",
            "With your lender, by using bag of bag of your words.",
            "Rectangular subwindow are commonly used because of their simplicity and high efficiency.",
            "But however, for non convex objects and objects that are very close to each other rectangle, often no rectangular subwindow can cover the object of interest tightly.",
            "In order to address this problem, we propose a new approach by searching for an age.",
            "An Angel and octane are super windows without pre specifying each is shape as shown in the figures.",
            "Our friendship subwindow can't.",
            "Covers object tightly.",
            "We tested our method on will see 2006 and will say 2007 and we achieve better performance than the state of the art object localization method.",
            "Do you do you want to know more about our research?",
            "Please come to our poster.",
            "Thank you."
        ],
        [
            "Hi, I'm your souped up.",
            "It's from Inga Inga, inria, Grenoble.",
            "Imagine that you want to search on net for the images of for example."
        ],
        [
            "Power what current search engines give you is pretty noisy, can be pretty noisy because they rely only a textual metadata and ignore completely visual content of the image.",
            "What we could do is take this images and try to re rank them using including visual information.",
            "Now how people have been doing this so far is take the top ranked images from search engine, train a classifier and using the classifier scores to rank the images.",
            "What the problem with this approach is is that.",
            "It you need to train a classifier for for every query, so it doesn't really scale up to a real world scenario where you want to be able to quickly answer to any user query.",
            "So what we do is we define the query relative features which were.",
            "The data representation doesn't doesn't depend only on visual and textual content, but also depends on the query.",
            "This allows us to train query relative classifier which train only once and tests on any.",
            "Possible imaginable query?",
            "Or we obtain significant improvement over the search engines ranking even for difficult queries.",
            "We have also shining new datasets, big annotated that we tend to release to be used for these kinds of problems.",
            "Thank you and please come see us at the poster a 25 I think."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Cindy Ann from cutting University of Technology in Australia.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Patrick one once weather and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show me.",
                    "label": 0
                },
                {
                    "sent": "So someone in search appears in object detection when we use sliding window method to optimize the quality function.",
                    "label": 1
                },
                {
                    "sent": "So this problem can be formulated as finding the maximum entry of four dimensional area.",
                    "label": 1
                },
                {
                    "sent": "So by exhaustive search and will take all into the powerful time for embodying images.",
                    "label": 1
                },
                {
                    "sent": "So in this people will show that for special type of nonlinear quality functions called submodular function.",
                    "label": 0
                },
                {
                    "sent": "So the 40 area has some 2 dimensional merge sabarish so we use this property so can reduce the time complexity to be quick.",
                    "label": 0
                },
                {
                    "sent": "So however in practice cubic term solution is still too complex so we develop an approximate quadratic time.",
                    "label": 0
                },
                {
                    "sent": "So for more details please come to see the Post, thank you.",
                    "label": 0
                },
                {
                    "sent": "Hello.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Gabriel Takac and you see the rest of the authors up there so I won't read them all off.",
                    "label": 0
                },
                {
                    "sent": "Our paper is called Unified Tracking and Recognition.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With rotation invariant, fast features and the idea is that we want to do mobile augmented reality sort of application where we've got a video stream coming in.",
                    "label": 1
                },
                {
                    "sent": "He said you removed the animations.",
                    "label": 0
                },
                {
                    "sent": "And all the contents.",
                    "label": 0
                },
                {
                    "sent": "OK. Oh, there it is.",
                    "label": 0
                },
                {
                    "sent": "So the idea is we want to track frame to frame.",
                    "label": 0
                },
                {
                    "sent": "You can just go all the way home.",
                    "label": 0
                },
                {
                    "sent": "And then periodically you want to query the image to see what is in the video screen and then you want to augment the frame with the results of that.",
                    "label": 1
                },
                {
                    "sent": "So typically this is done using some tracking algorithm and some image recognition algorithm and the novelty of our approach is that we're going to use the same feature descriptors for both and we can do this because they are fast enough to do it in real time on a mobile phone.",
                    "label": 0
                },
                {
                    "sent": "So if you come by, we have both a demo and a poster and I'll give you all the details.",
                    "label": 0
                },
                {
                    "sent": "I just want to set up the problem for you guys, thank you.",
                    "label": 0
                },
                {
                    "sent": "Hi, I miss you.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm from the University of Surrey in England.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with young cow funded with zone and touch and jam nowadays.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The integral image is widely used in computer vision.",
                    "label": 1
                },
                {
                    "sent": "Highlight features, integral into histograms, spatial pyramid matching, serve and bilateral filtering are among many applications of the integral image.",
                    "label": 0
                },
                {
                    "sent": "This is because we can quickly integrate over a rectangular rectangular region using the integral image.",
                    "label": 0
                },
                {
                    "sent": "However, the integral image imposes a rectilinear constraint on the integration on the region of integration.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's impossible to quickly integrate over a non rectilinear Polygon using the integral image.",
                    "label": 1
                },
                {
                    "sent": "For example a triangle.",
                    "label": 0
                },
                {
                    "sent": "So in this work we present a method that removes this rectilinear constraint and allows to integrate over a Polygon in time only linear to the number of vertice.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "This is done by changing the core idea of the integral image.",
                    "label": 0
                },
                {
                    "sent": "Instead of precomputing rectangular integrals, we precompute right triangular integrals and use the trips are the rule to do the integration.",
                    "label": 0
                },
                {
                    "sent": "Example of an example application we applied this work to improve the Viola Jones object detection framework by extending highlight features with polygonal highlight features and obtained better results do come to our poster and find out more about the method.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, my name is Alexander Joseph and I would like to kindly invite you to our poster object.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Action via boundary structure segmentation.",
                    "label": 1
                },
                {
                    "sent": "In this work we address the problems of object detection and segmentation using shape as a representation.",
                    "label": 0
                },
                {
                    "sent": "Our most important contribution is an Oval shape descriptor called Cardiogram which captures the shape of an object in holistic global manner.",
                    "label": 0
                },
                {
                    "sent": "Inject is capable of dealing robustly with interior clutter and background clutter.",
                    "label": 1
                },
                {
                    "sent": "To achieve this, we couple the shape descriptor cardiogram with the process of segment and bounding grouping in aerial image, which allows us to perform global in holistic shape.",
                    "label": 0
                },
                {
                    "sent": "Detection in real images simultaneously with object segmentation.",
                    "label": 0
                },
                {
                    "sent": "We propose a simple one step optimization for our approach and we achieve state of the art results on established object recognition datasets.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, my name is zany Belton.",
                    "label": 0
                },
                {
                    "sent": "It's a dream.",
                    "label": 0
                },
                {
                    "sent": "Work with Macs yourself.",
                    "label": 0
                },
                {
                    "sent": "From here, there's an Michelle from Tekken Paratek.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this work, we present a new boosting sliding window approach to build a multi view weekly object detector.",
                    "label": 0
                },
                {
                    "sent": "Without choosing specific view annotation.",
                    "label": 0
                },
                {
                    "sent": "In order.",
                    "label": 0
                },
                {
                    "sent": "Contrary to classical approach, where one classify your purview is build is used or divide, divide and conquer strategy is used with purpose here to to use a single cascade of weak classifiers.",
                    "label": 0
                },
                {
                    "sent": "But to introduce into an implicit theoretical structure.",
                    "label": 0
                },
                {
                    "sent": "In order.",
                    "label": 0
                },
                {
                    "sent": "To do that, we introduce a week petition concept.",
                    "label": 0
                },
                {
                    "sent": "This week petition concept enables to divide positive samples at each boosting stage.",
                    "label": 0
                },
                {
                    "sent": "Which enables to select a descriptor per view and consequently to build efficient material weak classifiers.",
                    "label": 0
                },
                {
                    "sent": "It's interesting to notice that the petition doesn't need to be perfect, since it is done at each boosting stage.",
                    "label": 0
                },
                {
                    "sent": "Experimental results show the efficiency of air pressure.",
                    "label": 0
                },
                {
                    "sent": "Please come to see us at a poster for more data is think.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, I like the spotlight presentations but there are so many great ideas flowing around here that it's easy to have a buffer overflow, so I will.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Focus on three takeaway messages of our paper connecting modalities.",
                    "label": 0
                },
                {
                    "sent": "The first is that we only need a small amount of supervised data.",
                    "label": 0
                },
                {
                    "sent": "We take advantage of the similarity between the statistics of nouns in text corpora such as New York Times and object regions in scene images from Flickr, we only need a total of five annotated images to outperform other methods.",
                    "label": 1
                },
                {
                    "sent": "Other annotation methods that used hundreds of images.",
                    "label": 0
                },
                {
                    "sent": "How do we do this?",
                    "label": 0
                },
                {
                    "sent": "And this leads me to the second point.",
                    "label": 0
                },
                {
                    "sent": "Our image representation reintroduce Flexibel new region based image representation.",
                    "label": 0
                },
                {
                    "sent": "Unique visual words.",
                    "label": 0
                },
                {
                    "sent": "It allows us to trade off how often a visual word occurs, with how many different object category it overlaps with.",
                    "label": 0
                },
                {
                    "sent": "Thirdly, visual words, an normal textual words are then input to our learning method.",
                    "label": 0
                },
                {
                    "sent": "We assume that there are these somewhat platonic ideas or latent concepts and they can be instantiated either images or text, and in both cases they will be embedded in a context we use kernelized Canonical correlation analysis or CCA.",
                    "label": 0
                },
                {
                    "sent": "To find which visual word corresponds to textual words, we add these concepts.",
                    "label": 0
                },
                {
                    "sent": "CCA is a statistical technique similar to in spirit to PCA, but it works with pairs of random vectors instead of just one random vector.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in annotation segmentation or how images and text corpora relate, feel free to stop by my poster a 9 and you can also learn about using CCA.",
                    "label": 0
                },
                {
                    "sent": "How do you say can be used to connect from modalities?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi my name is Laura Banku school and um, I'm from the University of New South Wales from Sydney.",
                    "label": 0
                },
                {
                    "sent": "In this paper we.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try to recognize the human identity formed by using the gate feature that capture form values views.",
                    "label": 0
                },
                {
                    "sent": "Actually the feature is like well recognized biometric feature that can use to identify The Walking human from the farthest end.",
                    "label": 0
                },
                {
                    "sent": "However, the performance of the K recognition can be significantly dropped if the camera viewpoint or the.",
                    "label": 0
                },
                {
                    "sent": "Walking direction of the human is change, so we try to follow the VTM order view transformation model based approach to tackle with this problem.",
                    "label": 1
                },
                {
                    "sent": "The VTM in our proposed technique is built up from the local motion regression by using the SVR of the gate energy email or the GI alser care feature.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "Basically, the GIS form the valleys view can be normalized into a common view by using a set of pre construct V teams and then the case similarity measurement of the T of the two T eyes from two that originally come from there.",
                    "label": 0
                },
                {
                    "sent": "Two different views can be carried out by using the standard measurement method and please come to my poster For more information.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Kate.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi there, my name is Marcus and Spider and this work on pedestrian classification orientation estimation is joint work with Yoga Villa from Diner research.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this work, we're going to focus on pedestrian classification orientation estimation from single to the images.",
                    "label": 1
                },
                {
                    "sent": "Besides the actual classification, the orientation estimation part is an important aspect for many applications and as opposed to previous work, we're going to use exactly the same model for both tasks, which means we have the same model and the same datasets to solve for both problems in more detail of framework consists of a set of post specific mixture of experts classifiers, which consists of two parts.",
                    "label": 0
                },
                {
                    "sent": "The first parts are body orientation priors which we derive from shape matching, and the second part are actual discriminative classifiers which use texture based features.",
                    "label": 0
                },
                {
                    "sent": "I'm fermentation estimation, we approximate the continuous density of body orientation using a Gaussian mixture models.",
                    "label": 0
                },
                {
                    "sent": "No experiments, we use a large pedestrian, real world datasets and our results show 50% less errors for both classification and orientation estimation versus state of the art.",
                    "label": 1
                },
                {
                    "sent": "So please come to see your poster and some video clips in section A, thanks.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second of sticking paper we have here is actually on integrating a model for.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Partial occlusion and pedestrian classification, and this is joint work with underlying Strata, Banshee land area gorilla.",
                    "label": 0
                },
                {
                    "sent": "So typically, most pedestrian classifieds assume full visibility of the profession in the image.",
                    "label": 1
                },
                {
                    "sent": "As a result, that simplification performance does not does not degrade gracefully when partial occlusions are present.",
                    "label": 0
                },
                {
                    "sent": "So here in our approach we explicitly integrate model of partial occlusions into a multi queue component based classification framework.",
                    "label": 0
                },
                {
                    "sent": "And occlusion typically manifest in discontinuity's in motion space and depth.",
                    "label": 0
                },
                {
                    "sent": "So so called occlusion boundaries.",
                    "label": 1
                },
                {
                    "sent": "So in first step we tried to examine those occlusion boundaries to recover visibility information about certain pedestrian body components.",
                    "label": 1
                },
                {
                    "sent": "In the second step we use this exact information to fusar multiqueue component classifiers within a combined mixture of expert framework and our component based classifiers use features derived from intensity, depth and motion and our results show that occlusion handling reduces false positives that constant detection rate levels.",
                    "label": 0
                },
                {
                    "sent": "By a factor of two, add an additional factor of two.",
                    "label": 1
                },
                {
                    "sent": "Performance improvement comes from the Magic you classification, so thanks a lot and please come see your posters.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, I'm bottom roast and this is joint work with Marcus already from VTech.",
                    "label": 0
                },
                {
                    "sent": "Nothing Robin Slobodan Ilic from the Technical University of Munich.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we're doing is 3D object detection, so we have some sort of object.",
                    "label": 0
                },
                {
                    "sent": "We say freeform objects or can have really any shape you want, and we have some 3D scene which was taken with any 3D sensor that's out there.",
                    "label": 0
                },
                {
                    "sent": "And what we want to do is we want to find that object in the scene going too fast, stable, accurate of course.",
                    "label": 0
                },
                {
                    "sent": "And I think we can do that.",
                    "label": 0
                },
                {
                    "sent": "Our main applications are robotics and industrial applications such as inspecting the object or grasping it for example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if you're interested in that step by the post so we can show you a small video with a robot that is really using the algorithm in a very nice demonstration, thanks.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm so the Norwegian are Seaman from UT Austin and this is joint work with Ashish Kapoor at MSR Redmond on visual recognition and detection and are bounded computational.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Current approaches for recognition and detection ignore computational constraints during recognition, and therefore they need to be run to completion in order to provide a useful answer in our.",
                    "label": 1
                },
                {
                    "sent": "In this paper work we explore an approach that reasons about available computational resources and try ages appropriate actions to take so that the best possible result can be obtained under time constraints.",
                    "label": 0
                },
                {
                    "sent": "In particular, our detection approach actively determines both the best location and also the best feature type to extract, given the computational cost of the features.",
                    "label": 1
                },
                {
                    "sent": "We do this by calculating the value of information of all image locations using our normal grid based model and choose a feature and update our model iteratively.",
                    "label": 0
                },
                {
                    "sent": "By doing this, our approach can target informative image locations as seen on the figure on the right in comparison to current methods, which are passive.",
                    "label": 0
                },
                {
                    "sent": "On 2 popular detection datasets, we show that our approach exhibits better anytime behavior than passive approaches.",
                    "label": 0
                },
                {
                    "sent": "In other words, it can be stopped at anytime to provide the best possible result or the best possible detection result.",
                    "label": 0
                },
                {
                    "sent": "If you are interested, interested in active detection, or if you want to know how to pronounce my last name, please visit our poster.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Timothy Cord from inria.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my colleagues on Talking Pictures.",
                    "label": 0
                },
                {
                    "sent": "There's.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Love recent interests in automatically tagging people in videos.",
                    "label": 0
                },
                {
                    "sent": "In current work, there is no need for extraneous supervision.",
                    "label": 0
                },
                {
                    "sent": "For example, using a screenplay as in our previous CPR work.",
                    "label": 0
                },
                {
                    "sent": "This dependence quickly, however, really limits the applicability of those methods.",
                    "label": 0
                },
                {
                    "sent": "In our work, we present the first fully automatic system for automatically tagging people in videos.",
                    "label": 0
                },
                {
                    "sent": "In this work, their only source of supervision is naturally occurring dialogue cues such as hay Jack, indicating that Jack is somewhere in the scene, whereas Jack left would indicate the opposite.",
                    "label": 0
                },
                {
                    "sent": "We integrate those dialogue cues using novel convex formulation for multiple instance learning and we further improve our results using grouping constraints and general constraints.",
                    "label": 0
                },
                {
                    "sent": "To this end, we propose a novel model for integrating non non just beyond pairwise grouping cues and it has both tractable inference and tractable learning.",
                    "label": 1
                },
                {
                    "sent": "We further show excellent performance on automatically naming people in the white diversity of TV shows and TV series with the state of the art performance for both grouping and naming.",
                    "label": 1
                },
                {
                    "sent": "So please come to our poster.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi my name is Christopher Lambert from the new Institute for Science and Technology Nir in Vienna.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The work that I'm presenting is on the acceleration of object detection cascades, so most of you will be familiar with object detection cascades from the Viola Jones face detector, for example, so detection cascade works by classifying many regions in an image, whether they contain an object or not.",
                    "label": 0
                },
                {
                    "sent": "By evaluating multiple classification functions and for positive detection or the individual classifier stages must have a positive response and you can see in a toy example here.",
                    "label": 0
                },
                {
                    "sent": "Have a cascade of two stages.",
                    "label": 0
                },
                {
                    "sent": "So it's a good idea to use such a cascade for two reasons.",
                    "label": 1
                },
                {
                    "sent": "One of them is that if you have multiple easy classifiers, you can learn a better decision than with just one simple classifier.",
                    "label": 0
                },
                {
                    "sent": "But the main reason is that it's faster to use it at Cascade because you have early stopping if one of the stages says this is not an object, you can immediately stop and you don't have to go to the later stages.",
                    "label": 0
                },
                {
                    "sent": "But this is smart in the early stopping way in the Cascade stages, but it's still an exhaustive search if you go.",
                    "label": 1
                },
                {
                    "sent": "Sliding window over all possibilities in the in the image, so the contents of my work is to make the system also smart in this search within each stage and do a divide and conquer procedure that works by not evaluating each position in the image separately and deciding to accept auto reject.",
                    "label": 0
                },
                {
                    "sent": "But to decide for whole sets of region at a time and thereby speed up the cascade.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is Steven Wagon.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with nicotine Maya connections and burn Sheila.",
                    "label": 0
                },
                {
                    "sent": "So our works on pedestrian detection.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we're introducing a new feature called Color Self Similarity or CSS that is complimentary to Hawken.",
                    "label": 1
                },
                {
                    "sent": "Histograms are flow and leads to a significant improvement of performance on the category and data set on in real person and onto the process.",
                    "label": 1
                },
                {
                    "sent": "So what this feature does is it is computes similarity coefficients between colors across different regions of the classification window.",
                    "label": 0
                },
                {
                    "sent": "So the classification can learn something about color without running into problems because of.",
                    "label": 0
                },
                {
                    "sent": "Different cameras or different lighting or the variability in clothing.",
                    "label": 0
                },
                {
                    "sent": "And we're also looking at some issues that can prevent repeatability.",
                    "label": 1
                },
                {
                    "sent": "For example, the evaluation protocol.",
                    "label": 0
                },
                {
                    "sent": "So if you just state that you're using the Pascal criterium to evaluate if it detects matches or not, this is not enough.",
                    "label": 0
                },
                {
                    "sent": "So yes, the room for interpretation, especially if you have a late on only subbranch of pedestrians, like only pedestrians off this height or unusual pedestrians.",
                    "label": 0
                },
                {
                    "sent": "A similar issue occurs for training where the particles of an unspecified to unstable.",
                    "label": 0
                },
                {
                    "sent": "And on the example of SVM bootstrapping, we show that some popular choices can lead to on repeat and repeat the presents.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Michael Jamison.",
                    "label": 0
                },
                {
                    "sent": "I am from the Robotics Institute in Barcelona and here in this work we address the detection of object.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That may appear on the rotation in the image plane.",
                    "label": 0
                },
                {
                    "sent": "Our contribution is to use boosting random furs in combination with the couple approach in order to have a simple but efficient detection methods.",
                    "label": 0
                },
                {
                    "sent": "Randall and firms are local random binary feature that are used for classification.",
                    "label": 0
                },
                {
                    "sent": "And but in this case, our binary feature or random fares are computed over local histogram of oriented gradients.",
                    "label": 0
                },
                {
                    "sent": "By the other hand, our D couple approach consisting of an orientation step an on object classification step allows to reduce the computational cost of evaluating this object classifier for different orientation.",
                    "label": 0
                },
                {
                    "sent": "So in this way the orientation estimator is evaluated over the input images to Jill potential.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis dannard invalidated, but rotating and classy.",
                    "label": 0
                },
                {
                    "sent": "Anne Anne testing the Object Classifier both estimator and the classifier are computed using a boosting algorithm with the end of finding the most discriminative and robust feature for larger classification.",
                    "label": 0
                },
                {
                    "sent": "These methods have been validated for standard and new data sets, showing remarkable results.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Afternoon in the middle level from the Computer Vision Center in Barcelona, an in over poster.",
                    "label": 0
                },
                {
                    "sent": "We are going to show you our segmentation method which is able to process.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Several images per second, which is based on back of features.",
                    "label": 0
                },
                {
                    "sent": "We use the back of features to a single pixel level category to every picture of the image, so we need it to work as fast as possible.",
                    "label": 0
                },
                {
                    "sent": "Therefore we use tensor features to extract information from the image.",
                    "label": 0
                },
                {
                    "sent": "An super linear complexity classifiers to contest them into visual words.",
                    "label": 0
                },
                {
                    "sent": "I'm with this with our words.",
                    "label": 0
                },
                {
                    "sent": "We can create an integral image with the weights of the linear classifier, which it allows us to calculate the classification score of any rectangular region of the image in Constantine, independently of the region of or the codebook size.",
                    "label": 0
                },
                {
                    "sent": "We use this method.",
                    "label": 0
                },
                {
                    "sent": "Combine it with a mid shift imitation method to obtain the final segmentation.",
                    "label": 1
                },
                {
                    "sent": "We have evaluated this method with the Pascal challenge or the red segmentation data set, obtained similar results to their state of their methods, but with a much lower computational cost.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention and if you have any questions concerning poster like.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Sasha McKay from the University College of London and this is joint work with my advisor, gave Robusto and my qualifies so given sequence of images in a set of algae.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Items, which ones should you use to perform feature matching or to compute optical flow?",
                    "label": 1
                },
                {
                    "sent": "You could just look at the performance evaluation table and pick the single best performing algorithm, but it's not clear if that will generalize well for your sequence.",
                    "label": 0
                },
                {
                    "sent": "Take the example of computing optical flow in the image in the top price, where Algorithme does best overall indicated by more areas of white in the less areas, avoiding the endpoint error image.",
                    "label": 1
                },
                {
                    "sent": "It doesn't do the best in every single location, so if you look at the circular region to the right of the teddy bear, algorithm B does better we propose that the single best algorithm for each location can be predicted to the supervised training of a classifier.",
                    "label": 0
                },
                {
                    "sent": "So come to your poster and will show you results for both feature matching experience and experiments and optical flow and will also show you how we can compute realistic looking correspondence data for training purposes.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm Leo coming from MRG.",
                    "label": 0
                },
                {
                    "sent": "It's a joint work with Chen Yuan Freeman.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, we starting object detection problem.",
                    "label": 1
                },
                {
                    "sent": "Basically in this work we try to ask what a good structures represent object in this work.",
                    "label": 0
                },
                {
                    "sent": "Particularly we propose a very simple hierarchical structure so you can see in left figure.",
                    "label": 0
                },
                {
                    "sent": "Here we propose a three layer.",
                    "label": 0
                },
                {
                    "sent": "Regular great structure to represent object and object paths in three layers, so we will show that this very simple three layer structure is able to achieve state of the art performance on Pascal data set.",
                    "label": 0
                },
                {
                    "sent": "So we also show that three layer structure is better than two layer structure.",
                    "label": 1
                },
                {
                    "sent": "So the learning of this model can be formulated.",
                    "label": 0
                },
                {
                    "sent": "As a latent structure as well, problem in this case learning can be solved by concave and convex procedure which guaranteed to find the local optimal.",
                    "label": 0
                },
                {
                    "sent": "So we will show that the details of the hierarchical learning in our post.",
                    "label": 0
                },
                {
                    "sent": "Thanks for attention.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A Steiner tree approach to efficient object detection.",
                    "label": 1
                },
                {
                    "sent": "I'm agora sakowski.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with and ring from Stanford.",
                    "label": 0
                },
                {
                    "sent": "So the goal of our work is to efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detect multiple object classes within a scene.",
                    "label": 1
                },
                {
                    "sent": "So for example, you know trash bins and ski boots, coffee mugs, whatever have you.",
                    "label": 0
                },
                {
                    "sent": "So the standard approach is to run sliding windows once per object class, which is extremely inefficient.",
                    "label": 0
                },
                {
                    "sent": "We developed an object detection pipeline that avoids using sliding windows by instead using unsupervised segmentation to propose candidate regions that are likely to contain objects.",
                    "label": 0
                },
                {
                    "sent": "However, different segmentations are needed for different types of objects.",
                    "label": 0
                },
                {
                    "sent": "Overall, we present a pipeline that consists of five steps for proposing these regions, and each step is controlled by parameter that needs to be tuned individually for each object class.",
                    "label": 0
                },
                {
                    "sent": "And at the core of our approach is the observation that actually we can reuse parts of this pipeline for between the different object classes, thus amortizing the cost of proposing these regions.",
                    "label": 1
                },
                {
                    "sent": "To do this, we develop a Steiner tree optimization framework that allows for efficient sharing of the parameters of the pipeline, thus further speeding up object detection an.",
                    "label": 0
                },
                {
                    "sent": "In practice, our method obtains about a 10 to 15 times speedup compared to sliding windows approach when detecting multiple object classes within cluttered scenes.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Scott Dollar.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Peter Welander and Pietro Perona.",
                    "label": 1
                },
                {
                    "sent": "Three Peter paper.",
                    "label": 0
                },
                {
                    "sent": "So what work?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On here is a lot of the previous spotlights and talks you've seen or about object detection.",
                    "label": 0
                },
                {
                    "sent": "Finding objects in the 1st place where we're interested in is given that you've actually found the object estimating its pose.",
                    "label": 0
                },
                {
                    "sent": "So what it's what's outlined is or what not.",
                    "label": 0
                },
                {
                    "sent": "And this could be formulated as a structured output prediction problem or a regression problem.",
                    "label": 0
                },
                {
                    "sent": "The difference here is though, that it's not just an arbitrary output, it's actually an output that suppose an observation we make is that based on an estimate of the pose we can actually query new features from the image based on our current estimate of the pose, and so the idea is we can come up with a very nice principle algorithm to exploit this, where as we refine our estimate of the pose we can actually get new features and we use random Fern features which are very fast.",
                    "label": 0
                },
                {
                    "sent": "And so we can prove some nice things about this algorithm, but maybe the best proof is that it actually works quite well that a lot of the times that actually matches or outperforms human performance.",
                    "label": 0
                },
                {
                    "sent": "Peter and I both will work both Peters, but Peter and I both labels some images and we trained algorithm using Peters annotations and then compared to my annotations and actually the algorithm is better than me.",
                    "label": 0
                },
                {
                    "sent": "So it actually works quite well.",
                    "label": 0
                },
                {
                    "sent": "But I'll give you the details if you come to my poster, thank you.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Junk images young.",
                    "label": 0
                },
                {
                    "sent": "I'm from the University of South Carolina.",
                    "label": 0
                },
                {
                    "sent": "The title of.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our paper is free shapes of windows.",
                    "label": 0
                },
                {
                    "sent": "Search for object localization.",
                    "label": 0
                },
                {
                    "sent": "As we know, backup your words along with the server.",
                    "label": 0
                },
                {
                    "sent": "Windows Search method is widely used in the object localization method.",
                    "label": 0
                },
                {
                    "sent": "As shown.",
                    "label": 0
                },
                {
                    "sent": "I've shown in this figures blue points represent negative features and red points represent positive features.",
                    "label": 0
                },
                {
                    "sent": "With your lender, by using bag of bag of your words.",
                    "label": 0
                },
                {
                    "sent": "Rectangular subwindow are commonly used because of their simplicity and high efficiency.",
                    "label": 0
                },
                {
                    "sent": "But however, for non convex objects and objects that are very close to each other rectangle, often no rectangular subwindow can cover the object of interest tightly.",
                    "label": 0
                },
                {
                    "sent": "In order to address this problem, we propose a new approach by searching for an age.",
                    "label": 0
                },
                {
                    "sent": "An Angel and octane are super windows without pre specifying each is shape as shown in the figures.",
                    "label": 0
                },
                {
                    "sent": "Our friendship subwindow can't.",
                    "label": 0
                },
                {
                    "sent": "Covers object tightly.",
                    "label": 0
                },
                {
                    "sent": "We tested our method on will see 2006 and will say 2007 and we achieve better performance than the state of the art object localization method.",
                    "label": 0
                },
                {
                    "sent": "Do you do you want to know more about our research?",
                    "label": 0
                },
                {
                    "sent": "Please come to our poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm your souped up.",
                    "label": 0
                },
                {
                    "sent": "It's from Inga Inga, inria, Grenoble.",
                    "label": 0
                },
                {
                    "sent": "Imagine that you want to search on net for the images of for example.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Power what current search engines give you is pretty noisy, can be pretty noisy because they rely only a textual metadata and ignore completely visual content of the image.",
                    "label": 1
                },
                {
                    "sent": "What we could do is take this images and try to re rank them using including visual information.",
                    "label": 0
                },
                {
                    "sent": "Now how people have been doing this so far is take the top ranked images from search engine, train a classifier and using the classifier scores to rank the images.",
                    "label": 0
                },
                {
                    "sent": "What the problem with this approach is is that.",
                    "label": 0
                },
                {
                    "sent": "It you need to train a classifier for for every query, so it doesn't really scale up to a real world scenario where you want to be able to quickly answer to any user query.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we define the query relative features which were.",
                    "label": 0
                },
                {
                    "sent": "The data representation doesn't doesn't depend only on visual and textual content, but also depends on the query.",
                    "label": 1
                },
                {
                    "sent": "This allows us to train query relative classifier which train only once and tests on any.",
                    "label": 0
                },
                {
                    "sent": "Possible imaginable query?",
                    "label": 0
                },
                {
                    "sent": "Or we obtain significant improvement over the search engines ranking even for difficult queries.",
                    "label": 0
                },
                {
                    "sent": "We have also shining new datasets, big annotated that we tend to release to be used for these kinds of problems.",
                    "label": 0
                },
                {
                    "sent": "Thank you and please come see us at the poster a 25 I think.",
                    "label": 0
                }
            ]
        }
    }
}