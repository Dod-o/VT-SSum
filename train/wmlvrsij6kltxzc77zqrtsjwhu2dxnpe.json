{
    "id": "wmlvrsij6kltxzc77zqrtsjwhu2dxnpe",
    "title": "Probabilistic Inference for Graph Classification",
    "info": {
        "author": [
            "Koji Tsuda, Max Planck Institute for Biological Cybernetics, Max Planck Institute"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->Structured Data"
        ]
    },
    "url": "http://videolectures.net/pmsb06_tsuda_pigc/",
    "segmentation": [
        [
            "I would I would like to go to the straight to the point and.",
            "Ask the first invited Speaker or Judah.",
            "Through the stage.",
            "Paris.",
            "So gorgeous.",
            "Um?",
            "He works at the National Institute for Advanced.",
            "Industrial science and technology.",
            "Japan.",
            "In a competition of Biologic Research Center.",
            "He has is not step.",
            "He have quite long time in MPI Tuebingen in the group of Professor Shelkoff.",
            "Working with the kernels.",
            "Computational biology ambrozic models many shells and we are very happy to quickly to open the website so slow.",
            "Um yeah, OK.",
            "So should I use this one?",
            "Your voice yeah OK?",
            "Yeah, so so.",
            "So my name is Cody Suda and first of all I'd like to thank you organizers to invite me here and give me opportunity to give a talk and confusing enough.",
            "Now I'm back in Tubingen so affiliation is our gain again.",
            "This Max Planck Institute for Biological Cybernetics.",
            "Under so is there any?",
            "Pointers.",
            "OK. Yeah, but he doesn't.",
            "Yeah.",
            "I don't know.",
            "Yeah, OK, today I direct you talk, you talk about graph classification problems.",
            "So now the title is a bit changes from announced.",
            "But I also have probabilistic inference part in the end."
        ],
        [
            "OK, so in this talk I talk about graph classification and stuff.",
            "And this is the motivation for graph analysis.",
            "So.",
            "Existing machine learning methods are students, basically tables, so the data assumed to be represented as a table.",
            "Read this for example.",
            "This is terrible for for some people's data, but as you know.",
            "As you know, by also data not always like this.",
            "So it doesn't like this, so you have some sequences or so.",
            "This is Barbara Scott Networks and this is protein 3D structures.",
            "So or a hard very complicated structure.",
            "So we need new missiles for analysis."
        ],
        [
            "And when you look at Doctor Graph data is like this, so you have to crash trying to classify them into three categories for example.",
            "And then you basically puzzled, right?",
            "So it's 3D.",
            "Difficult to get intuition from from those graphs.",
            "And in fact one roll.",
            "Is 1 graph this we so we have to classify.",
            "Ichiro's across but.",
            "Yeah, but how to do this?"
        ],
        [
            "Get on in in biology you have many graph structures, of course, and.",
            "Denisi case, it's just.",
            "Our basic idea so you can solve for Alpha bit but but on top of that you can define some alternatives, pricing structure and so on.",
            "So so in the end you get kind of graph.",
            "So, RNAs also nice example for graph representation and.",
            "In chemistry they use graph structure like this actually, and there are many papers about.",
            "Classifying compounds using graphs.",
            "And also you can think of texts in the future."
        ],
        [
            "OK, this is overview of my talk.",
            "So basically in machine learning or statistics or any data science field.",
            "So representation is the key point.",
            "So basically how to present a graph as a vector of features?",
            "So.",
            "I think there are two.",
            "To construct I mean two different ways of the presentation.",
            "And to begin with, I explained possibly presentation.",
            "So cold and I explain a bit about graph corners based on this path representation, and especially I focus on the at least about advantages now cause.",
            "I mean sometimes I experienced at this graph Connors doesn't work and.",
            "And I'm wondering why it doesn't work with him.",
            "And recently I started to use this substructure representation.",
            "Yeah, which explain later and to use this substructure representation, you need to use this graph mining which I was experiencing.",
            "And finally I. I come to therapeutic inference part, so I present a method of EMH based graph clustering."
        ],
        [
            "Yeah."
        ],
        [
            "OK, so now I directly introduce one method for classifying graphs.",
            "So basically the the purpose here is to define similarity measure between two graphs.",
            "So the question is OK, so you have two graphs G&G prime and then you like to have some similarity.",
            "Body between two graphs.",
            "And.",
            "And this similarity function is called accounting function and this can be used in conjunction with supportive care machines, PCs and so on for many.",
            "Data processing purposes.",
            "And yeah, so basically this method is called marginalized graph corners in there.",
            "And it's first presented by customer and Mia.",
            "In 2003 um.",
            "So I assume that both vertex and edges are labeled.",
            "So for example.",
            "Yeah, for example those bodies have AC-80 labels and ages have lower cases.",
            "They live.",
            "And and I assume this directed graph structure."
        ],
        [
            "OK. And basically the feature I use here is labor path.",
            "Um?",
            "It's a sequence of birthdays and its readers.",
            "So consider the walk on the graph like this.",
            "So basically you have you start from here and go here, here, here, here then.",
            "If you recall the labels you saw in this work, then you get this kind of sequence H. Right and and I consider random working on this graph using uniform initial transition time in our probabilities so I don't get into details, but there's.",
            "Fixed probability.",
            "From going here from here to here, here to here and so on.",
            "And you have also termination probabilities that you can quit.",
            "For example from North."
        ],
        [
            "OK, so after you have done random looking like a million times then you get this kind of pass probability vector.",
            "Out of one graph.",
            "So.",
            "So this is the probability.",
            "Of this River path happening by a random walking.",
            "And basically if.",
            "I mean, as the length of Labor passcodes.",
            "Goes up, then the probability goes down and you always have have the sum 1.",
            "Here in this vector."
        ],
        [
            "And the definition of Connor.",
            "So Connor here means.",
            "Similarity, but but the definition is like this.",
            "So once you.",
            "So first of all I define Connor for parties, H&H Prime, so they are taken from from from different graphs.",
            "And then if the length is different, I just put zero and then if the length happens to be the same.",
            "I just multiply all the.",
            "But it's an age columns.",
            "So for example, I compare.",
            "Say these sequences 8 on this sequence is H prime.",
            "Then I compare each label and I multiply the similarity of those labels.",
            "I mean for all symbols and then you get the content for each path.",
            "But but basically what we want to compare is a graph, not a path, so we for taking the similarity of graphs we take expectation of our possible passes and the probability of.",
            "Passes are determined by by random looking.",
            "So.",
            "So finally we get to this representation of graph column.",
            "So basically it's just.",
            "Expectation over all possible passes.",
            "Um?",
            "You know, multiplied by the path content.",
            "Skype."
        ],
        [
            "Under and basically doing random working.",
            "You know many times it's very time consuming, so I have alternative way of computing the analytically.",
            "So say computation goes like this so.",
            "Suppose this is V. Of X represents a set of passes ending at Nordby.",
            "And consider this kayveas account computed from the party is ending at.",
            "B&B prime so.",
            "So these two graphs I have.",
            "And suppose you get it right.",
            "Suppose you know it this KB or B&B prime.",
            "And.",
            "Then you go one step back then.",
            "You see that this cavey.",
            "Has this relationship, so here this KB or B prime and B prime, you know B&B prime.",
            "Is.",
            "Is a condom computed from the process ending at the neighbor of B&B Prime?",
            "So if this is P and this is the primes and the neighbor is like this?",
            "So.",
            "When you get this kind of relationships, then you find that.",
            "This is the linear equation.",
            "In this body of right?",
            "So basically this happens here, KB happened here and here, and there is a linear relationship, right?",
            "So this corner KB can be computed by solving linear equations, it's polynomial time.",
            "And the overall graph corner is just a sum over or possible B&B Prime.",
            "Yep, that's good."
        ],
        [
            "Under on the recently, especially in last year.",
            "So I saw several good approximate an approved applications of this graph corner.",
            "For example.",
            "Application to Crestline chemical compounds was done by my avatar so.",
            "The in game music sternal in SMB 2005.",
            "I saw this application to put in 3D structures that was very nice paper and you also have application to our any graphs and.",
            "So Interestingly, you also have something like pedestrian detection from the image where where you have each person is presented as a graph.",
            "And or signal processing applications."
        ],
        [
            "Fuck.",
            "So, so this was Sammy Sosa.",
            "Nice point, fast.",
            "The next point of this marginalized Connor is that you have polynomial time computation and it's really easy to implement because.",
            "Because you what you need is to solve linear equations so you can do this in Matara very quickly, so implementation is.",
            "I mean not extremely easy, but you can.",
            "You can give you give a paper to your student and then maybe he will make it in a week.",
            "He's good.",
            "And then at that point is that it supposed to be in color?",
            "So you can combine with?",
            "Manikanda missiles alright?",
            "But"
        ],
        [
            "But but they also Dropbox.",
            "I experienced the.",
            "The.",
            "One point that we have to care about is that this is a global similarity measure.",
            "The global means.",
            "Basically I'm taking all the features into account, taking chromatographs, right?",
            "So in the end I, I'm really considering all possible passes, so that sounds great, but but then you have to work on a very high dimensional feature space like I don't know medium or whatever.",
            "So, so it tends to help him.",
            "It takes to pay to capture Subs or differences.",
            "So if you have a graph somehow close to each other and then.",
            "Say the Connor body would be like 0.99 and then.",
            "Then she would take another long drive, 0.991 but it's not so big difference and the hope is that.",
            "Support vector machines can take can detect such a.",
            "A difference but.",
            "It's not successful every time.",
            "And then as I as I showed, so the short passes Harbridge rate, right?",
            "So it means that you are looking at only low car.",
            "Statistiques over graph, right so.",
            "This way, if.",
            "If it is crucial to look at long passes, then I mean it's not likely to work.",
            "And also another point is that the results not interpretable.",
            "So this is a program of Alcon missiles physically so becausw.",
            "All data is represented as pairwise similarities, so it's not easy to interpret the result.",
            "Yeah, OK and.",
            "And the software features even words for some fruit loops.",
            "People because we are simply using process only.",
            "So from passes you don't know whether it comes from a loop or not, for example.",
            "And.",
            "And it also depends really on.",
            "Raiders you about ticks and age rivers and suppose you have no labels at all, just graphs with frame frame, batiks and praying edges.",
            "Then everything matches everything.",
            "So so in the end your corner is always one.",
            "So of course you cannot cross fly.",
            "Anything short?"
        ],
        [
            "So OK, so now recently I'm working on this type of structure representation on graph mining."
        ],
        [
            "OK, so substructure representation is more advanced.",
            "One more advanced sound path.",
            "So visually when you have this kind of graph, you consider this 31 binary vector or pattern indicators.",
            "So.",
            "In the in the technical term of graph mining they call small graphs as patterns, so they're part of.",
            "And they are my features also.",
            "And if you have.",
            "If you find this pattern in this graph, then you put one here and the same and you have.",
            "You do this for or possible patterns.",
            "And of course, as you can imagine, this feature vector has huge dimensionality, so that's exponential to the.",
            "Size of.",
            "Python graph and.",
            "And I don't know exactly.",
            "How many dimensionality it has?",
            "So it's so for graph classification in general.",
            "It's so crucial to feature selection, so usually feature selection is.",
            "Is kind of a luxury thing, so it doesn't really.",
            "So for example, for many data sets of moderates, dimensionality doesn't really matter.",
            "So you can.",
            "You can do feature selection, but even if you don't do feature selection, it works where.",
            "You know, for example, in support vector machines case.",
            "But for graph unity needed.",
            "And the problem here is that our features are structured.",
            "For example our features or patterns here, and this one is a subgraph of this one, right?",
            "So we have this kind of subgraphs, bug relationship in the features.",
            "So we need some special algorithm for serving."
        ],
        [
            "Look at this graph mining so.",
            "So it's a strange world but but it's called mining because it's a subfield of data mining and in the conferences like KDD, ICBM, PKD, there are not so many.",
            "But several graph mining papers.",
            "But I think it's not popular in icy maroa nips and maybe in this audience too.",
            "The purpose of graph mining Misty analysis of graph databases, of course.",
            "On the.",
            "And the the main program is so called frequent substructure mining I explained in the next right so?",
            "It is a very combinatorial algorithm.",
            "And the worst case performance is often in Bihar.",
            "And this is a recently developed, so as far as I know.",
            "This algorithm, called AGM, is the first one, so it's presented by energy in PKD 2000 and then it despond, which is really a nice algorithm comes.",
            "In 2002 and recently.",
            "Gostlin customs from Sweden I think."
        ],
        [
            "So what they do?",
            "So they are mostly doing frequent substructural mining so.",
            "The problem is to enumerate or patterns occurs in at least in graphs.",
            "So say you have NN graphs and then you want to make a list of patterns which appears.",
            "Imo's are in graphs, right?",
            "So you would easily find all of them right, no approximation.",
            "Nor compromise so.",
            "So I wrote this down here.",
            "It's Rick as a set of patterns K which which appears in more than him graphs.",
            "So I I right here XIK as the indicator of Patton K in graphi.",
            "Right and.",
            "And it's their time in Alaji, but.",
            "They called the number of occurrences over pattern K at support of K so.",
            "Wherever I see support, it's the number of occurrences."
        ],
        [
            "OK, so it's very abstract right of explaining graph mining's idea.",
            "So first of all you have a database of graphs.",
            "Here you have only two, but of course you have.",
            "I don't follow them, so graphs and the.",
            "OK under for example, maybe the program is to find all subgraphs, happenings happening, at least one graph here.",
            "Then what they do is to what we do is to start from small one.",
            "So actually the root node has.",
            "Nothing at all and.",
            "The moon in the first reader has a has only one node and.",
            "And visually starting from the root node, we generate patterns, this such that the child is a super graph of of this character.",
            "So when you look at the child it always contains appearance.",
            "And.",
            "And the way when you go one step down, you add 18.",
            "So sometimes you would you add the extra node, right?",
            "But sometimes not but.",
            "But again, you, as long as you're here.",
            "And and in this way you you grow these three.",
            "Is such that you can find everything you want."
        ],
        [
            "But but if you really grow these three until the end, then you need a time right here or something.",
            "So.",
            "So what is crucial is 3 pruning.",
            "I.",
            "Under the support function.",
            "Five nights property called antimonious P. So I don't know why they call it anti monotonicity because it's just the monotonicity.",
            "But maybe maybe there is a word I don't know, but they called antimony see and.",
            "This very easy prime is a super graph of C. Then the support of Z is always greater than the support of the prime, right?",
            "'cause it's obviously.",
            "The other thing.",
            "Yeah OK so.",
            "So for example if you are looking for the graph happening more M times, then if you find in the trees that support of Z is less than M then you can stop right cause OK so here.",
            "Suppose this graph has M occurrences right then?",
            "Ony N Wall clients instead then those stuff.",
            "Must hub.",
            "Support this is not him.",
            "You cause it's a bug report.",
            "So this one is not there so we can stop generating here, right?",
            "And we can save time for generating."
        ],
        [
            "And basically in the rest of my talk I used method code spam, so this is a very efficient method for frequent substructure mining.",
            "And especially it adopts so called DFS code.",
            "Too efficient detection of isomorphic patterns on DFS means the depth first search.",
            "Um, but I don't get into details."
        ],
        [
            "Yeah, but only a bit.",
            "Yeah, maybe I don't explain this too much.",
            "But the but the crucial thing in graph mining is that, for example, when you generate your patterns, then it often happens that you generate the graph isomorphic to.",
            "To the graph you already generated, right?",
            "So so you have the two exactly the same thing.",
            "In in 1, three right then.",
            "Then you when you allow this, then then it's a big waste of time because you check the same thing again.",
            "So so you have to have a mechanism to prune this isomorphic graph Sunday.",
            "Mechanism."
        ],
        [
            "OK, and imagine running point of view.",
            "It's more interesting to search for discriminative patterns.",
            "So discriminative patterns means that.",
            "Yeah, so they are the patterns which happens in one craft but nothing does across.",
            "If you have two class program.",
            "And then.",
            "OK, so to find discriminative patterns we somehow engineer the graph mining algorithms a bit.",
            "But not not original.",
            "So we introduced away WI for each graph I.",
            "So it's not the it's posting for postcrossing negative negative cross.",
            "And I search for the pattern basically with large frequency difference in.",
            "In crosses.",
            "Um, so basically.",
            "I think so.",
            "So this basically shows the frequency difference and I look for all patterns.",
            "Such that this score is more than power.",
            "And one bad news is that this community discord is not anti monotonic.",
            "So instead I use abound of this core function such that the bound is anti monotonic and I use this bound to three today Sunday.",
            "Not this core function itself."
        ],
        [
            "Yeah.",
            "And you can think of March Cross version Hospital.",
            "So in this case.",
            "In this case, you have, say five 617 crosses.",
            "And.",
            "And for example, if graph I belongs to cross air then I. I said this way Wai.",
            "To be positive and otherwise negative so it's like thrombosis wrist support, vector machine and stuff and.",
            "And such buttons.",
            "That over different in cross country skiing across so.",
            "So you can design such a score function and.",
            "Do the same thing."
        ],
        [
            "So summary of graph mining.",
            "Is this so?",
            "It's an efficient way of searching patterns, satisfying predetermined conditions.",
            "It's NP hard actually, but but, but basically.",
            "The actual speed really depends on the data, of course, but but you tend to, you know you tend to design from the method.",
            "If you see this.",
            "But but in my experience it's not too bad and it's faster for sparse graphs of course.",
            "And if you have diverse kinds of readers, then it's also faster.",
            "Equals you can prune the tree area."
        ],
        [
            "And.",
            "And in the in our recent work appearing, I say May I use this graph mining for actually solving."
        ],
        [
            "Trusting problem.",
            "OK, so the motivation here is too too long.",
            "A mixture model in the feature space of patterns.",
            "So I shows this huge dimensionality.",
            "Maybe position orbital, but they don't want right?",
            "So I like to run McDonald in this space.",
            "So it could be simple.",
            "One simple probabilistic model, but I hope my hope is that this is a basis for more complex probabilistic inference.",
            "And my idea is to combine everyone realization, trust, graph mining.",
            "So again, what happens is that you do E7 mining instead."
        ],
        [
            "OK, so it's a bit going technical now.",
            "I hope.",
            "So, so this is my probabilistic model in itself is a very simple one.",
            "I have a mixture model.",
            "So each component is.",
            "Written like Pierre so I have C component.",
            "For secrecy and Starfire is just await parameters.",
            "And each component is just a. Binomial distribution, or about this binary vector, right?",
            "So this XK.",
            "Can be either there or one.",
            "Um, yeah.",
            "So it's not.",
            "It's not the special model."
        ],
        [
            "And OK, so let's apply the ordinary EMR Morrison and then the goal is to maximize their recruitment.",
            "For all the parameters for four 404 error and CDL.",
            "You have to optimize, alright?",
            "And user.",
            "EM algorithm you.",
            "Is it like this?",
            "So in each step you get you calculate the posterior are error.",
            "Which is the.",
            "The membership function of graph I.",
            "2.",
            "Crossed there.",
            "Right and in step you use this.",
            "Putative partition to estimate see to air.",
            "Of each component.",
            "And I have to say that both are computationally prohibitive becausw.",
            "In computing, the posterior underestimating city area have to scan overall features one.",
            "But it's impossible to scan over our feet equals it has to mean."
        ],
        [
            "So I have to introduce some technique for feature selection.",
            "And.",
            "Basically I use everyone regularizer so.",
            "Here.",
            "And when you look at this regularizer, you see that your parameter citarella K is attractive to some constants it there OK. Yeah, and.",
            "And this is not a squared loss, but this is just the absolute value between absolute difference between 2:00.",
            "Variables, so it's a it's called L1 norm.",
            "Under this regularizer is called, everybody right, so it's it's often used in feature selection.",
            "9 fields.",
            "And one tricky part is to.",
            "I mean, my question is how to set this sheet as Arrow Cave?",
            "And I said this because, OK, to be the maximum likelihood parameter estimate using single binomial distribution.",
            "So say support.",
            "So I'm considering to fit.",
            "Fit the mixer somewhere to that space, but consider you fit one buttons one binomial distribution to all graphs.",
            "Then you get this Citadel.",
            "So in order for most parameters, since they will be exactly equal to Constance because of the property of Aragon regularizer.",
            "So it's it's pasty.",
            "Introducing prior so."
        ],
        [
            "Yeah.",
            "And OK, and you can think of active the set of active patterns, so the active patterns.",
            "Define rugby.",
            "So if there exists error such that she to elkei is not equal to shooters rocaton I say this K Patton case active.",
            "So basically in an active pattern you have all the.",
            "Part of it, though, is equal to the constant.",
            "On the.",
            "And 1.2 emphasizes that the step is computed only with active patterns F. So I'm taking the.",
            "A product over, if only so so you don't need discount."
        ],
        [
            "And what about the instep?",
            "So given this putative across our assignment, R arrive, each parameter is sold separately, so I have a lot of parameters, but.",
            "But it factorizes out so I can help.",
            "I can solve each parameter separately, so it's a.",
            "It's a simple 1 dimensional program.",
            "So naive way to solve it is too.",
            "Two, I mean sorry for all parameters and identify active patterns, but but this?",
            "Is impossible because you have to solve it for all parameters.",
            "That's like exponentially as.",
            "So the idea is.",
            "To use graph mining to find active patterns.",
            "So if you know active patterns in advance.",
            "Me without actually solving this.",
            "Equation then it's OK, basically, but how?"
        ],
        [
            "So when you look at the solution of this problem, it's a bit weird cause because you have this L1 regularizer, so so you have piecewise kind of.",
            "Yeah, solution.",
            "And and it can be computed.",
            "Sorry from 2 values.",
            "So why the occurrence probability in across the entire K and the overall recurrence probability in type it there OK and what it says is that if?",
            "If the occurrence probability in a cluster is not so different from the overall occurrence probability, then you get the constant as the solution.",
            "And if it's not so gross, then you have to do the compute.",
            "Solution."
        ],
        [
            "Hey drugs please."
        ],
        [
            "And.",
            "And the crucial observation is that for active Pankey, the occurrence probability in a graph cluster is significantly different from the average, so.",
            "So this happens if and only if this happens.",
            "So basically I mean 2.",
            "I mean, so the definition of active pattern.",
            "Was this right?",
            "But you can replace this division by this propose, because this is equivalent."
        ],
        [
            "So.",
            "What happened is.",
            "That you have this little bucket button here.",
            "But now it's equivalent.",
            "Ready to ask this because of the error and regularizer and stuff and.",
            "And yeah, maybe you forgot to put these notations, but but the crucial thing is that it is different in terms of frequency only, not Sita.",
            "So now now we are looking at the frequencies.",
            "So so we can found these active button F by graph mining.",
            "So I I.",
            "A day.",
            "Yeah.",
            "This."
        ],
        [
            "Yeah, so I don't know if you can pull this, but but basically the the point is that I could do actually the map estimation of parameters without any approximation.",
            "Because I didn't approximate it at all, just.",
            "I use it every one regularizer and then yeah.",
            "Then it comes as a natural consequence of.",
            "OK, so I show a small experiment.",
            "So these are about our any graphs.",
            "And.",
            "As you know RNA, you know it's folded like a shape like this, so it says it is T RNA.",
            "And I use Steam so this.",
            "I don't know this.",
            "You can solve hybridized pairs.",
            "As an old.",
            "And if it's 100 group red and if it doesn't have a self group, is blue.",
            "And if it is adjusting in this structure, then I make up.",
            "So I have to know the secondary structure of RNAs in advance, but but not always know.",
            "So I predict it then buy the software called RNA port.",
            "Yeah."
        ],
        [
            "And so clustering task.",
            "It's kind of small, but we have three or four families.",
            "So in terms EP1, SSR, RNA five and one is.",
            "Buckley under.",
            "And I I chose this because they have.",
            "They are.",
            "City laws are in a with the result of.",
            "Things with 20 steps and so.",
            "So I mean so.",
            "So my method is used as if you just one step.",
            "So.",
            "I made three by passion programs out of these three families, so I couple two families and try to classify.",
            "Without using drivers without using cross rails.",
            "So these are evaluated by underscores.",
            "Out of this course.",
            "I mean the regular the area under."
        ],
        [
            "OK, so this was actually already graphs.",
            "This is the Inter on GP one.",
            "This is SSU and this is our next.",
            "So you see that the number of nodes are quite different, for example.",
            "I mean, this one has more nodes than this one.",
            "Yeah, so you see, it's not a big deal."
        ],
        [
            "OK, so here is the arosi scores.",
            "So this is the result of marginalized graph content combined with K means.",
            "Crossing, and this is the result for so called spectral distance, which completes compares the Laplacian matrices of two graphs.",
            "And.",
            "Yeah, basically this pic was not very good except for this easy case.",
            "On the margins requires worked somewhere for this task and this task, but.",
            "But for this task, for the most difficult one.",
            "This performed very badly.",
            "It's auto score 3.5 so it's random.",
            "It's not.",
            "It's not better than random.",
            "Peoples Random comes to 0.5.",
            "And So what I would like to say that our method marked.",
            "They're going to 945 here because I'm using substructure information.",
            "So as you see.",
            "I just said those graphs do not have meaningful labels, so the labels are just.",
            "Very long so.",
            "This kind of thing.",
            "Modernize both corners performs very poor.",
            "I mean, except for the case that you have some clear cut."
        ],
        [
            "And look at this is the time.",
            "Consumed by our method of sorry I didn't say, but this is a regularization parameter.",
            "Realisation strings.",
            "So when you.",
            "Increase the regularization strings.",
            "Then you get less patterns.",
            "But basically we hub you have like thousands of patterns overall.",
            "On the.",
            "The time needed was like one minute 2 minutes for these datasets and.",
            "For example, this contains 100 graphs, so I think it's not.",
            "But I mean it's kind of still put it up for me to wait for a minute, but it's a. I mean, but it may not be.",
            "So I cannot really say that how, how it is scalable to do more data, because it really depends on the data and depends on the labels and how you can prove it, but but at least in this moderate case, and I can do it."
        ],
        [
            "You want me?",
            "And the nice point about the messages that we actually found patterns and and I actually.",
            "Had thousands of buttons, but I fixed it 8.",
            "Most of this community ones.",
            "On the Odyssey.",
            "The feature is not trivial, right?",
            "So you have.",
            "So this one was the most.",
            "Pretty people the most discriminating, but you have 123456789 nodes, so such kind of features.",
            "Nearby capture he goes.",
            "It looks at short partners."
        ],
        [
            "OK, now conclusion so.",
            "Um, yeah, my messages that the substructure representation is big doesn't party, and probabilistic inference here if I got mine and.",
            "And this work.",
            "I did clustering but there are many possible extensions, naive Bayes, graph, PCA, Fisher discriminant analysis, CCA services provide training and so on so forth.",
            "So I didn't really say about applications.",
            "Embarrassing things should follow interviews."
        ],
        [
            "Yeah, so one ongoing work is to operate these two image classification.",
            "So yeah, so I don't describe in details but you.",
            "Be present.",
            "Image of the graphene.",
            "Yeah, then you can find such a.",
            "But come on.",
            "Yeah, so thank you.",
            "Thank you, please interesting.",
            "Question.",
            "This modified PM.",
            "You have your graph mining stuff, so my question is, is there a formal convergence guarantee of EM?",
            "So Are you sure that you in every step increase the likelihood until you get a local optimum?",
            "Because you have this this feature selection step in between, so it's probably you change the underlying space.",
            "So the cause, because this is regularization comes in really in support, so I I remember you did it once you present it.",
            "Yeah, we had a similar model, but it was really difficult in that in adult formally prove that Emerald converges because you change the underlying probability space.",
            "If you do the feature selection.",
            "Really OK, so I didn't really think about it, but.",
            "But what I can say is that we're ready.",
            "So to be with you this problem I show it to you, so this prototype is trust figure right now without any approximation and under the underwriting spaces brothers, but still fine so so we don't have any in mathematical program about an infinite summation space.",
            "So I saw this OK but yeah of course.",
            "Um?",
            "But I just checked similar rules of Cinderella.",
            "So there are regular Izium algorithms out there.",
            "They really, so I said it's OK, but.",
            "Yeah.",
            "And you know, that doesn't.",
            "Some questions.",
            "Are you sending this or or slacking?",
            "This community happens.",
            "Combat score involve weights is using his classes that we think are put codes saying 1 roses on it.",
            "Seems to me that if you have a large number of classes than that score would be dominated by patterns that occur in none of the classes is better.",
            "Uh huh.",
            "Yeah, so in interscore I take Max.",
            "Yeah."
        ],
        [
            "Yeah so.",
            "So basically this is designed to capture.",
            "Capture the button you nobody presented in at least one class.",
            "So.",
            "So basically, if if the pattern is, you know.",
            "Included in the same frequency over our classes then.",
            "Then these cannot be picked up.",
            "So.",
            "If you know if you have many, in fact, if you have many crosses, then the design of this.",
            "We thought this school will be a problem, I think.",
            "And you know, so initiating you have many ways to sort of much craft programs and and you have also many possible quote for that and.",
            "Yeah, so actually this maxi he.",
            "It is somehow conservative, so it's not so aggressive, so maybe we can make more aggressive score too.",
            "To reduce the computational costs result without sacrificing security but.",
            "But in this world I I didn't really.",
            "I think about it, I just used him.",
            "This is this one.",
            "One request."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I would I would like to go to the straight to the point and.",
                    "label": 0
                },
                {
                    "sent": "Ask the first invited Speaker or Judah.",
                    "label": 0
                },
                {
                    "sent": "Through the stage.",
                    "label": 0
                },
                {
                    "sent": "Paris.",
                    "label": 0
                },
                {
                    "sent": "So gorgeous.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "He works at the National Institute for Advanced.",
                    "label": 0
                },
                {
                    "sent": "Industrial science and technology.",
                    "label": 0
                },
                {
                    "sent": "Japan.",
                    "label": 0
                },
                {
                    "sent": "In a competition of Biologic Research Center.",
                    "label": 0
                },
                {
                    "sent": "He has is not step.",
                    "label": 0
                },
                {
                    "sent": "He have quite long time in MPI Tuebingen in the group of Professor Shelkoff.",
                    "label": 0
                },
                {
                    "sent": "Working with the kernels.",
                    "label": 0
                },
                {
                    "sent": "Computational biology ambrozic models many shells and we are very happy to quickly to open the website so slow.",
                    "label": 0
                },
                {
                    "sent": "Um yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "So should I use this one?",
                    "label": 0
                },
                {
                    "sent": "Your voice yeah OK?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so.",
                    "label": 0
                },
                {
                    "sent": "So my name is Cody Suda and first of all I'd like to thank you organizers to invite me here and give me opportunity to give a talk and confusing enough.",
                    "label": 0
                },
                {
                    "sent": "Now I'm back in Tubingen so affiliation is our gain again.",
                    "label": 0
                },
                {
                    "sent": "This Max Planck Institute for Biological Cybernetics.",
                    "label": 1
                },
                {
                    "sent": "Under so is there any?",
                    "label": 0
                },
                {
                    "sent": "Pointers.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah, but he doesn't.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, today I direct you talk, you talk about graph classification problems.",
                    "label": 0
                },
                {
                    "sent": "So now the title is a bit changes from announced.",
                    "label": 0
                },
                {
                    "sent": "But I also have probabilistic inference part in the end.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in this talk I talk about graph classification and stuff.",
                    "label": 0
                },
                {
                    "sent": "And this is the motivation for graph analysis.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Existing machine learning methods are students, basically tables, so the data assumed to be represented as a table.",
                    "label": 0
                },
                {
                    "sent": "Read this for example.",
                    "label": 0
                },
                {
                    "sent": "This is terrible for for some people's data, but as you know.",
                    "label": 0
                },
                {
                    "sent": "As you know, by also data not always like this.",
                    "label": 0
                },
                {
                    "sent": "So it doesn't like this, so you have some sequences or so.",
                    "label": 0
                },
                {
                    "sent": "This is Barbara Scott Networks and this is protein 3D structures.",
                    "label": 0
                },
                {
                    "sent": "So or a hard very complicated structure.",
                    "label": 1
                },
                {
                    "sent": "So we need new missiles for analysis.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when you look at Doctor Graph data is like this, so you have to crash trying to classify them into three categories for example.",
                    "label": 0
                },
                {
                    "sent": "And then you basically puzzled, right?",
                    "label": 0
                },
                {
                    "sent": "So it's 3D.",
                    "label": 0
                },
                {
                    "sent": "Difficult to get intuition from from those graphs.",
                    "label": 0
                },
                {
                    "sent": "And in fact one roll.",
                    "label": 0
                },
                {
                    "sent": "Is 1 graph this we so we have to classify.",
                    "label": 0
                },
                {
                    "sent": "Ichiro's across but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but how to do this?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Get on in in biology you have many graph structures, of course, and.",
                    "label": 1
                },
                {
                    "sent": "Denisi case, it's just.",
                    "label": 0
                },
                {
                    "sent": "Our basic idea so you can solve for Alpha bit but but on top of that you can define some alternatives, pricing structure and so on.",
                    "label": 0
                },
                {
                    "sent": "So so in the end you get kind of graph.",
                    "label": 0
                },
                {
                    "sent": "So, RNAs also nice example for graph representation and.",
                    "label": 0
                },
                {
                    "sent": "In chemistry they use graph structure like this actually, and there are many papers about.",
                    "label": 0
                },
                {
                    "sent": "Classifying compounds using graphs.",
                    "label": 1
                },
                {
                    "sent": "And also you can think of texts in the future.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, this is overview of my talk.",
                    "label": 0
                },
                {
                    "sent": "So basically in machine learning or statistics or any data science field.",
                    "label": 0
                },
                {
                    "sent": "So representation is the key point.",
                    "label": 0
                },
                {
                    "sent": "So basically how to present a graph as a vector of features?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I think there are two.",
                    "label": 0
                },
                {
                    "sent": "To construct I mean two different ways of the presentation.",
                    "label": 0
                },
                {
                    "sent": "And to begin with, I explained possibly presentation.",
                    "label": 0
                },
                {
                    "sent": "So cold and I explain a bit about graph corners based on this path representation, and especially I focus on the at least about advantages now cause.",
                    "label": 0
                },
                {
                    "sent": "I mean sometimes I experienced at this graph Connors doesn't work and.",
                    "label": 0
                },
                {
                    "sent": "And I'm wondering why it doesn't work with him.",
                    "label": 0
                },
                {
                    "sent": "And recently I started to use this substructure representation.",
                    "label": 0
                },
                {
                    "sent": "Yeah, which explain later and to use this substructure representation, you need to use this graph mining which I was experiencing.",
                    "label": 1
                },
                {
                    "sent": "And finally I. I come to therapeutic inference part, so I present a method of EMH based graph clustering.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I directly introduce one method for classifying graphs.",
                    "label": 0
                },
                {
                    "sent": "So basically the the purpose here is to define similarity measure between two graphs.",
                    "label": 0
                },
                {
                    "sent": "So the question is OK, so you have two graphs G&G prime and then you like to have some similarity.",
                    "label": 0
                },
                {
                    "sent": "Body between two graphs.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And this similarity function is called accounting function and this can be used in conjunction with supportive care machines, PCs and so on for many.",
                    "label": 0
                },
                {
                    "sent": "Data processing purposes.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so basically this method is called marginalized graph corners in there.",
                    "label": 0
                },
                {
                    "sent": "And it's first presented by customer and Mia.",
                    "label": 0
                },
                {
                    "sent": "In 2003 um.",
                    "label": 0
                },
                {
                    "sent": "So I assume that both vertex and edges are labeled.",
                    "label": 1
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for example those bodies have AC-80 labels and ages have lower cases.",
                    "label": 0
                },
                {
                    "sent": "They live.",
                    "label": 0
                },
                {
                    "sent": "And and I assume this directed graph structure.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And basically the feature I use here is labor path.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It's a sequence of birthdays and its readers.",
                    "label": 1
                },
                {
                    "sent": "So consider the walk on the graph like this.",
                    "label": 0
                },
                {
                    "sent": "So basically you have you start from here and go here, here, here, here then.",
                    "label": 1
                },
                {
                    "sent": "If you recall the labels you saw in this work, then you get this kind of sequence H. Right and and I consider random working on this graph using uniform initial transition time in our probabilities so I don't get into details, but there's.",
                    "label": 0
                },
                {
                    "sent": "Fixed probability.",
                    "label": 0
                },
                {
                    "sent": "From going here from here to here, here to here and so on.",
                    "label": 0
                },
                {
                    "sent": "And you have also termination probabilities that you can quit.",
                    "label": 0
                },
                {
                    "sent": "For example from North.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so after you have done random looking like a million times then you get this kind of pass probability vector.",
                    "label": 0
                },
                {
                    "sent": "Out of one graph.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this is the probability.",
                    "label": 0
                },
                {
                    "sent": "Of this River path happening by a random walking.",
                    "label": 0
                },
                {
                    "sent": "And basically if.",
                    "label": 0
                },
                {
                    "sent": "I mean, as the length of Labor passcodes.",
                    "label": 0
                },
                {
                    "sent": "Goes up, then the probability goes down and you always have have the sum 1.",
                    "label": 0
                },
                {
                    "sent": "Here in this vector.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the definition of Connor.",
                    "label": 0
                },
                {
                    "sent": "So Connor here means.",
                    "label": 0
                },
                {
                    "sent": "Similarity, but but the definition is like this.",
                    "label": 0
                },
                {
                    "sent": "So once you.",
                    "label": 0
                },
                {
                    "sent": "So first of all I define Connor for parties, H&H Prime, so they are taken from from from different graphs.",
                    "label": 0
                },
                {
                    "sent": "And then if the length is different, I just put zero and then if the length happens to be the same.",
                    "label": 0
                },
                {
                    "sent": "I just multiply all the.",
                    "label": 0
                },
                {
                    "sent": "But it's an age columns.",
                    "label": 0
                },
                {
                    "sent": "So for example, I compare.",
                    "label": 0
                },
                {
                    "sent": "Say these sequences 8 on this sequence is H prime.",
                    "label": 0
                },
                {
                    "sent": "Then I compare each label and I multiply the similarity of those labels.",
                    "label": 0
                },
                {
                    "sent": "I mean for all symbols and then you get the content for each path.",
                    "label": 0
                },
                {
                    "sent": "But but basically what we want to compare is a graph, not a path, so we for taking the similarity of graphs we take expectation of our possible passes and the probability of.",
                    "label": 0
                },
                {
                    "sent": "Passes are determined by by random looking.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So finally we get to this representation of graph column.",
                    "label": 0
                },
                {
                    "sent": "So basically it's just.",
                    "label": 0
                },
                {
                    "sent": "Expectation over all possible passes.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You know, multiplied by the path content.",
                    "label": 0
                },
                {
                    "sent": "Skype.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under and basically doing random working.",
                    "label": 0
                },
                {
                    "sent": "You know many times it's very time consuming, so I have alternative way of computing the analytically.",
                    "label": 0
                },
                {
                    "sent": "So say computation goes like this so.",
                    "label": 0
                },
                {
                    "sent": "Suppose this is V. Of X represents a set of passes ending at Nordby.",
                    "label": 1
                },
                {
                    "sent": "And consider this kayveas account computed from the party is ending at.",
                    "label": 1
                },
                {
                    "sent": "B&B prime so.",
                    "label": 0
                },
                {
                    "sent": "So these two graphs I have.",
                    "label": 0
                },
                {
                    "sent": "And suppose you get it right.",
                    "label": 0
                },
                {
                    "sent": "Suppose you know it this KB or B&B prime.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Then you go one step back then.",
                    "label": 0
                },
                {
                    "sent": "You see that this cavey.",
                    "label": 0
                },
                {
                    "sent": "Has this relationship, so here this KB or B prime and B prime, you know B&B prime.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Is a condom computed from the process ending at the neighbor of B&B Prime?",
                    "label": 0
                },
                {
                    "sent": "So if this is P and this is the primes and the neighbor is like this?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "When you get this kind of relationships, then you find that.",
                    "label": 0
                },
                {
                    "sent": "This is the linear equation.",
                    "label": 0
                },
                {
                    "sent": "In this body of right?",
                    "label": 0
                },
                {
                    "sent": "So basically this happens here, KB happened here and here, and there is a linear relationship, right?",
                    "label": 0
                },
                {
                    "sent": "So this corner KB can be computed by solving linear equations, it's polynomial time.",
                    "label": 1
                },
                {
                    "sent": "And the overall graph corner is just a sum over or possible B&B Prime.",
                    "label": 0
                },
                {
                    "sent": "Yep, that's good.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under on the recently, especially in last year.",
                    "label": 0
                },
                {
                    "sent": "So I saw several good approximate an approved applications of this graph corner.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Application to Crestline chemical compounds was done by my avatar so.",
                    "label": 1
                },
                {
                    "sent": "The in game music sternal in SMB 2005.",
                    "label": 0
                },
                {
                    "sent": "I saw this application to put in 3D structures that was very nice paper and you also have application to our any graphs and.",
                    "label": 0
                },
                {
                    "sent": "So Interestingly, you also have something like pedestrian detection from the image where where you have each person is presented as a graph.",
                    "label": 0
                },
                {
                    "sent": "And or signal processing applications.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fuck.",
                    "label": 0
                },
                {
                    "sent": "So, so this was Sammy Sosa.",
                    "label": 0
                },
                {
                    "sent": "Nice point, fast.",
                    "label": 0
                },
                {
                    "sent": "The next point of this marginalized Connor is that you have polynomial time computation and it's really easy to implement because.",
                    "label": 1
                },
                {
                    "sent": "Because you what you need is to solve linear equations so you can do this in Matara very quickly, so implementation is.",
                    "label": 0
                },
                {
                    "sent": "I mean not extremely easy, but you can.",
                    "label": 0
                },
                {
                    "sent": "You can give you give a paper to your student and then maybe he will make it in a week.",
                    "label": 0
                },
                {
                    "sent": "He's good.",
                    "label": 0
                },
                {
                    "sent": "And then at that point is that it supposed to be in color?",
                    "label": 0
                },
                {
                    "sent": "So you can combine with?",
                    "label": 0
                },
                {
                    "sent": "Manikanda missiles alright?",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But but they also Dropbox.",
                    "label": 0
                },
                {
                    "sent": "I experienced the.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "One point that we have to care about is that this is a global similarity measure.",
                    "label": 1
                },
                {
                    "sent": "The global means.",
                    "label": 0
                },
                {
                    "sent": "Basically I'm taking all the features into account, taking chromatographs, right?",
                    "label": 0
                },
                {
                    "sent": "So in the end I, I'm really considering all possible passes, so that sounds great, but but then you have to work on a very high dimensional feature space like I don't know medium or whatever.",
                    "label": 0
                },
                {
                    "sent": "So, so it tends to help him.",
                    "label": 1
                },
                {
                    "sent": "It takes to pay to capture Subs or differences.",
                    "label": 0
                },
                {
                    "sent": "So if you have a graph somehow close to each other and then.",
                    "label": 0
                },
                {
                    "sent": "Say the Connor body would be like 0.99 and then.",
                    "label": 0
                },
                {
                    "sent": "Then she would take another long drive, 0.991 but it's not so big difference and the hope is that.",
                    "label": 0
                },
                {
                    "sent": "Support vector machines can take can detect such a.",
                    "label": 0
                },
                {
                    "sent": "A difference but.",
                    "label": 0
                },
                {
                    "sent": "It's not successful every time.",
                    "label": 0
                },
                {
                    "sent": "And then as I as I showed, so the short passes Harbridge rate, right?",
                    "label": 0
                },
                {
                    "sent": "So it means that you are looking at only low car.",
                    "label": 0
                },
                {
                    "sent": "Statistiques over graph, right so.",
                    "label": 0
                },
                {
                    "sent": "This way, if.",
                    "label": 0
                },
                {
                    "sent": "If it is crucial to look at long passes, then I mean it's not likely to work.",
                    "label": 0
                },
                {
                    "sent": "And also another point is that the results not interpretable.",
                    "label": 1
                },
                {
                    "sent": "So this is a program of Alcon missiles physically so becausw.",
                    "label": 0
                },
                {
                    "sent": "All data is represented as pairwise similarities, so it's not easy to interpret the result.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK and.",
                    "label": 0
                },
                {
                    "sent": "And the software features even words for some fruit loops.",
                    "label": 0
                },
                {
                    "sent": "People because we are simply using process only.",
                    "label": 0
                },
                {
                    "sent": "So from passes you don't know whether it comes from a loop or not, for example.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And it also depends really on.",
                    "label": 0
                },
                {
                    "sent": "Raiders you about ticks and age rivers and suppose you have no labels at all, just graphs with frame frame, batiks and praying edges.",
                    "label": 0
                },
                {
                    "sent": "Then everything matches everything.",
                    "label": 0
                },
                {
                    "sent": "So so in the end your corner is always one.",
                    "label": 0
                },
                {
                    "sent": "So of course you cannot cross fly.",
                    "label": 0
                },
                {
                    "sent": "Anything short?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So OK, so now recently I'm working on this type of structure representation on graph mining.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so substructure representation is more advanced.",
                    "label": 1
                },
                {
                    "sent": "One more advanced sound path.",
                    "label": 1
                },
                {
                    "sent": "So visually when you have this kind of graph, you consider this 31 binary vector or pattern indicators.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In the in the technical term of graph mining they call small graphs as patterns, so they're part of.",
                    "label": 0
                },
                {
                    "sent": "And they are my features also.",
                    "label": 0
                },
                {
                    "sent": "And if you have.",
                    "label": 0
                },
                {
                    "sent": "If you find this pattern in this graph, then you put one here and the same and you have.",
                    "label": 1
                },
                {
                    "sent": "You do this for or possible patterns.",
                    "label": 0
                },
                {
                    "sent": "And of course, as you can imagine, this feature vector has huge dimensionality, so that's exponential to the.",
                    "label": 0
                },
                {
                    "sent": "Size of.",
                    "label": 0
                },
                {
                    "sent": "Python graph and.",
                    "label": 0
                },
                {
                    "sent": "And I don't know exactly.",
                    "label": 0
                },
                {
                    "sent": "How many dimensionality it has?",
                    "label": 0
                },
                {
                    "sent": "So it's so for graph classification in general.",
                    "label": 0
                },
                {
                    "sent": "It's so crucial to feature selection, so usually feature selection is.",
                    "label": 0
                },
                {
                    "sent": "Is kind of a luxury thing, so it doesn't really.",
                    "label": 0
                },
                {
                    "sent": "So for example, for many data sets of moderates, dimensionality doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "You can do feature selection, but even if you don't do feature selection, it works where.",
                    "label": 0
                },
                {
                    "sent": "You know, for example, in support vector machines case.",
                    "label": 0
                },
                {
                    "sent": "But for graph unity needed.",
                    "label": 0
                },
                {
                    "sent": "And the problem here is that our features are structured.",
                    "label": 0
                },
                {
                    "sent": "For example our features or patterns here, and this one is a subgraph of this one, right?",
                    "label": 0
                },
                {
                    "sent": "So we have this kind of subgraphs, bug relationship in the features.",
                    "label": 0
                },
                {
                    "sent": "So we need some special algorithm for serving.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look at this graph mining so.",
                    "label": 0
                },
                {
                    "sent": "So it's a strange world but but it's called mining because it's a subfield of data mining and in the conferences like KDD, ICBM, PKD, there are not so many.",
                    "label": 0
                },
                {
                    "sent": "But several graph mining papers.",
                    "label": 0
                },
                {
                    "sent": "But I think it's not popular in icy maroa nips and maybe in this audience too.",
                    "label": 1
                },
                {
                    "sent": "The purpose of graph mining Misty analysis of graph databases, of course.",
                    "label": 1
                },
                {
                    "sent": "On the.",
                    "label": 1
                },
                {
                    "sent": "And the the main program is so called frequent substructure mining I explained in the next right so?",
                    "label": 0
                },
                {
                    "sent": "It is a very combinatorial algorithm.",
                    "label": 0
                },
                {
                    "sent": "And the worst case performance is often in Bihar.",
                    "label": 0
                },
                {
                    "sent": "And this is a recently developed, so as far as I know.",
                    "label": 0
                },
                {
                    "sent": "This algorithm, called AGM, is the first one, so it's presented by energy in PKD 2000 and then it despond, which is really a nice algorithm comes.",
                    "label": 0
                },
                {
                    "sent": "In 2002 and recently.",
                    "label": 0
                },
                {
                    "sent": "Gostlin customs from Sweden I think.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what they do?",
                    "label": 0
                },
                {
                    "sent": "So they are mostly doing frequent substructural mining so.",
                    "label": 0
                },
                {
                    "sent": "The problem is to enumerate or patterns occurs in at least in graphs.",
                    "label": 1
                },
                {
                    "sent": "So say you have NN graphs and then you want to make a list of patterns which appears.",
                    "label": 0
                },
                {
                    "sent": "Imo's are in graphs, right?",
                    "label": 0
                },
                {
                    "sent": "So you would easily find all of them right, no approximation.",
                    "label": 0
                },
                {
                    "sent": "Nor compromise so.",
                    "label": 0
                },
                {
                    "sent": "So I wrote this down here.",
                    "label": 0
                },
                {
                    "sent": "It's Rick as a set of patterns K which which appears in more than him graphs.",
                    "label": 1
                },
                {
                    "sent": "So I I right here XIK as the indicator of Patton K in graphi.",
                    "label": 0
                },
                {
                    "sent": "Right and.",
                    "label": 0
                },
                {
                    "sent": "And it's their time in Alaji, but.",
                    "label": 0
                },
                {
                    "sent": "They called the number of occurrences over pattern K at support of K so.",
                    "label": 0
                },
                {
                    "sent": "Wherever I see support, it's the number of occurrences.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's very abstract right of explaining graph mining's idea.",
                    "label": 0
                },
                {
                    "sent": "So first of all you have a database of graphs.",
                    "label": 0
                },
                {
                    "sent": "Here you have only two, but of course you have.",
                    "label": 0
                },
                {
                    "sent": "I don't follow them, so graphs and the.",
                    "label": 0
                },
                {
                    "sent": "OK under for example, maybe the program is to find all subgraphs, happenings happening, at least one graph here.",
                    "label": 0
                },
                {
                    "sent": "Then what they do is to what we do is to start from small one.",
                    "label": 0
                },
                {
                    "sent": "So actually the root node has.",
                    "label": 1
                },
                {
                    "sent": "Nothing at all and.",
                    "label": 0
                },
                {
                    "sent": "The moon in the first reader has a has only one node and.",
                    "label": 0
                },
                {
                    "sent": "And visually starting from the root node, we generate patterns, this such that the child is a super graph of of this character.",
                    "label": 0
                },
                {
                    "sent": "So when you look at the child it always contains appearance.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And the way when you go one step down, you add 18.",
                    "label": 0
                },
                {
                    "sent": "So sometimes you would you add the extra node, right?",
                    "label": 0
                },
                {
                    "sent": "But sometimes not but.",
                    "label": 0
                },
                {
                    "sent": "But again, you, as long as you're here.",
                    "label": 0
                },
                {
                    "sent": "And and in this way you you grow these three.",
                    "label": 0
                },
                {
                    "sent": "Is such that you can find everything you want.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But but if you really grow these three until the end, then you need a time right here or something.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So what is crucial is 3 pruning.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Under the support function.",
                    "label": 0
                },
                {
                    "sent": "Five nights property called antimonious P. So I don't know why they call it anti monotonicity because it's just the monotonicity.",
                    "label": 0
                },
                {
                    "sent": "But maybe maybe there is a word I don't know, but they called antimony see and.",
                    "label": 0
                },
                {
                    "sent": "This very easy prime is a super graph of C. Then the support of Z is always greater than the support of the prime, right?",
                    "label": 0
                },
                {
                    "sent": "'cause it's obviously.",
                    "label": 0
                },
                {
                    "sent": "The other thing.",
                    "label": 0
                },
                {
                    "sent": "Yeah OK so.",
                    "label": 0
                },
                {
                    "sent": "So for example if you are looking for the graph happening more M times, then if you find in the trees that support of Z is less than M then you can stop right cause OK so here.",
                    "label": 0
                },
                {
                    "sent": "Suppose this graph has M occurrences right then?",
                    "label": 0
                },
                {
                    "sent": "Ony N Wall clients instead then those stuff.",
                    "label": 0
                },
                {
                    "sent": "Must hub.",
                    "label": 0
                },
                {
                    "sent": "Support this is not him.",
                    "label": 0
                },
                {
                    "sent": "You cause it's a bug report.",
                    "label": 0
                },
                {
                    "sent": "So this one is not there so we can stop generating here, right?",
                    "label": 0
                },
                {
                    "sent": "And we can save time for generating.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And basically in the rest of my talk I used method code spam, so this is a very efficient method for frequent substructure mining.",
                    "label": 0
                },
                {
                    "sent": "And especially it adopts so called DFS code.",
                    "label": 1
                },
                {
                    "sent": "Too efficient detection of isomorphic patterns on DFS means the depth first search.",
                    "label": 1
                },
                {
                    "sent": "Um, but I don't get into details.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, but only a bit.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe I don't explain this too much.",
                    "label": 0
                },
                {
                    "sent": "But the but the crucial thing in graph mining is that, for example, when you generate your patterns, then it often happens that you generate the graph isomorphic to.",
                    "label": 0
                },
                {
                    "sent": "To the graph you already generated, right?",
                    "label": 0
                },
                {
                    "sent": "So so you have the two exactly the same thing.",
                    "label": 0
                },
                {
                    "sent": "In in 1, three right then.",
                    "label": 0
                },
                {
                    "sent": "Then you when you allow this, then then it's a big waste of time because you check the same thing again.",
                    "label": 0
                },
                {
                    "sent": "So so you have to have a mechanism to prune this isomorphic graph Sunday.",
                    "label": 0
                },
                {
                    "sent": "Mechanism.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and imagine running point of view.",
                    "label": 0
                },
                {
                    "sent": "It's more interesting to search for discriminative patterns.",
                    "label": 0
                },
                {
                    "sent": "So discriminative patterns means that.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so they are the patterns which happens in one craft but nothing does across.",
                    "label": 0
                },
                {
                    "sent": "If you have two class program.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "OK, so to find discriminative patterns we somehow engineer the graph mining algorithms a bit.",
                    "label": 0
                },
                {
                    "sent": "But not not original.",
                    "label": 0
                },
                {
                    "sent": "So we introduced away WI for each graph I.",
                    "label": 0
                },
                {
                    "sent": "So it's not the it's posting for postcrossing negative negative cross.",
                    "label": 0
                },
                {
                    "sent": "And I search for the pattern basically with large frequency difference in.",
                    "label": 1
                },
                {
                    "sent": "In crosses.",
                    "label": 0
                },
                {
                    "sent": "Um, so basically.",
                    "label": 0
                },
                {
                    "sent": "I think so.",
                    "label": 0
                },
                {
                    "sent": "So this basically shows the frequency difference and I look for all patterns.",
                    "label": 0
                },
                {
                    "sent": "Such that this score is more than power.",
                    "label": 0
                },
                {
                    "sent": "And one bad news is that this community discord is not anti monotonic.",
                    "label": 0
                },
                {
                    "sent": "So instead I use abound of this core function such that the bound is anti monotonic and I use this bound to three today Sunday.",
                    "label": 0
                },
                {
                    "sent": "Not this core function itself.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And you can think of March Cross version Hospital.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                },
                {
                    "sent": "In this case, you have, say five 617 crosses.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And for example, if graph I belongs to cross air then I. I said this way Wai.",
                    "label": 1
                },
                {
                    "sent": "To be positive and otherwise negative so it's like thrombosis wrist support, vector machine and stuff and.",
                    "label": 0
                },
                {
                    "sent": "And such buttons.",
                    "label": 0
                },
                {
                    "sent": "That over different in cross country skiing across so.",
                    "label": 0
                },
                {
                    "sent": "So you can design such a score function and.",
                    "label": 0
                },
                {
                    "sent": "Do the same thing.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So summary of graph mining.",
                    "label": 1
                },
                {
                    "sent": "Is this so?",
                    "label": 0
                },
                {
                    "sent": "It's an efficient way of searching patterns, satisfying predetermined conditions.",
                    "label": 1
                },
                {
                    "sent": "It's NP hard actually, but but, but basically.",
                    "label": 0
                },
                {
                    "sent": "The actual speed really depends on the data, of course, but but you tend to, you know you tend to design from the method.",
                    "label": 0
                },
                {
                    "sent": "If you see this.",
                    "label": 0
                },
                {
                    "sent": "But but in my experience it's not too bad and it's faster for sparse graphs of course.",
                    "label": 0
                },
                {
                    "sent": "And if you have diverse kinds of readers, then it's also faster.",
                    "label": 0
                },
                {
                    "sent": "Equals you can prune the tree area.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And in the in our recent work appearing, I say May I use this graph mining for actually solving.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trusting problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so the motivation here is too too long.",
                    "label": 0
                },
                {
                    "sent": "A mixture model in the feature space of patterns.",
                    "label": 1
                },
                {
                    "sent": "So I shows this huge dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Maybe position orbital, but they don't want right?",
                    "label": 0
                },
                {
                    "sent": "So I like to run McDonald in this space.",
                    "label": 0
                },
                {
                    "sent": "So it could be simple.",
                    "label": 0
                },
                {
                    "sent": "One simple probabilistic model, but I hope my hope is that this is a basis for more complex probabilistic inference.",
                    "label": 0
                },
                {
                    "sent": "And my idea is to combine everyone realization, trust, graph mining.",
                    "label": 0
                },
                {
                    "sent": "So again, what happens is that you do E7 mining instead.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's a bit going technical now.",
                    "label": 0
                },
                {
                    "sent": "I hope.",
                    "label": 0
                },
                {
                    "sent": "So, so this is my probabilistic model in itself is a very simple one.",
                    "label": 1
                },
                {
                    "sent": "I have a mixture model.",
                    "label": 0
                },
                {
                    "sent": "So each component is.",
                    "label": 0
                },
                {
                    "sent": "Written like Pierre so I have C component.",
                    "label": 0
                },
                {
                    "sent": "For secrecy and Starfire is just await parameters.",
                    "label": 1
                },
                {
                    "sent": "And each component is just a. Binomial distribution, or about this binary vector, right?",
                    "label": 0
                },
                {
                    "sent": "So this XK.",
                    "label": 0
                },
                {
                    "sent": "Can be either there or one.",
                    "label": 0
                },
                {
                    "sent": "Um, yeah.",
                    "label": 0
                },
                {
                    "sent": "So it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not the special model.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And OK, so let's apply the ordinary EMR Morrison and then the goal is to maximize their recruitment.",
                    "label": 0
                },
                {
                    "sent": "For all the parameters for four 404 error and CDL.",
                    "label": 0
                },
                {
                    "sent": "You have to optimize, alright?",
                    "label": 0
                },
                {
                    "sent": "And user.",
                    "label": 0
                },
                {
                    "sent": "EM algorithm you.",
                    "label": 0
                },
                {
                    "sent": "Is it like this?",
                    "label": 0
                },
                {
                    "sent": "So in each step you get you calculate the posterior are error.",
                    "label": 0
                },
                {
                    "sent": "Which is the.",
                    "label": 0
                },
                {
                    "sent": "The membership function of graph I.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Crossed there.",
                    "label": 0
                },
                {
                    "sent": "Right and in step you use this.",
                    "label": 0
                },
                {
                    "sent": "Putative partition to estimate see to air.",
                    "label": 0
                },
                {
                    "sent": "Of each component.",
                    "label": 0
                },
                {
                    "sent": "And I have to say that both are computationally prohibitive becausw.",
                    "label": 1
                },
                {
                    "sent": "In computing, the posterior underestimating city area have to scan overall features one.",
                    "label": 0
                },
                {
                    "sent": "But it's impossible to scan over our feet equals it has to mean.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I have to introduce some technique for feature selection.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Basically I use everyone regularizer so.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "And when you look at this regularizer, you see that your parameter citarella K is attractive to some constants it there OK. Yeah, and.",
                    "label": 0
                },
                {
                    "sent": "And this is not a squared loss, but this is just the absolute value between absolute difference between 2:00.",
                    "label": 0
                },
                {
                    "sent": "Variables, so it's a it's called L1 norm.",
                    "label": 0
                },
                {
                    "sent": "Under this regularizer is called, everybody right, so it's it's often used in feature selection.",
                    "label": 0
                },
                {
                    "sent": "9 fields.",
                    "label": 0
                },
                {
                    "sent": "And one tricky part is to.",
                    "label": 0
                },
                {
                    "sent": "I mean, my question is how to set this sheet as Arrow Cave?",
                    "label": 0
                },
                {
                    "sent": "And I said this because, OK, to be the maximum likelihood parameter estimate using single binomial distribution.",
                    "label": 1
                },
                {
                    "sent": "So say support.",
                    "label": 0
                },
                {
                    "sent": "So I'm considering to fit.",
                    "label": 0
                },
                {
                    "sent": "Fit the mixer somewhere to that space, but consider you fit one buttons one binomial distribution to all graphs.",
                    "label": 0
                },
                {
                    "sent": "Then you get this Citadel.",
                    "label": 1
                },
                {
                    "sent": "So in order for most parameters, since they will be exactly equal to Constance because of the property of Aragon regularizer.",
                    "label": 0
                },
                {
                    "sent": "So it's it's pasty.",
                    "label": 0
                },
                {
                    "sent": "Introducing prior so.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And OK, and you can think of active the set of active patterns, so the active patterns.",
                    "label": 0
                },
                {
                    "sent": "Define rugby.",
                    "label": 0
                },
                {
                    "sent": "So if there exists error such that she to elkei is not equal to shooters rocaton I say this K Patton case active.",
                    "label": 0
                },
                {
                    "sent": "So basically in an active pattern you have all the.",
                    "label": 0
                },
                {
                    "sent": "Part of it, though, is equal to the constant.",
                    "label": 0
                },
                {
                    "sent": "On the.",
                    "label": 0
                },
                {
                    "sent": "And 1.2 emphasizes that the step is computed only with active patterns F. So I'm taking the.",
                    "label": 1
                },
                {
                    "sent": "A product over, if only so so you don't need discount.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what about the instep?",
                    "label": 0
                },
                {
                    "sent": "So given this putative across our assignment, R arrive, each parameter is sold separately, so I have a lot of parameters, but.",
                    "label": 0
                },
                {
                    "sent": "But it factorizes out so I can help.",
                    "label": 0
                },
                {
                    "sent": "I can solve each parameter separately, so it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a simple 1 dimensional program.",
                    "label": 0
                },
                {
                    "sent": "So naive way to solve it is too.",
                    "label": 1
                },
                {
                    "sent": "Two, I mean sorry for all parameters and identify active patterns, but but this?",
                    "label": 1
                },
                {
                    "sent": "Is impossible because you have to solve it for all parameters.",
                    "label": 0
                },
                {
                    "sent": "That's like exponentially as.",
                    "label": 0
                },
                {
                    "sent": "So the idea is.",
                    "label": 0
                },
                {
                    "sent": "To use graph mining to find active patterns.",
                    "label": 1
                },
                {
                    "sent": "So if you know active patterns in advance.",
                    "label": 0
                },
                {
                    "sent": "Me without actually solving this.",
                    "label": 0
                },
                {
                    "sent": "Equation then it's OK, basically, but how?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when you look at the solution of this problem, it's a bit weird cause because you have this L1 regularizer, so so you have piecewise kind of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, solution.",
                    "label": 0
                },
                {
                    "sent": "And and it can be computed.",
                    "label": 0
                },
                {
                    "sent": "Sorry from 2 values.",
                    "label": 0
                },
                {
                    "sent": "So why the occurrence probability in across the entire K and the overall recurrence probability in type it there OK and what it says is that if?",
                    "label": 0
                },
                {
                    "sent": "If the occurrence probability in a cluster is not so different from the overall occurrence probability, then you get the constant as the solution.",
                    "label": 1
                },
                {
                    "sent": "And if it's not so gross, then you have to do the compute.",
                    "label": 0
                },
                {
                    "sent": "Solution.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey drugs please.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And the crucial observation is that for active Pankey, the occurrence probability in a graph cluster is significantly different from the average, so.",
                    "label": 1
                },
                {
                    "sent": "So this happens if and only if this happens.",
                    "label": 0
                },
                {
                    "sent": "So basically I mean 2.",
                    "label": 0
                },
                {
                    "sent": "I mean, so the definition of active pattern.",
                    "label": 0
                },
                {
                    "sent": "Was this right?",
                    "label": 0
                },
                {
                    "sent": "But you can replace this division by this propose, because this is equivalent.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What happened is.",
                    "label": 0
                },
                {
                    "sent": "That you have this little bucket button here.",
                    "label": 0
                },
                {
                    "sent": "But now it's equivalent.",
                    "label": 0
                },
                {
                    "sent": "Ready to ask this because of the error and regularizer and stuff and.",
                    "label": 0
                },
                {
                    "sent": "And yeah, maybe you forgot to put these notations, but but the crucial thing is that it is different in terms of frequency only, not Sita.",
                    "label": 0
                },
                {
                    "sent": "So now now we are looking at the frequencies.",
                    "label": 0
                },
                {
                    "sent": "So so we can found these active button F by graph mining.",
                    "label": 1
                },
                {
                    "sent": "So I I.",
                    "label": 0
                },
                {
                    "sent": "A day.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so I don't know if you can pull this, but but basically the the point is that I could do actually the map estimation of parameters without any approximation.",
                    "label": 0
                },
                {
                    "sent": "Because I didn't approximate it at all, just.",
                    "label": 0
                },
                {
                    "sent": "I use it every one regularizer and then yeah.",
                    "label": 0
                },
                {
                    "sent": "Then it comes as a natural consequence of.",
                    "label": 1
                },
                {
                    "sent": "OK, so I show a small experiment.",
                    "label": 0
                },
                {
                    "sent": "So these are about our any graphs.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "As you know RNA, you know it's folded like a shape like this, so it says it is T RNA.",
                    "label": 0
                },
                {
                    "sent": "And I use Steam so this.",
                    "label": 0
                },
                {
                    "sent": "I don't know this.",
                    "label": 0
                },
                {
                    "sent": "You can solve hybridized pairs.",
                    "label": 0
                },
                {
                    "sent": "As an old.",
                    "label": 0
                },
                {
                    "sent": "And if it's 100 group red and if it doesn't have a self group, is blue.",
                    "label": 0
                },
                {
                    "sent": "And if it is adjusting in this structure, then I make up.",
                    "label": 1
                },
                {
                    "sent": "So I have to know the secondary structure of RNAs in advance, but but not always know.",
                    "label": 0
                },
                {
                    "sent": "So I predict it then buy the software called RNA port.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so clustering task.",
                    "label": 0
                },
                {
                    "sent": "It's kind of small, but we have three or four families.",
                    "label": 0
                },
                {
                    "sent": "So in terms EP1, SSR, RNA five and one is.",
                    "label": 0
                },
                {
                    "sent": "Buckley under.",
                    "label": 0
                },
                {
                    "sent": "And I I chose this because they have.",
                    "label": 0
                },
                {
                    "sent": "They are.",
                    "label": 0
                },
                {
                    "sent": "City laws are in a with the result of.",
                    "label": 0
                },
                {
                    "sent": "Things with 20 steps and so.",
                    "label": 0
                },
                {
                    "sent": "So I mean so.",
                    "label": 0
                },
                {
                    "sent": "So my method is used as if you just one step.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I made three by passion programs out of these three families, so I couple two families and try to classify.",
                    "label": 0
                },
                {
                    "sent": "Without using drivers without using cross rails.",
                    "label": 0
                },
                {
                    "sent": "So these are evaluated by underscores.",
                    "label": 1
                },
                {
                    "sent": "Out of this course.",
                    "label": 1
                },
                {
                    "sent": "I mean the regular the area under.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this was actually already graphs.",
                    "label": 0
                },
                {
                    "sent": "This is the Inter on GP one.",
                    "label": 0
                },
                {
                    "sent": "This is SSU and this is our next.",
                    "label": 0
                },
                {
                    "sent": "So you see that the number of nodes are quite different, for example.",
                    "label": 0
                },
                {
                    "sent": "I mean, this one has more nodes than this one.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you see, it's not a big deal.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here is the arosi scores.",
                    "label": 0
                },
                {
                    "sent": "So this is the result of marginalized graph content combined with K means.",
                    "label": 0
                },
                {
                    "sent": "Crossing, and this is the result for so called spectral distance, which completes compares the Laplacian matrices of two graphs.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Yeah, basically this pic was not very good except for this easy case.",
                    "label": 0
                },
                {
                    "sent": "On the margins requires worked somewhere for this task and this task, but.",
                    "label": 0
                },
                {
                    "sent": "But for this task, for the most difficult one.",
                    "label": 0
                },
                {
                    "sent": "This performed very badly.",
                    "label": 0
                },
                {
                    "sent": "It's auto score 3.5 so it's random.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "It's not better than random.",
                    "label": 0
                },
                {
                    "sent": "Peoples Random comes to 0.5.",
                    "label": 0
                },
                {
                    "sent": "And So what I would like to say that our method marked.",
                    "label": 0
                },
                {
                    "sent": "They're going to 945 here because I'm using substructure information.",
                    "label": 0
                },
                {
                    "sent": "So as you see.",
                    "label": 0
                },
                {
                    "sent": "I just said those graphs do not have meaningful labels, so the labels are just.",
                    "label": 0
                },
                {
                    "sent": "Very long so.",
                    "label": 0
                },
                {
                    "sent": "This kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Modernize both corners performs very poor.",
                    "label": 0
                },
                {
                    "sent": "I mean, except for the case that you have some clear cut.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And look at this is the time.",
                    "label": 0
                },
                {
                    "sent": "Consumed by our method of sorry I didn't say, but this is a regularization parameter.",
                    "label": 0
                },
                {
                    "sent": "Realisation strings.",
                    "label": 0
                },
                {
                    "sent": "So when you.",
                    "label": 0
                },
                {
                    "sent": "Increase the regularization strings.",
                    "label": 0
                },
                {
                    "sent": "Then you get less patterns.",
                    "label": 0
                },
                {
                    "sent": "But basically we hub you have like thousands of patterns overall.",
                    "label": 1
                },
                {
                    "sent": "On the.",
                    "label": 0
                },
                {
                    "sent": "The time needed was like one minute 2 minutes for these datasets and.",
                    "label": 0
                },
                {
                    "sent": "For example, this contains 100 graphs, so I think it's not.",
                    "label": 0
                },
                {
                    "sent": "But I mean it's kind of still put it up for me to wait for a minute, but it's a. I mean, but it may not be.",
                    "label": 0
                },
                {
                    "sent": "So I cannot really say that how, how it is scalable to do more data, because it really depends on the data and depends on the labels and how you can prove it, but but at least in this moderate case, and I can do it.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You want me?",
                    "label": 0
                },
                {
                    "sent": "And the nice point about the messages that we actually found patterns and and I actually.",
                    "label": 0
                },
                {
                    "sent": "Had thousands of buttons, but I fixed it 8.",
                    "label": 0
                },
                {
                    "sent": "Most of this community ones.",
                    "label": 0
                },
                {
                    "sent": "On the Odyssey.",
                    "label": 0
                },
                {
                    "sent": "The feature is not trivial, right?",
                    "label": 0
                },
                {
                    "sent": "So you have.",
                    "label": 0
                },
                {
                    "sent": "So this one was the most.",
                    "label": 0
                },
                {
                    "sent": "Pretty people the most discriminating, but you have 123456789 nodes, so such kind of features.",
                    "label": 0
                },
                {
                    "sent": "Nearby capture he goes.",
                    "label": 0
                },
                {
                    "sent": "It looks at short partners.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now conclusion so.",
                    "label": 0
                },
                {
                    "sent": "Um, yeah, my messages that the substructure representation is big doesn't party, and probabilistic inference here if I got mine and.",
                    "label": 0
                },
                {
                    "sent": "And this work.",
                    "label": 0
                },
                {
                    "sent": "I did clustering but there are many possible extensions, naive Bayes, graph, PCA, Fisher discriminant analysis, CCA services provide training and so on so forth.",
                    "label": 1
                },
                {
                    "sent": "So I didn't really say about applications.",
                    "label": 0
                },
                {
                    "sent": "Embarrassing things should follow interviews.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so one ongoing work is to operate these two image classification.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so I don't describe in details but you.",
                    "label": 0
                },
                {
                    "sent": "Be present.",
                    "label": 0
                },
                {
                    "sent": "Image of the graphene.",
                    "label": 0
                },
                {
                    "sent": "Yeah, then you can find such a.",
                    "label": 0
                },
                {
                    "sent": "But come on.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you, please interesting.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "This modified PM.",
                    "label": 0
                },
                {
                    "sent": "You have your graph mining stuff, so my question is, is there a formal convergence guarantee of EM?",
                    "label": 0
                },
                {
                    "sent": "So Are you sure that you in every step increase the likelihood until you get a local optimum?",
                    "label": 0
                },
                {
                    "sent": "Because you have this this feature selection step in between, so it's probably you change the underlying space.",
                    "label": 0
                },
                {
                    "sent": "So the cause, because this is regularization comes in really in support, so I I remember you did it once you present it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we had a similar model, but it was really difficult in that in adult formally prove that Emerald converges because you change the underlying probability space.",
                    "label": 0
                },
                {
                    "sent": "If you do the feature selection.",
                    "label": 0
                },
                {
                    "sent": "Really OK, so I didn't really think about it, but.",
                    "label": 0
                },
                {
                    "sent": "But what I can say is that we're ready.",
                    "label": 0
                },
                {
                    "sent": "So to be with you this problem I show it to you, so this prototype is trust figure right now without any approximation and under the underwriting spaces brothers, but still fine so so we don't have any in mathematical program about an infinite summation space.",
                    "label": 0
                },
                {
                    "sent": "So I saw this OK but yeah of course.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "But I just checked similar rules of Cinderella.",
                    "label": 0
                },
                {
                    "sent": "So there are regular Izium algorithms out there.",
                    "label": 0
                },
                {
                    "sent": "They really, so I said it's OK, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And you know, that doesn't.",
                    "label": 0
                },
                {
                    "sent": "Some questions.",
                    "label": 0
                },
                {
                    "sent": "Are you sending this or or slacking?",
                    "label": 0
                },
                {
                    "sent": "This community happens.",
                    "label": 0
                },
                {
                    "sent": "Combat score involve weights is using his classes that we think are put codes saying 1 roses on it.",
                    "label": 0
                },
                {
                    "sent": "Seems to me that if you have a large number of classes than that score would be dominated by patterns that occur in none of the classes is better.",
                    "label": 0
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in interscore I take Max.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "So basically this is designed to capture.",
                    "label": 0
                },
                {
                    "sent": "Capture the button you nobody presented in at least one class.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So basically, if if the pattern is, you know.",
                    "label": 0
                },
                {
                    "sent": "Included in the same frequency over our classes then.",
                    "label": 0
                },
                {
                    "sent": "Then these cannot be picked up.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you know if you have many, in fact, if you have many crosses, then the design of this.",
                    "label": 0
                },
                {
                    "sent": "We thought this school will be a problem, I think.",
                    "label": 0
                },
                {
                    "sent": "And you know, so initiating you have many ways to sort of much craft programs and and you have also many possible quote for that and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so actually this maxi he.",
                    "label": 0
                },
                {
                    "sent": "It is somehow conservative, so it's not so aggressive, so maybe we can make more aggressive score too.",
                    "label": 0
                },
                {
                    "sent": "To reduce the computational costs result without sacrificing security but.",
                    "label": 0
                },
                {
                    "sent": "But in this world I I didn't really.",
                    "label": 0
                },
                {
                    "sent": "I think about it, I just used him.",
                    "label": 0
                },
                {
                    "sent": "This is this one.",
                    "label": 0
                },
                {
                    "sent": "One request.",
                    "label": 0
                }
            ]
        }
    }
}