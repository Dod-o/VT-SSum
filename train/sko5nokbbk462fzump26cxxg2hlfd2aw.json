{
    "id": "sko5nokbbk462fzump26cxxg2hlfd2aw",
    "title": "Training Deep Neural Networks",
    "info": {
        "author": [
            "Hugo Larochelle, D\u00e9partement d'informatique, Universit\u00e9 de Sherbrooke"
        ],
        "published": "Sept. 13, 2015",
        "recorded": "August 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2015_larochelle_neural_networks/",
    "segmentation": [
        [
            "Alright, thanks for the intro everyone.",
            "So yeah so today what I'll do is I guess pick up from where Layonne stopped and try to go a bit further into giving details about how to train deep neural networks.",
            "In the description of the talk of supposed to give, there's a mention of back prop in it, but I see that Leo has already presented that yesterday, so I just wanted to see.",
            "Raise your hand if before the summer is cool, you had seen backdrop already.",
            "OK, so if you had not seen backdrop, that's going to be more useful.",
            "If you had not seen backdrop, can you raise your hand?",
            "So either you're shy or there's like no one.",
            "So what I'll do is that I won't arrive back rough.",
            "Well, I didn't have time to count I, you know I'm I don't have that autistic, you know, kind of ability.",
            "But So what I'll do is I won't derive backdrop.",
            "But and you to resources where you can, if you really want the details, when you can actually get the details of it, alright so."
        ],
        [
            "Actually, some of what I'm going to present is part of an online course which is available on YouTube, so you might know about it.",
            "This is where you can go find the details about backdrops.",
            "I go through, you know, painful steps of deriving each and every single part of backdrop.",
            "So if you want to really sort of master the different steps that go from you know the basic idea of the chain rule and so on into the actual instantiation of backdrop for.",
            "Classification neural net.",
            "This is all described in the online course and other things as well.",
            "I talk about our BMS convolutional Nets, so this can be also useful resources if during the week you have thank you forgotten about certain topics again, of course, go back to the slides and also have some explanations that offer you on YouTube right there.",
            "So a lot of the slides I'm going to use today are from that, but not all of them.",
            "There's some new stuff as well."
        ],
        [
            "Oh and also please do not hesitate to interrupt me if you have questions.",
            "That's totally fine.",
            "It's going to wake me up.",
            "It's going to wake you up.",
            "This is going to be better all around.",
            "Alright, so OK, so I'm first going to do a little wrap up of some of what you've seen, probably yesterday if anything is going to introduce the notation that I've used.",
            "So this is the notation that I'll be using for a classification feed for neural network.",
            "In this case with two hidden layers.",
            "So when you want to compute the output of Internet, what do you do?",
            "You take the input vector which is X. I'll use bold X bold for a vector.",
            "OK, so when the letter is bolded and lower case, that usually means a vector, and so each dimension X1 XJXD.",
            "This is essentially different dimensions of that vector X.",
            "And when you compute a layer, you first compute what I call a pre activation.",
            "So I think that's possibly a word you haven't.",
            "Heard before, but that's what I'll use to talk about the linear transformation from the previous layer up to the next.",
            "So I'm using K here to indicate the index of the layer so you can see I'm taking the value, so I'm using HH of X as the K -- 1 youth layer in my network, and so for the 0F network that would be X.",
            "That would be the input.",
            "I'm going to linear transform it to get my pre activation for the.",
            "Layer above it, so I'm multiplying by your matrix again, so I'm using these exponent in parentheses to indicate indices of layers, so that's for the connections with The Cave layer plus a bias vector, and that gives me my pre activation using a for the symbol for that, and then I apply an activation function time knowing G here, so that could be a sigmoid function, tangent function.",
            "Relu, I think you've seen some of those yesterday.",
            "So we have a non linearity here that's introduced that's applied on the pre activation to give you the activation of the layer and you keep doing this from the first layer up to the last one which is the output layer.",
            "So those are here are two hidden layers and this is the output layer an at the output.",
            "Often we use a different activation function depending on the problem.",
            "I'll be mostly talking about classification problems So what will uses the softmax activation function if you haven't seen it yet?",
            "The softmax is just you take the exponential of all the elements in your pre activation at the output layer and then you divide by the sum.",
            "So the exponential gives you a positive number by divided by the sum.",
            "You get numbers that sum to one.",
            "So we can interpret those as probabilities that you're assigning and here these are probabilities will assign to the different classes to which the input can belong.",
            "So the number of units.",
            "The size of the output layer is going to match the number of classes that we want to distinguish.",
            "So for instance, there's the in this data set, which is used a lot in deep learning where you have images of handwritten characters, and those are usually the digits from zero to 9.",
            "So there are 10 classes in this case, with the output layer would have 10 units.",
            "And so I'm off sometime going to use L as the capital letters, the number of hidden units, sorry, and a number of hidden layers.",
            "So layer L plus one is the output layer OK?",
            "Any questions about that notation?",
            "Makes sense, so we have activations pre activations is before the activation function and each layer is really just a linear transformation which we have here, parameterized by my bias vector B in my matrix W. Followed by non linearity which I'm noting as G here.",
            "Alright."
        ],
        [
            "So how do we train in their own network and how do we train?",
            "Most machine learning models really is we're going to use empirical risk minimization.",
            "Actually, here this is the version that's regularised, so in essentially we're going to frame training a model as an optimization problem, where we're finding the value of our parameters Theta.",
            "So Theta consists in all the bias is an all of the weight matrices in my neural net, and I'm going to specify.",
            "A loss function L which compares the output of my neural net with the target Y.",
            "So why is the true answer the true thing that the ground truth that I'm trying to predict from X and the loss function compares the two as a measure of whether I did or good or bad prediction?",
            "So I'm going to minimize the average loss.",
            "And.",
            "Sometimes we add a regularizer so this or make a function.",
            "Here it takes the parameters and then computes a sort of essentially a value that gives us to what extent we like that configuration of the parameters and I'll talk about regularizers before 'cause I think that wasn't really mentioned yesterday.",
            "I'm.",
            "So this is the setup in which were mostly going to talk about training neural networks.",
            "We're going to cast it as optimization problem, where we're optimizing the mean of a loss function comparing the output with the target."
        ],
        [
            "OK, so.",
            "This is an optimization problem, so we need an optimization procedure to find the solution and the algorithm is going to be used almost all of the time in deep learning is known as stochastic gradient descent.",
            "So how does it work?",
            "Little is going to talk about this algorithm quite a bit, I think after my presentation, so I'll just present without describing it too much.",
            "The algorithm itself is just assume from there now that that's what we'll be using.",
            "We're training neural Nets, so we start.",
            "By initializing our parameters so that means all of our connection matrices and biases will initialize them often randomly.",
            "But I'll talk about other ways of doing that.",
            "And then for a certain number of iterations, these iterations, often we use instead the word apacs for them in neural Nets, so iteration or epoc is really the same thing.",
            "In my notation here, we're going to pick one of the training examples.",
            "So a pair XY.",
            "And then we'll try to figure out a direction in which I'm going to move my parameters, my biases, and my connections.",
            "So that direction is going to be based on what is the gradient of the loss and the regularizer so that gradient tells me in what direction.",
            "For that example, could I increase the loss and regularizer function the most by making a very small step, and then I'll go in the opposite direction?",
            "Because I want to decrease that Lawson.",
            "Regularizer function OK So what we need is that this direction is going to be the opposite direction of the gradient.",
            "Of that last function, So what you're seeing here is that this nabla symbol, it corresponds to the notation for gradient and the Theta.",
            "Here just says I want the gradient with respect to, so the vector of partial derivatives with respect to all of my parameters in my big vector Theta.",
            "And I want the gradient with respect to Theta of what of the loss function for that example.",
            "So for that example, what's the gradient with respect to parameters?",
            "How do we impact the loss?",
            "And also I'll need the gradient of the regularizer and I'll go in the opposite direction of that.",
            "So we also have this Lambda here which I can talk about, which is the weight of the regularizer with respect to balance its influence with respect to the average loss.",
            "And then I'll take my vector Theta and I'll just take a step of size Alpha in that direction.",
            "So this is a vector.",
            "An Alpha.",
            "Here is what we often call a learning rate, and that's something we that's a hyperparameter that we need to specify a priority, and I'll talk a bit more about how to search for a good value for the hyperparameter later on.",
            "So I make an update in my parameters, and then I continue doing this for all the examples in my training set.",
            "So for all pairs X&Y.",
            "And then I repeat for several epochs, or several iterations until I meet some sort of convergence criteria, and I'll talk also about what good convergence criteria we can use for training neural Nets.",
            "OK, so that's stochastic gradient descent.",
            "This is how we're going to optimize this empirical risk here.",
            "This regularize empirical risk for each example we look at which direction could we decrease by taking a small step tolosan regularizer, and then I repeat this for each example, OK?",
            "So if I want to use this algorithm, if that's the optimization algorithm, want to use to optimize or training neural net, what do I need to specify?",
            "I need to specify a way of initializing the way.",
            "The yes, the weights in the bicis.",
            "So all of my parameters I need to specify a loss function.",
            "So which determines you know, to what extent are certain predictions good or bad?",
            "And I need to specify procedure for obtaining these gradients for a given XY pair with respect to my parameters.",
            "And I need to specify a regularizer if I want to use that if I want to regularize my objective.",
            "And of course I need also a simple way of getting the gradient with respect to that regularizer.",
            "OK, So what I'll do is just talk about these different choices for the initialization.",
            "The last function.",
            "How do we get the gradient?",
            "The short answer is back propagation.",
            "This is what this computing this gradient, and choices of regularizer.",
            "Questions about this so far.",
            "Yes.",
            "So the question is, why do I define the regularizer?",
            "Just a function of the weights, so I guess regularization could depend on other things.",
            "It will typically not depend on the pair XY, but the weights as well.",
            "See the type of regularization functions will use, which is.",
            "You know the Euclidean norm or the L1 norm only depends on the weights, but I should say that yeah, you could think of other types or.",
            "Regularization's and I guess to some extent that's a lot of what research and deep learning is finding new ways or better ways of regularising neural net so that they don't overfit.",
            "And I will talk a bit more about like how this is a challenge with deep neural Nets that regularization, unless you have a huge data set is something you need to be concerned about.",
            "Other questions.",
            "It's a great question, thank you.",
            "Alright."
        ],
        [
            "OK, so for the last function I'll mainly talk about classification so.",
            "The last function that I'll usually assume is the log probability.",
            "The negative log probability of the correct class.",
            "For my example, XOF of X.",
            "Is this vector of probabilities for our class, so if I'm looking at FXY, that's the probability I'm assigning to the correct class.",
            "I'm going to take minus the log of that, mainly because taking the log makes there both the math and the numerical computations more stable.",
            "An easier and minus because if I want to minimize if I want to maximize the probability of the correct class, which makes sense well, and if I'm framing everything into a minimization problem, I'm going to want to minimize the negative of that.",
            "OK, so that's known as doing essentially maximum likelihood, where minimizing the negative log likelihood.",
            "So we're maximizing the likelihood of the class assignments that I see in my training set.",
            "According to my neural net.",
            "OK."
        ],
        [
            "And then I need a procedure that takes this choice of a loss and gives me forgiven example XY.",
            "What is the gradient of that loss with respect to all my parameters?",
            "All my bases in all my weights?",
            "And that's the backpropagation algorithm.",
            "It's essentially an application, a small application of the chain rule.",
            "So I start by computing what is the gradient of the loss function with respect to.",
            "It's sort of happens to be more convenient to start with that the pre activation at the output layer.",
            "So the vector right before the softmax.",
            "So this is what this symbol is.",
            "This is a vector here, so this is saying nabla of that vector.",
            "So I'm looking at the gradient with respect to that vector.",
            "Of my last, which is minus the log of the probability of the correct class an.",
            "It's actually super simple using the softmax and the negative log probability.",
            "It's what I'm calling EY.",
            "So EY is a vector.",
            "We know it's a vector because I put it in bold, the E. Here an I provide Y just to specify.",
            "So YY is going to be a vector filled with zeros except with the position Y corresponding to the correct class.",
            "So if I have 10 classes, an Y is equal to two because this particular example X belongs to the second class.",
            "I'm going to have a bunch of zeros and in the second entry is going to be equal to 1.",
            "So that's this EY here, it's also known as the one Hot vector, which is something you word you'll probably hear about later on this week.",
            "So I take that one hot vector, which is really what essentially what the target is.",
            "I want zero probability to everything, and the probability of 1 to the correct class.",
            "That would be the best case scenario.",
            "And then I subtract my current prediction.",
            "OK, and that happens to be so.",
            "Take minus that that happens to be what is the gradient of their pre activation at the output layer of the loss function?",
            "OK, so effectively what it's saying is that whatever I'm predicting right now, I don't want to predict that anymore.",
            "I want to predict that's one hot vector.",
            "This is the signal that we're sending to the neural net and then I'm going to start from the last layer and I'm going to propagate the gradients towards the input an on the way.",
            "Also compute the gradients with respect to the diocese.",
            "And the weight matrix.",
            "So.",
            "From the last layer to the first, I compute the gradients with respect to the hidden layer parameters.",
            "That is the weight matrix and the bias.",
            "As it turns out, it just corresponds to taking the gradient of the pre activation of the layer on top.",
            "So that's also my notation assumes that all vectors are column vectors, so this here is a column vector.",
            "Times the activation of the layer below for that.",
            "For that index K. So I'm taking the pre activation of the layer on top and the activation at the layer below.",
            "Sorry the green in the pre activation layer of top and the activation of the layer below an.",
            "I'm taking the transpose of that so that gives me a column vector times a row vector.",
            "If I multiplied this together I'm getting a matrix and that matrix you'll notice will match that.",
            "Dimensionality of the matrix for that layer, it's going to be number of hidden units in the layer K times number of units in the layer came on this one.",
            "OK, so this is the gradient of.",
            "This is the gradient of my weight matrix for layer K. The gradient of the bias is simply the gradient of the loss with respect to their pre activation that I have already starting this loop.",
            "And so that's computing the gradients for the hidden layer parameters.",
            "Next, I'm going to propagate the gradients to the layer below it at index K -- 1.",
            "So I'm at layer K and propagating to index to layer key minus one.",
            "So the gradient of the loss with respect to the activation at layer K -- 1 is just going to be my gradient for the pre activation at the layer above it multiplied by the transpose of my weight matrix, and that's because.",
            "I'm propagating through a linear transformation and so the Jacobian is just this.",
            "It's just a weight matrix essentially.",
            "So that's the first step and then to get the gradient which reflected the pre activation for the layer below I need to pass the gradient through the non linearity and so I'm taking that gradient here which I'm seeing here and then multiplying I'm doing and elementwise multiplication with the derivatives of the activation function for each unit.",
            "So This is why this is an elementwise multiplication.",
            "So what dissemble that I'm taking the derivative?",
            "Of my activation function, say the sigmoid, for instance, for the particular value of the pre activation.",
            "OK, so this operation here for instance, if the sigmoid you might have learned about the fact that sigmoid will have saturating directives, which means that if the pre activation is very large and very small then the output is either going to be one or zero and then the data is going to be very close to 0.",
            "So this operation here might zero out some of the gradients, and that's a problem will.",
            "Talk about later on, but essentially once I've multiplied the gradients by the transpose of the weights, I do an elementwise multiplication of the narrative of the activation function, and then I can go back to the beginning of the loop and do this for the next layer, and I do this from the top to the bottom, yes question.",
            "That's the problem.",
            "Vanishing gradient.",
            "Yet that's what I was reffering too.",
            "That's why I will talk a bit more about that later on, but their vanishing grading a lot of it comes from this here from the fact we're doing this elementwise multiplication, at least some of it comes from that.",
            "So that's the backdrop algorithm.",
            "As you can see, it's as expensive as doing a forward prop.",
            "It's just we're doing it in the opposite direction, OK?",
            "Questions about that.",
            "Makes sense.",
            "Alright."
        ],
        [
            "An little talked a bit about this, but the way really to structure this in terms of code is to think of all these operations were doing when reconstructing a neural net, as these boxes that take inputs and produce an output, and then unknown.",
            "That is really just a flow graph where we've chained together each of these different boxes so that neural net that we saw before.",
            "We can think of it as a pre activation box which takes as input the input layer an.",
            "Also the parameters WNB.",
            "And it uses those parameters to transform X into a vector, which is the value of that box which is passed on to the another box which computes an element wise non linearity which is fed as input to a linear transformation which is a two of X.",
            "So this is the linear component that Leon was mentioning when it was showing examples of torch code and then you eventually reach an output layer and then you feed data loss function and then doing back prop.",
            "The way you can structure your code is that each of these boxes, and they're going to compute an output given their inputs, but also if you provide them a gradient for their outputs, it will have a B prop function, which will take that and propagate those gradients to each of its inputs."
        ],
        [
            "So then these gradients should correspond to the gradient of the loss function with respect to that box.",
            "So you start with your loss and the gradient of the loss with respect of the losses one, so it's easy to initialize at the very top, and then you just go in the opposite direction.",
            "Calling the B prop method.",
            "Backpropagation gradient green up to here and up to here and up to the weights so you get your gradients with respect to your weights and then up to back propagating to the first layer through the activation function and up to the weights for the first layer.",
            "And we don't need to back propagate up to X 'cause there's nothing to update in X.",
            "So that's essentially what the you know in terms of structuring your code and what not.",
            "You know, doing backdrop looks like an.",
            "I think later today.",
            "Maybe you have already, but you're going to learn about Theano.",
            "Theano essentially does this, but in even more sophisticated way where it actually outputs a graph that computes these gradients and torch works a lot in this way as well.",
            "Where you change these boxes, and then when it comes to doing backdrop, well, it does pretty much what I shown here.",
            "It calls all of these boxes in the reverse order, calling a different function, which is the backdrop function alright?"
        ],
        [
            "OK.",
            "So we have the last function we have the way to compute the gradients.",
            "Now what are the other missing pieces?",
            "While we might want to regularize on your own net to sort of play with this bias variance compromise that Pascal myself talked about yesterday.",
            "The two regularization functions that are used the most is so the first one is the L2 regularization.",
            "It's just the sum over all the weight matrices and all of its entries of the squared of the value of the entries to square of their connections.",
            "OK, so it's the squared of the business norm, summed over all the weights.",
            "So you could include the biases.",
            "I think often we actually don't.",
            "This might vary between different researchers, but usually we think of, you know the most most of the capacity is really in the weight matrix.",
            "So often this is the weight matrix.",
            "We're going to regularize.",
            "Anne and the green of that is actually very simple, is just two times the weight matrix.",
            "There's the other one.",
            "Oh, and when we talk about weight decaying, so if you're that expression, usually we talk about L2 weight decay, so L2 regularization.",
            "The L word."
        ],
        [
            "Nization is another one that's used a lot.",
            "It has the one of it's interesting properties is that if their regularization coefficient, this Lambda that multiplies the regularizer is big enough.",
            "Some of the connections are going to be forced to exactly 0, so it's going to give you potentially a neural net with a sparse connectivity.",
            "And so it's just the sum of the absolute values of the weights, and the gradient is actually one if the weight was positive and minus one if the wait was negative and if it's zero, we just climb the gradient to 0.",
            "So again, the gradient is super trivial to compute."
        ],
        [
            "OK, so we have regularization and now we need the initialization.",
            "I think Leo talked about this so there are a few choices.",
            "Well which are really bad initializing.",
            "So for the biases, often we initialize them to zero before the weights.",
            "Initializing everything to zero.",
            "With attention activation we can show that then all the gradients would be 0, so it's under saddle Point.",
            "You're stuck there and you can't move, so that's a bad idea.",
            "Initializing all the weights to exactly the same value will create symmetries, which means that.",
            "Each unit as they're being updated will essentially be identical.",
            "They will compute exactly the same features, so that's not a good idea, so that's why we essentially go with something that's more random.",
            "Each entry is going to be sample from a distribution.",
            "Some people use Gaussian distribution between, you know, not between certain variants.",
            "That's fairly small, so yahshua navigo have explored this.",
            "This problem in 2010, and it came up with this formula, which was adapted for the attention.",
            "Activation function and has some nice properties in terms of initially.",
            "How does the gradient propagate?",
            "Does it?",
            "I think it maintains essentially the gradient of the same size as initially when you back propagate.",
            "Alright, so that's why initialization you know.",
            "In short, it needs to be random.",
            "That's more or less it and with small values around zero.",
            "That's the short answer."
        ],
        [
            "OK so so now you have mainly the algorithm for training a feedforward neural network.",
            "Now I'm going to talk about other things that go yes, I see a question, yes.",
            "In yeah, so if you're asking me if.",
            "So the way that's the most interpretability again give right now the one way to think about it is to start to think about the grain at the output.",
            "The creativity output.",
            "What it does is that it essentially says you're supposed to increase the probability for the correct class and decrease the probability for everything else.",
            "And as you're applying the chain rule, what happens is that you are informing, say, the layer below it.",
            "Well to achieve this.",
            "How should you adapt your activations?",
            "OK, so should 1 activation and the first vector should increase or should it decrease and once you know this you can propagate this information to the weights so that now the weights no OK. Well if I wanted to increase my value should I?",
            "How should I change the different weights that go into this neuron?",
            "Should they increase or should they decrease so that's essentially the information that's being propagated around the network?",
            "Four different units?",
            "Should you if you want to make a small?",
            "Improvement in your loss.",
            "Should I increase or decrease the value?",
            "But it also send you some information as to what extent you want to increase it or not.",
            "So that's you know that's an interpretation of it.",
            "Yes, yeah, sure, I think wants to add something.",
            "Yeah.",
            "Yeah.",
            "So yes, I was making a point that it needs to be small.",
            "The initialization of weights but not too small.",
            "And so this, I think essentially that equation here.",
            "This way of saying we gotta initialize the weights uniformly between minus B&B where B is this sqrt 6 divided by the square root of the sum of the number of hidden units at the layer K plus the number of hidden units at the layer K -- 1.",
            "That essentially comes from trying to achieve this have a gradient which initially stays.",
            "About the same size.",
            "Whoops hello questions yes.",
            "So it will make a difference.",
            "So the question is, does it make a big difference to choose the Gaussian versus the uniform?",
            "As far as I know, people that have their so some people stick on using Gaussians they've never changed, so presumably it's not a deal breaker.",
            "I think if you look at the details you might see and maybe also can comment on this, but you might see some differences.",
            "I think I've heard some people say that by using this except instead of the Gaussian initialization they did see.",
            "No significant improvements, but it's not.",
            "You know the extent to which is going to be worse is not compared to like initializing everything to 0 or to the same value.",
            "Yes, yeah, sure."
        ],
        [
            "Doesn't happen.",
            "Information.",
            "Yeah, so the Gaussian does have this property that it is possible it's going to sample very large values.",
            "It's fairly unlikely, but it is possible.",
            "The uniform.",
            "You sure it's never going to happen outside of the bounds that you defined.",
            "Ask your question here.",
            "Yeah, sure, I'm going to give you this one.",
            "Yeah.",
            "So check out the paper, it is fairly simple.",
            "When I looked at it some time ago.",
            "Other questions.",
            "Yes.",
            "Yes.",
            "I think no.",
            "I think you need to change them, and I think the paper describes the formula for different activation functions.",
            "This one, I think, is for the 10 H. So it might actually be important.",
            "Yeah, so this is a good piece of code to have in whatever library using for neural Nets to have these sort of checks on the size of the gradients or their variances as your training.",
            "And when you're initializing can give you hints as to whether why you know maybe training doesn't work as well as you'd expect.",
            "Yes question.",
            "Yeah, so excellent question.",
            "So here what I described is an update per example, but in practice what people do, I was going to talk about it later is that you will actually update for a mini batch where we call a mini batch of examples you would take maybe 128 or 64 examples and then actually I'll talk about this later since I have a slide about it.",
            "But that's a very good point so far.",
            "Just assume you're essentially mini batch of size 1, but that's not what people do in practice.",
            "Yes.",
            "Shit.",
            "Right, so I would say that at least initially you want that it's true towards convergence.",
            "You will have gradients that should become small and close to 0.",
            "If they all go to zero at about the same rate, I would say that's a fairly good sign because it suggests that all layers are trained.",
            "You know at about the same amount.",
            "Informally, so yes, try to achieve.",
            "Try to and.",
            "This is why I was saying maybe having this.",
            "You know in your code this thing that just shows you what's the variance of the gradient that different layers might be useful.",
            "Maybe you can track?",
            "Oh, it seems at one point there's this layer that has converged.",
            "It's hard to say whether that's a good or bad thing, but you know, if you see it happening very quickly and you don't really suspect it could have converged, say the first layer that quickly, that might be a sign of something to adjust.",
            "Yeah, lot of questions.",
            "Oh so yeah.",
            "So that's another trick.",
            "So the question is whether this initialization requires any preprocessing on the inputs.",
            "And yes, it does assume that the inputs have been preprocessed to have mean zero and variance of 1.",
            "Yes, good point.",
            "OK, last question so I can move on, yeah?",
            "It's more like the bottom layers for so, so the question is whether the gradients will come close to zero more rapidly at the top layer of the bottom layer.",
            "You tend to see this more at the bottom layer, and the reason is 1 explanation is the fact that we're multiplying by the derivative of the activation function, and if all the activations have saturated then they will essentially block all gradients.",
            "OK.",
            "So let's move on to."
        ],
        [
            "Next step, so now we've seen essentially how do we train Internet?",
            "Once I've chosen number of hidden units in each layer, learning rates and things like that.",
            "Now I'm going to talk about what comes around that and 1st we want to talk about model selection.",
            "OK, so I think Pascal's talked about this.",
            "The notion of hyperparameters.",
            "So these are the parameters that backdrop essentially doesn't give you an answer for it doesn't optimize the number of hidden units, doesn't optimize the learning rate.",
            "You have to provide those before you start training.",
            "So how do you pick those so the."
        ],
        [
            "My hyperparameters we're going to select them like we said, hyperparameters for, especially all learning algorithms more or less.",
            "So the training set which I'm noting Detrain will serve to train the model, but we're going to have a separate set which is usually smaller, which we call a validation set an what it serves 4.",
            "Is that we're going to essentially try a bunch of different values for the hyperparameters, the learning rates, and the number of hidden layers and the size of the hidden layers.",
            "Will it rain a bunch of neural Nets with these different choices of hyperparameters?",
            "And then we're going to look at the performance on the validation set.",
            "And when I say that, I mean usually for classification network, you look at the classification error, because that's really what interests you.",
            "So we're not going to look at the log probability of the correct class or the negative log property of the correct class.",
            "We use that for training, because this is a differentiable loss function, so we can get gradients.",
            "But for validation, where we will never have gradient.",
            "So essentially we'll just do this trial and error, and then we might as well use the loss that really interests us for classification.",
            "It's the classification error.",
            "So in the validation set we compare different networks trained with different hyperparameters, and then essentially we're going to pick the best one based on the validation set error and to get an unbiased estimate of what is the performance of that network.",
            "We're going to evaluate it on a test set, so I think that's something you know about and Pascal as discussed before, so that's what I mean by model selection essentially, and the goal of course is to do as well as possible on the test set.",
            "But of course, without cheating, that is.",
            "Without introducing any biases in our estimate of that error."
        ],
        [
            "So.",
            "One of the very few different approaches for selecting hyperparameters, and actually fairly recently there's been more more progress on understanding what are good strategies for that one which has been used a whole lot is what's called grid search.",
            "That is, for all your hyperparameters, which you'll do is that you'll define a set of values for each of them, and then you're going to try all combinations for all values of these hyperparameters.",
            "So if you have two hyperparameters.",
            "Number of hidden units and learning rates, and if you specify 10 values for each, you're going to have 100 different combinations.",
            "You're going to train 100 different neural Nets, so it's called grid search, because you could think of this as like.",
            "You know, one defines the ticks of the grid and saying you know the Y axis and the other in the X axis, and so all combinations really are.",
            "This points on that grid formed by these sticks.",
            "The problem with this is that it's going to explode.",
            "The number of hyperparameters you're going to want based on this procedure to test or two to number of to validate.",
            "So more recently, James Bergstrom Yoshua propose instead to investigated really well the idea of doing instead random search.",
            "So here it's a bit similar to Grid search but has some much better properties.",
            "What will do is that we will define for each parameter an set of values, or if it's a continuous parameter, maybe arrange.",
            "And we're going to determine a distribution over these values, so if it's the learning rate, well, maybe I'll take a log uniform distribution between 0.001 and 0.1 and for the number of hidden units, maybe a uniform distribution on the integers from 10 to 100, and I imagine I have a cluster, but I have only so many machines I have maybe 20 machines or 40 machines, So what I'll do is that so I have a sort of computational budget.",
            "Well, the grid search.",
            "It's sort of annoying to try to figure out what values where I put on that red such that I don't go over these 40.",
            "Computers that I can use for random searches super trivial.",
            "You just say I'm going to sample 40 values from these marginal distributions for parameter.",
            "So in my example with the learning rate and a hidden layer for each machine, what I do is that sample from the distribution for the prior distribution I determined for the learning rate simple value do the same thing for the number of hidden units.",
            "Launch that job on computer one.",
            "Sample a new pair learning rate hidden units for the second machine.",
            "Trained that on computer to an continue like this and so here.",
            "You really control separately the ranges of values are going to try for the hyperparameters, and the number of jobs you're going to train.",
            "So it has this really nice feature and you don't really have the problem with grid search, which is that maybe one point on your grid will not finish because the computer crashed down or something like this.",
            "Since you're sampling in dependently, all of these points and random search well.",
            "If a computer crashes, well, that's as if you never actually tried this value, and it's not like a point is missing on the grid, so it has these nice properties that make it very convenient.",
            "Again, in each of these cases, the validation set.",
            "This used to determine what is the winner choice amongst all of these values of hyper parameters and then you can always go back if you.",
            "If you've identified that on your grid, it always picks the smallest or biggest value for one in the hyper.",
            "Suggest you should use if it's the smallest smaller lower value or larger larger value for the hyperparameters.",
            "If kept choosing the largest value so we can refine your grid or distribution and go back and do a few more experiments.",
            "That's how people have done like these experiments with finding parameters for neural Nets for a long time, and more recently allowed with random search.",
            "I wanted to talk quickly about more recent developments in using essentially machine learning to tune these hyperparameters for neural Nets.",
            "So we could think of this problem of guessing what is the performance on the validation set given some hyperparameter values as a function that I would like to learn, and I have a bunch of machine learning.",
            "You know algorithms I could use maybe 2 to learn that function that relationship so this is what has been explored under the expression or Bayesian optimization or some other use and they are slightly different.",
            "But sequential model based optimization.",
            "Their idea is fairly simple, so we're going to use machine learning to predict the performance on the validation set and we're going to use that train model to suggest what should be the next hyperparameter that I try.",
            "So we're going to alternate between suggesting hyperparameters based on the model that I've trained on the experiments I've done so far.",
            "And then I run the experiment I get.",
            "What is the validation set performance?",
            "I add this to my training data for my validation set performance predictor.",
            "I retrain my model and then again a new suggestion to have this loop like this which is like retrain my predictor validation set performance.",
            "Get a suggestion out of this, I get a validation set performance.",
            "I retrain and so on.",
            "These items usually require that the model the machine model you train has to output a mean and variance, so it needs a form of confidence in its prediction.",
            "So the mean will essentially be in expectation.",
            "I expect the validation set performance to be that and the variance is going to be, but I more or less certain about what that value is going to be.",
            "So in Bayesian optimization, the machine learning algorithm is used to make that prediction is Gaussian processes, which I will not talk about, but just think of it as a black box that trains on the set of points that does regression, and when it does regression prediction, it gives you not just a mean prediction but also a variance which is its confidence in its output.",
            "See ahead, yes.",
            "You should, I think, the right way to think about it is more like the.",
            "It's like the beige and variance that is.",
            "What is my confidence in my prediction?",
            "So it's more like you know, like there's a frequentist way of interpreting the variance, which is, like, you know, the results of doing this experiment, observing the spread, and so on.",
            "And here in Bayesian optimization, you're the way it works is that you actually say a priority.",
            "I think the function looks like something and then based on points you observe, then you can say, well, I expect the value to be like this, but have that much uncertainty of what about what this value could be.",
            "Given what I've seen so far, so that's more.",
            "I think the more appropriate we have interpret that variance.",
            "So I'm just going to give you like a cartoon, description or illustration of how this works."
        ],
        [
            "So imagine that we have just a single hyperparameter which is on this line.",
            "Here the X axis, and imagine that the dotted line that you're seeing here.",
            "I should say this lies come from Ryan Adams who made this in.",
            "It's really interesting illustration.",
            "That's why I'm using it here.",
            "So imagine that this is the performance for different values of the hyperparameter on the validation set, so actually varies quite a bit.",
            "It's a non convex function and what I'd like to ideally is to find the minimum which is here that's.",
            "Where do I get the lowest validation errors in?",
            "OK, and imagine so far I've tried these two points.",
            "I've tried this value of say the learning rate and this order value, and I've observed that value of validation set error and this value of their validation set error.",
            "Now because I have an algorithm that gives me not just an expectation over what my prediction is for different or new validation set point or new.",
            "Sorry, a new learning rate also have a variance.",
            "That's why I see this curve here.",
            "So the solid line is this.",
            "Expected.",
            "A value for the validation set performance based on my Gaussian process and the width of this Gray area reflects the variance of the prediction.",
            "So what this means is that I expect the value to be about the same as this one here.",
            "For that choice of the learning rate at this position in the X axis.",
            "But I have a lot of uncertainty about that actual prediction.",
            "So because I have an expectation and the variance and in the Gaussian process, because this is the expectation of the variance of a Gaussian, I can compute something like which is not the expected improvement.",
            "So what is the improvement?",
            "The improvement is going to be if I try a new configuration of my learning rate, the improvement is going to be what we call improvement here is going to be the previous best value that I found if the new learning rate doesn't improve on it or it's going to be my new best.",
            "So essentially what the expected improvement you should think of it as it's essentially what is going to be my new best value after I tried this experiment.",
            "OK, and it turns out that if I know if I assume that you know the validation set performance on that new point is going to follow a Gaussian with this mean and this variance I can compute analytically what this expected expected improvement is going to be OK, So what is the expectation of the new best value?",
            "And yes.",
            "Yep.",
            "Um?",
            "OK, so so the question is, even for one value of the hyperparameters.",
            "There's no the question initialization is going to be important, and that is true to some extent.",
            "Just show the I'll show the the simulation and then we'll see whether I'll try to jump back to your question.",
            "So OK, an actually I misspoke.",
            "So the expected improvement the improvement is going to be 0 if I haven't done better than before, and it's going to be the difference between the my previous best configuration an my new best configuration if I do better.",
            "OK, so that's the expected improvement, so you can see that after two points, my expected improvement at Triangle Point, which is exactly 1 configuration I've tried so far is zero.",
            "I don't expect to improve at all because I know what is the value of the validation set performance at that point.",
            "Same thing here and you can see that as I go further away from the eye providers that I've tried, the expected improvement increases and increases because I have uncertainty about what the exact value is going to be OK, and the lower that point.",
            "Is well, the more likely I'm going to improve next to it because it's a good configuration compared, say to this one where we can see the expected improvement doesn't increase as rapidly as we move away from this configuration.",
            "So, and what is nice is that this expected improvement quantity is something that is continuous with respect to the value of the hyperparameters.",
            "So it can actually optimize that curve.",
            "So I can do gradient in this case ascent 'cause I want to get the point with the highest expected improvement.",
            "I think I can do gradient descent on that function Now, it's nonconvex, so we're going to try a lot of different points and from one point we're going to increase the expected improvement by gradient ascent.",
            "Agreed to send procedure so that you know I'm more likely to cover all the local Optima, but with these two points, well, the best configuration, which I would find is this one here.",
            "So my next experiment I'm going to use that value of the hyperparameter.",
            "Then I asked my Gaussian process OK, what is now your prediction and your variance over the validation set performance for different values of the hyperparameter.",
            "And now you see my expected improvement has also changed, reflecting the fact that I know now what is the performance here and now the new point with the best expected improvement is this one.",
            "So that's going to be my new parameter that I'm going to try.",
            "An I get a value like this which is a bit higher than what is the current best, which I think is here so you can see that expected provement in that region has increased as decreased quite a bit and I'm going to focus in other areas of the region where which has some potential and I it's a compromise essentially between do I see lovallo value of my validation set error an my fairly uncertain about what the value could because I haven't explored that so much, so that's the new best point and I continue like this.",
            "Eventually converging to the best point.",
            "OK so.",
            "This so going back to your question where the initialization might have an impact is the fact that when I'm proposing a new point, I do have to solve a problem, which is a nonconvex optimization problem, and so the initialization is essentially which points am I going to start with?",
            "Doing gradient descent to find the best point with best expected improvement.",
            "So in that extent, yes, it's going to have an impact whether you so.",
            "Usually we do Sobel sequence Grid over the space if it's in two D3D and so on.",
            "And then for each of these points, we optimize the expected improvement as much as we can, and we take the best one.",
            "There's no guarantee we actually get the global optimum.",
            "They expect an improvement while you practice.",
            "It works really well.",
            "So I just that's just a cartoon and not very detailed description of how this works, but I really encourage you to look at the literature.",
            "It's used more and more so either look for Bayesian optimization or sequential model based optimization.",
            "So my colleague Ryan Adams and Jasper Snook of series of papers trying to adapt this simplistic scenario to other cases, like when you want to do experiments in parallel and so on.",
            "Frank Hutter is another researcher that has a lot of really cool work around this idea, so I encourage you to.",
            "Look that up.",
            "Alright, so um.",
            "OK, for so that's something we can use these different methods for selecting the hyper parameters that we can use for most hyper parameters for the number of epochs.",
            "So a number of iterations of gradient descent.",
            "What we usually do instead of treating it as a normal hyperparameter is we use a procedure known as early stopping.",
            "So the idea is that as we know, we as we increase the capacity in this case, if as we increase the number of iterations of gradient descent, I expect the distance or the difference between the training performance and the validation set performance to increase and the."
        ],
        [
            "Ideas that we'd like to find the sweet spot.",
            "The number of epochs where the validation set.",
            "If I had trained a bit less, would give me a worse error, but if I tried a bit more I would have also worse error.",
            "So this sweet spot between an underfitting scenario and an overfitting scenario.",
            "And since the number of epochs is something that I can just increment and reuse the network that I've trained, say after 10 at box and just trained it one more epoc and check the validation set performance, this suggests a very simple way of selecting the number of epochs, which is I start with, say, one epoc.",
            "I look at the validation set performance and then I check.",
            "Is this the best I've achieved so far?",
            "Yes, no, and I continue one more impact.",
            "If I improve the validation set performance, yes no.",
            "And I continue like this.",
            "Until I reached this point where I've actually.",
            "So in this case I reached this point, it's the best so far.",
            "I do one more iteration and then it's become worse.",
            "So this suggests that maybe I should have stopped before.",
            "OK, now this is like more like a cartoon illustration.",
            "Sometimes you will see a bit of going up and down of the validation set performance so often what we do in practice is that we use something known as look, look ahead.",
            "That is when I don't, I'm going to allow the network to continue training for say 10 at box.",
            "Even though the validation set performance hasn't improved, just in case it went up for two epochs, but then it went much further down after because that's something that can happen.",
            "So this lookahead idea is something that we actually use in practice.",
            "We don't stop as soon as it gets worse, and also small detail, but that's important.",
            "When you've identified the number of epochs, that's the best what you want to do is go back to the weight configurations of your network that corresponded to that best value.",
            "So you don't want to stop there and use that network, as this one is worse 'cause you've stopped.",
            "You want to go back to the network that had the best validation set performance, so usually you have to do bit of bookkeeping where you copy the connections of your network and flag it as your best so far, and that's the network you go back to.",
            "Once you achieve this early stopping condition.",
            "Question yes.",
            "So you know, typically you don't.",
            "There are so you could.",
            "Anyways, this is more like events reach research ideas, but you might want to like.",
            "It could be that you could identify that a number of hidden units and number and value of the learning rate is bad just from like 2 epochs.",
            "And then stop just because you know you should give up that selection hyperparameters, but that's something that's not currently well developed and people are exploring.",
            "So currently when people use Bayesian optimization, they don't use it for that.",
            "So you just assume that for the for the number of epochs.",
            "This is the procedure you're going to be using and for all the other hyperparameters you might want to use Bayesian optimization, yes?",
            "Yeah.",
            "Yeah.",
            "Yeah.",
            "Yes, you are doing a number of iterations so it it could be.",
            "It depends a lot on how many iterations you actually do.",
            "So random search initially is going to look and Bayesian optimization are going to perform about the same because Bayesian optimization is solar blind for the first few iterations it is more or less replicating random search.",
            "It's more after quite a few iterations that now you might have.",
            "You know you might actually have a better model of what is the relationship between the hyperparameters and the value on the validation set.",
            "But if you want, we can talk about this more after.",
            "Yeah.",
            "Yep.",
            "It's a validation set last year just to be oh sorry, so you mean for training the neural net?",
            "Yeah.",
            "Yes, so use.",
            "So OK, so the question is if you have the global optimizer that guaranteed you to find the best configuration of the neural net parameters for the training error, it would be a very bad idea to you know.",
            "Would it be a very bad idea then to actually use it for training and it is true unless you have hyper parameters that control the capacity of the network.",
            "So regularization will mean that you are penalizing potentially the best performing under training.",
            "Set in terms of its error, you are penalizing that configuration, so This is why we would talk about.",
            "You know, having a compromise between bias and variance.",
            "In this case regularization, which is going to control the amount of capacity that you that you can essentially explore, and finding a good solution to your problem, you would essentially use model selection on this validation set to control the amount of regularization you would impose to the training procedure.",
            "So that's how you would, you know.",
            "Make sure that your global optimizer Google Optimiser doesn't overfit by controlling this capacity with your hyperparameters.",
            "Alright.",
            "So I think I've."
        ],
        [
            "One of my slides, but not half my time, so let me go quickly on other things.",
            "OK, so I want to mention a few other or you could call tricks of the trade so things that people use when they train your neural Nets and."
        ],
        [
            "That either does improve the results or make your life easier when you're training them.",
            "So someone mentioned normalizing your data.",
            "That is, take each dimension of your input space.",
            "Subtracting the empirical mean, dividing by the empirical standard deviation.",
            "That is something that will often speed up training if your dimensions are real valued.",
            "If you have dimensions that are is a binary 01, normalization like this is not necessarily going to help you.",
            "You should stick with 01, but for real valued kind of.",
            "Input distribution normalizing the inputs have been shown to speed up training in terms of the number of epochs.",
            "It also helps to decay the learning rate so intuitively, because initially we are very far from what is probably Internet that classify as best you can probably allow yourself to do.",
            "Bigger steps when you do a gradient step, but as you get closer to the solution you might want to take more refined, smaller steps towards the optimum Ann.",
            "There are a lot of optimization methods that will implicitly decay the neural net learning rate.",
            "Little might talks about some of these later.",
            "1.",
            "Essentially realistic that people have used a lot that tends to work well is to start with a large learning rate and then you track kind of like early stopping.",
            "You track the validation set performance once it starts getting worse, you go back to your previous best neural net and you continue training, but you divide your learning rate by you take a fraction of your learning rate, so maybe you divide by two and then you continue training from that best point so far.",
            "And then once the validation set their performance.",
            "Again, starts getting worse.",
            "You read the value learning rate by two, going back to your best point so far, and you continue like this.",
            "Maybe you repeat this five or six times, so that's a procedure that automatically gives you a learning rate schedule with the learning rate is decreasing based on your validation set performance."
        ],
        [
            "In practice, we also mentioned that or there was a question whether we should be using.",
            "You know, one example per update or a mini batch.",
            "So indeed, in practice people use mini batches.",
            "That is, you take if you have a data set you're going to take a subsample of size 64, maybe 128, partly.",
            "The reason for doing that is that gaining all of the outputs for all the examples in that mini batch can be expressed as matrix matrix multiplies.",
            "When you do this linear transformation, instead of doing one vector one input vector times matrix, you can now do the whole mini batch matrix.",
            "Times the connections and that's going to be faster than doing as many matrix vector multiplications, so that's part of the reason.",
            "The reason is that you are going to get a.",
            "So in this case you're computing the average gradient for that mini batch, so it's going to be less variance in the.",
            "It's going to be a better estimate, essentially of your gradient, so you also gain that, and so in practice people often use this and in terms of you know how fast you're going to train your neural Nets.",
            "You do get improvements.",
            "Often people also use something known as momentum, so the idea is that instead of using just a gradient for that mini batch as the update direction, I'm going to use a combination of my current direction for my mini batch an what is the direction that I use for updating my parameters in the previous update, so I'm going to take my previous direction multiplied by a momentum factor, which is better.",
            "I'm going to add this to the average gradient for my mini batch and that's going to be my direction for this current update.",
            "OK, So what this allows is that.",
            "If you fall into the optimization problem, falls into a region where you have a plateau.",
            "That is, you have a very slowly decreasing region of the hyperparameter space, but if it always points in the same direction, then you can gain momentum.",
            "That is, all these grain is going to point the same direction, so they're going to accumulate like this, and you might go faster than you would otherwise if you had not used momentum, and if the gradient start to disagree while they're going to cancel each other in the directions where there's so where you shouldn't, maybe move as much so.",
            "Momentum is another thing.",
            "It adds a hyperparameter, but it can make a big difference."
        ],
        [
            "And finally, so if you're going to use storage or Theano and use the components that are part of the library, you are pretty much guaranteed that their gradients are computed correctly, at least if you don't use the development version.",
            "I guess if it's development version, you have fewer guarantees, though I think usually it's fine if you are going to develop your own modules, it needs to compute gradients and needs to output the gradient.",
            "I highly recommend.",
            "That when you do this, you use the finite difference approximation to compare your gradient computer by your code and the estimate of the gradient.",
            "That is for each parameter in your module you take a step of epsilon forward.",
            "You look at what's the value of the output of your module.",
            "You also take it step backwards and you take the difference in divide by sensory.",
            "The difference between these two points to epsilon and that's going to be the partial derivative in that direction for that parameter, and you compare that.",
            "With what your code actually computes as the gradient, and the difference should be very small, so I say this because you would think I don't need to do this.",
            "If I'm wrong, then probably won't train and I'll go back and check my gradients, but it's surprising to what extent and know that can work if only a small part of it has bad gradients and other parts will to some extent possibly accommodate for the fact that a part of your network is not training properly.",
            "So do not use that as indication as.",
            "Whether there's a bug or not in your code, do check your gradients like that.",
            "If you're implementing a new module.",
            "If using all the modules already in Torch or Theano, you should be fine."
        ],
        [
            "Alright.",
            "Question yes.",
            "Yeah, so now I think this finite difference is, you know, usually sufficient, yeah.",
            "Other questions.",
            "OK so I have like 6 minutes left.",
            "An much more material so I'm going to try to go fairly quickly.",
            "The slides are are there anyways and some of it I actually talk about in the online course.",
            "We can go check it out so.",
            "Essentially what I want to talk about now is that all of what I've discussed so far are more or less things that were known.",
            "You know, 15 years ago or 20 years ago.",
            "I've been development since we've started talking about deep learning, which is just sort of a new expression for talking about.",
            "You know, neural Nets, and these developments were inspired by the fact that we really wanted to train neural Nets that were very deep, but often we had little success doing that.",
            "So essentially there were attempts to try to fix this difficulty of training that we had identified in training deep neural Nets."
        ],
        [
            "So there's actually two things that can happen.",
            "And the first hypothesis for why you might have difficulty training at deep neural net is that essentially the problem you set up in training this know that this is a hard optimization problem, and you're having a hard time fitting your training your training set so you are more in Underfitting regime.",
            "One thing that can be caused by this is this vanishing gradient problem, where we notice that you might notice that the gradients for your weights at the first layer are much smaller, so the signal is weaker more intuitively than the grades at the top of the layer.",
            "OK, this is actually a well known problem if I think you have lectures on on record Nets, this is a problem that's particularly present when you're training record neural Nets.",
            "I won't say much more."
        ],
        [
            "That and there's not second hypothesis which it might be.",
            "You're overfitting and.",
            "The reason might be that you know when we are considering not just one hidden layer, but multiple hidden layers where we're increasing the capacity of our models.",
            "So where essentially in a regime where we have increased the variance of our.",
            "Estimate of our training procedure.",
            "If you increase the number of parameters, there will be many more configurations of your neural net that can fit perfectly your training data, so effectively increasing the variance, and so you might be in that situation instead.",
            "In this case, you'd want to somehow get to a better trade off and find a better way of regularising, so limiting the capacity of your neural network."
        ],
        [
            "So I guess since you know we've, I guess we could call it the creation of deep learning since we coined that term.",
            "There's have been developments in trying to tackle either of these two issues.",
            "So one of them.",
            "So for the first hypothesis, if you think that the problems I'm underfitting part of this has been solved by the fact we're using GPS, we can wait longer when we're training and roll net if you're known that is stuck in a regime where it's in the plateau, while if you're using a GPU, you might not notice the plateau as much as we did before.",
            "OK, so that solve part of the problem.",
            "Which is better optimization methods?",
            "I think Liz going to talk a bit about that fully half the time.",
            "I'll talk about batch normalization, which is you can think of as an attempt to try also to optimize better an if it's more like the second hypothesis.",
            "That is the problem that you're facing and training deep neural Nets will use better.",
            "You need to use better regularization and I'm going to talk about two ways of doing that.",
            "The first one is to use unsupervised learning to get better regularization and the other one is to use something known as dropout.",
            "To better recognize your new."
        ],
        [
            "Net.",
            "Alright, so I'm going to quickly talk about unsupervised pretraining.",
            "So the idea here is that if we think that on deep neural Nets are not sufficiently regularised, we need to somehow restricta potential solutions that training, well, fine.",
            "When training on a data set, and the idea behind unsupervised pre training is that amongst all neural Nets amounts all configurations of the weights of the neural Nets that will want to explore.",
            "We want to restrict ourselves to neural Nets that understand the difference between essentially.",
            "Real data and any other type of data such as random data.",
            "So we'd like to know.",
            "Net where the hidden units sort of understand that this is a well formed image of a character irrespective of what the identity of that character is.",
            "And this isn't OK."
        ],
        [
            "So known as that to some extent this is actually a harder problem than just classification, because presumably it would help to know that this is, you know, a good signal that that comes from my training distribution.",
            "If I knew that there were zeros and ones, and twos and threes, and so on.",
            "So amongst when I'm training this deep neural net, what I want to do here is to add some unsupervised learning signal such that my hidden units are not just good at predicting the target class.",
            "There.",
            "They also aware that.",
            "You know, I expect things like this and I don't expect things like that."
        ],
        [
            "So you're going to see a lot of unsupervised learning algorithm during this summer school.",
            "I'm going to talk about a very simple one, which is the auto in quarter.",
            "It's not the one that's used the most currently, but it has been used as like a first step to another better learning algorithm, unsupervised learning algorithm.",
            "You're going to see denoising autoencoders.",
            "For instance, I think this game is going to talk about that, and it's based on this so.",
            "So there is a feedforward neural net.",
            "Yeah, I'm showing one with a single hidden layer by which at the output tries to compute a reconstruction of its input.",
            "So now instead of trying to predict that the output able Y, we're actually going to try to predict the input, reconstruct the input.",
            "So this is what I'm calling X hat here.",
            "So for that we need to define the last function.",
            "If you have data that's between zero and one one loss, that's often uses the cross entropy.",
            "It's more precisely the sum of Bernoulli cross entropies, so X hat K is going to be the reconstruction from the cat dimension of my input space, so I get this by doing a linear transformation in my hidden layer and passing that through a sigmoid so I get a number between zero and one, and I'm going to compare that with the true input, which might be binary or might be between zero and one.",
            "OK, so if I talk a bit I give more details about this in my online videos, but if you look at this you'll see that the best thing you can do is have X hat K match XXK.",
            "If you have real value data which is not between zero and one we often use instead the.",
            "Squared difference.",
            "For the squared distance."
        ],
        [
            "And so that's what algorithm that we could use, and you can see that if I'm trying to reconstruct the input where I need to learn something about the structure, what you know what these inputs look like if I'm trying to reconstruct images of digits, handwritten digits, it might be useful to have hidden units that detect different types of pen strokes, because that's how we write digits.",
            "We essentially draw pen strokes and to encourage the hidden units to be safer handwritten character classification to detect these pen strokes.",
            "What we'll do is that will train in a greedy way.",
            "Each hidden layer as a note on quarter.",
            "So we'll start by training the actually pre training the first hidden layer as an auto encoder.",
            "That is, I'm going to compute my hidden layer and then I'm going to try to reconstruct my input and I'll do that for a certain number of iterations, which is going to be a hyper parameters and then after some time I'll stop out, freeze these weights and then compute the value.",
            "The representation of the first hidden layer of all of my inputs.",
            "And I'm going to train my second hidden layer to reconstruct the first hidden layer representation of my inputs.",
            "So learn good features of my first hidden layer.",
            "I do this for certain number of time and then I fix these weights and I repeat this for the third hidden layer and so on until I've pre trying the number of hidden layers that I want."
        ],
        [
            "So the first thing layer features will hidden units will correspond to features that are coming in training inputs, but not necessarily in random inputs because they're not training random inputs.",
            "They're trained on my input distribution.",
            "Second layer is going to be combinations of hidden unit features that are more common than random combinations, and so on.",
            "Yes.",
            "Yep.",
            "So.",
            "I think that we found other regularizers that are there at least is good and I think that currently anyways.",
            "Unsupervised pre training is more useful in the setting where you have a lot of unlabeled data that is.",
            "So the question sorry is that also by switching is not something that's actively used currently.",
            "If you look at different papers it's not used a lot.",
            "Small used in the in this context of semi supervised learning because of since I don't need labeled data to pre train these hidden layers, I can actually do this on a lot of unlabeled data and then move to my labeled data set to do what is the fine tuning without presenting a few.",
            "So the latter networks right?",
            "Yeah, yeah.",
            "So that's one example where there is unsupervised pre training and we're able to do really well with just a few label examples by exploring a larger set of unlabeled examples.",
            "That's not semi supervised learning.",
            "Yes.",
            "So not really.",
            "I think.",
            "I think I'll talk a bit about the relationship between you know, denoising auto encoders and trying to interpret them as as generative models also talk this afternoon about a version of autoencoder which is a generative model, but I will say that I can definitely tell you that what we came up with the idea we did not have a generative model in mind, that's that was not what I had in mind anyways.",
            "But we studied it and turns out there's some interesting interpretations.",
            "OK, I'm I'm going to move on because I have almost no time.",
            "Take questions after, by the way, you know during the coffee break no problem so."
        ],
        [
            "So anyway, so that's the pre training algorithm.",
            "I just wanted to quickly you start from your input layers and then what you do is that you Rep you construct an unsupervised data set by mapping your inputs to the layer you've pre trained so far.",
            "So initially featuring no layer.",
            "So the representation is going to be the right input.",
            "You feed that to an unsupervised learning algorithms such as the auto encoder and GBM is another option.",
            "You'll learn about that later this week.",
            "Do this for all layers and now this all serves as an initialization step, so you essentially replace this random initialization with this unsupervised learning based initialization and then after that you do what is called fine tuning, which is really backdrop.",
            "That's backdrop that I've described so far, so we initialize the top weights connecting with the output as you normally do random initialization, and then you do stochastic gradient descent with mini batches like you did before.",
            "So really, here we're just introduce a different way of initializing the parameters of a deep neural net.",
            "I'll just."
        ],
        [
            "Start.",
            "Another option for Regularising Underall net or deep neural net."
        ],
        [
            "That particular is dropout."
        ],
        [
            "This was proposed fairly recently.",
            "The idea now is to avoid overfitting.",
            "You can think of it as we're trying to cripple training of the neural net, and we're going to cripple the training process by removing hidden units in a stochastic way.",
            "So for each hidden unit.",
            "Will determine which probably 0.5 whether we're going to zero out that hidden unit we're going to multiply it by zero.",
            "OK, so an we independently for each hidden unit, determine whether we're going to do that or not.",
            "So, say in this case I've sampled that I would multiply by zero here and here, but not here, here and here.",
            "OK, so effectively if I multiply by zero, it means that it's as if these connections going into and out of these units don't exist.",
            "They're not even present.",
            "There are not going to be trained.",
            "When I do my backpropagation because their gradient is going to be 0 because they don't impact the output.",
            "So this probability of 0.5 is a hyperparameter, but conveniently, 0.5 tends to work well.",
            "You can also do that on the inputs, usually with a smaller probability.",
            "But sometimes some people do that as well.",
            "Ann, this sampling of this dropping out pattern you do for each update, so that's something that you do every time before you do an update, you sample these masks, the sampling these masking patterns.",
            "OK, so more specifically, the way we update the feedforward equations is just by adding this element.",
            "Wise multiplication.",
            "Uh Vay mask vector, where you've sampled each dimension by randomly picking with 0.5 probability where it's going to be 1.",
            "Or 0.",
            "OK, and that's all that changes at training time."
        ],
        [
            "So backdrop is changed.",
            "Also, you have to take that into consideration and backdrop first by the fact that, well, the activations.",
            "Now I've been computing using these masks and also when you back propagate to the lower layer, in addition to multiplying by the derivative of the activation function, you're going to multiply by the mask so you can see that some of the gradients are going to multiply by zero.",
            "They're going not going to back propagate."
        ],
        [
            "Not test time because we all want something stochastic.",
            "We replace the masks by their expectation, which is your .5.",
            "So we multiply by this constant vector with 0.5 everywhere and there is an interpretation of this where in the hidden single hidden layer case it actually corresponds to taking a geometric average of all the different neural Nets, with all the different patterns of dropping out.",
            "That's something that you can show which was in part the inspiration for doing this.",
            "The other reason why or one way of understanding why this helps is that if as a hidden unit you are not guaranteed that.",
            "Other head units are going to be present are not going to be dropped out then your feature out to be useful by itself.",
            "OK, so essentially the neural net is going to grow features which don't Co adapt with other features that are going to be more independent.",
            "Lee useful.",
            "There is another way of thinking about it.",
            "There might be some redundancy.",
            "So that's a good question.",
            "I'm not sure whether there is a lot of redundancy.",
            "I can definitely tell you that this very often helps.",
            "That's the feature is also visually 10 to be more interpretable than features you get with regular background."
        ],
        [
            "OK, and then the final trick that I really wanted to talk about because you're probably going to hear about it this week, and I don't think anyone else is going to talk about it is batch normalization."
        ],
        [
            "So this is a more recent trick, and what's interesting is that if you look at the paper, they will show that training is faster.",
            "Norms of number of epochs, it tends to converge faster in terms of learning and also.",
            "But somehow it seems to also have a regularization effect.",
            "That is, people have noticed that when they use it, they don't necessarily need to use dropout anymore to get good results.",
            "So I think we're still.",
            "Trying to understand what is going on.",
            "Why.",
            "Anyways, I am still trying to, you know.",
            "Finally understand what's going on with batch normalization but the idea."
        ],
        [
            "Is essentially that if normalizing my input layer helps, maybe it would help if I normalized other parts of the network at the hidden layer level OK, and so that's essentially what batch normalization tries to do.",
            "The few key things to remember the normalization, where we subtract by the mean and the virus standard deviation is going to happen, not at the activation, not after the non linearity but before the non linearity.",
            "Let's first thing to remember.",
            "When we to get the mean and to get the standard deviation, we're going to get it from the current mini batch, not the global mean or global standard deviation from the current mini batch.",
            "Back propagation is going to take into account this.",
            "It's not going to treat the mean and the standard deviation as constants, so gradients will flow through the computation of the mean and the computation of the standard deviation and at Test time we replace this mean and standard deviation by the global mean and the global standard deviation that we will compute once and for all, and then we can deploy this network and apply it on new data.",
            "OK."
        ],
        [
            "So this is essentially the transformation.",
            "It's taken out of the paper.",
            "So imagine X say.",
            "X. I is going to be Despres activation of a given unit and this XI up to M is just all the pre activations of that unit in the mini batch.",
            "So if it's mini batch of size 64 or 64 numbers here.",
            "So this is just computing the mean, computing the variance and I'm taking the square root with a small constant in case the variance was zero so it's numerically stable.",
            "There is one thing here that batch normalization does is that before feeding instead of feeding X hat to the activation function.",
            "I'm actually going to feed a linear transformation of it, so I'm going to multiply it by a scalar gamma and then add a bias better, and these are now part of the parameters of the network.",
            "I am doing gradient descent on these parameters as I train them.",
            "So the reason we have this is essentially to make sure that you can essentially explore all of the range of the activation function.",
            "So if you were to normalize everything by removing the minion, dividing by the standard deviation with the sigmoid, you'd be stuck in the linear regime always, so this allows it to sort of explore saturation regime, but at least it gets an input which is normalized, so it's going to be in practice we say it's better behave this way."
        ],
        [
            "So why normalize the preactivation?",
            "Well, at least initially.",
            "All units are guaranteed not to be in the saturation regime, so that might be helpful.",
            "Even though the linear transformation can cancel this effect, but it would be later on in learning while use many matches, well, because we're normalizing units, the normalization depends on the parameters and the parameters are constantly changing while we're training, so we don't want to go over the whole training set every time we need to compute or update this mean and standard deviation.",
            "So we use a mini batch instead, and it adds some stochastic city in the computation on a network, which might be useful.",
            "It might act as a sort of crippling effect that dropout has, which seems to bring some regularization, and in fact they do notice in the paper that proposes that they don't need dropout as much anymore."
        ],
        [
            "It's taking into account normalization by backpropagating the gradient through the mean, so remember that when I'm computing the mean and standard deviation, my pre activation is present in that mean, and that standard deviation.",
            "So I need to take into account the gradients.",
            "The gradients are so as exercise.",
            "I encourage you to look at the paper they provide the gradients just check whether you can derive them.",
            "So this is the kind of exercise you would have to do if you want to propose a.",
            "A new method or a new module in a neural net, so it's a good exercise to try out.",
            "And use a global mean at Test time.",
            "Well, so that it's not stochastic once you apply it.",
            "Alright, so I had other stuff but that was more or less optional, so I'm going to stop here."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, thanks for the intro everyone.",
                    "label": 0
                },
                {
                    "sent": "So yeah so today what I'll do is I guess pick up from where Layonne stopped and try to go a bit further into giving details about how to train deep neural networks.",
                    "label": 1
                },
                {
                    "sent": "In the description of the talk of supposed to give, there's a mention of back prop in it, but I see that Leo has already presented that yesterday, so I just wanted to see.",
                    "label": 0
                },
                {
                    "sent": "Raise your hand if before the summer is cool, you had seen backdrop already.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you had not seen backdrop, that's going to be more useful.",
                    "label": 0
                },
                {
                    "sent": "If you had not seen backdrop, can you raise your hand?",
                    "label": 0
                },
                {
                    "sent": "So either you're shy or there's like no one.",
                    "label": 0
                },
                {
                    "sent": "So what I'll do is that I won't arrive back rough.",
                    "label": 0
                },
                {
                    "sent": "Well, I didn't have time to count I, you know I'm I don't have that autistic, you know, kind of ability.",
                    "label": 0
                },
                {
                    "sent": "But So what I'll do is I won't derive backdrop.",
                    "label": 0
                },
                {
                    "sent": "But and you to resources where you can, if you really want the details, when you can actually get the details of it, alright so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, some of what I'm going to present is part of an online course which is available on YouTube, so you might know about it.",
                    "label": 0
                },
                {
                    "sent": "This is where you can go find the details about backdrops.",
                    "label": 0
                },
                {
                    "sent": "I go through, you know, painful steps of deriving each and every single part of backdrop.",
                    "label": 0
                },
                {
                    "sent": "So if you want to really sort of master the different steps that go from you know the basic idea of the chain rule and so on into the actual instantiation of backdrop for.",
                    "label": 0
                },
                {
                    "sent": "Classification neural net.",
                    "label": 0
                },
                {
                    "sent": "This is all described in the online course and other things as well.",
                    "label": 1
                },
                {
                    "sent": "I talk about our BMS convolutional Nets, so this can be also useful resources if during the week you have thank you forgotten about certain topics again, of course, go back to the slides and also have some explanations that offer you on YouTube right there.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the slides I'm going to use today are from that, but not all of them.",
                    "label": 0
                },
                {
                    "sent": "There's some new stuff as well.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh and also please do not hesitate to interrupt me if you have questions.",
                    "label": 0
                },
                {
                    "sent": "That's totally fine.",
                    "label": 0
                },
                {
                    "sent": "It's going to wake me up.",
                    "label": 0
                },
                {
                    "sent": "It's going to wake you up.",
                    "label": 0
                },
                {
                    "sent": "This is going to be better all around.",
                    "label": 0
                },
                {
                    "sent": "Alright, so OK, so I'm first going to do a little wrap up of some of what you've seen, probably yesterday if anything is going to introduce the notation that I've used.",
                    "label": 0
                },
                {
                    "sent": "So this is the notation that I'll be using for a classification feed for neural network.",
                    "label": 0
                },
                {
                    "sent": "In this case with two hidden layers.",
                    "label": 0
                },
                {
                    "sent": "So when you want to compute the output of Internet, what do you do?",
                    "label": 0
                },
                {
                    "sent": "You take the input vector which is X. I'll use bold X bold for a vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so when the letter is bolded and lower case, that usually means a vector, and so each dimension X1 XJXD.",
                    "label": 0
                },
                {
                    "sent": "This is essentially different dimensions of that vector X.",
                    "label": 0
                },
                {
                    "sent": "And when you compute a layer, you first compute what I call a pre activation.",
                    "label": 0
                },
                {
                    "sent": "So I think that's possibly a word you haven't.",
                    "label": 0
                },
                {
                    "sent": "Heard before, but that's what I'll use to talk about the linear transformation from the previous layer up to the next.",
                    "label": 0
                },
                {
                    "sent": "So I'm using K here to indicate the index of the layer so you can see I'm taking the value, so I'm using HH of X as the K -- 1 youth layer in my network, and so for the 0F network that would be X.",
                    "label": 0
                },
                {
                    "sent": "That would be the input.",
                    "label": 0
                },
                {
                    "sent": "I'm going to linear transform it to get my pre activation for the.",
                    "label": 0
                },
                {
                    "sent": "Layer above it, so I'm multiplying by your matrix again, so I'm using these exponent in parentheses to indicate indices of layers, so that's for the connections with The Cave layer plus a bias vector, and that gives me my pre activation using a for the symbol for that, and then I apply an activation function time knowing G here, so that could be a sigmoid function, tangent function.",
                    "label": 0
                },
                {
                    "sent": "Relu, I think you've seen some of those yesterday.",
                    "label": 0
                },
                {
                    "sent": "So we have a non linearity here that's introduced that's applied on the pre activation to give you the activation of the layer and you keep doing this from the first layer up to the last one which is the output layer.",
                    "label": 0
                },
                {
                    "sent": "So those are here are two hidden layers and this is the output layer an at the output.",
                    "label": 0
                },
                {
                    "sent": "Often we use a different activation function depending on the problem.",
                    "label": 0
                },
                {
                    "sent": "I'll be mostly talking about classification problems So what will uses the softmax activation function if you haven't seen it yet?",
                    "label": 0
                },
                {
                    "sent": "The softmax is just you take the exponential of all the elements in your pre activation at the output layer and then you divide by the sum.",
                    "label": 0
                },
                {
                    "sent": "So the exponential gives you a positive number by divided by the sum.",
                    "label": 0
                },
                {
                    "sent": "You get numbers that sum to one.",
                    "label": 0
                },
                {
                    "sent": "So we can interpret those as probabilities that you're assigning and here these are probabilities will assign to the different classes to which the input can belong.",
                    "label": 0
                },
                {
                    "sent": "So the number of units.",
                    "label": 0
                },
                {
                    "sent": "The size of the output layer is going to match the number of classes that we want to distinguish.",
                    "label": 0
                },
                {
                    "sent": "So for instance, there's the in this data set, which is used a lot in deep learning where you have images of handwritten characters, and those are usually the digits from zero to 9.",
                    "label": 0
                },
                {
                    "sent": "So there are 10 classes in this case, with the output layer would have 10 units.",
                    "label": 0
                },
                {
                    "sent": "And so I'm off sometime going to use L as the capital letters, the number of hidden units, sorry, and a number of hidden layers.",
                    "label": 0
                },
                {
                    "sent": "So layer L plus one is the output layer OK?",
                    "label": 0
                },
                {
                    "sent": "Any questions about that notation?",
                    "label": 0
                },
                {
                    "sent": "Makes sense, so we have activations pre activations is before the activation function and each layer is really just a linear transformation which we have here, parameterized by my bias vector B in my matrix W. Followed by non linearity which I'm noting as G here.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we train in their own network and how do we train?",
                    "label": 0
                },
                {
                    "sent": "Most machine learning models really is we're going to use empirical risk minimization.",
                    "label": 1
                },
                {
                    "sent": "Actually, here this is the version that's regularised, so in essentially we're going to frame training a model as an optimization problem, where we're finding the value of our parameters Theta.",
                    "label": 0
                },
                {
                    "sent": "So Theta consists in all the bias is an all of the weight matrices in my neural net, and I'm going to specify.",
                    "label": 1
                },
                {
                    "sent": "A loss function L which compares the output of my neural net with the target Y.",
                    "label": 0
                },
                {
                    "sent": "So why is the true answer the true thing that the ground truth that I'm trying to predict from X and the loss function compares the two as a measure of whether I did or good or bad prediction?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to minimize the average loss.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "Sometimes we add a regularizer so this or make a function.",
                    "label": 0
                },
                {
                    "sent": "Here it takes the parameters and then computes a sort of essentially a value that gives us to what extent we like that configuration of the parameters and I'll talk about regularizers before 'cause I think that wasn't really mentioned yesterday.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So this is the setup in which were mostly going to talk about training neural networks.",
                    "label": 1
                },
                {
                    "sent": "We're going to cast it as optimization problem, where we're optimizing the mean of a loss function comparing the output with the target.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This is an optimization problem, so we need an optimization procedure to find the solution and the algorithm is going to be used almost all of the time in deep learning is known as stochastic gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So how does it work?",
                    "label": 1
                },
                {
                    "sent": "Little is going to talk about this algorithm quite a bit, I think after my presentation, so I'll just present without describing it too much.",
                    "label": 0
                },
                {
                    "sent": "The algorithm itself is just assume from there now that that's what we'll be using.",
                    "label": 0
                },
                {
                    "sent": "We're training neural Nets, so we start.",
                    "label": 0
                },
                {
                    "sent": "By initializing our parameters so that means all of our connection matrices and biases will initialize them often randomly.",
                    "label": 0
                },
                {
                    "sent": "But I'll talk about other ways of doing that.",
                    "label": 0
                },
                {
                    "sent": "And then for a certain number of iterations, these iterations, often we use instead the word apacs for them in neural Nets, so iteration or epoc is really the same thing.",
                    "label": 0
                },
                {
                    "sent": "In my notation here, we're going to pick one of the training examples.",
                    "label": 0
                },
                {
                    "sent": "So a pair XY.",
                    "label": 0
                },
                {
                    "sent": "And then we'll try to figure out a direction in which I'm going to move my parameters, my biases, and my connections.",
                    "label": 0
                },
                {
                    "sent": "So that direction is going to be based on what is the gradient of the loss and the regularizer so that gradient tells me in what direction.",
                    "label": 0
                },
                {
                    "sent": "For that example, could I increase the loss and regularizer function the most by making a very small step, and then I'll go in the opposite direction?",
                    "label": 0
                },
                {
                    "sent": "Because I want to decrease that Lawson.",
                    "label": 0
                },
                {
                    "sent": "Regularizer function OK So what we need is that this direction is going to be the opposite direction of the gradient.",
                    "label": 0
                },
                {
                    "sent": "Of that last function, So what you're seeing here is that this nabla symbol, it corresponds to the notation for gradient and the Theta.",
                    "label": 0
                },
                {
                    "sent": "Here just says I want the gradient with respect to, so the vector of partial derivatives with respect to all of my parameters in my big vector Theta.",
                    "label": 1
                },
                {
                    "sent": "And I want the gradient with respect to Theta of what of the loss function for that example.",
                    "label": 0
                },
                {
                    "sent": "So for that example, what's the gradient with respect to parameters?",
                    "label": 0
                },
                {
                    "sent": "How do we impact the loss?",
                    "label": 1
                },
                {
                    "sent": "And also I'll need the gradient of the regularizer and I'll go in the opposite direction of that.",
                    "label": 0
                },
                {
                    "sent": "So we also have this Lambda here which I can talk about, which is the weight of the regularizer with respect to balance its influence with respect to the average loss.",
                    "label": 0
                },
                {
                    "sent": "And then I'll take my vector Theta and I'll just take a step of size Alpha in that direction.",
                    "label": 0
                },
                {
                    "sent": "So this is a vector.",
                    "label": 0
                },
                {
                    "sent": "An Alpha.",
                    "label": 0
                },
                {
                    "sent": "Here is what we often call a learning rate, and that's something we that's a hyperparameter that we need to specify a priority, and I'll talk a bit more about how to search for a good value for the hyperparameter later on.",
                    "label": 0
                },
                {
                    "sent": "So I make an update in my parameters, and then I continue doing this for all the examples in my training set.",
                    "label": 0
                },
                {
                    "sent": "So for all pairs X&Y.",
                    "label": 0
                },
                {
                    "sent": "And then I repeat for several epochs, or several iterations until I meet some sort of convergence criteria, and I'll talk also about what good convergence criteria we can use for training neural Nets.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "This is how we're going to optimize this empirical risk here.",
                    "label": 0
                },
                {
                    "sent": "This regularize empirical risk for each example we look at which direction could we decrease by taking a small step tolosan regularizer, and then I repeat this for each example, OK?",
                    "label": 0
                },
                {
                    "sent": "So if I want to use this algorithm, if that's the optimization algorithm, want to use to optimize or training neural net, what do I need to specify?",
                    "label": 0
                },
                {
                    "sent": "I need to specify a way of initializing the way.",
                    "label": 0
                },
                {
                    "sent": "The yes, the weights in the bicis.",
                    "label": 0
                },
                {
                    "sent": "So all of my parameters I need to specify a loss function.",
                    "label": 0
                },
                {
                    "sent": "So which determines you know, to what extent are certain predictions good or bad?",
                    "label": 0
                },
                {
                    "sent": "And I need to specify procedure for obtaining these gradients for a given XY pair with respect to my parameters.",
                    "label": 0
                },
                {
                    "sent": "And I need to specify a regularizer if I want to use that if I want to regularize my objective.",
                    "label": 0
                },
                {
                    "sent": "And of course I need also a simple way of getting the gradient with respect to that regularizer.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'll do is just talk about these different choices for the initialization.",
                    "label": 0
                },
                {
                    "sent": "The last function.",
                    "label": 0
                },
                {
                    "sent": "How do we get the gradient?",
                    "label": 0
                },
                {
                    "sent": "The short answer is back propagation.",
                    "label": 0
                },
                {
                    "sent": "This is what this computing this gradient, and choices of regularizer.",
                    "label": 0
                },
                {
                    "sent": "Questions about this so far.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So the question is, why do I define the regularizer?",
                    "label": 0
                },
                {
                    "sent": "Just a function of the weights, so I guess regularization could depend on other things.",
                    "label": 0
                },
                {
                    "sent": "It will typically not depend on the pair XY, but the weights as well.",
                    "label": 0
                },
                {
                    "sent": "See the type of regularization functions will use, which is.",
                    "label": 0
                },
                {
                    "sent": "You know the Euclidean norm or the L1 norm only depends on the weights, but I should say that yeah, you could think of other types or.",
                    "label": 0
                },
                {
                    "sent": "Regularization's and I guess to some extent that's a lot of what research and deep learning is finding new ways or better ways of regularising neural net so that they don't overfit.",
                    "label": 0
                },
                {
                    "sent": "And I will talk a bit more about like how this is a challenge with deep neural Nets that regularization, unless you have a huge data set is something you need to be concerned about.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "It's a great question, thank you.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so for the last function I'll mainly talk about classification so.",
                    "label": 0
                },
                {
                    "sent": "The last function that I'll usually assume is the log probability.",
                    "label": 0
                },
                {
                    "sent": "The negative log probability of the correct class.",
                    "label": 0
                },
                {
                    "sent": "For my example, XOF of X.",
                    "label": 0
                },
                {
                    "sent": "Is this vector of probabilities for our class, so if I'm looking at FXY, that's the probability I'm assigning to the correct class.",
                    "label": 0
                },
                {
                    "sent": "I'm going to take minus the log of that, mainly because taking the log makes there both the math and the numerical computations more stable.",
                    "label": 0
                },
                {
                    "sent": "An easier and minus because if I want to minimize if I want to maximize the probability of the correct class, which makes sense well, and if I'm framing everything into a minimization problem, I'm going to want to minimize the negative of that.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's known as doing essentially maximum likelihood, where minimizing the negative log likelihood.",
                    "label": 0
                },
                {
                    "sent": "So we're maximizing the likelihood of the class assignments that I see in my training set.",
                    "label": 0
                },
                {
                    "sent": "According to my neural net.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I need a procedure that takes this choice of a loss and gives me forgiven example XY.",
                    "label": 0
                },
                {
                    "sent": "What is the gradient of that loss with respect to all my parameters?",
                    "label": 0
                },
                {
                    "sent": "All my bases in all my weights?",
                    "label": 0
                },
                {
                    "sent": "And that's the backpropagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's essentially an application, a small application of the chain rule.",
                    "label": 0
                },
                {
                    "sent": "So I start by computing what is the gradient of the loss function with respect to.",
                    "label": 0
                },
                {
                    "sent": "It's sort of happens to be more convenient to start with that the pre activation at the output layer.",
                    "label": 0
                },
                {
                    "sent": "So the vector right before the softmax.",
                    "label": 0
                },
                {
                    "sent": "So this is what this symbol is.",
                    "label": 0
                },
                {
                    "sent": "This is a vector here, so this is saying nabla of that vector.",
                    "label": 0
                },
                {
                    "sent": "So I'm looking at the gradient with respect to that vector.",
                    "label": 0
                },
                {
                    "sent": "Of my last, which is minus the log of the probability of the correct class an.",
                    "label": 0
                },
                {
                    "sent": "It's actually super simple using the softmax and the negative log probability.",
                    "label": 0
                },
                {
                    "sent": "It's what I'm calling EY.",
                    "label": 0
                },
                {
                    "sent": "So EY is a vector.",
                    "label": 0
                },
                {
                    "sent": "We know it's a vector because I put it in bold, the E. Here an I provide Y just to specify.",
                    "label": 0
                },
                {
                    "sent": "So YY is going to be a vector filled with zeros except with the position Y corresponding to the correct class.",
                    "label": 0
                },
                {
                    "sent": "So if I have 10 classes, an Y is equal to two because this particular example X belongs to the second class.",
                    "label": 0
                },
                {
                    "sent": "I'm going to have a bunch of zeros and in the second entry is going to be equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So that's this EY here, it's also known as the one Hot vector, which is something you word you'll probably hear about later on this week.",
                    "label": 0
                },
                {
                    "sent": "So I take that one hot vector, which is really what essentially what the target is.",
                    "label": 0
                },
                {
                    "sent": "I want zero probability to everything, and the probability of 1 to the correct class.",
                    "label": 0
                },
                {
                    "sent": "That would be the best case scenario.",
                    "label": 0
                },
                {
                    "sent": "And then I subtract my current prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, and that happens to be so.",
                    "label": 0
                },
                {
                    "sent": "Take minus that that happens to be what is the gradient of their pre activation at the output layer of the loss function?",
                    "label": 0
                },
                {
                    "sent": "OK, so effectively what it's saying is that whatever I'm predicting right now, I don't want to predict that anymore.",
                    "label": 0
                },
                {
                    "sent": "I want to predict that's one hot vector.",
                    "label": 0
                },
                {
                    "sent": "This is the signal that we're sending to the neural net and then I'm going to start from the last layer and I'm going to propagate the gradients towards the input an on the way.",
                    "label": 0
                },
                {
                    "sent": "Also compute the gradients with respect to the diocese.",
                    "label": 0
                },
                {
                    "sent": "And the weight matrix.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "From the last layer to the first, I compute the gradients with respect to the hidden layer parameters.",
                    "label": 0
                },
                {
                    "sent": "That is the weight matrix and the bias.",
                    "label": 0
                },
                {
                    "sent": "As it turns out, it just corresponds to taking the gradient of the pre activation of the layer on top.",
                    "label": 0
                },
                {
                    "sent": "So that's also my notation assumes that all vectors are column vectors, so this here is a column vector.",
                    "label": 0
                },
                {
                    "sent": "Times the activation of the layer below for that.",
                    "label": 0
                },
                {
                    "sent": "For that index K. So I'm taking the pre activation of the layer on top and the activation at the layer below.",
                    "label": 0
                },
                {
                    "sent": "Sorry the green in the pre activation layer of top and the activation of the layer below an.",
                    "label": 0
                },
                {
                    "sent": "I'm taking the transpose of that so that gives me a column vector times a row vector.",
                    "label": 0
                },
                {
                    "sent": "If I multiplied this together I'm getting a matrix and that matrix you'll notice will match that.",
                    "label": 0
                },
                {
                    "sent": "Dimensionality of the matrix for that layer, it's going to be number of hidden units in the layer K times number of units in the layer came on this one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the gradient of.",
                    "label": 0
                },
                {
                    "sent": "This is the gradient of my weight matrix for layer K. The gradient of the bias is simply the gradient of the loss with respect to their pre activation that I have already starting this loop.",
                    "label": 0
                },
                {
                    "sent": "And so that's computing the gradients for the hidden layer parameters.",
                    "label": 0
                },
                {
                    "sent": "Next, I'm going to propagate the gradients to the layer below it at index K -- 1.",
                    "label": 0
                },
                {
                    "sent": "So I'm at layer K and propagating to index to layer key minus one.",
                    "label": 0
                },
                {
                    "sent": "So the gradient of the loss with respect to the activation at layer K -- 1 is just going to be my gradient for the pre activation at the layer above it multiplied by the transpose of my weight matrix, and that's because.",
                    "label": 0
                },
                {
                    "sent": "I'm propagating through a linear transformation and so the Jacobian is just this.",
                    "label": 0
                },
                {
                    "sent": "It's just a weight matrix essentially.",
                    "label": 0
                },
                {
                    "sent": "So that's the first step and then to get the gradient which reflected the pre activation for the layer below I need to pass the gradient through the non linearity and so I'm taking that gradient here which I'm seeing here and then multiplying I'm doing and elementwise multiplication with the derivatives of the activation function for each unit.",
                    "label": 0
                },
                {
                    "sent": "So This is why this is an elementwise multiplication.",
                    "label": 0
                },
                {
                    "sent": "So what dissemble that I'm taking the derivative?",
                    "label": 0
                },
                {
                    "sent": "Of my activation function, say the sigmoid, for instance, for the particular value of the pre activation.",
                    "label": 0
                },
                {
                    "sent": "OK, so this operation here for instance, if the sigmoid you might have learned about the fact that sigmoid will have saturating directives, which means that if the pre activation is very large and very small then the output is either going to be one or zero and then the data is going to be very close to 0.",
                    "label": 0
                },
                {
                    "sent": "So this operation here might zero out some of the gradients, and that's a problem will.",
                    "label": 0
                },
                {
                    "sent": "Talk about later on, but essentially once I've multiplied the gradients by the transpose of the weights, I do an elementwise multiplication of the narrative of the activation function, and then I can go back to the beginning of the loop and do this for the next layer, and I do this from the top to the bottom, yes question.",
                    "label": 0
                },
                {
                    "sent": "That's the problem.",
                    "label": 0
                },
                {
                    "sent": "Vanishing gradient.",
                    "label": 0
                },
                {
                    "sent": "Yet that's what I was reffering too.",
                    "label": 0
                },
                {
                    "sent": "That's why I will talk a bit more about that later on, but their vanishing grading a lot of it comes from this here from the fact we're doing this elementwise multiplication, at least some of it comes from that.",
                    "label": 0
                },
                {
                    "sent": "So that's the backdrop algorithm.",
                    "label": 0
                },
                {
                    "sent": "As you can see, it's as expensive as doing a forward prop.",
                    "label": 0
                },
                {
                    "sent": "It's just we're doing it in the opposite direction, OK?",
                    "label": 0
                },
                {
                    "sent": "Questions about that.",
                    "label": 0
                },
                {
                    "sent": "Makes sense.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An little talked a bit about this, but the way really to structure this in terms of code is to think of all these operations were doing when reconstructing a neural net, as these boxes that take inputs and produce an output, and then unknown.",
                    "label": 0
                },
                {
                    "sent": "That is really just a flow graph where we've chained together each of these different boxes so that neural net that we saw before.",
                    "label": 0
                },
                {
                    "sent": "We can think of it as a pre activation box which takes as input the input layer an.",
                    "label": 0
                },
                {
                    "sent": "Also the parameters WNB.",
                    "label": 0
                },
                {
                    "sent": "And it uses those parameters to transform X into a vector, which is the value of that box which is passed on to the another box which computes an element wise non linearity which is fed as input to a linear transformation which is a two of X.",
                    "label": 0
                },
                {
                    "sent": "So this is the linear component that Leon was mentioning when it was showing examples of torch code and then you eventually reach an output layer and then you feed data loss function and then doing back prop.",
                    "label": 0
                },
                {
                    "sent": "The way you can structure your code is that each of these boxes, and they're going to compute an output given their inputs, but also if you provide them a gradient for their outputs, it will have a B prop function, which will take that and propagate those gradients to each of its inputs.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then these gradients should correspond to the gradient of the loss function with respect to that box.",
                    "label": 1
                },
                {
                    "sent": "So you start with your loss and the gradient of the loss with respect of the losses one, so it's easy to initialize at the very top, and then you just go in the opposite direction.",
                    "label": 1
                },
                {
                    "sent": "Calling the B prop method.",
                    "label": 0
                },
                {
                    "sent": "Backpropagation gradient green up to here and up to here and up to the weights so you get your gradients with respect to your weights and then up to back propagating to the first layer through the activation function and up to the weights for the first layer.",
                    "label": 1
                },
                {
                    "sent": "And we don't need to back propagate up to X 'cause there's nothing to update in X.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially what the you know in terms of structuring your code and what not.",
                    "label": 0
                },
                {
                    "sent": "You know, doing backdrop looks like an.",
                    "label": 0
                },
                {
                    "sent": "I think later today.",
                    "label": 0
                },
                {
                    "sent": "Maybe you have already, but you're going to learn about Theano.",
                    "label": 0
                },
                {
                    "sent": "Theano essentially does this, but in even more sophisticated way where it actually outputs a graph that computes these gradients and torch works a lot in this way as well.",
                    "label": 0
                },
                {
                    "sent": "Where you change these boxes, and then when it comes to doing backdrop, well, it does pretty much what I shown here.",
                    "label": 1
                },
                {
                    "sent": "It calls all of these boxes in the reverse order, calling a different function, which is the backdrop function alright?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we have the last function we have the way to compute the gradients.",
                    "label": 0
                },
                {
                    "sent": "Now what are the other missing pieces?",
                    "label": 0
                },
                {
                    "sent": "While we might want to regularize on your own net to sort of play with this bias variance compromise that Pascal myself talked about yesterday.",
                    "label": 0
                },
                {
                    "sent": "The two regularization functions that are used the most is so the first one is the L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "It's just the sum over all the weight matrices and all of its entries of the squared of the value of the entries to square of their connections.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's the squared of the business norm, summed over all the weights.",
                    "label": 0
                },
                {
                    "sent": "So you could include the biases.",
                    "label": 0
                },
                {
                    "sent": "I think often we actually don't.",
                    "label": 0
                },
                {
                    "sent": "This might vary between different researchers, but usually we think of, you know the most most of the capacity is really in the weight matrix.",
                    "label": 0
                },
                {
                    "sent": "So often this is the weight matrix.",
                    "label": 0
                },
                {
                    "sent": "We're going to regularize.",
                    "label": 0
                },
                {
                    "sent": "Anne and the green of that is actually very simple, is just two times the weight matrix.",
                    "label": 0
                },
                {
                    "sent": "There's the other one.",
                    "label": 0
                },
                {
                    "sent": "Oh, and when we talk about weight decaying, so if you're that expression, usually we talk about L2 weight decay, so L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "The L word.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nization is another one that's used a lot.",
                    "label": 0
                },
                {
                    "sent": "It has the one of it's interesting properties is that if their regularization coefficient, this Lambda that multiplies the regularizer is big enough.",
                    "label": 0
                },
                {
                    "sent": "Some of the connections are going to be forced to exactly 0, so it's going to give you potentially a neural net with a sparse connectivity.",
                    "label": 0
                },
                {
                    "sent": "And so it's just the sum of the absolute values of the weights, and the gradient is actually one if the weight was positive and minus one if the wait was negative and if it's zero, we just climb the gradient to 0.",
                    "label": 0
                },
                {
                    "sent": "So again, the gradient is super trivial to compute.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we have regularization and now we need the initialization.",
                    "label": 0
                },
                {
                    "sent": "I think Leo talked about this so there are a few choices.",
                    "label": 0
                },
                {
                    "sent": "Well which are really bad initializing.",
                    "label": 0
                },
                {
                    "sent": "So for the biases, often we initialize them to zero before the weights.",
                    "label": 0
                },
                {
                    "sent": "Initializing everything to zero.",
                    "label": 0
                },
                {
                    "sent": "With attention activation we can show that then all the gradients would be 0, so it's under saddle Point.",
                    "label": 1
                },
                {
                    "sent": "You're stuck there and you can't move, so that's a bad idea.",
                    "label": 1
                },
                {
                    "sent": "Initializing all the weights to exactly the same value will create symmetries, which means that.",
                    "label": 0
                },
                {
                    "sent": "Each unit as they're being updated will essentially be identical.",
                    "label": 1
                },
                {
                    "sent": "They will compute exactly the same features, so that's not a good idea, so that's why we essentially go with something that's more random.",
                    "label": 0
                },
                {
                    "sent": "Each entry is going to be sample from a distribution.",
                    "label": 0
                },
                {
                    "sent": "Some people use Gaussian distribution between, you know, not between certain variants.",
                    "label": 0
                },
                {
                    "sent": "That's fairly small, so yahshua navigo have explored this.",
                    "label": 0
                },
                {
                    "sent": "This problem in 2010, and it came up with this formula, which was adapted for the attention.",
                    "label": 0
                },
                {
                    "sent": "Activation function and has some nice properties in terms of initially.",
                    "label": 1
                },
                {
                    "sent": "How does the gradient propagate?",
                    "label": 0
                },
                {
                    "sent": "Does it?",
                    "label": 0
                },
                {
                    "sent": "I think it maintains essentially the gradient of the same size as initially when you back propagate.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's why initialization you know.",
                    "label": 0
                },
                {
                    "sent": "In short, it needs to be random.",
                    "label": 0
                },
                {
                    "sent": "That's more or less it and with small values around zero.",
                    "label": 0
                },
                {
                    "sent": "That's the short answer.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so so now you have mainly the algorithm for training a feedforward neural network.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about other things that go yes, I see a question, yes.",
                    "label": 0
                },
                {
                    "sent": "In yeah, so if you're asking me if.",
                    "label": 0
                },
                {
                    "sent": "So the way that's the most interpretability again give right now the one way to think about it is to start to think about the grain at the output.",
                    "label": 0
                },
                {
                    "sent": "The creativity output.",
                    "label": 0
                },
                {
                    "sent": "What it does is that it essentially says you're supposed to increase the probability for the correct class and decrease the probability for everything else.",
                    "label": 0
                },
                {
                    "sent": "And as you're applying the chain rule, what happens is that you are informing, say, the layer below it.",
                    "label": 0
                },
                {
                    "sent": "Well to achieve this.",
                    "label": 0
                },
                {
                    "sent": "How should you adapt your activations?",
                    "label": 0
                },
                {
                    "sent": "OK, so should 1 activation and the first vector should increase or should it decrease and once you know this you can propagate this information to the weights so that now the weights no OK. Well if I wanted to increase my value should I?",
                    "label": 0
                },
                {
                    "sent": "How should I change the different weights that go into this neuron?",
                    "label": 0
                },
                {
                    "sent": "Should they increase or should they decrease so that's essentially the information that's being propagated around the network?",
                    "label": 0
                },
                {
                    "sent": "Four different units?",
                    "label": 0
                },
                {
                    "sent": "Should you if you want to make a small?",
                    "label": 0
                },
                {
                    "sent": "Improvement in your loss.",
                    "label": 0
                },
                {
                    "sent": "Should I increase or decrease the value?",
                    "label": 0
                },
                {
                    "sent": "But it also send you some information as to what extent you want to increase it or not.",
                    "label": 0
                },
                {
                    "sent": "So that's you know that's an interpretation of it.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, sure, I think wants to add something.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So yes, I was making a point that it needs to be small.",
                    "label": 0
                },
                {
                    "sent": "The initialization of weights but not too small.",
                    "label": 0
                },
                {
                    "sent": "And so this, I think essentially that equation here.",
                    "label": 0
                },
                {
                    "sent": "This way of saying we gotta initialize the weights uniformly between minus B&B where B is this sqrt 6 divided by the square root of the sum of the number of hidden units at the layer K plus the number of hidden units at the layer K -- 1.",
                    "label": 0
                },
                {
                    "sent": "That essentially comes from trying to achieve this have a gradient which initially stays.",
                    "label": 0
                },
                {
                    "sent": "About the same size.",
                    "label": 0
                },
                {
                    "sent": "Whoops hello questions yes.",
                    "label": 0
                },
                {
                    "sent": "So it will make a difference.",
                    "label": 0
                },
                {
                    "sent": "So the question is, does it make a big difference to choose the Gaussian versus the uniform?",
                    "label": 0
                },
                {
                    "sent": "As far as I know, people that have their so some people stick on using Gaussians they've never changed, so presumably it's not a deal breaker.",
                    "label": 0
                },
                {
                    "sent": "I think if you look at the details you might see and maybe also can comment on this, but you might see some differences.",
                    "label": 0
                },
                {
                    "sent": "I think I've heard some people say that by using this except instead of the Gaussian initialization they did see.",
                    "label": 0
                },
                {
                    "sent": "No significant improvements, but it's not.",
                    "label": 0
                },
                {
                    "sent": "You know the extent to which is going to be worse is not compared to like initializing everything to 0 or to the same value.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, sure.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doesn't happen.",
                    "label": 0
                },
                {
                    "sent": "Information.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the Gaussian does have this property that it is possible it's going to sample very large values.",
                    "label": 0
                },
                {
                    "sent": "It's fairly unlikely, but it is possible.",
                    "label": 0
                },
                {
                    "sent": "The uniform.",
                    "label": 0
                },
                {
                    "sent": "You sure it's never going to happen outside of the bounds that you defined.",
                    "label": 0
                },
                {
                    "sent": "Ask your question here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure, I'm going to give you this one.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So check out the paper, it is fairly simple.",
                    "label": 0
                },
                {
                    "sent": "When I looked at it some time ago.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I think no.",
                    "label": 0
                },
                {
                    "sent": "I think you need to change them, and I think the paper describes the formula for different activation functions.",
                    "label": 0
                },
                {
                    "sent": "This one, I think, is for the 10 H. So it might actually be important.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is a good piece of code to have in whatever library using for neural Nets to have these sort of checks on the size of the gradients or their variances as your training.",
                    "label": 0
                },
                {
                    "sent": "And when you're initializing can give you hints as to whether why you know maybe training doesn't work as well as you'd expect.",
                    "label": 0
                },
                {
                    "sent": "Yes question.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so excellent question.",
                    "label": 0
                },
                {
                    "sent": "So here what I described is an update per example, but in practice what people do, I was going to talk about it later is that you will actually update for a mini batch where we call a mini batch of examples you would take maybe 128 or 64 examples and then actually I'll talk about this later since I have a slide about it.",
                    "label": 0
                },
                {
                    "sent": "But that's a very good point so far.",
                    "label": 0
                },
                {
                    "sent": "Just assume you're essentially mini batch of size 1, but that's not what people do in practice.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Shit.",
                    "label": 0
                },
                {
                    "sent": "Right, so I would say that at least initially you want that it's true towards convergence.",
                    "label": 0
                },
                {
                    "sent": "You will have gradients that should become small and close to 0.",
                    "label": 0
                },
                {
                    "sent": "If they all go to zero at about the same rate, I would say that's a fairly good sign because it suggests that all layers are trained.",
                    "label": 0
                },
                {
                    "sent": "You know at about the same amount.",
                    "label": 0
                },
                {
                    "sent": "Informally, so yes, try to achieve.",
                    "label": 0
                },
                {
                    "sent": "Try to and.",
                    "label": 0
                },
                {
                    "sent": "This is why I was saying maybe having this.",
                    "label": 0
                },
                {
                    "sent": "You know in your code this thing that just shows you what's the variance of the gradient that different layers might be useful.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can track?",
                    "label": 0
                },
                {
                    "sent": "Oh, it seems at one point there's this layer that has converged.",
                    "label": 0
                },
                {
                    "sent": "It's hard to say whether that's a good or bad thing, but you know, if you see it happening very quickly and you don't really suspect it could have converged, say the first layer that quickly, that might be a sign of something to adjust.",
                    "label": 0
                },
                {
                    "sent": "Yeah, lot of questions.",
                    "label": 0
                },
                {
                    "sent": "Oh so yeah.",
                    "label": 0
                },
                {
                    "sent": "So that's another trick.",
                    "label": 0
                },
                {
                    "sent": "So the question is whether this initialization requires any preprocessing on the inputs.",
                    "label": 0
                },
                {
                    "sent": "And yes, it does assume that the inputs have been preprocessed to have mean zero and variance of 1.",
                    "label": 0
                },
                {
                    "sent": "Yes, good point.",
                    "label": 0
                },
                {
                    "sent": "OK, last question so I can move on, yeah?",
                    "label": 0
                },
                {
                    "sent": "It's more like the bottom layers for so, so the question is whether the gradients will come close to zero more rapidly at the top layer of the bottom layer.",
                    "label": 0
                },
                {
                    "sent": "You tend to see this more at the bottom layer, and the reason is 1 explanation is the fact that we're multiplying by the derivative of the activation function, and if all the activations have saturated then they will essentially block all gradients.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's move on to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next step, so now we've seen essentially how do we train Internet?",
                    "label": 0
                },
                {
                    "sent": "Once I've chosen number of hidden units in each layer, learning rates and things like that.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about what comes around that and 1st we want to talk about model selection.",
                    "label": 1
                },
                {
                    "sent": "OK, so I think Pascal's talked about this.",
                    "label": 0
                },
                {
                    "sent": "The notion of hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So these are the parameters that backdrop essentially doesn't give you an answer for it doesn't optimize the number of hidden units, doesn't optimize the learning rate.",
                    "label": 0
                },
                {
                    "sent": "You have to provide those before you start training.",
                    "label": 0
                },
                {
                    "sent": "So how do you pick those so the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My hyperparameters we're going to select them like we said, hyperparameters for, especially all learning algorithms more or less.",
                    "label": 1
                },
                {
                    "sent": "So the training set which I'm noting Detrain will serve to train the model, but we're going to have a separate set which is usually smaller, which we call a validation set an what it serves 4.",
                    "label": 1
                },
                {
                    "sent": "Is that we're going to essentially try a bunch of different values for the hyperparameters, the learning rates, and the number of hidden layers and the size of the hidden layers.",
                    "label": 0
                },
                {
                    "sent": "Will it rain a bunch of neural Nets with these different choices of hyperparameters?",
                    "label": 0
                },
                {
                    "sent": "And then we're going to look at the performance on the validation set.",
                    "label": 0
                },
                {
                    "sent": "And when I say that, I mean usually for classification network, you look at the classification error, because that's really what interests you.",
                    "label": 1
                },
                {
                    "sent": "So we're not going to look at the log probability of the correct class or the negative log property of the correct class.",
                    "label": 0
                },
                {
                    "sent": "We use that for training, because this is a differentiable loss function, so we can get gradients.",
                    "label": 0
                },
                {
                    "sent": "But for validation, where we will never have gradient.",
                    "label": 0
                },
                {
                    "sent": "So essentially we'll just do this trial and error, and then we might as well use the loss that really interests us for classification.",
                    "label": 0
                },
                {
                    "sent": "It's the classification error.",
                    "label": 0
                },
                {
                    "sent": "So in the validation set we compare different networks trained with different hyperparameters, and then essentially we're going to pick the best one based on the validation set error and to get an unbiased estimate of what is the performance of that network.",
                    "label": 0
                },
                {
                    "sent": "We're going to evaluate it on a test set, so I think that's something you know about and Pascal as discussed before, so that's what I mean by model selection essentially, and the goal of course is to do as well as possible on the test set.",
                    "label": 0
                },
                {
                    "sent": "But of course, without cheating, that is.",
                    "label": 0
                },
                {
                    "sent": "Without introducing any biases in our estimate of that error.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One of the very few different approaches for selecting hyperparameters, and actually fairly recently there's been more more progress on understanding what are good strategies for that one which has been used a whole lot is what's called grid search.",
                    "label": 0
                },
                {
                    "sent": "That is, for all your hyperparameters, which you'll do is that you'll define a set of values for each of them, and then you're going to try all combinations for all values of these hyperparameters.",
                    "label": 1
                },
                {
                    "sent": "So if you have two hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "Number of hidden units and learning rates, and if you specify 10 values for each, you're going to have 100 different combinations.",
                    "label": 0
                },
                {
                    "sent": "You're going to train 100 different neural Nets, so it's called grid search, because you could think of this as like.",
                    "label": 0
                },
                {
                    "sent": "You know, one defines the ticks of the grid and saying you know the Y axis and the other in the X axis, and so all combinations really are.",
                    "label": 0
                },
                {
                    "sent": "This points on that grid formed by these sticks.",
                    "label": 0
                },
                {
                    "sent": "The problem with this is that it's going to explode.",
                    "label": 0
                },
                {
                    "sent": "The number of hyperparameters you're going to want based on this procedure to test or two to number of to validate.",
                    "label": 0
                },
                {
                    "sent": "So more recently, James Bergstrom Yoshua propose instead to investigated really well the idea of doing instead random search.",
                    "label": 0
                },
                {
                    "sent": "So here it's a bit similar to Grid search but has some much better properties.",
                    "label": 0
                },
                {
                    "sent": "What will do is that we will define for each parameter an set of values, or if it's a continuous parameter, maybe arrange.",
                    "label": 0
                },
                {
                    "sent": "And we're going to determine a distribution over these values, so if it's the learning rate, well, maybe I'll take a log uniform distribution between 0.001 and 0.1 and for the number of hidden units, maybe a uniform distribution on the integers from 10 to 100, and I imagine I have a cluster, but I have only so many machines I have maybe 20 machines or 40 machines, So what I'll do is that so I have a sort of computational budget.",
                    "label": 0
                },
                {
                    "sent": "Well, the grid search.",
                    "label": 0
                },
                {
                    "sent": "It's sort of annoying to try to figure out what values where I put on that red such that I don't go over these 40.",
                    "label": 0
                },
                {
                    "sent": "Computers that I can use for random searches super trivial.",
                    "label": 0
                },
                {
                    "sent": "You just say I'm going to sample 40 values from these marginal distributions for parameter.",
                    "label": 0
                },
                {
                    "sent": "So in my example with the learning rate and a hidden layer for each machine, what I do is that sample from the distribution for the prior distribution I determined for the learning rate simple value do the same thing for the number of hidden units.",
                    "label": 0
                },
                {
                    "sent": "Launch that job on computer one.",
                    "label": 0
                },
                {
                    "sent": "Sample a new pair learning rate hidden units for the second machine.",
                    "label": 0
                },
                {
                    "sent": "Trained that on computer to an continue like this and so here.",
                    "label": 0
                },
                {
                    "sent": "You really control separately the ranges of values are going to try for the hyperparameters, and the number of jobs you're going to train.",
                    "label": 0
                },
                {
                    "sent": "So it has this really nice feature and you don't really have the problem with grid search, which is that maybe one point on your grid will not finish because the computer crashed down or something like this.",
                    "label": 0
                },
                {
                    "sent": "Since you're sampling in dependently, all of these points and random search well.",
                    "label": 0
                },
                {
                    "sent": "If a computer crashes, well, that's as if you never actually tried this value, and it's not like a point is missing on the grid, so it has these nice properties that make it very convenient.",
                    "label": 0
                },
                {
                    "sent": "Again, in each of these cases, the validation set.",
                    "label": 1
                },
                {
                    "sent": "This used to determine what is the winner choice amongst all of these values of hyper parameters and then you can always go back if you.",
                    "label": 1
                },
                {
                    "sent": "If you've identified that on your grid, it always picks the smallest or biggest value for one in the hyper.",
                    "label": 0
                },
                {
                    "sent": "Suggest you should use if it's the smallest smaller lower value or larger larger value for the hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "If kept choosing the largest value so we can refine your grid or distribution and go back and do a few more experiments.",
                    "label": 0
                },
                {
                    "sent": "That's how people have done like these experiments with finding parameters for neural Nets for a long time, and more recently allowed with random search.",
                    "label": 0
                },
                {
                    "sent": "I wanted to talk quickly about more recent developments in using essentially machine learning to tune these hyperparameters for neural Nets.",
                    "label": 0
                },
                {
                    "sent": "So we could think of this problem of guessing what is the performance on the validation set given some hyperparameter values as a function that I would like to learn, and I have a bunch of machine learning.",
                    "label": 0
                },
                {
                    "sent": "You know algorithms I could use maybe 2 to learn that function that relationship so this is what has been explored under the expression or Bayesian optimization or some other use and they are slightly different.",
                    "label": 0
                },
                {
                    "sent": "But sequential model based optimization.",
                    "label": 0
                },
                {
                    "sent": "Their idea is fairly simple, so we're going to use machine learning to predict the performance on the validation set and we're going to use that train model to suggest what should be the next hyperparameter that I try.",
                    "label": 0
                },
                {
                    "sent": "So we're going to alternate between suggesting hyperparameters based on the model that I've trained on the experiments I've done so far.",
                    "label": 0
                },
                {
                    "sent": "And then I run the experiment I get.",
                    "label": 0
                },
                {
                    "sent": "What is the validation set performance?",
                    "label": 0
                },
                {
                    "sent": "I add this to my training data for my validation set performance predictor.",
                    "label": 0
                },
                {
                    "sent": "I retrain my model and then again a new suggestion to have this loop like this which is like retrain my predictor validation set performance.",
                    "label": 1
                },
                {
                    "sent": "Get a suggestion out of this, I get a validation set performance.",
                    "label": 0
                },
                {
                    "sent": "I retrain and so on.",
                    "label": 0
                },
                {
                    "sent": "These items usually require that the model the machine model you train has to output a mean and variance, so it needs a form of confidence in its prediction.",
                    "label": 0
                },
                {
                    "sent": "So the mean will essentially be in expectation.",
                    "label": 0
                },
                {
                    "sent": "I expect the validation set performance to be that and the variance is going to be, but I more or less certain about what that value is going to be.",
                    "label": 0
                },
                {
                    "sent": "So in Bayesian optimization, the machine learning algorithm is used to make that prediction is Gaussian processes, which I will not talk about, but just think of it as a black box that trains on the set of points that does regression, and when it does regression prediction, it gives you not just a mean prediction but also a variance which is its confidence in its output.",
                    "label": 0
                },
                {
                    "sent": "See ahead, yes.",
                    "label": 0
                },
                {
                    "sent": "You should, I think, the right way to think about it is more like the.",
                    "label": 0
                },
                {
                    "sent": "It's like the beige and variance that is.",
                    "label": 0
                },
                {
                    "sent": "What is my confidence in my prediction?",
                    "label": 0
                },
                {
                    "sent": "So it's more like you know, like there's a frequentist way of interpreting the variance, which is, like, you know, the results of doing this experiment, observing the spread, and so on.",
                    "label": 0
                },
                {
                    "sent": "And here in Bayesian optimization, you're the way it works is that you actually say a priority.",
                    "label": 0
                },
                {
                    "sent": "I think the function looks like something and then based on points you observe, then you can say, well, I expect the value to be like this, but have that much uncertainty of what about what this value could be.",
                    "label": 0
                },
                {
                    "sent": "Given what I've seen so far, so that's more.",
                    "label": 0
                },
                {
                    "sent": "I think the more appropriate we have interpret that variance.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to give you like a cartoon, description or illustration of how this works.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So imagine that we have just a single hyperparameter which is on this line.",
                    "label": 0
                },
                {
                    "sent": "Here the X axis, and imagine that the dotted line that you're seeing here.",
                    "label": 0
                },
                {
                    "sent": "I should say this lies come from Ryan Adams who made this in.",
                    "label": 0
                },
                {
                    "sent": "It's really interesting illustration.",
                    "label": 0
                },
                {
                    "sent": "That's why I'm using it here.",
                    "label": 0
                },
                {
                    "sent": "So imagine that this is the performance for different values of the hyperparameter on the validation set, so actually varies quite a bit.",
                    "label": 0
                },
                {
                    "sent": "It's a non convex function and what I'd like to ideally is to find the minimum which is here that's.",
                    "label": 0
                },
                {
                    "sent": "Where do I get the lowest validation errors in?",
                    "label": 0
                },
                {
                    "sent": "OK, and imagine so far I've tried these two points.",
                    "label": 0
                },
                {
                    "sent": "I've tried this value of say the learning rate and this order value, and I've observed that value of validation set error and this value of their validation set error.",
                    "label": 0
                },
                {
                    "sent": "Now because I have an algorithm that gives me not just an expectation over what my prediction is for different or new validation set point or new.",
                    "label": 0
                },
                {
                    "sent": "Sorry, a new learning rate also have a variance.",
                    "label": 0
                },
                {
                    "sent": "That's why I see this curve here.",
                    "label": 0
                },
                {
                    "sent": "So the solid line is this.",
                    "label": 0
                },
                {
                    "sent": "Expected.",
                    "label": 0
                },
                {
                    "sent": "A value for the validation set performance based on my Gaussian process and the width of this Gray area reflects the variance of the prediction.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that I expect the value to be about the same as this one here.",
                    "label": 0
                },
                {
                    "sent": "For that choice of the learning rate at this position in the X axis.",
                    "label": 0
                },
                {
                    "sent": "But I have a lot of uncertainty about that actual prediction.",
                    "label": 0
                },
                {
                    "sent": "So because I have an expectation and the variance and in the Gaussian process, because this is the expectation of the variance of a Gaussian, I can compute something like which is not the expected improvement.",
                    "label": 0
                },
                {
                    "sent": "So what is the improvement?",
                    "label": 0
                },
                {
                    "sent": "The improvement is going to be if I try a new configuration of my learning rate, the improvement is going to be what we call improvement here is going to be the previous best value that I found if the new learning rate doesn't improve on it or it's going to be my new best.",
                    "label": 0
                },
                {
                    "sent": "So essentially what the expected improvement you should think of it as it's essentially what is going to be my new best value after I tried this experiment.",
                    "label": 0
                },
                {
                    "sent": "OK, and it turns out that if I know if I assume that you know the validation set performance on that new point is going to follow a Gaussian with this mean and this variance I can compute analytically what this expected expected improvement is going to be OK, So what is the expectation of the new best value?",
                    "label": 1
                },
                {
                    "sent": "And yes.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so so the question is, even for one value of the hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "There's no the question initialization is going to be important, and that is true to some extent.",
                    "label": 0
                },
                {
                    "sent": "Just show the I'll show the the simulation and then we'll see whether I'll try to jump back to your question.",
                    "label": 0
                },
                {
                    "sent": "So OK, an actually I misspoke.",
                    "label": 0
                },
                {
                    "sent": "So the expected improvement the improvement is going to be 0 if I haven't done better than before, and it's going to be the difference between the my previous best configuration an my new best configuration if I do better.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the expected improvement, so you can see that after two points, my expected improvement at Triangle Point, which is exactly 1 configuration I've tried so far is zero.",
                    "label": 0
                },
                {
                    "sent": "I don't expect to improve at all because I know what is the value of the validation set performance at that point.",
                    "label": 0
                },
                {
                    "sent": "Same thing here and you can see that as I go further away from the eye providers that I've tried, the expected improvement increases and increases because I have uncertainty about what the exact value is going to be OK, and the lower that point.",
                    "label": 0
                },
                {
                    "sent": "Is well, the more likely I'm going to improve next to it because it's a good configuration compared, say to this one where we can see the expected improvement doesn't increase as rapidly as we move away from this configuration.",
                    "label": 0
                },
                {
                    "sent": "So, and what is nice is that this expected improvement quantity is something that is continuous with respect to the value of the hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "So it can actually optimize that curve.",
                    "label": 0
                },
                {
                    "sent": "So I can do gradient in this case ascent 'cause I want to get the point with the highest expected improvement.",
                    "label": 0
                },
                {
                    "sent": "I think I can do gradient descent on that function Now, it's nonconvex, so we're going to try a lot of different points and from one point we're going to increase the expected improvement by gradient ascent.",
                    "label": 0
                },
                {
                    "sent": "Agreed to send procedure so that you know I'm more likely to cover all the local Optima, but with these two points, well, the best configuration, which I would find is this one here.",
                    "label": 0
                },
                {
                    "sent": "So my next experiment I'm going to use that value of the hyperparameter.",
                    "label": 0
                },
                {
                    "sent": "Then I asked my Gaussian process OK, what is now your prediction and your variance over the validation set performance for different values of the hyperparameter.",
                    "label": 0
                },
                {
                    "sent": "And now you see my expected improvement has also changed, reflecting the fact that I know now what is the performance here and now the new point with the best expected improvement is this one.",
                    "label": 0
                },
                {
                    "sent": "So that's going to be my new parameter that I'm going to try.",
                    "label": 0
                },
                {
                    "sent": "An I get a value like this which is a bit higher than what is the current best, which I think is here so you can see that expected provement in that region has increased as decreased quite a bit and I'm going to focus in other areas of the region where which has some potential and I it's a compromise essentially between do I see lovallo value of my validation set error an my fairly uncertain about what the value could because I haven't explored that so much, so that's the new best point and I continue like this.",
                    "label": 0
                },
                {
                    "sent": "Eventually converging to the best point.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "This so going back to your question where the initialization might have an impact is the fact that when I'm proposing a new point, I do have to solve a problem, which is a nonconvex optimization problem, and so the initialization is essentially which points am I going to start with?",
                    "label": 0
                },
                {
                    "sent": "Doing gradient descent to find the best point with best expected improvement.",
                    "label": 0
                },
                {
                    "sent": "So in that extent, yes, it's going to have an impact whether you so.",
                    "label": 0
                },
                {
                    "sent": "Usually we do Sobel sequence Grid over the space if it's in two D3D and so on.",
                    "label": 0
                },
                {
                    "sent": "And then for each of these points, we optimize the expected improvement as much as we can, and we take the best one.",
                    "label": 0
                },
                {
                    "sent": "There's no guarantee we actually get the global optimum.",
                    "label": 0
                },
                {
                    "sent": "They expect an improvement while you practice.",
                    "label": 0
                },
                {
                    "sent": "It works really well.",
                    "label": 0
                },
                {
                    "sent": "So I just that's just a cartoon and not very detailed description of how this works, but I really encourage you to look at the literature.",
                    "label": 1
                },
                {
                    "sent": "It's used more and more so either look for Bayesian optimization or sequential model based optimization.",
                    "label": 0
                },
                {
                    "sent": "So my colleague Ryan Adams and Jasper Snook of series of papers trying to adapt this simplistic scenario to other cases, like when you want to do experiments in parallel and so on.",
                    "label": 0
                },
                {
                    "sent": "Frank Hutter is another researcher that has a lot of really cool work around this idea, so I encourage you to.",
                    "label": 0
                },
                {
                    "sent": "Look that up.",
                    "label": 0
                },
                {
                    "sent": "Alright, so um.",
                    "label": 0
                },
                {
                    "sent": "OK, for so that's something we can use these different methods for selecting the hyper parameters that we can use for most hyper parameters for the number of epochs.",
                    "label": 0
                },
                {
                    "sent": "So a number of iterations of gradient descent.",
                    "label": 0
                },
                {
                    "sent": "What we usually do instead of treating it as a normal hyperparameter is we use a procedure known as early stopping.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that as we know, we as we increase the capacity in this case, if as we increase the number of iterations of gradient descent, I expect the distance or the difference between the training performance and the validation set performance to increase and the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ideas that we'd like to find the sweet spot.",
                    "label": 0
                },
                {
                    "sent": "The number of epochs where the validation set.",
                    "label": 1
                },
                {
                    "sent": "If I had trained a bit less, would give me a worse error, but if I tried a bit more I would have also worse error.",
                    "label": 0
                },
                {
                    "sent": "So this sweet spot between an underfitting scenario and an overfitting scenario.",
                    "label": 0
                },
                {
                    "sent": "And since the number of epochs is something that I can just increment and reuse the network that I've trained, say after 10 at box and just trained it one more epoc and check the validation set performance, this suggests a very simple way of selecting the number of epochs, which is I start with, say, one epoc.",
                    "label": 0
                },
                {
                    "sent": "I look at the validation set performance and then I check.",
                    "label": 0
                },
                {
                    "sent": "Is this the best I've achieved so far?",
                    "label": 0
                },
                {
                    "sent": "Yes, no, and I continue one more impact.",
                    "label": 0
                },
                {
                    "sent": "If I improve the validation set performance, yes no.",
                    "label": 0
                },
                {
                    "sent": "And I continue like this.",
                    "label": 0
                },
                {
                    "sent": "Until I reached this point where I've actually.",
                    "label": 0
                },
                {
                    "sent": "So in this case I reached this point, it's the best so far.",
                    "label": 0
                },
                {
                    "sent": "I do one more iteration and then it's become worse.",
                    "label": 0
                },
                {
                    "sent": "So this suggests that maybe I should have stopped before.",
                    "label": 0
                },
                {
                    "sent": "OK, now this is like more like a cartoon illustration.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you will see a bit of going up and down of the validation set performance so often what we do in practice is that we use something known as look, look ahead.",
                    "label": 0
                },
                {
                    "sent": "That is when I don't, I'm going to allow the network to continue training for say 10 at box.",
                    "label": 0
                },
                {
                    "sent": "Even though the validation set performance hasn't improved, just in case it went up for two epochs, but then it went much further down after because that's something that can happen.",
                    "label": 0
                },
                {
                    "sent": "So this lookahead idea is something that we actually use in practice.",
                    "label": 0
                },
                {
                    "sent": "We don't stop as soon as it gets worse, and also small detail, but that's important.",
                    "label": 0
                },
                {
                    "sent": "When you've identified the number of epochs, that's the best what you want to do is go back to the weight configurations of your network that corresponded to that best value.",
                    "label": 0
                },
                {
                    "sent": "So you don't want to stop there and use that network, as this one is worse 'cause you've stopped.",
                    "label": 0
                },
                {
                    "sent": "You want to go back to the network that had the best validation set performance, so usually you have to do bit of bookkeeping where you copy the connections of your network and flag it as your best so far, and that's the network you go back to.",
                    "label": 1
                },
                {
                    "sent": "Once you achieve this early stopping condition.",
                    "label": 0
                },
                {
                    "sent": "Question yes.",
                    "label": 0
                },
                {
                    "sent": "So you know, typically you don't.",
                    "label": 0
                },
                {
                    "sent": "There are so you could.",
                    "label": 0
                },
                {
                    "sent": "Anyways, this is more like events reach research ideas, but you might want to like.",
                    "label": 0
                },
                {
                    "sent": "It could be that you could identify that a number of hidden units and number and value of the learning rate is bad just from like 2 epochs.",
                    "label": 0
                },
                {
                    "sent": "And then stop just because you know you should give up that selection hyperparameters, but that's something that's not currently well developed and people are exploring.",
                    "label": 0
                },
                {
                    "sent": "So currently when people use Bayesian optimization, they don't use it for that.",
                    "label": 1
                },
                {
                    "sent": "So you just assume that for the for the number of epochs.",
                    "label": 0
                },
                {
                    "sent": "This is the procedure you're going to be using and for all the other hyperparameters you might want to use Bayesian optimization, yes?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, you are doing a number of iterations so it it could be.",
                    "label": 0
                },
                {
                    "sent": "It depends a lot on how many iterations you actually do.",
                    "label": 0
                },
                {
                    "sent": "So random search initially is going to look and Bayesian optimization are going to perform about the same because Bayesian optimization is solar blind for the first few iterations it is more or less replicating random search.",
                    "label": 0
                },
                {
                    "sent": "It's more after quite a few iterations that now you might have.",
                    "label": 0
                },
                {
                    "sent": "You know you might actually have a better model of what is the relationship between the hyperparameters and the value on the validation set.",
                    "label": 0
                },
                {
                    "sent": "But if you want, we can talk about this more after.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "It's a validation set last year just to be oh sorry, so you mean for training the neural net?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, so use.",
                    "label": 0
                },
                {
                    "sent": "So OK, so the question is if you have the global optimizer that guaranteed you to find the best configuration of the neural net parameters for the training error, it would be a very bad idea to you know.",
                    "label": 0
                },
                {
                    "sent": "Would it be a very bad idea then to actually use it for training and it is true unless you have hyper parameters that control the capacity of the network.",
                    "label": 0
                },
                {
                    "sent": "So regularization will mean that you are penalizing potentially the best performing under training.",
                    "label": 0
                },
                {
                    "sent": "Set in terms of its error, you are penalizing that configuration, so This is why we would talk about.",
                    "label": 0
                },
                {
                    "sent": "You know, having a compromise between bias and variance.",
                    "label": 0
                },
                {
                    "sent": "In this case regularization, which is going to control the amount of capacity that you that you can essentially explore, and finding a good solution to your problem, you would essentially use model selection on this validation set to control the amount of regularization you would impose to the training procedure.",
                    "label": 0
                },
                {
                    "sent": "So that's how you would, you know.",
                    "label": 0
                },
                {
                    "sent": "Make sure that your global optimizer Google Optimiser doesn't overfit by controlling this capacity with your hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So I think I've.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of my slides, but not half my time, so let me go quickly on other things.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to mention a few other or you could call tricks of the trade so things that people use when they train your neural Nets and.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That either does improve the results or make your life easier when you're training them.",
                    "label": 0
                },
                {
                    "sent": "So someone mentioned normalizing your data.",
                    "label": 1
                },
                {
                    "sent": "That is, take each dimension of your input space.",
                    "label": 1
                },
                {
                    "sent": "Subtracting the empirical mean, dividing by the empirical standard deviation.",
                    "label": 0
                },
                {
                    "sent": "That is something that will often speed up training if your dimensions are real valued.",
                    "label": 0
                },
                {
                    "sent": "If you have dimensions that are is a binary 01, normalization like this is not necessarily going to help you.",
                    "label": 0
                },
                {
                    "sent": "You should stick with 01, but for real valued kind of.",
                    "label": 0
                },
                {
                    "sent": "Input distribution normalizing the inputs have been shown to speed up training in terms of the number of epochs.",
                    "label": 1
                },
                {
                    "sent": "It also helps to decay the learning rate so intuitively, because initially we are very far from what is probably Internet that classify as best you can probably allow yourself to do.",
                    "label": 1
                },
                {
                    "sent": "Bigger steps when you do a gradient step, but as you get closer to the solution you might want to take more refined, smaller steps towards the optimum Ann.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of optimization methods that will implicitly decay the neural net learning rate.",
                    "label": 1
                },
                {
                    "sent": "Little might talks about some of these later.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "Essentially realistic that people have used a lot that tends to work well is to start with a large learning rate and then you track kind of like early stopping.",
                    "label": 0
                },
                {
                    "sent": "You track the validation set performance once it starts getting worse, you go back to your previous best neural net and you continue training, but you divide your learning rate by you take a fraction of your learning rate, so maybe you divide by two and then you continue training from that best point so far.",
                    "label": 0
                },
                {
                    "sent": "And then once the validation set their performance.",
                    "label": 1
                },
                {
                    "sent": "Again, starts getting worse.",
                    "label": 0
                },
                {
                    "sent": "You read the value learning rate by two, going back to your best point so far, and you continue like this.",
                    "label": 0
                },
                {
                    "sent": "Maybe you repeat this five or six times, so that's a procedure that automatically gives you a learning rate schedule with the learning rate is decreasing based on your validation set performance.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In practice, we also mentioned that or there was a question whether we should be using.",
                    "label": 0
                },
                {
                    "sent": "You know, one example per update or a mini batch.",
                    "label": 0
                },
                {
                    "sent": "So indeed, in practice people use mini batches.",
                    "label": 0
                },
                {
                    "sent": "That is, you take if you have a data set you're going to take a subsample of size 64, maybe 128, partly.",
                    "label": 0
                },
                {
                    "sent": "The reason for doing that is that gaining all of the outputs for all the examples in that mini batch can be expressed as matrix matrix multiplies.",
                    "label": 1
                },
                {
                    "sent": "When you do this linear transformation, instead of doing one vector one input vector times matrix, you can now do the whole mini batch matrix.",
                    "label": 0
                },
                {
                    "sent": "Times the connections and that's going to be faster than doing as many matrix vector multiplications, so that's part of the reason.",
                    "label": 1
                },
                {
                    "sent": "The reason is that you are going to get a.",
                    "label": 1
                },
                {
                    "sent": "So in this case you're computing the average gradient for that mini batch, so it's going to be less variance in the.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a better estimate, essentially of your gradient, so you also gain that, and so in practice people often use this and in terms of you know how fast you're going to train your neural Nets.",
                    "label": 0
                },
                {
                    "sent": "You do get improvements.",
                    "label": 0
                },
                {
                    "sent": "Often people also use something known as momentum, so the idea is that instead of using just a gradient for that mini batch as the update direction, I'm going to use a combination of my current direction for my mini batch an what is the direction that I use for updating my parameters in the previous update, so I'm going to take my previous direction multiplied by a momentum factor, which is better.",
                    "label": 1
                },
                {
                    "sent": "I'm going to add this to the average gradient for my mini batch and that's going to be my direction for this current update.",
                    "label": 0
                },
                {
                    "sent": "OK, So what this allows is that.",
                    "label": 0
                },
                {
                    "sent": "If you fall into the optimization problem, falls into a region where you have a plateau.",
                    "label": 0
                },
                {
                    "sent": "That is, you have a very slowly decreasing region of the hyperparameter space, but if it always points in the same direction, then you can gain momentum.",
                    "label": 0
                },
                {
                    "sent": "That is, all these grain is going to point the same direction, so they're going to accumulate like this, and you might go faster than you would otherwise if you had not used momentum, and if the gradient start to disagree while they're going to cancel each other in the directions where there's so where you shouldn't, maybe move as much so.",
                    "label": 0
                },
                {
                    "sent": "Momentum is another thing.",
                    "label": 0
                },
                {
                    "sent": "It adds a hyperparameter, but it can make a big difference.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, so if you're going to use storage or Theano and use the components that are part of the library, you are pretty much guaranteed that their gradients are computed correctly, at least if you don't use the development version.",
                    "label": 0
                },
                {
                    "sent": "I guess if it's development version, you have fewer guarantees, though I think usually it's fine if you are going to develop your own modules, it needs to compute gradients and needs to output the gradient.",
                    "label": 0
                },
                {
                    "sent": "I highly recommend.",
                    "label": 0
                },
                {
                    "sent": "That when you do this, you use the finite difference approximation to compare your gradient computer by your code and the estimate of the gradient.",
                    "label": 0
                },
                {
                    "sent": "That is for each parameter in your module you take a step of epsilon forward.",
                    "label": 0
                },
                {
                    "sent": "You look at what's the value of the output of your module.",
                    "label": 0
                },
                {
                    "sent": "You also take it step backwards and you take the difference in divide by sensory.",
                    "label": 0
                },
                {
                    "sent": "The difference between these two points to epsilon and that's going to be the partial derivative in that direction for that parameter, and you compare that.",
                    "label": 0
                },
                {
                    "sent": "With what your code actually computes as the gradient, and the difference should be very small, so I say this because you would think I don't need to do this.",
                    "label": 0
                },
                {
                    "sent": "If I'm wrong, then probably won't train and I'll go back and check my gradients, but it's surprising to what extent and know that can work if only a small part of it has bad gradients and other parts will to some extent possibly accommodate for the fact that a part of your network is not training properly.",
                    "label": 0
                },
                {
                    "sent": "So do not use that as indication as.",
                    "label": 0
                },
                {
                    "sent": "Whether there's a bug or not in your code, do check your gradients like that.",
                    "label": 0
                },
                {
                    "sent": "If you're implementing a new module.",
                    "label": 0
                },
                {
                    "sent": "If using all the modules already in Torch or Theano, you should be fine.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Question yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so now I think this finite difference is, you know, usually sufficient, yeah.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "OK so I have like 6 minutes left.",
                    "label": 0
                },
                {
                    "sent": "An much more material so I'm going to try to go fairly quickly.",
                    "label": 0
                },
                {
                    "sent": "The slides are are there anyways and some of it I actually talk about in the online course.",
                    "label": 0
                },
                {
                    "sent": "We can go check it out so.",
                    "label": 0
                },
                {
                    "sent": "Essentially what I want to talk about now is that all of what I've discussed so far are more or less things that were known.",
                    "label": 0
                },
                {
                    "sent": "You know, 15 years ago or 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "I've been development since we've started talking about deep learning, which is just sort of a new expression for talking about.",
                    "label": 0
                },
                {
                    "sent": "You know, neural Nets, and these developments were inspired by the fact that we really wanted to train neural Nets that were very deep, but often we had little success doing that.",
                    "label": 0
                },
                {
                    "sent": "So essentially there were attempts to try to fix this difficulty of training that we had identified in training deep neural Nets.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's actually two things that can happen.",
                    "label": 0
                },
                {
                    "sent": "And the first hypothesis for why you might have difficulty training at deep neural net is that essentially the problem you set up in training this know that this is a hard optimization problem, and you're having a hard time fitting your training your training set so you are more in Underfitting regime.",
                    "label": 0
                },
                {
                    "sent": "One thing that can be caused by this is this vanishing gradient problem, where we notice that you might notice that the gradients for your weights at the first layer are much smaller, so the signal is weaker more intuitively than the grades at the top of the layer.",
                    "label": 1
                },
                {
                    "sent": "OK, this is actually a well known problem if I think you have lectures on on record Nets, this is a problem that's particularly present when you're training record neural Nets.",
                    "label": 1
                },
                {
                    "sent": "I won't say much more.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That and there's not second hypothesis which it might be.",
                    "label": 0
                },
                {
                    "sent": "You're overfitting and.",
                    "label": 0
                },
                {
                    "sent": "The reason might be that you know when we are considering not just one hidden layer, but multiple hidden layers where we're increasing the capacity of our models.",
                    "label": 0
                },
                {
                    "sent": "So where essentially in a regime where we have increased the variance of our.",
                    "label": 0
                },
                {
                    "sent": "Estimate of our training procedure.",
                    "label": 0
                },
                {
                    "sent": "If you increase the number of parameters, there will be many more configurations of your neural net that can fit perfectly your training data, so effectively increasing the variance, and so you might be in that situation instead.",
                    "label": 0
                },
                {
                    "sent": "In this case, you'd want to somehow get to a better trade off and find a better way of regularising, so limiting the capacity of your neural network.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I guess since you know we've, I guess we could call it the creation of deep learning since we coined that term.",
                    "label": 0
                },
                {
                    "sent": "There's have been developments in trying to tackle either of these two issues.",
                    "label": 0
                },
                {
                    "sent": "So one of them.",
                    "label": 0
                },
                {
                    "sent": "So for the first hypothesis, if you think that the problems I'm underfitting part of this has been solved by the fact we're using GPS, we can wait longer when we're training and roll net if you're known that is stuck in a regime where it's in the plateau, while if you're using a GPU, you might not notice the plateau as much as we did before.",
                    "label": 0
                },
                {
                    "sent": "OK, so that solve part of the problem.",
                    "label": 0
                },
                {
                    "sent": "Which is better optimization methods?",
                    "label": 1
                },
                {
                    "sent": "I think Liz going to talk a bit about that fully half the time.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about batch normalization, which is you can think of as an attempt to try also to optimize better an if it's more like the second hypothesis.",
                    "label": 1
                },
                {
                    "sent": "That is the problem that you're facing and training deep neural Nets will use better.",
                    "label": 0
                },
                {
                    "sent": "You need to use better regularization and I'm going to talk about two ways of doing that.",
                    "label": 0
                },
                {
                    "sent": "The first one is to use unsupervised learning to get better regularization and the other one is to use something known as dropout.",
                    "label": 1
                },
                {
                    "sent": "To better recognize your new.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Net.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'm going to quickly talk about unsupervised pretraining.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is that if we think that on deep neural Nets are not sufficiently regularised, we need to somehow restricta potential solutions that training, well, fine.",
                    "label": 1
                },
                {
                    "sent": "When training on a data set, and the idea behind unsupervised pre training is that amongst all neural Nets amounts all configurations of the weights of the neural Nets that will want to explore.",
                    "label": 0
                },
                {
                    "sent": "We want to restrict ourselves to neural Nets that understand the difference between essentially.",
                    "label": 0
                },
                {
                    "sent": "Real data and any other type of data such as random data.",
                    "label": 0
                },
                {
                    "sent": "So we'd like to know.",
                    "label": 1
                },
                {
                    "sent": "Net where the hidden units sort of understand that this is a well formed image of a character irrespective of what the identity of that character is.",
                    "label": 0
                },
                {
                    "sent": "And this isn't OK.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So known as that to some extent this is actually a harder problem than just classification, because presumably it would help to know that this is, you know, a good signal that that comes from my training distribution.",
                    "label": 0
                },
                {
                    "sent": "If I knew that there were zeros and ones, and twos and threes, and so on.",
                    "label": 0
                },
                {
                    "sent": "So amongst when I'm training this deep neural net, what I want to do here is to add some unsupervised learning signal such that my hidden units are not just good at predicting the target class.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "They also aware that.",
                    "label": 0
                },
                {
                    "sent": "You know, I expect things like this and I don't expect things like that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you're going to see a lot of unsupervised learning algorithm during this summer school.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about a very simple one, which is the auto in quarter.",
                    "label": 0
                },
                {
                    "sent": "It's not the one that's used the most currently, but it has been used as like a first step to another better learning algorithm, unsupervised learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "You're going to see denoising autoencoders.",
                    "label": 0
                },
                {
                    "sent": "For instance, I think this game is going to talk about that, and it's based on this so.",
                    "label": 0
                },
                {
                    "sent": "So there is a feedforward neural net.",
                    "label": 1
                },
                {
                    "sent": "Yeah, I'm showing one with a single hidden layer by which at the output tries to compute a reconstruction of its input.",
                    "label": 1
                },
                {
                    "sent": "So now instead of trying to predict that the output able Y, we're actually going to try to predict the input, reconstruct the input.",
                    "label": 0
                },
                {
                    "sent": "So this is what I'm calling X hat here.",
                    "label": 0
                },
                {
                    "sent": "So for that we need to define the last function.",
                    "label": 0
                },
                {
                    "sent": "If you have data that's between zero and one one loss, that's often uses the cross entropy.",
                    "label": 0
                },
                {
                    "sent": "It's more precisely the sum of Bernoulli cross entropies, so X hat K is going to be the reconstruction from the cat dimension of my input space, so I get this by doing a linear transformation in my hidden layer and passing that through a sigmoid so I get a number between zero and one, and I'm going to compare that with the true input, which might be binary or might be between zero and one.",
                    "label": 0
                },
                {
                    "sent": "OK, so if I talk a bit I give more details about this in my online videos, but if you look at this you'll see that the best thing you can do is have X hat K match XXK.",
                    "label": 0
                },
                {
                    "sent": "If you have real value data which is not between zero and one we often use instead the.",
                    "label": 0
                },
                {
                    "sent": "Squared difference.",
                    "label": 0
                },
                {
                    "sent": "For the squared distance.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so that's what algorithm that we could use, and you can see that if I'm trying to reconstruct the input where I need to learn something about the structure, what you know what these inputs look like if I'm trying to reconstruct images of digits, handwritten digits, it might be useful to have hidden units that detect different types of pen strokes, because that's how we write digits.",
                    "label": 0
                },
                {
                    "sent": "We essentially draw pen strokes and to encourage the hidden units to be safer handwritten character classification to detect these pen strokes.",
                    "label": 0
                },
                {
                    "sent": "What we'll do is that will train in a greedy way.",
                    "label": 0
                },
                {
                    "sent": "Each hidden layer as a note on quarter.",
                    "label": 0
                },
                {
                    "sent": "So we'll start by training the actually pre training the first hidden layer as an auto encoder.",
                    "label": 0
                },
                {
                    "sent": "That is, I'm going to compute my hidden layer and then I'm going to try to reconstruct my input and I'll do that for a certain number of iterations, which is going to be a hyper parameters and then after some time I'll stop out, freeze these weights and then compute the value.",
                    "label": 0
                },
                {
                    "sent": "The representation of the first hidden layer of all of my inputs.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to train my second hidden layer to reconstruct the first hidden layer representation of my inputs.",
                    "label": 0
                },
                {
                    "sent": "So learn good features of my first hidden layer.",
                    "label": 0
                },
                {
                    "sent": "I do this for certain number of time and then I fix these weights and I repeat this for the third hidden layer and so on until I've pre trying the number of hidden layers that I want.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first thing layer features will hidden units will correspond to features that are coming in training inputs, but not necessarily in random inputs because they're not training random inputs.",
                    "label": 1
                },
                {
                    "sent": "They're trained on my input distribution.",
                    "label": 0
                },
                {
                    "sent": "Second layer is going to be combinations of hidden unit features that are more common than random combinations, and so on.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I think that we found other regularizers that are there at least is good and I think that currently anyways.",
                    "label": 0
                },
                {
                    "sent": "Unsupervised pre training is more useful in the setting where you have a lot of unlabeled data that is.",
                    "label": 0
                },
                {
                    "sent": "So the question sorry is that also by switching is not something that's actively used currently.",
                    "label": 0
                },
                {
                    "sent": "If you look at different papers it's not used a lot.",
                    "label": 0
                },
                {
                    "sent": "Small used in the in this context of semi supervised learning because of since I don't need labeled data to pre train these hidden layers, I can actually do this on a lot of unlabeled data and then move to my labeled data set to do what is the fine tuning without presenting a few.",
                    "label": 0
                },
                {
                    "sent": "So the latter networks right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So that's one example where there is unsupervised pre training and we're able to do really well with just a few label examples by exploring a larger set of unlabeled examples.",
                    "label": 0
                },
                {
                    "sent": "That's not semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So not really.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "I think I'll talk a bit about the relationship between you know, denoising auto encoders and trying to interpret them as as generative models also talk this afternoon about a version of autoencoder which is a generative model, but I will say that I can definitely tell you that what we came up with the idea we did not have a generative model in mind, that's that was not what I had in mind anyways.",
                    "label": 0
                },
                {
                    "sent": "But we studied it and turns out there's some interesting interpretations.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm I'm going to move on because I have almost no time.",
                    "label": 0
                },
                {
                    "sent": "Take questions after, by the way, you know during the coffee break no problem so.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So anyway, so that's the pre training algorithm.",
                    "label": 0
                },
                {
                    "sent": "I just wanted to quickly you start from your input layers and then what you do is that you Rep you construct an unsupervised data set by mapping your inputs to the layer you've pre trained so far.",
                    "label": 0
                },
                {
                    "sent": "So initially featuring no layer.",
                    "label": 0
                },
                {
                    "sent": "So the representation is going to be the right input.",
                    "label": 0
                },
                {
                    "sent": "You feed that to an unsupervised learning algorithms such as the auto encoder and GBM is another option.",
                    "label": 0
                },
                {
                    "sent": "You'll learn about that later this week.",
                    "label": 0
                },
                {
                    "sent": "Do this for all layers and now this all serves as an initialization step, so you essentially replace this random initialization with this unsupervised learning based initialization and then after that you do what is called fine tuning, which is really backdrop.",
                    "label": 0
                },
                {
                    "sent": "That's backdrop that I've described so far, so we initialize the top weights connecting with the output as you normally do random initialization, and then you do stochastic gradient descent with mini batches like you did before.",
                    "label": 0
                },
                {
                    "sent": "So really, here we're just introduce a different way of initializing the parameters of a deep neural net.",
                    "label": 0
                },
                {
                    "sent": "I'll just.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start.",
                    "label": 0
                },
                {
                    "sent": "Another option for Regularising Underall net or deep neural net.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That particular is dropout.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was proposed fairly recently.",
                    "label": 0
                },
                {
                    "sent": "The idea now is to avoid overfitting.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as we're trying to cripple training of the neural net, and we're going to cripple the training process by removing hidden units in a stochastic way.",
                    "label": 0
                },
                {
                    "sent": "So for each hidden unit.",
                    "label": 0
                },
                {
                    "sent": "Will determine which probably 0.5 whether we're going to zero out that hidden unit we're going to multiply it by zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so an we independently for each hidden unit, determine whether we're going to do that or not.",
                    "label": 0
                },
                {
                    "sent": "So, say in this case I've sampled that I would multiply by zero here and here, but not here, here and here.",
                    "label": 0
                },
                {
                    "sent": "OK, so effectively if I multiply by zero, it means that it's as if these connections going into and out of these units don't exist.",
                    "label": 0
                },
                {
                    "sent": "They're not even present.",
                    "label": 0
                },
                {
                    "sent": "There are not going to be trained.",
                    "label": 0
                },
                {
                    "sent": "When I do my backpropagation because their gradient is going to be 0 because they don't impact the output.",
                    "label": 0
                },
                {
                    "sent": "So this probability of 0.5 is a hyperparameter, but conveniently, 0.5 tends to work well.",
                    "label": 0
                },
                {
                    "sent": "You can also do that on the inputs, usually with a smaller probability.",
                    "label": 0
                },
                {
                    "sent": "But sometimes some people do that as well.",
                    "label": 0
                },
                {
                    "sent": "Ann, this sampling of this dropping out pattern you do for each update, so that's something that you do every time before you do an update, you sample these masks, the sampling these masking patterns.",
                    "label": 0
                },
                {
                    "sent": "OK, so more specifically, the way we update the feedforward equations is just by adding this element.",
                    "label": 0
                },
                {
                    "sent": "Wise multiplication.",
                    "label": 0
                },
                {
                    "sent": "Uh Vay mask vector, where you've sampled each dimension by randomly picking with 0.5 probability where it's going to be 1.",
                    "label": 0
                },
                {
                    "sent": "Or 0.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's all that changes at training time.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So backdrop is changed.",
                    "label": 0
                },
                {
                    "sent": "Also, you have to take that into consideration and backdrop first by the fact that, well, the activations.",
                    "label": 0
                },
                {
                    "sent": "Now I've been computing using these masks and also when you back propagate to the lower layer, in addition to multiplying by the derivative of the activation function, you're going to multiply by the mask so you can see that some of the gradients are going to multiply by zero.",
                    "label": 0
                },
                {
                    "sent": "They're going not going to back propagate.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not test time because we all want something stochastic.",
                    "label": 1
                },
                {
                    "sent": "We replace the masks by their expectation, which is your .5.",
                    "label": 1
                },
                {
                    "sent": "So we multiply by this constant vector with 0.5 everywhere and there is an interpretation of this where in the hidden single hidden layer case it actually corresponds to taking a geometric average of all the different neural Nets, with all the different patterns of dropping out.",
                    "label": 0
                },
                {
                    "sent": "That's something that you can show which was in part the inspiration for doing this.",
                    "label": 0
                },
                {
                    "sent": "The other reason why or one way of understanding why this helps is that if as a hidden unit you are not guaranteed that.",
                    "label": 0
                },
                {
                    "sent": "Other head units are going to be present are not going to be dropped out then your feature out to be useful by itself.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially the neural net is going to grow features which don't Co adapt with other features that are going to be more independent.",
                    "label": 0
                },
                {
                    "sent": "Lee useful.",
                    "label": 0
                },
                {
                    "sent": "There is another way of thinking about it.",
                    "label": 0
                },
                {
                    "sent": "There might be some redundancy.",
                    "label": 0
                },
                {
                    "sent": "So that's a good question.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether there is a lot of redundancy.",
                    "label": 0
                },
                {
                    "sent": "I can definitely tell you that this very often helps.",
                    "label": 0
                },
                {
                    "sent": "That's the feature is also visually 10 to be more interpretable than features you get with regular background.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and then the final trick that I really wanted to talk about because you're probably going to hear about it this week, and I don't think anyone else is going to talk about it is batch normalization.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a more recent trick, and what's interesting is that if you look at the paper, they will show that training is faster.",
                    "label": 0
                },
                {
                    "sent": "Norms of number of epochs, it tends to converge faster in terms of learning and also.",
                    "label": 0
                },
                {
                    "sent": "But somehow it seems to also have a regularization effect.",
                    "label": 0
                },
                {
                    "sent": "That is, people have noticed that when they use it, they don't necessarily need to use dropout anymore to get good results.",
                    "label": 0
                },
                {
                    "sent": "So I think we're still.",
                    "label": 0
                },
                {
                    "sent": "Trying to understand what is going on.",
                    "label": 0
                },
                {
                    "sent": "Why.",
                    "label": 0
                },
                {
                    "sent": "Anyways, I am still trying to, you know.",
                    "label": 0
                },
                {
                    "sent": "Finally understand what's going on with batch normalization but the idea.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is essentially that if normalizing my input layer helps, maybe it would help if I normalized other parts of the network at the hidden layer level OK, and so that's essentially what batch normalization tries to do.",
                    "label": 1
                },
                {
                    "sent": "The few key things to remember the normalization, where we subtract by the mean and the virus standard deviation is going to happen, not at the activation, not after the non linearity but before the non linearity.",
                    "label": 0
                },
                {
                    "sent": "Let's first thing to remember.",
                    "label": 0
                },
                {
                    "sent": "When we to get the mean and to get the standard deviation, we're going to get it from the current mini batch, not the global mean or global standard deviation from the current mini batch.",
                    "label": 0
                },
                {
                    "sent": "Back propagation is going to take into account this.",
                    "label": 1
                },
                {
                    "sent": "It's not going to treat the mean and the standard deviation as constants, so gradients will flow through the computation of the mean and the computation of the standard deviation and at Test time we replace this mean and standard deviation by the global mean and the global standard deviation that we will compute once and for all, and then we can deploy this network and apply it on new data.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is essentially the transformation.",
                    "label": 0
                },
                {
                    "sent": "It's taken out of the paper.",
                    "label": 0
                },
                {
                    "sent": "So imagine X say.",
                    "label": 0
                },
                {
                    "sent": "X. I is going to be Despres activation of a given unit and this XI up to M is just all the pre activations of that unit in the mini batch.",
                    "label": 0
                },
                {
                    "sent": "So if it's mini batch of size 64 or 64 numbers here.",
                    "label": 0
                },
                {
                    "sent": "So this is just computing the mean, computing the variance and I'm taking the square root with a small constant in case the variance was zero so it's numerically stable.",
                    "label": 0
                },
                {
                    "sent": "There is one thing here that batch normalization does is that before feeding instead of feeding X hat to the activation function.",
                    "label": 0
                },
                {
                    "sent": "I'm actually going to feed a linear transformation of it, so I'm going to multiply it by a scalar gamma and then add a bias better, and these are now part of the parameters of the network.",
                    "label": 0
                },
                {
                    "sent": "I am doing gradient descent on these parameters as I train them.",
                    "label": 0
                },
                {
                    "sent": "So the reason we have this is essentially to make sure that you can essentially explore all of the range of the activation function.",
                    "label": 0
                },
                {
                    "sent": "So if you were to normalize everything by removing the minion, dividing by the standard deviation with the sigmoid, you'd be stuck in the linear regime always, so this allows it to sort of explore saturation regime, but at least it gets an input which is normalized, so it's going to be in practice we say it's better behave this way.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why normalize the preactivation?",
                    "label": 1
                },
                {
                    "sent": "Well, at least initially.",
                    "label": 1
                },
                {
                    "sent": "All units are guaranteed not to be in the saturation regime, so that might be helpful.",
                    "label": 1
                },
                {
                    "sent": "Even though the linear transformation can cancel this effect, but it would be later on in learning while use many matches, well, because we're normalizing units, the normalization depends on the parameters and the parameters are constantly changing while we're training, so we don't want to go over the whole training set every time we need to compute or update this mean and standard deviation.",
                    "label": 1
                },
                {
                    "sent": "So we use a mini batch instead, and it adds some stochastic city in the computation on a network, which might be useful.",
                    "label": 0
                },
                {
                    "sent": "It might act as a sort of crippling effect that dropout has, which seems to bring some regularization, and in fact they do notice in the paper that proposes that they don't need dropout as much anymore.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's taking into account normalization by backpropagating the gradient through the mean, so remember that when I'm computing the mean and standard deviation, my pre activation is present in that mean, and that standard deviation.",
                    "label": 1
                },
                {
                    "sent": "So I need to take into account the gradients.",
                    "label": 1
                },
                {
                    "sent": "The gradients are so as exercise.",
                    "label": 0
                },
                {
                    "sent": "I encourage you to look at the paper they provide the gradients just check whether you can derive them.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of exercise you would have to do if you want to propose a.",
                    "label": 0
                },
                {
                    "sent": "A new method or a new module in a neural net, so it's a good exercise to try out.",
                    "label": 0
                },
                {
                    "sent": "And use a global mean at Test time.",
                    "label": 1
                },
                {
                    "sent": "Well, so that it's not stochastic once you apply it.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I had other stuff but that was more or less optional, so I'm going to stop here.",
                    "label": 0
                }
            ]
        }
    }
}