{
    "id": "y57bu3czd2kxbwaxhn2knilbsyk7jhb5",
    "title": "Weighted Transducers and Rational Kernels",
    "info": {
        "author": [
            "Mehryar Mohri, Courant Institute of Mathematical Sciences, Google Research"
        ],
        "published": "Dec. 14, 2007",
        "recorded": "October 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods"
        ]
    },
    "url": "http://videolectures.net/aop07_mohri_wtt/",
    "segmentation": [
        [
            "Alright, I'm going to start and hopefully further people start coming.",
            "Since we're going to start gradually, don't manage to catch up.",
            "I'm Mary Armori from the Courant Institute of Mathematical Sciences and.",
            "I'm also working for Google Research and this is joint work with much of this tutorial is joint work with Carina Quartus, but as you'll see on the slides there's a bunch of other people that are coauthors.",
            "The title is weighted transducers theory and algorithms, and in fact what I'm going to be speaking about is going to be both.",
            "Transducers in the first session and then later on about their use for well, using the title of this workshop.",
            "The analysis of patterns.",
            "Kernel kernels based on strings, and this kind of things."
        ],
        [
            "So let me start with some of the type of problems that's not mine, is it?",
            "Sounds like Windows kind of things.",
            "Let me start with one problem that.",
            "So people see often in speech recognition you know the task that consists of transcribing speech into text.",
            "One problem, in fact, more precisely spoken dialogue classification, so people speak into a microphone or pick up the phone and talk to make your reservation for a ticket and then the task consists of not necessarily recognizing in fact, perfectly what people said, but trying to classify what they said and the classification here consists of assigning a category out of a finite set of categories such as referral precertification.",
            "If it's a spoken dialogue system that's designed for healthcare systems.",
            "And to each speech utterance.",
            "So every time somebody says something, the dialogue manager is going to say, well, this is related to referral, or if it's something that is corresponding to AT&T or other systems of this kind.",
            "It's going to say this is related to credit.",
            "But here is an example.",
            "If somebody says, for example, hide.",
            "This is my number, what the speech recognizer outputs is not just one single transcription, but in fact a bunch of possible hypothesis, all of them compactly represented by what people in speech recognition called word lattice, and that is simply a acyclic weighted automaton.",
            "So as you can see.",
            "It's graph labeled with words and our weights along that path and the weight of a path is obtained by summing up the weights along that path and the pass with the smallest weight is there.",
            "Recognizes best guess, but that's not always correct, so it often makes sense to instead of just keeping the best path.",
            "In fact, in this case, it's not the best, because hi, this is my number.",
            "Does not have the smallest weight.",
            "If you look at it closely, so instead it's better to take the recognizers set of hypothesis, which often contains the right answer.",
            "OK, so I'm just trying to give you some examples of the type of problems that."
        ],
        [
            "Come up in various applications.",
            "A similar situation arises in computational biology where one might wish to decide, for example, which Class A protein family belongs to and the objects to classify.",
            "In that case are, well, not necessarily, then single protein sequences, but perhaps put in clusters.",
            "So you can see the two examples that I gave you so far the the objects to classify are not anymore just a single sequence, but even a set of sequences.",
            "In fact, the distribution over sequences, so that's what you have to classify.",
            "You have to assign a category to something of this kind."
        ],
        [
            "So this is a general problem that arises in spoken dialogue classification, computational biology, information extraction, or search engine systems, where each time the model does not output a single hypothesis but a set of hypothesis and each one of them ranked according to the system and information extraction system, for example, and so in fact you have to collect that set of hypothesis and often.",
            "You want to assign a category to that set so that arises again in text mining, document classification, database queries, and a variety of other applications so."
        ],
        [
            "This is, in a sense reflecting the state of this world.",
            "The data that we are dealing with is not anymore the fixed size vectors, perfectly designed for, say, compilers.",
            "Compilers that expect a very well written source code that you can analyze the type of objects that we need to analyze are more complicated.",
            "They can even be distributions of sequences.",
            "Typically represented by automata, variable length sequences, and certainly not what the standard learning algorithms used to expect, at least.",
            "So the question that comes up, and this is not a really novel question, is how do we design or how do we generalize existing learning algorithms to deal with variable length sequences?",
            "Or even, as I said, more complicated things such as.",
            "Distributions over variable length sequences OK, and you saw the terms weighted automaton transducers coming up several times.",
            "This is going to."
        ],
        [
            "A little bit.",
            "Object of the first part of this tutorial where.",
            "I'm going to quickly tell you about weighted transducers.",
            "Let their algorithms the little bit of the theory that is behind it, because that's going to be useful for later talking in the second part about kernels for computational biology and text and speech processing.",
            "Now, however, this first part weighted transducers that's relevant not just to designing kernels, but to variety of other applications in which strings sequences might occur, and in fact the objects that I'm going to speak about are used in such applications for designing large scale speech recognition systems.",
            "Natural language processing systems.",
            "In fact, there are even used in products.",
            "For this kind of things.",
            "So the 1st in this first part you're going to hear about weighted transducers.",
            "As I said in algorithms for about, I don't know something like an hour and I can talk about it as much as you want.",
            "I'll probably have to shorten it due to lack of time and then later on I will be speaking much more in detail about kernels, their use, and in fact not been looking at each one.",
            "Variety of kernels in biology and text and speech processing."
        ],
        [
            "Alright, before even starting the part about weighted transducers, let me just mention that almost any one of the algorithms and I'm going to be speaking about in what follows.",
            "We had already implemented with two colleagues of mine, Fernando Pereira and Michael Riley at agency, and that library is available for download.",
            "But only the executables of that library were available because we were working on a 20 but now much more recently joint work between crowds at NYU.",
            "You and Google has produced an open source library which we have called.",
            "Open FST and that one is available for download, including of course, the source code and it's an open source project.",
            "OK, so you can get it from open fc.org, so you should be able to download these things, and in fact do a variety of build a variety of things with it, including really, really."
        ],
        [
            "Large scale ones alright so.",
            "I'm going to be speaking about some definitions for weighted automata transducers and then a series of algorithms composition, shortest distance algorithms, epsilon removal, determinization pushing minimization.",
            "No, I'm not going to speak about all of them, because obviously we won't have time.",
            "So probably I'll stop somewhere here if you want to hear more, I'll continue, OK."
        ],
        [
            "So let me start with some algebraic definitions in the title.",
            "There was weighted transducers and the first question is what does it mean weighted and what weights are we talking about?",
            "And well, I gave you an example.",
            "In the case of speech recognition where you could see that the weights along the path were added, for example, that's not necessarily always the case.",
            "He more generally.",
            "Algebraic structure those weights could belong to an arbitrary set, but we need some rules.",
            "Well defined rules to combine them.",
            "So we need in fact what's called this semiring is simmering is.",
            "L ring it's half of a ring.",
            "If you like it's a ring that may lack negation, so it's a little bit like if you were taking non negative integers, right?",
            "You don't have negation, you have plus multiplication and you'll see that there is.",
            "There are some other Al give you in a second and some other examples of semirings.",
            "We need the two operations of the simmering, so it's the set is K. The two operations pronounce denoting in a very general way you know plus and all times zero is the identity element of the first operation and won the identity element of the second operation.",
            "We need both operations sum and product the product to compute the weight of a path by multiplying using this abstract multiplication to combine the weights of of compute the waiter path and we need some because there might be several path labeled with the same string.",
            "So the weight of his string is obtained by summing up the weight of the path labeled with that string using that.",
            "Some operation, so let me give you some."
        ],
        [
            "Examples of that.",
            "And is there is really a reason why I'm talking about these different semirings?",
            "One general reason that I can tell you is because they come up in a variety of applications in text processing, speech processing, even designing kernels.",
            "But there's also a mathematical and algorithmic reason to it is because you can write algorithms that abstract away from what the underlying algebra is OK, and here are some examples of semirings.",
            "The first one is a familiar one, the Boolean semiring that's commonly used in logic and other applications.",
            "The second one is the probability semiring, so this set is the set of non negative real numbers.",
            "Would say why don't you just restrict yourself to 01?",
            "Well because otherwise it would not be a semiring because if I add up numbers, in that case they can go beyond one.",
            "Anne.",
            "The first operation there in just plus the second operations that familiar multiplication identity elements are zero and one, and of course these are the.",
            "This is the semiring that we deal with when we're building probabilistic models.",
            "Now.",
            "However, nobody would be using this in practice.",
            "Why?",
            "Anybody who's a computer scientist could answer this right away.",
            "There's no way you would be using this simmering in practice, because if you multiply small numbers probabilities.",
            "Very quickly you run into numerical stability issues, right?",
            "So instead in practice, people use their log of those probabilities and then instead of multiplying weights along the path, you add them up then and the corresponding simmering is what I refer to as being the log simmering.",
            "You simply isomorphic simmering simmering as as amorphic two to the probability simmering by taking minus log.",
            "Of each wait.",
            "OK, so now what used to be multiplication is simply addition, because now we have to.",
            "We have taken minus lot and what used to be plus is another operation called that I called plus log and it's defined by this X plus log Y is minus log of exponential of minus X plus expression.",
            "Wonder why and you can verify the fuse that operation it does just exactly what you want summing up the probabilities if you like.",
            "Alright, and then there is another SIM hearing that people call a tropical semiring and that differs from the previous one only by the operation and all the rest is the same.",
            "The only thing that you do there is by is replacing what used to be the plus lock operation by minimum.",
            "So let's let's try if I just this tropical semiring.",
            "That's good so.",
            "So again, it's a familiar simmering.",
            "Why?",
            "Because this is the one where you're adding weights along a path, and then you were taking the minimum, so that obviously makes you think of shortest path algorithms, right?",
            "And in fact, this is probably the main reason why we are talking about the tropical semiring.",
            "By the way, why tropical?",
            "It's because the first person who started to talk about the simmering in the main person who's been studying it is inbred.",
            "Simone, who's living in Brazil and so people as a reference to that, started calling it this way so.",
            "You realize going from this semiring to this other semiring.",
            "If you were changing semirings in that case, you would be doing what I could refer to as being the.",
            "Viterbi approximation.",
            "Right, you're not changing anything.",
            "You suddenly just changing the plus operation in this, and that corresponds to keeping the among different probabilities for the for the same string, the dominating one.",
            "That's exactly what people refer to as being there better be approximation, so this is in effect in algebraic view of the verbal approximation.",
            "And the main reason, by the way, where white people have been talking about the Victoria approximation is algorithmic is because you would never talk about the Victoria approximation.",
            "If you could do everything without doing that approximation right, you do it because because that's what you know, shortest path algorithms.",
            "That's something that you can you can use."
        ],
        [
            "Alright.",
            "So I talked about weighted automata several times, or here's definition with the picture awaited automaton is a directed graph labeled directed graph, where in addition to the familiar labels, such as a, for example here, there's also some weights on each transition.",
            "So here are the weight is indicated after the slash 0.5 for example.",
            "And as we said, the weight of a path.",
            "Is obtained by multiplying the weights along that path.",
            "But now now we know that we are talking about multiplication and summing that general way, so don't always expect this sum and product to be the usual summer product they might be.",
            "You know mean and plus for example, in the lock simmering, so the weights are added along are multiplied along the path and the weight of his string is obtained by summing up the weights of the path labeled that string.",
            "So for example, the weight associated by this automaton to the string ABB is obtained by looking at the two paths ABB, this one, and by the way there is a double circle, indicates a final state.",
            "A bold circle indicates an initial state in this figure.",
            "And that final states there might be an additional weights that you take as you just leave the machine.",
            "OK, so the weight of this upper path there is .1 times .2 * .3 times .1.",
            "It's this right?",
            "And then there is another one, this path ABB, so that one is .5 * .3 times .6 times transferred.",
            "One you add these two and that's the weight associated by this automaton to the string ABB OK."
        ],
        [
            "Now it's slightly more general.",
            "Object is what's called a weighted transducer, which is a little bit more general than what we talked about, just by the fact that in addition to the usual input symbol A, you might also have on each transition and output symbol.",
            "Here B indicated after the column OK, and similarly there are weights and in the same way the weights are multiplied along the path.",
            "You take this sum.",
            "To compute the weight associated now, this time not to a single string, but to appear of strings.",
            "Which would be the string obtained by concatenating the inputs and concatenating and the other string obtained by conquering the outputs.",
            "This is the weight associated by this transducer T to the pair of strings ABB BAA so.",
            "Of course I've cooked this example in sort of the same to pass would be used here, so the upper path, now its input is the same ABB as we had before, and the output is B. AA right so and the weights are obtaining the same way by multiplying them.",
            "There are two weights to pass label with these pairs and the weight associated by the transducer to that pair is the sum of the weights of these two path.",
            "OK, you'll see that these objects weighted transducers as simple as they are.",
            "In fact they become crucial.",
            "Suddenly if we're talking about things like kernels and positive definite symmetric kernels."
        ],
        [
            "And there are some standard operations that can be used to combine weighted transducers, natural ones.",
            "The first one is a sum.",
            "It turns out that if you take the sum of two transducers, you obtain another way transducer, and it's the weighted transducer that I denote by T 1 + C, Two which associate's to each pair.",
            "Well, the some of the weights associated by these two transducers.",
            "Then there's another operation product which associate's to each pair XY, not the product of the of the two weights, but instead of product.",
            "Maybe here to give you the intuition I should talk about concatenation.",
            "OK. Where you can see here that it's in fact this some.",
            "Over of T1 of X1Y1T times, T2X 2Y2 over all possible ways of decomposing the input string X into a prefix X one and a suffix X2 and decomposing the output string Y into Y1Y2 OK. And then there's another operation that's familiar.",
            "One is when it's called closure or cleaning closure.",
            "In the unweighted case for standard on weighted automata, and that's the one obtained by taking the sum of the TN of XY, where TN is the multiplication of T by itself and minus one times OK according to this definition of multiplication.",
            "So here to understand this product again, you have to think.",
            "As cook, concatenating a transducer with itself.",
            "The T 1 * T Two is a concatenation of T1 with teachers, so they passed that you could read in T1.",
            "You didn't continue reading the rest in T2.",
            "Right, so that's just to say that there are some standard operations that you can use to combine transducers.",
            "And again again, you obtain more other transducers, so from simpler ones you can create more complex ones."
        ],
        [
            "But it turns out that there is an operation called composition that is in fact really the most fundamental one for combining transducers that comes up in a variety of applications for four.",
            "Also creating more complex transducers from simpler ones.",
            "But the reason why it becomes fundamental is because.",
            "It's a mapping a transducer from, say, one information source to another one.",
            "So composition helps you take the output of that mapping and map it yet another to another information source.",
            "And by doing this you can create complex systems such as speech synthesis, system, speech recognition systems, information extraction systems.",
            "By composing these each one of these components information sources to create more complicated things.",
            "And you will see that also for creating complex kernels you can use the same."
        ],
        [
            "Operation, so let me explain what this operation corresponds to.",
            "The composition and it's indicated by a little circle, the composition of two transducers T1 and T2.",
            "Turns out to be a weighted transducer as well.",
            "It's the one that associate is associated to the pair XY.",
            "This sum of T1 of X y * T two of ZY where the sum is over all possible strings E so that so not to give you the intuition it's over, the sum is over all possible strings that could be an output of a path in the first transducer and the input of a path in the second transducer.",
            "So it's a composition is a matching operation.",
            "If you like it match so you another view of it.",
            "Is that the transducer T1 map strings to some other set of strings on T2?",
            "Takes those strings and Maps them, get another to another set of strings and the weights are obtained by multiplying the weights of matching path and then you take this sum over all possible matches.",
            "OK, I'm going in a second is going to become more clear and as I'm going to describe the algorithm that is used to compute.",
            "Composition the algorithm in the epsilon free case epsilon is empty.",
            "Work the symbol that you know what you don't need to consume anything.",
            "When you're taking a transitional label with epsilon.",
            "When there's no epsilon, the algorithm is very simple.",
            "It just consists of matching.",
            "You would want to match path, but in fact you can just see more simply match transitions in the general case you need what's called an epsilon filter and I'll describe how this works.",
            "The complexity of the algorithm is quadratic is the size of the transducer T1 the size here is the sum of the number of transitions and states times the size of the transducer T2.",
            "This only occurs though in the case where every transition of the first machine matches every transition of the second machine, which is a very rare situation.",
            "So in practice the composition is much more efficient than what this worst case would indicate, and another aspect of composition that's very crucial in practice is the fact that you can do an on-demand construction of the result, in other words.",
            "You don't really need to in the cases where T1 and T2 are very large.",
            "Now they might have 100 million transitions.",
            "This is the type of things that sometimes we deal with.",
            "If both have 100 million transitions, you don't want to take T1 compose BT two and just build the whole thing.",
            "While you might only need some part of that compose machine instead, you can try to do what people in computer science refer to as being either that lazy evaluation.",
            "Or an equivalent term is actually dynamic computing computation.",
            "These things lazy dynamic seem to be the same in computer science for some reason.",
            "So what you do is that you only build we wanted somebody tells you to completely build the composition.",
            "You actually do nothing.",
            "You start building things only if somebody asks you for the output of that composition.",
            "OK, that's on demand."
        ],
        [
            "So.",
            "In the Epsilon free case.",
            "So again, when there is no epsilon transition, things are very simple.",
            "Composition consists of creating a new machine which for which the states are pairs of states of the original two machines.",
            "OK, so the set of states are pairs of Q1 instead of.",
            "States are the 1st in queue to sort of the states of the second machine.",
            "The initial states are simply the set of pairs where both states are initial.",
            "The final states are those states of Q that are both final and the transitions are obtaining this simple way.",
            "There is a transition from the pair Q1 Q prime one to the pair Q2 Q prime two with input a an output.",
            "See when there is a transition in the first machine from Q1 to Q2 with input a, an app would be and transition in the second machine from Q prime.",
            "One to Q prime two with input B you see it has to match the output here with input B and some output C. Whenever this happens, you create a new transition from despair to that pair with input.",
            "What used to be the input here on output, what used to be the output of this one.",
            "OK, and the weight is obtained by multiplying the weights of these two transitions.",
            "So it seems like a very simple thing to do and let me just illustrate it."
        ],
        [
            "In a particular case, at the same time I'm writing up there what you could use, you could write using the libraries that I mentioned, either the FSM library or the open source FST library.",
            "Here are two transducers, and this is the result of the composition.",
            "As you can see here the states corresponds correspond to pairs of states.",
            "So originally you start at the initial state of this machine and the initial state of this machine.",
            "So that's the pair 00.",
            "And then you're asking, well, if I'm leaving this state, what are the transitions that are obtained in this case?",
            "There's only one transition, the one with input A output B and you're asking if there is any transition leaving the initial state of the second machine that matches it matches it in the sense that the output of this has to match the input of that, while in this case the two match well, the input B matches the output be.",
            "So then I create a new transition from that pair 00 which goes to where it goes to another pair which is the destination state of this transition and the destination state of that one.",
            "So it's the pair 11.",
            "And then the input label of that transition is the input label of the first.",
            "The transition in the first machine, and the output is as we described before.",
            "The output label of the transition in the second machine, and the weight is obtained.",
            "In this case, we're in the plus time, simmering the usual operations.",
            "The weights are simply multiplied .1 times .1.",
            "That's .01 OK. And then I just continue from here alright.",
            "And you can see here that I've indicated something in red here.",
            "That's because we were now in, so it's the pair corresponding to three.",
            "One was in state, three in the first machine state, one in the second machine, and then I was asking again what are the matching transitions?",
            "Well, from here there is only one outgoing transition, that's AA.",
            "It matches which one of?",
            "The transitions leaving this one it matches both this and this right?",
            "But look at the one that matches this one.",
            "So I create a new transition for that one.",
            "This matches this, so I have a new transition AB that goes to 3, two OK. With whatever the weight obtained by multiplying the weights .6 times .3.",
            "But you can see that I'm not continuing from there on.",
            "Why, because once I let stay 3 here and stay two, I'm looking at matching transitions and I see that this still expects an A as an output, but here there is no a for any going transition, so I have to stop.",
            "So that means that in fact.",
            "That state is not going to be very useful because it's not going to admit any transition to a final state.",
            "So in a sense, once I'm done, I can just remove that state and that transition.",
            "I just want to indicate it still because these are some States and transitions that you might create during the execution of the algorithm, but that later on you will have to get rid of OK so you can see it's a very simple algorithm, very intuitive matching it's.",
            "Combining two mappings and at the same time taking advantage of the weights associated with those."
        ],
        [
            "Mappings OK.",
            "But things become a little bit more complicated when in addition to the usual labels, you also have epsilon transitions, Epson labels, and that's something that you need in all applications to use epsilons, the empty string.",
            "So take the case in fact of two very simple transducers.",
            "I mean, both are just, you know, linear chain.",
            "So you want anti two and in fact I'm not even indicating the weights here.",
            "Take them to be all equal to 1 OK.",
            "So now if I want to create the composition of this two transducers, well, I can try to proceed in the same way as in the epsilon free case.",
            "By studying at the pair 00 and then combining the first 2 transitions A&AD to create a transition that goes from zero zero to 1, one with input a, an app would be OK.",
            "So now I'm state one in the first machine state, one in the second machine.",
            "And now comes the problem because.",
            "I have an epsilon labor for the output of the transition, leaving state one in the first machine and here two.",
            "I have an epsilon leaving the state one.",
            "So what do I do?",
            "I can have different alternatives like we say, well, I can do things in the same way as in the epsilon free case.",
            "I can just pair epsilon and epsilon and create a new transition by matching those two.",
            "By doing that I would go from State 11 to State 22.",
            "OK, by pairing the two epsilons or I could say well look epsilon is not a real label.",
            "So let me just move forward on one of the first machines on the 1st machine.",
            "Consume all the epsilons that I can find until I find a real label to match with OK. Or I can say the same in the second machine.",
            "Doing this suddenly gives me a bunch of different alternatives, and, for example, continuing on the 1st machine by just reading epsilons that's doing this, that's continuing on the 1st machine, staying at the same state in the second machine.",
            "I could continue on this first machine and saying in the same state, so it gives me all these possible path for creating composition.",
            "That's too many path because in reality.",
            "I'm creating here.",
            "So each path is going to have weight one, and since I have to add up the weights of these path, I'm in fact going to be created associating a weight that is the number of path that I've created instead of just associated weight one, because that was just I was just matching.",
            "After all one string here with one string here OK and that is called the Epson path multiplicity problem.",
            "Instead of having all these paths, you should just keep one.",
            "So you could say, well, that's not a big problem, we just choose choose one.",
            "Any one of them is fine because after all, in terms of input output, they're all the same.",
            "It's just in what order I'm reading them.",
            "But which one and how would you select the particular path that you want?",
            "You could say, well, every time I want to create compositions, somebody is going to stand here and tell me well choose this particular path, yes?",
            "A few of the reasons mapping intended semantics, so I guess that at some point you have to think what do I intend to model and what's the right choice for what I'm trying to model, right?",
            "So the right things that I expect is that the weight should be the weight that corresponds to the definition of composition.",
            "So if I the weight, the weight associated by the compose transducer to an input X and output.",
            "Why should be precisely the product of the weights of these two?",
            "What is the semantics of his?",
            "In in re education, so maybe 10 four little examples so that we can see all this action which you have an example of.",
            "This is the example of how this works.",
            "Or something like that, really every speech.",
            "OK, when you try to order in process OK so.",
            "I guess I could.",
            "I could just say this in words.",
            "There you create epsilons in all these operations.",
            "When you for example taking the union of two transducers, the sum of two transducers to create that some you create.",
            "It's an artifact of the operations that you use.",
            "You need.",
            "You need those epsilons too.",
            "Doing good.",
            "But it's more than this.",
            "Let me just say so.",
            "This is it's a necessary artifact.",
            "As you said of various operations such as all the rational operations.",
            "In fact, some product or concatenation closure on this sum is obtained by creating a new state and putting up some transitions to the original state of the first machine.",
            "The product you have put epsilon transitions from this final state of the first machines with the initial states of the second machine.",
            "In the clip closure or cleaning closure, you need that epsilon to go back, but in fact it's even more than this in the case of transducers, because in the case of transducers there are certain mappings that you would not be able to use to define if you did not have epsilons.",
            "So, for example, if you.",
            "Take this one.",
            "I know if you can read from there if I have.",
            "This is from state Zero to state one, and if I wanted to have a loop that has input epsilon and outputs whatever C. OK.",
            "So this the fact that you can read epsilon on the input and then as many time produce as many seasons you want.",
            "This is something that this.",
            "This mapping is only possible, you can only describe it by having epsilons.",
            "You cannot remove the epsilons here.",
            "There's no way to write this transducer without using epsilon.",
            "So it is more than just an artifact in the case of automata, it is an artifact.",
            "You could say you could always get away with it.",
            "You could always not use epsilons in the case of transducers, that's not possible.",
            "OK, it is always possible to not have an epsilon epsilon, but it's not possible to not have an epsilon, C or similarly.",
            "Say C epsilon OK. Because you might wish to map all the strings that are of this kind.",
            "For example, were reading an arbitrary number of season erase PC's OK.",
            "I do think that FIFA at some point you can go back to your example of speech with the opening so we can see how that would translate into this.",
            "I think it will be so, so I'm not sure what you mean by the 1st.",
            "The first example that I gave was just to see the output of a speech recognition system so.",
            "We can see this graphically.",
            "Would be wise to do it?",
            "How would it look like if you have problems like that that we can relate to?",
            "Ending this condition of the populace.",
            "So I'm not still completely sure what you mean by this, but I I can, I can say maybe in words or I can I can give some other examples as we're going to.",
            "I could have given you in fact examples for.",
            "Because he sent A and if I'm trying to recall this switch on switch in the areas, I just want to advise it alright?",
            "Will let you.",
            "So epsilon is the empty word, right?",
            "So you might wish.",
            "Here's an example that might be helping you.",
            "Suppose that you want to compute the edit distance between two strings.",
            "OK, typically this is represented by talking to.",
            "People talk about a simple dynamic programming algorithm, and there's a very simple way of representing this with the transducers and that's this one.",
            "Suppose that the alphabet is just.",
            "Limited to two elements A&B for example.",
            "OK, so you would have a simple transducer that Maps well A to itself, but in that case you want to associate to it cost 0.",
            "Or you might want to have what's called dileesh and you map ETA epsilon for example with some cost.",
            "The standard way would be one for example.",
            "Or you might want to have an insertion, which means that now you go from.",
            "Empty string to assemble A and that also might cost you one, for example, or whatever other costs you choose, OK?",
            "So if you like, this would correspond here to deletions.",
            "This would correspond to insertions.",
            "OK, and again, for example, a simple transducer like this you would not be able to represent it without using epsilons, precisely because you want to talk about insertions and deletions.",
            "There are much more complicated ones than this one, and let me just also say, by the way, that what people talk about when they were talking about the edit distance.",
            "Much more complex edit distances can be computed in a.",
            "Very standard way using transducers composition and standard algorithms OK. Alright, so maybe this is a little bit too much for sophistication for some of the things that I'm going to be talking about, so I'm going to go a little bit faster in this, specially if you know if if already epsilon then this kind of things are novel Tees, then I'm going to go a little bit faster and this let me just say that it turns out that.",
            "I'm going to go too much into the details of this then at this point, it turns out that there is there is a way of selecting one path as opposed to all these different path that you needed and it turns out that that way of selecting a path can also be represented with a with a transducer.",
            "And it turns out that you can just simply change a little bit bit transducer T1 and T2 into T1 till 92~ and then compose them.",
            "Now this time using the usual epsilon free composition that I talked about before to compute the correct value of the transitional composition correct in the sense that you're not producing extra path.",
            "OK, this filter somehow helps you rule out all the path.",
            "In this case, except from this one, OK?",
            "I'm not going to go through the details of this unless you want to hear more.",
            "'cause I said, I feel like you know some of these things are maybe new for this audience so I can go back to them whatever."
        ],
        [
            "Like no OK. And I'm not going to give you then the proof of.",
            "Also why this filter is correct."
        ],
        [
            "And why it is doing?"
        ],
        [
            "Pricing OK and there are other filters.",
            "Other filters that you could choose yes.",
            "Just understand again that the role of EXO.",
            "So this is another building."
        ],
        [
            "And outpatient therapy sessions and the other one is introduces not just listen.",
            "So can you separate this Tuesday?",
            "I mean I want to allow deletions and insertions, but not in a naturalistic number of times.",
            "So Epson Epson almost always creates nondeterminism.",
            "Nondeterminism means that at a particular state.",
            "Labrador.",
            "Say it in session conditions without introducing nationalism.",
            "So, so you're right.",
            "Actually, although this is a good point that in fact epsilon uses introduces two things.",
            "One is the nondeterminism of the machine.",
            "Nondeterminism means that at a particular state you might need to follow several path.",
            "That's due to the semantic of epsilon, but indeed there is also the fact that it helps you define some mappings that you would not be able to define otherwise, and that's related to precisely the examples of this kind.",
            "I cannot separate them now in the way that you seem to wish, because separating them would mean that I would be able to get rid of the epsilon somehow here, but I cannot in in some cases, I just cannot get rid of them.",
            "OK, in terms of mappings because precisely the cases where I would have insertions or deletions of some material within the middle of a string.",
            "OK, I hope that's helping with.",
            "Alright, so too."
        ],
        [
            "To make it, make sure if you like."
        ],
        [
            "There are.",
            "There are situations in which you would have waited transducers such as these and these situations are standard situations that it happens all the time.",
            "We would have input epsilons or output epsilons, and somehow you have to deal with them when you are then composing these machines to create more complicated ones, yes.",
            "Something here, but I'm you order the code set up and I mean this is one thing that you can establish the accuracy of two automata, but it is not good for chronic stress, so they are more complicated.",
            "His object right fairly different.",
            "So that on that just, but actually Captain thinks so.",
            "Alright, so another set of algorithms that I want to talk about is that I've shortest distance algorithms.",
            "How you might say, well, these I know I've heard about them at school.",
            "You know why does he have to talk about this?",
            "Well, notice that I'm talking about shortest distance and not shortest path.",
            "And the main reason why I'm talking about this is because, again, we're going to need them to do various computations and.",
            "It's."
        ],
        [
            "Distance are not path because we're dealing with these general weights which might not be just in the mean plus case.",
            "So let me define the distance of a state from a state Q to the set of final states as being the sum of the weight of the path from that state to a final state.",
            "OK, the weight of a path you remember is obtained by multiplying the weights along that path, and then I'm taking this sum of all the path.",
            "The weights of all the path from that state.",
            "The final state in the particular case where the simmering is the tropical semiring, this definition coincides with the usual shortest path or shortest distance.",
            "Wait right?",
            "It's the minimum of the some of the weights of the path from that state to a final state, but we will need more.",
            "More generally, this definition, because we might deal with different semirings, and in particular we might deal with the probability semiring, right?",
            "If you now have probabilities, you would want to compute the sum of the weights of all the path from that state to a final state.",
            "So how do we compute that?",
            "Wait, it turns out that there are two ways of doing this.",
            "Of course, if you are in the case of the tropical semiring mean plus, you know how to do this, take any shortest path algorithm, those that you hear about at school Dijkstra's algorithm.",
            "Tropical, the topological order algorithm in the case of a cyclic graph, all of these are going to work, but in the most general case, that's you're going to have to come up with something different.",
            "He turns out that you can use.",
            "You can generalize the Floyd Warshall algorithm that is defined for all pairs algorithm, shortest path algorithms in the standard case to compute this, or to come up with a more general algorithm, which is a single source shortest distance algorithm that generalizes basically all the shortest path algorithms that you've heard about before.",
            "So I'm going to quickly describe these two because as I said, again, two algorithms that are going to be crucial for computing kernels, I'm going to tell you right away one is composition that I already talked about and the other one is shortest distance algorithms."
        ],
        [
            "So.",
            "This sort of the floodwater logarithm is the following."
        ],
        [
            "It's a very simple algorithm.",
            "You probably have heard about it when, as I said, we're discussing all pairs shortest path algorithms and textbooks, and it's the one that says that to compute the distance, sodium IJ here would be the distance from state I to state J to compute the distance from I to J.",
            "You look at all the path from I to J, but you first start by looking at all the path from.",
            "EG that go through the states that are numbered only one 2K that's at the Keith iteration.",
            "And then then you look at all the paths that are going from I to J and that that are going through the states one 2K plus one.",
            "And to do this you have to potentially go to K and then come back to 2K.",
            "That's the closure that you need here.",
            "OK, I'm not going to go too much into the details of this, but just to say that the algorithm is as simple as this, it has a triple loop and at each time you're updating the distance from I to J.",
            "By saying that it's whatever used to be the distance from I to J plus with this now generalized notion of plus.",
            "A path that goes 2 from I2K with a loop or cycle at K2K so I have to take the closure times the path that goes from KT J.",
            "So very simple algorithm.",
            "It was not completely trivial though.",
            "Well, almost trivial to realize that in fact this simple algorithm that was originally designed by Florida Warshel for all pairs can actually be generalized to other semirings.",
            "OK, in fact it works for all closed Semirings is simmering is closed when the closure operation is well defined for all the weights and that the sum, sum and product applied to infinite.",
            "Sociative iti commutativity work with infinite sounds OK.",
            "So that's it.",
            "That's the algorithm."
        ],
        [
            "Problem with this algorithm is that is its complexity because you could see that triple loop means that the time complexity of this algorithm is cubic.",
            "Even if you assume that the time to compute the plus and other operations of the simmering are constant.",
            "But that's not even the worst, because if you have a very large transducer which might have, as I said, 100 million transitions even if you were ready to wait for a very long time to compute it.",
            "The space complexity is even worse because you at least even in the in place implementation that I mentioned before, you still need to store that array of all pairs, so that's at least quadratic an if you have 100 million states, the square of that that's too much, even for the amount of memory that we have.",
            "So that means that this algorithm, both from the space and time complexity, is not very efficient.",
            "But that's about the exact it's exactly computing what you need, and it's computing too much because it's going to compute the distance from any state to any other state.",
            "But in particular, you can use it to compute the distance from any state to the set of final states."
        ],
        [
            "Another way in other algorithm that is much more efficient in practice for doing this, but that applies only to K close semirings.",
            "Is is an algorithm that is in fact the generalization of all the algorithms that you've heard about for shortest path algorithms?",
            "In the sense that.",
            "It works first of all for any key close simmering it cake low simmering isn't simmering in which when you stick this, some of the iterated XX to the power of I from zero to K + 1.",
            "Eventually, that's once you reach K plus one that's the same as this some when you go from zero to K. An example of this is for example, if I take the tropical semiring there, the sum is min.",
            "So in fact even for K = 0 that holds because the minimum of 0.",
            "And any non negative number is still just zero.",
            "OK so Trump tropical semiring verifies this.",
            "Even if you take the probability semiring, and if you have weights that are between zero and one, when you take this sum of X to the power of I very quickly at some point this the two.",
            "These two this inequality is going to hold in an approximate fashion.",
            "In fact, this is almost away.",
            "Computers are are giving you the result of X to the power.",
            "The sum of the X to the power of I.",
            "So this property holds approximately.",
            "Then in practice for the plus time simmering.",
            "And there is a way of generalizing the single source shortest algorithms to work for all semirings of this kind.",
            "In fact, there's a very simple algorithm that works for all of them.",
            "And the idea is to use this standard idea of relaxation.",
            "You remember what relaxation consists of four, Dijkstra's algorithm or other algorithms of this kind.",
            "It says I'm going to compute tentative distances from that source to each state, and then if I now have a transition from state to state Q.",
            "Maybe it's time for me to write a little bit this.",
            "Can you turn it into?",
            "Is that better?",
            "Can open it also?",
            "Well, that's going to be too much so.",
            "So suppose that you have now a.",
            "An edge from P to Q relaxation does the following.",
            "It says that.",
            "You have these distances that you tentative distances that you have computed so far, so for now you think that the distance to Q is DFQ and now you just update it.",
            "The distance to P. And now you're saying well.",
            "If the weights of this edges WE in the standard cases said well now I'm going to add the tentative distance DLP that I have.",
            "I'm going to add it to the weight of the edge, and if that sum is smaller than the distance that I had prepared previously computed for Q, then I should replace that DF Q by that some.",
            "OK so I'm comparing DFP.",
            "Us WAV OK, that's in the standard shortest path and I'm comparing it trying to see if it's less than DFQ.",
            "If it's less than, then that's going to become the New deal here.",
            "OK, So what am I doing?",
            "In fact in this I mean the shortest path.",
            "Our world where you remember is the tropical semiring.",
            "So the operations are mean and plus.",
            "So in reality another view of this.",
            "If I write it with respect to these general operations is that I'm right.",
            "I'm trying to see if the min of DFQ.",
            "I'm DFP times.",
            "W appears OK, that's what I'm looking at.",
            "I'm writing it on purpose by using these general operations.",
            "The Times of the tropical semiring is just the standard plus anmin.",
            "Now I'm going to in a second, replace it with the plus operation of the simmering.",
            "OK, so it means that in fact I'm now I'm going to raise this to.",
            "Say.",
            "I'm going to look at the minimum.",
            "Of.",
            "DFQ that's plus is the minimum.",
            "The minimum of the FQ&DAV times WE.",
            "If that minimum is equal, and that's a question if it's equal to the of Q, right?",
            "Then there is nothing to update.",
            "I'm fine if it is not equal equal then I have to update the FQ.",
            "So I'm not writing everything in terms of this general simulator to see now how I'm going to generalize this algorithm to the usual.",
            "Because the notional greeted Unequal is a notion that in fact comes from the Operation Min.",
            "But in general I might not have that definition.",
            "I might not know.",
            "Perhaps perhaps nobody is going to give me that partial order.",
            "OK, so I need to do this in a general way when someone I'm only using the.",
            "So this is called relaxation.",
            "Is simple idea.",
            "Again I have a distance, I add the weight of the edge I look at, look at the distance of the destination state.",
            "If it's less, I keep it as it was.",
            "If it's not updated.",
            "Simple idea, right?",
            "Well, in fact all the shortest path algorithms are based on that idea.",
            "Well, that same algorithm can be that same idea."
        ],
        [
            "Can simply be generalized.",
            "And that's the same code, and I'm not going to ask you to look at the details of that.",
            "Although you can see it's not that many lines, right, but it's just now generalizing everything to an arbitrary simmering that is K closed.",
            "This is the heart of it, and that's doing just the relaxation.",
            "Essentially the same as what we just wrote is the destination, the width of the destination state, the same yes or not than the previous weight of this destination plus.",
            "The weights of the Source Times WP is that the case yes or not.",
            "If it is, I update.",
            "If not, I keep it as it was.",
            "And the only thing that I need to do in addition to in with respect to the previous usual cases is that in addition to keeping track of the tentative distances the of queues, I also have to have another array, the RF cues which stores the amount of weight that I've added to the weights to the distance at a particular state since the last time I extracted a state from the queue.",
            "You don't even need to too much know about this.",
            "Let me now emphasize two things one.",
            "This very simple algorithm.",
            "Works for any queue discipline, as here is a Q.",
            "When I say any queue discipline, it means that you can choose different ways of implementing it.",
            "It could be a shortest first, which is giving you the dykstra's algorithm.",
            "It could be pfeifle, which then would correspond to the Bellman Ford algorithm.",
            "It could be the topological order which would then give you the acyclic shortest distance algorithm.",
            "So in a sense.",
            "This algorithm works with any queue discipline, and you can prove that in fact it means that all the shortest path algorithms are special instances of this algorithm.",
            "So in some sense, when you go to school you don't need to learn three different algorithms so fast is to use to learn one and then somebody will tell you.",
            "Well, we can use any queue discipline with it, that's it.",
            "But Furthermore, this same algorithm also works for any simmering.",
            "That is K closed.",
            "We will need this algorithm to compute the sum of the weights of the path.",
            "As I said before in this general ways.",
            "For an arbitrary summary, OK, and."
        ],
        [
            "So.",
            "And so this is just saying what I already said in words."
        ],
        [
            "OK.",
            "I am not sure that I'm even going to talk about epsilon removal at this point.",
            "I don't know, or before giving you some time to breathe or.",
            "Coffee cups at 10:30.",
            "Wanted to know.",
            "OK, so we have time then.",
            "OK, alright, so let me quickly tell you give you talked about this algorithm Exxon removal and after that I'll start talking about kernels.",
            "If yes.",
            "Introduce his capos mismatch.",
            "Can you say something about why it's justified or what does it?",
            "Yeah."
        ],
        [
            "I would in some sense, so you could say, why does he have to talk indeed about these key closed semirings.",
            "The reason the idea is in fact I could almost call them the computable semirings.",
            "I could almost claim that any other semiring is not computational WHI, because this means that if I have to compute the weight of a loop of a cycle, I have to be able to stop at some point of time.",
            "That's what it means.",
            "I'm taking this some of the X to the power of eyes.",
            "And every time I go through the loop, I add this new weight and at some point I have to stop.",
            "Semi rings that are such that I never have to stop where there one possible I have to know the answer before hand, but you can see even if you know the answer before hand, such as in the case of the probability semiring where you know the answer is 1 / 1 -- X right.",
            "But in fact 1 / 1 -- X is a power series, so to compute it.",
            "In fact computers still have to do that.",
            "Some of the excise.",
            "So in a sense.",
            "You cannot get away.",
            "You.",
            "In practice, computers are really dealing with Kako Semirings.",
            "So you know it for the tropical semiring and a variety of semirings, you know key in advance.",
            "If in the cases where it's hold, so it's holding in an exact manner.",
            "If it does not hold in an exact manner in an approximate manner, you have to choose it in such a way that it corresponds to the approximation that you make in fact.",
            "For dealing with floating point numbers OK, you can choose the epsilon that is appropriate for your for your application.",
            "In some sense, computers deal with it anyway.",
            "You cannot get away with that.",
            "Once again, they never compute compute 1 / 1 -- X in an exact manner that it's not possible, right?",
            "OK, so that was the it's a good point.",
            "Why do you need that?",
            "And that's kind of the answer.",
            "Let me also say that their use.",
            "There had been."
        ],
        [
            "Previously a question about could there be a general framework for talking about single source shortest distance algorithms and this seems to be sort of one way to talk about it, OK?",
            "Now composition and shortest distance algorithms are the two algorithms that I said we would need for talking about computing kernels, but I'm quickly going to tell you a little bit about another algorithm dealing with epsilons."
        ],
        [
            "You know, since you don't like epsilons, maybe I should, in fact not speak too much about this, but one other ways to speak a lot about it so that you hate it even more so.",
            "An artifact of various operations you might come up with machines that have epsilons in them in the weighted automata case, well, that would be just an epsilon, single epsilon input label if you like.",
            "In the transducer case it could be an epsilon epsilon.",
            "As we said, we cannot get, we cannot remove transitions of the type epsilon in necessarily, so my desire here is to remove only in the transducer case epsilon.",
            "Epsilon transitions OK, why'd would I want to do this is because epsilons create a deley and further nondeterminism.",
            "So I would want to make the these machines sometimes more efficient by removing that delay.",
            "How do you do this?",
            "Well, the algorithm has two components to it, the first one.",
            "So what would you do?",
            "How would you do this in a very intuitive way?",
            "You have a machine that has some epsilons in it.",
            "You could just say I just want to go and remove them, but you cannot just remove them 'cause you might break the consistency of that machine.",
            "So instead what you have to do is too many states when you want to remove an epsilon transition, you have to 1st see what are the transitions of this state that you can reach by reading epsilons.",
            "An you take all those transitions, put them at this state where you were within epsilon epsilon, and then you remove the epsilon.",
            "OK, so let me just figure just quickly say this.",
            "So.",
            "Suppose that I have a.",
            "There's a state P that has an epsilon transition going to Q, and from Qi read some.",
            "You know whatever transitions I have, what I'm going to do is that instead I'm going to remove that epsilon here.",
            "But so if this was Q prime, for example, here I'm directly going to create a transition from P to Q prime.",
            "With the transition a.",
            "So I'm basically going to take all the transitions that state Q had and put them back at P. If you like, OK, that's obvious.",
            "And similarly, if there was a Q second here, I'm going to be going to cusic.",
            "OK, it's very natural algorithm, so that's what you do in the unweighted case, and it's a very simple thing to do.",
            "Is a little bit more to do because you might have a sequence of epsilon transitions.",
            "I'm not just a single one.",
            "In that case, you have to compute the closure.",
            "You have to find all the states that can be reached by epsilon path.",
            "We can do that.",
            "There's a little bit more to do in the weighted case because in the weighted case there is also weights here, so I could have a weight .5 point 6.7.",
            "So what do I do here?",
            "I now not only have to find the states that I can reach by reading epsilons, but I also have to keep track of what weight I need to I take to go to those states.",
            "Once I've computed the weights to go through each one of those states, when I add these transitions I can now.",
            "Multiply that .5 with .6 right or here .5 with .7.",
            "OK so that means that I have to compute the epsilon closure of each state and the epsilon closure of this state.",
            "P is the set of state Q that I can reach by reading just epsilons.",
            "In together with the weight, the distance.",
            "Now suddenly we need the distance the distance from P to Q.",
            "In other words, this some of the weights of the path epsilon path.",
            "These are epsilon going from P to Q. OK, and so that in fact becomes shortest distance algorithm.",
            "And that's where you can see suddenly why this shortest distance algorithm becomes sort of crucial.",
            "Also for Epson removal so."
        ],
        [
            "Here is an example of a weighted automaton.",
            "Which has epsilons on it right?",
            "And here is an equivalent weighted automata into this one by removing the epsilons and to do this you have to do the two things that I said.",
            "You compute the distances from each state to the set of says that you can reach by reading epsilons and then remove the epsilons and the right transitions.",
            "OK, OK, so that was just to say that the shortest distance algorithm that I mentioned before is going to be crucial in a number of other algorithms.",
            "And there is another way of computing the epsilon removal by looking at the reverse machine, which would produce yet another equivalent machine to the to the one that used."
        ],
        [
            "Douglas OK, so this is just to say that you use the shortest distance algorithms, either the generalization of the Ford Marshall or the cake low simmering algorithm.",
            "And here is the complexity."
        ],
        [
            "OK.",
            "In view of what I feel from the audience and familiarity with this kind of things, I think it's time for me.",
            "Even before your coffee break to start talking about kernels and this kind of things.",
            "And maybe later on if people are just really, really becoming suddenly passionate about this, I could go back to some of these algorithm things which."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, I'm going to start and hopefully further people start coming.",
                    "label": 0
                },
                {
                    "sent": "Since we're going to start gradually, don't manage to catch up.",
                    "label": 0
                },
                {
                    "sent": "I'm Mary Armori from the Courant Institute of Mathematical Sciences and.",
                    "label": 1
                },
                {
                    "sent": "I'm also working for Google Research and this is joint work with much of this tutorial is joint work with Carina Quartus, but as you'll see on the slides there's a bunch of other people that are coauthors.",
                    "label": 0
                },
                {
                    "sent": "The title is weighted transducers theory and algorithms, and in fact what I'm going to be speaking about is going to be both.",
                    "label": 0
                },
                {
                    "sent": "Transducers in the first session and then later on about their use for well, using the title of this workshop.",
                    "label": 0
                },
                {
                    "sent": "The analysis of patterns.",
                    "label": 0
                },
                {
                    "sent": "Kernel kernels based on strings, and this kind of things.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me start with some of the type of problems that's not mine, is it?",
                    "label": 0
                },
                {
                    "sent": "Sounds like Windows kind of things.",
                    "label": 0
                },
                {
                    "sent": "Let me start with one problem that.",
                    "label": 0
                },
                {
                    "sent": "So people see often in speech recognition you know the task that consists of transcribing speech into text.",
                    "label": 0
                },
                {
                    "sent": "One problem, in fact, more precisely spoken dialogue classification, so people speak into a microphone or pick up the phone and talk to make your reservation for a ticket and then the task consists of not necessarily recognizing in fact, perfectly what people said, but trying to classify what they said and the classification here consists of assigning a category out of a finite set of categories such as referral precertification.",
                    "label": 0
                },
                {
                    "sent": "If it's a spoken dialogue system that's designed for healthcare systems.",
                    "label": 0
                },
                {
                    "sent": "And to each speech utterance.",
                    "label": 1
                },
                {
                    "sent": "So every time somebody says something, the dialogue manager is going to say, well, this is related to referral, or if it's something that is corresponding to AT&T or other systems of this kind.",
                    "label": 0
                },
                {
                    "sent": "It's going to say this is related to credit.",
                    "label": 0
                },
                {
                    "sent": "But here is an example.",
                    "label": 0
                },
                {
                    "sent": "If somebody says, for example, hide.",
                    "label": 0
                },
                {
                    "sent": "This is my number, what the speech recognizer outputs is not just one single transcription, but in fact a bunch of possible hypothesis, all of them compactly represented by what people in speech recognition called word lattice, and that is simply a acyclic weighted automaton.",
                    "label": 0
                },
                {
                    "sent": "So as you can see.",
                    "label": 0
                },
                {
                    "sent": "It's graph labeled with words and our weights along that path and the weight of a path is obtained by summing up the weights along that path and the pass with the smallest weight is there.",
                    "label": 0
                },
                {
                    "sent": "Recognizes best guess, but that's not always correct, so it often makes sense to instead of just keeping the best path.",
                    "label": 0
                },
                {
                    "sent": "In fact, in this case, it's not the best, because hi, this is my number.",
                    "label": 1
                },
                {
                    "sent": "Does not have the smallest weight.",
                    "label": 0
                },
                {
                    "sent": "If you look at it closely, so instead it's better to take the recognizers set of hypothesis, which often contains the right answer.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm just trying to give you some examples of the type of problems that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come up in various applications.",
                    "label": 0
                },
                {
                    "sent": "A similar situation arises in computational biology where one might wish to decide, for example, which Class A protein family belongs to and the objects to classify.",
                    "label": 1
                },
                {
                    "sent": "In that case are, well, not necessarily, then single protein sequences, but perhaps put in clusters.",
                    "label": 0
                },
                {
                    "sent": "So you can see the two examples that I gave you so far the the objects to classify are not anymore just a single sequence, but even a set of sequences.",
                    "label": 0
                },
                {
                    "sent": "In fact, the distribution over sequences, so that's what you have to classify.",
                    "label": 0
                },
                {
                    "sent": "You have to assign a category to something of this kind.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a general problem that arises in spoken dialogue classification, computational biology, information extraction, or search engine systems, where each time the model does not output a single hypothesis but a set of hypothesis and each one of them ranked according to the system and information extraction system, for example, and so in fact you have to collect that set of hypothesis and often.",
                    "label": 0
                },
                {
                    "sent": "You want to assign a category to that set so that arises again in text mining, document classification, database queries, and a variety of other applications so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is, in a sense reflecting the state of this world.",
                    "label": 0
                },
                {
                    "sent": "The data that we are dealing with is not anymore the fixed size vectors, perfectly designed for, say, compilers.",
                    "label": 0
                },
                {
                    "sent": "Compilers that expect a very well written source code that you can analyze the type of objects that we need to analyze are more complicated.",
                    "label": 0
                },
                {
                    "sent": "They can even be distributions of sequences.",
                    "label": 1
                },
                {
                    "sent": "Typically represented by automata, variable length sequences, and certainly not what the standard learning algorithms used to expect, at least.",
                    "label": 0
                },
                {
                    "sent": "So the question that comes up, and this is not a really novel question, is how do we design or how do we generalize existing learning algorithms to deal with variable length sequences?",
                    "label": 1
                },
                {
                    "sent": "Or even, as I said, more complicated things such as.",
                    "label": 0
                },
                {
                    "sent": "Distributions over variable length sequences OK, and you saw the terms weighted automaton transducers coming up several times.",
                    "label": 0
                },
                {
                    "sent": "This is going to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit.",
                    "label": 0
                },
                {
                    "sent": "Object of the first part of this tutorial where.",
                    "label": 0
                },
                {
                    "sent": "I'm going to quickly tell you about weighted transducers.",
                    "label": 0
                },
                {
                    "sent": "Let their algorithms the little bit of the theory that is behind it, because that's going to be useful for later talking in the second part about kernels for computational biology and text and speech processing.",
                    "label": 0
                },
                {
                    "sent": "Now, however, this first part weighted transducers that's relevant not just to designing kernels, but to variety of other applications in which strings sequences might occur, and in fact the objects that I'm going to speak about are used in such applications for designing large scale speech recognition systems.",
                    "label": 0
                },
                {
                    "sent": "Natural language processing systems.",
                    "label": 0
                },
                {
                    "sent": "In fact, there are even used in products.",
                    "label": 0
                },
                {
                    "sent": "For this kind of things.",
                    "label": 0
                },
                {
                    "sent": "So the 1st in this first part you're going to hear about weighted transducers.",
                    "label": 0
                },
                {
                    "sent": "As I said in algorithms for about, I don't know something like an hour and I can talk about it as much as you want.",
                    "label": 0
                },
                {
                    "sent": "I'll probably have to shorten it due to lack of time and then later on I will be speaking much more in detail about kernels, their use, and in fact not been looking at each one.",
                    "label": 0
                },
                {
                    "sent": "Variety of kernels in biology and text and speech processing.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, before even starting the part about weighted transducers, let me just mention that almost any one of the algorithms and I'm going to be speaking about in what follows.",
                    "label": 0
                },
                {
                    "sent": "We had already implemented with two colleagues of mine, Fernando Pereira and Michael Riley at agency, and that library is available for download.",
                    "label": 0
                },
                {
                    "sent": "But only the executables of that library were available because we were working on a 20 but now much more recently joint work between crowds at NYU.",
                    "label": 0
                },
                {
                    "sent": "You and Google has produced an open source library which we have called.",
                    "label": 0
                },
                {
                    "sent": "Open FST and that one is available for download, including of course, the source code and it's an open source project.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can get it from open fc.org, so you should be able to download these things, and in fact do a variety of build a variety of things with it, including really, really.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Large scale ones alright so.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be speaking about some definitions for weighted automata transducers and then a series of algorithms composition, shortest distance algorithms, epsilon removal, determinization pushing minimization.",
                    "label": 1
                },
                {
                    "sent": "No, I'm not going to speak about all of them, because obviously we won't have time.",
                    "label": 0
                },
                {
                    "sent": "So probably I'll stop somewhere here if you want to hear more, I'll continue, OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me start with some algebraic definitions in the title.",
                    "label": 0
                },
                {
                    "sent": "There was weighted transducers and the first question is what does it mean weighted and what weights are we talking about?",
                    "label": 0
                },
                {
                    "sent": "And well, I gave you an example.",
                    "label": 0
                },
                {
                    "sent": "In the case of speech recognition where you could see that the weights along the path were added, for example, that's not necessarily always the case.",
                    "label": 0
                },
                {
                    "sent": "He more generally.",
                    "label": 0
                },
                {
                    "sent": "Algebraic structure those weights could belong to an arbitrary set, but we need some rules.",
                    "label": 0
                },
                {
                    "sent": "Well defined rules to combine them.",
                    "label": 0
                },
                {
                    "sent": "So we need in fact what's called this semiring is simmering is.",
                    "label": 0
                },
                {
                    "sent": "L ring it's half of a ring.",
                    "label": 1
                },
                {
                    "sent": "If you like it's a ring that may lack negation, so it's a little bit like if you were taking non negative integers, right?",
                    "label": 1
                },
                {
                    "sent": "You don't have negation, you have plus multiplication and you'll see that there is.",
                    "label": 0
                },
                {
                    "sent": "There are some other Al give you in a second and some other examples of semirings.",
                    "label": 0
                },
                {
                    "sent": "We need the two operations of the simmering, so it's the set is K. The two operations pronounce denoting in a very general way you know plus and all times zero is the identity element of the first operation and won the identity element of the second operation.",
                    "label": 1
                },
                {
                    "sent": "We need both operations sum and product the product to compute the weight of a path by multiplying using this abstract multiplication to combine the weights of of compute the waiter path and we need some because there might be several path labeled with the same string.",
                    "label": 1
                },
                {
                    "sent": "So the weight of his string is obtained by summing up the weight of the path labeled with that string using that.",
                    "label": 0
                },
                {
                    "sent": "Some operation, so let me give you some.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Examples of that.",
                    "label": 0
                },
                {
                    "sent": "And is there is really a reason why I'm talking about these different semirings?",
                    "label": 0
                },
                {
                    "sent": "One general reason that I can tell you is because they come up in a variety of applications in text processing, speech processing, even designing kernels.",
                    "label": 0
                },
                {
                    "sent": "But there's also a mathematical and algorithmic reason to it is because you can write algorithms that abstract away from what the underlying algebra is OK, and here are some examples of semirings.",
                    "label": 0
                },
                {
                    "sent": "The first one is a familiar one, the Boolean semiring that's commonly used in logic and other applications.",
                    "label": 0
                },
                {
                    "sent": "The second one is the probability semiring, so this set is the set of non negative real numbers.",
                    "label": 0
                },
                {
                    "sent": "Would say why don't you just restrict yourself to 01?",
                    "label": 0
                },
                {
                    "sent": "Well because otherwise it would not be a semiring because if I add up numbers, in that case they can go beyond one.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The first operation there in just plus the second operations that familiar multiplication identity elements are zero and one, and of course these are the.",
                    "label": 0
                },
                {
                    "sent": "This is the semiring that we deal with when we're building probabilistic models.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "However, nobody would be using this in practice.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Anybody who's a computer scientist could answer this right away.",
                    "label": 0
                },
                {
                    "sent": "There's no way you would be using this simmering in practice, because if you multiply small numbers probabilities.",
                    "label": 0
                },
                {
                    "sent": "Very quickly you run into numerical stability issues, right?",
                    "label": 0
                },
                {
                    "sent": "So instead in practice, people use their log of those probabilities and then instead of multiplying weights along the path, you add them up then and the corresponding simmering is what I refer to as being the log simmering.",
                    "label": 0
                },
                {
                    "sent": "You simply isomorphic simmering simmering as as amorphic two to the probability simmering by taking minus log.",
                    "label": 0
                },
                {
                    "sent": "Of each wait.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what used to be multiplication is simply addition, because now we have to.",
                    "label": 0
                },
                {
                    "sent": "We have taken minus lot and what used to be plus is another operation called that I called plus log and it's defined by this X plus log Y is minus log of exponential of minus X plus expression.",
                    "label": 1
                },
                {
                    "sent": "Wonder why and you can verify the fuse that operation it does just exactly what you want summing up the probabilities if you like.",
                    "label": 0
                },
                {
                    "sent": "Alright, and then there is another SIM hearing that people call a tropical semiring and that differs from the previous one only by the operation and all the rest is the same.",
                    "label": 0
                },
                {
                    "sent": "The only thing that you do there is by is replacing what used to be the plus lock operation by minimum.",
                    "label": 0
                },
                {
                    "sent": "So let's let's try if I just this tropical semiring.",
                    "label": 0
                },
                {
                    "sent": "That's good so.",
                    "label": 0
                },
                {
                    "sent": "So again, it's a familiar simmering.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because this is the one where you're adding weights along a path, and then you were taking the minimum, so that obviously makes you think of shortest path algorithms, right?",
                    "label": 0
                },
                {
                    "sent": "And in fact, this is probably the main reason why we are talking about the tropical semiring.",
                    "label": 0
                },
                {
                    "sent": "By the way, why tropical?",
                    "label": 0
                },
                {
                    "sent": "It's because the first person who started to talk about the simmering in the main person who's been studying it is inbred.",
                    "label": 0
                },
                {
                    "sent": "Simone, who's living in Brazil and so people as a reference to that, started calling it this way so.",
                    "label": 0
                },
                {
                    "sent": "You realize going from this semiring to this other semiring.",
                    "label": 0
                },
                {
                    "sent": "If you were changing semirings in that case, you would be doing what I could refer to as being the.",
                    "label": 0
                },
                {
                    "sent": "Viterbi approximation.",
                    "label": 0
                },
                {
                    "sent": "Right, you're not changing anything.",
                    "label": 0
                },
                {
                    "sent": "You suddenly just changing the plus operation in this, and that corresponds to keeping the among different probabilities for the for the same string, the dominating one.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what people refer to as being there better be approximation, so this is in effect in algebraic view of the verbal approximation.",
                    "label": 0
                },
                {
                    "sent": "And the main reason, by the way, where white people have been talking about the Victoria approximation is algorithmic is because you would never talk about the Victoria approximation.",
                    "label": 0
                },
                {
                    "sent": "If you could do everything without doing that approximation right, you do it because because that's what you know, shortest path algorithms.",
                    "label": 0
                },
                {
                    "sent": "That's something that you can you can use.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So I talked about weighted automata several times, or here's definition with the picture awaited automaton is a directed graph labeled directed graph, where in addition to the familiar labels, such as a, for example here, there's also some weights on each transition.",
                    "label": 0
                },
                {
                    "sent": "So here are the weight is indicated after the slash 0.5 for example.",
                    "label": 0
                },
                {
                    "sent": "And as we said, the weight of a path.",
                    "label": 0
                },
                {
                    "sent": "Is obtained by multiplying the weights along that path.",
                    "label": 0
                },
                {
                    "sent": "But now now we know that we are talking about multiplication and summing that general way, so don't always expect this sum and product to be the usual summer product they might be.",
                    "label": 0
                },
                {
                    "sent": "You know mean and plus for example, in the lock simmering, so the weights are added along are multiplied along the path and the weight of his string is obtained by summing up the weights of the path labeled that string.",
                    "label": 1
                },
                {
                    "sent": "So for example, the weight associated by this automaton to the string ABB is obtained by looking at the two paths ABB, this one, and by the way there is a double circle, indicates a final state.",
                    "label": 0
                },
                {
                    "sent": "A bold circle indicates an initial state in this figure.",
                    "label": 0
                },
                {
                    "sent": "And that final states there might be an additional weights that you take as you just leave the machine.",
                    "label": 1
                },
                {
                    "sent": "OK, so the weight of this upper path there is .1 times .2 * .3 times .1.",
                    "label": 1
                },
                {
                    "sent": "It's this right?",
                    "label": 0
                },
                {
                    "sent": "And then there is another one, this path ABB, so that one is .5 * .3 times .6 times transferred.",
                    "label": 0
                },
                {
                    "sent": "One you add these two and that's the weight associated by this automaton to the string ABB OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it's slightly more general.",
                    "label": 0
                },
                {
                    "sent": "Object is what's called a weighted transducer, which is a little bit more general than what we talked about, just by the fact that in addition to the usual input symbol A, you might also have on each transition and output symbol.",
                    "label": 0
                },
                {
                    "sent": "Here B indicated after the column OK, and similarly there are weights and in the same way the weights are multiplied along the path.",
                    "label": 0
                },
                {
                    "sent": "You take this sum.",
                    "label": 0
                },
                {
                    "sent": "To compute the weight associated now, this time not to a single string, but to appear of strings.",
                    "label": 0
                },
                {
                    "sent": "Which would be the string obtained by concatenating the inputs and concatenating and the other string obtained by conquering the outputs.",
                    "label": 0
                },
                {
                    "sent": "This is the weight associated by this transducer T to the pair of strings ABB BAA so.",
                    "label": 0
                },
                {
                    "sent": "Of course I've cooked this example in sort of the same to pass would be used here, so the upper path, now its input is the same ABB as we had before, and the output is B. AA right so and the weights are obtaining the same way by multiplying them.",
                    "label": 0
                },
                {
                    "sent": "There are two weights to pass label with these pairs and the weight associated by the transducer to that pair is the sum of the weights of these two path.",
                    "label": 1
                },
                {
                    "sent": "OK, you'll see that these objects weighted transducers as simple as they are.",
                    "label": 0
                },
                {
                    "sent": "In fact they become crucial.",
                    "label": 0
                },
                {
                    "sent": "Suddenly if we're talking about things like kernels and positive definite symmetric kernels.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there are some standard operations that can be used to combine weighted transducers, natural ones.",
                    "label": 0
                },
                {
                    "sent": "The first one is a sum.",
                    "label": 0
                },
                {
                    "sent": "It turns out that if you take the sum of two transducers, you obtain another way transducer, and it's the weighted transducer that I denote by T 1 + C, Two which associate's to each pair.",
                    "label": 0
                },
                {
                    "sent": "Well, the some of the weights associated by these two transducers.",
                    "label": 0
                },
                {
                    "sent": "Then there's another operation product which associate's to each pair XY, not the product of the of the two weights, but instead of product.",
                    "label": 0
                },
                {
                    "sent": "Maybe here to give you the intuition I should talk about concatenation.",
                    "label": 0
                },
                {
                    "sent": "OK. Where you can see here that it's in fact this some.",
                    "label": 0
                },
                {
                    "sent": "Over of T1 of X1Y1T times, T2X 2Y2 over all possible ways of decomposing the input string X into a prefix X one and a suffix X2 and decomposing the output string Y into Y1Y2 OK. And then there's another operation that's familiar.",
                    "label": 0
                },
                {
                    "sent": "One is when it's called closure or cleaning closure.",
                    "label": 0
                },
                {
                    "sent": "In the unweighted case for standard on weighted automata, and that's the one obtained by taking the sum of the TN of XY, where TN is the multiplication of T by itself and minus one times OK according to this definition of multiplication.",
                    "label": 0
                },
                {
                    "sent": "So here to understand this product again, you have to think.",
                    "label": 0
                },
                {
                    "sent": "As cook, concatenating a transducer with itself.",
                    "label": 0
                },
                {
                    "sent": "The T 1 * T Two is a concatenation of T1 with teachers, so they passed that you could read in T1.",
                    "label": 0
                },
                {
                    "sent": "You didn't continue reading the rest in T2.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's just to say that there are some standard operations that you can use to combine transducers.",
                    "label": 0
                },
                {
                    "sent": "And again again, you obtain more other transducers, so from simpler ones you can create more complex ones.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it turns out that there is an operation called composition that is in fact really the most fundamental one for combining transducers that comes up in a variety of applications for four.",
                    "label": 0
                },
                {
                    "sent": "Also creating more complex transducers from simpler ones.",
                    "label": 0
                },
                {
                    "sent": "But the reason why it becomes fundamental is because.",
                    "label": 0
                },
                {
                    "sent": "It's a mapping a transducer from, say, one information source to another one.",
                    "label": 0
                },
                {
                    "sent": "So composition helps you take the output of that mapping and map it yet another to another information source.",
                    "label": 0
                },
                {
                    "sent": "And by doing this you can create complex systems such as speech synthesis, system, speech recognition systems, information extraction systems.",
                    "label": 0
                },
                {
                    "sent": "By composing these each one of these components information sources to create more complicated things.",
                    "label": 0
                },
                {
                    "sent": "And you will see that also for creating complex kernels you can use the same.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Operation, so let me explain what this operation corresponds to.",
                    "label": 0
                },
                {
                    "sent": "The composition and it's indicated by a little circle, the composition of two transducers T1 and T2.",
                    "label": 0
                },
                {
                    "sent": "Turns out to be a weighted transducer as well.",
                    "label": 0
                },
                {
                    "sent": "It's the one that associate is associated to the pair XY.",
                    "label": 0
                },
                {
                    "sent": "This sum of T1 of X y * T two of ZY where the sum is over all possible strings E so that so not to give you the intuition it's over, the sum is over all possible strings that could be an output of a path in the first transducer and the input of a path in the second transducer.",
                    "label": 0
                },
                {
                    "sent": "So it's a composition is a matching operation.",
                    "label": 0
                },
                {
                    "sent": "If you like it match so you another view of it.",
                    "label": 0
                },
                {
                    "sent": "Is that the transducer T1 map strings to some other set of strings on T2?",
                    "label": 0
                },
                {
                    "sent": "Takes those strings and Maps them, get another to another set of strings and the weights are obtained by multiplying the weights of matching path and then you take this sum over all possible matches.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going in a second is going to become more clear and as I'm going to describe the algorithm that is used to compute.",
                    "label": 0
                },
                {
                    "sent": "Composition the algorithm in the epsilon free case epsilon is empty.",
                    "label": 0
                },
                {
                    "sent": "Work the symbol that you know what you don't need to consume anything.",
                    "label": 0
                },
                {
                    "sent": "When you're taking a transitional label with epsilon.",
                    "label": 0
                },
                {
                    "sent": "When there's no epsilon, the algorithm is very simple.",
                    "label": 0
                },
                {
                    "sent": "It just consists of matching.",
                    "label": 0
                },
                {
                    "sent": "You would want to match path, but in fact you can just see more simply match transitions in the general case you need what's called an epsilon filter and I'll describe how this works.",
                    "label": 0
                },
                {
                    "sent": "The complexity of the algorithm is quadratic is the size of the transducer T1 the size here is the sum of the number of transitions and states times the size of the transducer T2.",
                    "label": 0
                },
                {
                    "sent": "This only occurs though in the case where every transition of the first machine matches every transition of the second machine, which is a very rare situation.",
                    "label": 0
                },
                {
                    "sent": "So in practice the composition is much more efficient than what this worst case would indicate, and another aspect of composition that's very crucial in practice is the fact that you can do an on-demand construction of the result, in other words.",
                    "label": 0
                },
                {
                    "sent": "You don't really need to in the cases where T1 and T2 are very large.",
                    "label": 0
                },
                {
                    "sent": "Now they might have 100 million transitions.",
                    "label": 0
                },
                {
                    "sent": "This is the type of things that sometimes we deal with.",
                    "label": 0
                },
                {
                    "sent": "If both have 100 million transitions, you don't want to take T1 compose BT two and just build the whole thing.",
                    "label": 0
                },
                {
                    "sent": "While you might only need some part of that compose machine instead, you can try to do what people in computer science refer to as being either that lazy evaluation.",
                    "label": 0
                },
                {
                    "sent": "Or an equivalent term is actually dynamic computing computation.",
                    "label": 0
                },
                {
                    "sent": "These things lazy dynamic seem to be the same in computer science for some reason.",
                    "label": 0
                },
                {
                    "sent": "So what you do is that you only build we wanted somebody tells you to completely build the composition.",
                    "label": 0
                },
                {
                    "sent": "You actually do nothing.",
                    "label": 0
                },
                {
                    "sent": "You start building things only if somebody asks you for the output of that composition.",
                    "label": 0
                },
                {
                    "sent": "OK, that's on demand.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In the Epsilon free case.",
                    "label": 0
                },
                {
                    "sent": "So again, when there is no epsilon transition, things are very simple.",
                    "label": 0
                },
                {
                    "sent": "Composition consists of creating a new machine which for which the states are pairs of states of the original two machines.",
                    "label": 0
                },
                {
                    "sent": "OK, so the set of states are pairs of Q1 instead of.",
                    "label": 0
                },
                {
                    "sent": "States are the 1st in queue to sort of the states of the second machine.",
                    "label": 0
                },
                {
                    "sent": "The initial states are simply the set of pairs where both states are initial.",
                    "label": 0
                },
                {
                    "sent": "The final states are those states of Q that are both final and the transitions are obtaining this simple way.",
                    "label": 0
                },
                {
                    "sent": "There is a transition from the pair Q1 Q prime one to the pair Q2 Q prime two with input a an output.",
                    "label": 1
                },
                {
                    "sent": "See when there is a transition in the first machine from Q1 to Q2 with input a, an app would be and transition in the second machine from Q prime.",
                    "label": 0
                },
                {
                    "sent": "One to Q prime two with input B you see it has to match the output here with input B and some output C. Whenever this happens, you create a new transition from despair to that pair with input.",
                    "label": 0
                },
                {
                    "sent": "What used to be the input here on output, what used to be the output of this one.",
                    "label": 0
                },
                {
                    "sent": "OK, and the weight is obtained by multiplying the weights of these two transitions.",
                    "label": 0
                },
                {
                    "sent": "So it seems like a very simple thing to do and let me just illustrate it.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a particular case, at the same time I'm writing up there what you could use, you could write using the libraries that I mentioned, either the FSM library or the open source FST library.",
                    "label": 0
                },
                {
                    "sent": "Here are two transducers, and this is the result of the composition.",
                    "label": 0
                },
                {
                    "sent": "As you can see here the states corresponds correspond to pairs of states.",
                    "label": 0
                },
                {
                    "sent": "So originally you start at the initial state of this machine and the initial state of this machine.",
                    "label": 0
                },
                {
                    "sent": "So that's the pair 00.",
                    "label": 0
                },
                {
                    "sent": "And then you're asking, well, if I'm leaving this state, what are the transitions that are obtained in this case?",
                    "label": 0
                },
                {
                    "sent": "There's only one transition, the one with input A output B and you're asking if there is any transition leaving the initial state of the second machine that matches it matches it in the sense that the output of this has to match the input of that, while in this case the two match well, the input B matches the output be.",
                    "label": 0
                },
                {
                    "sent": "So then I create a new transition from that pair 00 which goes to where it goes to another pair which is the destination state of this transition and the destination state of that one.",
                    "label": 0
                },
                {
                    "sent": "So it's the pair 11.",
                    "label": 0
                },
                {
                    "sent": "And then the input label of that transition is the input label of the first.",
                    "label": 0
                },
                {
                    "sent": "The transition in the first machine, and the output is as we described before.",
                    "label": 0
                },
                {
                    "sent": "The output label of the transition in the second machine, and the weight is obtained.",
                    "label": 0
                },
                {
                    "sent": "In this case, we're in the plus time, simmering the usual operations.",
                    "label": 0
                },
                {
                    "sent": "The weights are simply multiplied .1 times .1.",
                    "label": 0
                },
                {
                    "sent": "That's .01 OK. And then I just continue from here alright.",
                    "label": 0
                },
                {
                    "sent": "And you can see here that I've indicated something in red here.",
                    "label": 0
                },
                {
                    "sent": "That's because we were now in, so it's the pair corresponding to three.",
                    "label": 0
                },
                {
                    "sent": "One was in state, three in the first machine state, one in the second machine, and then I was asking again what are the matching transitions?",
                    "label": 0
                },
                {
                    "sent": "Well, from here there is only one outgoing transition, that's AA.",
                    "label": 0
                },
                {
                    "sent": "It matches which one of?",
                    "label": 0
                },
                {
                    "sent": "The transitions leaving this one it matches both this and this right?",
                    "label": 0
                },
                {
                    "sent": "But look at the one that matches this one.",
                    "label": 0
                },
                {
                    "sent": "So I create a new transition for that one.",
                    "label": 0
                },
                {
                    "sent": "This matches this, so I have a new transition AB that goes to 3, two OK. With whatever the weight obtained by multiplying the weights .6 times .3.",
                    "label": 0
                },
                {
                    "sent": "But you can see that I'm not continuing from there on.",
                    "label": 0
                },
                {
                    "sent": "Why, because once I let stay 3 here and stay two, I'm looking at matching transitions and I see that this still expects an A as an output, but here there is no a for any going transition, so I have to stop.",
                    "label": 0
                },
                {
                    "sent": "So that means that in fact.",
                    "label": 0
                },
                {
                    "sent": "That state is not going to be very useful because it's not going to admit any transition to a final state.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, once I'm done, I can just remove that state and that transition.",
                    "label": 0
                },
                {
                    "sent": "I just want to indicate it still because these are some States and transitions that you might create during the execution of the algorithm, but that later on you will have to get rid of OK so you can see it's a very simple algorithm, very intuitive matching it's.",
                    "label": 0
                },
                {
                    "sent": "Combining two mappings and at the same time taking advantage of the weights associated with those.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mappings OK.",
                    "label": 0
                },
                {
                    "sent": "But things become a little bit more complicated when in addition to the usual labels, you also have epsilon transitions, Epson labels, and that's something that you need in all applications to use epsilons, the empty string.",
                    "label": 0
                },
                {
                    "sent": "So take the case in fact of two very simple transducers.",
                    "label": 0
                },
                {
                    "sent": "I mean, both are just, you know, linear chain.",
                    "label": 0
                },
                {
                    "sent": "So you want anti two and in fact I'm not even indicating the weights here.",
                    "label": 0
                },
                {
                    "sent": "Take them to be all equal to 1 OK.",
                    "label": 0
                },
                {
                    "sent": "So now if I want to create the composition of this two transducers, well, I can try to proceed in the same way as in the epsilon free case.",
                    "label": 0
                },
                {
                    "sent": "By studying at the pair 00 and then combining the first 2 transitions A&AD to create a transition that goes from zero zero to 1, one with input a, an app would be OK.",
                    "label": 0
                },
                {
                    "sent": "So now I'm state one in the first machine state, one in the second machine.",
                    "label": 0
                },
                {
                    "sent": "And now comes the problem because.",
                    "label": 0
                },
                {
                    "sent": "I have an epsilon labor for the output of the transition, leaving state one in the first machine and here two.",
                    "label": 0
                },
                {
                    "sent": "I have an epsilon leaving the state one.",
                    "label": 0
                },
                {
                    "sent": "So what do I do?",
                    "label": 0
                },
                {
                    "sent": "I can have different alternatives like we say, well, I can do things in the same way as in the epsilon free case.",
                    "label": 0
                },
                {
                    "sent": "I can just pair epsilon and epsilon and create a new transition by matching those two.",
                    "label": 0
                },
                {
                    "sent": "By doing that I would go from State 11 to State 22.",
                    "label": 0
                },
                {
                    "sent": "OK, by pairing the two epsilons or I could say well look epsilon is not a real label.",
                    "label": 0
                },
                {
                    "sent": "So let me just move forward on one of the first machines on the 1st machine.",
                    "label": 0
                },
                {
                    "sent": "Consume all the epsilons that I can find until I find a real label to match with OK. Or I can say the same in the second machine.",
                    "label": 0
                },
                {
                    "sent": "Doing this suddenly gives me a bunch of different alternatives, and, for example, continuing on the 1st machine by just reading epsilons that's doing this, that's continuing on the 1st machine, staying at the same state in the second machine.",
                    "label": 0
                },
                {
                    "sent": "I could continue on this first machine and saying in the same state, so it gives me all these possible path for creating composition.",
                    "label": 0
                },
                {
                    "sent": "That's too many path because in reality.",
                    "label": 0
                },
                {
                    "sent": "I'm creating here.",
                    "label": 0
                },
                {
                    "sent": "So each path is going to have weight one, and since I have to add up the weights of these path, I'm in fact going to be created associating a weight that is the number of path that I've created instead of just associated weight one, because that was just I was just matching.",
                    "label": 0
                },
                {
                    "sent": "After all one string here with one string here OK and that is called the Epson path multiplicity problem.",
                    "label": 0
                },
                {
                    "sent": "Instead of having all these paths, you should just keep one.",
                    "label": 0
                },
                {
                    "sent": "So you could say, well, that's not a big problem, we just choose choose one.",
                    "label": 0
                },
                {
                    "sent": "Any one of them is fine because after all, in terms of input output, they're all the same.",
                    "label": 0
                },
                {
                    "sent": "It's just in what order I'm reading them.",
                    "label": 0
                },
                {
                    "sent": "But which one and how would you select the particular path that you want?",
                    "label": 0
                },
                {
                    "sent": "You could say, well, every time I want to create compositions, somebody is going to stand here and tell me well choose this particular path, yes?",
                    "label": 0
                },
                {
                    "sent": "A few of the reasons mapping intended semantics, so I guess that at some point you have to think what do I intend to model and what's the right choice for what I'm trying to model, right?",
                    "label": 0
                },
                {
                    "sent": "So the right things that I expect is that the weight should be the weight that corresponds to the definition of composition.",
                    "label": 0
                },
                {
                    "sent": "So if I the weight, the weight associated by the compose transducer to an input X and output.",
                    "label": 0
                },
                {
                    "sent": "Why should be precisely the product of the weights of these two?",
                    "label": 0
                },
                {
                    "sent": "What is the semantics of his?",
                    "label": 0
                },
                {
                    "sent": "In in re education, so maybe 10 four little examples so that we can see all this action which you have an example of.",
                    "label": 0
                },
                {
                    "sent": "This is the example of how this works.",
                    "label": 0
                },
                {
                    "sent": "Or something like that, really every speech.",
                    "label": 0
                },
                {
                    "sent": "OK, when you try to order in process OK so.",
                    "label": 0
                },
                {
                    "sent": "I guess I could.",
                    "label": 0
                },
                {
                    "sent": "I could just say this in words.",
                    "label": 0
                },
                {
                    "sent": "There you create epsilons in all these operations.",
                    "label": 0
                },
                {
                    "sent": "When you for example taking the union of two transducers, the sum of two transducers to create that some you create.",
                    "label": 0
                },
                {
                    "sent": "It's an artifact of the operations that you use.",
                    "label": 0
                },
                {
                    "sent": "You need.",
                    "label": 0
                },
                {
                    "sent": "You need those epsilons too.",
                    "label": 0
                },
                {
                    "sent": "Doing good.",
                    "label": 0
                },
                {
                    "sent": "But it's more than this.",
                    "label": 0
                },
                {
                    "sent": "Let me just say so.",
                    "label": 0
                },
                {
                    "sent": "This is it's a necessary artifact.",
                    "label": 0
                },
                {
                    "sent": "As you said of various operations such as all the rational operations.",
                    "label": 0
                },
                {
                    "sent": "In fact, some product or concatenation closure on this sum is obtained by creating a new state and putting up some transitions to the original state of the first machine.",
                    "label": 0
                },
                {
                    "sent": "The product you have put epsilon transitions from this final state of the first machines with the initial states of the second machine.",
                    "label": 0
                },
                {
                    "sent": "In the clip closure or cleaning closure, you need that epsilon to go back, but in fact it's even more than this in the case of transducers, because in the case of transducers there are certain mappings that you would not be able to use to define if you did not have epsilons.",
                    "label": 0
                },
                {
                    "sent": "So, for example, if you.",
                    "label": 0
                },
                {
                    "sent": "Take this one.",
                    "label": 0
                },
                {
                    "sent": "I know if you can read from there if I have.",
                    "label": 0
                },
                {
                    "sent": "This is from state Zero to state one, and if I wanted to have a loop that has input epsilon and outputs whatever C. OK.",
                    "label": 0
                },
                {
                    "sent": "So this the fact that you can read epsilon on the input and then as many time produce as many seasons you want.",
                    "label": 0
                },
                {
                    "sent": "This is something that this.",
                    "label": 0
                },
                {
                    "sent": "This mapping is only possible, you can only describe it by having epsilons.",
                    "label": 0
                },
                {
                    "sent": "You cannot remove the epsilons here.",
                    "label": 0
                },
                {
                    "sent": "There's no way to write this transducer without using epsilon.",
                    "label": 0
                },
                {
                    "sent": "So it is more than just an artifact in the case of automata, it is an artifact.",
                    "label": 0
                },
                {
                    "sent": "You could say you could always get away with it.",
                    "label": 0
                },
                {
                    "sent": "You could always not use epsilons in the case of transducers, that's not possible.",
                    "label": 0
                },
                {
                    "sent": "OK, it is always possible to not have an epsilon epsilon, but it's not possible to not have an epsilon, C or similarly.",
                    "label": 0
                },
                {
                    "sent": "Say C epsilon OK. Because you might wish to map all the strings that are of this kind.",
                    "label": 0
                },
                {
                    "sent": "For example, were reading an arbitrary number of season erase PC's OK.",
                    "label": 0
                },
                {
                    "sent": "I do think that FIFA at some point you can go back to your example of speech with the opening so we can see how that would translate into this.",
                    "label": 0
                },
                {
                    "sent": "I think it will be so, so I'm not sure what you mean by the 1st.",
                    "label": 0
                },
                {
                    "sent": "The first example that I gave was just to see the output of a speech recognition system so.",
                    "label": 0
                },
                {
                    "sent": "We can see this graphically.",
                    "label": 0
                },
                {
                    "sent": "Would be wise to do it?",
                    "label": 0
                },
                {
                    "sent": "How would it look like if you have problems like that that we can relate to?",
                    "label": 0
                },
                {
                    "sent": "Ending this condition of the populace.",
                    "label": 0
                },
                {
                    "sent": "So I'm not still completely sure what you mean by this, but I I can, I can say maybe in words or I can I can give some other examples as we're going to.",
                    "label": 0
                },
                {
                    "sent": "I could have given you in fact examples for.",
                    "label": 0
                },
                {
                    "sent": "Because he sent A and if I'm trying to recall this switch on switch in the areas, I just want to advise it alright?",
                    "label": 0
                },
                {
                    "sent": "Will let you.",
                    "label": 0
                },
                {
                    "sent": "So epsilon is the empty word, right?",
                    "label": 0
                },
                {
                    "sent": "So you might wish.",
                    "label": 0
                },
                {
                    "sent": "Here's an example that might be helping you.",
                    "label": 0
                },
                {
                    "sent": "Suppose that you want to compute the edit distance between two strings.",
                    "label": 0
                },
                {
                    "sent": "OK, typically this is represented by talking to.",
                    "label": 0
                },
                {
                    "sent": "People talk about a simple dynamic programming algorithm, and there's a very simple way of representing this with the transducers and that's this one.",
                    "label": 0
                },
                {
                    "sent": "Suppose that the alphabet is just.",
                    "label": 0
                },
                {
                    "sent": "Limited to two elements A&B for example.",
                    "label": 0
                },
                {
                    "sent": "OK, so you would have a simple transducer that Maps well A to itself, but in that case you want to associate to it cost 0.",
                    "label": 0
                },
                {
                    "sent": "Or you might want to have what's called dileesh and you map ETA epsilon for example with some cost.",
                    "label": 0
                },
                {
                    "sent": "The standard way would be one for example.",
                    "label": 0
                },
                {
                    "sent": "Or you might want to have an insertion, which means that now you go from.",
                    "label": 0
                },
                {
                    "sent": "Empty string to assemble A and that also might cost you one, for example, or whatever other costs you choose, OK?",
                    "label": 0
                },
                {
                    "sent": "So if you like, this would correspond here to deletions.",
                    "label": 0
                },
                {
                    "sent": "This would correspond to insertions.",
                    "label": 0
                },
                {
                    "sent": "OK, and again, for example, a simple transducer like this you would not be able to represent it without using epsilons, precisely because you want to talk about insertions and deletions.",
                    "label": 0
                },
                {
                    "sent": "There are much more complicated ones than this one, and let me just also say, by the way, that what people talk about when they were talking about the edit distance.",
                    "label": 0
                },
                {
                    "sent": "Much more complex edit distances can be computed in a.",
                    "label": 0
                },
                {
                    "sent": "Very standard way using transducers composition and standard algorithms OK. Alright, so maybe this is a little bit too much for sophistication for some of the things that I'm going to be talking about, so I'm going to go a little bit faster in this, specially if you know if if already epsilon then this kind of things are novel Tees, then I'm going to go a little bit faster and this let me just say that it turns out that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to go too much into the details of this then at this point, it turns out that there is there is a way of selecting one path as opposed to all these different path that you needed and it turns out that that way of selecting a path can also be represented with a with a transducer.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that you can just simply change a little bit bit transducer T1 and T2 into T1 till 92~ and then compose them.",
                    "label": 0
                },
                {
                    "sent": "Now this time using the usual epsilon free composition that I talked about before to compute the correct value of the transitional composition correct in the sense that you're not producing extra path.",
                    "label": 0
                },
                {
                    "sent": "OK, this filter somehow helps you rule out all the path.",
                    "label": 0
                },
                {
                    "sent": "In this case, except from this one, OK?",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go through the details of this unless you want to hear more.",
                    "label": 0
                },
                {
                    "sent": "'cause I said, I feel like you know some of these things are maybe new for this audience so I can go back to them whatever.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like no OK. And I'm not going to give you then the proof of.",
                    "label": 0
                },
                {
                    "sent": "Also why this filter is correct.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And why it is doing?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pricing OK and there are other filters.",
                    "label": 1
                },
                {
                    "sent": "Other filters that you could choose yes.",
                    "label": 0
                },
                {
                    "sent": "Just understand again that the role of EXO.",
                    "label": 0
                },
                {
                    "sent": "So this is another building.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And outpatient therapy sessions and the other one is introduces not just listen.",
                    "label": 0
                },
                {
                    "sent": "So can you separate this Tuesday?",
                    "label": 0
                },
                {
                    "sent": "I mean I want to allow deletions and insertions, but not in a naturalistic number of times.",
                    "label": 0
                },
                {
                    "sent": "So Epson Epson almost always creates nondeterminism.",
                    "label": 0
                },
                {
                    "sent": "Nondeterminism means that at a particular state.",
                    "label": 0
                },
                {
                    "sent": "Labrador.",
                    "label": 0
                },
                {
                    "sent": "Say it in session conditions without introducing nationalism.",
                    "label": 0
                },
                {
                    "sent": "So, so you're right.",
                    "label": 0
                },
                {
                    "sent": "Actually, although this is a good point that in fact epsilon uses introduces two things.",
                    "label": 0
                },
                {
                    "sent": "One is the nondeterminism of the machine.",
                    "label": 0
                },
                {
                    "sent": "Nondeterminism means that at a particular state you might need to follow several path.",
                    "label": 0
                },
                {
                    "sent": "That's due to the semantic of epsilon, but indeed there is also the fact that it helps you define some mappings that you would not be able to define otherwise, and that's related to precisely the examples of this kind.",
                    "label": 0
                },
                {
                    "sent": "I cannot separate them now in the way that you seem to wish, because separating them would mean that I would be able to get rid of the epsilon somehow here, but I cannot in in some cases, I just cannot get rid of them.",
                    "label": 0
                },
                {
                    "sent": "OK, in terms of mappings because precisely the cases where I would have insertions or deletions of some material within the middle of a string.",
                    "label": 0
                },
                {
                    "sent": "OK, I hope that's helping with.",
                    "label": 0
                },
                {
                    "sent": "Alright, so too.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To make it, make sure if you like.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are.",
                    "label": 0
                },
                {
                    "sent": "There are situations in which you would have waited transducers such as these and these situations are standard situations that it happens all the time.",
                    "label": 0
                },
                {
                    "sent": "We would have input epsilons or output epsilons, and somehow you have to deal with them when you are then composing these machines to create more complicated ones, yes.",
                    "label": 0
                },
                {
                    "sent": "Something here, but I'm you order the code set up and I mean this is one thing that you can establish the accuracy of two automata, but it is not good for chronic stress, so they are more complicated.",
                    "label": 0
                },
                {
                    "sent": "His object right fairly different.",
                    "label": 0
                },
                {
                    "sent": "So that on that just, but actually Captain thinks so.",
                    "label": 0
                },
                {
                    "sent": "Alright, so another set of algorithms that I want to talk about is that I've shortest distance algorithms.",
                    "label": 0
                },
                {
                    "sent": "How you might say, well, these I know I've heard about them at school.",
                    "label": 0
                },
                {
                    "sent": "You know why does he have to talk about this?",
                    "label": 0
                },
                {
                    "sent": "Well, notice that I'm talking about shortest distance and not shortest path.",
                    "label": 0
                },
                {
                    "sent": "And the main reason why I'm talking about this is because, again, we're going to need them to do various computations and.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distance are not path because we're dealing with these general weights which might not be just in the mean plus case.",
                    "label": 0
                },
                {
                    "sent": "So let me define the distance of a state from a state Q to the set of final states as being the sum of the weight of the path from that state to a final state.",
                    "label": 1
                },
                {
                    "sent": "OK, the weight of a path you remember is obtained by multiplying the weights along that path, and then I'm taking this sum of all the path.",
                    "label": 0
                },
                {
                    "sent": "The weights of all the path from that state.",
                    "label": 0
                },
                {
                    "sent": "The final state in the particular case where the simmering is the tropical semiring, this definition coincides with the usual shortest path or shortest distance.",
                    "label": 0
                },
                {
                    "sent": "Wait right?",
                    "label": 0
                },
                {
                    "sent": "It's the minimum of the some of the weights of the path from that state to a final state, but we will need more.",
                    "label": 0
                },
                {
                    "sent": "More generally, this definition, because we might deal with different semirings, and in particular we might deal with the probability semiring, right?",
                    "label": 0
                },
                {
                    "sent": "If you now have probabilities, you would want to compute the sum of the weights of all the path from that state to a final state.",
                    "label": 0
                },
                {
                    "sent": "So how do we compute that?",
                    "label": 0
                },
                {
                    "sent": "Wait, it turns out that there are two ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you are in the case of the tropical semiring mean plus, you know how to do this, take any shortest path algorithm, those that you hear about at school Dijkstra's algorithm.",
                    "label": 0
                },
                {
                    "sent": "Tropical, the topological order algorithm in the case of a cyclic graph, all of these are going to work, but in the most general case, that's you're going to have to come up with something different.",
                    "label": 0
                },
                {
                    "sent": "He turns out that you can use.",
                    "label": 0
                },
                {
                    "sent": "You can generalize the Floyd Warshall algorithm that is defined for all pairs algorithm, shortest path algorithms in the standard case to compute this, or to come up with a more general algorithm, which is a single source shortest distance algorithm that generalizes basically all the shortest path algorithms that you've heard about before.",
                    "label": 1
                },
                {
                    "sent": "So I'm going to quickly describe these two because as I said, again, two algorithms that are going to be crucial for computing kernels, I'm going to tell you right away one is composition that I already talked about and the other one is shortest distance algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This sort of the floodwater logarithm is the following.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "You probably have heard about it when, as I said, we're discussing all pairs shortest path algorithms and textbooks, and it's the one that says that to compute the distance, sodium IJ here would be the distance from state I to state J to compute the distance from I to J.",
                    "label": 0
                },
                {
                    "sent": "You look at all the path from I to J, but you first start by looking at all the path from.",
                    "label": 0
                },
                {
                    "sent": "EG that go through the states that are numbered only one 2K that's at the Keith iteration.",
                    "label": 0
                },
                {
                    "sent": "And then then you look at all the paths that are going from I to J and that that are going through the states one 2K plus one.",
                    "label": 0
                },
                {
                    "sent": "And to do this you have to potentially go to K and then come back to 2K.",
                    "label": 0
                },
                {
                    "sent": "That's the closure that you need here.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm not going to go too much into the details of this, but just to say that the algorithm is as simple as this, it has a triple loop and at each time you're updating the distance from I to J.",
                    "label": 0
                },
                {
                    "sent": "By saying that it's whatever used to be the distance from I to J plus with this now generalized notion of plus.",
                    "label": 0
                },
                {
                    "sent": "A path that goes 2 from I2K with a loop or cycle at K2K so I have to take the closure times the path that goes from KT J.",
                    "label": 0
                },
                {
                    "sent": "So very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "It was not completely trivial though.",
                    "label": 0
                },
                {
                    "sent": "Well, almost trivial to realize that in fact this simple algorithm that was originally designed by Florida Warshel for all pairs can actually be generalized to other semirings.",
                    "label": 0
                },
                {
                    "sent": "OK, in fact it works for all closed Semirings is simmering is closed when the closure operation is well defined for all the weights and that the sum, sum and product applied to infinite.",
                    "label": 0
                },
                {
                    "sent": "Sociative iti commutativity work with infinite sounds OK.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "That's the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem with this algorithm is that is its complexity because you could see that triple loop means that the time complexity of this algorithm is cubic.",
                    "label": 0
                },
                {
                    "sent": "Even if you assume that the time to compute the plus and other operations of the simmering are constant.",
                    "label": 0
                },
                {
                    "sent": "But that's not even the worst, because if you have a very large transducer which might have, as I said, 100 million transitions even if you were ready to wait for a very long time to compute it.",
                    "label": 0
                },
                {
                    "sent": "The space complexity is even worse because you at least even in the in place implementation that I mentioned before, you still need to store that array of all pairs, so that's at least quadratic an if you have 100 million states, the square of that that's too much, even for the amount of memory that we have.",
                    "label": 0
                },
                {
                    "sent": "So that means that this algorithm, both from the space and time complexity, is not very efficient.",
                    "label": 0
                },
                {
                    "sent": "But that's about the exact it's exactly computing what you need, and it's computing too much because it's going to compute the distance from any state to any other state.",
                    "label": 0
                },
                {
                    "sent": "But in particular, you can use it to compute the distance from any state to the set of final states.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another way in other algorithm that is much more efficient in practice for doing this, but that applies only to K close semirings.",
                    "label": 0
                },
                {
                    "sent": "Is is an algorithm that is in fact the generalization of all the algorithms that you've heard about for shortest path algorithms?",
                    "label": 0
                },
                {
                    "sent": "In the sense that.",
                    "label": 0
                },
                {
                    "sent": "It works first of all for any key close simmering it cake low simmering isn't simmering in which when you stick this, some of the iterated XX to the power of I from zero to K + 1.",
                    "label": 0
                },
                {
                    "sent": "Eventually, that's once you reach K plus one that's the same as this some when you go from zero to K. An example of this is for example, if I take the tropical semiring there, the sum is min.",
                    "label": 0
                },
                {
                    "sent": "So in fact even for K = 0 that holds because the minimum of 0.",
                    "label": 0
                },
                {
                    "sent": "And any non negative number is still just zero.",
                    "label": 0
                },
                {
                    "sent": "OK so Trump tropical semiring verifies this.",
                    "label": 0
                },
                {
                    "sent": "Even if you take the probability semiring, and if you have weights that are between zero and one, when you take this sum of X to the power of I very quickly at some point this the two.",
                    "label": 0
                },
                {
                    "sent": "These two this inequality is going to hold in an approximate fashion.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is almost away.",
                    "label": 0
                },
                {
                    "sent": "Computers are are giving you the result of X to the power.",
                    "label": 0
                },
                {
                    "sent": "The sum of the X to the power of I.",
                    "label": 0
                },
                {
                    "sent": "So this property holds approximately.",
                    "label": 0
                },
                {
                    "sent": "Then in practice for the plus time simmering.",
                    "label": 0
                },
                {
                    "sent": "And there is a way of generalizing the single source shortest algorithms to work for all semirings of this kind.",
                    "label": 0
                },
                {
                    "sent": "In fact, there's a very simple algorithm that works for all of them.",
                    "label": 0
                },
                {
                    "sent": "And the idea is to use this standard idea of relaxation.",
                    "label": 0
                },
                {
                    "sent": "You remember what relaxation consists of four, Dijkstra's algorithm or other algorithms of this kind.",
                    "label": 0
                },
                {
                    "sent": "It says I'm going to compute tentative distances from that source to each state, and then if I now have a transition from state to state Q.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's time for me to write a little bit this.",
                    "label": 0
                },
                {
                    "sent": "Can you turn it into?",
                    "label": 0
                },
                {
                    "sent": "Is that better?",
                    "label": 0
                },
                {
                    "sent": "Can open it also?",
                    "label": 0
                },
                {
                    "sent": "Well, that's going to be too much so.",
                    "label": 0
                },
                {
                    "sent": "So suppose that you have now a.",
                    "label": 0
                },
                {
                    "sent": "An edge from P to Q relaxation does the following.",
                    "label": 0
                },
                {
                    "sent": "It says that.",
                    "label": 0
                },
                {
                    "sent": "You have these distances that you tentative distances that you have computed so far, so for now you think that the distance to Q is DFQ and now you just update it.",
                    "label": 0
                },
                {
                    "sent": "The distance to P. And now you're saying well.",
                    "label": 0
                },
                {
                    "sent": "If the weights of this edges WE in the standard cases said well now I'm going to add the tentative distance DLP that I have.",
                    "label": 0
                },
                {
                    "sent": "I'm going to add it to the weight of the edge, and if that sum is smaller than the distance that I had prepared previously computed for Q, then I should replace that DF Q by that some.",
                    "label": 0
                },
                {
                    "sent": "OK so I'm comparing DFP.",
                    "label": 0
                },
                {
                    "sent": "Us WAV OK, that's in the standard shortest path and I'm comparing it trying to see if it's less than DFQ.",
                    "label": 0
                },
                {
                    "sent": "If it's less than, then that's going to become the New deal here.",
                    "label": 0
                },
                {
                    "sent": "OK, So what am I doing?",
                    "label": 0
                },
                {
                    "sent": "In fact in this I mean the shortest path.",
                    "label": 0
                },
                {
                    "sent": "Our world where you remember is the tropical semiring.",
                    "label": 0
                },
                {
                    "sent": "So the operations are mean and plus.",
                    "label": 0
                },
                {
                    "sent": "So in reality another view of this.",
                    "label": 0
                },
                {
                    "sent": "If I write it with respect to these general operations is that I'm right.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to see if the min of DFQ.",
                    "label": 0
                },
                {
                    "sent": "I'm DFP times.",
                    "label": 0
                },
                {
                    "sent": "W appears OK, that's what I'm looking at.",
                    "label": 0
                },
                {
                    "sent": "I'm writing it on purpose by using these general operations.",
                    "label": 0
                },
                {
                    "sent": "The Times of the tropical semiring is just the standard plus anmin.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to in a second, replace it with the plus operation of the simmering.",
                    "label": 0
                },
                {
                    "sent": "OK, so it means that in fact I'm now I'm going to raise this to.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "I'm going to look at the minimum.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "DFQ that's plus is the minimum.",
                    "label": 0
                },
                {
                    "sent": "The minimum of the FQ&DAV times WE.",
                    "label": 0
                },
                {
                    "sent": "If that minimum is equal, and that's a question if it's equal to the of Q, right?",
                    "label": 0
                },
                {
                    "sent": "Then there is nothing to update.",
                    "label": 0
                },
                {
                    "sent": "I'm fine if it is not equal equal then I have to update the FQ.",
                    "label": 0
                },
                {
                    "sent": "So I'm not writing everything in terms of this general simulator to see now how I'm going to generalize this algorithm to the usual.",
                    "label": 0
                },
                {
                    "sent": "Because the notional greeted Unequal is a notion that in fact comes from the Operation Min.",
                    "label": 0
                },
                {
                    "sent": "But in general I might not have that definition.",
                    "label": 0
                },
                {
                    "sent": "I might not know.",
                    "label": 0
                },
                {
                    "sent": "Perhaps perhaps nobody is going to give me that partial order.",
                    "label": 0
                },
                {
                    "sent": "OK, so I need to do this in a general way when someone I'm only using the.",
                    "label": 0
                },
                {
                    "sent": "So this is called relaxation.",
                    "label": 0
                },
                {
                    "sent": "Is simple idea.",
                    "label": 0
                },
                {
                    "sent": "Again I have a distance, I add the weight of the edge I look at, look at the distance of the destination state.",
                    "label": 0
                },
                {
                    "sent": "If it's less, I keep it as it was.",
                    "label": 0
                },
                {
                    "sent": "If it's not updated.",
                    "label": 0
                },
                {
                    "sent": "Simple idea, right?",
                    "label": 0
                },
                {
                    "sent": "Well, in fact all the shortest path algorithms are based on that idea.",
                    "label": 0
                },
                {
                    "sent": "Well, that same algorithm can be that same idea.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can simply be generalized.",
                    "label": 0
                },
                {
                    "sent": "And that's the same code, and I'm not going to ask you to look at the details of that.",
                    "label": 0
                },
                {
                    "sent": "Although you can see it's not that many lines, right, but it's just now generalizing everything to an arbitrary simmering that is K closed.",
                    "label": 0
                },
                {
                    "sent": "This is the heart of it, and that's doing just the relaxation.",
                    "label": 0
                },
                {
                    "sent": "Essentially the same as what we just wrote is the destination, the width of the destination state, the same yes or not than the previous weight of this destination plus.",
                    "label": 0
                },
                {
                    "sent": "The weights of the Source Times WP is that the case yes or not.",
                    "label": 1
                },
                {
                    "sent": "If it is, I update.",
                    "label": 0
                },
                {
                    "sent": "If not, I keep it as it was.",
                    "label": 0
                },
                {
                    "sent": "And the only thing that I need to do in addition to in with respect to the previous usual cases is that in addition to keeping track of the tentative distances the of queues, I also have to have another array, the RF cues which stores the amount of weight that I've added to the weights to the distance at a particular state since the last time I extracted a state from the queue.",
                    "label": 1
                },
                {
                    "sent": "You don't even need to too much know about this.",
                    "label": 0
                },
                {
                    "sent": "Let me now emphasize two things one.",
                    "label": 0
                },
                {
                    "sent": "This very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "Works for any queue discipline, as here is a Q.",
                    "label": 0
                },
                {
                    "sent": "When I say any queue discipline, it means that you can choose different ways of implementing it.",
                    "label": 0
                },
                {
                    "sent": "It could be a shortest first, which is giving you the dykstra's algorithm.",
                    "label": 0
                },
                {
                    "sent": "It could be pfeifle, which then would correspond to the Bellman Ford algorithm.",
                    "label": 0
                },
                {
                    "sent": "It could be the topological order which would then give you the acyclic shortest distance algorithm.",
                    "label": 0
                },
                {
                    "sent": "So in a sense.",
                    "label": 0
                },
                {
                    "sent": "This algorithm works with any queue discipline, and you can prove that in fact it means that all the shortest path algorithms are special instances of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, when you go to school you don't need to learn three different algorithms so fast is to use to learn one and then somebody will tell you.",
                    "label": 0
                },
                {
                    "sent": "Well, we can use any queue discipline with it, that's it.",
                    "label": 0
                },
                {
                    "sent": "But Furthermore, this same algorithm also works for any simmering.",
                    "label": 0
                },
                {
                    "sent": "That is K closed.",
                    "label": 0
                },
                {
                    "sent": "We will need this algorithm to compute the sum of the weights of the path.",
                    "label": 0
                },
                {
                    "sent": "As I said before in this general ways.",
                    "label": 0
                },
                {
                    "sent": "For an arbitrary summary, OK, and.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And so this is just saying what I already said in words.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I am not sure that I'm even going to talk about epsilon removal at this point.",
                    "label": 0
                },
                {
                    "sent": "I don't know, or before giving you some time to breathe or.",
                    "label": 0
                },
                {
                    "sent": "Coffee cups at 10:30.",
                    "label": 0
                },
                {
                    "sent": "Wanted to know.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have time then.",
                    "label": 0
                },
                {
                    "sent": "OK, alright, so let me quickly tell you give you talked about this algorithm Exxon removal and after that I'll start talking about kernels.",
                    "label": 0
                },
                {
                    "sent": "If yes.",
                    "label": 0
                },
                {
                    "sent": "Introduce his capos mismatch.",
                    "label": 0
                },
                {
                    "sent": "Can you say something about why it's justified or what does it?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would in some sense, so you could say, why does he have to talk indeed about these key closed semirings.",
                    "label": 0
                },
                {
                    "sent": "The reason the idea is in fact I could almost call them the computable semirings.",
                    "label": 0
                },
                {
                    "sent": "I could almost claim that any other semiring is not computational WHI, because this means that if I have to compute the weight of a loop of a cycle, I have to be able to stop at some point of time.",
                    "label": 0
                },
                {
                    "sent": "That's what it means.",
                    "label": 0
                },
                {
                    "sent": "I'm taking this some of the X to the power of eyes.",
                    "label": 0
                },
                {
                    "sent": "And every time I go through the loop, I add this new weight and at some point I have to stop.",
                    "label": 0
                },
                {
                    "sent": "Semi rings that are such that I never have to stop where there one possible I have to know the answer before hand, but you can see even if you know the answer before hand, such as in the case of the probability semiring where you know the answer is 1 / 1 -- X right.",
                    "label": 0
                },
                {
                    "sent": "But in fact 1 / 1 -- X is a power series, so to compute it.",
                    "label": 0
                },
                {
                    "sent": "In fact computers still have to do that.",
                    "label": 0
                },
                {
                    "sent": "Some of the excise.",
                    "label": 0
                },
                {
                    "sent": "So in a sense.",
                    "label": 0
                },
                {
                    "sent": "You cannot get away.",
                    "label": 0
                },
                {
                    "sent": "You.",
                    "label": 0
                },
                {
                    "sent": "In practice, computers are really dealing with Kako Semirings.",
                    "label": 0
                },
                {
                    "sent": "So you know it for the tropical semiring and a variety of semirings, you know key in advance.",
                    "label": 0
                },
                {
                    "sent": "If in the cases where it's hold, so it's holding in an exact manner.",
                    "label": 0
                },
                {
                    "sent": "If it does not hold in an exact manner in an approximate manner, you have to choose it in such a way that it corresponds to the approximation that you make in fact.",
                    "label": 0
                },
                {
                    "sent": "For dealing with floating point numbers OK, you can choose the epsilon that is appropriate for your for your application.",
                    "label": 0
                },
                {
                    "sent": "In some sense, computers deal with it anyway.",
                    "label": 0
                },
                {
                    "sent": "You cannot get away with that.",
                    "label": 0
                },
                {
                    "sent": "Once again, they never compute compute 1 / 1 -- X in an exact manner that it's not possible, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so that was the it's a good point.",
                    "label": 0
                },
                {
                    "sent": "Why do you need that?",
                    "label": 0
                },
                {
                    "sent": "And that's kind of the answer.",
                    "label": 0
                },
                {
                    "sent": "Let me also say that their use.",
                    "label": 0
                },
                {
                    "sent": "There had been.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Previously a question about could there be a general framework for talking about single source shortest distance algorithms and this seems to be sort of one way to talk about it, OK?",
                    "label": 0
                },
                {
                    "sent": "Now composition and shortest distance algorithms are the two algorithms that I said we would need for talking about computing kernels, but I'm quickly going to tell you a little bit about another algorithm dealing with epsilons.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know, since you don't like epsilons, maybe I should, in fact not speak too much about this, but one other ways to speak a lot about it so that you hate it even more so.",
                    "label": 0
                },
                {
                    "sent": "An artifact of various operations you might come up with machines that have epsilons in them in the weighted automata case, well, that would be just an epsilon, single epsilon input label if you like.",
                    "label": 0
                },
                {
                    "sent": "In the transducer case it could be an epsilon epsilon.",
                    "label": 0
                },
                {
                    "sent": "As we said, we cannot get, we cannot remove transitions of the type epsilon in necessarily, so my desire here is to remove only in the transducer case epsilon.",
                    "label": 0
                },
                {
                    "sent": "Epsilon transitions OK, why'd would I want to do this is because epsilons create a deley and further nondeterminism.",
                    "label": 0
                },
                {
                    "sent": "So I would want to make the these machines sometimes more efficient by removing that delay.",
                    "label": 0
                },
                {
                    "sent": "How do you do this?",
                    "label": 0
                },
                {
                    "sent": "Well, the algorithm has two components to it, the first one.",
                    "label": 0
                },
                {
                    "sent": "So what would you do?",
                    "label": 0
                },
                {
                    "sent": "How would you do this in a very intuitive way?",
                    "label": 0
                },
                {
                    "sent": "You have a machine that has some epsilons in it.",
                    "label": 0
                },
                {
                    "sent": "You could just say I just want to go and remove them, but you cannot just remove them 'cause you might break the consistency of that machine.",
                    "label": 0
                },
                {
                    "sent": "So instead what you have to do is too many states when you want to remove an epsilon transition, you have to 1st see what are the transitions of this state that you can reach by reading epsilons.",
                    "label": 0
                },
                {
                    "sent": "An you take all those transitions, put them at this state where you were within epsilon epsilon, and then you remove the epsilon.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me just figure just quickly say this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Suppose that I have a.",
                    "label": 0
                },
                {
                    "sent": "There's a state P that has an epsilon transition going to Q, and from Qi read some.",
                    "label": 1
                },
                {
                    "sent": "You know whatever transitions I have, what I'm going to do is that instead I'm going to remove that epsilon here.",
                    "label": 0
                },
                {
                    "sent": "But so if this was Q prime, for example, here I'm directly going to create a transition from P to Q prime.",
                    "label": 0
                },
                {
                    "sent": "With the transition a.",
                    "label": 0
                },
                {
                    "sent": "So I'm basically going to take all the transitions that state Q had and put them back at P. If you like, OK, that's obvious.",
                    "label": 0
                },
                {
                    "sent": "And similarly, if there was a Q second here, I'm going to be going to cusic.",
                    "label": 0
                },
                {
                    "sent": "OK, it's very natural algorithm, so that's what you do in the unweighted case, and it's a very simple thing to do.",
                    "label": 0
                },
                {
                    "sent": "Is a little bit more to do because you might have a sequence of epsilon transitions.",
                    "label": 0
                },
                {
                    "sent": "I'm not just a single one.",
                    "label": 0
                },
                {
                    "sent": "In that case, you have to compute the closure.",
                    "label": 0
                },
                {
                    "sent": "You have to find all the states that can be reached by epsilon path.",
                    "label": 0
                },
                {
                    "sent": "We can do that.",
                    "label": 0
                },
                {
                    "sent": "There's a little bit more to do in the weighted case because in the weighted case there is also weights here, so I could have a weight .5 point 6.7.",
                    "label": 0
                },
                {
                    "sent": "So what do I do here?",
                    "label": 0
                },
                {
                    "sent": "I now not only have to find the states that I can reach by reading epsilons, but I also have to keep track of what weight I need to I take to go to those states.",
                    "label": 0
                },
                {
                    "sent": "Once I've computed the weights to go through each one of those states, when I add these transitions I can now.",
                    "label": 0
                },
                {
                    "sent": "Multiply that .5 with .6 right or here .5 with .7.",
                    "label": 1
                },
                {
                    "sent": "OK so that means that I have to compute the epsilon closure of each state and the epsilon closure of this state.",
                    "label": 0
                },
                {
                    "sent": "P is the set of state Q that I can reach by reading just epsilons.",
                    "label": 0
                },
                {
                    "sent": "In together with the weight, the distance.",
                    "label": 0
                },
                {
                    "sent": "Now suddenly we need the distance the distance from P to Q.",
                    "label": 0
                },
                {
                    "sent": "In other words, this some of the weights of the path epsilon path.",
                    "label": 1
                },
                {
                    "sent": "These are epsilon going from P to Q. OK, and so that in fact becomes shortest distance algorithm.",
                    "label": 0
                },
                {
                    "sent": "And that's where you can see suddenly why this shortest distance algorithm becomes sort of crucial.",
                    "label": 0
                },
                {
                    "sent": "Also for Epson removal so.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is an example of a weighted automaton.",
                    "label": 0
                },
                {
                    "sent": "Which has epsilons on it right?",
                    "label": 0
                },
                {
                    "sent": "And here is an equivalent weighted automata into this one by removing the epsilons and to do this you have to do the two things that I said.",
                    "label": 0
                },
                {
                    "sent": "You compute the distances from each state to the set of says that you can reach by reading epsilons and then remove the epsilons and the right transitions.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so that was just to say that the shortest distance algorithm that I mentioned before is going to be crucial in a number of other algorithms.",
                    "label": 0
                },
                {
                    "sent": "And there is another way of computing the epsilon removal by looking at the reverse machine, which would produce yet another equivalent machine to the to the one that used.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Douglas OK, so this is just to say that you use the shortest distance algorithms, either the generalization of the Ford Marshall or the cake low simmering algorithm.",
                    "label": 0
                },
                {
                    "sent": "And here is the complexity.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In view of what I feel from the audience and familiarity with this kind of things, I think it's time for me.",
                    "label": 0
                },
                {
                    "sent": "Even before your coffee break to start talking about kernels and this kind of things.",
                    "label": 0
                },
                {
                    "sent": "And maybe later on if people are just really, really becoming suddenly passionate about this, I could go back to some of these algorithm things which.",
                    "label": 0
                }
            ]
        }
    }
}