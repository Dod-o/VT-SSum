{
    "id": "crrkx2ctzbk2cdqnyfn3vbor5vlrxpkj",
    "title": "Using Fast Weights to Improve Persistent Contrastive Divergence",
    "info": {
        "author": [
            "Tijmen Tieleman, Department of Computer Science, University of Toronto"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Algorithmic Information Theory"
        ]
    },
    "url": "http://videolectures.net/icml09_tieleman_ufw/",
    "segmentation": [
        [
            "Hello can everybody yes, I think everybody can hear me.",
            "Well, thank you for your introduction and first thing I would like to say is previous paper hung like that was a great paper and it shows very nicely the potential of these deep models.",
            "I'm.",
            "Which is perhaps something that should be kept in mind when you are listening to my talk, because while I will not be presenting some fancy application, I will be talking about an algorithm to train them restricted Boltzmann machines as homework introduced after news.",
            "This components of these deep architectures and I'm speaking about an algorithm to train those.",
            "First again.",
            "I'm not talking bout."
        ],
        [
            "Classification or regression.",
            "I'm talking about modeling data density with Markov random fields.",
            "Now restricted Boltzmann machines.",
            "I want type of Markov random fields, but there are quite some others and the algorithm that I'll be speaking about applies to all of them.",
            "Another important class of Markov random fields are those without hidden units, and the algorithm works well on that tool.",
            "The learning for market random fields is gradient descent usually, and the gradient consists of two parts.",
            "The first thing you should do is increase probability."
        ],
        [
            "See in those areas of the state space where you find your training data.",
            "And the second part is decreasing probability in those areas where you find samples from your model.",
            "This helps to keep the model under control, prevent it from assigning too much probability to random parts of the state space where there's no training data.",
            "Problem with all of this is not the first part, but rather the second, because sampling from these models is usually intractable.",
            "What we do instead is we use not samples from the model, but surrogates samples contrastive divergent's like like mentioned or a pseudo likelihood which is similar to start a Markov chain at the training data.",
            "Then do a few updates and the resulting state is treated as would be sample and that is where we do unlearning.",
            "It's not a true sample, so you do not get the true likelihood gradient, but because it's in the right direction it sort of works as well.",
            "I guess we have just seen.",
            "However, there may be a way to do better to get more accurate samples.",
            "What I'll be mentioning now is something that I explained last year at the same conference in Helsinki.",
            "The persistent contrastive divergent algorithm.",
            "And it's inspired by this observation contrastive divergent's.",
            "There's the unlearning in areas of the state space, where the model assigns too much probability but only areas that are close to your train."
        ],
        [
            "Data, so areas like here and here will be kept at low probability, But this one won't be, so that's how contrasty divergences in a way inaccurate.",
            "There is a way to do better and the central idea is to not throw everything away."
        ],
        [
            "Tween gradient estimates.",
            "We do.",
            "As for City one use Markov chain to get value, the samples are."
        ],
        [
            "Close to samples as we can get from the model and.",
            "Different from C1, we're going to keep it close to the true mobile distribution to the equilibrium distribution.",
            "We're going to do a few transitions on these Markov chains after every weight update.",
            "Two allowed model to allow the samples to catch up with the recent change in the model, but the new part is that we're not going to reset the Markov chains to the training data for every gradient estimates.",
            "That is what city wonders, but will not be doing that.",
            "So we just keep the state of these Markov chains.",
            "That's why I call it persistent contrastive divergent's.",
            "The idea is that this way we always have samples from close to the mobile it's.",
            "If we wouldn't change them all at all, it would be."
        ],
        [
            "Exactly the model we would have true samples after some burning.",
            "Because we would have a regular Markov chain.",
            "No learning, just the Markov chain updates the Gibbs updates.",
            "And we do a little learning with a small learning rate so the Markov chain is never quite at the equilibrium distribution, but always just a little behind and close enough to provide good samples.",
            "That's the idea of persistent contrastive divergent, and it works.",
            "Here is what you do."
        ],
        [
            "Practice you initialize 100 Markov chains arbitrarily.",
            "Initialize the model randomly small parameters.",
            "And the optimization iterations are like this.",
            "You get your next batch of training data and you estimate the positive part of the gradient using that batch.",
            "So this is where we're going to increase probability.",
            "And the negative part, the decreasing probability.",
            "That's what we're going to do wherever the Markov chains are at the moment the negative data.",
            "We take the difference of these two parts of the gradients, and we do a little learning on Theta.",
            "After doing the weight update we do an update on the negative data.",
            "A regular Markov chain update, Gibbs sampling on whatever the model happens to be at the moment, so that's always a little different from what it was at the previous iteration.",
            "And as I said, it works, but we should take another look at."
        ],
        [
            "What's really happening here?",
            "This is a slide that I had three slides back.",
            "The general idea here is something we should take another look at.",
            "The philosophy."
        ],
        [
            "Fear is that we keep the Markov chains close to equilibrium close to the model distribution, and that sounds nice and possible, but it was not something that I had tested when I talked about this algorithm.",
            "I'm to test it.",
            "Well the model is changing all the time, so if the Markov chains are to keep up then they should have a decent mixing rate.",
            "So let's take a look at that mixing rate."
        ],
        [
            "Whether this is a trend of restricted Boltzmann machine classification GBM with one additional visible unit which represents not a pixel but rather the class of the image that we're looking at.",
            "This was trained on the M list digits data set.",
            "So there are 10 possible labels.",
            "And what I'm showing is the state of 96 Markov chains, because 96 fits in a nice image.",
            "On the left I'm showing the state of the pixels.",
            "The Pixel visible units and on the right I'm showing a histogram.",
            "Of the states of the label unit, so the total is 96 and I initialize the all the 96 change with all the pixels off.",
            "And all the label units saying that we're looking at a zero.",
            "We're actually looking at the black image.",
            "We're not looking at a 0, but that's what it says.",
            "And.",
            "This this RBM was trained for three hours with 40,000 wait updates.",
            "It gets decent classification performance at one point 6% errors, so it's it's a mobile like you might encounter.",
            "What I'm going to do is 10,000 iterations of the Markov chain, and I'm going to display the state after every 100.",
            "So you're going to see a a 10 second video with 100 frames and between each frame are 100 updates.",
            "Of the Markov chain, and again as I said, the question is, is the mixing rate of this Markov chain what we expected to be?",
            "Let's take a look.",
            "As you see, things are changing as you'd expect for a Markov chain.",
            "But they're not changing all that much.",
            "The label unit.",
            "Most of the labels stay at zero in the middle.",
            "There were a few that switch to two for a moment and then switch back and accordingly the pixel units keep displaying 0 images.",
            "For all of these 10,000 Markov chain transitions, so this is not all that good of a mixing rate.",
            "We train the model with 40,000 wait updates so the internal persistent Markov chains software 2000.",
            "Transitions which they had to use to keep up with the changing mode all the time, and afterwards we look at it.",
            "We give it 10,000 transitions and we find that it does nothing.",
            "So something here is missing.",
            "Um?",
            "Well, this is a Markov chain as I said.",
            "It was in fact generated by a persistent contrastive divergent script with the learning rate set to zero.",
            "As I mentioned, that is a regular Markov chain, so here's something else I'm going to do.",
            "We're going to set a tiny learning rate.",
            "This mobile was well trained, but we're going to train it a little bit more for another 10,000."
        ],
        [
            "The weight of that with a learning rate of 3 * 10 to the negative 5.",
            "Now the original model was trained with a learning rate of 0.2, so this is really really tiny, but it's not zero, so let's see whether there's a difference.",
            "From what we saw in the previous slide, with the zero learning rate.",
            "What we see here is that.",
            "It takes awhile, but after awhile.",
            "The most of the chains go to something other than zero.",
            "They go to fairly balanced set of digits.",
            "I say you see this in the label and labels and you see this in the images.",
            "So with just this tiny bit of learning.",
            "The Markov chain, which is now no longer a regular Markov chain, but a piece of the Markov chain.",
            "Displays a lot more mixing.",
            "Let's try what happens with a bigger learning right now."
        ],
        [
            "Much bigger, you know.",
            "The original learning rate was 0.2, so this is still small.",
            "Well, just happens faster.",
            "See again now.",
            "It takes a few 1000 updates before we have a fairly balanced set of digits.",
            "See both in the histogram and in the images.",
            "Well, bigger learning, right?"
        ],
        [
            "Takes 1000 iterations to get something fairly balanced and well.",
            "The digits are mostly staying the same, but sometimes one changes into another, especially at the start of the whole iteration of the sequence.",
            "When all those zeros have to become something else.",
            "Bigger learning rate, much bigger learning rate."
        ],
        [
            "Learning rate of 1 which is bigger than what the model was trained with.",
            "No burning pareda to speak off.",
            "I would just jump straight into a balanced set of digits and.",
            "Quite often 1 digit changes into another.",
            "Pretty much on the.",
            "Every every frame, which means that in 100 Markov chain updates you get a different digit.",
            "If you do this much learning.",
            "Let's do some more learning."
        ],
        [
            "Learning rate of three.",
            "Now that's.",
            "An unhealthy little large learning rate.",
            "Still works, but the digits have become a little bit fuzzy.",
            "And of course they change rapidly because we have large learning rate and we've seen the larger learning rates cause more rapid mixing.",
            "Let's try a bigger learn."
        ],
        [
            "Right turn now we no longer get a meaningful mobile.",
            "This learning rate is too large.",
            "We still get a histogram of labels, but the images that we see no longer resemble digits.",
            "So what are we seeing here?"
        ],
        [
            "We see that without learning the mixing for this chain is terribly slow with just a tiny bit of learning, it gets decent and with more learning it gets better.",
            "Question is, how come well to answer that question, we need to have another look at the PCD algorithm.",
            "Remember what we do with this negative data?",
            "We treat it as would be samples from the model and then we reduce probability wherever they are.",
            "The negative fish unlearning.",
            "So after we've changed theater in this way, it's time for an update on the Markov chains and.",
            "What do all these Markov chains find?",
            "They find themselves suddenly in an area of low probability.",
            "They don't know that they themselves are the cause of that.",
            "They just see that it's an area of low probability.",
            "And what do Markov chains do when they are in an area of low probability, they quickly move to an area of high probability, so they quickly move away wherever they can go.",
            "And this is what happens on every iteration.",
            "So this is the central slide of my talk the learning.",
            "Accelerates the mixing you unlearn.",
            "On the state of your Markov chains, then you force them to mix you make wherever they are, low probability so that they quickly move to another area of the state space.",
            "That's the central idea, and this is how you can get a Markov chain, which intrinsically has a terrible mixing rate.",
            "You can make it much mix very fast.",
            "There was a similar talk yesterday by Max Welling.",
            "Hurting dynamical waits to learn, and if you're interested in what I'm telling you, you should also come to his poster this evening.",
            "His paper was similar, but had a deterministic learning and also he claims that regardless how however large, you want to make your learning rate, it still works.",
            "So something is different about his story, because in my version you still need, you know, not too large learning rates.",
            "So this will be interesting.",
            "We can make a Markov chain mix fast."
        ],
        [
            "By doing learning.",
            "And by doing more learning, we can make it mix faster.",
            "Now we all like Markov chains.",
            "That makes fast because it allows you access to good samples from your mobile.",
            "So maybe you'd want to have very fast learning, but very fast learning.",
            "You know, we've seen that.",
            "That's as it's drawbacks.",
            "There's a limit to that.",
            "So what are we gonna do?",
            "Well, we're gonna do both.",
            "We're going to do both fast money and slow learning.",
            "Fast learning is going to take care of the mixing and the slow learning is going to take care of the not going out of control.",
            "So we have the best of both worlds.",
            "To do fast learning, we also need a set of fast weights which we have next to the regular weights, and we're going to make sure that there are always close to it.",
            "So we have two models.",
            "The first model is going to take care of the mixing.",
            "And provide good samples and then the regular weights.",
            "The regular mobile is going to learn with a small learning rate using those good samples.",
            "Here's what it looks like in a computer program.",
            "You initialize as before Theta."
        ],
        [
            "Small weights first.",
            "Data is initialized to zeros.",
            "This parts new.",
            "You initialize negative data arbitrarily, as you did in PCD.",
            "Then an optimization iteration is as before you get the positive gradient or no couple of training data points.",
            "The negative gradient comes from wherever your persistent Markov chains are at the moment.",
            "Would you learning using the difference of those two gradients?",
            "On both of your models, both the regular and the fast model.",
            "And you do an update on the Markov chains using the fast model.",
            "To make the Markov chains move elsewhere rapidly.",
            "And then you decay this fast data a little, because the first model.",
            "The first model is actually.",
            "The regular theater plus the first theater.",
            "So.",
            "We we do the gifts update on the model that you get from regular theater plus fast data and fast data is always kept small.",
            "That's what this last step is for.",
            "When is very small when you."
        ],
        [
            "0 fast learning rate.",
            "Then you get back PCD.",
            "And as I said, the fast weights should have a bigger learning rate than the regular weights.",
            "The regular way to learn slowly to you know, not get anything terrible terribly going out of control with noise in your gradient estimates and the first weights don't care about that, they just learn rapidly to provide good samples, and that way the first mobile is always jumping around rapidly around the regular model.",
            "Regular mobile is slowly learning.",
            "The first model is jumping around around it to provide samples, but always staying close.",
            "Now I have XP."
        ],
        [
            "Mental results and I should say that it works.",
            "It works better than the city.",
            "When you don't have time for a lot of parameter updates, which is the time, which is the case if you are filled on time.",
            "But more importantly, when the gradient estimate it takes a long time.",
            "So the situation that homework talked about.",
            "That's a large dimensionality.",
            "So gradient estimates take a long time.",
            "You don't have time for a lot of parameter update, and my experience was that fast fish D outperforms specity and things like City one and pseudo likelihood.",
            "When you don't have time for a lot of parameter updates.",
            "So for large dimensionality this is an algorithm that looks quite promising.",
            "If you do have time for lots of updates than it does about the same, especially.",
            "Now this plot is.",
            "Classifying endless digits and I did some other experiments, but the most important part of what I've been telling you is actually the theoretical explanation of what's happening with this.",
            "Learning, encouraging, mixing.",
            "That's what I would like you to remember from this talk.",
            "If you do want to see more results, I have them on my poster this evening.",
            "My paper is number 363.",
            "I think that should enable you to find it.",
            "Um so."
        ],
        [
            "To wrap up.",
            "Especially fast by city is persistent contrastive divergent with fast weights, and it happens to, you know, learn faster.",
            "And this is achieved by making good use of the fact that learning encourages mixing, but doing it in such a way that it does not mess up your model because we do it on a separate model that's there only for the fast mixing.",
            "But that does not.",
            "It's not the true model that we're talking about.",
            "True model learns slowly with these high quality samples, and that's what I had to tell you today."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello can everybody yes, I think everybody can hear me.",
                    "label": 0
                },
                {
                    "sent": "Well, thank you for your introduction and first thing I would like to say is previous paper hung like that was a great paper and it shows very nicely the potential of these deep models.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Which is perhaps something that should be kept in mind when you are listening to my talk, because while I will not be presenting some fancy application, I will be talking about an algorithm to train them restricted Boltzmann machines as homework introduced after news.",
                    "label": 0
                },
                {
                    "sent": "This components of these deep architectures and I'm speaking about an algorithm to train those.",
                    "label": 0
                },
                {
                    "sent": "First again.",
                    "label": 0
                },
                {
                    "sent": "I'm not talking bout.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Classification or regression.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about modeling data density with Markov random fields.",
                    "label": 1
                },
                {
                    "sent": "Now restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "I want type of Markov random fields, but there are quite some others and the algorithm that I'll be speaking about applies to all of them.",
                    "label": 0
                },
                {
                    "sent": "Another important class of Markov random fields are those without hidden units, and the algorithm works well on that tool.",
                    "label": 0
                },
                {
                    "sent": "The learning for market random fields is gradient descent usually, and the gradient consists of two parts.",
                    "label": 0
                },
                {
                    "sent": "The first thing you should do is increase probability.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See in those areas of the state space where you find your training data.",
                    "label": 1
                },
                {
                    "sent": "And the second part is decreasing probability in those areas where you find samples from your model.",
                    "label": 0
                },
                {
                    "sent": "This helps to keep the model under control, prevent it from assigning too much probability to random parts of the state space where there's no training data.",
                    "label": 0
                },
                {
                    "sent": "Problem with all of this is not the first part, but rather the second, because sampling from these models is usually intractable.",
                    "label": 0
                },
                {
                    "sent": "What we do instead is we use not samples from the model, but surrogates samples contrastive divergent's like like mentioned or a pseudo likelihood which is similar to start a Markov chain at the training data.",
                    "label": 1
                },
                {
                    "sent": "Then do a few updates and the resulting state is treated as would be sample and that is where we do unlearning.",
                    "label": 0
                },
                {
                    "sent": "It's not a true sample, so you do not get the true likelihood gradient, but because it's in the right direction it sort of works as well.",
                    "label": 0
                },
                {
                    "sent": "I guess we have just seen.",
                    "label": 0
                },
                {
                    "sent": "However, there may be a way to do better to get more accurate samples.",
                    "label": 0
                },
                {
                    "sent": "What I'll be mentioning now is something that I explained last year at the same conference in Helsinki.",
                    "label": 0
                },
                {
                    "sent": "The persistent contrastive divergent algorithm.",
                    "label": 0
                },
                {
                    "sent": "And it's inspired by this observation contrastive divergent's.",
                    "label": 1
                },
                {
                    "sent": "There's the unlearning in areas of the state space, where the model assigns too much probability but only areas that are close to your train.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data, so areas like here and here will be kept at low probability, But this one won't be, so that's how contrasty divergences in a way inaccurate.",
                    "label": 0
                },
                {
                    "sent": "There is a way to do better and the central idea is to not throw everything away.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tween gradient estimates.",
                    "label": 0
                },
                {
                    "sent": "We do.",
                    "label": 0
                },
                {
                    "sent": "As for City one use Markov chain to get value, the samples are.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Close to samples as we can get from the model and.",
                    "label": 1
                },
                {
                    "sent": "Different from C1, we're going to keep it close to the true mobile distribution to the equilibrium distribution.",
                    "label": 1
                },
                {
                    "sent": "We're going to do a few transitions on these Markov chains after every weight update.",
                    "label": 0
                },
                {
                    "sent": "Two allowed model to allow the samples to catch up with the recent change in the model, but the new part is that we're not going to reset the Markov chains to the training data for every gradient estimates.",
                    "label": 0
                },
                {
                    "sent": "That is what city wonders, but will not be doing that.",
                    "label": 0
                },
                {
                    "sent": "So we just keep the state of these Markov chains.",
                    "label": 0
                },
                {
                    "sent": "That's why I call it persistent contrastive divergent's.",
                    "label": 0
                },
                {
                    "sent": "The idea is that this way we always have samples from close to the mobile it's.",
                    "label": 1
                },
                {
                    "sent": "If we wouldn't change them all at all, it would be.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exactly the model we would have true samples after some burning.",
                    "label": 0
                },
                {
                    "sent": "Because we would have a regular Markov chain.",
                    "label": 1
                },
                {
                    "sent": "No learning, just the Markov chain updates the Gibbs updates.",
                    "label": 1
                },
                {
                    "sent": "And we do a little learning with a small learning rate so the Markov chain is never quite at the equilibrium distribution, but always just a little behind and close enough to provide good samples.",
                    "label": 0
                },
                {
                    "sent": "That's the idea of persistent contrastive divergent, and it works.",
                    "label": 0
                },
                {
                    "sent": "Here is what you do.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Practice you initialize 100 Markov chains arbitrarily.",
                    "label": 1
                },
                {
                    "sent": "Initialize the model randomly small parameters.",
                    "label": 0
                },
                {
                    "sent": "And the optimization iterations are like this.",
                    "label": 0
                },
                {
                    "sent": "You get your next batch of training data and you estimate the positive part of the gradient using that batch.",
                    "label": 0
                },
                {
                    "sent": "So this is where we're going to increase probability.",
                    "label": 0
                },
                {
                    "sent": "And the negative part, the decreasing probability.",
                    "label": 0
                },
                {
                    "sent": "That's what we're going to do wherever the Markov chains are at the moment the negative data.",
                    "label": 0
                },
                {
                    "sent": "We take the difference of these two parts of the gradients, and we do a little learning on Theta.",
                    "label": 1
                },
                {
                    "sent": "After doing the weight update we do an update on the negative data.",
                    "label": 0
                },
                {
                    "sent": "A regular Markov chain update, Gibbs sampling on whatever the model happens to be at the moment, so that's always a little different from what it was at the previous iteration.",
                    "label": 0
                },
                {
                    "sent": "And as I said, it works, but we should take another look at.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What's really happening here?",
                    "label": 0
                },
                {
                    "sent": "This is a slide that I had three slides back.",
                    "label": 0
                },
                {
                    "sent": "The general idea here is something we should take another look at.",
                    "label": 0
                },
                {
                    "sent": "The philosophy.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fear is that we keep the Markov chains close to equilibrium close to the model distribution, and that sounds nice and possible, but it was not something that I had tested when I talked about this algorithm.",
                    "label": 1
                },
                {
                    "sent": "I'm to test it.",
                    "label": 0
                },
                {
                    "sent": "Well the model is changing all the time, so if the Markov chains are to keep up then they should have a decent mixing rate.",
                    "label": 0
                },
                {
                    "sent": "So let's take a look at that mixing rate.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Whether this is a trend of restricted Boltzmann machine classification GBM with one additional visible unit which represents not a pixel but rather the class of the image that we're looking at.",
                    "label": 0
                },
                {
                    "sent": "This was trained on the M list digits data set.",
                    "label": 0
                },
                {
                    "sent": "So there are 10 possible labels.",
                    "label": 0
                },
                {
                    "sent": "And what I'm showing is the state of 96 Markov chains, because 96 fits in a nice image.",
                    "label": 0
                },
                {
                    "sent": "On the left I'm showing the state of the pixels.",
                    "label": 0
                },
                {
                    "sent": "The Pixel visible units and on the right I'm showing a histogram.",
                    "label": 0
                },
                {
                    "sent": "Of the states of the label unit, so the total is 96 and I initialize the all the 96 change with all the pixels off.",
                    "label": 0
                },
                {
                    "sent": "And all the label units saying that we're looking at a zero.",
                    "label": 0
                },
                {
                    "sent": "We're actually looking at the black image.",
                    "label": 0
                },
                {
                    "sent": "We're not looking at a 0, but that's what it says.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This this RBM was trained for three hours with 40,000 wait updates.",
                    "label": 0
                },
                {
                    "sent": "It gets decent classification performance at one point 6% errors, so it's it's a mobile like you might encounter.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do is 10,000 iterations of the Markov chain, and I'm going to display the state after every 100.",
                    "label": 0
                },
                {
                    "sent": "So you're going to see a a 10 second video with 100 frames and between each frame are 100 updates.",
                    "label": 0
                },
                {
                    "sent": "Of the Markov chain, and again as I said, the question is, is the mixing rate of this Markov chain what we expected to be?",
                    "label": 1
                },
                {
                    "sent": "Let's take a look.",
                    "label": 0
                },
                {
                    "sent": "As you see, things are changing as you'd expect for a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "But they're not changing all that much.",
                    "label": 0
                },
                {
                    "sent": "The label unit.",
                    "label": 0
                },
                {
                    "sent": "Most of the labels stay at zero in the middle.",
                    "label": 0
                },
                {
                    "sent": "There were a few that switch to two for a moment and then switch back and accordingly the pixel units keep displaying 0 images.",
                    "label": 0
                },
                {
                    "sent": "For all of these 10,000 Markov chain transitions, so this is not all that good of a mixing rate.",
                    "label": 0
                },
                {
                    "sent": "We train the model with 40,000 wait updates so the internal persistent Markov chains software 2000.",
                    "label": 0
                },
                {
                    "sent": "Transitions which they had to use to keep up with the changing mode all the time, and afterwards we look at it.",
                    "label": 0
                },
                {
                    "sent": "We give it 10,000 transitions and we find that it does nothing.",
                    "label": 0
                },
                {
                    "sent": "So something here is missing.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, this is a Markov chain as I said.",
                    "label": 0
                },
                {
                    "sent": "It was in fact generated by a persistent contrastive divergent script with the learning rate set to zero.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, that is a regular Markov chain, so here's something else I'm going to do.",
                    "label": 0
                },
                {
                    "sent": "We're going to set a tiny learning rate.",
                    "label": 0
                },
                {
                    "sent": "This mobile was well trained, but we're going to train it a little bit more for another 10,000.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The weight of that with a learning rate of 3 * 10 to the negative 5.",
                    "label": 0
                },
                {
                    "sent": "Now the original model was trained with a learning rate of 0.2, so this is really really tiny, but it's not zero, so let's see whether there's a difference.",
                    "label": 0
                },
                {
                    "sent": "From what we saw in the previous slide, with the zero learning rate.",
                    "label": 1
                },
                {
                    "sent": "What we see here is that.",
                    "label": 0
                },
                {
                    "sent": "It takes awhile, but after awhile.",
                    "label": 0
                },
                {
                    "sent": "The most of the chains go to something other than zero.",
                    "label": 0
                },
                {
                    "sent": "They go to fairly balanced set of digits.",
                    "label": 0
                },
                {
                    "sent": "I say you see this in the label and labels and you see this in the images.",
                    "label": 0
                },
                {
                    "sent": "So with just this tiny bit of learning.",
                    "label": 0
                },
                {
                    "sent": "The Markov chain, which is now no longer a regular Markov chain, but a piece of the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "Displays a lot more mixing.",
                    "label": 0
                },
                {
                    "sent": "Let's try what happens with a bigger learning right now.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much bigger, you know.",
                    "label": 0
                },
                {
                    "sent": "The original learning rate was 0.2, so this is still small.",
                    "label": 1
                },
                {
                    "sent": "Well, just happens faster.",
                    "label": 0
                },
                {
                    "sent": "See again now.",
                    "label": 0
                },
                {
                    "sent": "It takes a few 1000 updates before we have a fairly balanced set of digits.",
                    "label": 0
                },
                {
                    "sent": "See both in the histogram and in the images.",
                    "label": 0
                },
                {
                    "sent": "Well, bigger learning, right?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Takes 1000 iterations to get something fairly balanced and well.",
                    "label": 0
                },
                {
                    "sent": "The digits are mostly staying the same, but sometimes one changes into another, especially at the start of the whole iteration of the sequence.",
                    "label": 0
                },
                {
                    "sent": "When all those zeros have to become something else.",
                    "label": 0
                },
                {
                    "sent": "Bigger learning rate, much bigger learning rate.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning rate of 1 which is bigger than what the model was trained with.",
                    "label": 1
                },
                {
                    "sent": "No burning pareda to speak off.",
                    "label": 0
                },
                {
                    "sent": "I would just jump straight into a balanced set of digits and.",
                    "label": 0
                },
                {
                    "sent": "Quite often 1 digit changes into another.",
                    "label": 0
                },
                {
                    "sent": "Pretty much on the.",
                    "label": 0
                },
                {
                    "sent": "Every every frame, which means that in 100 Markov chain updates you get a different digit.",
                    "label": 0
                },
                {
                    "sent": "If you do this much learning.",
                    "label": 0
                },
                {
                    "sent": "Let's do some more learning.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning rate of three.",
                    "label": 0
                },
                {
                    "sent": "Now that's.",
                    "label": 0
                },
                {
                    "sent": "An unhealthy little large learning rate.",
                    "label": 1
                },
                {
                    "sent": "Still works, but the digits have become a little bit fuzzy.",
                    "label": 0
                },
                {
                    "sent": "And of course they change rapidly because we have large learning rate and we've seen the larger learning rates cause more rapid mixing.",
                    "label": 0
                },
                {
                    "sent": "Let's try a bigger learn.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right turn now we no longer get a meaningful mobile.",
                    "label": 0
                },
                {
                    "sent": "This learning rate is too large.",
                    "label": 1
                },
                {
                    "sent": "We still get a histogram of labels, but the images that we see no longer resemble digits.",
                    "label": 0
                },
                {
                    "sent": "So what are we seeing here?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We see that without learning the mixing for this chain is terribly slow with just a tiny bit of learning, it gets decent and with more learning it gets better.",
                    "label": 0
                },
                {
                    "sent": "Question is, how come well to answer that question, we need to have another look at the PCD algorithm.",
                    "label": 0
                },
                {
                    "sent": "Remember what we do with this negative data?",
                    "label": 0
                },
                {
                    "sent": "We treat it as would be samples from the model and then we reduce probability wherever they are.",
                    "label": 0
                },
                {
                    "sent": "The negative fish unlearning.",
                    "label": 0
                },
                {
                    "sent": "So after we've changed theater in this way, it's time for an update on the Markov chains and.",
                    "label": 0
                },
                {
                    "sent": "What do all these Markov chains find?",
                    "label": 0
                },
                {
                    "sent": "They find themselves suddenly in an area of low probability.",
                    "label": 0
                },
                {
                    "sent": "They don't know that they themselves are the cause of that.",
                    "label": 0
                },
                {
                    "sent": "They just see that it's an area of low probability.",
                    "label": 0
                },
                {
                    "sent": "And what do Markov chains do when they are in an area of low probability, they quickly move to an area of high probability, so they quickly move away wherever they can go.",
                    "label": 1
                },
                {
                    "sent": "And this is what happens on every iteration.",
                    "label": 0
                },
                {
                    "sent": "So this is the central slide of my talk the learning.",
                    "label": 0
                },
                {
                    "sent": "Accelerates the mixing you unlearn.",
                    "label": 0
                },
                {
                    "sent": "On the state of your Markov chains, then you force them to mix you make wherever they are, low probability so that they quickly move to another area of the state space.",
                    "label": 0
                },
                {
                    "sent": "That's the central idea, and this is how you can get a Markov chain, which intrinsically has a terrible mixing rate.",
                    "label": 0
                },
                {
                    "sent": "You can make it much mix very fast.",
                    "label": 1
                },
                {
                    "sent": "There was a similar talk yesterday by Max Welling.",
                    "label": 0
                },
                {
                    "sent": "Hurting dynamical waits to learn, and if you're interested in what I'm telling you, you should also come to his poster this evening.",
                    "label": 0
                },
                {
                    "sent": "His paper was similar, but had a deterministic learning and also he claims that regardless how however large, you want to make your learning rate, it still works.",
                    "label": 0
                },
                {
                    "sent": "So something is different about his story, because in my version you still need, you know, not too large learning rates.",
                    "label": 0
                },
                {
                    "sent": "So this will be interesting.",
                    "label": 0
                },
                {
                    "sent": "We can make a Markov chain mix fast.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By doing learning.",
                    "label": 0
                },
                {
                    "sent": "And by doing more learning, we can make it mix faster.",
                    "label": 1
                },
                {
                    "sent": "Now we all like Markov chains.",
                    "label": 0
                },
                {
                    "sent": "That makes fast because it allows you access to good samples from your mobile.",
                    "label": 0
                },
                {
                    "sent": "So maybe you'd want to have very fast learning, but very fast learning.",
                    "label": 0
                },
                {
                    "sent": "You know, we've seen that.",
                    "label": 0
                },
                {
                    "sent": "That's as it's drawbacks.",
                    "label": 0
                },
                {
                    "sent": "There's a limit to that.",
                    "label": 0
                },
                {
                    "sent": "So what are we gonna do?",
                    "label": 0
                },
                {
                    "sent": "Well, we're gonna do both.",
                    "label": 0
                },
                {
                    "sent": "We're going to do both fast money and slow learning.",
                    "label": 0
                },
                {
                    "sent": "Fast learning is going to take care of the mixing and the slow learning is going to take care of the not going out of control.",
                    "label": 0
                },
                {
                    "sent": "So we have the best of both worlds.",
                    "label": 0
                },
                {
                    "sent": "To do fast learning, we also need a set of fast weights which we have next to the regular weights, and we're going to make sure that there are always close to it.",
                    "label": 1
                },
                {
                    "sent": "So we have two models.",
                    "label": 0
                },
                {
                    "sent": "The first model is going to take care of the mixing.",
                    "label": 0
                },
                {
                    "sent": "And provide good samples and then the regular weights.",
                    "label": 1
                },
                {
                    "sent": "The regular mobile is going to learn with a small learning rate using those good samples.",
                    "label": 0
                },
                {
                    "sent": "Here's what it looks like in a computer program.",
                    "label": 0
                },
                {
                    "sent": "You initialize as before Theta.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Small weights first.",
                    "label": 0
                },
                {
                    "sent": "Data is initialized to zeros.",
                    "label": 0
                },
                {
                    "sent": "This parts new.",
                    "label": 0
                },
                {
                    "sent": "You initialize negative data arbitrarily, as you did in PCD.",
                    "label": 0
                },
                {
                    "sent": "Then an optimization iteration is as before you get the positive gradient or no couple of training data points.",
                    "label": 1
                },
                {
                    "sent": "The negative gradient comes from wherever your persistent Markov chains are at the moment.",
                    "label": 1
                },
                {
                    "sent": "Would you learning using the difference of those two gradients?",
                    "label": 0
                },
                {
                    "sent": "On both of your models, both the regular and the fast model.",
                    "label": 0
                },
                {
                    "sent": "And you do an update on the Markov chains using the fast model.",
                    "label": 0
                },
                {
                    "sent": "To make the Markov chains move elsewhere rapidly.",
                    "label": 0
                },
                {
                    "sent": "And then you decay this fast data a little, because the first model.",
                    "label": 0
                },
                {
                    "sent": "The first model is actually.",
                    "label": 0
                },
                {
                    "sent": "The regular theater plus the first theater.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We we do the gifts update on the model that you get from regular theater plus fast data and fast data is always kept small.",
                    "label": 0
                },
                {
                    "sent": "That's what this last step is for.",
                    "label": 0
                },
                {
                    "sent": "When is very small when you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "0 fast learning rate.",
                    "label": 0
                },
                {
                    "sent": "Then you get back PCD.",
                    "label": 0
                },
                {
                    "sent": "And as I said, the fast weights should have a bigger learning rate than the regular weights.",
                    "label": 0
                },
                {
                    "sent": "The regular way to learn slowly to you know, not get anything terrible terribly going out of control with noise in your gradient estimates and the first weights don't care about that, they just learn rapidly to provide good samples, and that way the first mobile is always jumping around rapidly around the regular model.",
                    "label": 1
                },
                {
                    "sent": "Regular mobile is slowly learning.",
                    "label": 0
                },
                {
                    "sent": "The first model is jumping around around it to provide samples, but always staying close.",
                    "label": 0
                },
                {
                    "sent": "Now I have XP.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mental results and I should say that it works.",
                    "label": 0
                },
                {
                    "sent": "It works better than the city.",
                    "label": 0
                },
                {
                    "sent": "When you don't have time for a lot of parameter updates, which is the time, which is the case if you are filled on time.",
                    "label": 0
                },
                {
                    "sent": "But more importantly, when the gradient estimate it takes a long time.",
                    "label": 0
                },
                {
                    "sent": "So the situation that homework talked about.",
                    "label": 0
                },
                {
                    "sent": "That's a large dimensionality.",
                    "label": 0
                },
                {
                    "sent": "So gradient estimates take a long time.",
                    "label": 0
                },
                {
                    "sent": "You don't have time for a lot of parameter update, and my experience was that fast fish D outperforms specity and things like City one and pseudo likelihood.",
                    "label": 0
                },
                {
                    "sent": "When you don't have time for a lot of parameter updates.",
                    "label": 1
                },
                {
                    "sent": "So for large dimensionality this is an algorithm that looks quite promising.",
                    "label": 1
                },
                {
                    "sent": "If you do have time for lots of updates than it does about the same, especially.",
                    "label": 0
                },
                {
                    "sent": "Now this plot is.",
                    "label": 0
                },
                {
                    "sent": "Classifying endless digits and I did some other experiments, but the most important part of what I've been telling you is actually the theoretical explanation of what's happening with this.",
                    "label": 0
                },
                {
                    "sent": "Learning, encouraging, mixing.",
                    "label": 1
                },
                {
                    "sent": "That's what I would like you to remember from this talk.",
                    "label": 0
                },
                {
                    "sent": "If you do want to see more results, I have them on my poster this evening.",
                    "label": 0
                },
                {
                    "sent": "My paper is number 363.",
                    "label": 0
                },
                {
                    "sent": "I think that should enable you to find it.",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To wrap up.",
                    "label": 0
                },
                {
                    "sent": "Especially fast by city is persistent contrastive divergent with fast weights, and it happens to, you know, learn faster.",
                    "label": 1
                },
                {
                    "sent": "And this is achieved by making good use of the fact that learning encourages mixing, but doing it in such a way that it does not mess up your model because we do it on a separate model that's there only for the fast mixing.",
                    "label": 0
                },
                {
                    "sent": "But that does not.",
                    "label": 0
                },
                {
                    "sent": "It's not the true model that we're talking about.",
                    "label": 0
                },
                {
                    "sent": "True model learns slowly with these high quality samples, and that's what I had to tell you today.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}