{
    "id": "l2sxg2rkektlt4kmdxew57bwb6gjcfaf",
    "title": "Processing Shear Maps with Karhunen-Loeve Analysis",
    "info": {
        "author": [
            "Jacob VanderPlas, Department of Astronomy, University of Washington"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Astronomy->Cosmology"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_vanderplas_processing/",
    "segmentation": [
        [
            "As I'm Jake, Vander Plas and from University of Washington, this is work that I've done with my graduate student in done this work with Andrew Connolly and Budness Jane, and we're looking at a Kernan Louvre approach to processing Shearman."
        ],
        [
            "So there's going to be more detail on weak lensing later, but essentially what we're looking at is the statistics of shapes of distant galaxies, and by by analyzing those shapes, we can figure out the distortions as light travels through through the matter distribution in space, and that way learn something about the universe.",
            "So there are a lot of challenges in that in the measurement itself, and we'll hear about that later.",
            "But I'm going to assume for now that that we've done the measurement perfectly, that we've gotten the data perfectly perfectly measured, and what we end up with is an incomplete map of the Sky.",
            "Because there are places, for example, and these spots here are places that might be bled out by foreground sources.",
            "This is data from the Cosmos survey done by the Hubble Space Telescope.",
            "What we're looking at here is the number density on the Sky of the sources we can measure.",
            "So.",
            "And from this data where we're trying to infer some some properties like the matter distribution in the universe an this is difficult because we have the holes in the data.",
            "So the approach that we've taken is to do something akin to compress sensing where we come up with an underlying model, and then from the data we've measured try to constrain that underlying model.",
            "And because one property of the signal is that.",
            "Most of the information is in the two point information or the correlation for me."
        ],
        [
            "And we've been able to construct.",
            "We can construct a model using KL analysis which depends only on the correlation function.",
            "So by constructing a theoretical covariance matrix that should describe the data, we can decompose this into modes that have more signal and then modes that are noisy.",
            "And from this we can take our input data.",
            "That's kind of like a vector field, so you can represent it as a set of directions and magnitudes on the Sky.",
            "We take our input data and if you look right up here we have a.",
            "This is a Galaxy cluster that shows the concentric concentric circles around it as the data.",
            "You take the simulated data, we add noise and this is what you get and you're supposed to look in this in this noisy image and see this nice concentric circle here, but it's hard to do.",
            "And then on top of that we mask it, we mask out certain regions of the Sky and then use this scale process to reconstruct what's going on in the mask and also to filter out the noise and."
        ],
        [
            "There's more details in the poster, but we show a couple of things that we can.",
            "We can get fairly high Fidelity mass Maps out of this even with with missing data, so this is a this is a representation of a mass map that you can get out of a weak lensing analysis, and also because the Cosmo logical information and weak lensing is largely in the two point statistics in the correlation statistics.",
            "It allows looking at the two point function directly.",
            "Allows for four.",
            "Cosmo logical parameter estimation, and this is an example.",
            "This isn't something that we did with this technique, but this is from the schradieck 2010 analysis where they use similar information and we are on the path to getting this sort of information out of these gappy data catalogs using our method.",
            "So thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I'm Jake, Vander Plas and from University of Washington, this is work that I've done with my graduate student in done this work with Andrew Connolly and Budness Jane, and we're looking at a Kernan Louvre approach to processing Shearman.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's going to be more detail on weak lensing later, but essentially what we're looking at is the statistics of shapes of distant galaxies, and by by analyzing those shapes, we can figure out the distortions as light travels through through the matter distribution in space, and that way learn something about the universe.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of challenges in that in the measurement itself, and we'll hear about that later.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to assume for now that that we've done the measurement perfectly, that we've gotten the data perfectly perfectly measured, and what we end up with is an incomplete map of the Sky.",
                    "label": 0
                },
                {
                    "sent": "Because there are places, for example, and these spots here are places that might be bled out by foreground sources.",
                    "label": 0
                },
                {
                    "sent": "This is data from the Cosmos survey done by the Hubble Space Telescope.",
                    "label": 0
                },
                {
                    "sent": "What we're looking at here is the number density on the Sky of the sources we can measure.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And from this data where we're trying to infer some some properties like the matter distribution in the universe an this is difficult because we have the holes in the data.",
                    "label": 0
                },
                {
                    "sent": "So the approach that we've taken is to do something akin to compress sensing where we come up with an underlying model, and then from the data we've measured try to constrain that underlying model.",
                    "label": 0
                },
                {
                    "sent": "And because one property of the signal is that.",
                    "label": 1
                },
                {
                    "sent": "Most of the information is in the two point information or the correlation for me.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we've been able to construct.",
                    "label": 0
                },
                {
                    "sent": "We can construct a model using KL analysis which depends only on the correlation function.",
                    "label": 1
                },
                {
                    "sent": "So by constructing a theoretical covariance matrix that should describe the data, we can decompose this into modes that have more signal and then modes that are noisy.",
                    "label": 0
                },
                {
                    "sent": "And from this we can take our input data.",
                    "label": 1
                },
                {
                    "sent": "That's kind of like a vector field, so you can represent it as a set of directions and magnitudes on the Sky.",
                    "label": 0
                },
                {
                    "sent": "We take our input data and if you look right up here we have a.",
                    "label": 0
                },
                {
                    "sent": "This is a Galaxy cluster that shows the concentric concentric circles around it as the data.",
                    "label": 0
                },
                {
                    "sent": "You take the simulated data, we add noise and this is what you get and you're supposed to look in this in this noisy image and see this nice concentric circle here, but it's hard to do.",
                    "label": 0
                },
                {
                    "sent": "And then on top of that we mask it, we mask out certain regions of the Sky and then use this scale process to reconstruct what's going on in the mask and also to filter out the noise and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's more details in the poster, but we show a couple of things that we can.",
                    "label": 0
                },
                {
                    "sent": "We can get fairly high Fidelity mass Maps out of this even with with missing data, so this is a this is a representation of a mass map that you can get out of a weak lensing analysis, and also because the Cosmo logical information and weak lensing is largely in the two point statistics in the correlation statistics.",
                    "label": 0
                },
                {
                    "sent": "It allows looking at the two point function directly.",
                    "label": 0
                },
                {
                    "sent": "Allows for four.",
                    "label": 0
                },
                {
                    "sent": "Cosmo logical parameter estimation, and this is an example.",
                    "label": 0
                },
                {
                    "sent": "This isn't something that we did with this technique, but this is from the schradieck 2010 analysis where they use similar information and we are on the path to getting this sort of information out of these gappy data catalogs using our method.",
                    "label": 0
                },
                {
                    "sent": "So thanks.",
                    "label": 0
                }
            ]
        }
    }
}