{
    "id": "s4dlcrom52pvrb6c4ndmsat3erj4njak",
    "title": "Jointly Modeling Aspects, Ratings and Sentiments for Movie Recommendation (JMARS)",
    "info": {
        "author": [
            "Chao-Yuan Wu, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_wu_movie_recommendation/",
    "segmentation": [
        [
            "Until your new from Carnegie Mellon University, and this is a joint work with him in Dale Mitchell, Alex Smola, Jinjang and Sean Wong."
        ],
        [
            "OK, so here's a typical movie review.",
            "We have a rating and we also have a review text that the user explains why he likes or dislike a movie."
        ],
        [
            "And so there's no recommender systems.",
            "Usually.",
            "Just use the information in the ratings."
        ],
        [
            "But we can see this very rich information in the reviews like the users might comment on different aspects on a movie."
        ],
        [
            "So our motivation is OK. We want to jointly model not only the ratings, both of the reviews, and in order to provide better recommendation.",
            "And we also want to learn what the user users are interested in.",
            "Like does the user cares more about like plot or story or special effects.",
            "And we also want to know know more about the movies and at the same time we can also extract the topics.",
            "And the sentiment an in in a fully integrated model.",
            "And we do it in an unsupervised way, meaning that we don't need any like sentiment labels or predefined aspects."
        ],
        [
            "So we assume that there are many aspects that the user can evaluate in movie.",
            "Young, OK. For example, he might evaluate movie based on the acting or story.",
            "Or how did this as a horror movie or romance movie like that.",
            "So we will also have different ratings on these different aspects and there's also a distribution becausw.",
            "Each of the aspects may have different importances."
        ],
        [
            "And we can observe the rating and review.",
            "And our goal is to then what the aspects are and learn the ratings and learn the distribution and also want to model how the words are generated."
        ],
        [
            "So here's our topical model graphical model.",
            "So in the left plate we have the user and in the right plate we have the movie and in the intersection of the two place other ratings and reviews and the inner box.",
            "Other words in the review."
        ],
        [
            "And this model, composed of two major parts.",
            "The first part on the top is the rating model and the lower part is the review model and I will explain each of the components next."
        ],
        [
            "OK, so first of all, we have aspect distributions for user movie and reviews.",
            "So the aspect distribution for the user represents the interest of the user.",
            "Like is it.",
            "Cares more about like plots or special effects.",
            "Things like that and aspect distribution for the review for the movie represents the property of the of the movie.",
            "Like is it has a lot of special effects or is it more comedy than a Romance movie?",
            "And we assume that the aspect distribution of the review is the combination of both the aspect distribution of the user and the one of the movie.",
            "OK, so the intuition is that the user write something in the review only if the user cares about this aspect and also the in the movie there is something about the aspect that can be discussed OK."
        ],
        [
            "And we also have some rating model.",
            "I'm pretty similar to matrix factorization.",
            "We have latent features VU&VM and bias BU MB M over here.",
            "But instead of just predict the overall rating directly, we want to predict the ratings for each of the aspect.",
            "OK, that's for now.",
            "Just assume that we have learned the aspects and we'll get to that in a minute.",
            "OK, so this is done by learning a matrix MA over here, which captures the properties of the aspect so that we can predict different ratings for different aspects in the overall rating will be the weighted sum of the aspect specific ratings with it by the aspect distribution."
        ],
        [
            "Ann to extract information from the reviews, we want to model the review test carefully, so we assume that there are five categories of words.",
            "So first of all we have background words which other words like movie or film was like that those words appears in almost all the reviews but provide free information.",
            "And we also have some sentiment words.",
            "That is the positive ones and negative ones.",
            "So for example, like positive ones we might have like good grade, amazing words like that.",
            "And we also have movie specific words like the name of the characters, name of the actors, etc.",
            "And what's more interesting is the aspect words.",
            "For example, for the aspect about, say, visual effects, we might have words like CGI, animation, 3D special effects, things like that.",
            "And we also want to learn the sentiment words for each aspect.",
            "For example, for the aspect like about maybe story, we may have negative sentiment.",
            "Words like boring is predictable, OK?",
            "So."
        ],
        [
            "So how are these words generated?",
            "OK, so we assume that there is a categorical distribution initial review over the five categories.",
            "So for each word we sampled one category that is Y over here for each word and if the category is related to aspects, we also sampled the aspect from the aspect distribution.",
            "And if it is some words related to sentiment, we."
        ],
        [
            "Also want to sample the sentiment so the S here is binary variable takes the value positive or negative and we model this through a sigmoid mapping.",
            "The intuition is that the higher the rating is, the more likely the user will write about some positive words, and we can also learn the shape of this sigmoid functions.",
            "OK."
        ],
        [
            "So after the finding the graphical model.",
            "And let's see how they do the inference so that first look at the objective function, which is composed of two parts.",
            "The first part is the cost of their rating.",
            "We want to minimize the error we make of our prediction.",
            "And the second part is we want to maximize the likelihood of the words in the reviews given the model.",
            "OK, so we do this through.",
            "Some gives them meaning that in the eastep we fixed all the parameters and we do the Gibbs sampling to sample the category Y the on the aspesi and sentiment S in the M step we fix the ysz over here and we optimize all the other parameters.",
            "Use a gradient descent or it will be FGS and we repeat these two steps and iteratively.",
            "King"
        ],
        [
            "So.",
            "How does the work so?"
        ],
        [
            "The data set we used is the live copy we crowd from IMDb, which consists of more than 300,000 reviews.",
            "And notice that this data set is actually pretty sparse with density only .03%, and we can see Netflix data set has density of one person, so this is much sparser.",
            "An much harder data set."
        ],
        [
            "And that's first evaluate this in terms of mercy of our prediction.",
            "So we compare our model with three baseline.",
            "We have off the only which is the constant predictor that simply predictor rating to be the average, and we also compare it with the popular PMF.",
            "Probabilistic matrix factorization.",
            "And also the HFT which is a very recent state of the art work there.",
            "Also use the information from the review, but the model in assumptions are pretty different so we can see that our system outperforms all of them in terms of MSE."
        ],
        [
            "And we also evaluate our model in terms of the ability of our.",
            "Topic model.",
            "OK, so we compute the perplexity compare with HLT and we can see that our model also outperforms quite a lot.",
            "Ah."
        ],
        [
            "And what's more interesting Lee is that we also want to see if using the information in the reviews can help us address address the coastal problem.",
            "So the vertical axis here is the improvement we made compared with PMF.",
            "So as we can see that for users with few reviews, chili make even bigger improvement, and that's a good news, because those users are the Costar users.",
            "Those are the users we failed before, but we are making an even bigger improvement here."
        ],
        [
            "And that's also look at some qualitative evaluation."
        ],
        [
            "OK, so first of all we highlight some positive words, an highlight some movie specific words and we can see the words we find like excellent, incredible and movie.",
            "Specifically refunds are quite make sense."
        ],
        [
            "And more Interestingly, we can also see that the aspect distribution we learn in the aspect rating we learn are pretty consistent to the counter in the reviews.",
            "So for example, we have directing is incredible and we can see that in the aspect about Director we have high probability with high rating and similarly like battle, things are incredible.",
            "We have high probability in the world where aspect.",
            "With high high rating as well."
        ],
        [
            "And here is some aspect word in some aspect specific sentiment words we found.",
            "So here are two aspects.",
            "An we can see that the aspect words are clean in.",
            "Interestingly, the sentiment words we found out pretty specific to each of the aspect, like the positive words like violence, gritty blood visuals are pretty consistent to this topic.",
            "So I think this also emphasized the importance of modeling the sentiment words on each aspect instead of just general sentiment words, OK?"
        ],
        [
            "And here's those.",
            "Those are movies.",
            "Specifically we found, so we can see there are basically like the name of the characters, then of the actors etc.",
            "And we can also see the background words we found like film story, things like that and also positive words like good grade, negative words like bad boring here.",
            "Quite make sense."
        ],
        [
            "So in summary, in our work we jointly model ratings, reviews, movies and users and notice that in order model no any pre definition of aspects are needed and also we don't need any like labels for sentiments as well.",
            "Is fully unsupervised and we can also generate the topics automatically and generate the sentiment automatically.",
            "And what's more important is that through this model we can understand why the user likes or dislike a movie and we know the interest.",
            "We know the properties of the movie and know the interest of the user OK. Anne.",
            "And yeah, we don't need the any of the aspect sentiment labels as maybe other systems do.",
            "And is pretty much of it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Until your new from Carnegie Mellon University, and this is a joint work with him in Dale Mitchell, Alex Smola, Jinjang and Sean Wong.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's a typical movie review.",
                    "label": 0
                },
                {
                    "sent": "We have a rating and we also have a review text that the user explains why he likes or dislike a movie.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so there's no recommender systems.",
                    "label": 0
                },
                {
                    "sent": "Usually.",
                    "label": 0
                },
                {
                    "sent": "Just use the information in the ratings.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we can see this very rich information in the reviews like the users might comment on different aspects on a movie.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our motivation is OK. We want to jointly model not only the ratings, both of the reviews, and in order to provide better recommendation.",
                    "label": 0
                },
                {
                    "sent": "And we also want to learn what the user users are interested in.",
                    "label": 0
                },
                {
                    "sent": "Like does the user cares more about like plot or story or special effects.",
                    "label": 0
                },
                {
                    "sent": "And we also want to know know more about the movies and at the same time we can also extract the topics.",
                    "label": 0
                },
                {
                    "sent": "And the sentiment an in in a fully integrated model.",
                    "label": 1
                },
                {
                    "sent": "And we do it in an unsupervised way, meaning that we don't need any like sentiment labels or predefined aspects.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we assume that there are many aspects that the user can evaluate in movie.",
                    "label": 0
                },
                {
                    "sent": "Young, OK. For example, he might evaluate movie based on the acting or story.",
                    "label": 0
                },
                {
                    "sent": "Or how did this as a horror movie or romance movie like that.",
                    "label": 0
                },
                {
                    "sent": "So we will also have different ratings on these different aspects and there's also a distribution becausw.",
                    "label": 0
                },
                {
                    "sent": "Each of the aspects may have different importances.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can observe the rating and review.",
                    "label": 0
                },
                {
                    "sent": "And our goal is to then what the aspects are and learn the ratings and learn the distribution and also want to model how the words are generated.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's our topical model graphical model.",
                    "label": 0
                },
                {
                    "sent": "So in the left plate we have the user and in the right plate we have the movie and in the intersection of the two place other ratings and reviews and the inner box.",
                    "label": 0
                },
                {
                    "sent": "Other words in the review.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this model, composed of two major parts.",
                    "label": 0
                },
                {
                    "sent": "The first part on the top is the rating model and the lower part is the review model and I will explain each of the components next.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so first of all, we have aspect distributions for user movie and reviews.",
                    "label": 0
                },
                {
                    "sent": "So the aspect distribution for the user represents the interest of the user.",
                    "label": 0
                },
                {
                    "sent": "Like is it.",
                    "label": 0
                },
                {
                    "sent": "Cares more about like plots or special effects.",
                    "label": 0
                },
                {
                    "sent": "Things like that and aspect distribution for the review for the movie represents the property of the of the movie.",
                    "label": 0
                },
                {
                    "sent": "Like is it has a lot of special effects or is it more comedy than a Romance movie?",
                    "label": 0
                },
                {
                    "sent": "And we assume that the aspect distribution of the review is the combination of both the aspect distribution of the user and the one of the movie.",
                    "label": 0
                },
                {
                    "sent": "OK, so the intuition is that the user write something in the review only if the user cares about this aspect and also the in the movie there is something about the aspect that can be discussed OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also have some rating model.",
                    "label": 0
                },
                {
                    "sent": "I'm pretty similar to matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "We have latent features VU&VM and bias BU MB M over here.",
                    "label": 0
                },
                {
                    "sent": "But instead of just predict the overall rating directly, we want to predict the ratings for each of the aspect.",
                    "label": 0
                },
                {
                    "sent": "OK, that's for now.",
                    "label": 0
                },
                {
                    "sent": "Just assume that we have learned the aspects and we'll get to that in a minute.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is done by learning a matrix MA over here, which captures the properties of the aspect so that we can predict different ratings for different aspects in the overall rating will be the weighted sum of the aspect specific ratings with it by the aspect distribution.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ann to extract information from the reviews, we want to model the review test carefully, so we assume that there are five categories of words.",
                    "label": 0
                },
                {
                    "sent": "So first of all we have background words which other words like movie or film was like that those words appears in almost all the reviews but provide free information.",
                    "label": 0
                },
                {
                    "sent": "And we also have some sentiment words.",
                    "label": 0
                },
                {
                    "sent": "That is the positive ones and negative ones.",
                    "label": 0
                },
                {
                    "sent": "So for example, like positive ones we might have like good grade, amazing words like that.",
                    "label": 0
                },
                {
                    "sent": "And we also have movie specific words like the name of the characters, name of the actors, etc.",
                    "label": 0
                },
                {
                    "sent": "And what's more interesting is the aspect words.",
                    "label": 0
                },
                {
                    "sent": "For example, for the aspect about, say, visual effects, we might have words like CGI, animation, 3D special effects, things like that.",
                    "label": 0
                },
                {
                    "sent": "And we also want to learn the sentiment words for each aspect.",
                    "label": 0
                },
                {
                    "sent": "For example, for the aspect like about maybe story, we may have negative sentiment.",
                    "label": 0
                },
                {
                    "sent": "Words like boring is predictable, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how are these words generated?",
                    "label": 0
                },
                {
                    "sent": "OK, so we assume that there is a categorical distribution initial review over the five categories.",
                    "label": 0
                },
                {
                    "sent": "So for each word we sampled one category that is Y over here for each word and if the category is related to aspects, we also sampled the aspect from the aspect distribution.",
                    "label": 0
                },
                {
                    "sent": "And if it is some words related to sentiment, we.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also want to sample the sentiment so the S here is binary variable takes the value positive or negative and we model this through a sigmoid mapping.",
                    "label": 0
                },
                {
                    "sent": "The intuition is that the higher the rating is, the more likely the user will write about some positive words, and we can also learn the shape of this sigmoid functions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So after the finding the graphical model.",
                    "label": 0
                },
                {
                    "sent": "And let's see how they do the inference so that first look at the objective function, which is composed of two parts.",
                    "label": 1
                },
                {
                    "sent": "The first part is the cost of their rating.",
                    "label": 0
                },
                {
                    "sent": "We want to minimize the error we make of our prediction.",
                    "label": 0
                },
                {
                    "sent": "And the second part is we want to maximize the likelihood of the words in the reviews given the model.",
                    "label": 1
                },
                {
                    "sent": "OK, so we do this through.",
                    "label": 1
                },
                {
                    "sent": "Some gives them meaning that in the eastep we fixed all the parameters and we do the Gibbs sampling to sample the category Y the on the aspesi and sentiment S in the M step we fix the ysz over here and we optimize all the other parameters.",
                    "label": 1
                },
                {
                    "sent": "Use a gradient descent or it will be FGS and we repeat these two steps and iteratively.",
                    "label": 0
                },
                {
                    "sent": "King",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How does the work so?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The data set we used is the live copy we crowd from IMDb, which consists of more than 300,000 reviews.",
                    "label": 0
                },
                {
                    "sent": "And notice that this data set is actually pretty sparse with density only .03%, and we can see Netflix data set has density of one person, so this is much sparser.",
                    "label": 0
                },
                {
                    "sent": "An much harder data set.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's first evaluate this in terms of mercy of our prediction.",
                    "label": 0
                },
                {
                    "sent": "So we compare our model with three baseline.",
                    "label": 0
                },
                {
                    "sent": "We have off the only which is the constant predictor that simply predictor rating to be the average, and we also compare it with the popular PMF.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "And also the HFT which is a very recent state of the art work there.",
                    "label": 0
                },
                {
                    "sent": "Also use the information from the review, but the model in assumptions are pretty different so we can see that our system outperforms all of them in terms of MSE.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also evaluate our model in terms of the ability of our.",
                    "label": 0
                },
                {
                    "sent": "Topic model.",
                    "label": 0
                },
                {
                    "sent": "OK, so we compute the perplexity compare with HLT and we can see that our model also outperforms quite a lot.",
                    "label": 0
                },
                {
                    "sent": "Ah.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what's more interesting Lee is that we also want to see if using the information in the reviews can help us address address the coastal problem.",
                    "label": 0
                },
                {
                    "sent": "So the vertical axis here is the improvement we made compared with PMF.",
                    "label": 0
                },
                {
                    "sent": "So as we can see that for users with few reviews, chili make even bigger improvement, and that's a good news, because those users are the Costar users.",
                    "label": 0
                },
                {
                    "sent": "Those are the users we failed before, but we are making an even bigger improvement here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's also look at some qualitative evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so first of all we highlight some positive words, an highlight some movie specific words and we can see the words we find like excellent, incredible and movie.",
                    "label": 0
                },
                {
                    "sent": "Specifically refunds are quite make sense.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And more Interestingly, we can also see that the aspect distribution we learn in the aspect rating we learn are pretty consistent to the counter in the reviews.",
                    "label": 0
                },
                {
                    "sent": "So for example, we have directing is incredible and we can see that in the aspect about Director we have high probability with high rating and similarly like battle, things are incredible.",
                    "label": 0
                },
                {
                    "sent": "We have high probability in the world where aspect.",
                    "label": 0
                },
                {
                    "sent": "With high high rating as well.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is some aspect word in some aspect specific sentiment words we found.",
                    "label": 0
                },
                {
                    "sent": "So here are two aspects.",
                    "label": 0
                },
                {
                    "sent": "An we can see that the aspect words are clean in.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, the sentiment words we found out pretty specific to each of the aspect, like the positive words like violence, gritty blood visuals are pretty consistent to this topic.",
                    "label": 0
                },
                {
                    "sent": "So I think this also emphasized the importance of modeling the sentiment words on each aspect instead of just general sentiment words, OK?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's those.",
                    "label": 0
                },
                {
                    "sent": "Those are movies.",
                    "label": 0
                },
                {
                    "sent": "Specifically we found, so we can see there are basically like the name of the characters, then of the actors etc.",
                    "label": 0
                },
                {
                    "sent": "And we can also see the background words we found like film story, things like that and also positive words like good grade, negative words like bad boring here.",
                    "label": 0
                },
                {
                    "sent": "Quite make sense.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, in our work we jointly model ratings, reviews, movies and users and notice that in order model no any pre definition of aspects are needed and also we don't need any like labels for sentiments as well.",
                    "label": 1
                },
                {
                    "sent": "Is fully unsupervised and we can also generate the topics automatically and generate the sentiment automatically.",
                    "label": 0
                },
                {
                    "sent": "And what's more important is that through this model we can understand why the user likes or dislike a movie and we know the interest.",
                    "label": 0
                },
                {
                    "sent": "We know the properties of the movie and know the interest of the user OK. Anne.",
                    "label": 1
                },
                {
                    "sent": "And yeah, we don't need the any of the aspect sentiment labels as maybe other systems do.",
                    "label": 0
                },
                {
                    "sent": "And is pretty much of it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}