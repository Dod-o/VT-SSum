{
    "id": "eyfmi7y3dbj462t7vjcmjgsrdwx4rkqu",
    "title": "Large Scale Learning - Challenge",
    "info": {
        "author": [
            "S\u00f6ren Sonnenburg, Machine Learning and Intelligent Data Analysis Group, TU Berlin",
            "Vojtech Franc, Fraunhofer Institute for Intelligent Analysis and Information Systems"
        ],
        "published": "Sept. 1, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_sonnenburg_lsl/",
    "segmentation": [
        [
            "OK, so good morning everyone.",
            "Welcome to the evaluation of this Pascal Challenge World logical learning.",
            "So we will have.",
            "Like this kind of schedule so we have all these contributors talking, but first of all we were given introduction about.",
            "Like what we thought.",
            "What we had in mind for the challenge.",
            "And then, then yeah, then we will go full program and at the end we will have some quite long discussion because there are some very controversial design decisions that we made.",
            "Maybe it's possible to get come up with potentially better ones."
        ],
        [
            "OK."
        ],
        [
            "So.",
            "Like the overview is consists of like 4 parts, so we have like some motivation why we're doing a challenge.",
            "The evaluation criteria we designed and presented at NIPS.",
            "The Nips workshop already.",
            "Justification, then statistics and some preliminary results."
        ],
        [
            "So not all methods went through it, so.",
            "So we have a large scale definition here which we designed this by which we designed to challenge, and I know that for example, John Langford has a different one.",
            "So what makes the problem not scale to us?",
            "It's like anything that it's getting that making it extreme, so like lots of data points like high dimensionality or or algorithms that for their category of high effort.",
            "So so basically anything that reaches crime computational.",
            "Memory or transfer cost limits of current computers.",
            "So this also means that basically anything.",
            "From this definition definition, it also means that basically anything like like tuning algorithm in assembly language.",
            "To like have more memory to choose and like to invent a better algorithm that has lower leg, lower effort may turn the problem into a small scale problem already."
        ],
        [
            "OK, so our motivation was that current servers, so we seen we try to do some comparison between SVM solvers and we recognize that.",
            "Actually things are not so easy to compare.",
            "So for example, tossing arguments like in 2005.",
            "Showed as being purpose, much faster, mainstream, right?",
            "But when we reiterated everything's in, light was in fact much much faster and still is in Perth.",
            "Then they will shower Schwartz in 2007, showing that Pigasus is even faster than an SVM light in Perth.",
            "But in our experiment it was not not at all.",
            "Whenever.",
            "So we still at all coming with Beam M, which is in fact a special case of assume perfect.",
            "It was so much it was much faster.",
            "And then suddenly a newer version of SM Perth came out.",
            "It was really much faster, similar speed to BM or even faster.",
            "And then the number 2 and then show that SGD, which is basically it's very similar to appearances.",
            "I don't rightly agree.",
            "Outperforms lots of the computer, so it's really questionable which method is really fast, so we decided it might be a good idea to have a challenge.",
            "We are not.",
            "But not just us.",
            "Rerun all the experiments, but the authors themselves.",
            "Try to get the best out of."
        ],
        [
            "Benefits.",
            "So the main goal was to have like the exact same conditions for everyone such that we can have a fair valuation cause of course financial reasons that these methods were faster than the others that we had.",
            "These loops that, like we use different evaluation criteria criteria than they.",
            "And we decided to have an evaluation based on training time and some kind of error.",
            "So then we define some additional goals, for example.",
            "Which show do you want to know which method is like overall best and which which classifier is most efficient given certain certain budget like training time or memory and short one?",
            "Just use approximately algorithm?",
            "Or should one do like really exact optimization?",
            "And what is it?",
            "Once you tune, then when it's doing large scale like data representation?"
        ],
        [
            "What do you call over them?",
            "OK, so we designed this.",
            "I'm just challenge.",
            "Which had an in the beginning, 2 tracks like the Wild Track and to method specific trick.",
            "And now has an additional parlor trick.",
            "OK, for stuff and the setup was as follows that we had like several datasets.",
            "1010 data set.",
            "Actually with like several several data set sizes, and.",
            "We gave out only the training data with labels and kept the validation test set.",
            "On for us and the validation set, actually we also gave out but with our labels such that.",
            "Contributors can have a life revelation, so on what we ask is that people record training, time validation and test output for intermediate points that should be coming every time.",
            "Time over precision curve.",
            "Try to calibrate this timing by some.",
            "Program.",
            "And we have provided live feedback and in the end people participants had to submit detail."
        ],
        [
            "Explanation why why MF it quite MF works.",
            "OK, so now we're coming to the operation criteria.",
            "So we had basically free.",
            "We defined three different curves, which was this time with test error data.",
            "Set size was time.",
            "And data set size was test error.",
            "And so these figures, we think that these figures are really reasonable to do.",
            "The problem is for a challenge, you need to define some scalar measures to any and get a ranking.",
            "So we."
        ],
        [
            "Try to.",
            "Who tried to come up with some scalar measures?",
            "So this would be the first curve, so it's CPU time versus some error measure.",
            "And.",
            "Yeah, so it's so basically if you if you have this curve you can add like anytime point decide which method you should use.",
            "For your, for your time budget, which just the one which has the lowest error and the scale images we derive from this curve is our.",
            "The minimal test error that the method could achieve the time for method to be within 5% relative error to the best method.",
            "And the area on the under this this curve?",
            "Which basically.",
            "By which we want to express that it if a method is fast, like going down or in the beginning.",
            "It's like already quite optimal beginning, and it's then it's better."
        ],
        [
            "OK, so another another curve which is also not so debatable is that like data set size versus CPU time in a log log plot plotted in a log log plot.",
            "So the slope of these lines.",
            "Can be can be used as the computational effort.",
            "OK, so on."
        ],
        [
            "The scalar measure.",
            "And then we define another one we have to do last curve which is data set size versus precision.",
            "Again again error.",
            "So this is to say that if a method can can make more out of by using more data and also the method in like the in the early stages or few data points can be performing well.",
            "And for this we again use the area under the curve.",
            "It's also the again method which is within how many data points do you need to be within 5% of the best error."
        ],
        [
            "OK.",
            "So for ACMS you have to adjust the goals to look at.",
            "Actually it's solving optimization problems so fast SVM solver gets down the objective very fast.",
            "So we decided to to have objective you will test error, wait a second.",
            "We have objective value overtime.",
            "And you want to want to know is this like which stopping condition is good or which which algorithm is good for what kind of data?"
        ],
        [
            "Like chunking better for unbalanced 8 over.",
            "Things like this.",
            "Yeah, so in principle these figures.",
            "Yeah, so principle figure.",
            "It's really like objective value, overtime and something like C, overtime and otherwise the effort."
        ],
        [
            "Again.",
            "OK, so.",
            "This was the time of the challenge, so we started in February.",
            "We just just ended like a few weeks ago.",
            "Two weeks I think.",
            "You know it's still ongoing relating everything on the 32 gigabyte machine.",
            "And we're now here and evaluating and presenting criminal evenness, and I'll prove innocent primary results.",
            "We actually planning to have a Gmail artreach on large scale benefits for."
        ],
        [
            "The best methods and also other other entries.",
            "OK, so some statistics.",
            "We had an in total 49 people that subscribed.",
            "To to at least challenge website to change website.",
            "We got 44 different submissions total we had like really over 700 submissions to not submissions like like you had to submit for each data set.",
            "For each method you had to submit for each data set.",
            "So in the end we had like over 700 of these which we deleted like about 200 I would say or even more.",
            "For some mistakes, then most most submissions.",
            "So most submissions that we got where basically linear methods so variance of one or two items.",
            "So for example this STD.",
            "QN and Newton method some new methods and do a coin is sent.",
            "Some triple jump is from an interior point linear SVM.",
            "Material there were very few methods that tried any any nonlinear stuff.",
            "Like a decision tree or some basement pool and then just a plain SVM using RBF kernel.",
            "So we will have like in the next next talk, so you see all the all the people talking which are here and Bolt for presenting their results.",
            "OK."
        ],
        [
            "So.",
            "First, statistics, like most active force Christian, would send K. He didn't share point SVM and competed in the linear independent of IEEE Trick then.",
            "But while bodies he did like take part in this with SSD and rank.",
            "And only the Chappelle and Curtean.",
            "If there are news methods.",
            "Then then it's clear that it became clear that most people are actually interested just only in the wild trick.",
            "So we got like really, people only care about test test error in shortest possible time.",
            "There was at least interest in independence PM Check.",
            "Then and actually.",
            "The data set which were simplest, so the datasets which we artificially which were artificially generated, like the Alpha and so on.",
            "All these Greek letter.",
            "Datasets they got received a lot of submissions and people started usually with Alpha and so we had 74 submissions in there.",
            "Programming language wise, we've seen really CC C++.",
            "Lots of lots of Matlab and.",
            "And also Java.",
            "But I just told that it's actually just a wrapper calling to see."
        ],
        [
            "Alright, so which is so?",
            "Could you take?",
            "OK.",
            "So I'm going to tell you something about the datasets which we use for evaluation, so we wanted to have variants, various kinds of datasets from different domains and also with different properties.",
            "So what are the table shows?",
            "First, each line, each row is around data set.",
            "Then you can see split of the data to training, testing and validation's part.",
            "Also the dimensional attain and description of the data set.",
            "Basically we had two groups of datasets.",
            "First, some artificially generated data from Alpha Tezeta where we exactly know the ground true model and also we had some practical problems from different domains like face detection, OCR, some DNA classification, and that spend classification.",
            "The idea for having these artificially generated data was that basically then we have in hand ground true model, so we know how the data are generated, what are the properties so we can observe how the methods behave under different conditions.",
            "And also of course we have optimal classifier in this case.",
            "So we basically have the optimal possible performance.",
            "So we can see the gap between what was achieved by the submitters and what is possible to achieve.",
            "OK, we generate basically the model behind all these datasets is quite simple.",
            "Each class is generated by a single Gaussian.",
            "So the only difference is the mean vector and covariance matrix.",
            "So the structure of the covariance matrix.",
            "So the Alpha data set can be today said they are generated from Gaussian with full covariance matrix.",
            "The difference is that the Alpha data set is easy to separate.",
            "So the classification error is around 5%, but the beta is quite tough.",
            "It's the classification error is 35%.",
            "Then these two datasets basically use covariance matrix with diagonal only with diagonal elements.",
            "But the variance of of individual features is quite different.",
            "The reason for generating this data is that some methods, namely SVM's, have quite some problems if the variance is different.",
            "So we generated data with high variance features and low variance features.",
            "These two datasets and finally these two datasets.",
            "Are something which we called data with intrinsic dimensionality.",
            "So the idea is that the data are embedded to some high dimensional space, but in fact they can be described by in some very low dimensional space.",
            "So there is some Gaussian.",
            "Let's say that 200 dimensions or.",
            "There is a mistake.",
            "This should be 400 dimensions.",
            "Which generates the data and then we have some linear mapping to high dimensional space, so presumably methods which can take into account this model, like some subspace methods should.",
            "Should perform well here.",
            "Well.",
            "Maybe that it's about the datasets."
        ],
        [
            "So maybe one of the most important tables, the performance.",
            "For individual datasets.",
            "For the optimal classifier, at least for the artificially generated data.",
            "And also for some real problems we know the state of the art.",
            "So also this this is the optimal model in these cases.",
            "So for these two data set it is simple quadratic classifier.",
            "Here it is a quadratic classifier but only with the diagonal diagonal elements.",
            "And here it's a linear linear linear rule, is the optimal one.",
            "So this is the optimal.",
            "The performance, measured in terms of area over the precision recall curve and here you can see performance of the best submitted method.",
            "So.",
            "You can see that basically for these two datasets.",
            "The winner is a method which use some nonlinear decision function.",
            "Most of the submissions are some variants of SVM, so they use linear classification rules, but it was enough basically to use some combination of simple carbs to get.",
            "The best result, but still you can see that it is far from the from the optimum.",
            "For these two datasets.",
            "The submitted results are very close to the optimum becausw.",
            "Basically, the model fits well.",
            "In fact, the Naive Bayes rule assumes exactly the same model as we used for generating the data, so no big surprise that this method one.",
            "For these two datasets, the optimal model is linear, so again, no surprise SVM's.",
            "Vanna this, for these datasets, so you can see that we generated a lot of data, so the obtained performance is close to the optimal one.",
            "Well, we can afford the practical problems.",
            "Of course we don't have ground through model.",
            "We don't know what's possible to achieve, but The thing is that.",
            "We hope that.",
            "People value some domain knowledge which didn't happen.",
            "Basically, everyone used the basic data representation which we provided.",
            "The result is that.",
            "The performance achieved is much lower than what is the state of the art.",
            "So for instance, for DNA zone is the expert in this field, so this is the state of the art, so it's device better than voted this basic.",
            "Representation without using some domain knowledge can achieve.",
            "Well.",
            "This is about performance."
        ],
        [
            "So now we have some preliminary results.",
            "Results of the wildtrak develop practices.",
            "The track with the highest number of submissions.",
            "This is the score which is basically average over the rankings for four different for different scoring measures.",
            "So you can see.",
            "That the 1st four methods have very similar score, but there is a big gap between the 4th and the 5th place.",
            "Zoran said that we managed to evaluate it for already for eight best ranking methods, we would like to have it for 10, top 10.",
            "About, I think that there is a low chance that.",
            "After having these results done.",
            "It can somehow change the ordering, at least for the best ranking methods, because you can see the gap is quite significant here.",
            "So what are the winners or not Venus, but best performing methods?",
            "So SGD algorithm?",
            "Newton method.",
            "As the end, which will be presented today.",
            "Another optimizer for SVM's Lauren, which is basically also SVM method.",
            "Elite, cleaner and interior point SVM methods.",
            "So we are happy that most of these methods will be presented today, so we will learn what Verdi tricks to achieve these good results.",
            "Discord, OK, it was described, so we had several different scores for each score we had the ranking.",
            "And then we took average ranking and this is the average ranking.",
            "Of course there is a question how to combine different.",
            "Object feels well, yeah.",
            "It's the result."
        ],
        [
            "So examples of some figures.",
            "So this is the result on the 1st artificially generated data set where the ground through model is quadratic classifier.",
            "So the best performing method here is this averaged SVM.",
            "Is this blue curve which basically starts here and goes here.",
            "Another thing which we can see that the most method which used VM's.",
            "Have almost the same performance, but also the curves are very similar, so there are many methods which are discussed are overlapping so they behave quite similar.",
            "But still you can see that there is a big gap between the performance, which which was achieved and the optimal one which is in this case.",
            "0.001"
        ],
        [
            "Well, this curve shows performance as a function of data set size.",
            "So basically all the methods benefit from using more and more data.",
            "Of course, the method using the best model is blue one.",
            "Gains finally the best result, but here we can also see that.",
            "Some tradeoff between the complexity of the model and the optimization becausw for this method.",
            "This method was able to train only from.",
            "100 thousands of examples and it is clear that maybe if we would be able to train from more examples, we can still improve the results so clearly for large scale learning the optimization vectors."
        ],
        [
            "Another artificially generated data set.",
            "In this case, it was also the Gaussian distribution with full covariance matrix, but in this case the classification error was quite high, so you can see that all these linear SVM's perform equally bad.",
            "And that it's basically.",
            "Sufficient to have some slightly more difficult model to get much better results.",
            "But still not achieving the optimal, which was like 0.3."
        ],
        [
            "Well, again, for the same data set.",
            "If you have that model then you cannot benefit even from millions of data.",
            "Not big surprise."
        ],
        [
            "OK.",
            "This is another artificially generated data set.",
            "In this case, the model which the method which uses basically the same model as the one used for generating the data.",
            "Gets almost optimal solution, but you can also see here that if we want to learn with some budget on the time, then we have to trade off between the complexity of the model and.",
            "The optimization accuracy because you can see that if we have enough time then we can reach very nice performance.",
            "But if there is some limit on the time, then maybe it's useful to use some simple model like these linear SVM's which are able to find some solution in quite short time so.",
            "So on."
        ],
        [
            "Servation yeah, basically.",
            "Say."
        ],
        [
            "Think maybe I can."
        ],
        [
            "Speed up to."
        ],
        [
            "These"
        ],
        [
            "Optical problems, so as I said, we provided some basic data representation.",
            "We hope that people will try to somehow understand the problems and use some knowledge domain, which unfortunately didn't happen so.",
            "You can see that using this very simple features, you basically gain nothing.",
            "In this case, the state of the art result is something like 0.4.",
            "So.",
            "Maybe there is still big room for improvements.",
            "If there will be some follow up.",
            "To use the tools.",
            "In this case.",
            "We used A plus or.",
            "Or single character even.",
            "Peoples being yeah but we provide it.",
            "Also the raw data.",
            "So it was possible that they use some weighted degree kernel which is the best in this."
        ],
        [
            "OK.",
            "Phone.",
            "Yeah, for the web spam we used as features back of words so you can see that if you have good feature representation than linear SVM methods are quite good, so achieving nearly.",
            "The best possible performance.",
            "So here it is basically only competition between optimization algorithms."
        ],
        [
            "Well, yeah, it's it's seen that it's really needed to be able to train from almost all the data to get.",
            "To get good performance."
        ],
        [
            "Yeah yeah, for face detection it's the same.",
            "The features that are just pixels.",
            "Which is far from the optimum.",
            "The methods which use.",
            "Some filters, like other boost filters and so on, get by order of magnitude.",
            "Better performance here."
        ],
        [
            "Yeah, OCR.",
            "Well, the nice thing is that basically.",
            "All these methods here use the same linear classifier.",
            "The only difference is the C constant.",
            "So you can see that tuning the model really matters, because if you select the C incorrectly then you can get quite different results."
        ],
        [
            "And this is the graph for for the same methods.",
            "Which basically shows that even if you select wrong C, then if you are using more and more data than you can in some sense compensate for this but selected C. Which is interesting."
        ],
        [
            "Yeah, so we have also some preliminary results for linear SVM.",
            "Unfortunately, the Revolution is still pending.",
            "However, if you look at the difference between the best scoring method and the 2nd or the 3rd, there is quite a big gap, so we don't expect big changes.",
            "So.",
            "Yeah, maybe Zoran wants to give some conclusions and announce the winners.",
            "Yeah, so just just to comment on this with like the SVM trick we had some problems that people submitted objective values which are not necessarily the right ones.",
            "Are computed on only subsets of data so that we have there still weight room too lots to do to really get this to find into a final ranking.",
            "But I mean.",
            "It's definitely one of the reasons, definitely that we didn't ask for the W of the SVM or but just just ask people to submit the objective value in this clear that things can happen there.",
            "OK, so."
        ],
        [
            "So.",
            "So like some conclusions.",
            "OK, So what became really clear is that like the method that is best, whereas most efficient.",
            "This is the method which has the right tradeoff between like having a complex complex model like in terms of lots of parameters and and could find lots of training time and.",
            "Being like accurate and in the end.",
            "Um?",
            "Then there it's clear that.",
            "You can get that a low model error is.",
            "Is the crucial thing, so it's not not the optimization accuracy that really matters.",
            "So what we recognize that lots of that almost all of these VM servers stopped very, very early, so.",
            "Having like a big difference in accuracy, so the model to model is much more crucial than actually the optimization method behind it.",
            "We've also also seen that basically all these linear SVM solvers, also they're using very different optimization methods, performed more or less the same.",
            "So there maybe maybe this interior point methods are still computationally.",
            "Much more demanding but.",
            "This implementation here from Christian would send was performing quite well.",
            "So.",
            "OK, so then.",
            "Makes makes a lot of sense.",
            "If you have the right model to really use all of the data that you did you.",
            "You can use.",
            "Then you may still improve.",
            "Um?",
            "And the one the one the one thing we've learned is that basically no one really tried to modify the data representation at all.",
            "So basically everyone just used the data representation we provided, so we had like raw datasets.",
            "We provide some conversion into assume light format.",
            "And which was just meant as a suggestion suggestion.",
            "Just in time.",
            "Um?",
            "And there's like lots of there would have been lots of room for improvement, like by just creating quadratic features or squaring features and adding them to the space.",
            "And it's not really big.",
            "Big things, one lot of work to do so, but by this one could.",
            "But much easier, easier have one of the challenge."
        ],
        [
            "OK, so so we based on what we have on the relation that we have we.",
            "We can declare some winner Venus, which are definitely in a stable set.",
            "However, it's not.",
            "That's not the case that we can declare like single winners.",
            "It's like a group of business.",
            "Because these methods are really performing more or less equally well.",
            "So one on the SVM track and on the right track of these.",
            "This basically is this free linear SVM solvers.",
            "Come on twin.",
            "On TV and said here.",
            "Then for the for the SVM track.",
            "So far it's Linnea is best.",
            "Anne.",
            "And I'm not sure whether it's OK.",
            "I cannot even say the name with.",
            "It's actually he's the only author in this.",
            "And then.",
            "We decided to also have two additional awards in there for the for the best additional students in this taking part in this change.",
            "So into your point SVM 'cause it took part in all of these datasets and was actually showing how good you can still be with just a just a normal interior point method.",
            "And the triple jump.",
            "OK."
        ],
        [
            "So.",
            "So what the future?",
            "So I mean like in this.",
            "In this workshop we will at the end discuss all the very very many problems here we are seeing.",
            "And like ask for feedback like in the last session.",
            "So let's postpone all this.",
            "All this until then.",
            "For now we are planning like in the future to have like an agenda.",
            "Our special check on.",
            "On large scale methods.",
            "Yeah, which is.",
            "It's not clear that it will be accepted, but it's not so unlikely, I hope.",
            "Which will have the submission deadline in October.",
            "And then actually we will open this up to other participants, not only to participants of the workshop, but also others.",
            "However, we will then require them to use these three figures like these.",
            "These measures to evaluate their methods, otherwise it won't be really fair.",
            "And then the question is whether we should do another challenge and if someone is willing to step up and have good ideas about immigration criteria that like.",
            "Maybe better.",
            "OK, so so much for the overview."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "Welcome to the evaluation of this Pascal Challenge World logical learning.",
                    "label": 0
                },
                {
                    "sent": "So we will have.",
                    "label": 0
                },
                {
                    "sent": "Like this kind of schedule so we have all these contributors talking, but first of all we were given introduction about.",
                    "label": 0
                },
                {
                    "sent": "Like what we thought.",
                    "label": 0
                },
                {
                    "sent": "What we had in mind for the challenge.",
                    "label": 0
                },
                {
                    "sent": "And then, then yeah, then we will go full program and at the end we will have some quite long discussion because there are some very controversial design decisions that we made.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's possible to get come up with potentially better ones.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Like the overview is consists of like 4 parts, so we have like some motivation why we're doing a challenge.",
                    "label": 0
                },
                {
                    "sent": "The evaluation criteria we designed and presented at NIPS.",
                    "label": 1
                },
                {
                    "sent": "The Nips workshop already.",
                    "label": 0
                },
                {
                    "sent": "Justification, then statistics and some preliminary results.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So not all methods went through it, so.",
                    "label": 0
                },
                {
                    "sent": "So we have a large scale definition here which we designed this by which we designed to challenge, and I know that for example, John Langford has a different one.",
                    "label": 0
                },
                {
                    "sent": "So what makes the problem not scale to us?",
                    "label": 0
                },
                {
                    "sent": "It's like anything that it's getting that making it extreme, so like lots of data points like high dimensionality or or algorithms that for their category of high effort.",
                    "label": 1
                },
                {
                    "sent": "So so basically anything that reaches crime computational.",
                    "label": 1
                },
                {
                    "sent": "Memory or transfer cost limits of current computers.",
                    "label": 0
                },
                {
                    "sent": "So this also means that basically anything.",
                    "label": 0
                },
                {
                    "sent": "From this definition definition, it also means that basically anything like like tuning algorithm in assembly language.",
                    "label": 0
                },
                {
                    "sent": "To like have more memory to choose and like to invent a better algorithm that has lower leg, lower effort may turn the problem into a small scale problem already.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so our motivation was that current servers, so we seen we try to do some comparison between SVM solvers and we recognize that.",
                    "label": 1
                },
                {
                    "sent": "Actually things are not so easy to compare.",
                    "label": 0
                },
                {
                    "sent": "So for example, tossing arguments like in 2005.",
                    "label": 0
                },
                {
                    "sent": "Showed as being purpose, much faster, mainstream, right?",
                    "label": 0
                },
                {
                    "sent": "But when we reiterated everything's in, light was in fact much much faster and still is in Perth.",
                    "label": 0
                },
                {
                    "sent": "Then they will shower Schwartz in 2007, showing that Pigasus is even faster than an SVM light in Perth.",
                    "label": 0
                },
                {
                    "sent": "But in our experiment it was not not at all.",
                    "label": 0
                },
                {
                    "sent": "Whenever.",
                    "label": 0
                },
                {
                    "sent": "So we still at all coming with Beam M, which is in fact a special case of assume perfect.",
                    "label": 1
                },
                {
                    "sent": "It was so much it was much faster.",
                    "label": 0
                },
                {
                    "sent": "And then suddenly a newer version of SM Perth came out.",
                    "label": 1
                },
                {
                    "sent": "It was really much faster, similar speed to BM or even faster.",
                    "label": 0
                },
                {
                    "sent": "And then the number 2 and then show that SGD, which is basically it's very similar to appearances.",
                    "label": 0
                },
                {
                    "sent": "I don't rightly agree.",
                    "label": 0
                },
                {
                    "sent": "Outperforms lots of the computer, so it's really questionable which method is really fast, so we decided it might be a good idea to have a challenge.",
                    "label": 0
                },
                {
                    "sent": "We are not.",
                    "label": 0
                },
                {
                    "sent": "But not just us.",
                    "label": 0
                },
                {
                    "sent": "Rerun all the experiments, but the authors themselves.",
                    "label": 0
                },
                {
                    "sent": "Try to get the best out of.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Benefits.",
                    "label": 0
                },
                {
                    "sent": "So the main goal was to have like the exact same conditions for everyone such that we can have a fair valuation cause of course financial reasons that these methods were faster than the others that we had.",
                    "label": 0
                },
                {
                    "sent": "These loops that, like we use different evaluation criteria criteria than they.",
                    "label": 0
                },
                {
                    "sent": "And we decided to have an evaluation based on training time and some kind of error.",
                    "label": 1
                },
                {
                    "sent": "So then we define some additional goals, for example.",
                    "label": 0
                },
                {
                    "sent": "Which show do you want to know which method is like overall best and which which classifier is most efficient given certain certain budget like training time or memory and short one?",
                    "label": 1
                },
                {
                    "sent": "Just use approximately algorithm?",
                    "label": 0
                },
                {
                    "sent": "Or should one do like really exact optimization?",
                    "label": 0
                },
                {
                    "sent": "And what is it?",
                    "label": 0
                },
                {
                    "sent": "Once you tune, then when it's doing large scale like data representation?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What do you call over them?",
                    "label": 0
                },
                {
                    "sent": "OK, so we designed this.",
                    "label": 0
                },
                {
                    "sent": "I'm just challenge.",
                    "label": 0
                },
                {
                    "sent": "Which had an in the beginning, 2 tracks like the Wild Track and to method specific trick.",
                    "label": 0
                },
                {
                    "sent": "And now has an additional parlor trick.",
                    "label": 0
                },
                {
                    "sent": "OK, for stuff and the setup was as follows that we had like several datasets.",
                    "label": 0
                },
                {
                    "sent": "1010 data set.",
                    "label": 0
                },
                {
                    "sent": "Actually with like several several data set sizes, and.",
                    "label": 0
                },
                {
                    "sent": "We gave out only the training data with labels and kept the validation test set.",
                    "label": 0
                },
                {
                    "sent": "On for us and the validation set, actually we also gave out but with our labels such that.",
                    "label": 0
                },
                {
                    "sent": "Contributors can have a life revelation, so on what we ask is that people record training, time validation and test output for intermediate points that should be coming every time.",
                    "label": 1
                },
                {
                    "sent": "Time over precision curve.",
                    "label": 0
                },
                {
                    "sent": "Try to calibrate this timing by some.",
                    "label": 0
                },
                {
                    "sent": "Program.",
                    "label": 1
                },
                {
                    "sent": "And we have provided live feedback and in the end people participants had to submit detail.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Explanation why why MF it quite MF works.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're coming to the operation criteria.",
                    "label": 0
                },
                {
                    "sent": "So we had basically free.",
                    "label": 0
                },
                {
                    "sent": "We defined three different curves, which was this time with test error data.",
                    "label": 1
                },
                {
                    "sent": "Set size was time.",
                    "label": 0
                },
                {
                    "sent": "And data set size was test error.",
                    "label": 1
                },
                {
                    "sent": "And so these figures, we think that these figures are really reasonable to do.",
                    "label": 0
                },
                {
                    "sent": "The problem is for a challenge, you need to define some scalar measures to any and get a ranking.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try to.",
                    "label": 0
                },
                {
                    "sent": "Who tried to come up with some scalar measures?",
                    "label": 1
                },
                {
                    "sent": "So this would be the first curve, so it's CPU time versus some error measure.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's so basically if you if you have this curve you can add like anytime point decide which method you should use.",
                    "label": 0
                },
                {
                    "sent": "For your, for your time budget, which just the one which has the lowest error and the scale images we derive from this curve is our.",
                    "label": 0
                },
                {
                    "sent": "The minimal test error that the method could achieve the time for method to be within 5% relative error to the best method.",
                    "label": 1
                },
                {
                    "sent": "And the area on the under this this curve?",
                    "label": 0
                },
                {
                    "sent": "Which basically.",
                    "label": 0
                },
                {
                    "sent": "By which we want to express that it if a method is fast, like going down or in the beginning.",
                    "label": 0
                },
                {
                    "sent": "It's like already quite optimal beginning, and it's then it's better.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so another another curve which is also not so debatable is that like data set size versus CPU time in a log log plot plotted in a log log plot.",
                    "label": 0
                },
                {
                    "sent": "So the slope of these lines.",
                    "label": 0
                },
                {
                    "sent": "Can be can be used as the computational effort.",
                    "label": 0
                },
                {
                    "sent": "OK, so on.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The scalar measure.",
                    "label": 0
                },
                {
                    "sent": "And then we define another one we have to do last curve which is data set size versus precision.",
                    "label": 0
                },
                {
                    "sent": "Again again error.",
                    "label": 0
                },
                {
                    "sent": "So this is to say that if a method can can make more out of by using more data and also the method in like the in the early stages or few data points can be performing well.",
                    "label": 0
                },
                {
                    "sent": "And for this we again use the area under the curve.",
                    "label": 1
                },
                {
                    "sent": "It's also the again method which is within how many data points do you need to be within 5% of the best error.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So for ACMS you have to adjust the goals to look at.",
                    "label": 0
                },
                {
                    "sent": "Actually it's solving optimization problems so fast SVM solver gets down the objective very fast.",
                    "label": 0
                },
                {
                    "sent": "So we decided to to have objective you will test error, wait a second.",
                    "label": 0
                },
                {
                    "sent": "We have objective value overtime.",
                    "label": 1
                },
                {
                    "sent": "And you want to want to know is this like which stopping condition is good or which which algorithm is good for what kind of data?",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like chunking better for unbalanced 8 over.",
                    "label": 0
                },
                {
                    "sent": "Things like this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so in principle these figures.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so principle figure.",
                    "label": 0
                },
                {
                    "sent": "It's really like objective value, overtime and something like C, overtime and otherwise the effort.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This was the time of the challenge, so we started in February.",
                    "label": 0
                },
                {
                    "sent": "We just just ended like a few weeks ago.",
                    "label": 0
                },
                {
                    "sent": "Two weeks I think.",
                    "label": 0
                },
                {
                    "sent": "You know it's still ongoing relating everything on the 32 gigabyte machine.",
                    "label": 0
                },
                {
                    "sent": "And we're now here and evaluating and presenting criminal evenness, and I'll prove innocent primary results.",
                    "label": 0
                },
                {
                    "sent": "We actually planning to have a Gmail artreach on large scale benefits for.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The best methods and also other other entries.",
                    "label": 0
                },
                {
                    "sent": "OK, so some statistics.",
                    "label": 0
                },
                {
                    "sent": "We had an in total 49 people that subscribed.",
                    "label": 1
                },
                {
                    "sent": "To to at least challenge website to change website.",
                    "label": 0
                },
                {
                    "sent": "We got 44 different submissions total we had like really over 700 submissions to not submissions like like you had to submit for each data set.",
                    "label": 0
                },
                {
                    "sent": "For each method you had to submit for each data set.",
                    "label": 0
                },
                {
                    "sent": "So in the end we had like over 700 of these which we deleted like about 200 I would say or even more.",
                    "label": 0
                },
                {
                    "sent": "For some mistakes, then most most submissions.",
                    "label": 0
                },
                {
                    "sent": "So most submissions that we got where basically linear methods so variance of one or two items.",
                    "label": 1
                },
                {
                    "sent": "So for example this STD.",
                    "label": 1
                },
                {
                    "sent": "QN and Newton method some new methods and do a coin is sent.",
                    "label": 1
                },
                {
                    "sent": "Some triple jump is from an interior point linear SVM.",
                    "label": 0
                },
                {
                    "sent": "Material there were very few methods that tried any any nonlinear stuff.",
                    "label": 0
                },
                {
                    "sent": "Like a decision tree or some basement pool and then just a plain SVM using RBF kernel.",
                    "label": 0
                },
                {
                    "sent": "So we will have like in the next next talk, so you see all the all the people talking which are here and Bolt for presenting their results.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "First, statistics, like most active force Christian, would send K. He didn't share point SVM and competed in the linear independent of IEEE Trick then.",
                    "label": 1
                },
                {
                    "sent": "But while bodies he did like take part in this with SSD and rank.",
                    "label": 0
                },
                {
                    "sent": "And only the Chappelle and Curtean.",
                    "label": 0
                },
                {
                    "sent": "If there are news methods.",
                    "label": 0
                },
                {
                    "sent": "Then then it's clear that it became clear that most people are actually interested just only in the wild trick.",
                    "label": 0
                },
                {
                    "sent": "So we got like really, people only care about test test error in shortest possible time.",
                    "label": 0
                },
                {
                    "sent": "There was at least interest in independence PM Check.",
                    "label": 1
                },
                {
                    "sent": "Then and actually.",
                    "label": 0
                },
                {
                    "sent": "The data set which were simplest, so the datasets which we artificially which were artificially generated, like the Alpha and so on.",
                    "label": 0
                },
                {
                    "sent": "All these Greek letter.",
                    "label": 0
                },
                {
                    "sent": "Datasets they got received a lot of submissions and people started usually with Alpha and so we had 74 submissions in there.",
                    "label": 0
                },
                {
                    "sent": "Programming language wise, we've seen really CC C++.",
                    "label": 0
                },
                {
                    "sent": "Lots of lots of Matlab and.",
                    "label": 0
                },
                {
                    "sent": "And also Java.",
                    "label": 0
                },
                {
                    "sent": "But I just told that it's actually just a wrapper calling to see.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so which is so?",
                    "label": 0
                },
                {
                    "sent": "Could you take?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to tell you something about the datasets which we use for evaluation, so we wanted to have variants, various kinds of datasets from different domains and also with different properties.",
                    "label": 0
                },
                {
                    "sent": "So what are the table shows?",
                    "label": 0
                },
                {
                    "sent": "First, each line, each row is around data set.",
                    "label": 0
                },
                {
                    "sent": "Then you can see split of the data to training, testing and validation's part.",
                    "label": 0
                },
                {
                    "sent": "Also the dimensional attain and description of the data set.",
                    "label": 0
                },
                {
                    "sent": "Basically we had two groups of datasets.",
                    "label": 0
                },
                {
                    "sent": "First, some artificially generated data from Alpha Tezeta where we exactly know the ground true model and also we had some practical problems from different domains like face detection, OCR, some DNA classification, and that spend classification.",
                    "label": 0
                },
                {
                    "sent": "The idea for having these artificially generated data was that basically then we have in hand ground true model, so we know how the data are generated, what are the properties so we can observe how the methods behave under different conditions.",
                    "label": 0
                },
                {
                    "sent": "And also of course we have optimal classifier in this case.",
                    "label": 0
                },
                {
                    "sent": "So we basically have the optimal possible performance.",
                    "label": 0
                },
                {
                    "sent": "So we can see the gap between what was achieved by the submitters and what is possible to achieve.",
                    "label": 0
                },
                {
                    "sent": "OK, we generate basically the model behind all these datasets is quite simple.",
                    "label": 0
                },
                {
                    "sent": "Each class is generated by a single Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So the only difference is the mean vector and covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So the structure of the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So the Alpha data set can be today said they are generated from Gaussian with full covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "The difference is that the Alpha data set is easy to separate.",
                    "label": 0
                },
                {
                    "sent": "So the classification error is around 5%, but the beta is quite tough.",
                    "label": 0
                },
                {
                    "sent": "It's the classification error is 35%.",
                    "label": 0
                },
                {
                    "sent": "Then these two datasets basically use covariance matrix with diagonal only with diagonal elements.",
                    "label": 0
                },
                {
                    "sent": "But the variance of of individual features is quite different.",
                    "label": 0
                },
                {
                    "sent": "The reason for generating this data is that some methods, namely SVM's, have quite some problems if the variance is different.",
                    "label": 0
                },
                {
                    "sent": "So we generated data with high variance features and low variance features.",
                    "label": 0
                },
                {
                    "sent": "These two datasets and finally these two datasets.",
                    "label": 0
                },
                {
                    "sent": "Are something which we called data with intrinsic dimensionality.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that the data are embedded to some high dimensional space, but in fact they can be described by in some very low dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So there is some Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Let's say that 200 dimensions or.",
                    "label": 0
                },
                {
                    "sent": "There is a mistake.",
                    "label": 0
                },
                {
                    "sent": "This should be 400 dimensions.",
                    "label": 0
                },
                {
                    "sent": "Which generates the data and then we have some linear mapping to high dimensional space, so presumably methods which can take into account this model, like some subspace methods should.",
                    "label": 0
                },
                {
                    "sent": "Should perform well here.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Maybe that it's about the datasets.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So maybe one of the most important tables, the performance.",
                    "label": 0
                },
                {
                    "sent": "For individual datasets.",
                    "label": 0
                },
                {
                    "sent": "For the optimal classifier, at least for the artificially generated data.",
                    "label": 0
                },
                {
                    "sent": "And also for some real problems we know the state of the art.",
                    "label": 0
                },
                {
                    "sent": "So also this this is the optimal model in these cases.",
                    "label": 0
                },
                {
                    "sent": "So for these two data set it is simple quadratic classifier.",
                    "label": 0
                },
                {
                    "sent": "Here it is a quadratic classifier but only with the diagonal diagonal elements.",
                    "label": 0
                },
                {
                    "sent": "And here it's a linear linear linear rule, is the optimal one.",
                    "label": 0
                },
                {
                    "sent": "So this is the optimal.",
                    "label": 0
                },
                {
                    "sent": "The performance, measured in terms of area over the precision recall curve and here you can see performance of the best submitted method.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You can see that basically for these two datasets.",
                    "label": 0
                },
                {
                    "sent": "The winner is a method which use some nonlinear decision function.",
                    "label": 0
                },
                {
                    "sent": "Most of the submissions are some variants of SVM, so they use linear classification rules, but it was enough basically to use some combination of simple carbs to get.",
                    "label": 0
                },
                {
                    "sent": "The best result, but still you can see that it is far from the from the optimum.",
                    "label": 0
                },
                {
                    "sent": "For these two datasets.",
                    "label": 0
                },
                {
                    "sent": "The submitted results are very close to the optimum becausw.",
                    "label": 0
                },
                {
                    "sent": "Basically, the model fits well.",
                    "label": 0
                },
                {
                    "sent": "In fact, the Naive Bayes rule assumes exactly the same model as we used for generating the data, so no big surprise that this method one.",
                    "label": 0
                },
                {
                    "sent": "For these two datasets, the optimal model is linear, so again, no surprise SVM's.",
                    "label": 0
                },
                {
                    "sent": "Vanna this, for these datasets, so you can see that we generated a lot of data, so the obtained performance is close to the optimal one.",
                    "label": 0
                },
                {
                    "sent": "Well, we can afford the practical problems.",
                    "label": 0
                },
                {
                    "sent": "Of course we don't have ground through model.",
                    "label": 0
                },
                {
                    "sent": "We don't know what's possible to achieve, but The thing is that.",
                    "label": 0
                },
                {
                    "sent": "We hope that.",
                    "label": 0
                },
                {
                    "sent": "People value some domain knowledge which didn't happen.",
                    "label": 0
                },
                {
                    "sent": "Basically, everyone used the basic data representation which we provided.",
                    "label": 0
                },
                {
                    "sent": "The result is that.",
                    "label": 0
                },
                {
                    "sent": "The performance achieved is much lower than what is the state of the art.",
                    "label": 0
                },
                {
                    "sent": "So for instance, for DNA zone is the expert in this field, so this is the state of the art, so it's device better than voted this basic.",
                    "label": 0
                },
                {
                    "sent": "Representation without using some domain knowledge can achieve.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "This is about performance.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have some preliminary results.",
                    "label": 0
                },
                {
                    "sent": "Results of the wildtrak develop practices.",
                    "label": 0
                },
                {
                    "sent": "The track with the highest number of submissions.",
                    "label": 0
                },
                {
                    "sent": "This is the score which is basically average over the rankings for four different for different scoring measures.",
                    "label": 0
                },
                {
                    "sent": "So you can see.",
                    "label": 0
                },
                {
                    "sent": "That the 1st four methods have very similar score, but there is a big gap between the 4th and the 5th place.",
                    "label": 0
                },
                {
                    "sent": "Zoran said that we managed to evaluate it for already for eight best ranking methods, we would like to have it for 10, top 10.",
                    "label": 0
                },
                {
                    "sent": "About, I think that there is a low chance that.",
                    "label": 0
                },
                {
                    "sent": "After having these results done.",
                    "label": 0
                },
                {
                    "sent": "It can somehow change the ordering, at least for the best ranking methods, because you can see the gap is quite significant here.",
                    "label": 0
                },
                {
                    "sent": "So what are the winners or not Venus, but best performing methods?",
                    "label": 0
                },
                {
                    "sent": "So SGD algorithm?",
                    "label": 0
                },
                {
                    "sent": "Newton method.",
                    "label": 0
                },
                {
                    "sent": "As the end, which will be presented today.",
                    "label": 0
                },
                {
                    "sent": "Another optimizer for SVM's Lauren, which is basically also SVM method.",
                    "label": 0
                },
                {
                    "sent": "Elite, cleaner and interior point SVM methods.",
                    "label": 0
                },
                {
                    "sent": "So we are happy that most of these methods will be presented today, so we will learn what Verdi tricks to achieve these good results.",
                    "label": 0
                },
                {
                    "sent": "Discord, OK, it was described, so we had several different scores for each score we had the ranking.",
                    "label": 0
                },
                {
                    "sent": "And then we took average ranking and this is the average ranking.",
                    "label": 0
                },
                {
                    "sent": "Of course there is a question how to combine different.",
                    "label": 0
                },
                {
                    "sent": "Object feels well, yeah.",
                    "label": 0
                },
                {
                    "sent": "It's the result.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So examples of some figures.",
                    "label": 0
                },
                {
                    "sent": "So this is the result on the 1st artificially generated data set where the ground through model is quadratic classifier.",
                    "label": 0
                },
                {
                    "sent": "So the best performing method here is this averaged SVM.",
                    "label": 0
                },
                {
                    "sent": "Is this blue curve which basically starts here and goes here.",
                    "label": 0
                },
                {
                    "sent": "Another thing which we can see that the most method which used VM's.",
                    "label": 0
                },
                {
                    "sent": "Have almost the same performance, but also the curves are very similar, so there are many methods which are discussed are overlapping so they behave quite similar.",
                    "label": 0
                },
                {
                    "sent": "But still you can see that there is a big gap between the performance, which which was achieved and the optimal one which is in this case.",
                    "label": 0
                },
                {
                    "sent": "0.001",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, this curve shows performance as a function of data set size.",
                    "label": 0
                },
                {
                    "sent": "So basically all the methods benefit from using more and more data.",
                    "label": 0
                },
                {
                    "sent": "Of course, the method using the best model is blue one.",
                    "label": 0
                },
                {
                    "sent": "Gains finally the best result, but here we can also see that.",
                    "label": 0
                },
                {
                    "sent": "Some tradeoff between the complexity of the model and the optimization becausw for this method.",
                    "label": 0
                },
                {
                    "sent": "This method was able to train only from.",
                    "label": 0
                },
                {
                    "sent": "100 thousands of examples and it is clear that maybe if we would be able to train from more examples, we can still improve the results so clearly for large scale learning the optimization vectors.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another artificially generated data set.",
                    "label": 0
                },
                {
                    "sent": "In this case, it was also the Gaussian distribution with full covariance matrix, but in this case the classification error was quite high, so you can see that all these linear SVM's perform equally bad.",
                    "label": 0
                },
                {
                    "sent": "And that it's basically.",
                    "label": 0
                },
                {
                    "sent": "Sufficient to have some slightly more difficult model to get much better results.",
                    "label": 0
                },
                {
                    "sent": "But still not achieving the optimal, which was like 0.3.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, again, for the same data set.",
                    "label": 0
                },
                {
                    "sent": "If you have that model then you cannot benefit even from millions of data.",
                    "label": 0
                },
                {
                    "sent": "Not big surprise.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This is another artificially generated data set.",
                    "label": 0
                },
                {
                    "sent": "In this case, the model which the method which uses basically the same model as the one used for generating the data.",
                    "label": 0
                },
                {
                    "sent": "Gets almost optimal solution, but you can also see here that if we want to learn with some budget on the time, then we have to trade off between the complexity of the model and.",
                    "label": 0
                },
                {
                    "sent": "The optimization accuracy because you can see that if we have enough time then we can reach very nice performance.",
                    "label": 0
                },
                {
                    "sent": "But if there is some limit on the time, then maybe it's useful to use some simple model like these linear SVM's which are able to find some solution in quite short time so.",
                    "label": 0
                },
                {
                    "sent": "So on.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Servation yeah, basically.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Think maybe I can.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speed up to.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Optical problems, so as I said, we provided some basic data representation.",
                    "label": 0
                },
                {
                    "sent": "We hope that people will try to somehow understand the problems and use some knowledge domain, which unfortunately didn't happen so.",
                    "label": 0
                },
                {
                    "sent": "You can see that using this very simple features, you basically gain nothing.",
                    "label": 0
                },
                {
                    "sent": "In this case, the state of the art result is something like 0.4.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Maybe there is still big room for improvements.",
                    "label": 0
                },
                {
                    "sent": "If there will be some follow up.",
                    "label": 0
                },
                {
                    "sent": "To use the tools.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "We used A plus or.",
                    "label": 0
                },
                {
                    "sent": "Or single character even.",
                    "label": 0
                },
                {
                    "sent": "Peoples being yeah but we provide it.",
                    "label": 0
                },
                {
                    "sent": "Also the raw data.",
                    "label": 0
                },
                {
                    "sent": "So it was possible that they use some weighted degree kernel which is the best in this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Phone.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for the web spam we used as features back of words so you can see that if you have good feature representation than linear SVM methods are quite good, so achieving nearly.",
                    "label": 0
                },
                {
                    "sent": "The best possible performance.",
                    "label": 0
                },
                {
                    "sent": "So here it is basically only competition between optimization algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, yeah, it's it's seen that it's really needed to be able to train from almost all the data to get.",
                    "label": 0
                },
                {
                    "sent": "To get good performance.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah yeah, for face detection it's the same.",
                    "label": 0
                },
                {
                    "sent": "The features that are just pixels.",
                    "label": 0
                },
                {
                    "sent": "Which is far from the optimum.",
                    "label": 0
                },
                {
                    "sent": "The methods which use.",
                    "label": 0
                },
                {
                    "sent": "Some filters, like other boost filters and so on, get by order of magnitude.",
                    "label": 0
                },
                {
                    "sent": "Better performance here.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, OCR.",
                    "label": 0
                },
                {
                    "sent": "Well, the nice thing is that basically.",
                    "label": 0
                },
                {
                    "sent": "All these methods here use the same linear classifier.",
                    "label": 0
                },
                {
                    "sent": "The only difference is the C constant.",
                    "label": 0
                },
                {
                    "sent": "So you can see that tuning the model really matters, because if you select the C incorrectly then you can get quite different results.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the graph for for the same methods.",
                    "label": 0
                },
                {
                    "sent": "Which basically shows that even if you select wrong C, then if you are using more and more data than you can in some sense compensate for this but selected C. Which is interesting.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so we have also some preliminary results for linear SVM.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the Revolution is still pending.",
                    "label": 0
                },
                {
                    "sent": "However, if you look at the difference between the best scoring method and the 2nd or the 3rd, there is quite a big gap, so we don't expect big changes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe Zoran wants to give some conclusions and announce the winners.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so just just to comment on this with like the SVM trick we had some problems that people submitted objective values which are not necessarily the right ones.",
                    "label": 0
                },
                {
                    "sent": "Are computed on only subsets of data so that we have there still weight room too lots to do to really get this to find into a final ranking.",
                    "label": 0
                },
                {
                    "sent": "But I mean.",
                    "label": 0
                },
                {
                    "sent": "It's definitely one of the reasons, definitely that we didn't ask for the W of the SVM or but just just ask people to submit the objective value in this clear that things can happen there.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So like some conclusions.",
                    "label": 0
                },
                {
                    "sent": "OK, So what became really clear is that like the method that is best, whereas most efficient.",
                    "label": 0
                },
                {
                    "sent": "This is the method which has the right tradeoff between like having a complex complex model like in terms of lots of parameters and and could find lots of training time and.",
                    "label": 1
                },
                {
                    "sent": "Being like accurate and in the end.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then there it's clear that.",
                    "label": 1
                },
                {
                    "sent": "You can get that a low model error is.",
                    "label": 0
                },
                {
                    "sent": "Is the crucial thing, so it's not not the optimization accuracy that really matters.",
                    "label": 0
                },
                {
                    "sent": "So what we recognize that lots of that almost all of these VM servers stopped very, very early, so.",
                    "label": 1
                },
                {
                    "sent": "Having like a big difference in accuracy, so the model to model is much more crucial than actually the optimization method behind it.",
                    "label": 0
                },
                {
                    "sent": "We've also also seen that basically all these linear SVM solvers, also they're using very different optimization methods, performed more or less the same.",
                    "label": 0
                },
                {
                    "sent": "So there maybe maybe this interior point methods are still computationally.",
                    "label": 0
                },
                {
                    "sent": "Much more demanding but.",
                    "label": 0
                },
                {
                    "sent": "This implementation here from Christian would send was performing quite well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "OK, so then.",
                    "label": 0
                },
                {
                    "sent": "Makes makes a lot of sense.",
                    "label": 0
                },
                {
                    "sent": "If you have the right model to really use all of the data that you did you.",
                    "label": 0
                },
                {
                    "sent": "You can use.",
                    "label": 0
                },
                {
                    "sent": "Then you may still improve.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And the one the one the one thing we've learned is that basically no one really tried to modify the data representation at all.",
                    "label": 0
                },
                {
                    "sent": "So basically everyone just used the data representation we provided, so we had like raw datasets.",
                    "label": 0
                },
                {
                    "sent": "We provide some conversion into assume light format.",
                    "label": 1
                },
                {
                    "sent": "And which was just meant as a suggestion suggestion.",
                    "label": 0
                },
                {
                    "sent": "Just in time.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And there's like lots of there would have been lots of room for improvement, like by just creating quadratic features or squaring features and adding them to the space.",
                    "label": 0
                },
                {
                    "sent": "And it's not really big.",
                    "label": 0
                },
                {
                    "sent": "Big things, one lot of work to do so, but by this one could.",
                    "label": 0
                },
                {
                    "sent": "But much easier, easier have one of the challenge.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so we based on what we have on the relation that we have we.",
                    "label": 0
                },
                {
                    "sent": "We can declare some winner Venus, which are definitely in a stable set.",
                    "label": 0
                },
                {
                    "sent": "However, it's not.",
                    "label": 0
                },
                {
                    "sent": "That's not the case that we can declare like single winners.",
                    "label": 0
                },
                {
                    "sent": "It's like a group of business.",
                    "label": 0
                },
                {
                    "sent": "Because these methods are really performing more or less equally well.",
                    "label": 0
                },
                {
                    "sent": "So one on the SVM track and on the right track of these.",
                    "label": 0
                },
                {
                    "sent": "This basically is this free linear SVM solvers.",
                    "label": 0
                },
                {
                    "sent": "Come on twin.",
                    "label": 0
                },
                {
                    "sent": "On TV and said here.",
                    "label": 0
                },
                {
                    "sent": "Then for the for the SVM track.",
                    "label": 0
                },
                {
                    "sent": "So far it's Linnea is best.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And I'm not sure whether it's OK.",
                    "label": 0
                },
                {
                    "sent": "I cannot even say the name with.",
                    "label": 0
                },
                {
                    "sent": "It's actually he's the only author in this.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "We decided to also have two additional awards in there for the for the best additional students in this taking part in this change.",
                    "label": 0
                },
                {
                    "sent": "So into your point SVM 'cause it took part in all of these datasets and was actually showing how good you can still be with just a just a normal interior point method.",
                    "label": 1
                },
                {
                    "sent": "And the triple jump.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So what the future?",
                    "label": 0
                },
                {
                    "sent": "So I mean like in this.",
                    "label": 0
                },
                {
                    "sent": "In this workshop we will at the end discuss all the very very many problems here we are seeing.",
                    "label": 0
                },
                {
                    "sent": "And like ask for feedback like in the last session.",
                    "label": 0
                },
                {
                    "sent": "So let's postpone all this.",
                    "label": 0
                },
                {
                    "sent": "All this until then.",
                    "label": 0
                },
                {
                    "sent": "For now we are planning like in the future to have like an agenda.",
                    "label": 0
                },
                {
                    "sent": "Our special check on.",
                    "label": 0
                },
                {
                    "sent": "On large scale methods.",
                    "label": 0
                },
                {
                    "sent": "Yeah, which is.",
                    "label": 0
                },
                {
                    "sent": "It's not clear that it will be accepted, but it's not so unlikely, I hope.",
                    "label": 0
                },
                {
                    "sent": "Which will have the submission deadline in October.",
                    "label": 0
                },
                {
                    "sent": "And then actually we will open this up to other participants, not only to participants of the workshop, but also others.",
                    "label": 0
                },
                {
                    "sent": "However, we will then require them to use these three figures like these.",
                    "label": 0
                },
                {
                    "sent": "These measures to evaluate their methods, otherwise it won't be really fair.",
                    "label": 0
                },
                {
                    "sent": "And then the question is whether we should do another challenge and if someone is willing to step up and have good ideas about immigration criteria that like.",
                    "label": 0
                },
                {
                    "sent": "Maybe better.",
                    "label": 0
                },
                {
                    "sent": "OK, so so much for the overview.",
                    "label": 0
                }
            ]
        }
    }
}