{
    "id": "kjbc5ltcod2pivjd3ncfb6wp3jykgga7",
    "title": "Semi-automatic rule construction for semantic linking of relation arguments",
    "info": {
        "author": [
            "Janez Starc, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Oct. 30, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2013_starc_relation_arguments/",
    "segmentation": [
        [
            "So this will present together with Junior."
        ],
        [
            "And so the main goal of this work is to provide links from text to knowledge base which would express the meaning of the text.",
            "So this is done by constructing pattern rules.",
            "So on on one side we have lexical patterns which are applied to text.",
            "So for instance we have lexical pattern which expresses that how many.",
            "Trophies did a person, one in in some location and then in the on the other hand we have logical patterns which are which consist of terms from the knowledge base we selected.",
            "So for instance we selected a predicate number of trophies and these are the arguments of the logical patterns.",
            "So at the end we would like to extract relations so.",
            "But in this work we will focus more on extracting a particular argument of free relation an in this in this case.",
            "We need some nesting, so some lexical pattern is nested inside the other lexical pattern in the same for the logical pattern.",
            "Some logical patterns is nested inside the other.",
            "Logical pattern functions are really useful.",
            "So for instance we have a juice function which has one argument and this is some kind of fruit.",
            "So if we say just function and orange fruit, we get the concept of oranges."
        ],
        [
            "So now will show an example how roles of people that have in organizations can be extracted from text.",
            "So for instance, we want to extract that that the role of Ryan Blake in the clap is Chief researcher and former president.",
            "So first we would like to extract water.",
            "What chief researcher and former president is.",
            "So we would like to link those two.",
            "Phrases to a knowledge base.",
            "So."
        ],
        [
            "For instance, for Chief researcher, we have a chief and then some role and we link this to function in a selected knowledge base which is chief function row.",
            "So for instance we have Chief researcher, we have Chief Executive Officer and some other kinds of Chief Rose Ann it's similar."
        ],
        [
            "For also for for former president, we could have former president.",
            "We have former vice president, etc.",
            "And we use this former function to express the the somebodies was had some formal function in.",
            "Organization, so in this new these two new concepts are also rose, which can be used in other patterns.",
            "And here you can nest also former and chief.",
            "President, this would also reflect.",
            "Yeah, former first former function, then chief and then president whatever."
        ],
        [
            "So now we'd like to combine these two with so these two work in this case or combined with word and and we can provide."
        ],
        [
            "I'd link between this pattern roll and roll with the function in the knowledge base, which is basically an intersection of rose.",
            "To obtain this new role, which is which is intersection of being chief researcher and former president.",
            "Turn on the light."
        ],
        [
            "Step we would like to extract the relation itself, so we'd like to connect the role with the person and organization so."
        ],
        [
            "This could be done with this Russo person, role of organization is the lexical pattern and this is the logical pattern with the predicate rolling organization to obtain the whole meaning of this phrase."
        ],
        [
            "On and so I explain that how this practice work.",
            "So first we have a corpus of documents.",
            "We apply initial relation extraction method to obtain initial relations and then we will just focus on one argument.",
            "In the previous example, this is the role of a person, and then we would.",
            "Generalize this this rose to obtain lexical patterns, which would then show it to the user who will make pattern rules.",
            "That will be then applied, and when there will be applied we will get a new set of unlink arguments and final.",
            "Extra links arguments.",
            "So first initial."
        ],
        [
            "Relation extraction methods.",
            "So, for instance, we could apply a simple pattern that I showed before to get this textural arguments and also any other relation extraction extraction method could be used.",
            "And so in the next next step."
        ],
        [
            "We would like to generalize these textual fridges to obtain lexical patterns."
        ],
        [
            "So in in the step of generalization we can.",
            "Is named entity recognizer to link as an instance of a person to its type person?",
            "Or we could use in this case we also used entity rules, so these are rules for rose, so we.",
            "Looked in the freebase for rose that people can have in organization so for instance engineer has a concept with some ID and so and this is a job title so we can know that this is a role so and then we replace the actual textual phrases with their type.",
            "So in this case Rose or maybe also person organization or or something else.",
            "Should analyze.",
            "Sorry, how do you know how much to generalize?",
            "Which is probably for several hours?",
            "Yeah, so this generalization is done so.",
            "It's decided on what problem we have, so it's not automatically done, it's."
        ],
        [
            "So an index step.",
            "This lexical patterns are basically."
        ],
        [
            "We count how many times they occur and we get a table of this patterns and we then show this pattern should be stable to the user so he can select the most best pattern which will then then be translated.",
            "So in the top row we have all the all the.",
            "All the rows that have already been translated for, so for this we already have already.",
            "We have the links and for this.",
            "Then the next patterns the links has to be made."
        ],
        [
            "Then the then is the."
        ],
        [
            "Turn rule construction step so the user selects a pattern and creates a logical pattern for it, and then in the."
        ],
        [
            "Next step, this new rules and also the old one which are stored in the Rule store.",
            "Then apply it to.",
            "To the earth."
        ],
        [
            "Moments which have not been linked yet.",
            "So for instance you have a new rule, so formal role is mapped to former function role and with this rule we can extract the concept of former president and we said that this is a new entity rule and we then store it to the.",
            "Do the Entity Role Store and."
        ],
        [
            "Then with this we can understand that OK, we now we now know what is former president, and we know what is with the other rule.",
            "For Chief Researcher, we know what Chief Researcher is an by this week and.",
            "Generalize these two phrases and we obtain a new a new pattern that has not have not been already seen.",
            "Or just add it to the OR maybe this just adds up to the frequency of the of this pattern.",
            "So in this this new pattern is then put into the.",
            "To the arguments which have not been linked yet."
        ],
        [
            "So and then in the next iteration, for instance, if we select it in the previous iteration, like the lexical pattern roll, then what?"
        ],
        [
            "Happens is that sometimes patterns merge automatically.",
            "So for instance this rule and Darrell will become just roll and roll, so we don't have to do so much work that we do.",
            "We can do less work and also the frequency of old patterns always stays the same or gets bigger because of this.",
            "This happening?"
        ],
        [
            "So for the evaluation, so we use the corpus of million and 300,000 general news articles then apply this initial relation extraction to obtain.",
            "Some initial arguments the rows and then the user created 31 pattern rules with this pattern rules about 14,000 rows were completely linked to the to the knowledge base and then we left out 300 of those initial arguments for testing and testing showed the the 100% precision and 84%.",
            "Recall."
        ],
        [
            "And to conclude, so this work is about suggesting suggesting frequent lexical pattern for linking correlation arguments.",
            "So the goal is to construct a small number of rules that cover a large portion of text, so we don't need so much manual work, and for the future work we would like to make this first step of selecting.",
            "Which.",
            "Lexical patterns are most useful.",
            "Would like to do this automatically and then gradually add complexity so we would not just extract the rows of organizations, but would like to extract maybe first paragraph of Wikipedia articles which are not so complex than maybe general news.",
            "Extend the annex.",
            "Extends to not being before the extent to which Shakespeare.",
            "And that's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this will present together with Junior.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the main goal of this work is to provide links from text to knowledge base which would express the meaning of the text.",
                    "label": 0
                },
                {
                    "sent": "So this is done by constructing pattern rules.",
                    "label": 1
                },
                {
                    "sent": "So on on one side we have lexical patterns which are applied to text.",
                    "label": 0
                },
                {
                    "sent": "So for instance we have lexical pattern which expresses that how many.",
                    "label": 0
                },
                {
                    "sent": "Trophies did a person, one in in some location and then in the on the other hand we have logical patterns which are which consist of terms from the knowledge base we selected.",
                    "label": 0
                },
                {
                    "sent": "So for instance we selected a predicate number of trophies and these are the arguments of the logical patterns.",
                    "label": 0
                },
                {
                    "sent": "So at the end we would like to extract relations so.",
                    "label": 0
                },
                {
                    "sent": "But in this work we will focus more on extracting a particular argument of free relation an in this in this case.",
                    "label": 0
                },
                {
                    "sent": "We need some nesting, so some lexical pattern is nested inside the other lexical pattern in the same for the logical pattern.",
                    "label": 1
                },
                {
                    "sent": "Some logical patterns is nested inside the other.",
                    "label": 0
                },
                {
                    "sent": "Logical pattern functions are really useful.",
                    "label": 0
                },
                {
                    "sent": "So for instance we have a juice function which has one argument and this is some kind of fruit.",
                    "label": 0
                },
                {
                    "sent": "So if we say just function and orange fruit, we get the concept of oranges.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now will show an example how roles of people that have in organizations can be extracted from text.",
                    "label": 0
                },
                {
                    "sent": "So for instance, we want to extract that that the role of Ryan Blake in the clap is Chief researcher and former president.",
                    "label": 0
                },
                {
                    "sent": "So first we would like to extract water.",
                    "label": 0
                },
                {
                    "sent": "What chief researcher and former president is.",
                    "label": 1
                },
                {
                    "sent": "So we would like to link those two.",
                    "label": 0
                },
                {
                    "sent": "Phrases to a knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For instance, for Chief researcher, we have a chief and then some role and we link this to function in a selected knowledge base which is chief function row.",
                    "label": 0
                },
                {
                    "sent": "So for instance we have Chief researcher, we have Chief Executive Officer and some other kinds of Chief Rose Ann it's similar.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For also for for former president, we could have former president.",
                    "label": 1
                },
                {
                    "sent": "We have former vice president, etc.",
                    "label": 0
                },
                {
                    "sent": "And we use this former function to express the the somebodies was had some formal function in.",
                    "label": 0
                },
                {
                    "sent": "Organization, so in this new these two new concepts are also rose, which can be used in other patterns.",
                    "label": 0
                },
                {
                    "sent": "And here you can nest also former and chief.",
                    "label": 0
                },
                {
                    "sent": "President, this would also reflect.",
                    "label": 0
                },
                {
                    "sent": "Yeah, former first former function, then chief and then president whatever.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we'd like to combine these two with so these two work in this case or combined with word and and we can provide.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'd link between this pattern roll and roll with the function in the knowledge base, which is basically an intersection of rose.",
                    "label": 0
                },
                {
                    "sent": "To obtain this new role, which is which is intersection of being chief researcher and former president.",
                    "label": 1
                },
                {
                    "sent": "Turn on the light.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Step we would like to extract the relation itself, so we'd like to connect the role with the person and organization so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This could be done with this Russo person, role of organization is the lexical pattern and this is the logical pattern with the predicate rolling organization to obtain the whole meaning of this phrase.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On and so I explain that how this practice work.",
                    "label": 0
                },
                {
                    "sent": "So first we have a corpus of documents.",
                    "label": 0
                },
                {
                    "sent": "We apply initial relation extraction method to obtain initial relations and then we will just focus on one argument.",
                    "label": 1
                },
                {
                    "sent": "In the previous example, this is the role of a person, and then we would.",
                    "label": 1
                },
                {
                    "sent": "Generalize this this rose to obtain lexical patterns, which would then show it to the user who will make pattern rules.",
                    "label": 0
                },
                {
                    "sent": "That will be then applied, and when there will be applied we will get a new set of unlink arguments and final.",
                    "label": 0
                },
                {
                    "sent": "Extra links arguments.",
                    "label": 0
                },
                {
                    "sent": "So first initial.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relation extraction methods.",
                    "label": 0
                },
                {
                    "sent": "So, for instance, we could apply a simple pattern that I showed before to get this textural arguments and also any other relation extraction extraction method could be used.",
                    "label": 0
                },
                {
                    "sent": "And so in the next next step.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We would like to generalize these textual fridges to obtain lexical patterns.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in in the step of generalization we can.",
                    "label": 0
                },
                {
                    "sent": "Is named entity recognizer to link as an instance of a person to its type person?",
                    "label": 0
                },
                {
                    "sent": "Or we could use in this case we also used entity rules, so these are rules for rose, so we.",
                    "label": 0
                },
                {
                    "sent": "Looked in the freebase for rose that people can have in organization so for instance engineer has a concept with some ID and so and this is a job title so we can know that this is a role so and then we replace the actual textual phrases with their type.",
                    "label": 0
                },
                {
                    "sent": "So in this case Rose or maybe also person organization or or something else.",
                    "label": 0
                },
                {
                    "sent": "Should analyze.",
                    "label": 0
                },
                {
                    "sent": "Sorry, how do you know how much to generalize?",
                    "label": 0
                },
                {
                    "sent": "Which is probably for several hours?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this generalization is done so.",
                    "label": 0
                },
                {
                    "sent": "It's decided on what problem we have, so it's not automatically done, it's.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So an index step.",
                    "label": 0
                },
                {
                    "sent": "This lexical patterns are basically.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We count how many times they occur and we get a table of this patterns and we then show this pattern should be stable to the user so he can select the most best pattern which will then then be translated.",
                    "label": 0
                },
                {
                    "sent": "So in the top row we have all the all the.",
                    "label": 0
                },
                {
                    "sent": "All the rows that have already been translated for, so for this we already have already.",
                    "label": 0
                },
                {
                    "sent": "We have the links and for this.",
                    "label": 0
                },
                {
                    "sent": "Then the next patterns the links has to be made.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the then is the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turn rule construction step so the user selects a pattern and creates a logical pattern for it, and then in the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next step, this new rules and also the old one which are stored in the Rule store.",
                    "label": 0
                },
                {
                    "sent": "Then apply it to.",
                    "label": 0
                },
                {
                    "sent": "To the earth.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Moments which have not been linked yet.",
                    "label": 0
                },
                {
                    "sent": "So for instance you have a new rule, so formal role is mapped to former function role and with this rule we can extract the concept of former president and we said that this is a new entity rule and we then store it to the.",
                    "label": 1
                },
                {
                    "sent": "Do the Entity Role Store and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then with this we can understand that OK, we now we now know what is former president, and we know what is with the other rule.",
                    "label": 0
                },
                {
                    "sent": "For Chief Researcher, we know what Chief Researcher is an by this week and.",
                    "label": 1
                },
                {
                    "sent": "Generalize these two phrases and we obtain a new a new pattern that has not have not been already seen.",
                    "label": 0
                },
                {
                    "sent": "Or just add it to the OR maybe this just adds up to the frequency of the of this pattern.",
                    "label": 0
                },
                {
                    "sent": "So in this this new pattern is then put into the.",
                    "label": 0
                },
                {
                    "sent": "To the arguments which have not been linked yet.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and then in the next iteration, for instance, if we select it in the previous iteration, like the lexical pattern roll, then what?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happens is that sometimes patterns merge automatically.",
                    "label": 0
                },
                {
                    "sent": "So for instance this rule and Darrell will become just roll and roll, so we don't have to do so much work that we do.",
                    "label": 0
                },
                {
                    "sent": "We can do less work and also the frequency of old patterns always stays the same or gets bigger because of this.",
                    "label": 0
                },
                {
                    "sent": "This happening?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the evaluation, so we use the corpus of million and 300,000 general news articles then apply this initial relation extraction to obtain.",
                    "label": 0
                },
                {
                    "sent": "Some initial arguments the rows and then the user created 31 pattern rules with this pattern rules about 14,000 rows were completely linked to the to the knowledge base and then we left out 300 of those initial arguments for testing and testing showed the the 100% precision and 84%.",
                    "label": 1
                },
                {
                    "sent": "Recall.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to conclude, so this work is about suggesting suggesting frequent lexical pattern for linking correlation arguments.",
                    "label": 1
                },
                {
                    "sent": "So the goal is to construct a small number of rules that cover a large portion of text, so we don't need so much manual work, and for the future work we would like to make this first step of selecting.",
                    "label": 1
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Lexical patterns are most useful.",
                    "label": 0
                },
                {
                    "sent": "Would like to do this automatically and then gradually add complexity so we would not just extract the rows of organizations, but would like to extract maybe first paragraph of Wikipedia articles which are not so complex than maybe general news.",
                    "label": 0
                },
                {
                    "sent": "Extend the annex.",
                    "label": 0
                },
                {
                    "sent": "Extends to not being before the extent to which Shakespeare.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                }
            ]
        }
    }
}