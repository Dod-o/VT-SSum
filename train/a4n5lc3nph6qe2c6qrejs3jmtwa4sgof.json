{
    "id": "a4n5lc3nph6qe2c6qrejs3jmtwa4sgof",
    "title": "SpudTV Field Trials",
    "info": {
        "author": [
            "Sander Koelstra, Queen Mary, University of London"
        ],
        "published": "Oct. 19, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Information Retrieval->Multimedia Retrieval"
        ]
    },
    "url": "http://videolectures.net/petamediaworkshop2011_koelstra_trials/",
    "segmentation": [
        [
            "OK, so hello.",
            "My name is Sandra Kustron with Queen Mary, University of London, PhD student there.",
            "I'm going to tell you a bit about the spot iffy project, which is one of the projects."
        ],
        [
            "Impact the media.",
            "So I'll first give you a quick introduction and then tell you something about our work on estimating affective state and then a little bit about the development of a real time music video recommendation system that uses affects also."
        ],
        [
            "So first of all, who are who are in spot TV, so we have people from all the four core partners here.",
            "Actually was missing except for Delft and then we have two affiliated partners from Geneva.",
            "20"
        ],
        [
            "So the scenario here is that we want to build a system that basically estimates a user's effective state and then recommends music videos based on that.",
            "So there's two main parts to this.",
            "First, we have to develop an estimation technique which is easier said than done.",
            "And then we have to merge that with the content recommendation system.",
            "So tell you first a bit about our affect estimation system."
        ],
        [
            "So the first thing we need to do if we are going to discuss effect, is an actual model of effect.",
            "So we use the valence and arousal space defined by Russell.",
            "So we have two axis here.",
            "Arousal ranges from inactive to active, and fairless ranges from unpleasant pleasant.",
            "So in this 2 dimensional model which is somewhat simplified, but we can capture most emotions as an area on this map.",
            "So for instance, high arousal and high valence gives us elated's emotion."
        ],
        [
            "So the next thing we need to do is for me to create a data set of videos that we will actually use to elicit emotions.",
            "So how can we select a set of music videos that elicit strong emotions?",
            "So what we did is we went to last FM which is a website that tracks users listening habits and they can also apply tags to songs.",
            "So what we did is if you search for instance for sad then you get a whole bunch of sad songs.",
            "Dog attacked by people with the keyword said So what we do?"
        ],
        [
            "We take a large list of emotions.",
            "We find all that the songs that are most most tags for that an then, then we do some manual filtering to see if we can actually find the music video and in some cases you you so there is.",
            "For instance, a band called Fear.",
            "So it was also tagged fear.",
            "So in that case it doesn't really apply.",
            "So we want to tag to really describe the music and not the band name.",
            "So we have to do some manual filtering which gave us 120 videos.",
            "In the end and then we had people doing an online test where they watched the video and then they rate their valence N arousal emotions."
        ],
        [
            "So this gives us so.",
            "Then we complete all these videos on the on the balance and arousal scale.",
            "So here it is and then we selected the 40 most outdoor ones.",
            "So which elicited the strongest emotions in our online test?",
            "So you can see for instance here, so low arousal and high valence, so positive but inactive song is that Louis Armstrong.",
            "What a wonderful world which is a slow song but also quite.",
            "Stiff so we used."
        ],
        [
            "40 videos in our experiments.",
            "So we have 30 two people in this chair and we recorded their e.g of their which 32 electrodes we recorded EOG, which is eye movement EMG.",
            "So the small so you use electrodes to measure muscle activity.",
            "We use the smile muscle and also the neck muscle which can indicate tension.",
            "We have respiration.",
            "We have skin temp temperature an.",
            "So.",
            "Sweating soda sedation.",
            "I use all those features to predict."
        ],
        [
            "The affect.",
            "So this is the data set that we gathered.",
            "So just to note, this data set is actually the largest datasets.",
            "I mean in many fields, 32 subjects sounds like something you do in one day, but in this case for EG.",
            "Because we have the setup time, etc.",
            "It's quite a large number."
        ],
        [
            "So some analysis on that.",
            "So if we see what the correlations are, felons and arousal ratings with actual EG measurements so we can see that there are several electrodes.",
            "So for instance this area here.",
            "In high frequency has a very significant correlation to valence, which is also something that has been.",
            "Proposition before in the literature.",
            "And."
        ],
        [
            "Then we also did a single trial classification, so we make.",
            "The threshold the ratings that people give into two classes.",
            "So we say low valence or high valence and then we try to predict for every for every single video that somebody sees whether he felt low valence or hyphens.",
            "So this gives us results that are significantly higher than random level.",
            "So this is for all the different modalities and if we fuse them we get to like 63 to 66%.",
            "Which is a lot higher than random, but of course still it's far from perfect."
        ],
        [
            "So so much for our effect estimation system.",
            "So this data set is also available online and it's become quite popular.",
            "This one outputs."
        ],
        [
            "So the next step there was to actually build to merge this with the recommendation system so that we actually could do effective recommendation.",
            "So the goal here was to take the."
        ],
        [
            "I'll show you here, so this is the system overview where we have the MCA multimedia content analysis on the videos themselves, the EEG signals, the physiological sensors, we estimate the effect based on each of those of those.",
            "Then we fuse it.",
            "Then we feed that to the recommendation engine, which then select which is based on last FM taste profiles and that selects video and that is shown to the user.",
            "And this is like a loop that runs.",
            "All the time."
        ],
        [
            "So how does the recommendation system actually work?",
            "So what we do is the participant has a last FM profile and we've achieved the most recent songs he played, and then we cluster these songs and then we use a hidden Markov model to navigate this.",
            "So we will play similar songs until the person doesn't like it anymore, and then we moved to different cluster.",
            "That's more or less."
        ],
        [
            "Very shortly, how it works.",
            "So now the challenge is here.",
            "How do we add effect to this?",
            "What does it mean if a user is sad from watching a song?",
            "Should we play another sad song?",
            "Should we play a happy song to make them cheerful?",
            "This is a very hard problem and.",
            "So."
        ],
        [
            "What we chose to do in the end is to recommend songs that match the current affective state, which is quite intuitive, but.",
            "Maybe not the optimal way.",
            "In any case, So what we do is we use the affective states, which was annotated by by by online subject.",
            "So we use that as an extra parameter in our clustering, so the clusters will also be effective and then we can say if a person doesn't feel anymore the same as the cluster is in, we jump to a cluster that that matches their state.",
            "So that's how it works."
        ],
        [
            "So this was quite difficult to do because all these.",
            "All these software components that we built were all built in different.",
            "Programming languages.",
            "That forms etc.",
            "And the other problem is that we want to have a large data set, but we need every video in their annotated by at least 10 people to have some sort of average, so that's difficult.",
            "And then the other thing that's hard is that each computer, each analysis algorithm needs basically its own computer to be able to work."
        ],
        [
            "So what we did we built this quite complicated system that you can see here.",
            "So each component runs on the different PC's and then we have 300 videos there that are all manually annotated an.",
            "We use this Python as a glue language to have it or communicate over network, so you can actually see this."
        ],
        [
            "No, which is shown here at the pet media stand where there are several laptops doing this work.",
            "So this is the final.",
            "The GUI of the software where you can see the.",
            "The affect estimates coming in and then the recommended songs are being displayed to the user.",
            "So."
        ],
        [
            "Oh yeah, that's what I wanted to say."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so hello.",
                    "label": 0
                },
                {
                    "sent": "My name is Sandra Kustron with Queen Mary, University of London, PhD student there.",
                    "label": 1
                },
                {
                    "sent": "I'm going to tell you a bit about the spot iffy project, which is one of the projects.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Impact the media.",
                    "label": 0
                },
                {
                    "sent": "So I'll first give you a quick introduction and then tell you something about our work on estimating affective state and then a little bit about the development of a real time music video recommendation system that uses affects also.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, who are who are in spot TV, so we have people from all the four core partners here.",
                    "label": 0
                },
                {
                    "sent": "Actually was missing except for Delft and then we have two affiliated partners from Geneva.",
                    "label": 0
                },
                {
                    "sent": "20",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the scenario here is that we want to build a system that basically estimates a user's effective state and then recommends music videos based on that.",
                    "label": 1
                },
                {
                    "sent": "So there's two main parts to this.",
                    "label": 0
                },
                {
                    "sent": "First, we have to develop an estimation technique which is easier said than done.",
                    "label": 0
                },
                {
                    "sent": "And then we have to merge that with the content recommendation system.",
                    "label": 1
                },
                {
                    "sent": "So tell you first a bit about our affect estimation system.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing we need to do if we are going to discuss effect, is an actual model of effect.",
                    "label": 0
                },
                {
                    "sent": "So we use the valence and arousal space defined by Russell.",
                    "label": 0
                },
                {
                    "sent": "So we have two axis here.",
                    "label": 0
                },
                {
                    "sent": "Arousal ranges from inactive to active, and fairless ranges from unpleasant pleasant.",
                    "label": 0
                },
                {
                    "sent": "So in this 2 dimensional model which is somewhat simplified, but we can capture most emotions as an area on this map.",
                    "label": 0
                },
                {
                    "sent": "So for instance, high arousal and high valence gives us elated's emotion.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the next thing we need to do is for me to create a data set of videos that we will actually use to elicit emotions.",
                    "label": 0
                },
                {
                    "sent": "So how can we select a set of music videos that elicit strong emotions?",
                    "label": 1
                },
                {
                    "sent": "So what we did is we went to last FM which is a website that tracks users listening habits and they can also apply tags to songs.",
                    "label": 0
                },
                {
                    "sent": "So what we did is if you search for instance for sad then you get a whole bunch of sad songs.",
                    "label": 0
                },
                {
                    "sent": "Dog attacked by people with the keyword said So what we do?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We take a large list of emotions.",
                    "label": 0
                },
                {
                    "sent": "We find all that the songs that are most most tags for that an then, then we do some manual filtering to see if we can actually find the music video and in some cases you you so there is.",
                    "label": 0
                },
                {
                    "sent": "For instance, a band called Fear.",
                    "label": 0
                },
                {
                    "sent": "So it was also tagged fear.",
                    "label": 0
                },
                {
                    "sent": "So in that case it doesn't really apply.",
                    "label": 0
                },
                {
                    "sent": "So we want to tag to really describe the music and not the band name.",
                    "label": 0
                },
                {
                    "sent": "So we have to do some manual filtering which gave us 120 videos.",
                    "label": 0
                },
                {
                    "sent": "In the end and then we had people doing an online test where they watched the video and then they rate their valence N arousal emotions.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this gives us so.",
                    "label": 0
                },
                {
                    "sent": "Then we complete all these videos on the on the balance and arousal scale.",
                    "label": 0
                },
                {
                    "sent": "So here it is and then we selected the 40 most outdoor ones.",
                    "label": 0
                },
                {
                    "sent": "So which elicited the strongest emotions in our online test?",
                    "label": 0
                },
                {
                    "sent": "So you can see for instance here, so low arousal and high valence, so positive but inactive song is that Louis Armstrong.",
                    "label": 0
                },
                {
                    "sent": "What a wonderful world which is a slow song but also quite.",
                    "label": 0
                },
                {
                    "sent": "Stiff so we used.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "40 videos in our experiments.",
                    "label": 0
                },
                {
                    "sent": "So we have 30 two people in this chair and we recorded their e.g of their which 32 electrodes we recorded EOG, which is eye movement EMG.",
                    "label": 0
                },
                {
                    "sent": "So the small so you use electrodes to measure muscle activity.",
                    "label": 0
                },
                {
                    "sent": "We use the smile muscle and also the neck muscle which can indicate tension.",
                    "label": 0
                },
                {
                    "sent": "We have respiration.",
                    "label": 0
                },
                {
                    "sent": "We have skin temp temperature an.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Sweating soda sedation.",
                    "label": 0
                },
                {
                    "sent": "I use all those features to predict.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The affect.",
                    "label": 0
                },
                {
                    "sent": "So this is the data set that we gathered.",
                    "label": 0
                },
                {
                    "sent": "So just to note, this data set is actually the largest datasets.",
                    "label": 0
                },
                {
                    "sent": "I mean in many fields, 32 subjects sounds like something you do in one day, but in this case for EG.",
                    "label": 0
                },
                {
                    "sent": "Because we have the setup time, etc.",
                    "label": 0
                },
                {
                    "sent": "It's quite a large number.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some analysis on that.",
                    "label": 0
                },
                {
                    "sent": "So if we see what the correlations are, felons and arousal ratings with actual EG measurements so we can see that there are several electrodes.",
                    "label": 0
                },
                {
                    "sent": "So for instance this area here.",
                    "label": 0
                },
                {
                    "sent": "In high frequency has a very significant correlation to valence, which is also something that has been.",
                    "label": 0
                },
                {
                    "sent": "Proposition before in the literature.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we also did a single trial classification, so we make.",
                    "label": 0
                },
                {
                    "sent": "The threshold the ratings that people give into two classes.",
                    "label": 0
                },
                {
                    "sent": "So we say low valence or high valence and then we try to predict for every for every single video that somebody sees whether he felt low valence or hyphens.",
                    "label": 0
                },
                {
                    "sent": "So this gives us results that are significantly higher than random level.",
                    "label": 0
                },
                {
                    "sent": "So this is for all the different modalities and if we fuse them we get to like 63 to 66%.",
                    "label": 0
                },
                {
                    "sent": "Which is a lot higher than random, but of course still it's far from perfect.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so much for our effect estimation system.",
                    "label": 0
                },
                {
                    "sent": "So this data set is also available online and it's become quite popular.",
                    "label": 1
                },
                {
                    "sent": "This one outputs.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the next step there was to actually build to merge this with the recommendation system so that we actually could do effective recommendation.",
                    "label": 0
                },
                {
                    "sent": "So the goal here was to take the.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll show you here, so this is the system overview where we have the MCA multimedia content analysis on the videos themselves, the EEG signals, the physiological sensors, we estimate the effect based on each of those of those.",
                    "label": 0
                },
                {
                    "sent": "Then we fuse it.",
                    "label": 0
                },
                {
                    "sent": "Then we feed that to the recommendation engine, which then select which is based on last FM taste profiles and that selects video and that is shown to the user.",
                    "label": 0
                },
                {
                    "sent": "And this is like a loop that runs.",
                    "label": 0
                },
                {
                    "sent": "All the time.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does the recommendation system actually work?",
                    "label": 0
                },
                {
                    "sent": "So what we do is the participant has a last FM profile and we've achieved the most recent songs he played, and then we cluster these songs and then we use a hidden Markov model to navigate this.",
                    "label": 1
                },
                {
                    "sent": "So we will play similar songs until the person doesn't like it anymore, and then we moved to different cluster.",
                    "label": 0
                },
                {
                    "sent": "That's more or less.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very shortly, how it works.",
                    "label": 0
                },
                {
                    "sent": "So now the challenge is here.",
                    "label": 0
                },
                {
                    "sent": "How do we add effect to this?",
                    "label": 0
                },
                {
                    "sent": "What does it mean if a user is sad from watching a song?",
                    "label": 0
                },
                {
                    "sent": "Should we play another sad song?",
                    "label": 1
                },
                {
                    "sent": "Should we play a happy song to make them cheerful?",
                    "label": 1
                },
                {
                    "sent": "This is a very hard problem and.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we chose to do in the end is to recommend songs that match the current affective state, which is quite intuitive, but.",
                    "label": 1
                },
                {
                    "sent": "Maybe not the optimal way.",
                    "label": 0
                },
                {
                    "sent": "In any case, So what we do is we use the affective states, which was annotated by by by online subject.",
                    "label": 0
                },
                {
                    "sent": "So we use that as an extra parameter in our clustering, so the clusters will also be effective and then we can say if a person doesn't feel anymore the same as the cluster is in, we jump to a cluster that that matches their state.",
                    "label": 0
                },
                {
                    "sent": "So that's how it works.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was quite difficult to do because all these.",
                    "label": 0
                },
                {
                    "sent": "All these software components that we built were all built in different.",
                    "label": 0
                },
                {
                    "sent": "Programming languages.",
                    "label": 0
                },
                {
                    "sent": "That forms etc.",
                    "label": 0
                },
                {
                    "sent": "And the other problem is that we want to have a large data set, but we need every video in their annotated by at least 10 people to have some sort of average, so that's difficult.",
                    "label": 0
                },
                {
                    "sent": "And then the other thing that's hard is that each computer, each analysis algorithm needs basically its own computer to be able to work.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we did we built this quite complicated system that you can see here.",
                    "label": 0
                },
                {
                    "sent": "So each component runs on the different PC's and then we have 300 videos there that are all manually annotated an.",
                    "label": 1
                },
                {
                    "sent": "We use this Python as a glue language to have it or communicate over network, so you can actually see this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, which is shown here at the pet media stand where there are several laptops doing this work.",
                    "label": 0
                },
                {
                    "sent": "So this is the final.",
                    "label": 0
                },
                {
                    "sent": "The GUI of the software where you can see the.",
                    "label": 1
                },
                {
                    "sent": "The affect estimates coming in and then the recommended songs are being displayed to the user.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh yeah, that's what I wanted to say.",
                    "label": 0
                }
            ]
        }
    }
}