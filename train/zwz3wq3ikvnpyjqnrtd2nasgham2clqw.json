{
    "id": "zwz3wq3ikvnpyjqnrtd2nasgham2clqw",
    "title": "Streaming Multi-label Classification",
    "info": {
        "author": [
            "Jesse Read, \u00c9cole Polytechnique"
        ],
        "published": "Nov. 11, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/wapa2011_read_classification/",
    "segmentation": [
        [
            "This talk is about where multi label classification meets data stream classification, and a framework for working in such a content."
        ],
        [
            "Term Multi label classification.",
            "This is where each data instances associated with a subset of class labels that supposed to the more traditional task of.",
            "Multi class classification where each data instance is associated with a single class label.",
            "So this is the implications that there may be dependencies between labels, because you can have multiple labels associated with a single example.",
            "Obviously certain labels are more likely to occur together then than others, so in this small example from a real data set small data set where pieces of music are labeled with emotions, the thickness of the lines represents the Co occurrences, so you can see that the emotions relaxing, calm, quiet, still an sad lonely.",
            "They often are associated together with the same piece of music, whereas for example, amazed, surprised and sad lonely.",
            "Those mutually exclusive within the particular data set.",
            "And we also have greater dimensionality because instead of three for a given data instance to make a prediction instead of selecting one of L classes were selecting one of two to the L label set combinations.",
            "And evaluation is also different.",
            "I'll talk about that later in the talk."
        ],
        [
            "Data stream classification.",
            "This is the context where data instances arrive continually and potentially infinitely.",
            "So that's.",
            "Usually because of this.",
            "Automatic process, like a robot or something which can make a prediction and then evaluate its prediction automatically afterwards or or a collaborative process.",
            "For example, where a lot of people are contributing to the labeling task.",
            "So this is the implications that, first of all we can't store everything, so obviously you can't store infinite data, so.",
            "Let's 1 one thing and you have to be ready to predict at any point because we might have a new data instance, we might have to make a prediction at any point.",
            "Thirdly, concept drift is you have to expect that its concentration is going to be an issue at some stage.",
            "And again, here evaluation is different from from traditional batch learning setting."
        ],
        [
            "So despite the fact their multi label classification is sort of only received a lot of interest in recent years, there are a wide number of applications to probably one reason that we've been focused on that multiclassed ask for so long is because of physical limitations, like say, a newspaper article might fit under the labels economy and international, but you wouldn't.",
            "The same article in both sections of a newspaper the exact same same medical, but of course there's as everything becomes more digitized.",
            "I mean obviously online you can find the same medical under separate headings, so I expect that we're going to find the multi label setting much more relevant.",
            "So.",
            "Text documents that could be so news articles as the example I gave, but I mean academic articles.",
            "This talk would be labeled multi label classification, an data stream classification.",
            "Emails as well so.",
            "And an even things like so medical texts classifications are medical.",
            "Description A textual description of other patient symptoms may correspond to may be associated with more than one diagnosis, so you might have the flu and heart disease at the same time.",
            "Vision obviously seen image concept can have multiple.",
            "An image can have multiple concepts or there could be multiple objects identified or recognized within.",
            "The source I gave the started with the small data set.",
            "An example of music.",
            "Bioinformatics is another area where multi label classification is important, and robotics obviously encompasses vision and audio as well, but any sort of sensor inputs.",
            "Can correspond to multiple states or multiple error errors for exam."
        ],
        [
            "And of course, that note that many of these application exist in a streaming context, so obviously things like email, email arrives continually every time, and you never expect to find more final email.",
            "So I mean basically potentially infinite.",
            "Ah, same with news articles.",
            "And of course concept drift can can occur as well.",
            "Obviously the news, the focus of the news changes.",
            "Changes, overtime and even things like the medical takes, I mean obviously an outbreak is of a certain illness is going to change the concept, at least temporarily."
        ],
        [
            "So we start to do multi label classification so there one of the main approaches this problem transformation where you actually transform the problem.",
            "The multi label problem into a single label problem.",
            "So multi class or binary problems.",
            "And then you can use any of the shelf classifier single label classifier to suit your requirements.",
            "Maybe you want to work with decision trees, or maybe your data you get good results with support vector machines.",
            "Or maybe time is a consideration so you want a fast incremental classifier like like my base and so that's important.",
            "That's going to be important for working data streams if you can plug in incremental classifiers."
        ],
        [
            "Another way of looking at multi level classification is by adapting an existing single label method for multi label classification so.",
            "As is often the case is.",
            "Often, first specifically for a specific domain in mind.",
            "So if you're working with IC decision trees used a lot and one for medics and multilabel classification papers.",
            "Makes people laugh tonight working with probabilistic methods and so on.",
            "So you incorporate the advantages and disadvantages obviously of your chosen method."
        ],
        [
            "So a simple problem.",
            "Transformation method is the binary relevance method.",
            "So if you've got say 10 labels, then you just form 10 separate binary problems, one classifier for each.",
            "Each one bottom classifier learns that to predict the relevance of one of the labels, so it's obviously a simple approach and flexible because you can add labels and take away labels just as easy as you can add and remove binary classifiers.",
            "It's fast as well, and you can also run the.",
            "You can run the binary models in parallel because there are separate from each other.",
            "Because of course, because they are separate.",
            "Then it's not as easy to, well, you don't explicitly model label dependencies at all, so that often results in poor accuracy.",
            "Though there are ways around this, like work in.",
            "On classified chains.",
            "So which kept the binary approach but use the class so the predicted class of one of their binding classifiers as an attribute for predicting the second in the second binding classifier and so and so on a longer chains that gets high performance whereas without exceeding.",
            "Too much, the speed of the Bony relevance method.",
            "And there are no general approaches to run that by elements method twice 1st and you get the outputs as normal and then you run that into a second layer with the idea of learning learning their dependencies the between the labels so the outputs are the input to into the second layer."
        ],
        [
            "Another simple method is this, but well used within the literature as building blocks for more advanced methods is the label Powerset method?",
            "So here this is a multi class transformation where if you've got our labels then you consider all of the two to the L possible label set combinations as single classes.",
            "So as class labels in multiclass problem.",
            "So during this you you are explicitly modeling modeling the label dependencies, so the accuracy is tends to be higher than the binary method that you get overfitting in sparsity, so of course you're right.",
            "You're actually only doing the combinations that you've seen in the training set, so that could lead to overfitting or.",
            "Especially as in you may only have one or two, because you can have so many possible combinations, you only have one or two data instances associated with each label.",
            "But the biggest problem is definitely that it's it's can be very slow if you end up with anywhere near the two DL possible.",
            "Class labels on some of the larger problems.",
            "So one way around this is.",
            "The prune sets method where so you take away you prune out the infrequent labels to say L1 and L5 like in the example I gave up the top say that there was sort of almost like a freak.",
            "It like an outlier that only occurred once in it in the training set it would be better to take that combination out into split into two instances, one with associated with L1 and the other with L5.",
            "And that way you sort of you keep the.",
            "Information, but without introducing a new class label.",
            "So without introducing new complexity, more complexity, which is much faster and can can even be more accurate than the.",
            "The label Powerset Method, in another approach is very well known raychel method, where instead of training LP on.",
            "Full so so on the full set of our labels, you train it on random subsets of K labels where K is of course less than now.",
            "So that's one way to reduce the complexity of iterations."
        ],
        [
            "So I mentioned algorithm adaptation.",
            "So one well known method is this adaptation to decision trees, where the.",
            "The multi so that the entropy is calculation is modified basically to allow for multi label predictions at the leaves.",
            "So this method is fast.",
            "I mean it's just a simple, it's just a single model, single decision tree and it works very well, though most of its success as far as I've seen has been related to biological data, as certainly is the case with their original paper."
        ],
        [
            "So those are some some well used methods for multi label classification.",
            "How do they apply if we want to learn in a data stream context?",
            "So the binary relevance methods is straightforward.",
            "Obviously you just use a data stream method data stream, binary method, so there might be naive Bayes or often trees the the.",
            "Incremental version of decision trees.",
            "So these are instance incremental methods given.",
            "If you give them the Model 1 instance, then it can update the model without having to rebuild.",
            "And if you want to use something like support vector machines, then you have to look at better incremental where you learn in in batches.",
            "So you save up instances until you feel better and then you and then you learn on from there."
        ],
        [
            "They're using the label Powerset methods isn't as straightforward because the class labels change of overtime because each class label is a label combination, a combination of labels, which of course can change quite quite rapidly.",
            "So one festival you could use the Princess method.",
            "In fact, you pretty much have to because of the complexity.",
            "And then you end up with a lot fewer class labels.",
            "But that of course doesn't solve the problem now.",
            "One thing you could probably do is as modify naive Bayes, for example 22.",
            "Dynamically incorporate the new class labels overtime, but a general method that we've been using is to assume that you can learn the distribution.",
            "So learn the core label combinations and at which represent the label dependencies from the first N examples.",
            "We've used 1000 for the first 1000 examples.",
            "First glance, this seems like a step back, I mean.",
            "Not predicting it at first glance, it looks like we're not predicting at any point, and we're not learning.",
            "Instance incrementally, but for the first 1000 examples you can just use the binary relevance method.",
            "And then while you're gathering label combinations and then then the label, the label Powerset method for Princess Method can just take over and also continue incrementally.",
            "And of course, if the distribution changes if the label sets suddenly become different, then we reset the classifier.",
            "But that's the case with any.",
            "Any learning scheme is that when the concept changes then you print out the old concept and you start.",
            "Start learning the new one."
        ],
        [
            "And with the Decision Tree classifier, of course we can use the same entropy modification 2 for hosting trees, which we've done."
        ],
        [
            "Dealing with concept drift is obviously important part of multi label learning, though it doesn't necessarily have to be integral to the classifier and using.",
            "We've got good results using an ensemble scheme of multiple models.",
            "Anna drift detection method.",
            "So I mean you can use any method of your choice, but we use admin.",
            "It's got good guarantees on memory use.",
            "And so when Edwin in this case that takes drift, then the worst model of the ensemble is reset, with the idea that you are now going to learn the new, the new concept with that with that model."
        ],
        [
            "And an alternative method would be batch incremental, so that's been used.",
            "In the in the literature before.",
            "So, in this case, you're sort of making the assumption is always just so in this particular the paper they use eight models of working on batches of 1000 instances each, so.",
            "After 1000 instances, then you build a new model and you phase out the old ones.",
            "So I mean potential disadvantage here is first you've got to wait for.",
            "In worst case, wait for 1000 instances before you can even start before you even get to see.",
            "Current well the concepts change.",
            "Get see the current instance.",
            "Anne, and Secondly, you can only learn from in this case 8000 instances.",
            "So if you're working, you may have a concept may not change for 10s of thousands of of instances, but you of those you have only learned from from the previous eight 8000.",
            "So that's one reason why we don't use batch incremental.",
            "Altsounds"
        ],
        [
            "So maybe you've heard of of Wicca is.",
            "Machine learning framework.",
            "Came out of University of Waikato.",
            "It was in Java with a wide range of machine learning algorithms, but also tools for data preparation and visualization.",
            "And that sort of thing."
        ],
        [
            "I'm fine, are you afraid of more, which is basically?",
            "It's closely related to workout, but it deals with incremental context, so the data stream context contains instance incremental and an.",
            "You can use a wrap around any worker classifier, and if that were classified as an instance incremental in it, it becomes bench bench incremental.",
            "An obviously comes with Edwin for detecting concept drift.",
            "And it's easy to create a classifier when you just need to be able to reset the method in case there's differences detected and to update a method update their model with an instance and to get a prediction basically."
        ],
        [
            "And Meanwhile I've been working on an MCR which is the multi label.",
            "Extension to work here because worker doesn't support directly multilabel classification, so this is very closely integrated with Wicker.",
            "It uses the same build classifier method and the same method for getting a prediction, though of course in regular multiclass case you would take the highest so that the distribution for instance returns for example the posterior probabilities, and in multiclass classification would take the highest probability that that would be the class that you choose.",
            "Obviously multi label classification, you select several, so user threshold in any probabilities above that threshold.",
            "Become relevant labels and the rest become irrelevant labels in the label set prediction.",
            "So and make a.",
            "You've got problems.",
            "Transformation within.",
            "You can use any worker based classifier and some generic ensemble and thresholding methods.",
            "It also provides a wrapper on Moulin which is another.",
            "Another multi level framework if you're looking to multi level classification, it's worth.",
            "Looking at.",
            "And the most important thing is the evaluation.",
            "So that's what what made.",
            "Multi Label classification worker directly most difficult as the evaluation is.",
            "Is different."
        ],
        [
            "So that's where we were coming from.",
            "So working with alert and more and I'm working.",
            "So we came up with initially with more rappers for for Mecca, Classifieds and Maker rappers.",
            "For more classifiers and we're working towards a murder.",
            "Multilabel capable well basically."
        ],
        [
            "So I've mentioned several Times Now the evaluation, so it's different to multi label classification because for a make a prediction and you get a set of labels and of course you compare with an actual set of labels.",
            "Of course it may not be exactly the same, so if you can either check if their prediction in the predicted set and they actually are exactly the same, and even if they differ by a bit, if they're not exactly the same, then it's a false example.",
            "Or you can go along checking label by label the relevance of each label of.",
            "It possible label for each example.",
            "Or they are also in between methods such as subset accuracy, rough.",
            "Given here.",
            "And I mentioned also the thresholds.",
            "So if you get a vector which of real valued upwards, which is common, then you need a threshold to get the actual label.",
            "Relevance.",
            "Is that legal set prediction from there.",
            "And data stream evaluation with it, so cross validation becomes difficult because you don't have all your data at once in a batch and you've gotta ready look at retaining the time ordering as well.",
            "So you could use a holdout holdout set or interleaved, so make your prediction.",
            "Then then use that example for for training.",
            "Or, for example, proquin shall have a sliding window evaluation.",
            "So we've looked at that."
        ],
        [
            "Now, unfortunately, large data sources of real World Multi label data.",
            "I had to get hold of because they're either.",
            "Sensitive contain sensitive information, for example.",
            "Or maybe companies just hold on to them, hold on to their dad.",
            "I don't want to share it.",
            "Or maybe it's just too large too.",
            "To fit into memory, I mean, if you if you're dealing with if you want to do some quick tests and you've got to load many, many, many gigabytes.",
            "That can also be a."
        ],
        [
            "Nishing so we've had to look at generating.",
            "Synthesizing multi label data streams.",
            "Sir.",
            "To generate an an example, we sort of parameterized the label dependencies in and with the number of labels, the average number of labels assigned to each example an from that distribution get out, get out, get a label set and using that label, set an A MOA binary class generator.",
            "So my account was already comes with these many generators for generating synthetic.",
            "Data.",
            "Is well more several to choose from.",
            "And yeah, and from that and the label set, then you can generate the instance to better instance to go with it.",
            "So you can chain introduce concept shift in the label space by changing the parameters for generating the label sets an.",
            "You can introduce Jeff in the input space in instance based.",
            "In other words, just as you do and more does.",
            "That does that already, so that part wasn't an issue."
        ],
        [
            "So here is an example of of multi label classification in mower so.",
            "You can see we're considering that prune sets.",
            "Classify using pruning value of three subsampling value of 1 and I mentioned that we use 1000 for the initial buffer and the base learner hunting tree.",
            "And that's going to be run on a real world data set.",
            "With potential evaluation."
        ],
        [
            "And generating a multilabel stream.",
            "So you just need to select the binary generator and the number of labels and how screwed you wanted an average number of labels, for example and the label dependencies are generated automatically 'cause you don't want to be filling in thousands of matrix values which specify that."
        ],
        [
            "So methods so I mentioned the binary relevance method, ensembles of binary relevance.",
            "So with the ensemble an Edwin for.",
            "Detecting concept drift.",
            "On some of classified chains, though I admit here that we've had the classified chains work really well in a batch setting, but they at least so far we haven't got good results in the.",
            "With massive amounts of data compared to some of the other methods.",
            "I want someone to Prinsens.",
            "As I mentioned an this.",
            "At 2 two times binary relevance method, we feed the outputs into the inputs of the of the second layer, which was the base of of method in the literature that they did a bit more.",
            "On top of that, but that's essentially what it was and multi neighborhood in trees and we looked at how these methods were performing.",
            "Anne Anne Anne and came up with so use them as building blocks to create a novel method, which is ensembles of multi level.",
            "Often trees with prune sets at the leaves of the whole thing tree."
        ],
        [
            "So here are some of the data sources with.",
            "Been working with so the real data sets.",
            "Team C 2007.",
            "Its aviation reports.",
            "Textural Aviation reports, labeled with.",
            "The error category that they default category that they categories that they fit into media Mail that video.",
            "Concepts.",
            "So 101 labels, and in this case it's the most labels of.",
            "That we're looking at here.",
            "And the final column is the average number of labels that.",
            "Each instance is associated with, so you can see multi labeling.",
            "Multi Label is quite sparse.",
            "Generally the multi labeling itself.",
            "20 newsgroups IMDb.",
            "That's takes movie plot summaries associated with genres.",
            "Slashdotters news.",
            "From theirslashdot.org website.",
            "Enron is an email data set and then a medical medical data set.",
            "And finally, some synthetic data sets the first to breakdown the second, the after that with various concepts within them.",
            "So even average number of labels assigned gifts from for example 1.5 to 3.5 in the first case."
        ],
        [
            "So just to give you like it overall very rough picture on these are living data sets with three evaluation measures.",
            "Measure service with the three evaluation measures I meant before mentioned, for example, accuracy label accuracy in a sort of in between subset accuracy.",
            "So the on someone's affecting trees with Princess.",
            "That leaves that as well.",
            "Best overall most number of wins.",
            "And then the the ensemble of an irrelevance method that does quite well considering that it's really a simple method, it's just.",
            "One binary classifier for each label and an ensemble of of their hosting trees does well on a few measures as well an if you look at the second table, which is the average running time.",
            "I mean, you can see that this would be an attractive method for many cases if you wanted.",
            "If you were happy to not have the best possible accuracy, but.",
            "So, and that was actually one reason why we looked at often trees for our method of ensembles affecting trees with Prince at the set.",
            "The leader consulting trees are fast and reasonable performance.",
            "An eye on someone's appearance, it's not.",
            "And the two times binary relevance method as well after after that.",
            "Yes Sir, you can see the time is very the last one that responded well and said that was the batch method I mentioned so you can see that that's.",
            "I mean about twice is almost twice as.",
            "Slow is the next slowest method, so.",
            "Which indicates that instancing, at least in this case instance incremental learning is a good option for speed.",
            "Yeah.",
            "So obviously the best incremental learning was using the this particular paper there.",
            "They are afraid to before they use static decision trees, so J.",
            "48 which is work is implementation of C 4.5 decision trees and all methods are using Edwin for detecting concept just except the to be our method, which is because it's a batch and commitment.",
            "It assumes as always Jeff.",
            "So it's constantly phasing phasing out old information and beginning."
        ],
        [
            "New models.",
            "So a. Multi Label streaming framework with streaming problem transformation and algorithm adaption.",
            "Adaptation methods for multi label classification.",
            "Multi label and data seems specific evaluation.",
            "And synthetic multi label data generation.",
            "I'm within the framework are a novel method for.",
            "Novel method which sets a benchmark.",
            "And for future work, it would be interesting to look into where the label space is more dynamic, so you actually consider labels are coming and going.",
            "Anne.",
            "With it, without having any idea beforehand how many labels that are going to be or or whatever, same with the attribute space.",
            "And looking into different just detection thresholding methods."
        ],
        [
            "To hear some references in an affirmative anything out, you can probably find it on my website.",
            "I'm not really familiar with out at the most recent developments in multi level.",
            "You mentioned something like more lending.",
            "That footnote.",
            "Yeah.",
            "Suffer with.",
            "Well, mulin is."
        ],
        [
            "It's basically another.",
            "Method of another framework for multi label classification.",
            "They were sort of developed and in parallel for awhile and.",
            "Yeah, I mean they've probably got more methods to be honest, so I provided.",
            "A wrapper for\nClassifiers so I can use any of their classifieds, and if that their framework if you look in interested in like hierarchical multi label classification and they deal with that as well.",
            "Where is Mecca is?",
            "As most strictly just friend classification.",
            "Have a seat data where the labels are probabilistic as well as mean they said the outputs, and that's that's a interesting point 'cause I've thought about it and I haven't come across any real world data where that where that is the case, but it would be interesting exactly, especially because in real world situations I mean some labels might be more relevant than another.",
            "Yeah, so it's just a question of I don't have any any data to work with.",
            "Yeah.",
            "No, not not.",
            "There I've seen one work with a.",
            "They they re classified the training data with relevance is an then then learned those relevance is but not where they raw data comes from.",
            "It comes with label relevance is."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This talk is about where multi label classification meets data stream classification, and a framework for working in such a content.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Term Multi label classification.",
                    "label": 0
                },
                {
                    "sent": "This is where each data instances associated with a subset of class labels that supposed to the more traditional task of.",
                    "label": 1
                },
                {
                    "sent": "Multi class classification where each data instance is associated with a single class label.",
                    "label": 1
                },
                {
                    "sent": "So this is the implications that there may be dependencies between labels, because you can have multiple labels associated with a single example.",
                    "label": 0
                },
                {
                    "sent": "Obviously certain labels are more likely to occur together then than others, so in this small example from a real data set small data set where pieces of music are labeled with emotions, the thickness of the lines represents the Co occurrences, so you can see that the emotions relaxing, calm, quiet, still an sad lonely.",
                    "label": 0
                },
                {
                    "sent": "They often are associated together with the same piece of music, whereas for example, amazed, surprised and sad lonely.",
                    "label": 0
                },
                {
                    "sent": "Those mutually exclusive within the particular data set.",
                    "label": 0
                },
                {
                    "sent": "And we also have greater dimensionality because instead of three for a given data instance to make a prediction instead of selecting one of L classes were selecting one of two to the L label set combinations.",
                    "label": 0
                },
                {
                    "sent": "And evaluation is also different.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about that later in the talk.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data stream classification.",
                    "label": 0
                },
                {
                    "sent": "This is the context where data instances arrive continually and potentially infinitely.",
                    "label": 1
                },
                {
                    "sent": "So that's.",
                    "label": 0
                },
                {
                    "sent": "Usually because of this.",
                    "label": 0
                },
                {
                    "sent": "Automatic process, like a robot or something which can make a prediction and then evaluate its prediction automatically afterwards or or a collaborative process.",
                    "label": 0
                },
                {
                    "sent": "For example, where a lot of people are contributing to the labeling task.",
                    "label": 0
                },
                {
                    "sent": "So this is the implications that, first of all we can't store everything, so obviously you can't store infinite data, so.",
                    "label": 1
                },
                {
                    "sent": "Let's 1 one thing and you have to be ready to predict at any point because we might have a new data instance, we might have to make a prediction at any point.",
                    "label": 0
                },
                {
                    "sent": "Thirdly, concept drift is you have to expect that its concentration is going to be an issue at some stage.",
                    "label": 0
                },
                {
                    "sent": "And again, here evaluation is different from from traditional batch learning setting.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So despite the fact their multi label classification is sort of only received a lot of interest in recent years, there are a wide number of applications to probably one reason that we've been focused on that multiclassed ask for so long is because of physical limitations, like say, a newspaper article might fit under the labels economy and international, but you wouldn't.",
                    "label": 0
                },
                {
                    "sent": "The same article in both sections of a newspaper the exact same same medical, but of course there's as everything becomes more digitized.",
                    "label": 0
                },
                {
                    "sent": "I mean obviously online you can find the same medical under separate headings, so I expect that we're going to find the multi label setting much more relevant.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Text documents that could be so news articles as the example I gave, but I mean academic articles.",
                    "label": 0
                },
                {
                    "sent": "This talk would be labeled multi label classification, an data stream classification.",
                    "label": 0
                },
                {
                    "sent": "Emails as well so.",
                    "label": 0
                },
                {
                    "sent": "And an even things like so medical texts classifications are medical.",
                    "label": 0
                },
                {
                    "sent": "Description A textual description of other patient symptoms may correspond to may be associated with more than one diagnosis, so you might have the flu and heart disease at the same time.",
                    "label": 0
                },
                {
                    "sent": "Vision obviously seen image concept can have multiple.",
                    "label": 0
                },
                {
                    "sent": "An image can have multiple concepts or there could be multiple objects identified or recognized within.",
                    "label": 0
                },
                {
                    "sent": "The source I gave the started with the small data set.",
                    "label": 0
                },
                {
                    "sent": "An example of music.",
                    "label": 0
                },
                {
                    "sent": "Bioinformatics is another area where multi label classification is important, and robotics obviously encompasses vision and audio as well, but any sort of sensor inputs.",
                    "label": 0
                },
                {
                    "sent": "Can correspond to multiple states or multiple error errors for exam.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of course, that note that many of these application exist in a streaming context, so obviously things like email, email arrives continually every time, and you never expect to find more final email.",
                    "label": 0
                },
                {
                    "sent": "So I mean basically potentially infinite.",
                    "label": 0
                },
                {
                    "sent": "Ah, same with news articles.",
                    "label": 0
                },
                {
                    "sent": "And of course concept drift can can occur as well.",
                    "label": 0
                },
                {
                    "sent": "Obviously the news, the focus of the news changes.",
                    "label": 0
                },
                {
                    "sent": "Changes, overtime and even things like the medical takes, I mean obviously an outbreak is of a certain illness is going to change the concept, at least temporarily.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we start to do multi label classification so there one of the main approaches this problem transformation where you actually transform the problem.",
                    "label": 0
                },
                {
                    "sent": "The multi label problem into a single label problem.",
                    "label": 1
                },
                {
                    "sent": "So multi class or binary problems.",
                    "label": 0
                },
                {
                    "sent": "And then you can use any of the shelf classifier single label classifier to suit your requirements.",
                    "label": 1
                },
                {
                    "sent": "Maybe you want to work with decision trees, or maybe your data you get good results with support vector machines.",
                    "label": 0
                },
                {
                    "sent": "Or maybe time is a consideration so you want a fast incremental classifier like like my base and so that's important.",
                    "label": 0
                },
                {
                    "sent": "That's going to be important for working data streams if you can plug in incremental classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another way of looking at multi level classification is by adapting an existing single label method for multi label classification so.",
                    "label": 0
                },
                {
                    "sent": "As is often the case is.",
                    "label": 0
                },
                {
                    "sent": "Often, first specifically for a specific domain in mind.",
                    "label": 1
                },
                {
                    "sent": "So if you're working with IC decision trees used a lot and one for medics and multilabel classification papers.",
                    "label": 1
                },
                {
                    "sent": "Makes people laugh tonight working with probabilistic methods and so on.",
                    "label": 0
                },
                {
                    "sent": "So you incorporate the advantages and disadvantages obviously of your chosen method.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a simple problem.",
                    "label": 0
                },
                {
                    "sent": "Transformation method is the binary relevance method.",
                    "label": 1
                },
                {
                    "sent": "So if you've got say 10 labels, then you just form 10 separate binary problems, one classifier for each.",
                    "label": 0
                },
                {
                    "sent": "Each one bottom classifier learns that to predict the relevance of one of the labels, so it's obviously a simple approach and flexible because you can add labels and take away labels just as easy as you can add and remove binary classifiers.",
                    "label": 1
                },
                {
                    "sent": "It's fast as well, and you can also run the.",
                    "label": 0
                },
                {
                    "sent": "You can run the binary models in parallel because there are separate from each other.",
                    "label": 0
                },
                {
                    "sent": "Because of course, because they are separate.",
                    "label": 0
                },
                {
                    "sent": "Then it's not as easy to, well, you don't explicitly model label dependencies at all, so that often results in poor accuracy.",
                    "label": 1
                },
                {
                    "sent": "Though there are ways around this, like work in.",
                    "label": 0
                },
                {
                    "sent": "On classified chains.",
                    "label": 0
                },
                {
                    "sent": "So which kept the binary approach but use the class so the predicted class of one of their binding classifiers as an attribute for predicting the second in the second binding classifier and so and so on a longer chains that gets high performance whereas without exceeding.",
                    "label": 0
                },
                {
                    "sent": "Too much, the speed of the Bony relevance method.",
                    "label": 0
                },
                {
                    "sent": "And there are no general approaches to run that by elements method twice 1st and you get the outputs as normal and then you run that into a second layer with the idea of learning learning their dependencies the between the labels so the outputs are the input to into the second layer.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another simple method is this, but well used within the literature as building blocks for more advanced methods is the label Powerset method?",
                    "label": 0
                },
                {
                    "sent": "So here this is a multi class transformation where if you've got our labels then you consider all of the two to the L possible label set combinations as single classes.",
                    "label": 1
                },
                {
                    "sent": "So as class labels in multiclass problem.",
                    "label": 0
                },
                {
                    "sent": "So during this you you are explicitly modeling modeling the label dependencies, so the accuracy is tends to be higher than the binary method that you get overfitting in sparsity, so of course you're right.",
                    "label": 1
                },
                {
                    "sent": "You're actually only doing the combinations that you've seen in the training set, so that could lead to overfitting or.",
                    "label": 0
                },
                {
                    "sent": "Especially as in you may only have one or two, because you can have so many possible combinations, you only have one or two data instances associated with each label.",
                    "label": 0
                },
                {
                    "sent": "But the biggest problem is definitely that it's it's can be very slow if you end up with anywhere near the two DL possible.",
                    "label": 1
                },
                {
                    "sent": "Class labels on some of the larger problems.",
                    "label": 0
                },
                {
                    "sent": "So one way around this is.",
                    "label": 0
                },
                {
                    "sent": "The prune sets method where so you take away you prune out the infrequent labels to say L1 and L5 like in the example I gave up the top say that there was sort of almost like a freak.",
                    "label": 0
                },
                {
                    "sent": "It like an outlier that only occurred once in it in the training set it would be better to take that combination out into split into two instances, one with associated with L1 and the other with L5.",
                    "label": 1
                },
                {
                    "sent": "And that way you sort of you keep the.",
                    "label": 0
                },
                {
                    "sent": "Information, but without introducing a new class label.",
                    "label": 0
                },
                {
                    "sent": "So without introducing new complexity, more complexity, which is much faster and can can even be more accurate than the.",
                    "label": 0
                },
                {
                    "sent": "The label Powerset Method, in another approach is very well known raychel method, where instead of training LP on.",
                    "label": 0
                },
                {
                    "sent": "Full so so on the full set of our labels, you train it on random subsets of K labels where K is of course less than now.",
                    "label": 0
                },
                {
                    "sent": "So that's one way to reduce the complexity of iterations.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I mentioned algorithm adaptation.",
                    "label": 1
                },
                {
                    "sent": "So one well known method is this adaptation to decision trees, where the.",
                    "label": 0
                },
                {
                    "sent": "The multi so that the entropy is calculation is modified basically to allow for multi label predictions at the leaves.",
                    "label": 1
                },
                {
                    "sent": "So this method is fast.",
                    "label": 0
                },
                {
                    "sent": "I mean it's just a simple, it's just a single model, single decision tree and it works very well, though most of its success as far as I've seen has been related to biological data, as certainly is the case with their original paper.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So those are some some well used methods for multi label classification.",
                    "label": 0
                },
                {
                    "sent": "How do they apply if we want to learn in a data stream context?",
                    "label": 0
                },
                {
                    "sent": "So the binary relevance methods is straightforward.",
                    "label": 1
                },
                {
                    "sent": "Obviously you just use a data stream method data stream, binary method, so there might be naive Bayes or often trees the the.",
                    "label": 0
                },
                {
                    "sent": "Incremental version of decision trees.",
                    "label": 0
                },
                {
                    "sent": "So these are instance incremental methods given.",
                    "label": 0
                },
                {
                    "sent": "If you give them the Model 1 instance, then it can update the model without having to rebuild.",
                    "label": 0
                },
                {
                    "sent": "And if you want to use something like support vector machines, then you have to look at better incremental where you learn in in batches.",
                    "label": 0
                },
                {
                    "sent": "So you save up instances until you feel better and then you and then you learn on from there.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They're using the label Powerset methods isn't as straightforward because the class labels change of overtime because each class label is a label combination, a combination of labels, which of course can change quite quite rapidly.",
                    "label": 0
                },
                {
                    "sent": "So one festival you could use the Princess method.",
                    "label": 0
                },
                {
                    "sent": "In fact, you pretty much have to because of the complexity.",
                    "label": 0
                },
                {
                    "sent": "And then you end up with a lot fewer class labels.",
                    "label": 0
                },
                {
                    "sent": "But that of course doesn't solve the problem now.",
                    "label": 0
                },
                {
                    "sent": "One thing you could probably do is as modify naive Bayes, for example 22.",
                    "label": 0
                },
                {
                    "sent": "Dynamically incorporate the new class labels overtime, but a general method that we've been using is to assume that you can learn the distribution.",
                    "label": 0
                },
                {
                    "sent": "So learn the core label combinations and at which represent the label dependencies from the first N examples.",
                    "label": 1
                },
                {
                    "sent": "We've used 1000 for the first 1000 examples.",
                    "label": 0
                },
                {
                    "sent": "First glance, this seems like a step back, I mean.",
                    "label": 0
                },
                {
                    "sent": "Not predicting it at first glance, it looks like we're not predicting at any point, and we're not learning.",
                    "label": 0
                },
                {
                    "sent": "Instance incrementally, but for the first 1000 examples you can just use the binary relevance method.",
                    "label": 0
                },
                {
                    "sent": "And then while you're gathering label combinations and then then the label, the label Powerset method for Princess Method can just take over and also continue incrementally.",
                    "label": 0
                },
                {
                    "sent": "And of course, if the distribution changes if the label sets suddenly become different, then we reset the classifier.",
                    "label": 0
                },
                {
                    "sent": "But that's the case with any.",
                    "label": 0
                },
                {
                    "sent": "Any learning scheme is that when the concept changes then you print out the old concept and you start.",
                    "label": 0
                },
                {
                    "sent": "Start learning the new one.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with the Decision Tree classifier, of course we can use the same entropy modification 2 for hosting trees, which we've done.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dealing with concept drift is obviously important part of multi label learning, though it doesn't necessarily have to be integral to the classifier and using.",
                    "label": 1
                },
                {
                    "sent": "We've got good results using an ensemble scheme of multiple models.",
                    "label": 0
                },
                {
                    "sent": "Anna drift detection method.",
                    "label": 0
                },
                {
                    "sent": "So I mean you can use any method of your choice, but we use admin.",
                    "label": 1
                },
                {
                    "sent": "It's got good guarantees on memory use.",
                    "label": 0
                },
                {
                    "sent": "And so when Edwin in this case that takes drift, then the worst model of the ensemble is reset, with the idea that you are now going to learn the new, the new concept with that with that model.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And an alternative method would be batch incremental, so that's been used.",
                    "label": 0
                },
                {
                    "sent": "In the in the literature before.",
                    "label": 0
                },
                {
                    "sent": "So, in this case, you're sort of making the assumption is always just so in this particular the paper they use eight models of working on batches of 1000 instances each, so.",
                    "label": 0
                },
                {
                    "sent": "After 1000 instances, then you build a new model and you phase out the old ones.",
                    "label": 0
                },
                {
                    "sent": "So I mean potential disadvantage here is first you've got to wait for.",
                    "label": 0
                },
                {
                    "sent": "In worst case, wait for 1000 instances before you can even start before you even get to see.",
                    "label": 0
                },
                {
                    "sent": "Current well the concepts change.",
                    "label": 0
                },
                {
                    "sent": "Get see the current instance.",
                    "label": 0
                },
                {
                    "sent": "Anne, and Secondly, you can only learn from in this case 8000 instances.",
                    "label": 0
                },
                {
                    "sent": "So if you're working, you may have a concept may not change for 10s of thousands of of instances, but you of those you have only learned from from the previous eight 8000.",
                    "label": 0
                },
                {
                    "sent": "So that's one reason why we don't use batch incremental.",
                    "label": 0
                },
                {
                    "sent": "Altsounds",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So maybe you've heard of of Wicca is.",
                    "label": 0
                },
                {
                    "sent": "Machine learning framework.",
                    "label": 0
                },
                {
                    "sent": "Came out of University of Waikato.",
                    "label": 0
                },
                {
                    "sent": "It was in Java with a wide range of machine learning algorithms, but also tools for data preparation and visualization.",
                    "label": 1
                },
                {
                    "sent": "And that sort of thing.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm fine, are you afraid of more, which is basically?",
                    "label": 0
                },
                {
                    "sent": "It's closely related to workout, but it deals with incremental context, so the data stream context contains instance incremental and an.",
                    "label": 1
                },
                {
                    "sent": "You can use a wrap around any worker classifier, and if that were classified as an instance incremental in it, it becomes bench bench incremental.",
                    "label": 1
                },
                {
                    "sent": "An obviously comes with Edwin for detecting concept drift.",
                    "label": 0
                },
                {
                    "sent": "And it's easy to create a classifier when you just need to be able to reset the method in case there's differences detected and to update a method update their model with an instance and to get a prediction basically.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And Meanwhile I've been working on an MCR which is the multi label.",
                    "label": 0
                },
                {
                    "sent": "Extension to work here because worker doesn't support directly multilabel classification, so this is very closely integrated with Wicker.",
                    "label": 1
                },
                {
                    "sent": "It uses the same build classifier method and the same method for getting a prediction, though of course in regular multiclass case you would take the highest so that the distribution for instance returns for example the posterior probabilities, and in multiclass classification would take the highest probability that that would be the class that you choose.",
                    "label": 0
                },
                {
                    "sent": "Obviously multi label classification, you select several, so user threshold in any probabilities above that threshold.",
                    "label": 0
                },
                {
                    "sent": "Become relevant labels and the rest become irrelevant labels in the label set prediction.",
                    "label": 0
                },
                {
                    "sent": "So and make a.",
                    "label": 0
                },
                {
                    "sent": "You've got problems.",
                    "label": 0
                },
                {
                    "sent": "Transformation within.",
                    "label": 1
                },
                {
                    "sent": "You can use any worker based classifier and some generic ensemble and thresholding methods.",
                    "label": 0
                },
                {
                    "sent": "It also provides a wrapper on Moulin which is another.",
                    "label": 0
                },
                {
                    "sent": "Another multi level framework if you're looking to multi level classification, it's worth.",
                    "label": 0
                },
                {
                    "sent": "Looking at.",
                    "label": 0
                },
                {
                    "sent": "And the most important thing is the evaluation.",
                    "label": 0
                },
                {
                    "sent": "So that's what what made.",
                    "label": 0
                },
                {
                    "sent": "Multi Label classification worker directly most difficult as the evaluation is.",
                    "label": 0
                },
                {
                    "sent": "Is different.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's where we were coming from.",
                    "label": 0
                },
                {
                    "sent": "So working with alert and more and I'm working.",
                    "label": 0
                },
                {
                    "sent": "So we came up with initially with more rappers for for Mecca, Classifieds and Maker rappers.",
                    "label": 0
                },
                {
                    "sent": "For more classifiers and we're working towards a murder.",
                    "label": 0
                },
                {
                    "sent": "Multilabel capable well basically.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I've mentioned several Times Now the evaluation, so it's different to multi label classification because for a make a prediction and you get a set of labels and of course you compare with an actual set of labels.",
                    "label": 0
                },
                {
                    "sent": "Of course it may not be exactly the same, so if you can either check if their prediction in the predicted set and they actually are exactly the same, and even if they differ by a bit, if they're not exactly the same, then it's a false example.",
                    "label": 0
                },
                {
                    "sent": "Or you can go along checking label by label the relevance of each label of.",
                    "label": 0
                },
                {
                    "sent": "It possible label for each example.",
                    "label": 0
                },
                {
                    "sent": "Or they are also in between methods such as subset accuracy, rough.",
                    "label": 1
                },
                {
                    "sent": "Given here.",
                    "label": 0
                },
                {
                    "sent": "And I mentioned also the thresholds.",
                    "label": 1
                },
                {
                    "sent": "So if you get a vector which of real valued upwards, which is common, then you need a threshold to get the actual label.",
                    "label": 0
                },
                {
                    "sent": "Relevance.",
                    "label": 0
                },
                {
                    "sent": "Is that legal set prediction from there.",
                    "label": 0
                },
                {
                    "sent": "And data stream evaluation with it, so cross validation becomes difficult because you don't have all your data at once in a batch and you've gotta ready look at retaining the time ordering as well.",
                    "label": 1
                },
                {
                    "sent": "So you could use a holdout holdout set or interleaved, so make your prediction.",
                    "label": 0
                },
                {
                    "sent": "Then then use that example for for training.",
                    "label": 0
                },
                {
                    "sent": "Or, for example, proquin shall have a sliding window evaluation.",
                    "label": 1
                },
                {
                    "sent": "So we've looked at that.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, unfortunately, large data sources of real World Multi label data.",
                    "label": 1
                },
                {
                    "sent": "I had to get hold of because they're either.",
                    "label": 0
                },
                {
                    "sent": "Sensitive contain sensitive information, for example.",
                    "label": 0
                },
                {
                    "sent": "Or maybe companies just hold on to them, hold on to their dad.",
                    "label": 0
                },
                {
                    "sent": "I don't want to share it.",
                    "label": 1
                },
                {
                    "sent": "Or maybe it's just too large too.",
                    "label": 0
                },
                {
                    "sent": "To fit into memory, I mean, if you if you're dealing with if you want to do some quick tests and you've got to load many, many, many gigabytes.",
                    "label": 0
                },
                {
                    "sent": "That can also be a.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nishing so we've had to look at generating.",
                    "label": 0
                },
                {
                    "sent": "Synthesizing multi label data streams.",
                    "label": 1
                },
                {
                    "sent": "Sir.",
                    "label": 0
                },
                {
                    "sent": "To generate an an example, we sort of parameterized the label dependencies in and with the number of labels, the average number of labels assigned to each example an from that distribution get out, get out, get a label set and using that label, set an A MOA binary class generator.",
                    "label": 1
                },
                {
                    "sent": "So my account was already comes with these many generators for generating synthetic.",
                    "label": 0
                },
                {
                    "sent": "Data.",
                    "label": 0
                },
                {
                    "sent": "Is well more several to choose from.",
                    "label": 0
                },
                {
                    "sent": "And yeah, and from that and the label set, then you can generate the instance to better instance to go with it.",
                    "label": 0
                },
                {
                    "sent": "So you can chain introduce concept shift in the label space by changing the parameters for generating the label sets an.",
                    "label": 1
                },
                {
                    "sent": "You can introduce Jeff in the input space in instance based.",
                    "label": 0
                },
                {
                    "sent": "In other words, just as you do and more does.",
                    "label": 0
                },
                {
                    "sent": "That does that already, so that part wasn't an issue.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is an example of of multi label classification in mower so.",
                    "label": 0
                },
                {
                    "sent": "You can see we're considering that prune sets.",
                    "label": 0
                },
                {
                    "sent": "Classify using pruning value of three subsampling value of 1 and I mentioned that we use 1000 for the initial buffer and the base learner hunting tree.",
                    "label": 0
                },
                {
                    "sent": "And that's going to be run on a real world data set.",
                    "label": 0
                },
                {
                    "sent": "With potential evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And generating a multilabel stream.",
                    "label": 0
                },
                {
                    "sent": "So you just need to select the binary generator and the number of labels and how screwed you wanted an average number of labels, for example and the label dependencies are generated automatically 'cause you don't want to be filling in thousands of matrix values which specify that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So methods so I mentioned the binary relevance method, ensembles of binary relevance.",
                    "label": 1
                },
                {
                    "sent": "So with the ensemble an Edwin for.",
                    "label": 0
                },
                {
                    "sent": "Detecting concept drift.",
                    "label": 0
                },
                {
                    "sent": "On some of classified chains, though I admit here that we've had the classified chains work really well in a batch setting, but they at least so far we haven't got good results in the.",
                    "label": 0
                },
                {
                    "sent": "With massive amounts of data compared to some of the other methods.",
                    "label": 0
                },
                {
                    "sent": "I want someone to Prinsens.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned an this.",
                    "label": 0
                },
                {
                    "sent": "At 2 two times binary relevance method, we feed the outputs into the inputs of the of the second layer, which was the base of of method in the literature that they did a bit more.",
                    "label": 0
                },
                {
                    "sent": "On top of that, but that's essentially what it was and multi neighborhood in trees and we looked at how these methods were performing.",
                    "label": 1
                },
                {
                    "sent": "Anne Anne Anne and came up with so use them as building blocks to create a novel method, which is ensembles of multi level.",
                    "label": 1
                },
                {
                    "sent": "Often trees with prune sets at the leaves of the whole thing tree.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some of the data sources with.",
                    "label": 0
                },
                {
                    "sent": "Been working with so the real data sets.",
                    "label": 0
                },
                {
                    "sent": "Team C 2007.",
                    "label": 0
                },
                {
                    "sent": "Its aviation reports.",
                    "label": 0
                },
                {
                    "sent": "Textural Aviation reports, labeled with.",
                    "label": 0
                },
                {
                    "sent": "The error category that they default category that they categories that they fit into media Mail that video.",
                    "label": 0
                },
                {
                    "sent": "Concepts.",
                    "label": 0
                },
                {
                    "sent": "So 101 labels, and in this case it's the most labels of.",
                    "label": 0
                },
                {
                    "sent": "That we're looking at here.",
                    "label": 0
                },
                {
                    "sent": "And the final column is the average number of labels that.",
                    "label": 0
                },
                {
                    "sent": "Each instance is associated with, so you can see multi labeling.",
                    "label": 0
                },
                {
                    "sent": "Multi Label is quite sparse.",
                    "label": 0
                },
                {
                    "sent": "Generally the multi labeling itself.",
                    "label": 0
                },
                {
                    "sent": "20 newsgroups IMDb.",
                    "label": 0
                },
                {
                    "sent": "That's takes movie plot summaries associated with genres.",
                    "label": 0
                },
                {
                    "sent": "Slashdotters news.",
                    "label": 0
                },
                {
                    "sent": "From theirslashdot.org website.",
                    "label": 0
                },
                {
                    "sent": "Enron is an email data set and then a medical medical data set.",
                    "label": 0
                },
                {
                    "sent": "And finally, some synthetic data sets the first to breakdown the second, the after that with various concepts within them.",
                    "label": 0
                },
                {
                    "sent": "So even average number of labels assigned gifts from for example 1.5 to 3.5 in the first case.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to give you like it overall very rough picture on these are living data sets with three evaluation measures.",
                    "label": 1
                },
                {
                    "sent": "Measure service with the three evaluation measures I meant before mentioned, for example, accuracy label accuracy in a sort of in between subset accuracy.",
                    "label": 0
                },
                {
                    "sent": "So the on someone's affecting trees with Princess.",
                    "label": 0
                },
                {
                    "sent": "That leaves that as well.",
                    "label": 0
                },
                {
                    "sent": "Best overall most number of wins.",
                    "label": 1
                },
                {
                    "sent": "And then the the ensemble of an irrelevance method that does quite well considering that it's really a simple method, it's just.",
                    "label": 1
                },
                {
                    "sent": "One binary classifier for each label and an ensemble of of their hosting trees does well on a few measures as well an if you look at the second table, which is the average running time.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can see that this would be an attractive method for many cases if you wanted.",
                    "label": 0
                },
                {
                    "sent": "If you were happy to not have the best possible accuracy, but.",
                    "label": 0
                },
                {
                    "sent": "So, and that was actually one reason why we looked at often trees for our method of ensembles affecting trees with Prince at the set.",
                    "label": 0
                },
                {
                    "sent": "The leader consulting trees are fast and reasonable performance.",
                    "label": 0
                },
                {
                    "sent": "An eye on someone's appearance, it's not.",
                    "label": 0
                },
                {
                    "sent": "And the two times binary relevance method as well after after that.",
                    "label": 0
                },
                {
                    "sent": "Yes Sir, you can see the time is very the last one that responded well and said that was the batch method I mentioned so you can see that that's.",
                    "label": 0
                },
                {
                    "sent": "I mean about twice is almost twice as.",
                    "label": 0
                },
                {
                    "sent": "Slow is the next slowest method, so.",
                    "label": 0
                },
                {
                    "sent": "Which indicates that instancing, at least in this case instance incremental learning is a good option for speed.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So obviously the best incremental learning was using the this particular paper there.",
                    "label": 0
                },
                {
                    "sent": "They are afraid to before they use static decision trees, so J.",
                    "label": 0
                },
                {
                    "sent": "48 which is work is implementation of C 4.5 decision trees and all methods are using Edwin for detecting concept just except the to be our method, which is because it's a batch and commitment.",
                    "label": 0
                },
                {
                    "sent": "It assumes as always Jeff.",
                    "label": 0
                },
                {
                    "sent": "So it's constantly phasing phasing out old information and beginning.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "New models.",
                    "label": 0
                },
                {
                    "sent": "So a. Multi Label streaming framework with streaming problem transformation and algorithm adaption.",
                    "label": 1
                },
                {
                    "sent": "Adaptation methods for multi label classification.",
                    "label": 0
                },
                {
                    "sent": "Multi label and data seems specific evaluation.",
                    "label": 0
                },
                {
                    "sent": "And synthetic multi label data generation.",
                    "label": 0
                },
                {
                    "sent": "I'm within the framework are a novel method for.",
                    "label": 1
                },
                {
                    "sent": "Novel method which sets a benchmark.",
                    "label": 1
                },
                {
                    "sent": "And for future work, it would be interesting to look into where the label space is more dynamic, so you actually consider labels are coming and going.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "With it, without having any idea beforehand how many labels that are going to be or or whatever, same with the attribute space.",
                    "label": 0
                },
                {
                    "sent": "And looking into different just detection thresholding methods.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To hear some references in an affirmative anything out, you can probably find it on my website.",
                    "label": 0
                },
                {
                    "sent": "I'm not really familiar with out at the most recent developments in multi level.",
                    "label": 0
                },
                {
                    "sent": "You mentioned something like more lending.",
                    "label": 0
                },
                {
                    "sent": "That footnote.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Suffer with.",
                    "label": 0
                },
                {
                    "sent": "Well, mulin is.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's basically another.",
                    "label": 0
                },
                {
                    "sent": "Method of another framework for multi label classification.",
                    "label": 0
                },
                {
                    "sent": "They were sort of developed and in parallel for awhile and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean they've probably got more methods to be honest, so I provided.",
                    "label": 0
                },
                {
                    "sent": "A wrapper for\nClassifiers so I can use any of their classifieds, and if that their framework if you look in interested in like hierarchical multi label classification and they deal with that as well.",
                    "label": 0
                },
                {
                    "sent": "Where is Mecca is?",
                    "label": 0
                },
                {
                    "sent": "As most strictly just friend classification.",
                    "label": 0
                },
                {
                    "sent": "Have a seat data where the labels are probabilistic as well as mean they said the outputs, and that's that's a interesting point 'cause I've thought about it and I haven't come across any real world data where that where that is the case, but it would be interesting exactly, especially because in real world situations I mean some labels might be more relevant than another.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's just a question of I don't have any any data to work with.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "No, not not.",
                    "label": 0
                },
                {
                    "sent": "There I've seen one work with a.",
                    "label": 0
                },
                {
                    "sent": "They they re classified the training data with relevance is an then then learned those relevance is but not where they raw data comes from.",
                    "label": 0
                },
                {
                    "sent": "It comes with label relevance is.",
                    "label": 0
                }
            ]
        }
    }
}