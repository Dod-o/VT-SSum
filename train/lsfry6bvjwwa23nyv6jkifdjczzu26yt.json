{
    "id": "lsfry6bvjwwa23nyv6jkifdjczzu26yt",
    "title": "Translating Webpages into Bidphrases for Advertising",
    "info": {
        "author": [
            "Bo Pang, Yahoo! Research Silicon Valley"
        ],
        "published": "April 12, 2010",
        "recorded": "February 2010",
        "category": [
            "Top->Computer Science->Web Mining->Search & Advertising"
        ]
    },
    "url": "http://videolectures.net/wsdm2010_pang_agobp/",
    "segmentation": [
        [
            "Mission this is joint work with our summer intern.",
            "Unfortunately suggests can be here, so I'll be giving the talk.",
            "So in the previous talk you see that the notion of keywords is pretty or the notion of keywords or big phrases is pretty central to online advertising.",
            "So in this talk will talk about how we actually generate them."
        ],
        [
            "So here's what the advertiser typically issue.",
            "So the advertisers have some pages they're trying to attract users to in order to do this."
        ],
        [
            "Actually need to provide a list of relevant speech phrases or keywords to the search engine so these are the words that they want to be.",
            "These are essentially the queries that they want their ads to be shown for, and these are the phrases that they're willing to bid on.",
            "So as you can probably see, this will be a pretty labor intensive process, especially if you have 10s of thousands landing pages to deal with.",
            "There's some on line."
        ],
        [
            "Shoes are such as keyword suggestion that help you automate this process.",
            "Before keyword suggestion, you need to provide some feet phrases to begin with, and there's also some potential concept drift.",
            "So even in this case, if you're handling really 10s of thousands of pages to provide a RC seed phrase for each one of them can still be pretty labor intensive.",
            "So we're trying to see can we leverage the kind of data we have and further automate this process."
        ],
        [
            "So here's our problem.",
            "We start with a landing page.",
            "In many cases is a web page describing some product and we want to automatically generate bid phrases.",
            "Or these are the phrases that are supposed to be relevant to this page and potentially the advertisers might be willing to bid on.",
            "So, is this a difficult problem?"
        ],
        [
            "You might wonder that maybe you can just try to get the most informative phrase out of the landing."
        ],
        [
            "Page.",
            "We did a analysis of the corpus.",
            "We have an.",
            "We find that in 96% of the time a landing page would be associated with at least one bit phrase that's actually not in the page, right?",
            "So if you're limiting yourself to only pages available to only phrases available on the page, you will be losing many of the valid phrases."
        ],
        [
            "So then you would think how about we just back up towards so?",
            "First of all, what we really need are the phrases.",
            "So if you're just getting worse."
        ],
        [
            "Although the page you need some good ways to actually mix and match them, so you still come up with value phrases."
        ],
        [
            "And Secondly, even when you back up to the word level, we find that many of the words in the bit phrases don't appear on the page either.",
            "OK, so this probably by now looks like a challenging problem."
        ],
        [
            "So here's the high high level overview of our approach.",
            "This is essentially a two phase two phase approach.",
            "In the first step, we generate the candidate bit phrases will introduce a couple of different approaches to this, and the main goal here is that you need to be the main requirement is that you really need to be able to generate novel phrases and some in some cases they need to include novel words that are not present on the page and in the second stage.",
            "We'll be ranking these candidates according to some criteria.",
            "Mostly we care about two things.",
            "First, this phrase needs to be relevant to the page, and Secondly, this phrase needs to resemble queries in some way.",
            "They can't just be random phrases.",
            "OK, so if we start with the criterion we have for the second stage, and we try to think what we what would be a good way to combine these two requirements, that is phrases being relevant.",
            "And phrases being valid."
        ],
        [
            "We would think about a translation based approach that is the problem of generating the bid phrases is now the problem of doing the monolingual translation from the page into the bit phrase and the typical approach taken in statistical machine translation is a noisy channel approach which flip this process.",
            "So you try to imagine you're generating a landing page out of a bit phrase, and given this generative model you will then try to flip this.",
            "Back into your original problem, which is trying to locate the most likely be phrases that have generated the page.",
            "So here's the overview of the generative model."
        ],
        [
            "First you start with some big phrases according to some language model that tell you what are good phrases and what not.",
            "Good phrases and then the big phrase goes through the translation mode."
        ],
        [
            "Which gives you some probability of each bit phrase word being translated into a landing page word, and this generate the page for you.",
            "OK so.",
            "Now if we have the both the language model and the translation model estimated in some ways.",
            "Then the ranking part is actually easy.",
            "You just flip this."
        ],
        [
            "Process.",
            "An you would suppose you are given both the landing page and some candidate phrases will talk about how we generate the candidate phrases later.",
            "Suppose you have both of those.",
            "Then with the help of both language model and the translation model, essentially you score each candidate bid phrase according to the probability of the bid phrase given by the language model times the probability of the page being generated from the phrase so.",
            "You can then rank the list of candidate phrases according to the score and as you can see by this combination of the probability of the bid phrase and the probability of the landing page are given a bit phrase, we are satisfying the two criterion.",
            "That is, the phrase needs to look like a query an.",
            "That's the phrase needs to be somehow relevant to the page.",
            "So how do we actually estimate these models?"
        ],
        [
            "The language model should be fairly easy because as we mentioned here, we mostly just want to require the bid phrases looking like the queries.",
            "So we are estimating a bigram language model with a back up to unigram based on the huge query corpus sampled from our web search log.",
            "As you can see, using unigram model, you're essentially trying to see whether a word is likely to have appeared as part of a query and bigram part give you constraints.",
            "Which word are likely to Co occur in a query rather than putting random words together?"
        ],
        [
            "So the estimation of the translation model is slightly more complicated if you're familiar with the statistical machine translation literature.",
            "This is essentially IBM Model 1.",
            "If you don't know much about it, then essentially this is estimating a big translation model of word pairs, and the idea is to maximize the likelihood of the observed parallel data.",
            "An in our case, the parallel data is the bit phrase learning page pairs, which we obviously have.",
            "A lot of that we can utilize US training data.",
            "So there are some little tricks you need to do to make it work in this scenario, because machine translation is essentially between tax bands with comparable length an in our case.",
            "Obviously the landing page is much longer than the bit phrase and a lot of the content on the landing page may not be relevant for the bit."
        ],
        [
            "So one thing is we do need to add the null token which are people in SMT to use an.",
            "In their case they use the null token to account for words that are valid in one language but don't have a corresponding counterpart in the other language.",
            "In our case this is mostly to account for the irrelevant words on the given page."
        ],
        [
            "And the other thing we need to do is to incorporate importance of words in the page, particularly as we all know in the HTML page.",
            "Usually words in titles or URLs are more important than just a random words in the body.",
            "So we have a notion of importance weight associated with each word and we are putting that into the probability weighting, which essentially is trying to duplicate.",
            "The words that are supposed to be important so that they actually count more when you look for the alignments.",
            "OK, so with these two models estimated now if you have a selection of candidate phrases, we would actually be able to rank them.",
            "But how do we generate the candidate?"
        ],
        [
            "It's.",
            "Big phrases, so theoretically all the words in the prologue can be candidates, but clearly to rank all the phrases in the choir log would be inefficient.",
            "So in the first strategy we have, we build a candidate set containing only the phrases that appear in the landing page.",
            "That is, we iterate phrases of different lines inside the page.",
            "So clearly this would have the downside of not generating.",
            "Now will be phrases.",
            "And as we mentioned before this.",
            "Will not be covering all the valid phrases, so the other approach, the strategy number two we take is to further expand the set of learning page is the set of candidate bit phrases with novel phrases that we can generate using the translation model.",
            "So the idea here is to use salient words, and by salient we're just ranking words according to the weight we mentioned on the previous slides.",
            "We took the salient words on the page.",
            "And we generate the most likely translations of them according to the translation model, and then we make some together to generate novel phrases.",
            "OK, so with this we explained how the translation based model would work, how it would help us generate novel phrases, how it would help us rank."
        ],
        [
            "Here are some of the alternative methods that will be comparing.",
            "First, we introduce this baseline, which essentially you use the phrases you extract out of the page and you just compute cosine similarity between this between this phrase and the landing page.",
            "And then we can also try to use a discriminative system as the ranking system.",
            "Note that for discriminative subsystem you cannot really generate any phrases.",
            "It will depend it'll have to depend on some other candidate generation method.",
            "But once the candidates are generated, we could rank these candidates using this or SVM rank where features include things like word overlap for cosine similarity between a bit phrase and the landing page.",
            "And where did the words in the candidate be phrase appear so long?",
            "And Lastly, we also compared against the system that's built on essentially a content match system, so a content match system is trying to find a adds to put onto a web page.",
            "So now we kind of pretend, then the landing page is the web page on which you want to put on some ads.",
            "We use the content match system to extract.",
            "Some masks are matched against this and the bit phrases used by these ads would actually help you overcome some of the.",
            "Or counter mismatch problems so we can use them as a big phrase as the candidate be phrases and also the content match system.",
            "Also give you some ranking that I won't go into detail."
        ],
        [
            "Self.",
            "So how do we evaluate a one of the goal here is that we really want to conduct a large scale evaluation without too much human annotation, so we hope to develop some automatic metric.",
            "And of course in this case automatic metric cannot be perfect.",
            "We just hope that we get something where the comparisons will be meaningful.",
            "So remember that in the when we talk about how to train a translation model, we said that we have a huge core parallel corpus with.",
            "Landing pages and their associated bid phrases so we could actually use holdout data in the same in the same manner and use them as a gold standard data.",
            "So for instance, in our case we construct a task focus with over 10,000 pages and for each page we have the set of bid phrases provided by the advertiser will call them the goal set and on average we have about 9 phrases per page and then for each.",
            "Of the bit phrases generated by a given system, we would be comparing them against this Golden set.",
            "So there's actually no existing metric that compares a phrase against a Golden set."
        ],
        [
            "We develope or we use two metrics or the first one is minimum at a distance where you compute the other distance between each produce phrase and each of the phrase in the Golden set and you took."
        ],
        [
            "At minimum, so essentially you're trying to see whether the candidates are phrases similar to any one of the goal phrase, but obviously this is not really covering the diversity inside the gold freight inside the Gulf reset, so we also developed a Rouge based metric, so rush is a metric that's similar to blue, which was developed for automatic machine translation evaluation.",
            "So in both.",
            "Summarization where Russia was developed and machine translation.",
            "They have shown this metric to calculate are pretty well with human judgments, so we adapted this metric for our case, which is essentially looking for overlap between our generate phrase and the goal phrase, and we go."
        ],
        [
            "For the entire set, so this is sort of a recall measure of trying to see how many of the different words inside the goal phrase set that we're getting back."
        ],
        [
            "OK, so here's the main comparison.",
            "We remember that we said we mentioned a couple of different candidate generation strong."
        ],
        [
            "She's the first one is just to get the phrases from the landing page itself."
        ],
        [
            "This could be expanded by the big phrases proposed by the content matches."
        ],
        [
            "System, or Alternatively, we can also expand that with new phrases generated by the translation basis."
        ],
        [
            "System.",
            "So paired up with these candidates, different candidate generations."
        ],
        [
            "Oh geez, we could use the simple cosine measure to rank the candidates.",
            "This is our baseline we."
        ],
        [
            "Could use the counter Match system ranking."
        ],
        [
            "We could also use SVM rank since it doesn't have its own generation strategy, its own candidate generation strategy.",
            "We give it the candidate sets proposed by the."
        ],
        [
            "The mesh system.",
            "And Lastly we can use the ranking provided by the translation."
        ],
        [
            "Model.",
            "So here's the main result.",
            "Remember that for the added distance based measure, the lower the better and in three in most of the cases.",
            "So I should mention that because for each landing page there could be multiple bid phrases that are reasonable, so we are evaluating this at different ranks where the added distance at runtime is just the average of the distance score for the top ten phrases proposed by the system.",
            "So except for rank one, the language translation based system performs the best and for the roof score you can see that across the board the translation based system is performing better than everyone else.",
            "So this is saying that first of all, it doesn't take too many compared to the other method.",
            "It doesn't take too many operations to change a candidate phrase generated by our system into the gold one, and also it's covering the diversity."
        ],
        [
            "So to summarize, this is the first comparison that we were doing.",
            "Each system paired up with this native bid phrase candidate generation."
        ],
        [
            "We also compared difference bit generated phrase generation strategy by fixing on the same ranking function."
        ],
        [
            "And we also fixed the same bit phrase candidate generation strategy and compare different ranking function.",
            "And you see that the translation based model is actually good at."
        ],
        [
            "Both of the components.",
            "So here's the typical plot, showing that both of the components for the translation based methods, the language model itself and the translation model itself both contribute to the performance.",
            "You get better performance by using better language model.",
            "You get better performance by using better translate."
        ],
        [
            "Although.",
            "So here's some examples from our translation model, so you can see interesting translations like between just emoji into both magazine subscription or between ticket and flight.",
            "This just showing you how we are bridging the vocabulary."
        ],
        [
            "Match.",
            "OK, so the related work on the online advertising front we have quite a number of related work.",
            "Usually there are addressing a slightly different problem for from us, but nonetheless there will be things common themes underneath on the machine translation fronts are using the noisy channel model is quite common theme.",
            "It has been used for text summarization or paraphrase extraction and also there has been working incorporating this.",
            "As one of the features for contact contextual advertising."
        ],
        [
            "So in conclusion, first we developed several automatic methods to generate the phrases for online advertising.",
            "We examined two evaluation measures and across the board in pretty much most of the cases.",
            "The translation based model is outperforming the other methods, and this is because we were able to generate novel phrases and at the same time we are making them still relevant to the page.",
            "So this is the end of the talk.",
            "I think.",
            "So the reason we use IBM Model one is mainly because we don't really think the order information matter all that much.",
            "Do.",
            "So we didn't do comparison, but do you have any intuition on why the order information should matter?",
            "Verifying that farmers market speculators not the US, so I guess part of The thing is the if you see the evaluation metric which developed, they are essentially order order insensitive so.",
            "If we're using a more complicated model, it wouldn't show in the.",
            "Yeah.",
            "Sorry.",
            "Connect 200 this talk one of the things that online advertisers care about very much is how well these keywords off.",
            "You gotta modify.",
            "In addition to relevance you have is not all that problem.",
            "Figuring out how he.",
            "Value these keywords are as well, so in some of the cases I guess we separate these two issues.",
            "You generate the candidate and then you can re rank them.",
            "But as you can see in the general framework, if you want this could be part of the language model that you can prefer the ones with more or less monetary value.",
            "So yeah, the framework would actually support this if you have a good way of expressing the value.",
            "So do you think it would help to have some information about the synonyms and the relationships of words that the search engine was using?",
            "Or do you think you got that information incorporated from the query log training sets so?",
            "So we're hoping that I guess it's mostly in the translation training part of it that it should cover the reasonable parts of it.",
            "Sticker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mission this is joint work with our summer intern.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately suggests can be here, so I'll be giving the talk.",
                    "label": 0
                },
                {
                    "sent": "So in the previous talk you see that the notion of keywords is pretty or the notion of keywords or big phrases is pretty central to online advertising.",
                    "label": 0
                },
                {
                    "sent": "So in this talk will talk about how we actually generate them.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what the advertiser typically issue.",
                    "label": 0
                },
                {
                    "sent": "So the advertisers have some pages they're trying to attract users to in order to do this.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually need to provide a list of relevant speech phrases or keywords to the search engine so these are the words that they want to be.",
                    "label": 0
                },
                {
                    "sent": "These are essentially the queries that they want their ads to be shown for, and these are the phrases that they're willing to bid on.",
                    "label": 0
                },
                {
                    "sent": "So as you can probably see, this will be a pretty labor intensive process, especially if you have 10s of thousands landing pages to deal with.",
                    "label": 0
                },
                {
                    "sent": "There's some on line.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Shoes are such as keyword suggestion that help you automate this process.",
                    "label": 0
                },
                {
                    "sent": "Before keyword suggestion, you need to provide some feet phrases to begin with, and there's also some potential concept drift.",
                    "label": 0
                },
                {
                    "sent": "So even in this case, if you're handling really 10s of thousands of pages to provide a RC seed phrase for each one of them can still be pretty labor intensive.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to see can we leverage the kind of data we have and further automate this process.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's our problem.",
                    "label": 0
                },
                {
                    "sent": "We start with a landing page.",
                    "label": 1
                },
                {
                    "sent": "In many cases is a web page describing some product and we want to automatically generate bid phrases.",
                    "label": 0
                },
                {
                    "sent": "Or these are the phrases that are supposed to be relevant to this page and potentially the advertisers might be willing to bid on.",
                    "label": 0
                },
                {
                    "sent": "So, is this a difficult problem?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You might wonder that maybe you can just try to get the most informative phrase out of the landing.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Page.",
                    "label": 0
                },
                {
                    "sent": "We did a analysis of the corpus.",
                    "label": 0
                },
                {
                    "sent": "We have an.",
                    "label": 0
                },
                {
                    "sent": "We find that in 96% of the time a landing page would be associated with at least one bit phrase that's actually not in the page, right?",
                    "label": 1
                },
                {
                    "sent": "So if you're limiting yourself to only pages available to only phrases available on the page, you will be losing many of the valid phrases.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then you would think how about we just back up towards so?",
                    "label": 0
                },
                {
                    "sent": "First of all, what we really need are the phrases.",
                    "label": 0
                },
                {
                    "sent": "So if you're just getting worse.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Although the page you need some good ways to actually mix and match them, so you still come up with value phrases.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Secondly, even when you back up to the word level, we find that many of the words in the bit phrases don't appear on the page either.",
                    "label": 0
                },
                {
                    "sent": "OK, so this probably by now looks like a challenging problem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the high high level overview of our approach.",
                    "label": 0
                },
                {
                    "sent": "This is essentially a two phase two phase approach.",
                    "label": 0
                },
                {
                    "sent": "In the first step, we generate the candidate bit phrases will introduce a couple of different approaches to this, and the main goal here is that you need to be the main requirement is that you really need to be able to generate novel phrases and some in some cases they need to include novel words that are not present on the page and in the second stage.",
                    "label": 1
                },
                {
                    "sent": "We'll be ranking these candidates according to some criteria.",
                    "label": 0
                },
                {
                    "sent": "Mostly we care about two things.",
                    "label": 1
                },
                {
                    "sent": "First, this phrase needs to be relevant to the page, and Secondly, this phrase needs to resemble queries in some way.",
                    "label": 0
                },
                {
                    "sent": "They can't just be random phrases.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we start with the criterion we have for the second stage, and we try to think what we what would be a good way to combine these two requirements, that is phrases being relevant.",
                    "label": 0
                },
                {
                    "sent": "And phrases being valid.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We would think about a translation based approach that is the problem of generating the bid phrases is now the problem of doing the monolingual translation from the page into the bit phrase and the typical approach taken in statistical machine translation is a noisy channel approach which flip this process.",
                    "label": 0
                },
                {
                    "sent": "So you try to imagine you're generating a landing page out of a bit phrase, and given this generative model you will then try to flip this.",
                    "label": 1
                },
                {
                    "sent": "Back into your original problem, which is trying to locate the most likely be phrases that have generated the page.",
                    "label": 0
                },
                {
                    "sent": "So here's the overview of the generative model.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First you start with some big phrases according to some language model that tell you what are good phrases and what not.",
                    "label": 0
                },
                {
                    "sent": "Good phrases and then the big phrase goes through the translation mode.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which gives you some probability of each bit phrase word being translated into a landing page word, and this generate the page for you.",
                    "label": 1
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "Now if we have the both the language model and the translation model estimated in some ways.",
                    "label": 1
                },
                {
                    "sent": "Then the ranking part is actually easy.",
                    "label": 0
                },
                {
                    "sent": "You just flip this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Process.",
                    "label": 0
                },
                {
                    "sent": "An you would suppose you are given both the landing page and some candidate phrases will talk about how we generate the candidate phrases later.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have both of those.",
                    "label": 0
                },
                {
                    "sent": "Then with the help of both language model and the translation model, essentially you score each candidate bid phrase according to the probability of the bid phrase given by the language model times the probability of the page being generated from the phrase so.",
                    "label": 0
                },
                {
                    "sent": "You can then rank the list of candidate phrases according to the score and as you can see by this combination of the probability of the bid phrase and the probability of the landing page are given a bit phrase, we are satisfying the two criterion.",
                    "label": 1
                },
                {
                    "sent": "That is, the phrase needs to look like a query an.",
                    "label": 0
                },
                {
                    "sent": "That's the phrase needs to be somehow relevant to the page.",
                    "label": 0
                },
                {
                    "sent": "So how do we actually estimate these models?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The language model should be fairly easy because as we mentioned here, we mostly just want to require the bid phrases looking like the queries.",
                    "label": 0
                },
                {
                    "sent": "So we are estimating a bigram language model with a back up to unigram based on the huge query corpus sampled from our web search log.",
                    "label": 1
                },
                {
                    "sent": "As you can see, using unigram model, you're essentially trying to see whether a word is likely to have appeared as part of a query and bigram part give you constraints.",
                    "label": 0
                },
                {
                    "sent": "Which word are likely to Co occur in a query rather than putting random words together?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the estimation of the translation model is slightly more complicated if you're familiar with the statistical machine translation literature.",
                    "label": 0
                },
                {
                    "sent": "This is essentially IBM Model 1.",
                    "label": 1
                },
                {
                    "sent": "If you don't know much about it, then essentially this is estimating a big translation model of word pairs, and the idea is to maximize the likelihood of the observed parallel data.",
                    "label": 1
                },
                {
                    "sent": "An in our case, the parallel data is the bit phrase learning page pairs, which we obviously have.",
                    "label": 0
                },
                {
                    "sent": "A lot of that we can utilize US training data.",
                    "label": 0
                },
                {
                    "sent": "So there are some little tricks you need to do to make it work in this scenario, because machine translation is essentially between tax bands with comparable length an in our case.",
                    "label": 0
                },
                {
                    "sent": "Obviously the landing page is much longer than the bit phrase and a lot of the content on the landing page may not be relevant for the bit.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one thing is we do need to add the null token which are people in SMT to use an.",
                    "label": 1
                },
                {
                    "sent": "In their case they use the null token to account for words that are valid in one language but don't have a corresponding counterpart in the other language.",
                    "label": 0
                },
                {
                    "sent": "In our case this is mostly to account for the irrelevant words on the given page.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the other thing we need to do is to incorporate importance of words in the page, particularly as we all know in the HTML page.",
                    "label": 1
                },
                {
                    "sent": "Usually words in titles or URLs are more important than just a random words in the body.",
                    "label": 0
                },
                {
                    "sent": "So we have a notion of importance weight associated with each word and we are putting that into the probability weighting, which essentially is trying to duplicate.",
                    "label": 0
                },
                {
                    "sent": "The words that are supposed to be important so that they actually count more when you look for the alignments.",
                    "label": 0
                },
                {
                    "sent": "OK, so with these two models estimated now if you have a selection of candidate phrases, we would actually be able to rank them.",
                    "label": 0
                },
                {
                    "sent": "But how do we generate the candidate?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "Big phrases, so theoretically all the words in the prologue can be candidates, but clearly to rank all the phrases in the choir log would be inefficient.",
                    "label": 1
                },
                {
                    "sent": "So in the first strategy we have, we build a candidate set containing only the phrases that appear in the landing page.",
                    "label": 1
                },
                {
                    "sent": "That is, we iterate phrases of different lines inside the page.",
                    "label": 0
                },
                {
                    "sent": "So clearly this would have the downside of not generating.",
                    "label": 0
                },
                {
                    "sent": "Now will be phrases.",
                    "label": 0
                },
                {
                    "sent": "And as we mentioned before this.",
                    "label": 0
                },
                {
                    "sent": "Will not be covering all the valid phrases, so the other approach, the strategy number two we take is to further expand the set of learning page is the set of candidate bit phrases with novel phrases that we can generate using the translation model.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is to use salient words, and by salient we're just ranking words according to the weight we mentioned on the previous slides.",
                    "label": 1
                },
                {
                    "sent": "We took the salient words on the page.",
                    "label": 0
                },
                {
                    "sent": "And we generate the most likely translations of them according to the translation model, and then we make some together to generate novel phrases.",
                    "label": 0
                },
                {
                    "sent": "OK, so with this we explained how the translation based model would work, how it would help us generate novel phrases, how it would help us rank.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some of the alternative methods that will be comparing.",
                    "label": 1
                },
                {
                    "sent": "First, we introduce this baseline, which essentially you use the phrases you extract out of the page and you just compute cosine similarity between this between this phrase and the landing page.",
                    "label": 1
                },
                {
                    "sent": "And then we can also try to use a discriminative system as the ranking system.",
                    "label": 0
                },
                {
                    "sent": "Note that for discriminative subsystem you cannot really generate any phrases.",
                    "label": 0
                },
                {
                    "sent": "It will depend it'll have to depend on some other candidate generation method.",
                    "label": 0
                },
                {
                    "sent": "But once the candidates are generated, we could rank these candidates using this or SVM rank where features include things like word overlap for cosine similarity between a bit phrase and the landing page.",
                    "label": 0
                },
                {
                    "sent": "And where did the words in the candidate be phrase appear so long?",
                    "label": 1
                },
                {
                    "sent": "And Lastly, we also compared against the system that's built on essentially a content match system, so a content match system is trying to find a adds to put onto a web page.",
                    "label": 0
                },
                {
                    "sent": "So now we kind of pretend, then the landing page is the web page on which you want to put on some ads.",
                    "label": 0
                },
                {
                    "sent": "We use the content match system to extract.",
                    "label": 0
                },
                {
                    "sent": "Some masks are matched against this and the bit phrases used by these ads would actually help you overcome some of the.",
                    "label": 0
                },
                {
                    "sent": "Or counter mismatch problems so we can use them as a big phrase as the candidate be phrases and also the content match system.",
                    "label": 0
                },
                {
                    "sent": "Also give you some ranking that I won't go into detail.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Self.",
                    "label": 0
                },
                {
                    "sent": "So how do we evaluate a one of the goal here is that we really want to conduct a large scale evaluation without too much human annotation, so we hope to develop some automatic metric.",
                    "label": 0
                },
                {
                    "sent": "And of course in this case automatic metric cannot be perfect.",
                    "label": 0
                },
                {
                    "sent": "We just hope that we get something where the comparisons will be meaningful.",
                    "label": 0
                },
                {
                    "sent": "So remember that in the when we talk about how to train a translation model, we said that we have a huge core parallel corpus with.",
                    "label": 0
                },
                {
                    "sent": "Landing pages and their associated bid phrases so we could actually use holdout data in the same in the same manner and use them as a gold standard data.",
                    "label": 1
                },
                {
                    "sent": "So for instance, in our case we construct a task focus with over 10,000 pages and for each page we have the set of bid phrases provided by the advertiser will call them the goal set and on average we have about 9 phrases per page and then for each.",
                    "label": 1
                },
                {
                    "sent": "Of the bit phrases generated by a given system, we would be comparing them against this Golden set.",
                    "label": 0
                },
                {
                    "sent": "So there's actually no existing metric that compares a phrase against a Golden set.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We develope or we use two metrics or the first one is minimum at a distance where you compute the other distance between each produce phrase and each of the phrase in the Golden set and you took.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At minimum, so essentially you're trying to see whether the candidates are phrases similar to any one of the goal phrase, but obviously this is not really covering the diversity inside the gold freight inside the Gulf reset, so we also developed a Rouge based metric, so rush is a metric that's similar to blue, which was developed for automatic machine translation evaluation.",
                    "label": 0
                },
                {
                    "sent": "So in both.",
                    "label": 0
                },
                {
                    "sent": "Summarization where Russia was developed and machine translation.",
                    "label": 0
                },
                {
                    "sent": "They have shown this metric to calculate are pretty well with human judgments, so we adapted this metric for our case, which is essentially looking for overlap between our generate phrase and the goal phrase, and we go.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the entire set, so this is sort of a recall measure of trying to see how many of the different words inside the goal phrase set that we're getting back.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's the main comparison.",
                    "label": 0
                },
                {
                    "sent": "We remember that we said we mentioned a couple of different candidate generation strong.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She's the first one is just to get the phrases from the landing page itself.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This could be expanded by the big phrases proposed by the content matches.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System, or Alternatively, we can also expand that with new phrases generated by the translation basis.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System.",
                    "label": 0
                },
                {
                    "sent": "So paired up with these candidates, different candidate generations.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh geez, we could use the simple cosine measure to rank the candidates.",
                    "label": 0
                },
                {
                    "sent": "This is our baseline we.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Could use the counter Match system ranking.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We could also use SVM rank since it doesn't have its own generation strategy, its own candidate generation strategy.",
                    "label": 0
                },
                {
                    "sent": "We give it the candidate sets proposed by the.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The mesh system.",
                    "label": 0
                },
                {
                    "sent": "And Lastly we can use the ranking provided by the translation.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "So here's the main result.",
                    "label": 0
                },
                {
                    "sent": "Remember that for the added distance based measure, the lower the better and in three in most of the cases.",
                    "label": 0
                },
                {
                    "sent": "So I should mention that because for each landing page there could be multiple bid phrases that are reasonable, so we are evaluating this at different ranks where the added distance at runtime is just the average of the distance score for the top ten phrases proposed by the system.",
                    "label": 0
                },
                {
                    "sent": "So except for rank one, the language translation based system performs the best and for the roof score you can see that across the board the translation based system is performing better than everyone else.",
                    "label": 0
                },
                {
                    "sent": "So this is saying that first of all, it doesn't take too many compared to the other method.",
                    "label": 0
                },
                {
                    "sent": "It doesn't take too many operations to change a candidate phrase generated by our system into the gold one, and also it's covering the diversity.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize, this is the first comparison that we were doing.",
                    "label": 0
                },
                {
                    "sent": "Each system paired up with this native bid phrase candidate generation.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also compared difference bit generated phrase generation strategy by fixing on the same ranking function.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also fixed the same bit phrase candidate generation strategy and compare different ranking function.",
                    "label": 0
                },
                {
                    "sent": "And you see that the translation based model is actually good at.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Both of the components.",
                    "label": 0
                },
                {
                    "sent": "So here's the typical plot, showing that both of the components for the translation based methods, the language model itself and the translation model itself both contribute to the performance.",
                    "label": 1
                },
                {
                    "sent": "You get better performance by using better language model.",
                    "label": 1
                },
                {
                    "sent": "You get better performance by using better translate.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Although.",
                    "label": 0
                },
                {
                    "sent": "So here's some examples from our translation model, so you can see interesting translations like between just emoji into both magazine subscription or between ticket and flight.",
                    "label": 0
                },
                {
                    "sent": "This just showing you how we are bridging the vocabulary.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Match.",
                    "label": 0
                },
                {
                    "sent": "OK, so the related work on the online advertising front we have quite a number of related work.",
                    "label": 1
                },
                {
                    "sent": "Usually there are addressing a slightly different problem for from us, but nonetheless there will be things common themes underneath on the machine translation fronts are using the noisy channel model is quite common theme.",
                    "label": 1
                },
                {
                    "sent": "It has been used for text summarization or paraphrase extraction and also there has been working incorporating this.",
                    "label": 0
                },
                {
                    "sent": "As one of the features for contact contextual advertising.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, first we developed several automatic methods to generate the phrases for online advertising.",
                    "label": 1
                },
                {
                    "sent": "We examined two evaluation measures and across the board in pretty much most of the cases.",
                    "label": 0
                },
                {
                    "sent": "The translation based model is outperforming the other methods, and this is because we were able to generate novel phrases and at the same time we are making them still relevant to the page.",
                    "label": 0
                },
                {
                    "sent": "So this is the end of the talk.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "So the reason we use IBM Model one is mainly because we don't really think the order information matter all that much.",
                    "label": 0
                },
                {
                    "sent": "Do.",
                    "label": 0
                },
                {
                    "sent": "So we didn't do comparison, but do you have any intuition on why the order information should matter?",
                    "label": 0
                },
                {
                    "sent": "Verifying that farmers market speculators not the US, so I guess part of The thing is the if you see the evaluation metric which developed, they are essentially order order insensitive so.",
                    "label": 0
                },
                {
                    "sent": "If we're using a more complicated model, it wouldn't show in the.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Connect 200 this talk one of the things that online advertisers care about very much is how well these keywords off.",
                    "label": 0
                },
                {
                    "sent": "You gotta modify.",
                    "label": 0
                },
                {
                    "sent": "In addition to relevance you have is not all that problem.",
                    "label": 0
                },
                {
                    "sent": "Figuring out how he.",
                    "label": 0
                },
                {
                    "sent": "Value these keywords are as well, so in some of the cases I guess we separate these two issues.",
                    "label": 0
                },
                {
                    "sent": "You generate the candidate and then you can re rank them.",
                    "label": 0
                },
                {
                    "sent": "But as you can see in the general framework, if you want this could be part of the language model that you can prefer the ones with more or less monetary value.",
                    "label": 0
                },
                {
                    "sent": "So yeah, the framework would actually support this if you have a good way of expressing the value.",
                    "label": 0
                },
                {
                    "sent": "So do you think it would help to have some information about the synonyms and the relationships of words that the search engine was using?",
                    "label": 0
                },
                {
                    "sent": "Or do you think you got that information incorporated from the query log training sets so?",
                    "label": 0
                },
                {
                    "sent": "So we're hoping that I guess it's mostly in the translation training part of it that it should cover the reasonable parts of it.",
                    "label": 0
                },
                {
                    "sent": "Sticker again.",
                    "label": 0
                }
            ]
        }
    }
}