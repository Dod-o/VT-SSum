{
    "id": "qoofqfcpw2cejxyinpzhjharzwztyvb4",
    "title": "A note on Inference for reaction kinetics with monomolecular reactions",
    "info": {
        "author": [
            "Manfred Opper, Department of Artificial Intelligence, TU Berlin"
        ],
        "published": "Nov. 8, 2010",
        "recorded": "October 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/mlsb2010_opper_ano/",
    "segmentation": [
        [
            "This is ongoing work with Andrea.",
            "Cerruto is here in the audience and we are from Berlin in the Computer science Department, but actually our background is more physics and we call this a note because it's not about a general method but about a method that is applicable, hopefully for a smaller class of systems, maybe not without interest for systems biology, so this is again about parameter estimation and we had talks yesterday.",
            "And the previous talk was about parameter estimation, but in the present case we're interested in stochastic dynamics so that."
        ],
        [
            "It means if we are describing the system now really by a discrete number of molecules, we have D types of molecules, N is theirs respective number in the system, and we assume that we have a Markovian dynamics.",
            "So we really think about we have only a small number of molecules such that stochastic city is of relevance.",
            "So we think that the probability of finding the system in state in prime.",
            "Having been in state N at time T is changing with a rate function F Theta that is sort of encodes the properties of the system, so that's the rates and well, given the rates, we know that the system, the state of the system at least, well, the probability of finding the system in a certain state is given by the master equation, and very often in chemical kinetics we assume.",
            "That this is given by mass action kinetics.",
            "Well, I don't want to go into too much detail, but the question is again, how can we do parameter inference in this case?",
            "Parameters would be rate constants in front of these individual reactions."
        ],
        [
            "So the question again, having noisy observations of the stochastic process at certain times, TI discrete times TI would like to, among other things, of course like to estimate systems parameters that are parts of that rate functions well.",
            "Of course we could say, let's do.",
            "Let's do likelihood estimation, and the likelihood would be something like that.",
            "That would be the probability of the data given the parameter Theta, and that would be.",
            "An expectation overall, the path of the stochastic process and the expectation is over that product.",
            "Assuming that the noise is is IID, it would we would have to compute such an expectation, and this is usually, well, we can't do it exactly, so there's a variety of methods on the market and I."
        ],
        [
            "If chosen for here too well without any citations, but essentially methods that would be exact if we run the algorithm long enough would be a Monte Carlo sampling based on the posterior process and means the process given the data.",
            "And of course it's not an entirely simple problem.",
            "We have to come up usually with interesting proposals for a Markov chain Monte Carlo, well, there's a certain simplification if we think about.",
            "Approximating the mark of jump process, forgetting about the discreteness of the molecule numbers, but still wanting to have fluctuations.",
            "So we approximate them by diffusion approximation.",
            "Again, there are Montecarlo schemes for doing that.",
            "Well, these two types of approaches are innocence exact.",
            "If we run them long enough then are simpler, usually faster approximations.",
            "Ones is one is based on the idea of a week or a linear noise approximation essentially.",
            "Related to linearizations, using together with ideas of.",
            "I said of continuous time Kalman filters related to something that we've heard in the previous talk and in their kind of machine learning ideas.",
            "I would call them because they are based on variational mean field approach variational techniques, where you actually try to approximate the complicated process by by something by a simpler process and optimize the parameters of that simpler process.",
            "And we have heard an example yesterday in under Real Corners talk.",
            "So these are kind of general methods because they can be applied to two systems with arbitrary rate constants answered.",
            "Our question was well.",
            "These two are not exact, but usually maybe faster and in this sense more interesting.",
            "But the question is all these types of approximation that come from machine learning are very often well we don't know in advance how good they are, and so we thought about looking at simpler classes of models where maybe you can develop somehow methods that you can better understand.",
            "So that's the motivation before we come up with a general kind of thing.",
            "A general approximation, let's play with something simpler and under.",
            "Extend possibly understand what it does, so the simpler type of systems that we are interested in."
        ],
        [
            "Is the system with well monomonac mono molecular reactions and those are defined by somewhat simpler rules, so the process that you can have is you can get one more molecule in in one state, but you lose a molecule in another state.",
            "That means just molecules exchange their identity's.",
            "You can lose, you can create a molecule and you can annihilate a molecule.",
            "Then it's gone.",
            "And these are the corresponding rates and the rates are.",
            "Well, at most linear in the present number of molecules that you have.",
            "So this linearity together with the change of only plus or minus one defines these type of monomolecular reaction systems.",
            "That means we don't have real chemical reactions.",
            "So there's no two molecules bouncing together and producing a third one."
        ],
        [
            "So if you look at this kind of thing where we that would be kind of a non trivial application of these type of systems was discussed today and the dynamics of the density of a certain protein in in in.",
            "In Drosophila where you look at the process that this protein is fed in at a certain point at a spatial point and now space in a compartment model sort of denotes the different.",
            "Types of molecules.",
            "So where a molecule is defines well it's type.",
            "So you feed in molecules.",
            "At a certain point you molecules will degrade, so you lose them and molecules exchange their type by going to neighboring positions.",
            "And this is this is a forbidden reaction.",
            "We don't treat them in in this simplified model.",
            "So what can we say about these simplified types of system?"
        ],
        [
            "Well, first of all, some known results if we just look at the expected number of molecules not thinking about inference or anything, we know the parameters, then these Avaya very simple.",
            "Actually system of linear equations, so this is well known.",
            "See ijr.",
            "Again these rate parameters, but you can show something more and it was shown in a nice paper by by a yangqin who singer.",
            "That you actually can compute the transition probabilities for this for the Markov process.",
            "For a general system of that type, and you can characterize it as a default convolution, D is the number of possible types of molecules that you have in the system would correspond to the number of compartments in the model.",
            "The fold convolution of multivariate Poisson and multinomial probabilities.",
            "So there is a is a nice theorem that you can prove and it's beautiful, but again I think these these many.",
            "Essentially the convolution of that many distributions makes it not easily tractable when you want to do inference with that result.",
            "So it's a general result.",
            "You can write down a formula, but the question is how you get numbers out of it, and so this is probably not an.",
            "Terribly."
        ],
        [
            "Useful if the system is sufficiently large, so let's go back to the question of what we wanted to do.",
            "If we could do it.",
            "So we wanted to do computation of a likelihood of the data given the system parameter.",
            "That's again, expectation of well of the likelihood, and assuming now we have Gaussian noise, that means that the wise the observations are corrupted.",
            "Noisy versions of the system state.",
            "That would be the likelihood that we would like to compute.",
            "Well, this is not quite what we can compute, but we can compute something well, slightly different, and is something similar.",
            "We can compute this expectation when the variable N appears only linearly in the exponent, so we see there's something quadratic here here.",
            "It's only linear, and actually you could call that.",
            "That's the the moment generating function, and that's something you can actually compute analytically.",
            "And somehow then we have to go from here.",
            "Two there.",
            "So to compute that."
        ],
        [
            "So we tried that.",
            "We define something that's related to that.",
            "So this PSI function is the expectation of.",
            "Well, it's the likelihood for all the data that are in the future of T. An If I condition and condition on the state N. So this type of thing, well, you conditioned on an initial can you conditioned on the number of molecules at a certain time T and such objects.",
            "Usually solutions of the so called Kolmogorov backward equation.",
            "Well, some people have seen that before, so they might believe me.",
            "So this type of Kolmogorov backward equation is is this.",
            "Is this a base?",
            "It an actually we have an end condition.",
            "If well, we're at the last observation.",
            "Then there's no observations left in this exponent, and we have a one and we get also jump conditions anytime.",
            "We go backward in time and there is a data point.",
            "Then this PSI function will jump by this amount.",
            "So this is the the equations that we need to consider and well for."
        ],
        [
            "Is money molecular kind of thing?",
            "We can solve it analytically.",
            "Actually, it turns out that this function is solved by is very simple linear thing in Endwell exponential of a linear thing in N. And if you plug this in.",
            "Into the backward equation you can solve.",
            "You can see that A&B based certain types of well essentially linear odies which you can solve by hand, and it turns out you can compute this type of function, essentially linear by by linear operations.",
            "So you have something like matrix exponentials and things that, well Matlab does for you anyhow and so you have a way of recursively computing.",
            "The likelihood this pseudo likelihood as I would call it so you can recursively compute that for any given Phi.",
            "Now how?"
        ],
        [
            "Having gone so far.",
            "This is not what we want to compute, but what we like to compute is essentially this quantity, and here comes in a nice variational trick that has been used in the machine learning community a couple of times, so I guess Tommy Ocular was one of the people who worked with duality transformation, so I want something quadratic and I can do something linear.",
            "So let's introduce a FI and use that operation so it's essentially's.",
            "Probably something like this genre transform probably so if you do that type of thing so you relate something quadratically in an something linearly, and then so if you plug this result into into that one and exchange the Max operation operation with the expectation, well, you interchange it.",
            "You get an inequality abound of the exact thing in terms of the thing that is an approximation.",
            "Well, we can do that.",
            "And So what we have to do is we have to maximize that expression in order to get the best lower bound to that negative log likelihood.",
            "So this is the guy that we want, but we can only bound it, and that's kind of the machine learning type of trick.",
            "Usually people applied well.",
            "They often people get upper bounds.",
            "In this case we get a lower bound, so this is used as an approximation.",
            "For the thing that we want, that means for an algorithm, what we would have to do is for any parameter we would have to optimize this FI.",
            "So in an inner loop you have to optimize files and well this is a concave.",
            "This is concave in five, so actually there's only a single solution for that and then having for a fixed parameter optimized FI, we could still minimize that negative log likelihood with respect to the parameters or use it within a Bayesian procedure.",
            "So this is this kind of thing, right?",
            "Well, I have I gone 15 minutes or something.",
            "OK, good right.",
            "So this is the kind of thing that that she could do.",
            "Then, historically we have to say after submission summer came and other things.",
            "Well occupied us.",
            "So there was just a last minute last minute try of that."
        ],
        [
            "Algorithm on on some simulated data essentially on that type of compartment model, where we use eight compartments.",
            "Molecules are fed in.",
            "In the first in the first compartment, molecules can decay with a certain rate in every compartment, and they can diffuse between neighboring compartments.",
            "And this is just a single run that we managed to 22.",
            "To to get done.",
            "So we have three parameters in that model, a decay rate diffusion raid, Anna creation rate.",
            "And these were the true parameters that generated the data using Gillespie algorithm and these are the estimates.",
            "Well, they're not essentially bad, but of course we would have to do some statistics to see how well that would do when I average over many simulations and you can actually see the worst parameter is to creation one, but that can be easily understood because.",
            "The creation one?",
            "Well, let's only on a single point where all the other ones get data from everywhere from from all over from Allstate.",
            "So this is clear.",
            "Well now I could actually stop if I wanted and say, well, you know, in the future we will do all this and compare with everything.",
            "But well, maybe I'll just do three more slides because we can still get an idea what this approximation means by looking at.",
            "Um?"
        ],
        [
            "An exact representation of this likelihood, so the exact representation again, well, the exact expression is that, and I mentioned that this guy is just the generating functions for moments of the underlying stochastic process of what we want is to get the this essentially the probability out of the generating function, and that can be done by kind of a Fourier integral.",
            "So this is the exact answer we would have to do.",
            "A big Fourier integral, Welcare runs over all the observations and the fact that this is a is a vector denotes all the possible different types of molecules, so it would be a big integral that we would have to do in order to solve the problem exactly.",
            "And of course, there's a well known approximation in well in physics and statistics that says, well, we can try and approximate that integral using certain deformations of the path of integration in the complex plane.",
            "Well, there are many copies of complex planes, of course, because it's a multivariate integral and then actually look at take an approximation where this exponent with this integral is approximated by E to the exponent.",
            "Taken at the point where this is becoming stationary and if you look at this carefully, the stationary point is precisely this.",
            "This approximation that we have introduced before, so it's a part of what is called."
        ],
        [
            "Called the Saddle Point approximation to that integral and actually the first bit is the thing that I just mentioned.",
            "And if you want to do if you want to be a bit more accurate than you should also include the fluctuations around the saddle point and that would give you typically something that contains a determinant and so if you have solved your optimization problem then you should go and also take the matrix of 2nd derivatives which many solvers.",
            "Actually would give you so you can actually use them in order to get a slightly improved.",
            "Approximation, and now as I said, we should of course compare this to everything, and since we didn't have time to compare it to everything, so we could at least comparing to some example where you know the true answer.",
            "So it's always good to compare it to the truth and the truth."
        ],
        [
            "In this case, you can get the truth easily for a simple case where you don't have any molecules in the system in the beginning, and then if the system evolves then the probability of having the system at time T Anna state Y.",
            "So I assume now I have no the observations are noise free, so it's really I have to come to compute the probability of the state at time T. This is a multivariate.",
            "Plus on distribution where these guys are defined well enough using some matrix exponentials as I said, but the answer is a multivariate plus and now what we do with our approximation is, well, we use this auxiliary likelihood.",
            "Then we go through some optimization step and we get something which is well.",
            "If you compare this, the log of that with that, you might think this is kind of.",
            "This is some kind of."
        ],
        [
            "Stirling's approximation, actually it is the Stirling's approximation to the to the factorials.",
            "If you include the quadratic fluctuations around the saddle point, and then you might ask, well, this is probably not so bad because we know that the factorials that appear in the exact solution and the Stirling approximation, well, you know they not so bad if, for instance.",
            "If X is sufficiently large, X in this case is the number of molecules in a certain compartment, and now they don't have to be infinite.",
            "Well, we're nowhere.",
            "The fluctuations are gone and we would go to two ordinary rate equations, but I think this is not so bad.",
            "1 / 12 X 1 / 12 X plus one.",
            "So this is a classical result on the on the air of the steering Stirling approximation, so I think well, at least in this exactly solvable case the approximation together.",
            "With a with fluctuations around the saddle point would be not so bad, so I think this brings me then finally to the end of my talk I had, I tried to sell you a machine learning kind of trick for inference, inamona molecular system, and we discovered that actually this trick is equivalent to a saddle point approximation, But the saddle point approximation is not yet popular in machine learning.",
            "Maybe it will at some point."
        ],
        [
            "Then of course I have also plans for the future.",
            "We all have plans for the future.",
            "Among them is one, of course, comparing with everything we have other approximations that we can compare it to not only the truth so, but also we can try a full Bayesian approach.",
            "In that case we actually started doing that, so we get marginal posteriors by integrating approximately out other variables using Laplace's method, and then of course the nice thing is we can also run the system with infinitely many compartments.",
            "Well, of course we don't observe everything, but we sort of.",
            "We have observations that are smooth version, spatially smooth versions of the molecules and then really look at a stochastic reaction diffusion system.",
            "So all these matrix exponentials, well matrices become operators and things can be done.",
            "As long as it's linear, of course, this is something that we know that can be done because we had done it before in a in a in a week.",
            "Noise in a linear noise approximation, and this is something that I'm really interested in in because you could say well look, I mean, come on.",
            "This is monomolecular reactions.",
            "There's no really chemistry in here right now.",
            "Nothing interesting.",
            "Then.",
            "Of course, if you look at physics papers, they usually have.",
            "Well, you find some ideas of doing perturbation theory, especially for that cumulant generating function.",
            "But you can say, well, I have a solvable model.",
            "Of course the solver model is the monomolecular one, and if you tried to treat the true chemical reactions as perturbations, well I think I would love to have a go at it.",
            "And I know that cumulant generating functions are nice objects where you can try to do perturbation theory.",
            "Of course, I can't guarantee anything on that, but well, thank you, that's it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is ongoing work with Andrea.",
                    "label": 0
                },
                {
                    "sent": "Cerruto is here in the audience and we are from Berlin in the Computer science Department, but actually our background is more physics and we call this a note because it's not about a general method but about a method that is applicable, hopefully for a smaller class of systems, maybe not without interest for systems biology, so this is again about parameter estimation and we had talks yesterday.",
                    "label": 0
                },
                {
                    "sent": "And the previous talk was about parameter estimation, but in the present case we're interested in stochastic dynamics so that.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It means if we are describing the system now really by a discrete number of molecules, we have D types of molecules, N is theirs respective number in the system, and we assume that we have a Markovian dynamics.",
                    "label": 0
                },
                {
                    "sent": "So we really think about we have only a small number of molecules such that stochastic city is of relevance.",
                    "label": 1
                },
                {
                    "sent": "So we think that the probability of finding the system in state in prime.",
                    "label": 0
                },
                {
                    "sent": "Having been in state N at time T is changing with a rate function F Theta that is sort of encodes the properties of the system, so that's the rates and well, given the rates, we know that the system, the state of the system at least, well, the probability of finding the system in a certain state is given by the master equation, and very often in chemical kinetics we assume.",
                    "label": 0
                },
                {
                    "sent": "That this is given by mass action kinetics.",
                    "label": 1
                },
                {
                    "sent": "Well, I don't want to go into too much detail, but the question is again, how can we do parameter inference in this case?",
                    "label": 0
                },
                {
                    "sent": "Parameters would be rate constants in front of these individual reactions.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question again, having noisy observations of the stochastic process at certain times, TI discrete times TI would like to, among other things, of course like to estimate systems parameters that are parts of that rate functions well.",
                    "label": 1
                },
                {
                    "sent": "Of course we could say, let's do.",
                    "label": 0
                },
                {
                    "sent": "Let's do likelihood estimation, and the likelihood would be something like that.",
                    "label": 0
                },
                {
                    "sent": "That would be the probability of the data given the parameter Theta, and that would be.",
                    "label": 0
                },
                {
                    "sent": "An expectation overall, the path of the stochastic process and the expectation is over that product.",
                    "label": 0
                },
                {
                    "sent": "Assuming that the noise is is IID, it would we would have to compute such an expectation, and this is usually, well, we can't do it exactly, so there's a variety of methods on the market and I.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If chosen for here too well without any citations, but essentially methods that would be exact if we run the algorithm long enough would be a Monte Carlo sampling based on the posterior process and means the process given the data.",
                    "label": 0
                },
                {
                    "sent": "And of course it's not an entirely simple problem.",
                    "label": 0
                },
                {
                    "sent": "We have to come up usually with interesting proposals for a Markov chain Monte Carlo, well, there's a certain simplification if we think about.",
                    "label": 0
                },
                {
                    "sent": "Approximating the mark of jump process, forgetting about the discreteness of the molecule numbers, but still wanting to have fluctuations.",
                    "label": 0
                },
                {
                    "sent": "So we approximate them by diffusion approximation.",
                    "label": 1
                },
                {
                    "sent": "Again, there are Montecarlo schemes for doing that.",
                    "label": 0
                },
                {
                    "sent": "Well, these two types of approaches are innocence exact.",
                    "label": 0
                },
                {
                    "sent": "If we run them long enough then are simpler, usually faster approximations.",
                    "label": 1
                },
                {
                    "sent": "Ones is one is based on the idea of a week or a linear noise approximation essentially.",
                    "label": 0
                },
                {
                    "sent": "Related to linearizations, using together with ideas of.",
                    "label": 0
                },
                {
                    "sent": "I said of continuous time Kalman filters related to something that we've heard in the previous talk and in their kind of machine learning ideas.",
                    "label": 1
                },
                {
                    "sent": "I would call them because they are based on variational mean field approach variational techniques, where you actually try to approximate the complicated process by by something by a simpler process and optimize the parameters of that simpler process.",
                    "label": 0
                },
                {
                    "sent": "And we have heard an example yesterday in under Real Corners talk.",
                    "label": 0
                },
                {
                    "sent": "So these are kind of general methods because they can be applied to two systems with arbitrary rate constants answered.",
                    "label": 0
                },
                {
                    "sent": "Our question was well.",
                    "label": 0
                },
                {
                    "sent": "These two are not exact, but usually maybe faster and in this sense more interesting.",
                    "label": 0
                },
                {
                    "sent": "But the question is all these types of approximation that come from machine learning are very often well we don't know in advance how good they are, and so we thought about looking at simpler classes of models where maybe you can develop somehow methods that you can better understand.",
                    "label": 0
                },
                {
                    "sent": "So that's the motivation before we come up with a general kind of thing.",
                    "label": 0
                },
                {
                    "sent": "A general approximation, let's play with something simpler and under.",
                    "label": 0
                },
                {
                    "sent": "Extend possibly understand what it does, so the simpler type of systems that we are interested in.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the system with well monomonac mono molecular reactions and those are defined by somewhat simpler rules, so the process that you can have is you can get one more molecule in in one state, but you lose a molecule in another state.",
                    "label": 0
                },
                {
                    "sent": "That means just molecules exchange their identity's.",
                    "label": 0
                },
                {
                    "sent": "You can lose, you can create a molecule and you can annihilate a molecule.",
                    "label": 0
                },
                {
                    "sent": "Then it's gone.",
                    "label": 0
                },
                {
                    "sent": "And these are the corresponding rates and the rates are.",
                    "label": 0
                },
                {
                    "sent": "Well, at most linear in the present number of molecules that you have.",
                    "label": 0
                },
                {
                    "sent": "So this linearity together with the change of only plus or minus one defines these type of monomolecular reaction systems.",
                    "label": 1
                },
                {
                    "sent": "That means we don't have real chemical reactions.",
                    "label": 1
                },
                {
                    "sent": "So there's no two molecules bouncing together and producing a third one.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you look at this kind of thing where we that would be kind of a non trivial application of these type of systems was discussed today and the dynamics of the density of a certain protein in in in.",
                    "label": 1
                },
                {
                    "sent": "In Drosophila where you look at the process that this protein is fed in at a certain point at a spatial point and now space in a compartment model sort of denotes the different.",
                    "label": 0
                },
                {
                    "sent": "Types of molecules.",
                    "label": 0
                },
                {
                    "sent": "So where a molecule is defines well it's type.",
                    "label": 0
                },
                {
                    "sent": "So you feed in molecules.",
                    "label": 0
                },
                {
                    "sent": "At a certain point you molecules will degrade, so you lose them and molecules exchange their type by going to neighboring positions.",
                    "label": 0
                },
                {
                    "sent": "And this is this is a forbidden reaction.",
                    "label": 0
                },
                {
                    "sent": "We don't treat them in in this simplified model.",
                    "label": 0
                },
                {
                    "sent": "So what can we say about these simplified types of system?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, first of all, some known results if we just look at the expected number of molecules not thinking about inference or anything, we know the parameters, then these Avaya very simple.",
                    "label": 0
                },
                {
                    "sent": "Actually system of linear equations, so this is well known.",
                    "label": 0
                },
                {
                    "sent": "See ijr.",
                    "label": 0
                },
                {
                    "sent": "Again these rate parameters, but you can show something more and it was shown in a nice paper by by a yangqin who singer.",
                    "label": 0
                },
                {
                    "sent": "That you actually can compute the transition probabilities for this for the Markov process.",
                    "label": 0
                },
                {
                    "sent": "For a general system of that type, and you can characterize it as a default convolution, D is the number of possible types of molecules that you have in the system would correspond to the number of compartments in the model.",
                    "label": 0
                },
                {
                    "sent": "The fold convolution of multivariate Poisson and multinomial probabilities.",
                    "label": 1
                },
                {
                    "sent": "So there is a is a nice theorem that you can prove and it's beautiful, but again I think these these many.",
                    "label": 0
                },
                {
                    "sent": "Essentially the convolution of that many distributions makes it not easily tractable when you want to do inference with that result.",
                    "label": 0
                },
                {
                    "sent": "So it's a general result.",
                    "label": 0
                },
                {
                    "sent": "You can write down a formula, but the question is how you get numbers out of it, and so this is probably not an.",
                    "label": 0
                },
                {
                    "sent": "Terribly.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Useful if the system is sufficiently large, so let's go back to the question of what we wanted to do.",
                    "label": 0
                },
                {
                    "sent": "If we could do it.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to do computation of a likelihood of the data given the system parameter.",
                    "label": 0
                },
                {
                    "sent": "That's again, expectation of well of the likelihood, and assuming now we have Gaussian noise, that means that the wise the observations are corrupted.",
                    "label": 0
                },
                {
                    "sent": "Noisy versions of the system state.",
                    "label": 0
                },
                {
                    "sent": "That would be the likelihood that we would like to compute.",
                    "label": 1
                },
                {
                    "sent": "Well, this is not quite what we can compute, but we can compute something well, slightly different, and is something similar.",
                    "label": 0
                },
                {
                    "sent": "We can compute this expectation when the variable N appears only linearly in the exponent, so we see there's something quadratic here here.",
                    "label": 0
                },
                {
                    "sent": "It's only linear, and actually you could call that.",
                    "label": 0
                },
                {
                    "sent": "That's the the moment generating function, and that's something you can actually compute analytically.",
                    "label": 0
                },
                {
                    "sent": "And somehow then we have to go from here.",
                    "label": 0
                },
                {
                    "sent": "Two there.",
                    "label": 0
                },
                {
                    "sent": "So to compute that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we tried that.",
                    "label": 0
                },
                {
                    "sent": "We define something that's related to that.",
                    "label": 0
                },
                {
                    "sent": "So this PSI function is the expectation of.",
                    "label": 0
                },
                {
                    "sent": "Well, it's the likelihood for all the data that are in the future of T. An If I condition and condition on the state N. So this type of thing, well, you conditioned on an initial can you conditioned on the number of molecules at a certain time T and such objects.",
                    "label": 0
                },
                {
                    "sent": "Usually solutions of the so called Kolmogorov backward equation.",
                    "label": 1
                },
                {
                    "sent": "Well, some people have seen that before, so they might believe me.",
                    "label": 0
                },
                {
                    "sent": "So this type of Kolmogorov backward equation is is this.",
                    "label": 0
                },
                {
                    "sent": "Is this a base?",
                    "label": 0
                },
                {
                    "sent": "It an actually we have an end condition.",
                    "label": 1
                },
                {
                    "sent": "If well, we're at the last observation.",
                    "label": 0
                },
                {
                    "sent": "Then there's no observations left in this exponent, and we have a one and we get also jump conditions anytime.",
                    "label": 0
                },
                {
                    "sent": "We go backward in time and there is a data point.",
                    "label": 0
                },
                {
                    "sent": "Then this PSI function will jump by this amount.",
                    "label": 0
                },
                {
                    "sent": "So this is the the equations that we need to consider and well for.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is money molecular kind of thing?",
                    "label": 0
                },
                {
                    "sent": "We can solve it analytically.",
                    "label": 0
                },
                {
                    "sent": "Actually, it turns out that this function is solved by is very simple linear thing in Endwell exponential of a linear thing in N. And if you plug this in.",
                    "label": 0
                },
                {
                    "sent": "Into the backward equation you can solve.",
                    "label": 0
                },
                {
                    "sent": "You can see that A&B based certain types of well essentially linear odies which you can solve by hand, and it turns out you can compute this type of function, essentially linear by by linear operations.",
                    "label": 0
                },
                {
                    "sent": "So you have something like matrix exponentials and things that, well Matlab does for you anyhow and so you have a way of recursively computing.",
                    "label": 0
                },
                {
                    "sent": "The likelihood this pseudo likelihood as I would call it so you can recursively compute that for any given Phi.",
                    "label": 0
                },
                {
                    "sent": "Now how?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Having gone so far.",
                    "label": 0
                },
                {
                    "sent": "This is not what we want to compute, but what we like to compute is essentially this quantity, and here comes in a nice variational trick that has been used in the machine learning community a couple of times, so I guess Tommy Ocular was one of the people who worked with duality transformation, so I want something quadratic and I can do something linear.",
                    "label": 0
                },
                {
                    "sent": "So let's introduce a FI and use that operation so it's essentially's.",
                    "label": 0
                },
                {
                    "sent": "Probably something like this genre transform probably so if you do that type of thing so you relate something quadratically in an something linearly, and then so if you plug this result into into that one and exchange the Max operation operation with the expectation, well, you interchange it.",
                    "label": 0
                },
                {
                    "sent": "You get an inequality abound of the exact thing in terms of the thing that is an approximation.",
                    "label": 0
                },
                {
                    "sent": "Well, we can do that.",
                    "label": 0
                },
                {
                    "sent": "And So what we have to do is we have to maximize that expression in order to get the best lower bound to that negative log likelihood.",
                    "label": 0
                },
                {
                    "sent": "So this is the guy that we want, but we can only bound it, and that's kind of the machine learning type of trick.",
                    "label": 0
                },
                {
                    "sent": "Usually people applied well.",
                    "label": 0
                },
                {
                    "sent": "They often people get upper bounds.",
                    "label": 0
                },
                {
                    "sent": "In this case we get a lower bound, so this is used as an approximation.",
                    "label": 0
                },
                {
                    "sent": "For the thing that we want, that means for an algorithm, what we would have to do is for any parameter we would have to optimize this FI.",
                    "label": 0
                },
                {
                    "sent": "So in an inner loop you have to optimize files and well this is a concave.",
                    "label": 0
                },
                {
                    "sent": "This is concave in five, so actually there's only a single solution for that and then having for a fixed parameter optimized FI, we could still minimize that negative log likelihood with respect to the parameters or use it within a Bayesian procedure.",
                    "label": 0
                },
                {
                    "sent": "So this is this kind of thing, right?",
                    "label": 0
                },
                {
                    "sent": "Well, I have I gone 15 minutes or something.",
                    "label": 0
                },
                {
                    "sent": "OK, good right.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of thing that that she could do.",
                    "label": 0
                },
                {
                    "sent": "Then, historically we have to say after submission summer came and other things.",
                    "label": 0
                },
                {
                    "sent": "Well occupied us.",
                    "label": 0
                },
                {
                    "sent": "So there was just a last minute last minute try of that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Algorithm on on some simulated data essentially on that type of compartment model, where we use eight compartments.",
                    "label": 1
                },
                {
                    "sent": "Molecules are fed in.",
                    "label": 0
                },
                {
                    "sent": "In the first in the first compartment, molecules can decay with a certain rate in every compartment, and they can diffuse between neighboring compartments.",
                    "label": 0
                },
                {
                    "sent": "And this is just a single run that we managed to 22.",
                    "label": 0
                },
                {
                    "sent": "To to get done.",
                    "label": 0
                },
                {
                    "sent": "So we have three parameters in that model, a decay rate diffusion raid, Anna creation rate.",
                    "label": 0
                },
                {
                    "sent": "And these were the true parameters that generated the data using Gillespie algorithm and these are the estimates.",
                    "label": 0
                },
                {
                    "sent": "Well, they're not essentially bad, but of course we would have to do some statistics to see how well that would do when I average over many simulations and you can actually see the worst parameter is to creation one, but that can be easily understood because.",
                    "label": 0
                },
                {
                    "sent": "The creation one?",
                    "label": 0
                },
                {
                    "sent": "Well, let's only on a single point where all the other ones get data from everywhere from from all over from Allstate.",
                    "label": 0
                },
                {
                    "sent": "So this is clear.",
                    "label": 0
                },
                {
                    "sent": "Well now I could actually stop if I wanted and say, well, you know, in the future we will do all this and compare with everything.",
                    "label": 0
                },
                {
                    "sent": "But well, maybe I'll just do three more slides because we can still get an idea what this approximation means by looking at.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An exact representation of this likelihood, so the exact representation again, well, the exact expression is that, and I mentioned that this guy is just the generating functions for moments of the underlying stochastic process of what we want is to get the this essentially the probability out of the generating function, and that can be done by kind of a Fourier integral.",
                    "label": 1
                },
                {
                    "sent": "So this is the exact answer we would have to do.",
                    "label": 0
                },
                {
                    "sent": "A big Fourier integral, Welcare runs over all the observations and the fact that this is a is a vector denotes all the possible different types of molecules, so it would be a big integral that we would have to do in order to solve the problem exactly.",
                    "label": 0
                },
                {
                    "sent": "And of course, there's a well known approximation in well in physics and statistics that says, well, we can try and approximate that integral using certain deformations of the path of integration in the complex plane.",
                    "label": 0
                },
                {
                    "sent": "Well, there are many copies of complex planes, of course, because it's a multivariate integral and then actually look at take an approximation where this exponent with this integral is approximated by E to the exponent.",
                    "label": 0
                },
                {
                    "sent": "Taken at the point where this is becoming stationary and if you look at this carefully, the stationary point is precisely this.",
                    "label": 0
                },
                {
                    "sent": "This approximation that we have introduced before, so it's a part of what is called.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Called the Saddle Point approximation to that integral and actually the first bit is the thing that I just mentioned.",
                    "label": 1
                },
                {
                    "sent": "And if you want to do if you want to be a bit more accurate than you should also include the fluctuations around the saddle point and that would give you typically something that contains a determinant and so if you have solved your optimization problem then you should go and also take the matrix of 2nd derivatives which many solvers.",
                    "label": 0
                },
                {
                    "sent": "Actually would give you so you can actually use them in order to get a slightly improved.",
                    "label": 0
                },
                {
                    "sent": "Approximation, and now as I said, we should of course compare this to everything, and since we didn't have time to compare it to everything, so we could at least comparing to some example where you know the true answer.",
                    "label": 0
                },
                {
                    "sent": "So it's always good to compare it to the truth and the truth.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this case, you can get the truth easily for a simple case where you don't have any molecules in the system in the beginning, and then if the system evolves then the probability of having the system at time T Anna state Y.",
                    "label": 0
                },
                {
                    "sent": "So I assume now I have no the observations are noise free, so it's really I have to come to compute the probability of the state at time T. This is a multivariate.",
                    "label": 1
                },
                {
                    "sent": "Plus on distribution where these guys are defined well enough using some matrix exponentials as I said, but the answer is a multivariate plus and now what we do with our approximation is, well, we use this auxiliary likelihood.",
                    "label": 0
                },
                {
                    "sent": "Then we go through some optimization step and we get something which is well.",
                    "label": 0
                },
                {
                    "sent": "If you compare this, the log of that with that, you might think this is kind of.",
                    "label": 0
                },
                {
                    "sent": "This is some kind of.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stirling's approximation, actually it is the Stirling's approximation to the to the factorials.",
                    "label": 0
                },
                {
                    "sent": "If you include the quadratic fluctuations around the saddle point, and then you might ask, well, this is probably not so bad because we know that the factorials that appear in the exact solution and the Stirling approximation, well, you know they not so bad if, for instance.",
                    "label": 1
                },
                {
                    "sent": "If X is sufficiently large, X in this case is the number of molecules in a certain compartment, and now they don't have to be infinite.",
                    "label": 0
                },
                {
                    "sent": "Well, we're nowhere.",
                    "label": 0
                },
                {
                    "sent": "The fluctuations are gone and we would go to two ordinary rate equations, but I think this is not so bad.",
                    "label": 1
                },
                {
                    "sent": "1 / 12 X 1 / 12 X plus one.",
                    "label": 0
                },
                {
                    "sent": "So this is a classical result on the on the air of the steering Stirling approximation, so I think well, at least in this exactly solvable case the approximation together.",
                    "label": 0
                },
                {
                    "sent": "With a with fluctuations around the saddle point would be not so bad, so I think this brings me then finally to the end of my talk I had, I tried to sell you a machine learning kind of trick for inference, inamona molecular system, and we discovered that actually this trick is equivalent to a saddle point approximation, But the saddle point approximation is not yet popular in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Maybe it will at some point.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then of course I have also plans for the future.",
                    "label": 0
                },
                {
                    "sent": "We all have plans for the future.",
                    "label": 1
                },
                {
                    "sent": "Among them is one, of course, comparing with everything we have other approximations that we can compare it to not only the truth so, but also we can try a full Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "In that case we actually started doing that, so we get marginal posteriors by integrating approximately out other variables using Laplace's method, and then of course the nice thing is we can also run the system with infinitely many compartments.",
                    "label": 0
                },
                {
                    "sent": "Well, of course we don't observe everything, but we sort of.",
                    "label": 0
                },
                {
                    "sent": "We have observations that are smooth version, spatially smooth versions of the molecules and then really look at a stochastic reaction diffusion system.",
                    "label": 0
                },
                {
                    "sent": "So all these matrix exponentials, well matrices become operators and things can be done.",
                    "label": 0
                },
                {
                    "sent": "As long as it's linear, of course, this is something that we know that can be done because we had done it before in a in a in a week.",
                    "label": 0
                },
                {
                    "sent": "Noise in a linear noise approximation, and this is something that I'm really interested in in because you could say well look, I mean, come on.",
                    "label": 0
                },
                {
                    "sent": "This is monomolecular reactions.",
                    "label": 0
                },
                {
                    "sent": "There's no really chemistry in here right now.",
                    "label": 0
                },
                {
                    "sent": "Nothing interesting.",
                    "label": 0
                },
                {
                    "sent": "Then.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you look at physics papers, they usually have.",
                    "label": 1
                },
                {
                    "sent": "Well, you find some ideas of doing perturbation theory, especially for that cumulant generating function.",
                    "label": 0
                },
                {
                    "sent": "But you can say, well, I have a solvable model.",
                    "label": 0
                },
                {
                    "sent": "Of course the solver model is the monomolecular one, and if you tried to treat the true chemical reactions as perturbations, well I think I would love to have a go at it.",
                    "label": 0
                },
                {
                    "sent": "And I know that cumulant generating functions are nice objects where you can try to do perturbation theory.",
                    "label": 0
                },
                {
                    "sent": "Of course, I can't guarantee anything on that, but well, thank you, that's it.",
                    "label": 0
                }
            ]
        }
    }
}