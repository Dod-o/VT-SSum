{
    "id": "fdbwcw4t2giqdq4zytojptq3g24qtysr",
    "title": "Automatic Affective Dimension Recognition from Naturalistic Facial Expressions Based on Wavelet Filtering and PLS Regression",
    "info": {
        "author": [
            "Hongying Meng, University of Southampton"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_meng_pls_regression/",
    "segmentation": [
        [
            "Thank you everyone and my name is human and this work is from my peer students Yona for now and they seem fine and Saeed and this is basically we focus on automatically affective dimension regulation from naturalistic, naturalistic facial expression and we provide method focused use will transform and PNS regression."
        ],
        [
            "This is an outline of the presentation we talk about.",
            "Little bit if emotion regulation from facial expression and talk about the focus of this work.",
            "And then we produce the detail information about our produced system, including the image feature, extraction, audio feature extraction.",
            "And we transform machine learning and decision level.",
            "And then gives you experiments, results and comparison with the state of art.",
            "So basically it will cover everything we built on the facial expression regulation from naturalistic emotional facial expression videos.",
            "So bye."
        ],
        [
            "Actually, I think facial expression has been used for emotion regulation for a long time and starting from acted or stereo, typical facial expression and recent years.",
            "More people focus on continuous and video expression, especially from naturalistic expressions.",
            "So they have gained more and more people, so that's why there's a international challenge.",
            "If it's A and from 2011 twelve 1314, and they produce the good data set and then ask all the peoples of the world can be able to try your system.",
            "So we follow this topic and things from 2012 and we have built lots of system already.",
            "And try to improve year by year."
        ],
        [
            "So the key thing is becauses continues.",
            "So we need to find out how can you model the relationship between and each frames.",
            "And from independent one from the baseline for many.",
            "The Challenger Deep reduced baseline, but most of them use independent fashion fashion from each frames, and then they produce the label.",
            "For the label, basically they can give you the bundle label I think 2011, so it's for the arousal valence they give you.",
            "The scale is high is 1 and is no.",
            "It's zero against binary labels.",
            "That is totally 11 and recently after that recent years is more focused on the real values for the real valuable emotional arousal valence values from.",
            "It's a real value so that make a big change on the machine learning becausw the original one is classification problems, and this one is regression problems."
        ],
        [
            "So we did some work, and especially in the 2011 and we want the audio sub challenge.",
            "We used model we try to model the relationship between the consecutive frames and similar.",
            "The other people also try different ways to modeling these expressions.",
            "An especially in 2014 last year, the challenge I think data is more bigger than the previous one and have more people attend.",
            "So our work here is also based on this database and we try to use our method try to improve the previous results."
        ],
        [
            "So how to model and we in our 2011 work we try to model the system and we try to model system based on the decision level.",
            "So that means we produce a system have two layers when there is produce the normal regression on each frame and in the second level.",
            "Young second level we try to find the relationship between them.",
            "So we use Hedmark model to meet that.",
            "But last year we tried, we found for the 2014 database.",
            "For that one we found from decision level it's very hard to make further.",
            "So my students said OK, we can we look at the feature level, so that's work here.",
            "So from the label you can see for the continuous one from the figure a so labels you can see it's like this.",
            "And you will find the features every frame.",
            "They have big difference.",
            "You from the video itself is not big difference, but from the features you can see lots of difference.",
            "So from the label we found the label is not changed suddenly because human nature, your emotion cannot change suddenly from happy to sad as consent happy very quickly.",
            "You still is based on the video recording 30 frames per second.",
            "You cannot change too much so there is a.",
            "The relationship between the labels and we did the free transform.",
            "You can see in the second picture.",
            "We found all the labels.",
            "If you do the film transform you found.",
            "France is very quiet now and you can see all the most of them under no friends apart.",
            "So that make a mismatch between the labels you want to produce and the features you have very wide from range.",
            "So we."
        ],
        [
            "Build a system is like this.",
            "We have the original videos and we can get the video features like you use most time and BPUH and the other features and then you can do the machine learning.",
            "For the regression, most people use support vector regression and we use P LS in 2013 and cheap very good results.",
            "So here we used PNS regression and that can make 2 features together and then we produce the arousal and dominance and violence frame labels.",
            "So in this one you can see it's quite normal procedure for the.",
            "Basical system so we'll hear mean focus we want to on the feature part we can make some difference differences here.",
            "So we change from this features.",
            "This is all the features, so this is the frames and this is complaints.",
            "And then we make of it, transform data filtering to think if you have emotions has small change then the features, if it changes to big, that means there are noise there not contribute to your predictions for machine learning.",
            "So we use filter make this.",
            "It's like a smoother make.",
            "This feature is more matching the nature of the labels, so these steps make our performance improvement."
        ],
        [
            "Again, give details about features, the features we use, this one, called the edge or attention histogram, is quite similar, is with LHD and so it use edge 1st and then produce.",
            "Histogram based on the polar coordinate system.",
            "And we tried this one with LBP.",
            "The others we found.",
            "This one is really good and much quicker.",
            "Of."
        ],
        [
            "In our system we try to use more and try to compact help each other, so we also use normal NP features.",
            "And so we try to use them together to capture the different feature information."
        ],
        [
            "Another one is LPQ is provided by the organizer AVC, so we also use this one as well.",
            "So in the."
        ],
        [
            "Radio One we also have all the information, so in order to achieve better information formants we also use MCC feature from the organizer and this one.",
            "We try to do the fielding on the decision level with."
        ],
        [
            "Even audio, try to get the better performance."
        ],
        [
            "So.",
            "Basically we use very simple one is hard with transform and try to remove the- C complaints from the features.",
            "And how will it transform?",
            "I'm not sure how many people know will transform.",
            "OK, so basically it's very simple and just do edge, not just do average and difference.",
            "You get the low frequency part and having support and it's very very quick and easy in here.",
            "We didn't use advanced one becausw we just want to check is this one useful not."
        ],
        [
            "So basically this is the theory about we transform.",
            "And the singular you do we transform decomposition?",
            "It will change.",
            "Like this here so you have the original feature and then do we transform you get low frames part and hyphens part.",
            "And then we remove the happens part and zero and then do.",
            "The involves will transform.",
            "We will recover the.",
            "Recover."
        ],
        [
            "The feature so Oriental features like this and the one we got is like this.",
            "So basically we remove the high precision components, just make sure and this this high frequency components will not contribute to our machine learning."
        ],
        [
            "And so it's like a smoother if you.",
            "Some people do something, it's like smaller, it's just make it more reliable.",
            "We just think the conferences is noise.",
            "It's based on the property of low frequency change.",
            "On the emotions we produce this one another paper 2011, and we found the the we analyze all the emotion labels found.",
            "This is changing very slow."
        ],
        [
            "So we use this in our system and then use AVC feature extraction database for the facial expression regulation for the recognition part we use PLS regression.",
            "Partial list spell regulating.",
            "Regression is basically it's quite similar.",
            "Is means you have two features and you mention in the common space one is the feature we produce here.",
            "One is labels, so we not map it together.",
            "We map in the same common.",
            "Space and then we make the best regression."
        ],
        [
            "So I'll show you the results.",
            "Basically compare with SVR and with a cane as well and this one is better.",
            "So we use KPS on both audio and video."
        ],
        [
            "To produce label.",
            "And then after that we will combine them together, combine them together.",
            "So you can see here."
        ],
        [
            "The combination we just do a very simple one.",
            "And I think there are many different technologies you can use to combine the video audio together in a better way, but here we just do a simple linear combination.",
            "Anne."
        ],
        [
            "It's like this, so you have two decissions and we combine them.",
            "Give a witch."
        ],
        [
            "So this is the experiment results we will give you, so it's.",
            "The AVC 2014 database.",
            "There are three labels.",
            "Is continuously, uh, rather dominance and violence, so all three labels are real values on each frame.",
            "The task is you can produce.",
            "You can produce the labels on each frame, and these values and compare with the true values and then calculate like correlation coefficients.",
            "And root mean square measures you compare with two.",
            "If you have high correlation is better.",
            "If you have no root, mean square error is better."
        ],
        [
            "OK, so based on our system we produce the results.",
            "So here you can see and in the baseline.",
            "On this challenge they use allergy BP top feature and they said this feature is better than at BP top.",
            "Because it's for the videos and they use this one and for the video modality you can see for other dominance and violence, the performance on the table tool.",
            "So."
        ],
        [
            "The Coronation.",
            "Is big is better, so arousal is better than violence and then dominates and we use our system.",
            "You can see we check use 3 features and correlation is."
        ],
        [
            "All above 0.5.",
            "So it's much better than the.",
            "Baseline that make give us the confidence we we can make it better so this is on the development set."
        ],
        [
            "And then we also tried audius.",
            "For the audio, they provide three type of feature is long segment, short segment and validated segment.",
            "So they divide the audio in different ways and we use some technology you can see and this one we produce also much better results than the the baseline on the development set."
        ],
        [
            "The best lines thereupon 6 something.",
            "And then we do the feeling as well for the audio video together and then combine them together and we got similar results.",
            "So their .5 zero point 6 and better than the baseline.",
            "And then last year after the AVC and they produce the testing labels.",
            "So at the beginning we started work is not label available for testing date.",
            "And then they produce.",
            "You can say for the testing set is much difficult than the development and business results for the video is very known.",
            "They respond to their .1 something and but our system is still very reliable, very reliable, their point falling for five.",
            "And this is all audio.",
            "And I got similar results.",
            "And this one based on the feeling.",
            "On the field in businesses got a big boost.",
            "I don't know how did they manage this, but anyway we got better results as well.",
            "So ah."
        ],
        [
            "So we did this one.",
            "We compare and beginning when started this work we don't know what's the."
        ],
        [
            "Best performance and later on this workshop finished and we got found the results.",
            "And then compare with the other people.",
            "So for this challenge you can see on the table 13 they give you the different methods and give you an re performance.",
            "You can see the baseline.",
            "Performance data .4 and the best one from ARM.",
            "It's 0.59.",
            "And they do some very special methods actually, and beginning I had communication with them and they said the paper to us and they use totally different.",
            "They consider the subject information so they consider and this data from which subject and they found the labels instead of label is wrong label becausw label procedure.",
            "They have delays and so they consider all this information.",
            "Try to produce the better best performance.",
            "And from workshop we also found another one is reference nine and they got 0.45499 use deep learning on the image and they got feeling level smooth and well so they produce their .45499.",
            "So in comparison with other results, you can see our performance is a bit.",
            "Unless that is true, that is true.",
            "And but I think our method is much simpler and.",
            "And it's better than the other the rest.",
            "So I think we just mean focus is the one we want.",
            "Want to prove if you can.",
            "Do the feature extraction better.",
            "You can get better performance."
        ],
        [
            "So main contributions we focus on the feature level smooth feature level, removed, high frequency components and try to make better results."
        ],
        [
            "And in the future work we will consider combined Fusion on the feature and on the decision level together.",
            "Maybe we can make better."
        ],
        [
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you everyone and my name is human and this work is from my peer students Yona for now and they seem fine and Saeed and this is basically we focus on automatically affective dimension regulation from naturalistic, naturalistic facial expression and we provide method focused use will transform and PNS regression.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is an outline of the presentation we talk about.",
                    "label": 1
                },
                {
                    "sent": "Little bit if emotion regulation from facial expression and talk about the focus of this work.",
                    "label": 1
                },
                {
                    "sent": "And then we produce the detail information about our produced system, including the image feature, extraction, audio feature extraction.",
                    "label": 0
                },
                {
                    "sent": "And we transform machine learning and decision level.",
                    "label": 0
                },
                {
                    "sent": "And then gives you experiments, results and comparison with the state of art.",
                    "label": 0
                },
                {
                    "sent": "So basically it will cover everything we built on the facial expression regulation from naturalistic emotional facial expression videos.",
                    "label": 0
                },
                {
                    "sent": "So bye.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, I think facial expression has been used for emotion regulation for a long time and starting from acted or stereo, typical facial expression and recent years.",
                    "label": 1
                },
                {
                    "sent": "More people focus on continuous and video expression, especially from naturalistic expressions.",
                    "label": 0
                },
                {
                    "sent": "So they have gained more and more people, so that's why there's a international challenge.",
                    "label": 0
                },
                {
                    "sent": "If it's A and from 2011 twelve 1314, and they produce the good data set and then ask all the peoples of the world can be able to try your system.",
                    "label": 0
                },
                {
                    "sent": "So we follow this topic and things from 2012 and we have built lots of system already.",
                    "label": 0
                },
                {
                    "sent": "And try to improve year by year.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the key thing is becauses continues.",
                    "label": 0
                },
                {
                    "sent": "So we need to find out how can you model the relationship between and each frames.",
                    "label": 0
                },
                {
                    "sent": "And from independent one from the baseline for many.",
                    "label": 0
                },
                {
                    "sent": "The Challenger Deep reduced baseline, but most of them use independent fashion fashion from each frames, and then they produce the label.",
                    "label": 0
                },
                {
                    "sent": "For the label, basically they can give you the bundle label I think 2011, so it's for the arousal valence they give you.",
                    "label": 0
                },
                {
                    "sent": "The scale is high is 1 and is no.",
                    "label": 0
                },
                {
                    "sent": "It's zero against binary labels.",
                    "label": 0
                },
                {
                    "sent": "That is totally 11 and recently after that recent years is more focused on the real values for the real valuable emotional arousal valence values from.",
                    "label": 0
                },
                {
                    "sent": "It's a real value so that make a big change on the machine learning becausw the original one is classification problems, and this one is regression problems.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we did some work, and especially in the 2011 and we want the audio sub challenge.",
                    "label": 0
                },
                {
                    "sent": "We used model we try to model the relationship between the consecutive frames and similar.",
                    "label": 0
                },
                {
                    "sent": "The other people also try different ways to modeling these expressions.",
                    "label": 0
                },
                {
                    "sent": "An especially in 2014 last year, the challenge I think data is more bigger than the previous one and have more people attend.",
                    "label": 0
                },
                {
                    "sent": "So our work here is also based on this database and we try to use our method try to improve the previous results.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how to model and we in our 2011 work we try to model the system and we try to model system based on the decision level.",
                    "label": 1
                },
                {
                    "sent": "So that means we produce a system have two layers when there is produce the normal regression on each frame and in the second level.",
                    "label": 0
                },
                {
                    "sent": "Young second level we try to find the relationship between them.",
                    "label": 0
                },
                {
                    "sent": "So we use Hedmark model to meet that.",
                    "label": 0
                },
                {
                    "sent": "But last year we tried, we found for the 2014 database.",
                    "label": 0
                },
                {
                    "sent": "For that one we found from decision level it's very hard to make further.",
                    "label": 0
                },
                {
                    "sent": "So my students said OK, we can we look at the feature level, so that's work here.",
                    "label": 0
                },
                {
                    "sent": "So from the label you can see for the continuous one from the figure a so labels you can see it's like this.",
                    "label": 0
                },
                {
                    "sent": "And you will find the features every frame.",
                    "label": 0
                },
                {
                    "sent": "They have big difference.",
                    "label": 0
                },
                {
                    "sent": "You from the video itself is not big difference, but from the features you can see lots of difference.",
                    "label": 0
                },
                {
                    "sent": "So from the label we found the label is not changed suddenly because human nature, your emotion cannot change suddenly from happy to sad as consent happy very quickly.",
                    "label": 0
                },
                {
                    "sent": "You still is based on the video recording 30 frames per second.",
                    "label": 0
                },
                {
                    "sent": "You cannot change too much so there is a.",
                    "label": 0
                },
                {
                    "sent": "The relationship between the labels and we did the free transform.",
                    "label": 0
                },
                {
                    "sent": "You can see in the second picture.",
                    "label": 0
                },
                {
                    "sent": "We found all the labels.",
                    "label": 0
                },
                {
                    "sent": "If you do the film transform you found.",
                    "label": 0
                },
                {
                    "sent": "France is very quiet now and you can see all the most of them under no friends apart.",
                    "label": 0
                },
                {
                    "sent": "So that make a mismatch between the labels you want to produce and the features you have very wide from range.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Build a system is like this.",
                    "label": 0
                },
                {
                    "sent": "We have the original videos and we can get the video features like you use most time and BPUH and the other features and then you can do the machine learning.",
                    "label": 0
                },
                {
                    "sent": "For the regression, most people use support vector regression and we use P LS in 2013 and cheap very good results.",
                    "label": 0
                },
                {
                    "sent": "So here we used PNS regression and that can make 2 features together and then we produce the arousal and dominance and violence frame labels.",
                    "label": 0
                },
                {
                    "sent": "So in this one you can see it's quite normal procedure for the.",
                    "label": 0
                },
                {
                    "sent": "Basical system so we'll hear mean focus we want to on the feature part we can make some difference differences here.",
                    "label": 0
                },
                {
                    "sent": "So we change from this features.",
                    "label": 0
                },
                {
                    "sent": "This is all the features, so this is the frames and this is complaints.",
                    "label": 0
                },
                {
                    "sent": "And then we make of it, transform data filtering to think if you have emotions has small change then the features, if it changes to big, that means there are noise there not contribute to your predictions for machine learning.",
                    "label": 0
                },
                {
                    "sent": "So we use filter make this.",
                    "label": 0
                },
                {
                    "sent": "It's like a smoother make.",
                    "label": 0
                },
                {
                    "sent": "This feature is more matching the nature of the labels, so these steps make our performance improvement.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, give details about features, the features we use, this one, called the edge or attention histogram, is quite similar, is with LHD and so it use edge 1st and then produce.",
                    "label": 0
                },
                {
                    "sent": "Histogram based on the polar coordinate system.",
                    "label": 0
                },
                {
                    "sent": "And we tried this one with LBP.",
                    "label": 0
                },
                {
                    "sent": "The others we found.",
                    "label": 0
                },
                {
                    "sent": "This one is really good and much quicker.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In our system we try to use more and try to compact help each other, so we also use normal NP features.",
                    "label": 0
                },
                {
                    "sent": "And so we try to use them together to capture the different feature information.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another one is LPQ is provided by the organizer AVC, so we also use this one as well.",
                    "label": 0
                },
                {
                    "sent": "So in the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Radio One we also have all the information, so in order to achieve better information formants we also use MCC feature from the organizer and this one.",
                    "label": 0
                },
                {
                    "sent": "We try to do the fielding on the decision level with.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Even audio, try to get the better performance.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Basically we use very simple one is hard with transform and try to remove the- C complaints from the features.",
                    "label": 0
                },
                {
                    "sent": "And how will it transform?",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how many people know will transform.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically it's very simple and just do edge, not just do average and difference.",
                    "label": 0
                },
                {
                    "sent": "You get the low frequency part and having support and it's very very quick and easy in here.",
                    "label": 0
                },
                {
                    "sent": "We didn't use advanced one becausw we just want to check is this one useful not.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically this is the theory about we transform.",
                    "label": 0
                },
                {
                    "sent": "And the singular you do we transform decomposition?",
                    "label": 0
                },
                {
                    "sent": "It will change.",
                    "label": 0
                },
                {
                    "sent": "Like this here so you have the original feature and then do we transform you get low frames part and hyphens part.",
                    "label": 0
                },
                {
                    "sent": "And then we remove the happens part and zero and then do.",
                    "label": 0
                },
                {
                    "sent": "The involves will transform.",
                    "label": 0
                },
                {
                    "sent": "We will recover the.",
                    "label": 0
                },
                {
                    "sent": "Recover.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The feature so Oriental features like this and the one we got is like this.",
                    "label": 0
                },
                {
                    "sent": "So basically we remove the high precision components, just make sure and this this high frequency components will not contribute to our machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so it's like a smoother if you.",
                    "label": 0
                },
                {
                    "sent": "Some people do something, it's like smaller, it's just make it more reliable.",
                    "label": 0
                },
                {
                    "sent": "We just think the conferences is noise.",
                    "label": 0
                },
                {
                    "sent": "It's based on the property of low frequency change.",
                    "label": 0
                },
                {
                    "sent": "On the emotions we produce this one another paper 2011, and we found the the we analyze all the emotion labels found.",
                    "label": 0
                },
                {
                    "sent": "This is changing very slow.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we use this in our system and then use AVC feature extraction database for the facial expression regulation for the recognition part we use PLS regression.",
                    "label": 0
                },
                {
                    "sent": "Partial list spell regulating.",
                    "label": 0
                },
                {
                    "sent": "Regression is basically it's quite similar.",
                    "label": 0
                },
                {
                    "sent": "Is means you have two features and you mention in the common space one is the feature we produce here.",
                    "label": 0
                },
                {
                    "sent": "One is labels, so we not map it together.",
                    "label": 0
                },
                {
                    "sent": "We map in the same common.",
                    "label": 0
                },
                {
                    "sent": "Space and then we make the best regression.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll show you the results.",
                    "label": 0
                },
                {
                    "sent": "Basically compare with SVR and with a cane as well and this one is better.",
                    "label": 0
                },
                {
                    "sent": "So we use KPS on both audio and video.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To produce label.",
                    "label": 0
                },
                {
                    "sent": "And then after that we will combine them together, combine them together.",
                    "label": 0
                },
                {
                    "sent": "So you can see here.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The combination we just do a very simple one.",
                    "label": 0
                },
                {
                    "sent": "And I think there are many different technologies you can use to combine the video audio together in a better way, but here we just do a simple linear combination.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's like this, so you have two decissions and we combine them.",
                    "label": 0
                },
                {
                    "sent": "Give a witch.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the experiment results we will give you, so it's.",
                    "label": 0
                },
                {
                    "sent": "The AVC 2014 database.",
                    "label": 0
                },
                {
                    "sent": "There are three labels.",
                    "label": 0
                },
                {
                    "sent": "Is continuously, uh, rather dominance and violence, so all three labels are real values on each frame.",
                    "label": 0
                },
                {
                    "sent": "The task is you can produce.",
                    "label": 0
                },
                {
                    "sent": "You can produce the labels on each frame, and these values and compare with the true values and then calculate like correlation coefficients.",
                    "label": 0
                },
                {
                    "sent": "And root mean square measures you compare with two.",
                    "label": 0
                },
                {
                    "sent": "If you have high correlation is better.",
                    "label": 0
                },
                {
                    "sent": "If you have no root, mean square error is better.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so based on our system we produce the results.",
                    "label": 0
                },
                {
                    "sent": "So here you can see and in the baseline.",
                    "label": 0
                },
                {
                    "sent": "On this challenge they use allergy BP top feature and they said this feature is better than at BP top.",
                    "label": 0
                },
                {
                    "sent": "Because it's for the videos and they use this one and for the video modality you can see for other dominance and violence, the performance on the table tool.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Coronation.",
                    "label": 0
                },
                {
                    "sent": "Is big is better, so arousal is better than violence and then dominates and we use our system.",
                    "label": 0
                },
                {
                    "sent": "You can see we check use 3 features and correlation is.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All above 0.5.",
                    "label": 0
                },
                {
                    "sent": "So it's much better than the.",
                    "label": 0
                },
                {
                    "sent": "Baseline that make give us the confidence we we can make it better so this is on the development set.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we also tried audius.",
                    "label": 0
                },
                {
                    "sent": "For the audio, they provide three type of feature is long segment, short segment and validated segment.",
                    "label": 0
                },
                {
                    "sent": "So they divide the audio in different ways and we use some technology you can see and this one we produce also much better results than the the baseline on the development set.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The best lines thereupon 6 something.",
                    "label": 0
                },
                {
                    "sent": "And then we do the feeling as well for the audio video together and then combine them together and we got similar results.",
                    "label": 0
                },
                {
                    "sent": "So their .5 zero point 6 and better than the baseline.",
                    "label": 0
                },
                {
                    "sent": "And then last year after the AVC and they produce the testing labels.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning we started work is not label available for testing date.",
                    "label": 0
                },
                {
                    "sent": "And then they produce.",
                    "label": 0
                },
                {
                    "sent": "You can say for the testing set is much difficult than the development and business results for the video is very known.",
                    "label": 0
                },
                {
                    "sent": "They respond to their .1 something and but our system is still very reliable, very reliable, their point falling for five.",
                    "label": 0
                },
                {
                    "sent": "And this is all audio.",
                    "label": 0
                },
                {
                    "sent": "And I got similar results.",
                    "label": 0
                },
                {
                    "sent": "And this one based on the feeling.",
                    "label": 0
                },
                {
                    "sent": "On the field in businesses got a big boost.",
                    "label": 0
                },
                {
                    "sent": "I don't know how did they manage this, but anyway we got better results as well.",
                    "label": 0
                },
                {
                    "sent": "So ah.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we did this one.",
                    "label": 0
                },
                {
                    "sent": "We compare and beginning when started this work we don't know what's the.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best performance and later on this workshop finished and we got found the results.",
                    "label": 0
                },
                {
                    "sent": "And then compare with the other people.",
                    "label": 0
                },
                {
                    "sent": "So for this challenge you can see on the table 13 they give you the different methods and give you an re performance.",
                    "label": 0
                },
                {
                    "sent": "You can see the baseline.",
                    "label": 0
                },
                {
                    "sent": "Performance data .4 and the best one from ARM.",
                    "label": 0
                },
                {
                    "sent": "It's 0.59.",
                    "label": 0
                },
                {
                    "sent": "And they do some very special methods actually, and beginning I had communication with them and they said the paper to us and they use totally different.",
                    "label": 0
                },
                {
                    "sent": "They consider the subject information so they consider and this data from which subject and they found the labels instead of label is wrong label becausw label procedure.",
                    "label": 0
                },
                {
                    "sent": "They have delays and so they consider all this information.",
                    "label": 0
                },
                {
                    "sent": "Try to produce the better best performance.",
                    "label": 0
                },
                {
                    "sent": "And from workshop we also found another one is reference nine and they got 0.45499 use deep learning on the image and they got feeling level smooth and well so they produce their .45499.",
                    "label": 0
                },
                {
                    "sent": "So in comparison with other results, you can see our performance is a bit.",
                    "label": 0
                },
                {
                    "sent": "Unless that is true, that is true.",
                    "label": 0
                },
                {
                    "sent": "And but I think our method is much simpler and.",
                    "label": 0
                },
                {
                    "sent": "And it's better than the other the rest.",
                    "label": 0
                },
                {
                    "sent": "So I think we just mean focus is the one we want.",
                    "label": 0
                },
                {
                    "sent": "Want to prove if you can.",
                    "label": 0
                },
                {
                    "sent": "Do the feature extraction better.",
                    "label": 0
                },
                {
                    "sent": "You can get better performance.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So main contributions we focus on the feature level smooth feature level, removed, high frequency components and try to make better results.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the future work we will consider combined Fusion on the feature and on the decision level together.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can make better.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}