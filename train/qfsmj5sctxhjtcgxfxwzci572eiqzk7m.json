{
    "id": "qfsmj5sctxhjtcgxfxwzci572eiqzk7m",
    "title": "Inferring exon junction expression from RNASeq data",
    "info": {
        "author": [
            "Boyko Kakaradov, UC San Diego"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Bioinformatics",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_kakaradov_ieje/",
    "segmentation": [
        [
            "So this problem needs little motivation, but I'll just quickly explain the goal."
        ],
        [
            "Is to estimate transcript expression and we're interested in sort of both modalities.",
            "The absolute counts are interesting and also the relative counts between sort of specific transcripts, such as in alternative splicing.",
            "We are also interested in and, so we will try to do a good job on both of these.",
            "The signal is coming from RNA sequencing reads that are already well covered, so I won't spend too much time on that and.",
            "The good thing about Arnie sequencing is that it provides discrete counts for the coverage of transcripts, but it also depending on their depth of coverage, can also be pretty sparse, which introduces noises and biases that are very interesting.",
            "As I'll show you a little bit later.",
            "OK, so."
        ],
        [
            "First I will describe how exactly I use the RNA sequencing reads.",
            "So here is a very cartoon version.",
            "We have two exams and their junction.",
            "This is in the transcript, so there's no.",
            "the Internet has already missed placed out these reads nicely covered this junction we mark on each read where the junction occurs.",
            "So because of sort of mapping restrictions we don't allow them to be too far to then, because otherwise you don't really can really be sure that.",
            "You're mapping to it to the next exam.",
            "OK, so just take the reason covering the junction.",
            "Stack them like cards and calculate a histogram of the coverage and so this is a coverage of the junction onto the reads rather than vice versa, which is what usually people do.",
            "It's equivalent, it just helps us think about this in a slightly different way.",
            "OK, so this is for one junction, the span for these reads.",
            "I'm using 50 new class, but obviously.",
            "Whatever your sequencing platform is spitting out, you can use.",
            "And then.",
            "I have data for about 2500 junctions in 16 different issues.",
            "And this is what I will be working on.",
            "OK."
        ],
        [
            "OK, so this is one of the junctions.",
            "It's actually the first one I ever looked at and it's fits the bill nicely, so I will just talk about it.",
            "You can see on the Y axis is this histogram and then accesses the positions.",
            "You can see that it is quite sparse, so there's a bunch of positions where no reads happen to align to that junction, which is kind of interesting.",
            "This is clearly not what I showed you in the cartoon.",
            "Previously in the cartoon, there's a nice even coverage.",
            "Operator practices random crime experts or what is it?",
            "This is Polly a selected.",
            "I don't know how much of the other.",
            "Details.",
            "Right, yeah, this is alumina sequencing.",
            "Yeah, so yeah.",
            "The biases that I'm going to talk about are specific to a little platform.",
            "Um?",
            "OK, so once you can see it's sparse and the other one, you can see that the variation in the Heights of these columns is quite high, so I'll explore this further.",
            "So I will talk about first of all people.",
            "Do they assume a post on model so they assume uniform coverage, so all junctions are all reads?",
            "They happen to map to this junction are seen as sort of random samples.",
            "They just get averaged out.",
            "Over the positions and this becomes the expression of disjunction an I'll talk about.",
            "So I'll formalize this and then I'll talk about why it's not such a good idea."
        ],
        [
            "I call this the simple model.",
            "Usually in the machine learning cognitive model, but I don't want to offend the community so.",
            "For each position, tissue in junction.",
            "I will sample a single single height for those bars from a post on model.",
            "Of what is essentially the mean that line that I showed you, the mean coverage of that particular junctions for, so the junctions are really represented by their tissue and their junction number.",
            "OK, and for those of you that need a refresher, this is the most common of my.",
            "Pointer is dead.",
            "OK. Um?",
            "Just the top one, thanks OK.",
            "So.",
            "As I said before, this model assumes a uniform read coverage, but it has a nice property that because of all the shared parameters.",
            "It's quite simple, name suggests and so there's only three times J free parameters to fit.",
            "With.",
            "Sort of 50 fold more data, so that's doable."
        ],
        [
            "OK, so I'll elaborate now why for particular datasets like this this is.",
            "Not necessarily good model.",
            "Quite quantified, the sparsity I showed.",
            "I told you earlier sparse.",
            "This is not just for the junction, is for all the junctions.",
            "I get 73% zeros and so you can think if you have higher depth of coverage.",
            "This will hopefully be lower, but it still.",
            "It is still not a linear function of the linearly decreasing function of the coverage.",
            "And the other is the variance within the data.",
            "And this is again a global statistics.",
            "If I take the standard deviation for each junction and then sort of divided by the mean of the junction, I get an average ratio.",
            "Overall tissues, injunctions of three, and so the Postal model assumes that this multiplier is 1.",
            "And so, again, not, there's something more we can do.",
            "OK, so."
        ],
        [
            "How am I going to deviate from the person model?",
            "The first thing I observed is that there is bias that are specific to each tissue.",
            "So something like the total expression of a particular junction or of transcript that contains these junction in this tissue would be.",
            "So such a bias and also observed that there is certain positions throughout all junctions that or preferred.",
            "So you can see here, this intensity describes.",
            "This is basically all the junctions summed onto.",
            "At this point, and so sort of reader here is high coverage and glorious, less coverage.",
            "OK, so how?",
            "How could I use this?",
            "I just separated the two factors tissues in positions.",
            "In two"
        ],
        [
            "Again, these two factors, Alpha, Beta, beta, here is this observation that the positions are.",
            "Um?",
            "Different so it's indexed by.",
            "Position in tissue and here I have sort of the.",
            "Remainder called Alpha for each teacher injunction this is.",
            "Very similar to the simple model.",
            "In fact the Alpha here for the simple model is just the mean that I showed you earlier.",
            "OK.",
            "So I will now say.",
            "Multiply these two together.",
            "And still usable."
        ],
        [
            "Model, but now it's factor.",
            "So the key key assumption that I'm breaking is the identically distributed part of the IID assumption for the simple model.",
            "OK, so this is.",
            "I call this the factor model.",
            "And, um."
        ],
        [
            "I can write this look like hood.",
            "I can derive a coordinate descent algorithm to optimize the parameters.",
            "And if I let myself so this is not identifiable because of this multiplication, you can just see how scaling one and reciprocal scaling the other gives you the exact same fit.",
            "So if I restrict on the beta system to one overall positions, which is a.",
            "A reasonable assumption or reasonable constrain.",
            "I get a close form solution, which looks great, except if you look at the alphas, they're not that different from my simple model.",
            "In fact, their constant factor.",
            "Um?",
            "And so."
        ],
        [
            "These are the learned parameters.",
            "The office will look very much like the means, and the betas will capture.",
            "Part of the biases that I showed you earlier, and the reason this didn't quite work so well as I hoped is that a lot of the.",
            "The biases are.",
            "They are positioned, issue specific but there also.",
            "These things called read stacks, which are common to the aluminum platform.",
            "They basically repeat a read even though there's no.",
            "They repeat every day.",
            "Just get stuck and there's no.",
            "Support for it in the data, so the junction doesn't actually have such a high coverage, even though you're seeing a bunch of identical samples from it.",
            "OK so I went back to the drawing board."
        ],
        [
            "And wanted to add this.",
            "Capture this into my factor model and so instead of observing instead of modeling the boson directly, I said what if.",
            "I observe."
        ],
        [
            "My observed counts are noisy version of this post on a model.",
            "Is that?",
            "If I have an outlier, just a binary variable which tells me yes, this is all I know it isn't.",
            "I get."
        ],
        [
            "This additive geometric noise, so if these two factors are enough to explain, say X of the counts, then the extra counts that could be the street stacks are explained by this geometric.",
            "Additive noise.",
            "OK, so."
        ],
        [
            "Let's see the math.",
            "Here is a little bit hairier, so I'll just give you the solution.",
            "You have the exact same part for the.",
            "After model and here is the outline model and here is this key.",
            "Outlier probability, so I'm actually learning this as well, and some of the positions in some of the issues and junctions will have a higher one and a lot of them will just stay close to 0.",
            "OK, and this is just the normalization.",
            "So then step.",
            "The optimization for these is done in the exact same way as before, and actually looks exactly the same with.",
            "If you squint a little bit instead of using the raw counts observed counts, I'm essentially.",
            "Seeing the expectation over this.",
            "Empirical or or this proposal distribution here instead of the observed counts.",
            "And so far from beta, and here is this.",
            "So I have this parameter, so I'm increasing.",
            "I've kind of snuck this past year.",
            "I'm increasing the number of parameters I'm fitting, but I'm feeling sort of easier and easier parameters, so this is these are Bernoulli parameters.",
            "They're much easier to fit them, so these continuous.",
            "Multi factor parameters OK."
        ],
        [
            "So this is the result from.",
            "The.",
            "MM&M running M on the latent model and now you can see first data captures a lot more of this positional and tissue bias that I showed you before.",
            "And Alpha also.",
            "Sort of reflects that this is actually the log of Alpha, because there is very big variations between transcript expression so.",
            "This is a lot more nuanced.",
            "I mean can't read too much into this bunch of noise, but a bunch of.",
            "Yeah, color, but."
        ],
        [
            "We can evaluate how much better we've done and.",
            "One way to evaluate is the machine learning way is to look at model fits or the likelihood of the self reported likelihood model and also try to sample some data from just dream up some data from these models and see how well it fits the observed data.",
            "So there's caveats with both of these, likelihood is.",
            "If you're overfitting the likelihood it would be great and also the reconstruction error at least.",
            "Well, there's two caveats with this reconstruction is 1 is.",
            "The observed counts are already noisy, so how well do you really want to?",
            "State near them and the other one is.",
            "This is sort of one of the standard ways to.",
            "To measure reconstruction error and this is very biased towards the really high expression.",
            "Junctions, which is not necessarily the most biologically interesting junctions, and so I.",
            "Thought a little bit about this an.",
            "Came up with the application as a form of evaluation.",
            "Now this is not.",
            "I don't actually have a gold standard for altering this blessing, and if you do, please let me know, but.",
            "I could use my.",
            "Approximation for the smooth.",
            "It counts to calculate a log ratio between alternative.",
            "Junctions an cathedral directions.",
            "So sort of between transcripts that are contain alternative exon an the ones that don't tan.",
            "Next speaker will tell you a lot more about alternative splicing, so I'm just kind of going out on a limb here and hoping they understand.",
            "So OK.",
            "When we just compare the, this is if you remember the notation.",
            "This is a simple model, just.",
            "Averaging across the positions, and this will be my sort of.",
            "Four guns are latent factor model.",
            "And the first one."
        ],
        [
            "The simple model gives you something like this, so again, tissues on the axis junctions.",
            "And here the junction is not 2500 but only 250, because these are the ones that have this alternative splicing structure, the constitutive versus alternative skipped exon.",
            "OK, so.",
            "This is what it is.",
            "You see some junctions here that have.",
            "Very consistent log ratios and.",
            "I'll"
        ],
        [
            "Skip to next one.",
            "This is from the late model and you can see.",
            "The.",
            "The junctions themselves are not so consistent anymore as as are the tissues and some of these gaps or so seeming gaps in the previous are sort of filled in by the extra smoothing by the outlier essentially.",
            "I have no idea how I'm doing on time, but.",
            "I'm done so."
        ],
        [
            "I'll just summarize and then there will be more time for questions.",
            "OK so I.",
            "First showed you what junction coverage looks like under an AC can is not what you see in the textbook.",
            "Proposed a couple of for some models that try to fit it.",
            "Not very well.",
            "The send it to a late model which has sort of an explicit outlier.",
            "Additive noise.",
            "And finally, I didn't.",
            "I didn't show you actual numbers, but.",
            "The ordering goes pretty much what you assumed simple model for superseded by the factored model.",
            "Superseded by the latent model."
        ],
        [
            "So I guess the question.",
            "So do you know why there is?",
            "Um?",
            "So.",
            "If.",
            "I would say if the.",
            "Reads were actually order.",
            "If I knew the strength of the rates of the real strand, I could tell you something about because the way.",
            "You see, the positions is always from the start.",
            "It's there's a lot higher.",
            "Yeah, so there's a higher bias on left end that could just be.",
            "The the GC bias around junctions being higher at sort of the donor Exxon.",
            "So you could probably verify that by choosing I mean there shouldn't be much difference between the spice junction rates and breeds that spend any other position.",
            "Write the body rate.",
            "Sort of similar.",
            "Similar characteristics like GC, whatever, right I could I could build a background model, you're right.",
            "So some of the.",
            "They in fact they are absolutely.",
            "Also, you're just looking at the public.",
            "Movie times.",
            "Is so that.",
            "Right, so that outlier will fill in for zero reads, but it's kind of a stretch so it doesn't doesn't fix the zeros as much, it's the positional bias that fixes the zero reads more.",
            "Yeah so.",
            "So what?",
            "I don't know if this will answer it, but one thing I tried is tool, so we doubt the series is to use a more robust estimator than the mean.",
            "So like median or something like that used, a bunch of them and they weren't significantly better in these evaluations now.",
            "Exactly.",
            "Could be yeah.",
            "So maybe maybe we'll talk.",
            "Maybe you can discuss that after that.",
            "So this indication why there are reports that very much depends on the 1st 6 Watt first 10 nucleotides of the read.",
            "Whether the Reed is actually being sequenced or not OK if you take this into account.",
            "One explanation for the non uniform recovers would be really depends on the dynamic weather on the exonic sequence, never that.",
            "6 or 10 nucleotides.",
            "What is right?",
            "And if there was a favoring one, you get a lot of reads, and if there's a non favoring one this week, but what you're doing is not taking that into account, you're kind of smoothing smoothing that out I guess right?",
            "So why not worldbuilding us sequence specific model modeling that that's next.",
            "In fact, in more than one ways than one, it depends how your libraries made right.",
            "You guys did the RT reactions.",
            "You gotta prime it in some way.",
            "Dragon's is 1 prime is one of the factors, but I mean that's why I asked about the library, how your libraries generated.",
            "If you could to know the answer to that question.",
            "I think there was one of them, so there are other models coming over this first pass on like an evening, binomial or like explicitly model that there is version compared to that for you.",
            "So as an alternative to this mixture model.",
            "I'm not aware of it, so maybe you can.",
            "It might be a cheaper computationally cheaper alternative is what you think.",
            "So there's just a couple questions if you try to compare it model with something.",
            "Models like this something like regular ratio test or.",
            "To sort of see whether the increasing number of parameters is statically significant.",
            "Um?",
            "Might have something to do.",
            "All good ideas.",
            "Further questions thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this problem needs little motivation, but I'll just quickly explain the goal.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is to estimate transcript expression and we're interested in sort of both modalities.",
                    "label": 1
                },
                {
                    "sent": "The absolute counts are interesting and also the relative counts between sort of specific transcripts, such as in alternative splicing.",
                    "label": 0
                },
                {
                    "sent": "We are also interested in and, so we will try to do a good job on both of these.",
                    "label": 0
                },
                {
                    "sent": "The signal is coming from RNA sequencing reads that are already well covered, so I won't spend too much time on that and.",
                    "label": 0
                },
                {
                    "sent": "The good thing about Arnie sequencing is that it provides discrete counts for the coverage of transcripts, but it also depending on their depth of coverage, can also be pretty sparse, which introduces noises and biases that are very interesting.",
                    "label": 0
                },
                {
                    "sent": "As I'll show you a little bit later.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First I will describe how exactly I use the RNA sequencing reads.",
                    "label": 0
                },
                {
                    "sent": "So here is a very cartoon version.",
                    "label": 0
                },
                {
                    "sent": "We have two exams and their junction.",
                    "label": 0
                },
                {
                    "sent": "This is in the transcript, so there's no.",
                    "label": 0
                },
                {
                    "sent": "the Internet has already missed placed out these reads nicely covered this junction we mark on each read where the junction occurs.",
                    "label": 0
                },
                {
                    "sent": "So because of sort of mapping restrictions we don't allow them to be too far to then, because otherwise you don't really can really be sure that.",
                    "label": 0
                },
                {
                    "sent": "You're mapping to it to the next exam.",
                    "label": 0
                },
                {
                    "sent": "OK, so just take the reason covering the junction.",
                    "label": 0
                },
                {
                    "sent": "Stack them like cards and calculate a histogram of the coverage and so this is a coverage of the junction onto the reads rather than vice versa, which is what usually people do.",
                    "label": 0
                },
                {
                    "sent": "It's equivalent, it just helps us think about this in a slightly different way.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is for one junction, the span for these reads.",
                    "label": 0
                },
                {
                    "sent": "I'm using 50 new class, but obviously.",
                    "label": 0
                },
                {
                    "sent": "Whatever your sequencing platform is spitting out, you can use.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "I have data for about 2500 junctions in 16 different issues.",
                    "label": 0
                },
                {
                    "sent": "And this is what I will be working on.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is one of the junctions.",
                    "label": 0
                },
                {
                    "sent": "It's actually the first one I ever looked at and it's fits the bill nicely, so I will just talk about it.",
                    "label": 0
                },
                {
                    "sent": "You can see on the Y axis is this histogram and then accesses the positions.",
                    "label": 0
                },
                {
                    "sent": "You can see that it is quite sparse, so there's a bunch of positions where no reads happen to align to that junction, which is kind of interesting.",
                    "label": 0
                },
                {
                    "sent": "This is clearly not what I showed you in the cartoon.",
                    "label": 0
                },
                {
                    "sent": "Previously in the cartoon, there's a nice even coverage.",
                    "label": 0
                },
                {
                    "sent": "Operator practices random crime experts or what is it?",
                    "label": 0
                },
                {
                    "sent": "This is Polly a selected.",
                    "label": 0
                },
                {
                    "sent": "I don't know how much of the other.",
                    "label": 0
                },
                {
                    "sent": "Details.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah, this is alumina sequencing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah.",
                    "label": 0
                },
                {
                    "sent": "The biases that I'm going to talk about are specific to a little platform.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so once you can see it's sparse and the other one, you can see that the variation in the Heights of these columns is quite high, so I'll explore this further.",
                    "label": 0
                },
                {
                    "sent": "So I will talk about first of all people.",
                    "label": 0
                },
                {
                    "sent": "Do they assume a post on model so they assume uniform coverage, so all junctions are all reads?",
                    "label": 0
                },
                {
                    "sent": "They happen to map to this junction are seen as sort of random samples.",
                    "label": 0
                },
                {
                    "sent": "They just get averaged out.",
                    "label": 0
                },
                {
                    "sent": "Over the positions and this becomes the expression of disjunction an I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "So I'll formalize this and then I'll talk about why it's not such a good idea.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I call this the simple model.",
                    "label": 1
                },
                {
                    "sent": "Usually in the machine learning cognitive model, but I don't want to offend the community so.",
                    "label": 0
                },
                {
                    "sent": "For each position, tissue in junction.",
                    "label": 0
                },
                {
                    "sent": "I will sample a single single height for those bars from a post on model.",
                    "label": 0
                },
                {
                    "sent": "Of what is essentially the mean that line that I showed you, the mean coverage of that particular junctions for, so the junctions are really represented by their tissue and their junction number.",
                    "label": 0
                },
                {
                    "sent": "OK, and for those of you that need a refresher, this is the most common of my.",
                    "label": 0
                },
                {
                    "sent": "Pointer is dead.",
                    "label": 0
                },
                {
                    "sent": "OK. Um?",
                    "label": 0
                },
                {
                    "sent": "Just the top one, thanks OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "As I said before, this model assumes a uniform read coverage, but it has a nice property that because of all the shared parameters.",
                    "label": 1
                },
                {
                    "sent": "It's quite simple, name suggests and so there's only three times J free parameters to fit.",
                    "label": 0
                },
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "Sort of 50 fold more data, so that's doable.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'll elaborate now why for particular datasets like this this is.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily good model.",
                    "label": 0
                },
                {
                    "sent": "Quite quantified, the sparsity I showed.",
                    "label": 0
                },
                {
                    "sent": "I told you earlier sparse.",
                    "label": 0
                },
                {
                    "sent": "This is not just for the junction, is for all the junctions.",
                    "label": 1
                },
                {
                    "sent": "I get 73% zeros and so you can think if you have higher depth of coverage.",
                    "label": 0
                },
                {
                    "sent": "This will hopefully be lower, but it still.",
                    "label": 0
                },
                {
                    "sent": "It is still not a linear function of the linearly decreasing function of the coverage.",
                    "label": 0
                },
                {
                    "sent": "And the other is the variance within the data.",
                    "label": 0
                },
                {
                    "sent": "And this is again a global statistics.",
                    "label": 0
                },
                {
                    "sent": "If I take the standard deviation for each junction and then sort of divided by the mean of the junction, I get an average ratio.",
                    "label": 0
                },
                {
                    "sent": "Overall tissues, injunctions of three, and so the Postal model assumes that this multiplier is 1.",
                    "label": 0
                },
                {
                    "sent": "And so, again, not, there's something more we can do.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How am I going to deviate from the person model?",
                    "label": 0
                },
                {
                    "sent": "The first thing I observed is that there is bias that are specific to each tissue.",
                    "label": 0
                },
                {
                    "sent": "So something like the total expression of a particular junction or of transcript that contains these junction in this tissue would be.",
                    "label": 0
                },
                {
                    "sent": "So such a bias and also observed that there is certain positions throughout all junctions that or preferred.",
                    "label": 0
                },
                {
                    "sent": "So you can see here, this intensity describes.",
                    "label": 0
                },
                {
                    "sent": "This is basically all the junctions summed onto.",
                    "label": 0
                },
                {
                    "sent": "At this point, and so sort of reader here is high coverage and glorious, less coverage.",
                    "label": 0
                },
                {
                    "sent": "OK, so how?",
                    "label": 0
                },
                {
                    "sent": "How could I use this?",
                    "label": 0
                },
                {
                    "sent": "I just separated the two factors tissues in positions.",
                    "label": 0
                },
                {
                    "sent": "In two",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, these two factors, Alpha, Beta, beta, here is this observation that the positions are.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Different so it's indexed by.",
                    "label": 0
                },
                {
                    "sent": "Position in tissue and here I have sort of the.",
                    "label": 0
                },
                {
                    "sent": "Remainder called Alpha for each teacher injunction this is.",
                    "label": 0
                },
                {
                    "sent": "Very similar to the simple model.",
                    "label": 0
                },
                {
                    "sent": "In fact the Alpha here for the simple model is just the mean that I showed you earlier.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I will now say.",
                    "label": 0
                },
                {
                    "sent": "Multiply these two together.",
                    "label": 0
                },
                {
                    "sent": "And still usable.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model, but now it's factor.",
                    "label": 0
                },
                {
                    "sent": "So the key key assumption that I'm breaking is the identically distributed part of the IID assumption for the simple model.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "I call this the factor model.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can write this look like hood.",
                    "label": 0
                },
                {
                    "sent": "I can derive a coordinate descent algorithm to optimize the parameters.",
                    "label": 0
                },
                {
                    "sent": "And if I let myself so this is not identifiable because of this multiplication, you can just see how scaling one and reciprocal scaling the other gives you the exact same fit.",
                    "label": 0
                },
                {
                    "sent": "So if I restrict on the beta system to one overall positions, which is a.",
                    "label": 0
                },
                {
                    "sent": "A reasonable assumption or reasonable constrain.",
                    "label": 0
                },
                {
                    "sent": "I get a close form solution, which looks great, except if you look at the alphas, they're not that different from my simple model.",
                    "label": 0
                },
                {
                    "sent": "In fact, their constant factor.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are the learned parameters.",
                    "label": 0
                },
                {
                    "sent": "The office will look very much like the means, and the betas will capture.",
                    "label": 0
                },
                {
                    "sent": "Part of the biases that I showed you earlier, and the reason this didn't quite work so well as I hoped is that a lot of the.",
                    "label": 0
                },
                {
                    "sent": "The biases are.",
                    "label": 0
                },
                {
                    "sent": "They are positioned, issue specific but there also.",
                    "label": 0
                },
                {
                    "sent": "These things called read stacks, which are common to the aluminum platform.",
                    "label": 0
                },
                {
                    "sent": "They basically repeat a read even though there's no.",
                    "label": 0
                },
                {
                    "sent": "They repeat every day.",
                    "label": 0
                },
                {
                    "sent": "Just get stuck and there's no.",
                    "label": 0
                },
                {
                    "sent": "Support for it in the data, so the junction doesn't actually have such a high coverage, even though you're seeing a bunch of identical samples from it.",
                    "label": 0
                },
                {
                    "sent": "OK so I went back to the drawing board.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And wanted to add this.",
                    "label": 0
                },
                {
                    "sent": "Capture this into my factor model and so instead of observing instead of modeling the boson directly, I said what if.",
                    "label": 0
                },
                {
                    "sent": "I observe.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My observed counts are noisy version of this post on a model.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "If I have an outlier, just a binary variable which tells me yes, this is all I know it isn't.",
                    "label": 0
                },
                {
                    "sent": "I get.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This additive geometric noise, so if these two factors are enough to explain, say X of the counts, then the extra counts that could be the street stacks are explained by this geometric.",
                    "label": 0
                },
                {
                    "sent": "Additive noise.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see the math.",
                    "label": 0
                },
                {
                    "sent": "Here is a little bit hairier, so I'll just give you the solution.",
                    "label": 0
                },
                {
                    "sent": "You have the exact same part for the.",
                    "label": 0
                },
                {
                    "sent": "After model and here is the outline model and here is this key.",
                    "label": 0
                },
                {
                    "sent": "Outlier probability, so I'm actually learning this as well, and some of the positions in some of the issues and junctions will have a higher one and a lot of them will just stay close to 0.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is just the normalization.",
                    "label": 0
                },
                {
                    "sent": "So then step.",
                    "label": 0
                },
                {
                    "sent": "The optimization for these is done in the exact same way as before, and actually looks exactly the same with.",
                    "label": 0
                },
                {
                    "sent": "If you squint a little bit instead of using the raw counts observed counts, I'm essentially.",
                    "label": 0
                },
                {
                    "sent": "Seeing the expectation over this.",
                    "label": 0
                },
                {
                    "sent": "Empirical or or this proposal distribution here instead of the observed counts.",
                    "label": 0
                },
                {
                    "sent": "And so far from beta, and here is this.",
                    "label": 0
                },
                {
                    "sent": "So I have this parameter, so I'm increasing.",
                    "label": 0
                },
                {
                    "sent": "I've kind of snuck this past year.",
                    "label": 0
                },
                {
                    "sent": "I'm increasing the number of parameters I'm fitting, but I'm feeling sort of easier and easier parameters, so this is these are Bernoulli parameters.",
                    "label": 0
                },
                {
                    "sent": "They're much easier to fit them, so these continuous.",
                    "label": 0
                },
                {
                    "sent": "Multi factor parameters OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the result from.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "MM&M running M on the latent model and now you can see first data captures a lot more of this positional and tissue bias that I showed you before.",
                    "label": 0
                },
                {
                    "sent": "And Alpha also.",
                    "label": 0
                },
                {
                    "sent": "Sort of reflects that this is actually the log of Alpha, because there is very big variations between transcript expression so.",
                    "label": 0
                },
                {
                    "sent": "This is a lot more nuanced.",
                    "label": 0
                },
                {
                    "sent": "I mean can't read too much into this bunch of noise, but a bunch of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, color, but.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can evaluate how much better we've done and.",
                    "label": 0
                },
                {
                    "sent": "One way to evaluate is the machine learning way is to look at model fits or the likelihood of the self reported likelihood model and also try to sample some data from just dream up some data from these models and see how well it fits the observed data.",
                    "label": 0
                },
                {
                    "sent": "So there's caveats with both of these, likelihood is.",
                    "label": 0
                },
                {
                    "sent": "If you're overfitting the likelihood it would be great and also the reconstruction error at least.",
                    "label": 0
                },
                {
                    "sent": "Well, there's two caveats with this reconstruction is 1 is.",
                    "label": 0
                },
                {
                    "sent": "The observed counts are already noisy, so how well do you really want to?",
                    "label": 0
                },
                {
                    "sent": "State near them and the other one is.",
                    "label": 0
                },
                {
                    "sent": "This is sort of one of the standard ways to.",
                    "label": 0
                },
                {
                    "sent": "To measure reconstruction error and this is very biased towards the really high expression.",
                    "label": 0
                },
                {
                    "sent": "Junctions, which is not necessarily the most biologically interesting junctions, and so I.",
                    "label": 0
                },
                {
                    "sent": "Thought a little bit about this an.",
                    "label": 0
                },
                {
                    "sent": "Came up with the application as a form of evaluation.",
                    "label": 0
                },
                {
                    "sent": "Now this is not.",
                    "label": 0
                },
                {
                    "sent": "I don't actually have a gold standard for altering this blessing, and if you do, please let me know, but.",
                    "label": 0
                },
                {
                    "sent": "I could use my.",
                    "label": 0
                },
                {
                    "sent": "Approximation for the smooth.",
                    "label": 0
                },
                {
                    "sent": "It counts to calculate a log ratio between alternative.",
                    "label": 0
                },
                {
                    "sent": "Junctions an cathedral directions.",
                    "label": 0
                },
                {
                    "sent": "So sort of between transcripts that are contain alternative exon an the ones that don't tan.",
                    "label": 0
                },
                {
                    "sent": "Next speaker will tell you a lot more about alternative splicing, so I'm just kind of going out on a limb here and hoping they understand.",
                    "label": 0
                },
                {
                    "sent": "So OK.",
                    "label": 0
                },
                {
                    "sent": "When we just compare the, this is if you remember the notation.",
                    "label": 0
                },
                {
                    "sent": "This is a simple model, just.",
                    "label": 0
                },
                {
                    "sent": "Averaging across the positions, and this will be my sort of.",
                    "label": 0
                },
                {
                    "sent": "Four guns are latent factor model.",
                    "label": 0
                },
                {
                    "sent": "And the first one.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The simple model gives you something like this, so again, tissues on the axis junctions.",
                    "label": 0
                },
                {
                    "sent": "And here the junction is not 2500 but only 250, because these are the ones that have this alternative splicing structure, the constitutive versus alternative skipped exon.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This is what it is.",
                    "label": 0
                },
                {
                    "sent": "You see some junctions here that have.",
                    "label": 0
                },
                {
                    "sent": "Very consistent log ratios and.",
                    "label": 0
                },
                {
                    "sent": "I'll",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Skip to next one.",
                    "label": 0
                },
                {
                    "sent": "This is from the late model and you can see.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The junctions themselves are not so consistent anymore as as are the tissues and some of these gaps or so seeming gaps in the previous are sort of filled in by the extra smoothing by the outlier essentially.",
                    "label": 0
                },
                {
                    "sent": "I have no idea how I'm doing on time, but.",
                    "label": 0
                },
                {
                    "sent": "I'm done so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll just summarize and then there will be more time for questions.",
                    "label": 0
                },
                {
                    "sent": "OK so I.",
                    "label": 0
                },
                {
                    "sent": "First showed you what junction coverage looks like under an AC can is not what you see in the textbook.",
                    "label": 0
                },
                {
                    "sent": "Proposed a couple of for some models that try to fit it.",
                    "label": 0
                },
                {
                    "sent": "Not very well.",
                    "label": 0
                },
                {
                    "sent": "The send it to a late model which has sort of an explicit outlier.",
                    "label": 0
                },
                {
                    "sent": "Additive noise.",
                    "label": 0
                },
                {
                    "sent": "And finally, I didn't.",
                    "label": 0
                },
                {
                    "sent": "I didn't show you actual numbers, but.",
                    "label": 0
                },
                {
                    "sent": "The ordering goes pretty much what you assumed simple model for superseded by the factored model.",
                    "label": 0
                },
                {
                    "sent": "Superseded by the latent model.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I guess the question.",
                    "label": 0
                },
                {
                    "sent": "So do you know why there is?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                },
                {
                    "sent": "I would say if the.",
                    "label": 0
                },
                {
                    "sent": "Reads were actually order.",
                    "label": 0
                },
                {
                    "sent": "If I knew the strength of the rates of the real strand, I could tell you something about because the way.",
                    "label": 0
                },
                {
                    "sent": "You see, the positions is always from the start.",
                    "label": 0
                },
                {
                    "sent": "It's there's a lot higher.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there's a higher bias on left end that could just be.",
                    "label": 0
                },
                {
                    "sent": "The the GC bias around junctions being higher at sort of the donor Exxon.",
                    "label": 0
                },
                {
                    "sent": "So you could probably verify that by choosing I mean there shouldn't be much difference between the spice junction rates and breeds that spend any other position.",
                    "label": 0
                },
                {
                    "sent": "Write the body rate.",
                    "label": 0
                },
                {
                    "sent": "Sort of similar.",
                    "label": 0
                },
                {
                    "sent": "Similar characteristics like GC, whatever, right I could I could build a background model, you're right.",
                    "label": 0
                },
                {
                    "sent": "So some of the.",
                    "label": 0
                },
                {
                    "sent": "They in fact they are absolutely.",
                    "label": 0
                },
                {
                    "sent": "Also, you're just looking at the public.",
                    "label": 0
                },
                {
                    "sent": "Movie times.",
                    "label": 0
                },
                {
                    "sent": "Is so that.",
                    "label": 0
                },
                {
                    "sent": "Right, so that outlier will fill in for zero reads, but it's kind of a stretch so it doesn't doesn't fix the zeros as much, it's the positional bias that fixes the zero reads more.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "I don't know if this will answer it, but one thing I tried is tool, so we doubt the series is to use a more robust estimator than the mean.",
                    "label": 0
                },
                {
                    "sent": "So like median or something like that used, a bunch of them and they weren't significantly better in these evaluations now.",
                    "label": 0
                },
                {
                    "sent": "Exactly.",
                    "label": 0
                },
                {
                    "sent": "Could be yeah.",
                    "label": 0
                },
                {
                    "sent": "So maybe maybe we'll talk.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can discuss that after that.",
                    "label": 0
                },
                {
                    "sent": "So this indication why there are reports that very much depends on the 1st 6 Watt first 10 nucleotides of the read.",
                    "label": 0
                },
                {
                    "sent": "Whether the Reed is actually being sequenced or not OK if you take this into account.",
                    "label": 0
                },
                {
                    "sent": "One explanation for the non uniform recovers would be really depends on the dynamic weather on the exonic sequence, never that.",
                    "label": 0
                },
                {
                    "sent": "6 or 10 nucleotides.",
                    "label": 0
                },
                {
                    "sent": "What is right?",
                    "label": 0
                },
                {
                    "sent": "And if there was a favoring one, you get a lot of reads, and if there's a non favoring one this week, but what you're doing is not taking that into account, you're kind of smoothing smoothing that out I guess right?",
                    "label": 0
                },
                {
                    "sent": "So why not worldbuilding us sequence specific model modeling that that's next.",
                    "label": 0
                },
                {
                    "sent": "In fact, in more than one ways than one, it depends how your libraries made right.",
                    "label": 0
                },
                {
                    "sent": "You guys did the RT reactions.",
                    "label": 0
                },
                {
                    "sent": "You gotta prime it in some way.",
                    "label": 0
                },
                {
                    "sent": "Dragon's is 1 prime is one of the factors, but I mean that's why I asked about the library, how your libraries generated.",
                    "label": 0
                },
                {
                    "sent": "If you could to know the answer to that question.",
                    "label": 0
                },
                {
                    "sent": "I think there was one of them, so there are other models coming over this first pass on like an evening, binomial or like explicitly model that there is version compared to that for you.",
                    "label": 0
                },
                {
                    "sent": "So as an alternative to this mixture model.",
                    "label": 0
                },
                {
                    "sent": "I'm not aware of it, so maybe you can.",
                    "label": 0
                },
                {
                    "sent": "It might be a cheaper computationally cheaper alternative is what you think.",
                    "label": 0
                },
                {
                    "sent": "So there's just a couple questions if you try to compare it model with something.",
                    "label": 0
                },
                {
                    "sent": "Models like this something like regular ratio test or.",
                    "label": 0
                },
                {
                    "sent": "To sort of see whether the increasing number of parameters is statically significant.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Might have something to do.",
                    "label": 0
                },
                {
                    "sent": "All good ideas.",
                    "label": 0
                },
                {
                    "sent": "Further questions thanks.",
                    "label": 0
                }
            ]
        }
    }
}