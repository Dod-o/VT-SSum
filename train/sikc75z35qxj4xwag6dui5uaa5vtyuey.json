{
    "id": "sikc75z35qxj4xwag6dui5uaa5vtyuey",
    "title": "Transitioning legacy applications to ontologies: Hands-on tutorial - Learning Domain Ontologies",
    "info": {
        "author": [
            "Miha Gr\u010dar, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Aug. 8, 2008",
        "recorded": "June 2008",
        "category": [
            "Top->Computer Science->Data Visualisation",
            "Top->Computer Science->Semantic Web->Ontologies",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/eswc08_grcar_tla/",
    "segmentation": [
        [
            "My name is Nick Carter from yourself.",
            "Stephen Institute.",
            "And I will be talking about learning domain ontologies."
        ],
        [
            "So the goal of our work package in the project is to facilitate the acquisition of Domain ontologies by first identifying the data sources that contain the knowledge that we want to transition into ontologies.",
            "And then we employ several data mining techniques that aid the domain expert in building the ontology."
        ],
        [
            "Because we want to be very general, we use the term application mining.",
            "Which which basically means extracting knowledge from the data sources that are available in the context of a particular application.",
            "And for example, in one case we can have a set of with those services.",
            "In another case we can have a software repository.",
            "In yet another case, we can have a relational database and so on.",
            "So what we want to do.",
            "First we want to.",
            "Transition all these data sources into a kind of intermediate data representation so that our ontology learning algorithms would work for each of these cases.",
            "And finally, in the end produce an ontology."
        ],
        [
            "So what is this intermediate data representation?",
            "We defined it as being something with two major components.",
            "One is the structured data, right which are networks.",
            "One is the, the other is the unstructured data which are basically textual documents, and this structured data is suitable for link analysis.",
            "While this unstructured data is suitable for text mining.",
            "So basically what we are talking about is document networks, which is nothing else but a set of interlinked documents."
        ],
        [
            "OK.",
            "So the rest of this presentation is as follows.",
            "So first I would say few words about the data sources that we want to be able to grab.",
            "Then I will tell you how we create this document networks.",
            "Then I will talk about computing feature vectors out of this data and how to exploit the data in this feature vectors by using two applications, namely onto again and autosite to construct.",
            "Ontology.",
            "And then I will also talk about one of the case studies on the project.",
            "So this is the sole case.",
            "Study.",
            "The soul is a company in France, basically building aircrafts and you will hear about it more later on.",
            "So far it is from the.",
            "OK."
        ],
        [
            "So let's get to it.",
            "So the data sources we can basically roughly divide the data sources into two major categories, the structured and the unstructured data sources.",
            "The structured data sources are such as code samples, the source code itself, the software, or the web service usage logs, the database schemas, and so on.",
            "So this data sources contain a lot of structured information.",
            "The unstructured data sources are such as like content of web pages.",
            "The reference, manuals, lectures, forums, newsgroups, source code comments and the content in the database.",
            "So this would be roughly how we distinguish this data sources.",
            "Yeah.",
            "User Chuck would be something like this.",
            "This function is called immediately after that function.",
            "This many times something like that, so you are able to extract kind of flows of functions that you often used together to perform a certain task.",
            "OK, I will now show you a very simple example how to how to how to.",
            "Create a document network out of out of source."
        ],
        [
            "Code.",
            "So this is one of the classes from the gate case.",
            "Study gate is a software library for natural language processing.",
            "You will hear about it in more details later on.",
            "So this is one of the classes from this software library.",
            "It's a it's a Java class, right?",
            "And we can see that it contains several comments like the class comment field, comment method, comment.",
            "So this green stuff for comments.",
            "And what we can see in addition is that.",
            "It contains references to other Java classes, so it references other Java classes.",
            "In the comments we call these comment references.",
            "It references other classes here where you have Internet inheritance and interface implementation definition.",
            "It also references other classes where you have field types and parameter types, so we have all these text and all these references between."
        ],
        [
            "Different classes, so how do we exploit this?",
            "Basically so this is our class and we create an instance document format.",
            "We name it after after the class.",
            "And we attach the document, we attach a document to it and we create this document simply by taking all the comments or all the relevant comments out of the source code."
        ],
        [
            "And this is now our instance with the attached document.",
            "What we do next is we exploit this references.",
            "By simply linking referenced classes to the this observed class.",
            "So these are now comment references.",
            "We also have this interface implementation inheritance references, so we attach these as well, but notice that this is now a different relation.",
            "So basically we have here the comment reference relation and this is the inheritance relation.",
            "And we also have these three, so these type type references.",
            "We also attach this.",
            "So this is a very simple document network that we have now created out of source."
        ],
        [
            "Code.",
            "So this is how more real life Document Network looks like.",
            "This is actually a gate gate document document network, but it's only it only includes comment reference links because otherwise it's already a message that would be even bigger mess if we show all of them.",
            "So if we do."
        ],
        [
            "I mean, for example to this particular path, what we can see from this is that this class Gazetteer event references this one gets the tier two times in its comments.",
            "So basically this is the information contained in this."
        ],
        [
            "Network.",
            "OK, now what we want to do is we have this networks in these documents and we want to now create feature vectors out of these things because we want to exploit this feature vectors for ontology construction for clustering and other machine learning tasks.",
            "So OK, this is now our instance with the attached documents that we have just created and we have several.",
            "Different types of relations such as comment references, inheritance and type references, right?",
            "First we we convert all these to feature vectors so that each each instance in each of these sub networks is assigned one feature vector which is nothing else but just the row from the corresponding adjacency matrix.",
            "So this is how we currently do it.",
            "It's nothing fancy.",
            "And we also convert these documents into feature vectors by using this typical text mining technique by removing stopwords, supplying stemming, detecting engrams and in the end we compute the TF IDF vector.",
            "OK, now we have this.",
            "All these parts or this pieces of feature vectors.",
            "What we do is we first combine this structure feature vectors into one single structure feature vector per one instance by simply concatenating them together and waiting them with certain way.",
            "So maybe this information is more important.",
            "So for the resulting ontology.",
            "So we wait it higher right?",
            "In the end what we do is we simply concatenate.",
            "Constant feature vector which is the TF IDF vector to the structure feature vector and what we get is one single feature vector for one instance that we have here in the intermediate data format.",
            "OK so OK. Now we have feature vectors.",
            "So what?",
            "So basically now now we need to do something with them."
        ],
        [
            "And I will show you how we exploit the data in this feature vectors.",
            "For ontology construction by using basically 2 software applications, one is onto again, which is a system for data driven, semi automatic ontology construction, and the other one is on the site which basically just helps to set those weights because those Alpha beta gamma is I was showing before, so because those are tricky to set because it's intuitively it's hard to understand how will those rates influence the target ontology in the end."
        ],
        [
            "OK, so on to gain is the system is already set for data driven, semi automatic ontology construction.",
            "It is semi automatic 'cause it's an interactive tool and it's data driven cause the eight provided by the system is actually based on some underlying data.",
            "This this was so this application was developed in the European project checked and it is freely available on this URL address.",
            "OK."
        ],
        [
            "So.",
            "This is how the main window of font again looks like here.",
            "Here you have the hierarchy of concepts, so this is the ontology that we are currently working on.",
            "This is the visualization and these two views are synchronized.",
            "So here we have like a tree view and this graph view.",
            "And here we have the root concept and this red one is the selected concept and what we have here is some details about this selected concepts such as the name of the concept.",
            "The the keywords that describe this concept and the keywords that distinct this concept from the rest of the concept.",
            "So this is all automatically."
        ],
        [
            "Computed.",
            "And when we start on it again, it looks like this.",
            "So we just have the root concept and nothing else.",
            "But then we can ask the system to suggest the first level concepts for our ontology.",
            "So basically what we're building now is a taxonomical or subsumption structure of the ontology and we're simply using K means clustering.",
            "We give the number of clusters that we want to get and the system will compute the class."
        ],
        [
            "As for us, we can select them and simply add them to our root cluster and basically what we do then is we just repeat this process for whichever subconcept we decide and we build another level of sub concepts and another and another and so on."
        ],
        [
            "One more very nice feature of 1 to gain is that we can visualize the semantic space, which means that.",
            "The system would project all these instances, so this Yellow Creek Criss crosses are the instances, so each instance has has one feature vector assigned to it and this feature vectors are highly dimensional, but the system can project these vectors onto 2 dimensions and the property of this projection is that the instances that are more similar to each other with like close to closer together than those that are.",
            "This similar so we can see this dense regions.",
            "Dense regions of instances which basically represent on the concepts in the target ontology and we have.",
            "I don't know if you can see that we have a kind of context tool with which we explore this space and get and get an idea of what the concepts in the target ontology should be.",
            "So."
        ],
        [
            "This is this inspection tool.",
            "And this is again from the gate case study by looking at these concepts we can.",
            "This is just a simple example.",
            "We can find out that gate is about annotation data storage.",
            "It has an user interface, deals with war net and so on."
        ],
        [
            "OK. Now, but as I already said, when we build feature vectors, when we compute feature vectors, we have some weights like this.",
            "Dose Alpha, Beta, gamma that I've shown you and it's not easy to set those weights because it's not clear what will happen.",
            "So we developed another software called onto site which visualizes networks and semantic spaces to the user and interact with the user to help him or her decide which data to include into this feature vector computation process.",
            "And how to say those rates?",
            "So the demo of this software is available on the tower project website under Research and development demos and downloads, and I will now show you a demo video.",
            "OK, so basically we first load the document network.",
            "This is again the gate document network containing called those relations like inheritance type reference so on.",
            "And we decide to visualize inheritance type references, type reference and common reference relations.",
            "So the visualization we get is basically a graph.",
            "We can we see these networks, this graph graphs and we can explore the networks.",
            "So this is the inheritance networks and this is the.",
            "This is for example the common reference network.",
            "And what we can see here is that this class is synset, word sense, word, adjective and so on.",
            "They all refer to the class word net in their comments, which kind of makes them award.",
            "Net cluster.",
            "OK.",
            "So, but this is just the intermediate data layer layer.",
            "It's not yet a semantic space, but we can also visualize the semantic space by giving it a name.",
            "And here you can see are all these weights.",
            "So for each relation we are able to set the weight.",
            "So how much of this particular relation we want to include into the semantic space?",
            "And basically here we can just try several combinations to see what works best.",
            "So and.",
            "I will not go into details how this projection works, but I just want to show you the the entire pipeline.",
            "So first we do K means clustering.",
            "We do stress majorization to position center rates of these clusters.",
            "We compute K&K nearest neighbors for each of the instances, and in the end we employ the least squares solver to have the final layout.",
            "In the end, I don't want to go too much into this, but just to see the complexity of this projection.",
            "OK, and this is basically what's going on here.",
            "OK, and when this is done?",
            "We get this nice visualization similar to the one in Aunt again, and we can explore this dense pockets which which are basically a concept or potential concept to see whether this space makes sense for our task.",
            "And we can see that, for example, that Gates Gate employees Wordnet deals with ontologies.",
            "We see all these ontology related classes is about imitation.",
            "So also is as non expert we can as well get to know a notion of what the domain is about and if we are a domain expert then we can assess the quality of this semantic space for the task that we have in mind.",
            "OK, so basically we are exploring this space and I will skip this.",
            "OK, and we can also now convert another semantic space, different one, right?",
            "We just save this way differently and the space will be completely different, which means that the concepts of the target ontology will be different and the structure will be different and everything will be different.",
            "OK, so there we have it, another semantic space and it is completely different and this one can be more or it can be less suitable for the task that we have in mind, right?",
            "So the domain expert should explore it and decide whether this one is better than the other one or not.",
            "And basically the semantic space that.",
            "Is most suitable for our task is then exported to want again and once again is then used.",
            "For for semi automatic ontology construction through hierarchical clustering and things like that.",
            "OK, so this was on the site."
        ],
        [
            "OK, now I will say just to conclude, I will show you one of the case studies, which is that this whole case study so you will hear about the Soul case study and the motivation for this.",
            "So more about this later on in this tutorial.",
            "Far it will talk about this.",
            "So what is this case study about?",
            "It's about inclusion dependency detection in the relational databases.",
            "So what are inclusion dependencies?",
            "Inclusion dependences are basically implicit or hidden relationships between database tables.",
            "So ideally in the database you would have a schema and this schema would tell you that to databases are related through this in this field, but in reality this is not always true.",
            "Becausw the only the only let's say the only thing that keeps the relation between two databases is the application that fits the data into these tables.",
            "So you enter the name of the employee and these names goes in three tables and.",
            "Nobody knows that this is actually related, right?",
            "So the discovery of this dependencies is very important in the context of information integration, and also when we try to transition our relational database into an ontology.",
            "So the fact is that the sole databases which are pretty huge contain inclusion dependencies because they were developed gradually.",
            "And this dependency should be taken into account in the transitioning process, but their detection manually is very time consuming, so we believe that our methods can help detect."
        ],
        [
            "This including dependencies.",
            "So this is just one simple example.",
            "It's not the sole database, it's a very more simple one.",
            "So this is a database schema transitioned into an ontology.",
            "And so the tables are actually classes here and, but you can see here this class is like real person organization which is not really shouldn't really be a class.",
            "It should be a relation between a person, an organization, just like here.",
            "So here we have a class person and the relation here to the class organization.",
            "So these are these implicit relationships that needs to be discovered.",
            "So this is what we don't want.",
            "And this is what we want to get."
        ],
        [
            "OK, so we were given a data set, so it's basically we were given content of database tables and we were given a set of Golden standard inclusion dependencies.",
            "And our setting was, so we decided that the columns of this table should be instances and documents attached to those instances should simply be concatenated values in this columns.",
            "And we have defined several relations between these instances, one being the cosine similarity between these documents.",
            "So this is an obvious one.",
            "So the other would be this Levenshtein or a distance between column names.",
            "And two more which are based on sets.",
            "So Jakarta similarity between sets of values in this columns and we have also defined one alternative set similarity.",
            "So the important thing here is that we have defined four different similarity measures between database columns.",
            "And then we set, but the true or the best similarity between these columns is probably or.",
            "Let's say we modeled it as a linear combination of these four basic similarity measures."
        ],
        [
            "Now I will now show you, so we have we have developed a dedicated user interface to try to help detect inclusion.",
            "Depends and I'll show you a demo video.",
            "OK.",
            "So what you can see here.",
            "So each of these rows is actually a pair of columns, right?",
            "So two columns and these numbers.",
            "These are these are similarities between the corresponding two columns.",
            "According to the linear combination computed with this weights here.",
            "And this check box is right.",
            "If there is a check mark then this means that this column and pair is actually in the Golden standard.",
            "So we were given like 20 or so Golden standard inclusion dependencies, which I don't think that it's all of them, it's just several right that?",
            "There are people who are able to clearly identify, but it's hard to be systematic cause this list gets really huge.",
            "OK.",
            "So as I already said, these sliders are used to set the weights in the linear combination.",
            "So and we have then assessed the quality of this linear combination by computing the area under receiver operator characteristic curve.",
            "Basically what this tells us the.",
            "The higher the area the so if the area is really high or then all these check check marks are at the top of the list, and if it's really low there at the bottom of the list.",
            "So what basically what we want to do?",
            "We want to maximize this area.",
            "We want to push all the checkmarks to the top of the towards the top of the list.",
            "But by setting these weights.",
            "So that they will go up.",
            "OK, so so I forgot to mention that.",
            "When we waited all these things equally, we had like 91 point something coverage here right 91.33 and now let's see how these measures perform on their own, just one by one.",
            "So cosine similarity is only 60.5%, right?",
            "Name similarity is 86.3, so this is a good one.",
            "Jakarta similarity is pretty bad, so 23%.",
            "And this alternative similarities 5454.8%.",
            "So we can see that if we wait all these measures equally, we will get a better result than if we take each each of these separately.",
            "But now what we can do, we can run a stochastic optimization algorithm.",
            "That in through several iterations.",
            "I will just quickly explain how this works, so through several iterations it will compute.",
            "Optimal, or at least very good weights.",
            "So how does this work?",
            "We said so I will not go really into details are just like abstract a little bit.",
            "So we said initially this wait.",
            "And we re adjust.",
            "We assess their quality.",
            "So we compute this area.",
            "We readjust them in a smart way.",
            "We re assess the quality and if the quality is improved we take this new weight into account.",
            "Otherwise, we repeat the loop until the stopping criterion is reached.",
            "So this is basically what.",
            "What is happening here?",
            "So this loop is running?",
            "So let's see what we can get.",
            "So we have now computed this weights which basically give us 96.3% coverage of the area.",
            "So, but what is really interesting to see is that the name similarity, which was the best on its own right of all the measures, is now not waited the highest so the cosine similarity is rated the highest and then the name similarities like half of the cosine similarity.",
            "OK. Yeah, and we can see that all these checkmarks are really quite at the top of the list, right?",
            "Because the list is quite quite long here so most of them are there.",
            "Here and this which are ranked even higher right?",
            "And are not not checked, this should be explored by the user becausw.",
            "They are most probably additional inclusion dependencies.",
            "OK, so.",
            "That was the sole case tag team."
        ],
        [
            "OK, now I will just conclude this presentation.",
            "So what what I talked about is that, well, obviously applications in general are accompanied with various kinds of data.",
            "It's not just text, it's not just XML or something.",
            "It's it's many things.",
            "So we decided to abstract the data representation with document networks and I'll show you how we create feature vectors out of this document networks and how we then use software such as.",
            "Want again an on the site for semi automatic Ontology construction.",
            "OK, so that's it.",
            "If you have any questions, please go ahead.",
            "Once you've extracted this, there is probably going to be a problem of long term evolution because you probably gonna connect if you're happy that you have a semantics, you're going to want to connect it to your source code artifacts and have you looked into that?",
            "So.",
            "It's a bit So what you're saying, is it possible to kind of update this ontology because of because of the source data which change, right?",
            "It's it's a bit tricky because the resulting ontology that comes out from these tools is not perfect yet, so the user would then invest some manual labor to make it appropriate for the task, and then if the source data changes.",
            "Of course, this tool can be.",
            "These tools can be used again, but again the user will have to kind of.",
            "Fix some things manually now to let's say to build a system that would minimize this manual of adaptation right?",
            "And update the ontology according to the source data.",
            "It's not a trivial task, but we have looked a bit at it, but we haven't done any serious work on this yet.",
            "We could be modeling all kinds of semantic relationships in between all kinds of artifacts, and then have that evolve with the source code, which is kind of like what extreme programming.",
            "Once that the code is your model and then evolves.",
            "Should be cool.",
            "Yeah yeah yeah, I think this is actually would be.",
            "It would be possible to define the entire Tier 3 year project dedicated just just this is it's not a trivial task.",
            "We have one last question.",
            "Have you found out what the ratios between just semantics?",
            "That is in the source code and just noise?",
            "So I'm going to into the infrastructure and patterns and stuff.",
            "That's exactly what we are just now doing, so this in this last year we were basically doing a set of evaluations and this one of them is this.",
            "Basically we want to see we have a Golden standard and we do all these automatic stuff and we want to see how much of the good stuff is there and how much of noise and things like that.",
            "So this is to be done.",
            "Related to that, if you consider it when mining source codes to take into account the execution semantics of the programming language, yes, yes.",
            "So this would be another network showing which function is called after which one and how many times.",
            "So, so this is a very valuable piece of information that we plan to include, but we just didn't yet, yeah, But yes, this is this is good.",
            "Actually, when I was talking about structured and unstructured data, we also we also have a distinction between dynamics and dynamic and static data.",
            "So this execution locks will be very dynamic data.",
            "So this is also connected to your question about this evolution.",
            "So this dynamic data is changing all the time related issues question, you know that we will hand.",
            "Hopefully they're doing a lot of process mining work.",
            "So basically they try to reconstruct process models, workflows from log data, not just for website navigation, But from any kind of business process.",
            "Yeah, so maybe that could be an additional input structure for mining if you have execution logs, yeah?",
            "Yeah, and they have very.",
            "I mean you you target it but they have very sophisticated techniques.",
            "Or for example are trying to reconstruct control flows.",
            "Frequency of certain patterns in the execution.",
            "Yeah, yeah, I've been looking.",
            "I'm not sure if it's the same author.",
            "Group T, like I haven't seen that yet.",
            "Yeah, so thank you for this.",
            "Yeah, I will.",
            "We can exchange this information, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My name is Nick Carter from yourself.",
                    "label": 0
                },
                {
                    "sent": "Stephen Institute.",
                    "label": 0
                },
                {
                    "sent": "And I will be talking about learning domain ontologies.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the goal of our work package in the project is to facilitate the acquisition of Domain ontologies by first identifying the data sources that contain the knowledge that we want to transition into ontologies.",
                    "label": 0
                },
                {
                    "sent": "And then we employ several data mining techniques that aid the domain expert in building the ontology.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because we want to be very general, we use the term application mining.",
                    "label": 1
                },
                {
                    "sent": "Which which basically means extracting knowledge from the data sources that are available in the context of a particular application.",
                    "label": 0
                },
                {
                    "sent": "And for example, in one case we can have a set of with those services.",
                    "label": 0
                },
                {
                    "sent": "In another case we can have a software repository.",
                    "label": 0
                },
                {
                    "sent": "In yet another case, we can have a relational database and so on.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do.",
                    "label": 0
                },
                {
                    "sent": "First we want to.",
                    "label": 0
                },
                {
                    "sent": "Transition all these data sources into a kind of intermediate data representation so that our ontology learning algorithms would work for each of these cases.",
                    "label": 1
                },
                {
                    "sent": "And finally, in the end produce an ontology.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is this intermediate data representation?",
                    "label": 1
                },
                {
                    "sent": "We defined it as being something with two major components.",
                    "label": 0
                },
                {
                    "sent": "One is the structured data, right which are networks.",
                    "label": 0
                },
                {
                    "sent": "One is the, the other is the unstructured data which are basically textual documents, and this structured data is suitable for link analysis.",
                    "label": 1
                },
                {
                    "sent": "While this unstructured data is suitable for text mining.",
                    "label": 0
                },
                {
                    "sent": "So basically what we are talking about is document networks, which is nothing else but a set of interlinked documents.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the rest of this presentation is as follows.",
                    "label": 0
                },
                {
                    "sent": "So first I would say few words about the data sources that we want to be able to grab.",
                    "label": 1
                },
                {
                    "sent": "Then I will tell you how we create this document networks.",
                    "label": 1
                },
                {
                    "sent": "Then I will talk about computing feature vectors out of this data and how to exploit the data in this feature vectors by using two applications, namely onto again and autosite to construct.",
                    "label": 1
                },
                {
                    "sent": "Ontology.",
                    "label": 0
                },
                {
                    "sent": "And then I will also talk about one of the case studies on the project.",
                    "label": 0
                },
                {
                    "sent": "So this is the sole case.",
                    "label": 0
                },
                {
                    "sent": "Study.",
                    "label": 0
                },
                {
                    "sent": "The soul is a company in France, basically building aircrafts and you will hear about it more later on.",
                    "label": 0
                },
                {
                    "sent": "So far it is from the.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's get to it.",
                    "label": 0
                },
                {
                    "sent": "So the data sources we can basically roughly divide the data sources into two major categories, the structured and the unstructured data sources.",
                    "label": 0
                },
                {
                    "sent": "The structured data sources are such as code samples, the source code itself, the software, or the web service usage logs, the database schemas, and so on.",
                    "label": 1
                },
                {
                    "sent": "So this data sources contain a lot of structured information.",
                    "label": 0
                },
                {
                    "sent": "The unstructured data sources are such as like content of web pages.",
                    "label": 1
                },
                {
                    "sent": "The reference, manuals, lectures, forums, newsgroups, source code comments and the content in the database.",
                    "label": 0
                },
                {
                    "sent": "So this would be roughly how we distinguish this data sources.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "User Chuck would be something like this.",
                    "label": 0
                },
                {
                    "sent": "This function is called immediately after that function.",
                    "label": 0
                },
                {
                    "sent": "This many times something like that, so you are able to extract kind of flows of functions that you often used together to perform a certain task.",
                    "label": 0
                },
                {
                    "sent": "OK, I will now show you a very simple example how to how to how to.",
                    "label": 0
                },
                {
                    "sent": "Create a document network out of out of source.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Code.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the classes from the gate case.",
                    "label": 0
                },
                {
                    "sent": "Study gate is a software library for natural language processing.",
                    "label": 0
                },
                {
                    "sent": "You will hear about it in more details later on.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the classes from this software library.",
                    "label": 0
                },
                {
                    "sent": "It's a it's a Java class, right?",
                    "label": 1
                },
                {
                    "sent": "And we can see that it contains several comments like the class comment field, comment method, comment.",
                    "label": 1
                },
                {
                    "sent": "So this green stuff for comments.",
                    "label": 0
                },
                {
                    "sent": "And what we can see in addition is that.",
                    "label": 0
                },
                {
                    "sent": "It contains references to other Java classes, so it references other Java classes.",
                    "label": 0
                },
                {
                    "sent": "In the comments we call these comment references.",
                    "label": 0
                },
                {
                    "sent": "It references other classes here where you have Internet inheritance and interface implementation definition.",
                    "label": 0
                },
                {
                    "sent": "It also references other classes where you have field types and parameter types, so we have all these text and all these references between.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different classes, so how do we exploit this?",
                    "label": 0
                },
                {
                    "sent": "Basically so this is our class and we create an instance document format.",
                    "label": 0
                },
                {
                    "sent": "We name it after after the class.",
                    "label": 0
                },
                {
                    "sent": "And we attach the document, we attach a document to it and we create this document simply by taking all the comments or all the relevant comments out of the source code.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is now our instance with the attached document.",
                    "label": 0
                },
                {
                    "sent": "What we do next is we exploit this references.",
                    "label": 0
                },
                {
                    "sent": "By simply linking referenced classes to the this observed class.",
                    "label": 0
                },
                {
                    "sent": "So these are now comment references.",
                    "label": 0
                },
                {
                    "sent": "We also have this interface implementation inheritance references, so we attach these as well, but notice that this is now a different relation.",
                    "label": 0
                },
                {
                    "sent": "So basically we have here the comment reference relation and this is the inheritance relation.",
                    "label": 0
                },
                {
                    "sent": "And we also have these three, so these type type references.",
                    "label": 0
                },
                {
                    "sent": "We also attach this.",
                    "label": 0
                },
                {
                    "sent": "So this is a very simple document network that we have now created out of source.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Code.",
                    "label": 0
                },
                {
                    "sent": "So this is how more real life Document Network looks like.",
                    "label": 0
                },
                {
                    "sent": "This is actually a gate gate document document network, but it's only it only includes comment reference links because otherwise it's already a message that would be even bigger mess if we show all of them.",
                    "label": 0
                },
                {
                    "sent": "So if we do.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, for example to this particular path, what we can see from this is that this class Gazetteer event references this one gets the tier two times in its comments.",
                    "label": 0
                },
                {
                    "sent": "So basically this is the information contained in this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Network.",
                    "label": 0
                },
                {
                    "sent": "OK, now what we want to do is we have this networks in these documents and we want to now create feature vectors out of these things because we want to exploit this feature vectors for ontology construction for clustering and other machine learning tasks.",
                    "label": 0
                },
                {
                    "sent": "So OK, this is now our instance with the attached documents that we have just created and we have several.",
                    "label": 0
                },
                {
                    "sent": "Different types of relations such as comment references, inheritance and type references, right?",
                    "label": 0
                },
                {
                    "sent": "First we we convert all these to feature vectors so that each each instance in each of these sub networks is assigned one feature vector which is nothing else but just the row from the corresponding adjacency matrix.",
                    "label": 1
                },
                {
                    "sent": "So this is how we currently do it.",
                    "label": 0
                },
                {
                    "sent": "It's nothing fancy.",
                    "label": 0
                },
                {
                    "sent": "And we also convert these documents into feature vectors by using this typical text mining technique by removing stopwords, supplying stemming, detecting engrams and in the end we compute the TF IDF vector.",
                    "label": 0
                },
                {
                    "sent": "OK, now we have this.",
                    "label": 0
                },
                {
                    "sent": "All these parts or this pieces of feature vectors.",
                    "label": 1
                },
                {
                    "sent": "What we do is we first combine this structure feature vectors into one single structure feature vector per one instance by simply concatenating them together and waiting them with certain way.",
                    "label": 0
                },
                {
                    "sent": "So maybe this information is more important.",
                    "label": 0
                },
                {
                    "sent": "So for the resulting ontology.",
                    "label": 0
                },
                {
                    "sent": "So we wait it higher right?",
                    "label": 0
                },
                {
                    "sent": "In the end what we do is we simply concatenate.",
                    "label": 1
                },
                {
                    "sent": "Constant feature vector which is the TF IDF vector to the structure feature vector and what we get is one single feature vector for one instance that we have here in the intermediate data format.",
                    "label": 0
                },
                {
                    "sent": "OK so OK. Now we have feature vectors.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "So basically now now we need to do something with them.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I will show you how we exploit the data in this feature vectors.",
                    "label": 0
                },
                {
                    "sent": "For ontology construction by using basically 2 software applications, one is onto again, which is a system for data driven, semi automatic ontology construction, and the other one is on the site which basically just helps to set those weights because those Alpha beta gamma is I was showing before, so because those are tricky to set because it's intuitively it's hard to understand how will those rates influence the target ontology in the end.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so on to gain is the system is already set for data driven, semi automatic ontology construction.",
                    "label": 0
                },
                {
                    "sent": "It is semi automatic 'cause it's an interactive tool and it's data driven cause the eight provided by the system is actually based on some underlying data.",
                    "label": 1
                },
                {
                    "sent": "This this was so this application was developed in the European project checked and it is freely available on this URL address.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is how the main window of font again looks like here.",
                    "label": 0
                },
                {
                    "sent": "Here you have the hierarchy of concepts, so this is the ontology that we are currently working on.",
                    "label": 1
                },
                {
                    "sent": "This is the visualization and these two views are synchronized.",
                    "label": 1
                },
                {
                    "sent": "So here we have like a tree view and this graph view.",
                    "label": 1
                },
                {
                    "sent": "And here we have the root concept and this red one is the selected concept and what we have here is some details about this selected concepts such as the name of the concept.",
                    "label": 0
                },
                {
                    "sent": "The the keywords that describe this concept and the keywords that distinct this concept from the rest of the concept.",
                    "label": 0
                },
                {
                    "sent": "So this is all automatically.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Computed.",
                    "label": 0
                },
                {
                    "sent": "And when we start on it again, it looks like this.",
                    "label": 0
                },
                {
                    "sent": "So we just have the root concept and nothing else.",
                    "label": 0
                },
                {
                    "sent": "But then we can ask the system to suggest the first level concepts for our ontology.",
                    "label": 0
                },
                {
                    "sent": "So basically what we're building now is a taxonomical or subsumption structure of the ontology and we're simply using K means clustering.",
                    "label": 0
                },
                {
                    "sent": "We give the number of clusters that we want to get and the system will compute the class.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As for us, we can select them and simply add them to our root cluster and basically what we do then is we just repeat this process for whichever subconcept we decide and we build another level of sub concepts and another and another and so on.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One more very nice feature of 1 to gain is that we can visualize the semantic space, which means that.",
                    "label": 0
                },
                {
                    "sent": "The system would project all these instances, so this Yellow Creek Criss crosses are the instances, so each instance has has one feature vector assigned to it and this feature vectors are highly dimensional, but the system can project these vectors onto 2 dimensions and the property of this projection is that the instances that are more similar to each other with like close to closer together than those that are.",
                    "label": 0
                },
                {
                    "sent": "This similar so we can see this dense regions.",
                    "label": 0
                },
                {
                    "sent": "Dense regions of instances which basically represent on the concepts in the target ontology and we have.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you can see that we have a kind of context tool with which we explore this space and get and get an idea of what the concepts in the target ontology should be.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is this inspection tool.",
                    "label": 0
                },
                {
                    "sent": "And this is again from the gate case study by looking at these concepts we can.",
                    "label": 0
                },
                {
                    "sent": "This is just a simple example.",
                    "label": 0
                },
                {
                    "sent": "We can find out that gate is about annotation data storage.",
                    "label": 1
                },
                {
                    "sent": "It has an user interface, deals with war net and so on.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Now, but as I already said, when we build feature vectors, when we compute feature vectors, we have some weights like this.",
                    "label": 0
                },
                {
                    "sent": "Dose Alpha, Beta, gamma that I've shown you and it's not easy to set those weights because it's not clear what will happen.",
                    "label": 0
                },
                {
                    "sent": "So we developed another software called onto site which visualizes networks and semantic spaces to the user and interact with the user to help him or her decide which data to include into this feature vector computation process.",
                    "label": 1
                },
                {
                    "sent": "And how to say those rates?",
                    "label": 0
                },
                {
                    "sent": "So the demo of this software is available on the tower project website under Research and development demos and downloads, and I will now show you a demo video.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically we first load the document network.",
                    "label": 0
                },
                {
                    "sent": "This is again the gate document network containing called those relations like inheritance type reference so on.",
                    "label": 0
                },
                {
                    "sent": "And we decide to visualize inheritance type references, type reference and common reference relations.",
                    "label": 0
                },
                {
                    "sent": "So the visualization we get is basically a graph.",
                    "label": 0
                },
                {
                    "sent": "We can we see these networks, this graph graphs and we can explore the networks.",
                    "label": 0
                },
                {
                    "sent": "So this is the inheritance networks and this is the.",
                    "label": 0
                },
                {
                    "sent": "This is for example the common reference network.",
                    "label": 0
                },
                {
                    "sent": "And what we can see here is that this class is synset, word sense, word, adjective and so on.",
                    "label": 0
                },
                {
                    "sent": "They all refer to the class word net in their comments, which kind of makes them award.",
                    "label": 0
                },
                {
                    "sent": "Net cluster.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, but this is just the intermediate data layer layer.",
                    "label": 0
                },
                {
                    "sent": "It's not yet a semantic space, but we can also visualize the semantic space by giving it a name.",
                    "label": 0
                },
                {
                    "sent": "And here you can see are all these weights.",
                    "label": 0
                },
                {
                    "sent": "So for each relation we are able to set the weight.",
                    "label": 0
                },
                {
                    "sent": "So how much of this particular relation we want to include into the semantic space?",
                    "label": 0
                },
                {
                    "sent": "And basically here we can just try several combinations to see what works best.",
                    "label": 0
                },
                {
                    "sent": "So and.",
                    "label": 0
                },
                {
                    "sent": "I will not go into details how this projection works, but I just want to show you the the entire pipeline.",
                    "label": 0
                },
                {
                    "sent": "So first we do K means clustering.",
                    "label": 0
                },
                {
                    "sent": "We do stress majorization to position center rates of these clusters.",
                    "label": 0
                },
                {
                    "sent": "We compute K&K nearest neighbors for each of the instances, and in the end we employ the least squares solver to have the final layout.",
                    "label": 0
                },
                {
                    "sent": "In the end, I don't want to go too much into this, but just to see the complexity of this projection.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is basically what's going on here.",
                    "label": 0
                },
                {
                    "sent": "OK, and when this is done?",
                    "label": 0
                },
                {
                    "sent": "We get this nice visualization similar to the one in Aunt again, and we can explore this dense pockets which which are basically a concept or potential concept to see whether this space makes sense for our task.",
                    "label": 0
                },
                {
                    "sent": "And we can see that, for example, that Gates Gate employees Wordnet deals with ontologies.",
                    "label": 0
                },
                {
                    "sent": "We see all these ontology related classes is about imitation.",
                    "label": 0
                },
                {
                    "sent": "So also is as non expert we can as well get to know a notion of what the domain is about and if we are a domain expert then we can assess the quality of this semantic space for the task that we have in mind.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically we are exploring this space and I will skip this.",
                    "label": 0
                },
                {
                    "sent": "OK, and we can also now convert another semantic space, different one, right?",
                    "label": 0
                },
                {
                    "sent": "We just save this way differently and the space will be completely different, which means that the concepts of the target ontology will be different and the structure will be different and everything will be different.",
                    "label": 0
                },
                {
                    "sent": "OK, so there we have it, another semantic space and it is completely different and this one can be more or it can be less suitable for the task that we have in mind, right?",
                    "label": 0
                },
                {
                    "sent": "So the domain expert should explore it and decide whether this one is better than the other one or not.",
                    "label": 0
                },
                {
                    "sent": "And basically the semantic space that.",
                    "label": 0
                },
                {
                    "sent": "Is most suitable for our task is then exported to want again and once again is then used.",
                    "label": 0
                },
                {
                    "sent": "For for semi automatic ontology construction through hierarchical clustering and things like that.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was on the site.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now I will say just to conclude, I will show you one of the case studies, which is that this whole case study so you will hear about the Soul case study and the motivation for this.",
                    "label": 0
                },
                {
                    "sent": "So more about this later on in this tutorial.",
                    "label": 0
                },
                {
                    "sent": "Far it will talk about this.",
                    "label": 0
                },
                {
                    "sent": "So what is this case study about?",
                    "label": 0
                },
                {
                    "sent": "It's about inclusion dependency detection in the relational databases.",
                    "label": 0
                },
                {
                    "sent": "So what are inclusion dependencies?",
                    "label": 1
                },
                {
                    "sent": "Inclusion dependences are basically implicit or hidden relationships between database tables.",
                    "label": 1
                },
                {
                    "sent": "So ideally in the database you would have a schema and this schema would tell you that to databases are related through this in this field, but in reality this is not always true.",
                    "label": 0
                },
                {
                    "sent": "Becausw the only the only let's say the only thing that keeps the relation between two databases is the application that fits the data into these tables.",
                    "label": 0
                },
                {
                    "sent": "So you enter the name of the employee and these names goes in three tables and.",
                    "label": 0
                },
                {
                    "sent": "Nobody knows that this is actually related, right?",
                    "label": 0
                },
                {
                    "sent": "So the discovery of this dependencies is very important in the context of information integration, and also when we try to transition our relational database into an ontology.",
                    "label": 1
                },
                {
                    "sent": "So the fact is that the sole databases which are pretty huge contain inclusion dependencies because they were developed gradually.",
                    "label": 0
                },
                {
                    "sent": "And this dependency should be taken into account in the transitioning process, but their detection manually is very time consuming, so we believe that our methods can help detect.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This including dependencies.",
                    "label": 0
                },
                {
                    "sent": "So this is just one simple example.",
                    "label": 0
                },
                {
                    "sent": "It's not the sole database, it's a very more simple one.",
                    "label": 0
                },
                {
                    "sent": "So this is a database schema transitioned into an ontology.",
                    "label": 0
                },
                {
                    "sent": "And so the tables are actually classes here and, but you can see here this class is like real person organization which is not really shouldn't really be a class.",
                    "label": 0
                },
                {
                    "sent": "It should be a relation between a person, an organization, just like here.",
                    "label": 0
                },
                {
                    "sent": "So here we have a class person and the relation here to the class organization.",
                    "label": 0
                },
                {
                    "sent": "So these are these implicit relationships that needs to be discovered.",
                    "label": 0
                },
                {
                    "sent": "So this is what we don't want.",
                    "label": 0
                },
                {
                    "sent": "And this is what we want to get.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we were given a data set, so it's basically we were given content of database tables and we were given a set of Golden standard inclusion dependencies.",
                    "label": 1
                },
                {
                    "sent": "And our setting was, so we decided that the columns of this table should be instances and documents attached to those instances should simply be concatenated values in this columns.",
                    "label": 1
                },
                {
                    "sent": "And we have defined several relations between these instances, one being the cosine similarity between these documents.",
                    "label": 0
                },
                {
                    "sent": "So this is an obvious one.",
                    "label": 1
                },
                {
                    "sent": "So the other would be this Levenshtein or a distance between column names.",
                    "label": 0
                },
                {
                    "sent": "And two more which are based on sets.",
                    "label": 1
                },
                {
                    "sent": "So Jakarta similarity between sets of values in this columns and we have also defined one alternative set similarity.",
                    "label": 0
                },
                {
                    "sent": "So the important thing here is that we have defined four different similarity measures between database columns.",
                    "label": 0
                },
                {
                    "sent": "And then we set, but the true or the best similarity between these columns is probably or.",
                    "label": 0
                },
                {
                    "sent": "Let's say we modeled it as a linear combination of these four basic similarity measures.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I will now show you, so we have we have developed a dedicated user interface to try to help detect inclusion.",
                    "label": 0
                },
                {
                    "sent": "Depends and I'll show you a demo video.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So what you can see here.",
                    "label": 0
                },
                {
                    "sent": "So each of these rows is actually a pair of columns, right?",
                    "label": 0
                },
                {
                    "sent": "So two columns and these numbers.",
                    "label": 0
                },
                {
                    "sent": "These are these are similarities between the corresponding two columns.",
                    "label": 0
                },
                {
                    "sent": "According to the linear combination computed with this weights here.",
                    "label": 0
                },
                {
                    "sent": "And this check box is right.",
                    "label": 0
                },
                {
                    "sent": "If there is a check mark then this means that this column and pair is actually in the Golden standard.",
                    "label": 0
                },
                {
                    "sent": "So we were given like 20 or so Golden standard inclusion dependencies, which I don't think that it's all of them, it's just several right that?",
                    "label": 0
                },
                {
                    "sent": "There are people who are able to clearly identify, but it's hard to be systematic cause this list gets really huge.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So as I already said, these sliders are used to set the weights in the linear combination.",
                    "label": 0
                },
                {
                    "sent": "So and we have then assessed the quality of this linear combination by computing the area under receiver operator characteristic curve.",
                    "label": 0
                },
                {
                    "sent": "Basically what this tells us the.",
                    "label": 0
                },
                {
                    "sent": "The higher the area the so if the area is really high or then all these check check marks are at the top of the list, and if it's really low there at the bottom of the list.",
                    "label": 0
                },
                {
                    "sent": "So what basically what we want to do?",
                    "label": 0
                },
                {
                    "sent": "We want to maximize this area.",
                    "label": 0
                },
                {
                    "sent": "We want to push all the checkmarks to the top of the towards the top of the list.",
                    "label": 0
                },
                {
                    "sent": "But by setting these weights.",
                    "label": 0
                },
                {
                    "sent": "So that they will go up.",
                    "label": 0
                },
                {
                    "sent": "OK, so so I forgot to mention that.",
                    "label": 0
                },
                {
                    "sent": "When we waited all these things equally, we had like 91 point something coverage here right 91.33 and now let's see how these measures perform on their own, just one by one.",
                    "label": 0
                },
                {
                    "sent": "So cosine similarity is only 60.5%, right?",
                    "label": 0
                },
                {
                    "sent": "Name similarity is 86.3, so this is a good one.",
                    "label": 0
                },
                {
                    "sent": "Jakarta similarity is pretty bad, so 23%.",
                    "label": 0
                },
                {
                    "sent": "And this alternative similarities 5454.8%.",
                    "label": 0
                },
                {
                    "sent": "So we can see that if we wait all these measures equally, we will get a better result than if we take each each of these separately.",
                    "label": 0
                },
                {
                    "sent": "But now what we can do, we can run a stochastic optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "That in through several iterations.",
                    "label": 0
                },
                {
                    "sent": "I will just quickly explain how this works, so through several iterations it will compute.",
                    "label": 0
                },
                {
                    "sent": "Optimal, or at least very good weights.",
                    "label": 0
                },
                {
                    "sent": "So how does this work?",
                    "label": 0
                },
                {
                    "sent": "We said so I will not go really into details are just like abstract a little bit.",
                    "label": 0
                },
                {
                    "sent": "So we said initially this wait.",
                    "label": 0
                },
                {
                    "sent": "And we re adjust.",
                    "label": 0
                },
                {
                    "sent": "We assess their quality.",
                    "label": 0
                },
                {
                    "sent": "So we compute this area.",
                    "label": 0
                },
                {
                    "sent": "We readjust them in a smart way.",
                    "label": 0
                },
                {
                    "sent": "We re assess the quality and if the quality is improved we take this new weight into account.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, we repeat the loop until the stopping criterion is reached.",
                    "label": 0
                },
                {
                    "sent": "So this is basically what.",
                    "label": 0
                },
                {
                    "sent": "What is happening here?",
                    "label": 0
                },
                {
                    "sent": "So this loop is running?",
                    "label": 0
                },
                {
                    "sent": "So let's see what we can get.",
                    "label": 0
                },
                {
                    "sent": "So we have now computed this weights which basically give us 96.3% coverage of the area.",
                    "label": 0
                },
                {
                    "sent": "So, but what is really interesting to see is that the name similarity, which was the best on its own right of all the measures, is now not waited the highest so the cosine similarity is rated the highest and then the name similarities like half of the cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah, and we can see that all these checkmarks are really quite at the top of the list, right?",
                    "label": 0
                },
                {
                    "sent": "Because the list is quite quite long here so most of them are there.",
                    "label": 0
                },
                {
                    "sent": "Here and this which are ranked even higher right?",
                    "label": 0
                },
                {
                    "sent": "And are not not checked, this should be explored by the user becausw.",
                    "label": 0
                },
                {
                    "sent": "They are most probably additional inclusion dependencies.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That was the sole case tag team.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now I will just conclude this presentation.",
                    "label": 0
                },
                {
                    "sent": "So what what I talked about is that, well, obviously applications in general are accompanied with various kinds of data.",
                    "label": 1
                },
                {
                    "sent": "It's not just text, it's not just XML or something.",
                    "label": 0
                },
                {
                    "sent": "It's it's many things.",
                    "label": 1
                },
                {
                    "sent": "So we decided to abstract the data representation with document networks and I'll show you how we create feature vectors out of this document networks and how we then use software such as.",
                    "label": 0
                },
                {
                    "sent": "Want again an on the site for semi automatic Ontology construction.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's it.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions, please go ahead.",
                    "label": 0
                },
                {
                    "sent": "Once you've extracted this, there is probably going to be a problem of long term evolution because you probably gonna connect if you're happy that you have a semantics, you're going to want to connect it to your source code artifacts and have you looked into that?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's a bit So what you're saying, is it possible to kind of update this ontology because of because of the source data which change, right?",
                    "label": 0
                },
                {
                    "sent": "It's it's a bit tricky because the resulting ontology that comes out from these tools is not perfect yet, so the user would then invest some manual labor to make it appropriate for the task, and then if the source data changes.",
                    "label": 0
                },
                {
                    "sent": "Of course, this tool can be.",
                    "label": 0
                },
                {
                    "sent": "These tools can be used again, but again the user will have to kind of.",
                    "label": 0
                },
                {
                    "sent": "Fix some things manually now to let's say to build a system that would minimize this manual of adaptation right?",
                    "label": 0
                },
                {
                    "sent": "And update the ontology according to the source data.",
                    "label": 0
                },
                {
                    "sent": "It's not a trivial task, but we have looked a bit at it, but we haven't done any serious work on this yet.",
                    "label": 0
                },
                {
                    "sent": "We could be modeling all kinds of semantic relationships in between all kinds of artifacts, and then have that evolve with the source code, which is kind of like what extreme programming.",
                    "label": 0
                },
                {
                    "sent": "Once that the code is your model and then evolves.",
                    "label": 0
                },
                {
                    "sent": "Should be cool.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah yeah, I think this is actually would be.",
                    "label": 0
                },
                {
                    "sent": "It would be possible to define the entire Tier 3 year project dedicated just just this is it's not a trivial task.",
                    "label": 0
                },
                {
                    "sent": "We have one last question.",
                    "label": 0
                },
                {
                    "sent": "Have you found out what the ratios between just semantics?",
                    "label": 0
                },
                {
                    "sent": "That is in the source code and just noise?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to into the infrastructure and patterns and stuff.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what we are just now doing, so this in this last year we were basically doing a set of evaluations and this one of them is this.",
                    "label": 0
                },
                {
                    "sent": "Basically we want to see we have a Golden standard and we do all these automatic stuff and we want to see how much of the good stuff is there and how much of noise and things like that.",
                    "label": 0
                },
                {
                    "sent": "So this is to be done.",
                    "label": 0
                },
                {
                    "sent": "Related to that, if you consider it when mining source codes to take into account the execution semantics of the programming language, yes, yes.",
                    "label": 0
                },
                {
                    "sent": "So this would be another network showing which function is called after which one and how many times.",
                    "label": 0
                },
                {
                    "sent": "So, so this is a very valuable piece of information that we plan to include, but we just didn't yet, yeah, But yes, this is this is good.",
                    "label": 0
                },
                {
                    "sent": "Actually, when I was talking about structured and unstructured data, we also we also have a distinction between dynamics and dynamic and static data.",
                    "label": 0
                },
                {
                    "sent": "So this execution locks will be very dynamic data.",
                    "label": 0
                },
                {
                    "sent": "So this is also connected to your question about this evolution.",
                    "label": 0
                },
                {
                    "sent": "So this dynamic data is changing all the time related issues question, you know that we will hand.",
                    "label": 0
                },
                {
                    "sent": "Hopefully they're doing a lot of process mining work.",
                    "label": 0
                },
                {
                    "sent": "So basically they try to reconstruct process models, workflows from log data, not just for website navigation, But from any kind of business process.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so maybe that could be an additional input structure for mining if you have execution logs, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and they have very.",
                    "label": 0
                },
                {
                    "sent": "I mean you you target it but they have very sophisticated techniques.",
                    "label": 0
                },
                {
                    "sent": "Or for example are trying to reconstruct control flows.",
                    "label": 0
                },
                {
                    "sent": "Frequency of certain patterns in the execution.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, I've been looking.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if it's the same author.",
                    "label": 0
                },
                {
                    "sent": "Group T, like I haven't seen that yet.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so thank you for this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I will.",
                    "label": 0
                },
                {
                    "sent": "We can exchange this information, thanks.",
                    "label": 0
                }
            ]
        }
    }
}