{
    "id": "lvdy63ky4nsey33bb3yxmprsay7xp7pl",
    "title": "Expanding a Gazetteer-Based Approach for Geo-Parsing Disease Alerts",
    "info": {
        "author": [
            "Mikaela Keller, Children's Hospital Informatics Program, Children's Hospital Boston"
        ],
        "published": "Aug. 11, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_keller_egb/",
    "segmentation": [
        [
            "OK so yeah.",
            "So I'm Michaela killer.",
            "I'm doing a postdoc at Harvard Medical School.",
            "And the work I'm going to present it's carry out in a.",
            "In the framework of system that is developed at the."
        ],
        [
            "Children's Hospital informatics programs and which is called healthmap.",
            "House Map is a system that monitors media sources.",
            "Different kind of media sources for disease outbreak alert detection.",
            "And once it has detected this alert, it automatically find which diseases.",
            "It's involved in this alert and also map it automatically in the inner world."
        ],
        [
            "So this information is very interesting for for a lot of people we have.",
            "This website has 20,000 unique visitors per month.",
            "A lot of international and national.",
            "Website Entity website Site has map as a resource for.",
            "Epidemiology.",
            "And we see that most of the users are like Maine public health institutions, such as The Who.",
            "CDC Center for Disease Control and the European Center for Disease Control."
        ],
        [
            "So.",
            "How smart can can be?",
            "You can see it people from NLP quite easily can see that it can be decomposed in a number of problems from information retrieval and natural language processing.",
            "There is a document retrieval step where looking at these sources such as Google News, Moreover another more specialized sources trying to find when there is a disease outbreak and then there is a.",
            "Information extraction step, which is to find which diseases involve and.",
            "And also the geographic location so.",
            "My the work I'm going to present here, it's about Subs.",
            "Except Basque preceding the geographic mapping."
        ],
        [
            "Which is called Geo parsing.",
            "So I'm going to explain Geo parsing and how.",
            "How healthmap treat that task and how I tried to come without an extension of that?",
            "For that task and explain this extension and some experiments I've done with this approach."
        ],
        [
            "So what is geographical mapping is in fact called Geo indexing and sometimes in some communities an it's to associate lanja tude latitude or an index to a text.",
            "So geographic index to the text."
        ],
        [
            "This involves in general something called a gazetteer, which is a list of geographic keywords and phrases with their associated keyword with their associated index.",
            "So here it says just a number, but it can be a latitude lanja tude.",
            "And so, so that you have this huge list of keywords.",
            "And phrases, and now what you want to do, is to have to look to find into your text where are these keywords and phrases so you're able to give the index to the text."
        ],
        [
            "And that's what's called Geo parsing, which is extracting in the text relevant keywords and phrases.",
            "That then you look, you look up the key in the gazetteer."
        ],
        [
            "OK, so to give an intuition of of what this problem look like, let's look at how human do that or.",
            "I don't know so that you feel it.",
            "There is a some places that you don't know of that are out of your vocabulary.",
            "I don't know they were out of mine.",
            "I don't know this place is in now.",
            "I look them, but so there in Malaysia and so this phrase this sentence, investigations into missiles outbreak in long rumen Belaga district trivial.",
            "The cases originated from penance, living in cramped and sanitary conditions.",
            "And.",
            "We're able because of the context, to infer that in fact, long Brunanburh Gala are probably geographic locations, while pennants, which is also out of our dictionary.",
            "Doesn't seem to be a location because there is a very involving.",
            "I don't know about you, but then I can infer that this is not a.",
            "Geographic location so a human reader rely both on the lexical context if he knows.",
            "Lease to them the word referring to that place, but also a lot in the contextual information.",
            "And we can see that also what helped us decide that those are location is not only the syntax, but also capitalization.",
            "Maybe also the vowel distribution.",
            "Gang of things."
        ],
        [
            "That so as I said, due parsing is a can be seen as an information extraction problem.",
            "And in recent approaches for.",
            "Information extraction approaches such as a name, entity recognition, semantic role, labeling.",
            "There have been a.",
            "Huge database that have been labeled for that specific task.",
            "Particularly, I think in the semantic role labeling, this last years was a huge effort on tagging these datasets.",
            "But for each new test, you have to come with a new set of of.",
            "The set of annotating documents.",
            "So it is up is expensive to obtain.",
            "In on your hand, healthmap Hazard it's already working on on on on the simple method, having it has a. Gazetteer that was crafted really carefully by by an expert and.",
            "It has been done incrementally, so it has been a few one year of adding locations.",
            "And so for now, the only thing is it does it look up tree algorithm.",
            "So it goes.",
            "It takes a text and look at each word trying to see if it represents the gazetteer as a tree and it tries to find if that word is in the gazetteer.",
            "Which is not an approach that you can extend, because if you if you.",
            "If you want to have a so for now also the resolution of the mapping is only at the country level.",
            "For some places a little more like the state but not the city, not the villages, not so it's a.",
            "It's a low resolution, but we want to have a higher resolution and so that means a bigger gazetteer, much longer gazetteer.",
            "And so you cannot go by the look up tree algorithm because it would be too long.",
            "So we need the Geo parsing so fine before hand, which are the places that are geographic location to then look into into a gazetteer.",
            "OK, so.",
            "So the way to go.",
            "Probably the when on the statistical learning way of thinking, would be to have an annotated data set, but we don't have it.",
            "But we have this this carefully crafted gazetteer so.",
            "Should we try to do something with discuss?"
        ],
        [
            "Teacher.",
            "To show you how this 'cause it sure looks like, so that that's just an extract, but there's there's a adjectives places name.",
            "More precise place name and some colloquialism that also help find that this is in Australia.",
            "Hospitals Names adventure hospital names.",
            "Some also negative phrases like this is not a place Brazil nuts that would.",
            "It's not in Brazil than Canada goose, which happened a lot of time because of a flu.",
            "And it's not.",
            "It does happen to be in in Canada.",
            "And also like Center for Disease Control.",
            "If Center for Disease Control appear in the taxes, there's a chance that the alert is happening in the US.",
            "And so on.",
            "So things that are not from any gazetteer but specific for disease outbreak alerts.",
            "So."
        ],
        [
            "The main idea of this approach is to use all that information encoded in that gazetteer.",
            "And to label a data set of disease outbreak alert using the gazetteer.",
            "So taking the entries of the Gazetteer and and.",
            "Look, look looking at the context there appearing.",
            "Augment the data set with some extra linguistic information that we think it's interesting for this task, such as the part of speech to have an access to the syntax and also the capitalization stages.",
            "And then so if we just stop here and try to learn, we will just kind of overfit the information that is in the gazetteer, but.",
            "The idea is to to hide the the lexical information and try to retrieve to learn the generalization of the context.",
            "So, like in this example where the original sentence will be health authorities in New Caledonia are closely monitoring, monitoring and observed.",
            "Often give fever cases, and in our training set we will hide New Caledonia and in the hope that.",
            "The context will tell us that this is a location."
        ],
        [
            "OK, so let me now go into the how this is in."
        ],
        [
            "Invented.",
            "So we represent our words as a as this huge sparse vector where there is a first chunk of the 1st.",
            "The components are related to the dictionary index, so this is the lexical part.",
            "Then the next K components are related to the part of speech list, so I have the index of my part of speech tag and then the third.",
            "The last position are the capitalization status, which is among is it capitalizing the first position?",
            "Are all the letters capitalized or?",
            "It's not capitalized, so our data set.",
            "We label our data set with part of speech tags using a Tiger Tiger, part of speech tagger provided by.",
            "Publicly available by NEC Senior Project which has a high accuracy.",
            "I'm not a good person."
        ],
        [
            "OK, and so how do we implement the hiding of the words so we.",
            "Something which is intuitive is that words that are used to refer to four locations are less frequent than typical words, so by thresholding.",
            "The words by their frequency will in fact remove from the dictionary first or most more the location words, so that's what you can see here is.",
            "Hello on the separated validation set and held out data.",
            "If I look at the percentage of words that I that I hide when I cut my dictionary removing the.",
            "The words that appear less than four times, for example, and correspondingly the locations words that are going to be removed.",
            "You can see that it goes faster.",
            "So, so that's the mechanism we use to hide words."
        ],
        [
            "The data set.",
            "And so for learning.",
            "Generalization of this context.",
            "We have this task where what we want to do is to tag the words so the Geo parsing task.",
            "Which we want to tag the words of data set with a location tag or non location tag and for that we learn and run network that gives us the probability of the.",
            "Of the tag given.",
            "A window around the words we want to tag.",
            "And so this this is an architecture that is inspired by the.",
            "Language model proposed by Bandula in all and also something similar to what color and Western proposed for semantic role labeling."
        ],
        [
            "And so, so to explain a little better.",
            "We have a first year first multilayer perceptron that it's going to embed our really sparse vector into more compact representation.",
            "And and this.",
            "This first media president is learn.",
            "During during the training.",
            "And then the different element in the in the windows around the words are concatenated into a into a bigger vector that is itself passing to a second multilayer perception, which is going to do the classification task.",
            "The tagging part.",
            "And so all that is a is trained by stochastic gradient descent."
        ],
        [
            "So let me present the."
        ],
        [
            "Payment.",
            "So I've tried to to train on two different sizes training set.",
            "First one was 1000 alerts and the second one we said.",
            "2015 hundred alerts.",
            "And so yeah, so I told you that I tried also different sizes of.",
            "Demo frequency threshold.",
            "And so these are the dictionary sizes, corresponding string sizes.",
            "And I'm testing on a validation set of 1000 alerts and as you can see, it's a.",
            "It's an unbalanced problem classification problem.",
            "I have much less.",
            "Words that are tag's location that words are tag known.",
            "And so I've trained several of these neural network for each for each of these.",
            "Mean frequency points and so I have also standard deviation on the.",
            "On the neural network."
        ],
        [
            "So here is the first experiment.",
            "So here you have the the F score and here.",
            "Along this axis, I'm hiding more and more of the of the location words of more and more words so you can see that the perform performance decreases 'cause the problems become more and more difficult.",
            "Since I'm hiding more more of my.",
            "Words.",
            "But despite the fact that it's it's completely artificial data, I still have, I was looking only at the data set of 2015 hundred.",
            "Alerts I haven't reached no OK, I haven't reached yet the I still have something to extract from this data set since you can see the performance increases when I increase the size of my training set."
        ],
        [
            "But the interesting result is that if I look separately at the so in my validation in my validation set, I also have our hidden words and if I look separately at the.",
            "At the words that in fact have their lexical index at the hour or to the ones that are hidden.",
            "You can see that the most I hide the words in the training set, the performance I.",
            "Kind of have a I discover better in the validation set my hidden word so it's like it has a capacity of discovering knew locations because my hidden words are like new location that out of my gazetteer and so I'm discovering new locations.",
            "While not losing performances on the one that are inside of my of my or not not much inside of my car."
        ],
        [
            "That year OK, so I have presented a method that that I found quite interesting.",
            "It's kind of it's able to transfer prior knowledge encoded in a rule based approach because gazetteer is a kind of a rule based approach.",
            "And to transfer this prior knowledge to be using the statistical learning approach.",
            "Um?",
            "It is able to discover recover geographic references based only on the context in which they appear.",
            "Oh, and we can see that despite the fact that it is fabricated data.",
            "I haven't reached yet about a boundary.",
            "Maybe I have to trade with bigger training set size, but I still I'm still able to increase the performance.",
            "OK, there's a lot of future work to do.",
            "First of all, it's kind of the.",
            "This results are kind of biased because I'm I'm not testing in a in a true expert labeled data me Now it's.",
            "Still working on this, testing on fabricated data so, but what we would like is to know if if I had someone labeled what is the location is it would be?",
            "Would it be able to recover that also so one labeled by an expert?",
            "Um?",
            "It's it's also we would like to know if that that will improve the Geo index, because for now that's only the Geo parsing step.",
            "But would that improve the Geo indexing step that needs to be tested?",
            "And also think on adding more complex features as input.",
            "Or maybe now that I've seen talks on this conference at the Multi Task branch on the other side to see if if that helps the training, that's it.",
            "Thank you.",
            "Yes.",
            "One of the common problems with this sort of thing is handling is ambiguity.",
            "Yeah, so yeah that I think would be in this in the step that is Geo indexing for now you mean that there is Paris, TX and various friends.",
            "Cars category yeah yeah.",
            "Yeah, but that's that's not.",
            "That's the second step, which is.",
            "It's more in the Geo indexing part.",
            "For now, we're just Geo.",
            "Parsing is just trying to find where are the location in the text.",
            "Thank you again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so yeah.",
                    "label": 0
                },
                {
                    "sent": "So I'm Michaela killer.",
                    "label": 0
                },
                {
                    "sent": "I'm doing a postdoc at Harvard Medical School.",
                    "label": 0
                },
                {
                    "sent": "And the work I'm going to present it's carry out in a.",
                    "label": 0
                },
                {
                    "sent": "In the framework of system that is developed at the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Children's Hospital informatics programs and which is called healthmap.",
                    "label": 0
                },
                {
                    "sent": "House Map is a system that monitors media sources.",
                    "label": 0
                },
                {
                    "sent": "Different kind of media sources for disease outbreak alert detection.",
                    "label": 0
                },
                {
                    "sent": "And once it has detected this alert, it automatically find which diseases.",
                    "label": 0
                },
                {
                    "sent": "It's involved in this alert and also map it automatically in the inner world.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this information is very interesting for for a lot of people we have.",
                    "label": 1
                },
                {
                    "sent": "This website has 20,000 unique visitors per month.",
                    "label": 1
                },
                {
                    "sent": "A lot of international and national.",
                    "label": 1
                },
                {
                    "sent": "Website Entity website Site has map as a resource for.",
                    "label": 0
                },
                {
                    "sent": "Epidemiology.",
                    "label": 0
                },
                {
                    "sent": "And we see that most of the users are like Maine public health institutions, such as The Who.",
                    "label": 0
                },
                {
                    "sent": "CDC Center for Disease Control and the European Center for Disease Control.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "How smart can can be?",
                    "label": 0
                },
                {
                    "sent": "You can see it people from NLP quite easily can see that it can be decomposed in a number of problems from information retrieval and natural language processing.",
                    "label": 0
                },
                {
                    "sent": "There is a document retrieval step where looking at these sources such as Google News, Moreover another more specialized sources trying to find when there is a disease outbreak and then there is a.",
                    "label": 0
                },
                {
                    "sent": "Information extraction step, which is to find which diseases involve and.",
                    "label": 0
                },
                {
                    "sent": "And also the geographic location so.",
                    "label": 0
                },
                {
                    "sent": "My the work I'm going to present here, it's about Subs.",
                    "label": 0
                },
                {
                    "sent": "Except Basque preceding the geographic mapping.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which is called Geo parsing.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to explain Geo parsing and how.",
                    "label": 0
                },
                {
                    "sent": "How healthmap treat that task and how I tried to come without an extension of that?",
                    "label": 1
                },
                {
                    "sent": "For that task and explain this extension and some experiments I've done with this approach.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is geographical mapping is in fact called Geo indexing and sometimes in some communities an it's to associate lanja tude latitude or an index to a text.",
                    "label": 0
                },
                {
                    "sent": "So geographic index to the text.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This involves in general something called a gazetteer, which is a list of geographic keywords and phrases with their associated keyword with their associated index.",
                    "label": 1
                },
                {
                    "sent": "So here it says just a number, but it can be a latitude lanja tude.",
                    "label": 0
                },
                {
                    "sent": "And so, so that you have this huge list of keywords.",
                    "label": 0
                },
                {
                    "sent": "And phrases, and now what you want to do, is to have to look to find into your text where are these keywords and phrases so you're able to give the index to the text.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's what's called Geo parsing, which is extracting in the text relevant keywords and phrases.",
                    "label": 0
                },
                {
                    "sent": "That then you look, you look up the key in the gazetteer.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to give an intuition of of what this problem look like, let's look at how human do that or.",
                    "label": 0
                },
                {
                    "sent": "I don't know so that you feel it.",
                    "label": 0
                },
                {
                    "sent": "There is a some places that you don't know of that are out of your vocabulary.",
                    "label": 0
                },
                {
                    "sent": "I don't know they were out of mine.",
                    "label": 0
                },
                {
                    "sent": "I don't know this place is in now.",
                    "label": 0
                },
                {
                    "sent": "I look them, but so there in Malaysia and so this phrase this sentence, investigations into missiles outbreak in long rumen Belaga district trivial.",
                    "label": 1
                },
                {
                    "sent": "The cases originated from penance, living in cramped and sanitary conditions.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We're able because of the context, to infer that in fact, long Brunanburh Gala are probably geographic locations, while pennants, which is also out of our dictionary.",
                    "label": 0
                },
                {
                    "sent": "Doesn't seem to be a location because there is a very involving.",
                    "label": 0
                },
                {
                    "sent": "I don't know about you, but then I can infer that this is not a.",
                    "label": 1
                },
                {
                    "sent": "Geographic location so a human reader rely both on the lexical context if he knows.",
                    "label": 0
                },
                {
                    "sent": "Lease to them the word referring to that place, but also a lot in the contextual information.",
                    "label": 0
                },
                {
                    "sent": "And we can see that also what helped us decide that those are location is not only the syntax, but also capitalization.",
                    "label": 0
                },
                {
                    "sent": "Maybe also the vowel distribution.",
                    "label": 0
                },
                {
                    "sent": "Gang of things.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That so as I said, due parsing is a can be seen as an information extraction problem.",
                    "label": 1
                },
                {
                    "sent": "And in recent approaches for.",
                    "label": 1
                },
                {
                    "sent": "Information extraction approaches such as a name, entity recognition, semantic role, labeling.",
                    "label": 0
                },
                {
                    "sent": "There have been a.",
                    "label": 0
                },
                {
                    "sent": "Huge database that have been labeled for that specific task.",
                    "label": 0
                },
                {
                    "sent": "Particularly, I think in the semantic role labeling, this last years was a huge effort on tagging these datasets.",
                    "label": 0
                },
                {
                    "sent": "But for each new test, you have to come with a new set of of.",
                    "label": 1
                },
                {
                    "sent": "The set of annotating documents.",
                    "label": 0
                },
                {
                    "sent": "So it is up is expensive to obtain.",
                    "label": 0
                },
                {
                    "sent": "In on your hand, healthmap Hazard it's already working on on on on the simple method, having it has a. Gazetteer that was crafted really carefully by by an expert and.",
                    "label": 1
                },
                {
                    "sent": "It has been done incrementally, so it has been a few one year of adding locations.",
                    "label": 0
                },
                {
                    "sent": "And so for now, the only thing is it does it look up tree algorithm.",
                    "label": 0
                },
                {
                    "sent": "So it goes.",
                    "label": 0
                },
                {
                    "sent": "It takes a text and look at each word trying to see if it represents the gazetteer as a tree and it tries to find if that word is in the gazetteer.",
                    "label": 0
                },
                {
                    "sent": "Which is not an approach that you can extend, because if you if you.",
                    "label": 0
                },
                {
                    "sent": "If you want to have a so for now also the resolution of the mapping is only at the country level.",
                    "label": 0
                },
                {
                    "sent": "For some places a little more like the state but not the city, not the villages, not so it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a low resolution, but we want to have a higher resolution and so that means a bigger gazetteer, much longer gazetteer.",
                    "label": 0
                },
                {
                    "sent": "And so you cannot go by the look up tree algorithm because it would be too long.",
                    "label": 0
                },
                {
                    "sent": "So we need the Geo parsing so fine before hand, which are the places that are geographic location to then look into into a gazetteer.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So the way to go.",
                    "label": 0
                },
                {
                    "sent": "Probably the when on the statistical learning way of thinking, would be to have an annotated data set, but we don't have it.",
                    "label": 0
                },
                {
                    "sent": "But we have this this carefully crafted gazetteer so.",
                    "label": 0
                },
                {
                    "sent": "Should we try to do something with discuss?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Teacher.",
                    "label": 0
                },
                {
                    "sent": "To show you how this 'cause it sure looks like, so that that's just an extract, but there's there's a adjectives places name.",
                    "label": 0
                },
                {
                    "sent": "More precise place name and some colloquialism that also help find that this is in Australia.",
                    "label": 0
                },
                {
                    "sent": "Hospitals Names adventure hospital names.",
                    "label": 0
                },
                {
                    "sent": "Some also negative phrases like this is not a place Brazil nuts that would.",
                    "label": 0
                },
                {
                    "sent": "It's not in Brazil than Canada goose, which happened a lot of time because of a flu.",
                    "label": 0
                },
                {
                    "sent": "And it's not.",
                    "label": 0
                },
                {
                    "sent": "It does happen to be in in Canada.",
                    "label": 0
                },
                {
                    "sent": "And also like Center for Disease Control.",
                    "label": 0
                },
                {
                    "sent": "If Center for Disease Control appear in the taxes, there's a chance that the alert is happening in the US.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So things that are not from any gazetteer but specific for disease outbreak alerts.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main idea of this approach is to use all that information encoded in that gazetteer.",
                    "label": 0
                },
                {
                    "sent": "And to label a data set of disease outbreak alert using the gazetteer.",
                    "label": 1
                },
                {
                    "sent": "So taking the entries of the Gazetteer and and.",
                    "label": 0
                },
                {
                    "sent": "Look, look looking at the context there appearing.",
                    "label": 0
                },
                {
                    "sent": "Augment the data set with some extra linguistic information that we think it's interesting for this task, such as the part of speech to have an access to the syntax and also the capitalization stages.",
                    "label": 0
                },
                {
                    "sent": "And then so if we just stop here and try to learn, we will just kind of overfit the information that is in the gazetteer, but.",
                    "label": 1
                },
                {
                    "sent": "The idea is to to hide the the lexical information and try to retrieve to learn the generalization of the context.",
                    "label": 1
                },
                {
                    "sent": "So, like in this example where the original sentence will be health authorities in New Caledonia are closely monitoring, monitoring and observed.",
                    "label": 1
                },
                {
                    "sent": "Often give fever cases, and in our training set we will hide New Caledonia and in the hope that.",
                    "label": 0
                },
                {
                    "sent": "The context will tell us that this is a location.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me now go into the how this is in.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Invented.",
                    "label": 0
                },
                {
                    "sent": "So we represent our words as a as this huge sparse vector where there is a first chunk of the 1st.",
                    "label": 0
                },
                {
                    "sent": "The components are related to the dictionary index, so this is the lexical part.",
                    "label": 0
                },
                {
                    "sent": "Then the next K components are related to the part of speech list, so I have the index of my part of speech tag and then the third.",
                    "label": 0
                },
                {
                    "sent": "The last position are the capitalization status, which is among is it capitalizing the first position?",
                    "label": 0
                },
                {
                    "sent": "Are all the letters capitalized or?",
                    "label": 0
                },
                {
                    "sent": "It's not capitalized, so our data set.",
                    "label": 0
                },
                {
                    "sent": "We label our data set with part of speech tags using a Tiger Tiger, part of speech tagger provided by.",
                    "label": 0
                },
                {
                    "sent": "Publicly available by NEC Senior Project which has a high accuracy.",
                    "label": 0
                },
                {
                    "sent": "I'm not a good person.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and so how do we implement the hiding of the words so we.",
                    "label": 0
                },
                {
                    "sent": "Something which is intuitive is that words that are used to refer to four locations are less frequent than typical words, so by thresholding.",
                    "label": 1
                },
                {
                    "sent": "The words by their frequency will in fact remove from the dictionary first or most more the location words, so that's what you can see here is.",
                    "label": 0
                },
                {
                    "sent": "Hello on the separated validation set and held out data.",
                    "label": 0
                },
                {
                    "sent": "If I look at the percentage of words that I that I hide when I cut my dictionary removing the.",
                    "label": 0
                },
                {
                    "sent": "The words that appear less than four times, for example, and correspondingly the locations words that are going to be removed.",
                    "label": 0
                },
                {
                    "sent": "You can see that it goes faster.",
                    "label": 0
                },
                {
                    "sent": "So, so that's the mechanism we use to hide words.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The data set.",
                    "label": 0
                },
                {
                    "sent": "And so for learning.",
                    "label": 0
                },
                {
                    "sent": "Generalization of this context.",
                    "label": 0
                },
                {
                    "sent": "We have this task where what we want to do is to tag the words so the Geo parsing task.",
                    "label": 0
                },
                {
                    "sent": "Which we want to tag the words of data set with a location tag or non location tag and for that we learn and run network that gives us the probability of the.",
                    "label": 0
                },
                {
                    "sent": "Of the tag given.",
                    "label": 0
                },
                {
                    "sent": "A window around the words we want to tag.",
                    "label": 0
                },
                {
                    "sent": "And so this this is an architecture that is inspired by the.",
                    "label": 0
                },
                {
                    "sent": "Language model proposed by Bandula in all and also something similar to what color and Western proposed for semantic role labeling.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so, so to explain a little better.",
                    "label": 0
                },
                {
                    "sent": "We have a first year first multilayer perceptron that it's going to embed our really sparse vector into more compact representation.",
                    "label": 1
                },
                {
                    "sent": "And and this.",
                    "label": 0
                },
                {
                    "sent": "This first media president is learn.",
                    "label": 0
                },
                {
                    "sent": "During during the training.",
                    "label": 0
                },
                {
                    "sent": "And then the different element in the in the windows around the words are concatenated into a into a bigger vector that is itself passing to a second multilayer perception, which is going to do the classification task.",
                    "label": 0
                },
                {
                    "sent": "The tagging part.",
                    "label": 0
                },
                {
                    "sent": "And so all that is a is trained by stochastic gradient descent.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me present the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Payment.",
                    "label": 0
                },
                {
                    "sent": "So I've tried to to train on two different sizes training set.",
                    "label": 0
                },
                {
                    "sent": "First one was 1000 alerts and the second one we said.",
                    "label": 1
                },
                {
                    "sent": "2015 hundred alerts.",
                    "label": 0
                },
                {
                    "sent": "And so yeah, so I told you that I tried also different sizes of.",
                    "label": 0
                },
                {
                    "sent": "Demo frequency threshold.",
                    "label": 0
                },
                {
                    "sent": "And so these are the dictionary sizes, corresponding string sizes.",
                    "label": 0
                },
                {
                    "sent": "And I'm testing on a validation set of 1000 alerts and as you can see, it's a.",
                    "label": 1
                },
                {
                    "sent": "It's an unbalanced problem classification problem.",
                    "label": 0
                },
                {
                    "sent": "I have much less.",
                    "label": 0
                },
                {
                    "sent": "Words that are tag's location that words are tag known.",
                    "label": 1
                },
                {
                    "sent": "And so I've trained several of these neural network for each for each of these.",
                    "label": 0
                },
                {
                    "sent": "Mean frequency points and so I have also standard deviation on the.",
                    "label": 0
                },
                {
                    "sent": "On the neural network.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the first experiment.",
                    "label": 0
                },
                {
                    "sent": "So here you have the the F score and here.",
                    "label": 0
                },
                {
                    "sent": "Along this axis, I'm hiding more and more of the of the location words of more and more words so you can see that the perform performance decreases 'cause the problems become more and more difficult.",
                    "label": 0
                },
                {
                    "sent": "Since I'm hiding more more of my.",
                    "label": 0
                },
                {
                    "sent": "Words.",
                    "label": 0
                },
                {
                    "sent": "But despite the fact that it's it's completely artificial data, I still have, I was looking only at the data set of 2015 hundred.",
                    "label": 0
                },
                {
                    "sent": "Alerts I haven't reached no OK, I haven't reached yet the I still have something to extract from this data set since you can see the performance increases when I increase the size of my training set.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the interesting result is that if I look separately at the so in my validation in my validation set, I also have our hidden words and if I look separately at the.",
                    "label": 0
                },
                {
                    "sent": "At the words that in fact have their lexical index at the hour or to the ones that are hidden.",
                    "label": 0
                },
                {
                    "sent": "You can see that the most I hide the words in the training set, the performance I.",
                    "label": 0
                },
                {
                    "sent": "Kind of have a I discover better in the validation set my hidden word so it's like it has a capacity of discovering knew locations because my hidden words are like new location that out of my gazetteer and so I'm discovering new locations.",
                    "label": 0
                },
                {
                    "sent": "While not losing performances on the one that are inside of my of my or not not much inside of my car.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That year OK, so I have presented a method that that I found quite interesting.",
                    "label": 1
                },
                {
                    "sent": "It's kind of it's able to transfer prior knowledge encoded in a rule based approach because gazetteer is a kind of a rule based approach.",
                    "label": 0
                },
                {
                    "sent": "And to transfer this prior knowledge to be using the statistical learning approach.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It is able to discover recover geographic references based only on the context in which they appear.",
                    "label": 1
                },
                {
                    "sent": "Oh, and we can see that despite the fact that it is fabricated data.",
                    "label": 0
                },
                {
                    "sent": "I haven't reached yet about a boundary.",
                    "label": 0
                },
                {
                    "sent": "Maybe I have to trade with bigger training set size, but I still I'm still able to increase the performance.",
                    "label": 0
                },
                {
                    "sent": "OK, there's a lot of future work to do.",
                    "label": 0
                },
                {
                    "sent": "First of all, it's kind of the.",
                    "label": 0
                },
                {
                    "sent": "This results are kind of biased because I'm I'm not testing in a in a true expert labeled data me Now it's.",
                    "label": 0
                },
                {
                    "sent": "Still working on this, testing on fabricated data so, but what we would like is to know if if I had someone labeled what is the location is it would be?",
                    "label": 0
                },
                {
                    "sent": "Would it be able to recover that also so one labeled by an expert?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "It's it's also we would like to know if that that will improve the Geo index, because for now that's only the Geo parsing step.",
                    "label": 0
                },
                {
                    "sent": "But would that improve the Geo indexing step that needs to be tested?",
                    "label": 0
                },
                {
                    "sent": "And also think on adding more complex features as input.",
                    "label": 0
                },
                {
                    "sent": "Or maybe now that I've seen talks on this conference at the Multi Task branch on the other side to see if if that helps the training, that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "One of the common problems with this sort of thing is handling is ambiguity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so yeah that I think would be in this in the step that is Geo indexing for now you mean that there is Paris, TX and various friends.",
                    "label": 0
                },
                {
                    "sent": "Cars category yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but that's that's not.",
                    "label": 0
                },
                {
                    "sent": "That's the second step, which is.",
                    "label": 0
                },
                {
                    "sent": "It's more in the Geo indexing part.",
                    "label": 0
                },
                {
                    "sent": "For now, we're just Geo.",
                    "label": 0
                },
                {
                    "sent": "Parsing is just trying to find where are the location in the text.",
                    "label": 0
                },
                {
                    "sent": "Thank you again.",
                    "label": 0
                }
            ]
        }
    }
}