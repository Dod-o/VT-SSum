{
    "id": "esq56dbwrtkfliamgqadfqbauymbjmyu",
    "title": "Refraction Wiggles for Measuring Fluid Depth and Velocity from Video",
    "info": {
        "author": [
            "Tianfan Xue, Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, MIT"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2014_xue_fluid_depth/",
    "segmentation": [
        [
            "How everyone I'm championship today I will present the work to measure the depth and velocity of reflective food off low."
        ],
        [
            "In particular, we're going to measure the free flow from natural video sequence, so here's the set up.",
            "A camera is an image in the texture background through hot air because the hot air has different index refraction compared with surroundings.",
            "Light Ray bands, when passing through it.",
            "This will generate some tiny distortion observed sequence.",
            "And today I will show that by analyzing distortion we can recover the motion of hot air.",
            "Like this?",
            "And Furthermore, if you have Stewart cameras that we can also recover the depth of hot air."
        ],
        [
            "So here's an example.",
            "We take a video of burning candles in front of a brick wall.",
            "We can hardly see any air flows in this input videos, but surprisingly orelsan can recover motion of how earth above the candles like this just from this input video.",
            "Furthermore, from serial sequence we can also recover depth low air flow like this."
        ],
        [
            "So here's the outline of today's talk.",
            "Let us first discuss some previous work in this area.",
            "Then I will talk about our Epson and at the end will show some experimental results."
        ],
        [
            "There are many potential applications for free motion estimation at the airport.",
            "It can be used to detect harmful wake vortex so airplane can take off or land more safely.",
            "In the factory it can also be used to detect the toxic gas."
        ],
        [
            "There are couple of techniques in the literature.",
            "Try to visualize and magical fruitful.",
            "One technique is called a particle image.",
            "Below symmetry.",
            "In this method some tiny tracers like dust or die are inserted into fluid.",
            "In this image a green tracer is used.",
            "Therefore the fully motion is measured.",
            "By tracking these tracers.",
            "However, the complete set up makes this method not easy to use for many applications."
        ],
        [
            "Another method is called sharing the Lance system show on the left transformed the distortion caused by airflow into intensities so the airflow become visible as shown in the middle.",
            "The motion of food can be further recovered using Technicolor children PIV, as shown on the right.",
            "However, both children unshaven PIV has a complicated setup, and it's hard to use outside the lab."
        ],
        [
            "So recently to simplify the setup, people propose a method called background Orange children or both of you or ask for short.",
            "Similar to our work, it is simply take a video of air flows in front of texture background.",
            "As shown on the left, then instruction distortions and show on the right buttons.",
            "This method has very simple setup setup and very easy to use, but it can only visualize not measured airflow."
        ],
        [
            "So to summarize, traditional children technique can only visualize airflow, particle image velocimetry or ceiling PIV.",
            "Both visualize and measure air flow, but they follow all of these three methods, has a complicated setup.",
            "On the contrary, be OS very simple setup like only requires the natural video as input, but it only for visualization and our wiggle stereo and we go flow algorithm which I will introduce some laughter.",
            "Can both measure the visualize and measure the depth and velocity airflow and it has a simple set as the OS."
        ],
        [
            "So now let me introduce our algorithm."
        ],
        [
            "Recorded, our task is to recover the velocity and depth of air flow from natural video sequence because the airflow are transparent.",
            "If we simply apply the standard stereo optical flow algorithms are input.",
            "Videos will only get it adapts or velocity of the solid object like candles or bricks in these videos, but would be interested in air flow.",
            "To solve this problem, we proposed a wiggle features.",
            "We are sure that now if we run the standard object for the stereo on this wiggle feature, we will get the correct motion, corrected velocity and depth of air flow."
        ],
        [
            "Let us first define what we go feature is considering this.",
            "Set up a camera is image in the background.",
            "Your hot air at time T. If we trace back from the camera to the background, the capture sequence looks like this.",
            "Now in the next frame, when the air bubble moves due to the change of reflections, the light race bands.",
            "This will generate some tiny distortion.",
            "An observer sequence as shown here, and we define distortion as we go feature.",
            "So in short, the definition of wiggle feature is the distortion due to the refraction."
        ],
        [
            "So here's how the week feature looks like from the candle sequence are shown at the beginning of the week.",
            "Features 2D vectors and we visualize it, but mapping into RGB color using the color will be low.",
            "From this video you can clearly see the wiggle feature acts like tracers, so we should be able to get in motion of a motion and depth of the footage from this legal feature."
        ],
        [
            "Now let me show how to do that.",
            "Let's start with depth."
        ],
        [
            "Our main observation is that to recover the depth of air flow, we can still use the standard stereo algorithm, but on the wiggle features, not on the input intensity videos.",
            "So here's the explanation.",
            "Consider two cameras.",
            "Imagine a solid background through hot air, still matching on intensities will only find a depth of solid background.",
            "This is because airflow is almost transparent.",
            "So if we project the point on the background to the left and right views, the projected interest intensity should be the same.",
            "Notice that now if we pick a point on air flows, the project intensity until use are different, so intensity does not work with reflective object.",
            "However, we go features from left, unreal, left and right views corresponding to this point a consistent.",
            "Here's the illustration for this constancy.",
            "When the reflective object moves, the light Rays from left and right views bands due to the change of reflection, and because these two light Rays passing through the same point on the reflector object, they should bend in the same way as shown here.",
            "As a consequence, we observed the same of the same distortions on left and right views, meaning the wiggle feature from left and right views are the same.",
            "So this is, this is what we called wiggle constancy.",
            "So to summarize, because we have the wiggle constancy, we can get a depth of reflective object object by stereo matching on wiggle features, just like we can get a depth of solid object by string matching on intensities."
        ],
        [
            "Let us apply this regal stereo to candle sequence we have shown before.",
            "Notice that we go feature from left and right views within this.",
            "Red rectangles are quite similar.",
            "Therefore still matching on wiggle features, we can recover the disparity map of airflow as shown here."
        ],
        [
            "Now let us move to the velocity estimation.",
            "Similarly, the same notion wiggle constancy are shown for stereo case also applies to neighboring frames in videos, which means we can use for flow."
        ],
        [
            "Now we only have 1 camera.",
            "The task of velocity estimation is to find a movement of reflective object that is like air flow from T1 to T2.",
            "Where T1 and T2 are close enough frames.",
            "Similar to stereo, we need to find a feature that is consistent between these two frames so we can track the motion for reflective object.",
            "By using this feature.",
            "Again, intensity is not good for each feature because for the same."
        ],
        [
            "Point on the object, the corresponding intensity on T1 and T2 are not the same.",
            "However, the wiggle motion added.",
            "These two frames are still consistent.",
            "To illustrate this, let us consider two small time intervals around T1 and T2 respectively.",
            "Within these two time intervals, the movement of reflective object generate distortion on captured sequence like this.",
            "Again, because the light Rays at T wanted to pass through the same point on reflective objects, they should bend in the same way, resulting the same wiggle features.",
            "And this is the wiggle constancy for flow.",
            "Now, because the wiggle features are consistent from T1 to T2, similarly, we can then get the free motion by calculating the optical flow of wiggle features from T1 to T2."
        ],
        [
            "Again, let us still use this candle sequence to demonstrate this.",
            "When we play the video slowly, you can see that we go features between neighboring frames consistent.",
            "Therefore, if you apply the optic flow on the video show on the left will get velocity airflow shown on the right."
        ],
        [
            "Now let us summarize.",
            "Summarize by this table the brightness constancy holds for the solid object.",
            "So optical flow and stereo for solid object is based on the intensities.",
            "However, if of reflective object present constancy fails but the refractory constancy still holds.",
            "Therefore for reflective object we should use the regal features."
        ],
        [
            "At last, or discuss how to improve robustness of the of our algorithm."
        ],
        [
            "So in all the previous slides, we do not consider sensor noise.",
            "However, the Wiggle feature is very sensitive to sensor noise because they're very small.",
            "Just giving you a sense.",
            "Normally the weaker features in order of 0.1 pixels, so this is very small.",
            "Signal can easily be well overwhelmed by the sensor noise.",
            "And this problem becomes more severe if the background is less textured."
        ],
        [
            "So here's an example.",
            "So in this video there's three groups of heating vents marked by this.",
            "Red circles are evacuating hot air.",
            "Because many regions in this video are very smooth, like the Sky, the wiggle features found.",
            "These sequences are very noisy as shown here.",
            "If we estimate the velocity of airflow only based on this video feature will get very noisy result like this.",
            "So to overcome this problem, we proposed a probabilistic optical flow algorithm that can not only get the meaning of the optic flow, but also the variance of the vehicle features.",
            "Australian here.",
            "The variance tells us where the wiggle features are not reliable, for example, because the Sky is very smooth that we go the variance of weak official features.",
            "There is very large and unreliable.",
            "So taking this variance into account, we can get a much cleaner reflective flow like this.",
            "Now you can see that there are three apriums right above the heating vents marking, but this is 3 red circles."
        ],
        [
            "Now let us look more results."
        ],
        [
            "We first evaluate or we go flow algorithm on simulated sequence so that we can compare the estimated flow with the ground truth flow.",
            "On the right we should error as a function of wiggle magnitude for three different backgrounds show on the bottom notice that error drop some wiggle major increases because a large we go magnitude, resulting a high signal noise ratio."
        ],
        [
            "Here's a real sequence to hide riders marked by the red circles are blowing hot air into the center, seen in opposite directions, so below you can see that we are everything can recover to opposite airflows."
        ],
        [
            "To further evaluate the record velocity in previous slide, we compare the estimated flow with measurement by valamit are so on the left we show our set experimental setup.",
            "So we pick four points on the capture sequence and compared recover velocity by our algorithm with the velocity measured by the millimeter and show under the numbers are shown bottom.",
            "So we can see that roughly match."
        ],
        [
            "So here's another sequence about the reflective stereo.",
            "So here is A3 length.",
            "The left left is the closest camera, so the heat general by this lead has the largest disparity where the middle light is the furthest the camera.",
            "So the room above it has the smallest disparity."
        ],
        [
            "Here's another video, scanned.",
            "Although the heat from hand is very faint and very hard to observed, or algorithm can still recover the motion of the heated air above the hand like this."
        ],
        [
            "OK, let me let me summarize this talk.",
            "In this talk we discussed how to measure the velocity and depth of air flow from natural video sequence.",
            "I hope I always convince you that we go feature is right feature to use for the reflective flow and stereo.",
            "Be cause there's wiggle feature can be still refused, revealing the depth of air flow, or can be tracked reviewed in the motion of air flow at last.",
            "To improve robustness.",
            "Robustness, we propose a probabilistic algorithm using both mean and variance to get a more robust track of the air flow."
        ],
        [
            "Thank you.",
            "So let me ask one question.",
            "In order to be able to assign a unique depth to to a point on the refractive medium, you effectively imply that there exists a sharp boundary.",
            "A sharp interface between air and you know the refractive.",
            "There's sort of the area where the where the density has changed, and in reality you know the density will vary continuously along the line of sight, and I'm wondering to what extent this approximation is an important one in practice.",
            "That you're making.",
            "So let me repeat your question so you are saying that here we assume that there is a sharp boundaries between the air flow, but if there's a smooth transition, how good is our approximation?",
            "So in general, the short question is if the F, let's say the air bubbles is small enough or seen enough, then whether it's a sharp boundary of smooth transition both in both case, algorithm works, but the air bubbles too large.",
            "Then this approximation may get some.",
            "Troubles so actually we have some analyzed about this in our papers.",
            "Any other questions?",
            "Sounds.",
            "A question about the assumptions.",
            "Of the option Modo.",
            "So first of all you should like to assume there should be texture on your background.",
            "Yes, yes, so yeah.",
            "So basically the stronger texture is, the easier we can recover airflow.",
            "So in extreme cases the if we have a totally wide background.",
            "Definitely we can recover nothing for it to stick to one.",
            "So you do have an equipment about the frames of the camera.",
            "So for example if the the two point.",
            "AA moves really fast or on other hand your camera is slow.",
            "Do you get errors in that perspective?",
            "Yeah, that's yeah, that's very good question.",
            "So actually we need to frame the frame rate to be fast enough because when I showed the bigger constancy, you can see that actually assumed that F bubbles between two neighboring frames does not change changes shape too much.",
            "Otherwise it just two frames have totally different shape.",
            "There's no way we can make the connection between doing so.",
            "So, but not in most of cases.",
            "So all this video we show here, except the high drivers sequence, we just use the 30 frame per second videos and we get a reasonable result out.",
            "OK, I think we have to move on.",
            "If you have other questions, let's say you can do it at the end of the end of the talk.",
            "At the end of the session.",
            "So let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How everyone I'm championship today I will present the work to measure the depth and velocity of reflective food off low.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In particular, we're going to measure the free flow from natural video sequence, so here's the set up.",
                    "label": 1
                },
                {
                    "sent": "A camera is an image in the texture background through hot air because the hot air has different index refraction compared with surroundings.",
                    "label": 0
                },
                {
                    "sent": "Light Ray bands, when passing through it.",
                    "label": 0
                },
                {
                    "sent": "This will generate some tiny distortion observed sequence.",
                    "label": 0
                },
                {
                    "sent": "And today I will show that by analyzing distortion we can recover the motion of hot air.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, if you have Stewart cameras that we can also recover the depth of hot air.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "We take a video of burning candles in front of a brick wall.",
                    "label": 0
                },
                {
                    "sent": "We can hardly see any air flows in this input videos, but surprisingly orelsan can recover motion of how earth above the candles like this just from this input video.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, from serial sequence we can also recover depth low air flow like this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the outline of today's talk.",
                    "label": 0
                },
                {
                    "sent": "Let us first discuss some previous work in this area.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk about our Epson and at the end will show some experimental results.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are many potential applications for free motion estimation at the airport.",
                    "label": 1
                },
                {
                    "sent": "It can be used to detect harmful wake vortex so airplane can take off or land more safely.",
                    "label": 0
                },
                {
                    "sent": "In the factory it can also be used to detect the toxic gas.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are couple of techniques in the literature.",
                    "label": 0
                },
                {
                    "sent": "Try to visualize and magical fruitful.",
                    "label": 0
                },
                {
                    "sent": "One technique is called a particle image.",
                    "label": 1
                },
                {
                    "sent": "Below symmetry.",
                    "label": 0
                },
                {
                    "sent": "In this method some tiny tracers like dust or die are inserted into fluid.",
                    "label": 0
                },
                {
                    "sent": "In this image a green tracer is used.",
                    "label": 0
                },
                {
                    "sent": "Therefore the fully motion is measured.",
                    "label": 0
                },
                {
                    "sent": "By tracking these tracers.",
                    "label": 0
                },
                {
                    "sent": "However, the complete set up makes this method not easy to use for many applications.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another method is called sharing the Lance system show on the left transformed the distortion caused by airflow into intensities so the airflow become visible as shown in the middle.",
                    "label": 0
                },
                {
                    "sent": "The motion of food can be further recovered using Technicolor children PIV, as shown on the right.",
                    "label": 0
                },
                {
                    "sent": "However, both children unshaven PIV has a complicated setup, and it's hard to use outside the lab.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So recently to simplify the setup, people propose a method called background Orange children or both of you or ask for short.",
                    "label": 0
                },
                {
                    "sent": "Similar to our work, it is simply take a video of air flows in front of texture background.",
                    "label": 0
                },
                {
                    "sent": "As shown on the left, then instruction distortions and show on the right buttons.",
                    "label": 0
                },
                {
                    "sent": "This method has very simple setup setup and very easy to use, but it can only visualize not measured airflow.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize, traditional children technique can only visualize airflow, particle image velocimetry or ceiling PIV.",
                    "label": 1
                },
                {
                    "sent": "Both visualize and measure air flow, but they follow all of these three methods, has a complicated setup.",
                    "label": 0
                },
                {
                    "sent": "On the contrary, be OS very simple setup like only requires the natural video as input, but it only for visualization and our wiggle stereo and we go flow algorithm which I will introduce some laughter.",
                    "label": 1
                },
                {
                    "sent": "Can both measure the visualize and measure the depth and velocity airflow and it has a simple set as the OS.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let me introduce our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Recorded, our task is to recover the velocity and depth of air flow from natural video sequence because the airflow are transparent.",
                    "label": 1
                },
                {
                    "sent": "If we simply apply the standard stereo optical flow algorithms are input.",
                    "label": 1
                },
                {
                    "sent": "Videos will only get it adapts or velocity of the solid object like candles or bricks in these videos, but would be interested in air flow.",
                    "label": 0
                },
                {
                    "sent": "To solve this problem, we proposed a wiggle features.",
                    "label": 0
                },
                {
                    "sent": "We are sure that now if we run the standard object for the stereo on this wiggle feature, we will get the correct motion, corrected velocity and depth of air flow.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let us first define what we go feature is considering this.",
                    "label": 0
                },
                {
                    "sent": "Set up a camera is image in the background.",
                    "label": 0
                },
                {
                    "sent": "Your hot air at time T. If we trace back from the camera to the background, the capture sequence looks like this.",
                    "label": 0
                },
                {
                    "sent": "Now in the next frame, when the air bubble moves due to the change of reflections, the light race bands.",
                    "label": 0
                },
                {
                    "sent": "This will generate some tiny distortion.",
                    "label": 0
                },
                {
                    "sent": "An observer sequence as shown here, and we define distortion as we go feature.",
                    "label": 0
                },
                {
                    "sent": "So in short, the definition of wiggle feature is the distortion due to the refraction.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's how the week feature looks like from the candle sequence are shown at the beginning of the week.",
                    "label": 0
                },
                {
                    "sent": "Features 2D vectors and we visualize it, but mapping into RGB color using the color will be low.",
                    "label": 0
                },
                {
                    "sent": "From this video you can clearly see the wiggle feature acts like tracers, so we should be able to get in motion of a motion and depth of the footage from this legal feature.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let me show how to do that.",
                    "label": 0
                },
                {
                    "sent": "Let's start with depth.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our main observation is that to recover the depth of air flow, we can still use the standard stereo algorithm, but on the wiggle features, not on the input intensity videos.",
                    "label": 0
                },
                {
                    "sent": "So here's the explanation.",
                    "label": 0
                },
                {
                    "sent": "Consider two cameras.",
                    "label": 0
                },
                {
                    "sent": "Imagine a solid background through hot air, still matching on intensities will only find a depth of solid background.",
                    "label": 1
                },
                {
                    "sent": "This is because airflow is almost transparent.",
                    "label": 0
                },
                {
                    "sent": "So if we project the point on the background to the left and right views, the projected interest intensity should be the same.",
                    "label": 0
                },
                {
                    "sent": "Notice that now if we pick a point on air flows, the project intensity until use are different, so intensity does not work with reflective object.",
                    "label": 0
                },
                {
                    "sent": "However, we go features from left, unreal, left and right views corresponding to this point a consistent.",
                    "label": 0
                },
                {
                    "sent": "Here's the illustration for this constancy.",
                    "label": 0
                },
                {
                    "sent": "When the reflective object moves, the light Rays from left and right views bands due to the change of reflection, and because these two light Rays passing through the same point on the reflector object, they should bend in the same way as shown here.",
                    "label": 0
                },
                {
                    "sent": "As a consequence, we observed the same of the same distortions on left and right views, meaning the wiggle feature from left and right views are the same.",
                    "label": 0
                },
                {
                    "sent": "So this is, this is what we called wiggle constancy.",
                    "label": 0
                },
                {
                    "sent": "So to summarize, because we have the wiggle constancy, we can get a depth of reflective object object by stereo matching on wiggle features, just like we can get a depth of solid object by string matching on intensities.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let us apply this regal stereo to candle sequence we have shown before.",
                    "label": 0
                },
                {
                    "sent": "Notice that we go feature from left and right views within this.",
                    "label": 0
                },
                {
                    "sent": "Red rectangles are quite similar.",
                    "label": 0
                },
                {
                    "sent": "Therefore still matching on wiggle features, we can recover the disparity map of airflow as shown here.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let us move to the velocity estimation.",
                    "label": 0
                },
                {
                    "sent": "Similarly, the same notion wiggle constancy are shown for stereo case also applies to neighboring frames in videos, which means we can use for flow.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we only have 1 camera.",
                    "label": 0
                },
                {
                    "sent": "The task of velocity estimation is to find a movement of reflective object that is like air flow from T1 to T2.",
                    "label": 0
                },
                {
                    "sent": "Where T1 and T2 are close enough frames.",
                    "label": 0
                },
                {
                    "sent": "Similar to stereo, we need to find a feature that is consistent between these two frames so we can track the motion for reflective object.",
                    "label": 0
                },
                {
                    "sent": "By using this feature.",
                    "label": 0
                },
                {
                    "sent": "Again, intensity is not good for each feature because for the same.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Point on the object, the corresponding intensity on T1 and T2 are not the same.",
                    "label": 0
                },
                {
                    "sent": "However, the wiggle motion added.",
                    "label": 0
                },
                {
                    "sent": "These two frames are still consistent.",
                    "label": 0
                },
                {
                    "sent": "To illustrate this, let us consider two small time intervals around T1 and T2 respectively.",
                    "label": 0
                },
                {
                    "sent": "Within these two time intervals, the movement of reflective object generate distortion on captured sequence like this.",
                    "label": 0
                },
                {
                    "sent": "Again, because the light Rays at T wanted to pass through the same point on reflective objects, they should bend in the same way, resulting the same wiggle features.",
                    "label": 0
                },
                {
                    "sent": "And this is the wiggle constancy for flow.",
                    "label": 0
                },
                {
                    "sent": "Now, because the wiggle features are consistent from T1 to T2, similarly, we can then get the free motion by calculating the optical flow of wiggle features from T1 to T2.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, let us still use this candle sequence to demonstrate this.",
                    "label": 0
                },
                {
                    "sent": "When we play the video slowly, you can see that we go features between neighboring frames consistent.",
                    "label": 0
                },
                {
                    "sent": "Therefore, if you apply the optic flow on the video show on the left will get velocity airflow shown on the right.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let us summarize.",
                    "label": 0
                },
                {
                    "sent": "Summarize by this table the brightness constancy holds for the solid object.",
                    "label": 1
                },
                {
                    "sent": "So optical flow and stereo for solid object is based on the intensities.",
                    "label": 0
                },
                {
                    "sent": "However, if of reflective object present constancy fails but the refractory constancy still holds.",
                    "label": 0
                },
                {
                    "sent": "Therefore for reflective object we should use the regal features.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At last, or discuss how to improve robustness of the of our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in all the previous slides, we do not consider sensor noise.",
                    "label": 0
                },
                {
                    "sent": "However, the Wiggle feature is very sensitive to sensor noise because they're very small.",
                    "label": 1
                },
                {
                    "sent": "Just giving you a sense.",
                    "label": 0
                },
                {
                    "sent": "Normally the weaker features in order of 0.1 pixels, so this is very small.",
                    "label": 0
                },
                {
                    "sent": "Signal can easily be well overwhelmed by the sensor noise.",
                    "label": 0
                },
                {
                    "sent": "And this problem becomes more severe if the background is less textured.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's an example.",
                    "label": 0
                },
                {
                    "sent": "So in this video there's three groups of heating vents marked by this.",
                    "label": 0
                },
                {
                    "sent": "Red circles are evacuating hot air.",
                    "label": 0
                },
                {
                    "sent": "Because many regions in this video are very smooth, like the Sky, the wiggle features found.",
                    "label": 0
                },
                {
                    "sent": "These sequences are very noisy as shown here.",
                    "label": 0
                },
                {
                    "sent": "If we estimate the velocity of airflow only based on this video feature will get very noisy result like this.",
                    "label": 0
                },
                {
                    "sent": "So to overcome this problem, we proposed a probabilistic optical flow algorithm that can not only get the meaning of the optic flow, but also the variance of the vehicle features.",
                    "label": 1
                },
                {
                    "sent": "Australian here.",
                    "label": 0
                },
                {
                    "sent": "The variance tells us where the wiggle features are not reliable, for example, because the Sky is very smooth that we go the variance of weak official features.",
                    "label": 0
                },
                {
                    "sent": "There is very large and unreliable.",
                    "label": 0
                },
                {
                    "sent": "So taking this variance into account, we can get a much cleaner reflective flow like this.",
                    "label": 0
                },
                {
                    "sent": "Now you can see that there are three apriums right above the heating vents marking, but this is 3 red circles.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let us look more results.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We first evaluate or we go flow algorithm on simulated sequence so that we can compare the estimated flow with the ground truth flow.",
                    "label": 0
                },
                {
                    "sent": "On the right we should error as a function of wiggle magnitude for three different backgrounds show on the bottom notice that error drop some wiggle major increases because a large we go magnitude, resulting a high signal noise ratio.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's a real sequence to hide riders marked by the red circles are blowing hot air into the center, seen in opposite directions, so below you can see that we are everything can recover to opposite airflows.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To further evaluate the record velocity in previous slide, we compare the estimated flow with measurement by valamit are so on the left we show our set experimental setup.",
                    "label": 0
                },
                {
                    "sent": "So we pick four points on the capture sequence and compared recover velocity by our algorithm with the velocity measured by the millimeter and show under the numbers are shown bottom.",
                    "label": 0
                },
                {
                    "sent": "So we can see that roughly match.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's another sequence about the reflective stereo.",
                    "label": 0
                },
                {
                    "sent": "So here is A3 length.",
                    "label": 0
                },
                {
                    "sent": "The left left is the closest camera, so the heat general by this lead has the largest disparity where the middle light is the furthest the camera.",
                    "label": 0
                },
                {
                    "sent": "So the room above it has the smallest disparity.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another video, scanned.",
                    "label": 0
                },
                {
                    "sent": "Although the heat from hand is very faint and very hard to observed, or algorithm can still recover the motion of the heated air above the hand like this.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let me let me summarize this talk.",
                    "label": 0
                },
                {
                    "sent": "In this talk we discussed how to measure the velocity and depth of air flow from natural video sequence.",
                    "label": 0
                },
                {
                    "sent": "I hope I always convince you that we go feature is right feature to use for the reflective flow and stereo.",
                    "label": 0
                },
                {
                    "sent": "Be cause there's wiggle feature can be still refused, revealing the depth of air flow, or can be tracked reviewed in the motion of air flow at last.",
                    "label": 1
                },
                {
                    "sent": "To improve robustness.",
                    "label": 0
                },
                {
                    "sent": "Robustness, we propose a probabilistic algorithm using both mean and variance to get a more robust track of the air flow.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So let me ask one question.",
                    "label": 0
                },
                {
                    "sent": "In order to be able to assign a unique depth to to a point on the refractive medium, you effectively imply that there exists a sharp boundary.",
                    "label": 0
                },
                {
                    "sent": "A sharp interface between air and you know the refractive.",
                    "label": 0
                },
                {
                    "sent": "There's sort of the area where the where the density has changed, and in reality you know the density will vary continuously along the line of sight, and I'm wondering to what extent this approximation is an important one in practice.",
                    "label": 0
                },
                {
                    "sent": "That you're making.",
                    "label": 0
                },
                {
                    "sent": "So let me repeat your question so you are saying that here we assume that there is a sharp boundaries between the air flow, but if there's a smooth transition, how good is our approximation?",
                    "label": 0
                },
                {
                    "sent": "So in general, the short question is if the F, let's say the air bubbles is small enough or seen enough, then whether it's a sharp boundary of smooth transition both in both case, algorithm works, but the air bubbles too large.",
                    "label": 0
                },
                {
                    "sent": "Then this approximation may get some.",
                    "label": 0
                },
                {
                    "sent": "Troubles so actually we have some analyzed about this in our papers.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Sounds.",
                    "label": 0
                },
                {
                    "sent": "A question about the assumptions.",
                    "label": 0
                },
                {
                    "sent": "Of the option Modo.",
                    "label": 0
                },
                {
                    "sent": "So first of all you should like to assume there should be texture on your background.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, so yeah.",
                    "label": 0
                },
                {
                    "sent": "So basically the stronger texture is, the easier we can recover airflow.",
                    "label": 0
                },
                {
                    "sent": "So in extreme cases the if we have a totally wide background.",
                    "label": 0
                },
                {
                    "sent": "Definitely we can recover nothing for it to stick to one.",
                    "label": 0
                },
                {
                    "sent": "So you do have an equipment about the frames of the camera.",
                    "label": 0
                },
                {
                    "sent": "So for example if the the two point.",
                    "label": 0
                },
                {
                    "sent": "AA moves really fast or on other hand your camera is slow.",
                    "label": 0
                },
                {
                    "sent": "Do you get errors in that perspective?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's yeah, that's very good question.",
                    "label": 0
                },
                {
                    "sent": "So actually we need to frame the frame rate to be fast enough because when I showed the bigger constancy, you can see that actually assumed that F bubbles between two neighboring frames does not change changes shape too much.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it just two frames have totally different shape.",
                    "label": 0
                },
                {
                    "sent": "There's no way we can make the connection between doing so.",
                    "label": 0
                },
                {
                    "sent": "So, but not in most of cases.",
                    "label": 0
                },
                {
                    "sent": "So all this video we show here, except the high drivers sequence, we just use the 30 frame per second videos and we get a reasonable result out.",
                    "label": 0
                },
                {
                    "sent": "OK, I think we have to move on.",
                    "label": 0
                },
                {
                    "sent": "If you have other questions, let's say you can do it at the end of the end of the talk.",
                    "label": 0
                },
                {
                    "sent": "At the end of the session.",
                    "label": 0
                },
                {
                    "sent": "So let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}