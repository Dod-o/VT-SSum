{
    "id": "qbjiqqemt7qoon3mcayqmvjzhylimjgc",
    "title": "Improved Regret Guarantees for Online Smooth Convex Optimization with Bandit Feedback",
    "info": {
        "author": [
            "Ankan Saha, Department of Computer Science, University of Chicago"
        ],
        "published": "May 6, 2011",
        "recorded": "April 2011",
        "category": [
            "Top->Computer Science->Optimization Methods"
        ]
    },
    "url": "http://videolectures.net/aistats2011_saha_guarantees/",
    "segmentation": [
        [
            "So after let's talk on contextual bandits, we come back to the domain of normal bandit problems like for online convex optimization."
        ],
        [
            "So we've had already had a lot of introduction to online learning and."
        ],
        [
            "To how important it is in machine learning and other areas these days, so I would just like to mention."
        ],
        [
            "But traditionally, online learning has been looked at as sequential decision making problems."
        ],
        [
            "And it is generally modeled as a sequential game between the learner and the adversary.",
            "So the setting, I mean the setting of traditional online learning, is that at every time step T you."
        ],
        [
            "They will play a point.",
            "I mean, the player will play a point from convex compact set and the adversary responds with a function from a certain function class and after the adversary response the player will suffer loss which is equivalent to the function applied on that particular point that had played.",
            "In online convex optimization, we restrict the class of functions of the adversary to just convex functions.",
            "So in this case the player is the adversary just playing."
        ],
        [
            "Convex functions and there are two main strands of work in online learning.",
            "One is the full information setting and the other one is the bandit setting.",
            "So in the full information setting, the player gets to see the entire function FT at every iteration, whereas in the bandit setting all he gets to see is the value of the loss at every iteration, whereas he does not get to see any of the the original function."
        ],
        [
            "So the goal of this game is to minimize this quantity called the regret, which varies from application to application.",
            "But the general idea is that it is the player's performance with respect to the best performance that you could have given if he knew all the functions of the adversary in advance.",
            "So basically it is the loss suffered by the player as compared to the loss that he."
        ],
        [
            "Death suffered if you could have played the best function while in new.",
            "All the functions that diversity was playing in France.",
            "So in the full information setting, Martins encourage showed in the paper in 2003 that if you just do projected gradient descent to find your point at the T + 1 iteration.",
            "So basically you take a gradient step with your point XT and just projected."
        ],
        [
            "After your convex set, then that algorithm gives you fantastic results.",
            "In fact, this gradient descent strategy it incurred square root T regret and this is bounded actually tight.",
            "So he showed a lower bound of square root T as well.",
            "And I mean the key to sync images algorithm is that you just require information about the gradient of the function at every step.",
            "So the main idea is that in this in case of online learning, we're actually minimizing the regret and not the actual loss.",
            "So in this case we benefit because if the adversary continues to play similar functions, then over the rounds we can learn this similar function, whereas if he continues to play random functions at every iteration, then the second time, which is the minimizing term, that is the best possible we could have done in hindsight that also suffers.",
            "So the regret is not that bad at the end.",
            "So this is the theorem that."
        ],
        [
            "I was in English paper and if you assume that the basically shows the square root T regret if you assume the diameter of the convex set to be a constant, then you see that the main term that matters is basically the maximum of the gradient of all the functions."
        ],
        [
            "And the convergence rate of course, depends upon this rate of this maximum value of the gradient."
        ],
        [
            "So the main intuition behind banded online problems is that since we do not know the actual function, we have some kind of missing information.",
            "And I mean some information is missing.",
            "So the best thing that you can do is, I mean the first thing that we want to do is once you have the point XD you provide some kind of proxy for this missing information and then you just feed it into a full information Oracle and just run a full information algorithm on that and that will give you the new point XT plus one."
        ],
        [
            "So in particular for Martin's English, is algorithm the missing information was just the gradient of the function.",
            "So what you want to do is provide an estimate of the gradient of the function.",
            "So this brings us to the crucial question that."
        ],
        [
            "How do we evaluate the gradient of a function from a single point evaluation of the function?",
            "So in an awesome paper by Flaxman Flaxman, Adam Kalai and Brendan Mcmahan, they showed in 2005 that you can actually find the estimate of a gradient from a single function evaluation, so this is of course I mean the key to this is to introduce randomness.",
            "So what do you do?"
        ],
        [
            "Who is you define this new function F hat, which is actually just the expected value of the function F evaluated on points are on a unit ball around X.",
            "So basically you drop 2 sample points from unit ball around X and calculated from that point on the all those points and then."
        ],
        [
            "Expectation of that.",
            "So here we actually lies in the unit ball, so it can be drawn from inside the ball as well.",
            "So if the function is running this way, then this paper showed that you can actually find the exact value of the gradient of the function F at and that is actually given by this expression.",
            "The main thing to note here is that EU is actually random variable which is drawn from the dementia unit dimensional sphere, so it is actually drawn from the surface of the ball and not the ball itself.",
            "I mean not from within the ball itself."
        ],
        [
            "So I mean we can basically the the main idea is that we can actually use this gradient of F of X as an estimate to the gradient of the original function.",
            "So the basic."
        ],
        [
            "The key trick in their paper was to choose the."
        ],
        [
            "These are the ball for evaluating the unbiased gradient estimate.",
            "And of course you want to play around with the Delta parameter after that.",
            "So if you choose two smaller deltas you draw from a ball which is very small, then you can shoot up the value of the gradient.",
            "If your .60 actually closer to the boundary of the set and this weekend the bounds.",
            "Again, if you choose to larger value of Delta, then your bounds of obviously become very weak because the gradient estimates are not very accurate.",
            "So what you want to do is trade off Delta for the best possible value.",
            "And this and."
        ],
        [
            "You feed this to the full information algorithm, which is basically encourages algorithm that gives them order to 3 by 4 regret for the online convex optimization bandit setting for Lipschitz functions.",
            "So I mean, this is still."
        ],
        [
            "The best possible rate known for general convex Lipschitz functions, but."
        ],
        [
            "There are certain subclasses of convex functions which are much more interesting to at least the machine learning community.",
            "For one, because they provide us better rates and for two because these functions are generally very well behaved in nature.",
            "So before going into the results on these classes, I would like to briefly mention some convex analysis basics."
        ],
        [
            "So I mean, everybody knows that convex functions are lower bounded by linear approximation.",
            "So you can at any point you can draw linear approximation so strongly convex functions that those functions which are lower bounded by a quadratic at every point.",
            "So I mean, every function always lies above its linear approximation plus a quadratic term.",
            "On the other hand, functions which have Lipschitz continuous gradient that those functions which can be upper."
        ],
        [
            "Under biquadratic at every time.",
            "So in this case, the inequality is reversed.",
            "So every function is always upper bounded by a linear approximation plus quadratic term.",
            "So in terms of figures."
        ],
        [
            "This is an example of a Lipschitz continuous gradient function, so the lower curve corresponds to the original function, and at any point X of the lower curve you can actually upper bound it by a quadratic.",
            "So we review some of the previous existing."
        ],
        [
            "Calls for some classes of convex functions in the full information setting.",
            "So for the general Lipschitz convex functions, the best results were provided by using images paper we showed to the half."
        ],
        [
            "Rates on regret which was tight for smooth convex functions.",
            "So by smooth here I mean convex functions which are Lipschitz as well as they have Lipschitz continuous gradient.",
            "So for these smooth functions the same paper gives you to the half strumming to half bound on the regret."
        ],
        [
            "So on the other hand, you can look at classes of functions which are Lipschitz an strongly convex.",
            "For this there was a paper by a lot of salmeterol and Southern Cali where they just used.",
            "For them again, but they use the analysis as with strongly convex functions, and they showed that you can actually obtain lochty regret and the results go through for the part in between where you actually have smooth and strongly convex functions as well.",
            "But the figure that I mean the story drastically changes when you go to the bandit setting."
        ],
        [
            "So for general Lipschitz functions, the paper by Flaxman client maximum, they showed that you can obtain it to 3/4 regret, but the lower bounds is actually still due to the full information setting.",
            "So you have to have lower bounds.",
            "And in this paper we opt we on the previous results known for smooth functions was also to 3 by 4.",
            "Do the same paper.",
            "In this paper we improve."
        ],
        [
            "Two to the 2/3 of talaga factor, but again the lower."
        ],
        [
            "Still remain due to open due to the."
        ],
        [
            "Full information setting.",
            "And for lip for strongly convex and smooth and strongly."
        ],
        [
            "Setting the the previous best results were again to 3 by 4, but in cool 2010 there was a paper by Alec Agarwal over Declan Lynch aware they wrote it two to three and what they did was they basically analyzed new, basically took the gradient estimate and ran the Hazan Kale analysis on that.",
            "So one interesting thing to notice is that for strongly convex functions there is a huge gap between the best upper bound that's known and the lower bounds that exist.",
            "So the lower bounds are still locked.",
            "Do the full information setting where the upper bounds currently have only been brought to the."
        ],
        [
            "Codes.",
            "So for the rest of the talk, I'll probably give you a brief idea about what we did in our paper to bring it bring the upper bound down to do the 2/3 for smooth functions.",
            "So there was a paper by Jake Abernethy, Alyzon and Sasha Sasha Rakhlin.",
            "They showed that for banded online linear optimization you can actually obtain tighter bounds for the calculating this gradient, and they did that by calculating gradient with respect to a changing local Nam.",
            "So before going to the concept of changing local, now we need this idea of what a self concordant barrier is.",
            "So a function defined on the convex set is called a self concordant barrier.",
            "If it shoots to Infinity near the boundary of the set and both the function and the Hessian of the function are Lipschitz continuous with respect to the local norm.",
            "So the local norm is defined with respect to any point inside the set, and you just defining the namaz this dot product where instead of taking dot product with just."
        ],
        [
            "F&F, you now, including this Hessian term inside.",
            "So a key property of such self concordant functions is that this Dick in ellipsoid, which is basically all points which are at unit distance from the point at the center of the ellipsoid with respect to the local norm.",
            "This Dick ellipsoid will always lie."
        ],
        [
            "Inside the set key.",
            "So to give you some intuition in figures, suppose."
        ],
        [
            "Is the compact convex set K that we're looking at?",
            "I choose the point XT inside the set and this is the deck in left side.",
            "So basically it is the set of all the points which are at unit distance from XT with respect to the local number XD and it will always lie inside key.",
            "So in particular if I choose a point which is very close to the boundary of the set."
        ],
        [
            "OK then the the self concordant function tends to go to Infinity near the boundary.",
            "So the flip side in order to stay inside the set will actually become slender and thin, but it will always stay inside the set."
        ],
        [
            "So in particular, if I define this term 80 square as the inverse of the Hessian, then I can show that if you define YT as this expression, where UT is actually drawn from the unit dimensional sphere, then this YT will always lie on the deck in left side.",
            "So this is basically choosing a point point at unit distance from XT, but with respect to the local now."
        ],
        [
            "So what we do in this paper is mainly combine the idea of taking single point gradient estimates with the idea of self concordant barriers and."
        ],
        [
            "Local norms, so the key advantage in using this kind of analysis is that now we have completely removed the idea of the problem of taking projections, so previously encourages algorithm was going in taking a gradient step and then projecting back into the step every time.",
            "But now we since we choose points from the digital side every time, we always guaranteed to be stay inside convex set, so we never need to project back.",
            "And I mean the complexity corresponding to that."
        ],
        [
            "Gone completely.",
            "So what we do is we generate a gradient estimate of the original function at every time step, and then we feed it to full information black box.",
            "As we had said before.",
            "So the full information black box that we use is not zinkevich is black box but the black box that was provided by the algorithm that was provided by Jake Abernethy, Alexandra Clean in their paper.",
            "So what this does is it takes it keeps the gradients from the first step to that step and it takes it up with support with X and it adds the self concordant function at X and minimizes this.",
            "So whatever, whatever X minimizes the new point.",
            "So this is the same as the follow the regularised leader approach, and there I mean the the XT plus one that you get is just by mini."
        ],
        [
            "Sing the same problem.",
            "So to give you a brief overview of the algorithm, we start with assuming that for a convex set."
        ],
        [
            "Self concordant barrier is already known, so there was a paper which basically proved that for any convex set, the self concordant barrier always exists.",
            "But we assume that we know it."
        ],
        [
            "Or the next key?",
            "And we start with a particular point X1 belonging to the convex set an at every step T. We assume you of course know XT at time T, and then since we know the self concordant barrier and we know the point XT, we can draw this Dick in lip side around XD and we can evaluate this quantity 80 which is basically just the square root of the inverse of the Hessian.",
            "Once this quantity is calculated.",
            "We can just."
        ],
        [
            "Is Whitey, which belongs which actually lies on the digital side and we choose Whitey at random.",
            "And the player instead of."
        ],
        [
            "Playing the point XD now plays this random point YT and receives the last 50 YT.",
            "So after that you can."
        ],
        [
            "Basically we use the same idea of taking the estimate of a gradient and the gradient estimate is given by this expression."
        ],
        [
            "And once we have the estimate of the gradient, we feed it to a full information algorithm, which is the Abernethy Hazan Reckling Oracle and we solve the FPL problem to get 60 + 1."
        ],
        [
            "So I'll give you a very brief proof sketch of why this thing works.",
            "So like the proof goes through defining this approximation of the original problem.",
            "So FT at X is now defined as the expected value of points of FT evaluated at points which are drawn from a Delta Dick in ellipsoid around X.",
            "So you draw you draw a Dick in lips around X, and you look at all the points inside the deck in left side, but off size Delta around XD, and then you draw points from that and you take the expected value with respect to that.",
            "So we open up the regret and we write it as a telescopic sum.",
            "Using this approximation and using the fact that we're actually playing the random point YT instead of the actual point XD that incurs a cost of order T Delta squared, whereas using the full information black box has its own cost of like square root by Delta login factors, this is all assuming that you're playing ball playing items within Delta balls and deltas fears, and after that if we trade up these two terms with respect to Delta, we get the to the 2/3 regret.",
            "Up to log rhythmic guarantees.",
            "So in conclusion."
        ],
        [
            "We improve the upper bounds on regret for bandit online convex optimization from T3 four, two, 2/3 for smooth."
        ],
        [
            "Functions.",
            "And the main problem that realizing this area is that the lower bound still correspond to the full information setting, and in some cases."
        ],
        [
            "A huge gap between the upper bounds on the lower bounds known right now, so the Golden question in online learning is how do you?"
        ],
        [
            "Is this gap one of the ideas is to look at better bounds on this price of banded information for very well behaved problems.",
            "So for example, if you remember the picture, the inner innermost part basically both strongly convex functions as well as smooth functions.",
            "These are in general in machine learning.",
            "The most well behaved functions, but apparently we still can provide better rates on regret on even those classes functions.",
            "So yeah, that's the main question that remains open."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So after let's talk on contextual bandits, we come back to the domain of normal bandit problems like for online convex optimization.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've had already had a lot of introduction to online learning and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To how important it is in machine learning and other areas these days, so I would just like to mention.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But traditionally, online learning has been looked at as sequential decision making problems.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it is generally modeled as a sequential game between the learner and the adversary.",
                    "label": 0
                },
                {
                    "sent": "So the setting, I mean the setting of traditional online learning, is that at every time step T you.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They will play a point.",
                    "label": 0
                },
                {
                    "sent": "I mean, the player will play a point from convex compact set and the adversary responds with a function from a certain function class and after the adversary response the player will suffer loss which is equivalent to the function applied on that particular point that had played.",
                    "label": 1
                },
                {
                    "sent": "In online convex optimization, we restrict the class of functions of the adversary to just convex functions.",
                    "label": 0
                },
                {
                    "sent": "So in this case the player is the adversary just playing.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convex functions and there are two main strands of work in online learning.",
                    "label": 0
                },
                {
                    "sent": "One is the full information setting and the other one is the bandit setting.",
                    "label": 0
                },
                {
                    "sent": "So in the full information setting, the player gets to see the entire function FT at every iteration, whereas in the bandit setting all he gets to see is the value of the loss at every iteration, whereas he does not get to see any of the the original function.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal of this game is to minimize this quantity called the regret, which varies from application to application.",
                    "label": 0
                },
                {
                    "sent": "But the general idea is that it is the player's performance with respect to the best performance that you could have given if he knew all the functions of the adversary in advance.",
                    "label": 1
                },
                {
                    "sent": "So basically it is the loss suffered by the player as compared to the loss that he.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Death suffered if you could have played the best function while in new.",
                    "label": 1
                },
                {
                    "sent": "All the functions that diversity was playing in France.",
                    "label": 0
                },
                {
                    "sent": "So in the full information setting, Martins encourage showed in the paper in 2003 that if you just do projected gradient descent to find your point at the T + 1 iteration.",
                    "label": 1
                },
                {
                    "sent": "So basically you take a gradient step with your point XT and just projected.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After your convex set, then that algorithm gives you fantastic results.",
                    "label": 0
                },
                {
                    "sent": "In fact, this gradient descent strategy it incurred square root T regret and this is bounded actually tight.",
                    "label": 1
                },
                {
                    "sent": "So he showed a lower bound of square root T as well.",
                    "label": 1
                },
                {
                    "sent": "And I mean the key to sync images algorithm is that you just require information about the gradient of the function at every step.",
                    "label": 0
                },
                {
                    "sent": "So the main idea is that in this in case of online learning, we're actually minimizing the regret and not the actual loss.",
                    "label": 1
                },
                {
                    "sent": "So in this case we benefit because if the adversary continues to play similar functions, then over the rounds we can learn this similar function, whereas if he continues to play random functions at every iteration, then the second time, which is the minimizing term, that is the best possible we could have done in hindsight that also suffers.",
                    "label": 0
                },
                {
                    "sent": "So the regret is not that bad at the end.",
                    "label": 0
                },
                {
                    "sent": "So this is the theorem that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I was in English paper and if you assume that the basically shows the square root T regret if you assume the diameter of the convex set to be a constant, then you see that the main term that matters is basically the maximum of the gradient of all the functions.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the convergence rate of course, depends upon this rate of this maximum value of the gradient.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main intuition behind banded online problems is that since we do not know the actual function, we have some kind of missing information.",
                    "label": 0
                },
                {
                    "sent": "And I mean some information is missing.",
                    "label": 0
                },
                {
                    "sent": "So the best thing that you can do is, I mean the first thing that we want to do is once you have the point XD you provide some kind of proxy for this missing information and then you just feed it into a full information Oracle and just run a full information algorithm on that and that will give you the new point XT plus one.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in particular for Martin's English, is algorithm the missing information was just the gradient of the function.",
                    "label": 1
                },
                {
                    "sent": "So what you want to do is provide an estimate of the gradient of the function.",
                    "label": 0
                },
                {
                    "sent": "So this brings us to the crucial question that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we evaluate the gradient of a function from a single point evaluation of the function?",
                    "label": 1
                },
                {
                    "sent": "So in an awesome paper by Flaxman Flaxman, Adam Kalai and Brendan Mcmahan, they showed in 2005 that you can actually find the estimate of a gradient from a single function evaluation, so this is of course I mean the key to this is to introduce randomness.",
                    "label": 0
                },
                {
                    "sent": "So what do you do?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who is you define this new function F hat, which is actually just the expected value of the function F evaluated on points are on a unit ball around X.",
                    "label": 0
                },
                {
                    "sent": "So basically you drop 2 sample points from unit ball around X and calculated from that point on the all those points and then.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Expectation of that.",
                    "label": 0
                },
                {
                    "sent": "So here we actually lies in the unit ball, so it can be drawn from inside the ball as well.",
                    "label": 0
                },
                {
                    "sent": "So if the function is running this way, then this paper showed that you can actually find the exact value of the gradient of the function F at and that is actually given by this expression.",
                    "label": 0
                },
                {
                    "sent": "The main thing to note here is that EU is actually random variable which is drawn from the dementia unit dimensional sphere, so it is actually drawn from the surface of the ball and not the ball itself.",
                    "label": 0
                },
                {
                    "sent": "I mean not from within the ball itself.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I mean we can basically the the main idea is that we can actually use this gradient of F of X as an estimate to the gradient of the original function.",
                    "label": 0
                },
                {
                    "sent": "So the basic.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The key trick in their paper was to choose the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are the ball for evaluating the unbiased gradient estimate.",
                    "label": 1
                },
                {
                    "sent": "And of course you want to play around with the Delta parameter after that.",
                    "label": 0
                },
                {
                    "sent": "So if you choose two smaller deltas you draw from a ball which is very small, then you can shoot up the value of the gradient.",
                    "label": 0
                },
                {
                    "sent": "If your .60 actually closer to the boundary of the set and this weekend the bounds.",
                    "label": 1
                },
                {
                    "sent": "Again, if you choose to larger value of Delta, then your bounds of obviously become very weak because the gradient estimates are not very accurate.",
                    "label": 0
                },
                {
                    "sent": "So what you want to do is trade off Delta for the best possible value.",
                    "label": 0
                },
                {
                    "sent": "And this and.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You feed this to the full information algorithm, which is basically encourages algorithm that gives them order to 3 by 4 regret for the online convex optimization bandit setting for Lipschitz functions.",
                    "label": 0
                },
                {
                    "sent": "So I mean, this is still.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The best possible rate known for general convex Lipschitz functions, but.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are certain subclasses of convex functions which are much more interesting to at least the machine learning community.",
                    "label": 1
                },
                {
                    "sent": "For one, because they provide us better rates and for two because these functions are generally very well behaved in nature.",
                    "label": 0
                },
                {
                    "sent": "So before going into the results on these classes, I would like to briefly mention some convex analysis basics.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I mean, everybody knows that convex functions are lower bounded by linear approximation.",
                    "label": 1
                },
                {
                    "sent": "So you can at any point you can draw linear approximation so strongly convex functions that those functions which are lower bounded by a quadratic at every point.",
                    "label": 1
                },
                {
                    "sent": "So I mean, every function always lies above its linear approximation plus a quadratic term.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, functions which have Lipschitz continuous gradient that those functions which can be upper.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under biquadratic at every time.",
                    "label": 0
                },
                {
                    "sent": "So in this case, the inequality is reversed.",
                    "label": 0
                },
                {
                    "sent": "So every function is always upper bounded by a linear approximation plus quadratic term.",
                    "label": 1
                },
                {
                    "sent": "So in terms of figures.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an example of a Lipschitz continuous gradient function, so the lower curve corresponds to the original function, and at any point X of the lower curve you can actually upper bound it by a quadratic.",
                    "label": 0
                },
                {
                    "sent": "So we review some of the previous existing.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Calls for some classes of convex functions in the full information setting.",
                    "label": 0
                },
                {
                    "sent": "So for the general Lipschitz convex functions, the best results were provided by using images paper we showed to the half.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rates on regret which was tight for smooth convex functions.",
                    "label": 1
                },
                {
                    "sent": "So by smooth here I mean convex functions which are Lipschitz as well as they have Lipschitz continuous gradient.",
                    "label": 0
                },
                {
                    "sent": "So for these smooth functions the same paper gives you to the half strumming to half bound on the regret.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So on the other hand, you can look at classes of functions which are Lipschitz an strongly convex.",
                    "label": 0
                },
                {
                    "sent": "For this there was a paper by a lot of salmeterol and Southern Cali where they just used.",
                    "label": 0
                },
                {
                    "sent": "For them again, but they use the analysis as with strongly convex functions, and they showed that you can actually obtain lochty regret and the results go through for the part in between where you actually have smooth and strongly convex functions as well.",
                    "label": 1
                },
                {
                    "sent": "But the figure that I mean the story drastically changes when you go to the bandit setting.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for general Lipschitz functions, the paper by Flaxman client maximum, they showed that you can obtain it to 3/4 regret, but the lower bounds is actually still due to the full information setting.",
                    "label": 0
                },
                {
                    "sent": "So you have to have lower bounds.",
                    "label": 0
                },
                {
                    "sent": "And in this paper we opt we on the previous results known for smooth functions was also to 3 by 4.",
                    "label": 0
                },
                {
                    "sent": "Do the same paper.",
                    "label": 0
                },
                {
                    "sent": "In this paper we improve.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two to the 2/3 of talaga factor, but again the lower.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still remain due to open due to the.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Full information setting.",
                    "label": 0
                },
                {
                    "sent": "And for lip for strongly convex and smooth and strongly.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Setting the the previous best results were again to 3 by 4, but in cool 2010 there was a paper by Alec Agarwal over Declan Lynch aware they wrote it two to three and what they did was they basically analyzed new, basically took the gradient estimate and ran the Hazan Kale analysis on that.",
                    "label": 0
                },
                {
                    "sent": "So one interesting thing to notice is that for strongly convex functions there is a huge gap between the best upper bound that's known and the lower bounds that exist.",
                    "label": 0
                },
                {
                    "sent": "So the lower bounds are still locked.",
                    "label": 0
                },
                {
                    "sent": "Do the full information setting where the upper bounds currently have only been brought to the.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Codes.",
                    "label": 0
                },
                {
                    "sent": "So for the rest of the talk, I'll probably give you a brief idea about what we did in our paper to bring it bring the upper bound down to do the 2/3 for smooth functions.",
                    "label": 0
                },
                {
                    "sent": "So there was a paper by Jake Abernethy, Alyzon and Sasha Sasha Rakhlin.",
                    "label": 0
                },
                {
                    "sent": "They showed that for banded online linear optimization you can actually obtain tighter bounds for the calculating this gradient, and they did that by calculating gradient with respect to a changing local Nam.",
                    "label": 1
                },
                {
                    "sent": "So before going to the concept of changing local, now we need this idea of what a self concordant barrier is.",
                    "label": 0
                },
                {
                    "sent": "So a function defined on the convex set is called a self concordant barrier.",
                    "label": 0
                },
                {
                    "sent": "If it shoots to Infinity near the boundary of the set and both the function and the Hessian of the function are Lipschitz continuous with respect to the local norm.",
                    "label": 1
                },
                {
                    "sent": "So the local norm is defined with respect to any point inside the set, and you just defining the namaz this dot product where instead of taking dot product with just.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "F&F, you now, including this Hessian term inside.",
                    "label": 0
                },
                {
                    "sent": "So a key property of such self concordant functions is that this Dick in ellipsoid, which is basically all points which are at unit distance from the point at the center of the ellipsoid with respect to the local norm.",
                    "label": 1
                },
                {
                    "sent": "This Dick ellipsoid will always lie.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inside the set key.",
                    "label": 0
                },
                {
                    "sent": "So to give you some intuition in figures, suppose.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the compact convex set K that we're looking at?",
                    "label": 0
                },
                {
                    "sent": "I choose the point XT inside the set and this is the deck in left side.",
                    "label": 0
                },
                {
                    "sent": "So basically it is the set of all the points which are at unit distance from XT with respect to the local number XD and it will always lie inside key.",
                    "label": 0
                },
                {
                    "sent": "So in particular if I choose a point which is very close to the boundary of the set.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK then the the self concordant function tends to go to Infinity near the boundary.",
                    "label": 0
                },
                {
                    "sent": "So the flip side in order to stay inside the set will actually become slender and thin, but it will always stay inside the set.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in particular, if I define this term 80 square as the inverse of the Hessian, then I can show that if you define YT as this expression, where UT is actually drawn from the unit dimensional sphere, then this YT will always lie on the deck in left side.",
                    "label": 0
                },
                {
                    "sent": "So this is basically choosing a point point at unit distance from XT, but with respect to the local now.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do in this paper is mainly combine the idea of taking single point gradient estimates with the idea of self concordant barriers and.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Local norms, so the key advantage in using this kind of analysis is that now we have completely removed the idea of the problem of taking projections, so previously encourages algorithm was going in taking a gradient step and then projecting back into the step every time.",
                    "label": 1
                },
                {
                    "sent": "But now we since we choose points from the digital side every time, we always guaranteed to be stay inside convex set, so we never need to project back.",
                    "label": 0
                },
                {
                    "sent": "And I mean the complexity corresponding to that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gone completely.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we generate a gradient estimate of the original function at every time step, and then we feed it to full information black box.",
                    "label": 1
                },
                {
                    "sent": "As we had said before.",
                    "label": 0
                },
                {
                    "sent": "So the full information black box that we use is not zinkevich is black box but the black box that was provided by the algorithm that was provided by Jake Abernethy, Alexandra Clean in their paper.",
                    "label": 0
                },
                {
                    "sent": "So what this does is it takes it keeps the gradients from the first step to that step and it takes it up with support with X and it adds the self concordant function at X and minimizes this.",
                    "label": 0
                },
                {
                    "sent": "So whatever, whatever X minimizes the new point.",
                    "label": 0
                },
                {
                    "sent": "So this is the same as the follow the regularised leader approach, and there I mean the the XT plus one that you get is just by mini.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sing the same problem.",
                    "label": 0
                },
                {
                    "sent": "So to give you a brief overview of the algorithm, we start with assuming that for a convex set.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Self concordant barrier is already known, so there was a paper which basically proved that for any convex set, the self concordant barrier always exists.",
                    "label": 0
                },
                {
                    "sent": "But we assume that we know it.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or the next key?",
                    "label": 0
                },
                {
                    "sent": "And we start with a particular point X1 belonging to the convex set an at every step T. We assume you of course know XT at time T, and then since we know the self concordant barrier and we know the point XT, we can draw this Dick in lip side around XD and we can evaluate this quantity 80 which is basically just the square root of the inverse of the Hessian.",
                    "label": 1
                },
                {
                    "sent": "Once this quantity is calculated.",
                    "label": 0
                },
                {
                    "sent": "We can just.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is Whitey, which belongs which actually lies on the digital side and we choose Whitey at random.",
                    "label": 0
                },
                {
                    "sent": "And the player instead of.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Playing the point XD now plays this random point YT and receives the last 50 YT.",
                    "label": 0
                },
                {
                    "sent": "So after that you can.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically we use the same idea of taking the estimate of a gradient and the gradient estimate is given by this expression.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once we have the estimate of the gradient, we feed it to a full information algorithm, which is the Abernethy Hazan Reckling Oracle and we solve the FPL problem to get 60 + 1.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll give you a very brief proof sketch of why this thing works.",
                    "label": 1
                },
                {
                    "sent": "So like the proof goes through defining this approximation of the original problem.",
                    "label": 0
                },
                {
                    "sent": "So FT at X is now defined as the expected value of points of FT evaluated at points which are drawn from a Delta Dick in ellipsoid around X.",
                    "label": 0
                },
                {
                    "sent": "So you draw you draw a Dick in lips around X, and you look at all the points inside the deck in left side, but off size Delta around XD, and then you draw points from that and you take the expected value with respect to that.",
                    "label": 0
                },
                {
                    "sent": "So we open up the regret and we write it as a telescopic sum.",
                    "label": 1
                },
                {
                    "sent": "Using this approximation and using the fact that we're actually playing the random point YT instead of the actual point XD that incurs a cost of order T Delta squared, whereas using the full information black box has its own cost of like square root by Delta login factors, this is all assuming that you're playing ball playing items within Delta balls and deltas fears, and after that if we trade up these two terms with respect to Delta, we get the to the 2/3 regret.",
                    "label": 0
                },
                {
                    "sent": "Up to log rhythmic guarantees.",
                    "label": 0
                },
                {
                    "sent": "So in conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We improve the upper bounds on regret for bandit online convex optimization from T3 four, two, 2/3 for smooth.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Functions.",
                    "label": 0
                },
                {
                    "sent": "And the main problem that realizing this area is that the lower bound still correspond to the full information setting, and in some cases.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A huge gap between the upper bounds on the lower bounds known right now, so the Golden question in online learning is how do you?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is this gap one of the ideas is to look at better bounds on this price of banded information for very well behaved problems.",
                    "label": 1
                },
                {
                    "sent": "So for example, if you remember the picture, the inner innermost part basically both strongly convex functions as well as smooth functions.",
                    "label": 0
                },
                {
                    "sent": "These are in general in machine learning.",
                    "label": 0
                },
                {
                    "sent": "The most well behaved functions, but apparently we still can provide better rates on regret on even those classes functions.",
                    "label": 0
                },
                {
                    "sent": "So yeah, that's the main question that remains open.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}