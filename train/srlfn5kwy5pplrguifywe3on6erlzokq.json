{
    "id": "srlfn5kwy5pplrguifywe3on6erlzokq",
    "title": "SoftRank: Optimising Non-Smooth Rank Metrics",
    "info": {
        "author": [
            "Michael Taylor, Microsoft Research, Cambridge, Microsoft Research"
        ],
        "published": "Feb. 25, 2008",
        "recorded": "February 2008",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm08_taylor_srons/",
    "segmentation": [
        [
            "Right, this is work done at Microsoft Research, Cambridge.",
            "The problem that I'm trying to address today is the optimization or the learning of ranking functions.",
            "So what I mean by saying?"
        ],
        [
            "Biometrics are not smooth in this talk.",
            "I'm going to take the example of N DCG, but many of the issues that I raised would apply equally if we were setting out to optimize another rank based IR metric like mean average precision.",
            "So just to get some some notation.",
            "That we have a ranking function F and it's generating it outputs the document score S. And it's got input Switcher, feature vectors, query and document feature query and document features X and it's got some tunable parameters W and in learning to rank.",
            "Comes to learn W from a set of labeled training queries, OK?",
            "So obviously typically a search engine will sort.",
            "By that score to give a ranked list of documents and in our training set we have labels between zero in our particular training set we got labels between 0, which is irrelevant document to up to three, which is a perfect document and central to the NDC.",
            "G is the gain function, which is what the G stands for, normalized discounted cumulative gain.",
            "The gain is usually an exponential function of the label, so this means that if you have a label 3 document for your query, it dominates the DCG for that query.",
            "So here we have a situation in a little figure.",
            "The height of the red bars represents the gain of the document that happens to land up at that rank as given to us by the sort of the document scores.",
            "And the other component of N DCG is this discount function here in Green Day of R&D of ours is a monotonically decreasing function.",
            "Which starts off at one at the top with the best rank.",
            "OK, so and given those two things, the discount and the gain N DCG is just the sum over the ranks starting from the top going down of the product of the height of the game, which is the height of the red bar and the discount which is the value of the green decaying function there.",
            "So we just sum this over ranks starting from the top and going down that gives gives us N DCG.",
            "OK, so.",
            "One might try and set out to optimize parameters using some gradient descent technique.",
            "And what we would really be after in that context is the rate of change.",
            "Is the gradient of N DCG, which I called G. Here with respect to these ranking function parameters W. Now the sorry the the problem with this is that these gradients are generally non smooth.",
            "OK, so the generally zero as you move.",
            "You can see this if you think of moving the weight vector a tiny amount, nothing if nothing happens to the ranking.",
            "The ordered list the positions of the documents in the ordered list.",
            "Then the entity just does not change and then will come a point when you moved the weight.",
            "The weight enough and the documents which order and at that point there's a step change in G and ECG.",
            "And in fact, the gradients have an infinite then honestly they have a spike at that point."
        ],
        [
            "OK, So what do people?",
            "What do people do to get round?",
            "This is clearly because the metric that we're interested in optimizing the I are top heavy metric.",
            "Is non smooth in the in the way I've just described.",
            "There are various ways to avoid this nonsense by using proxy training objectives in your in your.",
            "Training set so I like to think of these in three categories.",
            "The first one is a point wise and the simplest version of this kind of training objective function is.",
            "What you do if you do regression on labels.",
            "So if your ranking function assume you gotta say neural net ranking function if the output of that ranking function you set it up to try and predict the label of the documents in your training set then then you might have something like a mean square error.",
            "I mean square error objective function given by this this equation here and this is this is a pointwise cost function in the sense that is defined for a single document in a single label.",
            "OK, there's nothing to do with lists as the first speaker this afternoon described in quite nicely that there's a second class which is pairwise pairwise objectives.",
            "And here's an example of rank net.",
            "It would cost function which is defined for an ordering.",
            "So you give it a preference ordering of two documents.",
            "Document One is better than document two and then we have a cost function which is on the difference as a function of the difference of these scores of coming out of the ranking function S 2 S one so intuitively as S2 and S1 in the incorrect order, the cost the cost gets higher as they get incorrectly, they diverge in the incorrect order.",
            "So Frank, which is what I want to talk about today, is it comes in the category.",
            "This last category list based, which is much more close to the spirit of N, DCG and and I are metrics in general and that I think is is the reason why they seem to be.",
            "Well, algorithms of this kind seem to be the state of the art at the moment, and a good example of one wants to hear some several examples of people who have tried list based training objectives and the basic intuition is that if you're learning if you're if you're ranking function has limited capacity to to order documents, then you might be in a situation where you have to choose between this ordering.",
            "Here reads the red bars represents the scores of the relevant document, and the black bars represent the schools and irrelevant document.",
            "If you're if you're.",
            "Function if you're ranking function has limited capacity, you might be.",
            "This way you have to choose between these two guys and I've chosen this example such that the top down it again.",
            "Sorry, the top one would have a better N DCG because we have a relevant document in the Top Rank and the bottom one may quite possibly have a better pair wise error for example, but in IR applications.",
            "The thing is that this one here it would be a better a better choice.",
            "So this based metrics.",
            "Have this.",
            "That they have they know about the ranks of the documents in the at the training phase and they try and when forced to choose they will try and and make sure that the relevant document the ranking at the top of the ranking, the documents at the top of the ranking are good."
        ],
        [
            "OK, so the basic approach of soft rank is to take.",
            "If, like the the list based approaches to the extreme and really, really want to optimize something in our training set that is as close to N DCG as we can possibly make it so we have, the simple idea really, which is just to add noise to the scores.",
            "OK to treat, this causes random variables.",
            "So here here we have.",
            "3 egg toy.",
            "Example of a query with three three documents S1 and they have scores here.",
            "S1S2S3 and S3 is the document with the greatest score and these diagrams.",
            "These figures.",
            "Here are the what we call the rank distributions.",
            "OK, so if this if a document has a deterministic score, then its rank distribution is also deterministic, so the probability that the blue guy will end up at the top.",
            "Ranking is 1 and it's impossible that it could possibly end up at any other rank.",
            "Now when we add score noise to this course, they have the same means.",
            "But now we've got.",
            "We treat them as random Gaussian random variables.",
            "Just intuitively, we now have the situation where the blue the blue document generates a distribution over scores.",
            "Now a distribution of ranks, so it's it's it's most likely to come at rank at the Top Rank rank zero in this work.",
            "But there is a small probability that it could come second, and an even smaller problems that come third, and likewise that the red.",
            "The red guy is most likely to come bottom, but there is some chance that he'll come first or second.",
            "So when we add noise, the scores we can start thinking about these rank distributions.",
            "That's the main main subject of the talk.",
            "The trick that we want to present in the next few slides that we can come up with a precise equations for these rank distributions which do not involve sorting OK, and that's very important 'cause you have a sort, your gradients are no longer smooth and we want to do gradient based optimization of the weight parameters.",
            "So we want to avoid sorts at all costs.",
            "So given that we can do that and I'll explain that later, I don't worry.",
            "We can define soft N DCG, which is a smooth version of N DCG.",
            "But it's very close to N DCG, and it's precisely the expected value of N DCG.",
            "Under these rank distributions.",
            "And I'll explain what that means later on.",
            "So, given that we've got this, these handle on what these rank distributions R as a function of these noise variance is the noise that we add to the scores.",
            "It would probably come as no surprise that the derivatives of soft N DCG with respect to the weight parameters of our ranking model are smooth and we can therefore use them."
        ],
        [
            "For optimization.",
            "OK, So what are these rank distributions in a little bit more detail well?",
            "Again, using this three documents.",
            "Three documents, for example, here's the generative process for the exact distribution we sample from each individual score distribution 1, two, and three, and this in this case, this would give us a triple of scores and triplets of scores.",
            "We sort the three scores.",
            "In this case, we're generally we will have an of them for a query.",
            "We sort these three scores to get a rank for each document given the sample, and we do this many, many times.",
            "We sample the triplets many, many times and build up just a histogram of the rank distributions.",
            "And in this way we can generate these these rank distributions down here.",
            "So you can think of the rank distributions as a doubly stochastic matrix where these distributions are the rows OK, so the rows correspond to the rank distribution given a document and the columns are.",
            "You can also view them as the probability distribution of over documents given a rank, so.",
            "So that's a nice way of thinking about this.",
            "What this is, rank distributions are and what I want to go on to describe now is we need a good approximation of coming up with this rank matrix.",
            "These three.",
            "In this case it's in these nine values, right?",
            "We need a good way of coming up with these rank distributions.",
            "Which in a way that doesn't involve this sort, 'cause we can't differentiate through this sort.",
            "OK, so this exact generative process involves a sort we want to avoid, that that's what we got."
        ],
        [
            "To next.",
            "So we are going to introduce the idea of pairwise contest approximation.",
            "Now assume for the next couple of slides that we are seeking to infer the rank distribution for the J TH.",
            "Document SJ, So this is SJ score and we have some other document SI.",
            "An the means of these Gaussians we assume that Gaussian beyond the means of these Gaussians are given by the neural net ranking function.",
            "And the variance is a fixed right?",
            "So we have a pairwise contest between the document that whose rank distribution we seek and another documents.",
            "And we call.",
            "We define this quantity Pi J which is the probability that the other document beats.",
            "Beats my.",
            "Document J OK.",
            "So basically we will take this is this is this is plotting these two score distributions a circular 2 dimensional Gaussian.",
            "The joint distribution of the two scores and basically the Pi J is the area the probability mass that lies below this line.",
            "This line represents when the two scores are the same.",
            "So the Pi AJ is to simply the probability that this guy draw from here will be to draw from here.",
            "And obviously in this case is quite likely would expect by Jay to be quite close to 1.",
            "So, given this concept of this, this Bernoulli probability Pi J. I guess the key key idea we have in the whole paper is that well, if we do this a number of times for all the other documents, I so we sum I from one to N where I is not equal to J.",
            "If we sum these probabilities, then if they're all close to one for example, then that means that.",
            "A lot of the other guys are going to beat me, beat my document J and the rank.",
            "If we just sum them up, the rank will be close to N -- 1.",
            "In the limit, if they were all one, this is certain for every other document that my document J was going to beat and then this some would be N -- 1 which of course is the maximum rank the document can have.",
            "Conversely, if they're all close to 0, then this would be close to 0 and that's the best rank we can have, right?",
            "So this is a very simple expression for the expected rank.",
            "Given these Gaussian noise up scores, so the key thing is that we haven't done a sort right.",
            "So so if we use this approach.",
            "It'll be differentiable, but the question is, this is a pairwise.",
            "This pairwise contest is an approximation, so we'll come to that in a minute.",
            "So we have we have here.",
            "We've written down expected value of the rank of the rank for the document J.",
            "That's not enough.",
            "We need the actual distribution.",
            "We need to know the probability for each rank that this document they will end up at that rank.",
            "And this is a bit like a binomial distribution.",
            "Remember a binomial distribution you have N trials and for each trial you have the same success probability.",
            "It's usually called P. This is slightly different.",
            "We have N -- 1 trials of the bone in the probability that Bernoulli probability which has a zero or one outcome success or fail outcome, is this Pi, J and so the success will fail outcome unlike with the binomial distribution is different at each draw right?",
            "So we call this distribution.",
            "It's a slightly more complicated.",
            "Version of the binomial distribution, and we call this distribution the rank binomial."
        ],
        [
            "And the next slide.",
            "Don't worry bout if you don't understand this one.",
            "This is the details are in the slide.",
            "This this gives you the flavor of how we go about computing the value of the rank, rank, rank, binomial distribution.",
            "We have a recurrence relation, so we start off with our document SJ just on its own, so the rank that this document can have is is the best rank with Rancor zero with certain probability.",
            "Then we just we take.",
            "It doesn't matter which one, we just take a new document S1 in blue, OK, and now we have an event space over ranks which covers zero and one.",
            "And if we take the example of the probability that we will end up at rank one, well that's just simply the probability play one J.",
            "But this new.",
            "Document is going to beat me right now.",
            "Now we got a distribution over 2 ranks.",
            "We take another one at random.",
            "It doesn't really matter which one.",
            "You get the same answer.",
            "In the end, SAS two in green here and I'll just take this example.",
            "We want to workout the probability that in this 3 way contest that we're still end up at rank one, which is the 2nd rank.",
            "Well, that can happen in two ways.",
            "You could start off being at the Top Rank in the previous round and.",
            "Which is this probability that 2 means the second round and then we multiply that by the chance that were beaten right, pushing our rank down to one by the new green?",
            "Score distribution and we add on to that the probability that we were at rank one, which is this probability.",
            "That's what that one is, and we beat the next document, right?",
            "So the star rank doesn't change.",
            "So in this way as we go through all that we can add in each round you add in another document distribution and you end up at the end of the day with a discrete distribution over N. And ever end ranks, which is what we're after, so the take home message for this is given the expressions using this recurrence relation, we can come up with expressions for the rank matrix.",
            "I described a couple of slides back and its derivative is is analytic in the school means there's an integral on if you'd like.",
            "If it's not important, but the integral few slides back where we define the paije that disappears when you take the derivatives, and it makes this relation for the slightly.",
            "Slightly simpler, the main thing is it's a straightforward process and it doesn't involve a sort, so we have the rank distributions with no sort."
        ],
        [
            "At this point.",
            "So.",
            "We got we didn't use a sort, but we also we did use this pairwise contest trick, which is an approximation to what's really going on.",
            "Remember the real generative process involves sampling and sorting.",
            "So here's this with a qualitative view of the situation.",
            "We got more complicated set of Gaussian scores here.",
            "Here's the rank binomial obtained by the the recurrence relation I just described with no with no sorting.",
            "Here's the true rank distribution obtained by the generative process of sampling and binning, sampling, sorting, and billing that I described a while back.",
            "And here are the residual so at least.",
            "Qualitatively, we got a good a good approximation to the true rank distributions."
        ],
        [
            "OK, so given the given that we got rank distributions for any document as a function of their scores that come out of the neural net, how do we?",
            "How do we use that rank distribution to come up with a smooth version of N DCG that we can use in gradient descent?",
            "OK, so just as a reminder, here's the equation for N DCG.",
            "We've got this sum over the gains of the document J multiplied by the discount of the rank.",
            "That document J happens to occupy, so soft NTG as I said before, was just simply the expected value under the rank distribution of the hard NDC if you like.",
            "So anything that's random in this equation is the rank which appears inside.",
            "This expectation is a discount at that rank, so.",
            "Intuitively, what's going on here is we gotta rank distribution this example that the most likely rank is 2.",
            "We map it through a nonlinear discount function.",
            "And this gives an you discrete distribution over discounts.",
            "OK, so the maximum the most likely rank is 2.",
            "We map that through the distant only discount function.",
            "Reread office discounters .5.",
            "It's the most likely discount is here at .5.",
            "OK, so we this is just a simple non it's not simple.",
            "It's a nonlinear mapping of 1 discrete distribution to another discrete distribution.",
            "It will be really after is the mean value of this discrete distribution over discounts and that's what this sum is here.",
            "So that's really it.",
            "Once you once you've got that equation, Curly G soft N DCG, we can just go right ahead and differentiate it.",
            "What we're after is soft N DCG.",
            "This derivative respect to weights of our model ranking function and just by the simple application of the chain rule we've got the curly G by the score means which we get from the rank recursion on the last slide and this term.",
            "Here the rate of change of these scores with respect to the weight parameters.",
            "We get that in our particular model, from NDC, from backpropagation equations."
        ],
        [
            "OK, so we now I'm just going to describe some experiments where we use that gradient in gradient descent optimization and report how we do.",
            "So remember we gotta now we gotta a smooth, objective function which is.",
            "Quite quite closely related to N. DCG and I believe close, more closely related than many other attempts in the past, so we have our basic models in two layer neural net.",
            "And for the web data which I will focus on primary in this quick review of the results, we have 300 features, various proximity features being 25, the usual kind of thing we have 4000 training queries and we have a validation and a test that we use the validation set to prevent overfitting.",
            "Add validation test set of both have roughly two 2000 queries each, so we used any CG at 10 we got cut off 10 for our validation and our test metrics.",
            "And the optimization was a stochastic gradient descent with some restarts OK.",
            "So actually there's a couple of parameters that control this gradient descent, namely then learning rate or the step size and the initial smoothing that we use for the soft N, DCG, and we use these.",
            "We use the validation set to set the."
        ],
        [
            "So here's some results.",
            "The first thing I want to highlight is this is the web on the web set we have.",
            "This is the NDC G on the training set.",
            "So this is soft rank in purple.",
            "I'm drinking green right net in red and mean square error in.",
            "In blue there and across all that, all the corporate that we've tried this on, we get a consistently much better N DCG in the training set right?",
            "So this my opinion anyway validates our our assumptions about using the rank binomial in the pairwise contest trick so we do succeed in optimizing NDC on our training set much better than the other approaches.",
            "The bad news is that on the on the web datasets at least we have a significant.",
            "We do.",
            "We do significantly worse.",
            "This difference is significant.",
            "Statistically significant, then Lambda rank.",
            "So somehow are improvements on the test set on the test.",
            "It is not generalizing to new queries, OK?"
        ],
        [
            "So we haven't generated this.",
            "Motivated the generalization study.",
            "Are we just somehow overfitting?",
            "Is soft and ECG more prone to?",
            "Overfitting than the other metrics objectives.",
            "Well, we were GBS about this.",
            "'cause we do have an NDC G validation sets that we employed specifically to prevent overfitting so but just to test this a little bit more, we try to match.",
            "We tried training in with a much simpler linear model so the result I showed you before was a model with 3000 parameters.",
            "We tried a linear model with 300 parameters so these two results for the.",
            "That's the nonlinear case, and these two sets of results for the linear case.",
            "And here we see the gap with better on the.",
            "This is for the training set.",
            "We do better on the training set, worse on the test set and we still see the same effect with a much simpler model so.",
            "Let us to conclude that is because we're still seeing the same effect with a radically different model.",
            "There must be something."
        ],
        [
            "What's going on?",
            "It's not simple overfitting, so let this lead us to consider.",
            "The following hypothesis that SoftBank is focusing too much on the top ranks.",
            "In fact, they may be useful.",
            "For example, there may be useful information in the ordering at lower ranks that is effectively ignored by soft rank.",
            "So to test this, we tried a range of different discounts.",
            "This is the one misshape.",
            "Here is the one that's used in the TCG.",
            "They regular any CG on the evaluation or the test sets.",
            "We tried a range of different discount functions.",
            "This range is the performance on the test set is shown here and this horizontal line is our Lambda rank baseline and the rank performs better than all the other approaches on this set.",
            "So we observe that we can regain the performance of Lander rank if we use a much shallower discount function.",
            "So this for us is that that is indeed the case that focusing too much on the top of the ranking.",
            "Actually hurts you when when you come to looking at the holdouts."
        ],
        [
            "So queries OK, so to conclude.",
            "We've shown that soft rank with this rank, binomial assumptions optimizes NDC NDC G very well.",
            "One thing we can do in the future is to use the rank binomial distributions and those ideas to optimize other metrics.",
            "This often.",
            "DCG does not generalize well.",
            "It seems to focus too much on the top ranks in training and effects.",
            "It's an inefficient use of training data, in fact, so we let let us to realize really that's too close to ND DCG in some sense, so we can recover the Lambda rank performance with less severe discount function.",
            "That's it, thanks.",
            "Questions.",
            "In the pairwise context, the approximation where you have assumed Gaussian distribution on the scores, you decide the mean by the neural networks, but I'm not sure how you choose the variance there the the variance.",
            "So the question is, it's clear how you set the mean of the Gaussian store score distributions I from the output of the neural net, how do you set the variances?",
            "Um?",
            "There's a section in the paper which I didn't have time to talk about today, which which shows how when the there's a degree of freedom in the parameters which basically affects this the score, the magnitude of this course.",
            "So for example, if you multiplied all the scores by some common factor, you would you would not change the.",
            "It's impossible to change the ranking that way, right?",
            "The scores will just grow in the sit by the same amount, but their relative rankings would remain the same.",
            "So our model is free to vary the weights.",
            "To in in that dimension, if you like in that degree of freedom but so and multiple stretching out the score.",
            "The score access like that is the same thing as reducing the variance.",
            "So in fact what happening is that as it's learning the weight vector is constantly adjusting the variance through that mechanism.",
            "Is that clear?",
            "So we don't.",
            "We still quite sensitive to how you set the initial value of the variance at the beginning of learning, but once you set it off and it's an indispensable value, this mechanism comes into play.",
            "So it's actually trying to control the scale of the score, which has the effect of controlling the variance.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, this is work done at Microsoft Research, Cambridge.",
                    "label": 1
                },
                {
                    "sent": "The problem that I'm trying to address today is the optimization or the learning of ranking functions.",
                    "label": 0
                },
                {
                    "sent": "So what I mean by saying?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Biometrics are not smooth in this talk.",
                    "label": 1
                },
                {
                    "sent": "I'm going to take the example of N DCG, but many of the issues that I raised would apply equally if we were setting out to optimize another rank based IR metric like mean average precision.",
                    "label": 0
                },
                {
                    "sent": "So just to get some some notation.",
                    "label": 0
                },
                {
                    "sent": "That we have a ranking function F and it's generating it outputs the document score S. And it's got input Switcher, feature vectors, query and document feature query and document features X and it's got some tunable parameters W and in learning to rank.",
                    "label": 0
                },
                {
                    "sent": "Comes to learn W from a set of labeled training queries, OK?",
                    "label": 0
                },
                {
                    "sent": "So obviously typically a search engine will sort.",
                    "label": 1
                },
                {
                    "sent": "By that score to give a ranked list of documents and in our training set we have labels between zero in our particular training set we got labels between 0, which is irrelevant document to up to three, which is a perfect document and central to the NDC.",
                    "label": 0
                },
                {
                    "sent": "G is the gain function, which is what the G stands for, normalized discounted cumulative gain.",
                    "label": 0
                },
                {
                    "sent": "The gain is usually an exponential function of the label, so this means that if you have a label 3 document for your query, it dominates the DCG for that query.",
                    "label": 0
                },
                {
                    "sent": "So here we have a situation in a little figure.",
                    "label": 0
                },
                {
                    "sent": "The height of the red bars represents the gain of the document that happens to land up at that rank as given to us by the sort of the document scores.",
                    "label": 0
                },
                {
                    "sent": "And the other component of N DCG is this discount function here in Green Day of R&D of ours is a monotonically decreasing function.",
                    "label": 0
                },
                {
                    "sent": "Which starts off at one at the top with the best rank.",
                    "label": 0
                },
                {
                    "sent": "OK, so and given those two things, the discount and the gain N DCG is just the sum over the ranks starting from the top going down of the product of the height of the game, which is the height of the red bar and the discount which is the value of the green decaying function there.",
                    "label": 0
                },
                {
                    "sent": "So we just sum this over ranks starting from the top and going down that gives gives us N DCG.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "One might try and set out to optimize parameters using some gradient descent technique.",
                    "label": 0
                },
                {
                    "sent": "And what we would really be after in that context is the rate of change.",
                    "label": 1
                },
                {
                    "sent": "Is the gradient of N DCG, which I called G. Here with respect to these ranking function parameters W. Now the sorry the the problem with this is that these gradients are generally non smooth.",
                    "label": 0
                },
                {
                    "sent": "OK, so the generally zero as you move.",
                    "label": 0
                },
                {
                    "sent": "You can see this if you think of moving the weight vector a tiny amount, nothing if nothing happens to the ranking.",
                    "label": 0
                },
                {
                    "sent": "The ordered list the positions of the documents in the ordered list.",
                    "label": 0
                },
                {
                    "sent": "Then the entity just does not change and then will come a point when you moved the weight.",
                    "label": 0
                },
                {
                    "sent": "The weight enough and the documents which order and at that point there's a step change in G and ECG.",
                    "label": 0
                },
                {
                    "sent": "And in fact, the gradients have an infinite then honestly they have a spike at that point.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what do people?",
                    "label": 0
                },
                {
                    "sent": "What do people do to get round?",
                    "label": 0
                },
                {
                    "sent": "This is clearly because the metric that we're interested in optimizing the I are top heavy metric.",
                    "label": 0
                },
                {
                    "sent": "Is non smooth in the in the way I've just described.",
                    "label": 0
                },
                {
                    "sent": "There are various ways to avoid this nonsense by using proxy training objectives in your in your.",
                    "label": 1
                },
                {
                    "sent": "Training set so I like to think of these in three categories.",
                    "label": 0
                },
                {
                    "sent": "The first one is a point wise and the simplest version of this kind of training objective function is.",
                    "label": 0
                },
                {
                    "sent": "What you do if you do regression on labels.",
                    "label": 1
                },
                {
                    "sent": "So if your ranking function assume you gotta say neural net ranking function if the output of that ranking function you set it up to try and predict the label of the documents in your training set then then you might have something like a mean square error.",
                    "label": 0
                },
                {
                    "sent": "I mean square error objective function given by this this equation here and this is this is a pointwise cost function in the sense that is defined for a single document in a single label.",
                    "label": 0
                },
                {
                    "sent": "OK, there's nothing to do with lists as the first speaker this afternoon described in quite nicely that there's a second class which is pairwise pairwise objectives.",
                    "label": 0
                },
                {
                    "sent": "And here's an example of rank net.",
                    "label": 0
                },
                {
                    "sent": "It would cost function which is defined for an ordering.",
                    "label": 0
                },
                {
                    "sent": "So you give it a preference ordering of two documents.",
                    "label": 0
                },
                {
                    "sent": "Document One is better than document two and then we have a cost function which is on the difference as a function of the difference of these scores of coming out of the ranking function S 2 S one so intuitively as S2 and S1 in the incorrect order, the cost the cost gets higher as they get incorrectly, they diverge in the incorrect order.",
                    "label": 0
                },
                {
                    "sent": "So Frank, which is what I want to talk about today, is it comes in the category.",
                    "label": 0
                },
                {
                    "sent": "This last category list based, which is much more close to the spirit of N, DCG and and I are metrics in general and that I think is is the reason why they seem to be.",
                    "label": 0
                },
                {
                    "sent": "Well, algorithms of this kind seem to be the state of the art at the moment, and a good example of one wants to hear some several examples of people who have tried list based training objectives and the basic intuition is that if you're learning if you're if you're ranking function has limited capacity to to order documents, then you might be in a situation where you have to choose between this ordering.",
                    "label": 0
                },
                {
                    "sent": "Here reads the red bars represents the scores of the relevant document, and the black bars represent the schools and irrelevant document.",
                    "label": 0
                },
                {
                    "sent": "If you're if you're.",
                    "label": 0
                },
                {
                    "sent": "Function if you're ranking function has limited capacity, you might be.",
                    "label": 0
                },
                {
                    "sent": "This way you have to choose between these two guys and I've chosen this example such that the top down it again.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the top one would have a better N DCG because we have a relevant document in the Top Rank and the bottom one may quite possibly have a better pair wise error for example, but in IR applications.",
                    "label": 0
                },
                {
                    "sent": "The thing is that this one here it would be a better a better choice.",
                    "label": 0
                },
                {
                    "sent": "So this based metrics.",
                    "label": 0
                },
                {
                    "sent": "Have this.",
                    "label": 0
                },
                {
                    "sent": "That they have they know about the ranks of the documents in the at the training phase and they try and when forced to choose they will try and and make sure that the relevant document the ranking at the top of the ranking, the documents at the top of the ranking are good.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the basic approach of soft rank is to take.",
                    "label": 0
                },
                {
                    "sent": "If, like the the list based approaches to the extreme and really, really want to optimize something in our training set that is as close to N DCG as we can possibly make it so we have, the simple idea really, which is just to add noise to the scores.",
                    "label": 0
                },
                {
                    "sent": "OK to treat, this causes random variables.",
                    "label": 0
                },
                {
                    "sent": "So here here we have.",
                    "label": 0
                },
                {
                    "sent": "3 egg toy.",
                    "label": 0
                },
                {
                    "sent": "Example of a query with three three documents S1 and they have scores here.",
                    "label": 0
                },
                {
                    "sent": "S1S2S3 and S3 is the document with the greatest score and these diagrams.",
                    "label": 0
                },
                {
                    "sent": "These figures.",
                    "label": 0
                },
                {
                    "sent": "Here are the what we call the rank distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, so if this if a document has a deterministic score, then its rank distribution is also deterministic, so the probability that the blue guy will end up at the top.",
                    "label": 0
                },
                {
                    "sent": "Ranking is 1 and it's impossible that it could possibly end up at any other rank.",
                    "label": 0
                },
                {
                    "sent": "Now when we add score noise to this course, they have the same means.",
                    "label": 0
                },
                {
                    "sent": "But now we've got.",
                    "label": 0
                },
                {
                    "sent": "We treat them as random Gaussian random variables.",
                    "label": 0
                },
                {
                    "sent": "Just intuitively, we now have the situation where the blue the blue document generates a distribution over scores.",
                    "label": 0
                },
                {
                    "sent": "Now a distribution of ranks, so it's it's it's most likely to come at rank at the Top Rank rank zero in this work.",
                    "label": 0
                },
                {
                    "sent": "But there is a small probability that it could come second, and an even smaller problems that come third, and likewise that the red.",
                    "label": 0
                },
                {
                    "sent": "The red guy is most likely to come bottom, but there is some chance that he'll come first or second.",
                    "label": 0
                },
                {
                    "sent": "So when we add noise, the scores we can start thinking about these rank distributions.",
                    "label": 0
                },
                {
                    "sent": "That's the main main subject of the talk.",
                    "label": 0
                },
                {
                    "sent": "The trick that we want to present in the next few slides that we can come up with a precise equations for these rank distributions which do not involve sorting OK, and that's very important 'cause you have a sort, your gradients are no longer smooth and we want to do gradient based optimization of the weight parameters.",
                    "label": 0
                },
                {
                    "sent": "So we want to avoid sorts at all costs.",
                    "label": 0
                },
                {
                    "sent": "So given that we can do that and I'll explain that later, I don't worry.",
                    "label": 0
                },
                {
                    "sent": "We can define soft N DCG, which is a smooth version of N DCG.",
                    "label": 0
                },
                {
                    "sent": "But it's very close to N DCG, and it's precisely the expected value of N DCG.",
                    "label": 0
                },
                {
                    "sent": "Under these rank distributions.",
                    "label": 0
                },
                {
                    "sent": "And I'll explain what that means later on.",
                    "label": 0
                },
                {
                    "sent": "So, given that we've got this, these handle on what these rank distributions R as a function of these noise variance is the noise that we add to the scores.",
                    "label": 0
                },
                {
                    "sent": "It would probably come as no surprise that the derivatives of soft N DCG with respect to the weight parameters of our ranking model are smooth and we can therefore use them.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For optimization.",
                    "label": 0
                },
                {
                    "sent": "OK, So what are these rank distributions in a little bit more detail well?",
                    "label": 0
                },
                {
                    "sent": "Again, using this three documents.",
                    "label": 0
                },
                {
                    "sent": "Three documents, for example, here's the generative process for the exact distribution we sample from each individual score distribution 1, two, and three, and this in this case, this would give us a triple of scores and triplets of scores.",
                    "label": 1
                },
                {
                    "sent": "We sort the three scores.",
                    "label": 0
                },
                {
                    "sent": "In this case, we're generally we will have an of them for a query.",
                    "label": 1
                },
                {
                    "sent": "We sort these three scores to get a rank for each document given the sample, and we do this many, many times.",
                    "label": 0
                },
                {
                    "sent": "We sample the triplets many, many times and build up just a histogram of the rank distributions.",
                    "label": 0
                },
                {
                    "sent": "And in this way we can generate these these rank distributions down here.",
                    "label": 1
                },
                {
                    "sent": "So you can think of the rank distributions as a doubly stochastic matrix where these distributions are the rows OK, so the rows correspond to the rank distribution given a document and the columns are.",
                    "label": 0
                },
                {
                    "sent": "You can also view them as the probability distribution of over documents given a rank, so.",
                    "label": 0
                },
                {
                    "sent": "So that's a nice way of thinking about this.",
                    "label": 0
                },
                {
                    "sent": "What this is, rank distributions are and what I want to go on to describe now is we need a good approximation of coming up with this rank matrix.",
                    "label": 1
                },
                {
                    "sent": "These three.",
                    "label": 0
                },
                {
                    "sent": "In this case it's in these nine values, right?",
                    "label": 0
                },
                {
                    "sent": "We need a good way of coming up with these rank distributions.",
                    "label": 0
                },
                {
                    "sent": "Which in a way that doesn't involve this sort, 'cause we can't differentiate through this sort.",
                    "label": 0
                },
                {
                    "sent": "OK, so this exact generative process involves a sort we want to avoid, that that's what we got.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To next.",
                    "label": 0
                },
                {
                    "sent": "So we are going to introduce the idea of pairwise contest approximation.",
                    "label": 1
                },
                {
                    "sent": "Now assume for the next couple of slides that we are seeking to infer the rank distribution for the J TH.",
                    "label": 0
                },
                {
                    "sent": "Document SJ, So this is SJ score and we have some other document SI.",
                    "label": 0
                },
                {
                    "sent": "An the means of these Gaussians we assume that Gaussian beyond the means of these Gaussians are given by the neural net ranking function.",
                    "label": 0
                },
                {
                    "sent": "And the variance is a fixed right?",
                    "label": 0
                },
                {
                    "sent": "So we have a pairwise contest between the document that whose rank distribution we seek and another documents.",
                    "label": 0
                },
                {
                    "sent": "And we call.",
                    "label": 0
                },
                {
                    "sent": "We define this quantity Pi J which is the probability that the other document beats.",
                    "label": 0
                },
                {
                    "sent": "Beats my.",
                    "label": 0
                },
                {
                    "sent": "Document J OK.",
                    "label": 0
                },
                {
                    "sent": "So basically we will take this is this is this is plotting these two score distributions a circular 2 dimensional Gaussian.",
                    "label": 0
                },
                {
                    "sent": "The joint distribution of the two scores and basically the Pi J is the area the probability mass that lies below this line.",
                    "label": 1
                },
                {
                    "sent": "This line represents when the two scores are the same.",
                    "label": 0
                },
                {
                    "sent": "So the Pi AJ is to simply the probability that this guy draw from here will be to draw from here.",
                    "label": 0
                },
                {
                    "sent": "And obviously in this case is quite likely would expect by Jay to be quite close to 1.",
                    "label": 0
                },
                {
                    "sent": "So, given this concept of this, this Bernoulli probability Pi J. I guess the key key idea we have in the whole paper is that well, if we do this a number of times for all the other documents, I so we sum I from one to N where I is not equal to J.",
                    "label": 0
                },
                {
                    "sent": "If we sum these probabilities, then if they're all close to one for example, then that means that.",
                    "label": 0
                },
                {
                    "sent": "A lot of the other guys are going to beat me, beat my document J and the rank.",
                    "label": 0
                },
                {
                    "sent": "If we just sum them up, the rank will be close to N -- 1.",
                    "label": 0
                },
                {
                    "sent": "In the limit, if they were all one, this is certain for every other document that my document J was going to beat and then this some would be N -- 1 which of course is the maximum rank the document can have.",
                    "label": 1
                },
                {
                    "sent": "Conversely, if they're all close to 0, then this would be close to 0 and that's the best rank we can have, right?",
                    "label": 0
                },
                {
                    "sent": "So this is a very simple expression for the expected rank.",
                    "label": 0
                },
                {
                    "sent": "Given these Gaussian noise up scores, so the key thing is that we haven't done a sort right.",
                    "label": 1
                },
                {
                    "sent": "So so if we use this approach.",
                    "label": 0
                },
                {
                    "sent": "It'll be differentiable, but the question is, this is a pairwise.",
                    "label": 0
                },
                {
                    "sent": "This pairwise contest is an approximation, so we'll come to that in a minute.",
                    "label": 0
                },
                {
                    "sent": "So we have we have here.",
                    "label": 0
                },
                {
                    "sent": "We've written down expected value of the rank of the rank for the document J.",
                    "label": 0
                },
                {
                    "sent": "That's not enough.",
                    "label": 0
                },
                {
                    "sent": "We need the actual distribution.",
                    "label": 0
                },
                {
                    "sent": "We need to know the probability for each rank that this document they will end up at that rank.",
                    "label": 0
                },
                {
                    "sent": "And this is a bit like a binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "Remember a binomial distribution you have N trials and for each trial you have the same success probability.",
                    "label": 0
                },
                {
                    "sent": "It's usually called P. This is slightly different.",
                    "label": 0
                },
                {
                    "sent": "We have N -- 1 trials of the bone in the probability that Bernoulli probability which has a zero or one outcome success or fail outcome, is this Pi, J and so the success will fail outcome unlike with the binomial distribution is different at each draw right?",
                    "label": 0
                },
                {
                    "sent": "So we call this distribution.",
                    "label": 0
                },
                {
                    "sent": "It's a slightly more complicated.",
                    "label": 0
                },
                {
                    "sent": "Version of the binomial distribution, and we call this distribution the rank binomial.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the next slide.",
                    "label": 0
                },
                {
                    "sent": "Don't worry bout if you don't understand this one.",
                    "label": 0
                },
                {
                    "sent": "This is the details are in the slide.",
                    "label": 0
                },
                {
                    "sent": "This this gives you the flavor of how we go about computing the value of the rank, rank, rank, binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "We have a recurrence relation, so we start off with our document SJ just on its own, so the rank that this document can have is is the best rank with Rancor zero with certain probability.",
                    "label": 0
                },
                {
                    "sent": "Then we just we take.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter which one, we just take a new document S1 in blue, OK, and now we have an event space over ranks which covers zero and one.",
                    "label": 0
                },
                {
                    "sent": "And if we take the example of the probability that we will end up at rank one, well that's just simply the probability play one J.",
                    "label": 0
                },
                {
                    "sent": "But this new.",
                    "label": 0
                },
                {
                    "sent": "Document is going to beat me right now.",
                    "label": 0
                },
                {
                    "sent": "Now we got a distribution over 2 ranks.",
                    "label": 0
                },
                {
                    "sent": "We take another one at random.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter which one.",
                    "label": 0
                },
                {
                    "sent": "You get the same answer.",
                    "label": 0
                },
                {
                    "sent": "In the end, SAS two in green here and I'll just take this example.",
                    "label": 0
                },
                {
                    "sent": "We want to workout the probability that in this 3 way contest that we're still end up at rank one, which is the 2nd rank.",
                    "label": 0
                },
                {
                    "sent": "Well, that can happen in two ways.",
                    "label": 0
                },
                {
                    "sent": "You could start off being at the Top Rank in the previous round and.",
                    "label": 0
                },
                {
                    "sent": "Which is this probability that 2 means the second round and then we multiply that by the chance that were beaten right, pushing our rank down to one by the new green?",
                    "label": 0
                },
                {
                    "sent": "Score distribution and we add on to that the probability that we were at rank one, which is this probability.",
                    "label": 0
                },
                {
                    "sent": "That's what that one is, and we beat the next document, right?",
                    "label": 0
                },
                {
                    "sent": "So the star rank doesn't change.",
                    "label": 0
                },
                {
                    "sent": "So in this way as we go through all that we can add in each round you add in another document distribution and you end up at the end of the day with a discrete distribution over N. And ever end ranks, which is what we're after, so the take home message for this is given the expressions using this recurrence relation, we can come up with expressions for the rank matrix.",
                    "label": 0
                },
                {
                    "sent": "I described a couple of slides back and its derivative is is analytic in the school means there's an integral on if you'd like.",
                    "label": 0
                },
                {
                    "sent": "If it's not important, but the integral few slides back where we define the paije that disappears when you take the derivatives, and it makes this relation for the slightly.",
                    "label": 0
                },
                {
                    "sent": "Slightly simpler, the main thing is it's a straightforward process and it doesn't involve a sort, so we have the rank distributions with no sort.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At this point.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We got we didn't use a sort, but we also we did use this pairwise contest trick, which is an approximation to what's really going on.",
                    "label": 0
                },
                {
                    "sent": "Remember the real generative process involves sampling and sorting.",
                    "label": 0
                },
                {
                    "sent": "So here's this with a qualitative view of the situation.",
                    "label": 0
                },
                {
                    "sent": "We got more complicated set of Gaussian scores here.",
                    "label": 0
                },
                {
                    "sent": "Here's the rank binomial obtained by the the recurrence relation I just described with no with no sorting.",
                    "label": 0
                },
                {
                    "sent": "Here's the true rank distribution obtained by the generative process of sampling and binning, sampling, sorting, and billing that I described a while back.",
                    "label": 0
                },
                {
                    "sent": "And here are the residual so at least.",
                    "label": 0
                },
                {
                    "sent": "Qualitatively, we got a good a good approximation to the true rank distributions.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so given the given that we got rank distributions for any document as a function of their scores that come out of the neural net, how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we use that rank distribution to come up with a smooth version of N DCG that we can use in gradient descent?",
                    "label": 0
                },
                {
                    "sent": "OK, so just as a reminder, here's the equation for N DCG.",
                    "label": 0
                },
                {
                    "sent": "We've got this sum over the gains of the document J multiplied by the discount of the rank.",
                    "label": 0
                },
                {
                    "sent": "That document J happens to occupy, so soft NTG as I said before, was just simply the expected value under the rank distribution of the hard NDC if you like.",
                    "label": 0
                },
                {
                    "sent": "So anything that's random in this equation is the rank which appears inside.",
                    "label": 0
                },
                {
                    "sent": "This expectation is a discount at that rank, so.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, what's going on here is we gotta rank distribution this example that the most likely rank is 2.",
                    "label": 0
                },
                {
                    "sent": "We map it through a nonlinear discount function.",
                    "label": 0
                },
                {
                    "sent": "And this gives an you discrete distribution over discounts.",
                    "label": 0
                },
                {
                    "sent": "OK, so the maximum the most likely rank is 2.",
                    "label": 0
                },
                {
                    "sent": "We map that through the distant only discount function.",
                    "label": 0
                },
                {
                    "sent": "Reread office discounters .5.",
                    "label": 0
                },
                {
                    "sent": "It's the most likely discount is here at .5.",
                    "label": 0
                },
                {
                    "sent": "OK, so we this is just a simple non it's not simple.",
                    "label": 0
                },
                {
                    "sent": "It's a nonlinear mapping of 1 discrete distribution to another discrete distribution.",
                    "label": 0
                },
                {
                    "sent": "It will be really after is the mean value of this discrete distribution over discounts and that's what this sum is here.",
                    "label": 0
                },
                {
                    "sent": "So that's really it.",
                    "label": 0
                },
                {
                    "sent": "Once you once you've got that equation, Curly G soft N DCG, we can just go right ahead and differentiate it.",
                    "label": 0
                },
                {
                    "sent": "What we're after is soft N DCG.",
                    "label": 0
                },
                {
                    "sent": "This derivative respect to weights of our model ranking function and just by the simple application of the chain rule we've got the curly G by the score means which we get from the rank recursion on the last slide and this term.",
                    "label": 0
                },
                {
                    "sent": "Here the rate of change of these scores with respect to the weight parameters.",
                    "label": 0
                },
                {
                    "sent": "We get that in our particular model, from NDC, from backpropagation equations.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we now I'm just going to describe some experiments where we use that gradient in gradient descent optimization and report how we do.",
                    "label": 0
                },
                {
                    "sent": "So remember we gotta now we gotta a smooth, objective function which is.",
                    "label": 0
                },
                {
                    "sent": "Quite quite closely related to N. DCG and I believe close, more closely related than many other attempts in the past, so we have our basic models in two layer neural net.",
                    "label": 0
                },
                {
                    "sent": "And for the web data which I will focus on primary in this quick review of the results, we have 300 features, various proximity features being 25, the usual kind of thing we have 4000 training queries and we have a validation and a test that we use the validation set to prevent overfitting.",
                    "label": 0
                },
                {
                    "sent": "Add validation test set of both have roughly two 2000 queries each, so we used any CG at 10 we got cut off 10 for our validation and our test metrics.",
                    "label": 0
                },
                {
                    "sent": "And the optimization was a stochastic gradient descent with some restarts OK.",
                    "label": 1
                },
                {
                    "sent": "So actually there's a couple of parameters that control this gradient descent, namely then learning rate or the step size and the initial smoothing that we use for the soft N, DCG, and we use these.",
                    "label": 1
                },
                {
                    "sent": "We use the validation set to set the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's some results.",
                    "label": 0
                },
                {
                    "sent": "The first thing I want to highlight is this is the web on the web set we have.",
                    "label": 0
                },
                {
                    "sent": "This is the NDC G on the training set.",
                    "label": 1
                },
                {
                    "sent": "So this is soft rank in purple.",
                    "label": 0
                },
                {
                    "sent": "I'm drinking green right net in red and mean square error in.",
                    "label": 0
                },
                {
                    "sent": "In blue there and across all that, all the corporate that we've tried this on, we get a consistently much better N DCG in the training set right?",
                    "label": 0
                },
                {
                    "sent": "So this my opinion anyway validates our our assumptions about using the rank binomial in the pairwise contest trick so we do succeed in optimizing NDC on our training set much better than the other approaches.",
                    "label": 0
                },
                {
                    "sent": "The bad news is that on the on the web datasets at least we have a significant.",
                    "label": 0
                },
                {
                    "sent": "We do.",
                    "label": 0
                },
                {
                    "sent": "We do significantly worse.",
                    "label": 0
                },
                {
                    "sent": "This difference is significant.",
                    "label": 0
                },
                {
                    "sent": "Statistically significant, then Lambda rank.",
                    "label": 1
                },
                {
                    "sent": "So somehow are improvements on the test set on the test.",
                    "label": 0
                },
                {
                    "sent": "It is not generalizing to new queries, OK?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we haven't generated this.",
                    "label": 0
                },
                {
                    "sent": "Motivated the generalization study.",
                    "label": 0
                },
                {
                    "sent": "Are we just somehow overfitting?",
                    "label": 1
                },
                {
                    "sent": "Is soft and ECG more prone to?",
                    "label": 0
                },
                {
                    "sent": "Overfitting than the other metrics objectives.",
                    "label": 0
                },
                {
                    "sent": "Well, we were GBS about this.",
                    "label": 0
                },
                {
                    "sent": "'cause we do have an NDC G validation sets that we employed specifically to prevent overfitting so but just to test this a little bit more, we try to match.",
                    "label": 0
                },
                {
                    "sent": "We tried training in with a much simpler linear model so the result I showed you before was a model with 3000 parameters.",
                    "label": 0
                },
                {
                    "sent": "We tried a linear model with 300 parameters so these two results for the.",
                    "label": 1
                },
                {
                    "sent": "That's the nonlinear case, and these two sets of results for the linear case.",
                    "label": 0
                },
                {
                    "sent": "And here we see the gap with better on the.",
                    "label": 0
                },
                {
                    "sent": "This is for the training set.",
                    "label": 0
                },
                {
                    "sent": "We do better on the training set, worse on the test set and we still see the same effect with a much simpler model so.",
                    "label": 1
                },
                {
                    "sent": "Let us to conclude that is because we're still seeing the same effect with a radically different model.",
                    "label": 0
                },
                {
                    "sent": "There must be something.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's going on?",
                    "label": 0
                },
                {
                    "sent": "It's not simple overfitting, so let this lead us to consider.",
                    "label": 0
                },
                {
                    "sent": "The following hypothesis that SoftBank is focusing too much on the top ranks.",
                    "label": 1
                },
                {
                    "sent": "In fact, they may be useful.",
                    "label": 0
                },
                {
                    "sent": "For example, there may be useful information in the ordering at lower ranks that is effectively ignored by soft rank.",
                    "label": 1
                },
                {
                    "sent": "So to test this, we tried a range of different discounts.",
                    "label": 0
                },
                {
                    "sent": "This is the one misshape.",
                    "label": 0
                },
                {
                    "sent": "Here is the one that's used in the TCG.",
                    "label": 0
                },
                {
                    "sent": "They regular any CG on the evaluation or the test sets.",
                    "label": 0
                },
                {
                    "sent": "We tried a range of different discount functions.",
                    "label": 0
                },
                {
                    "sent": "This range is the performance on the test set is shown here and this horizontal line is our Lambda rank baseline and the rank performs better than all the other approaches on this set.",
                    "label": 0
                },
                {
                    "sent": "So we observe that we can regain the performance of Lander rank if we use a much shallower discount function.",
                    "label": 0
                },
                {
                    "sent": "So this for us is that that is indeed the case that focusing too much on the top of the ranking.",
                    "label": 0
                },
                {
                    "sent": "Actually hurts you when when you come to looking at the holdouts.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So queries OK, so to conclude.",
                    "label": 0
                },
                {
                    "sent": "We've shown that soft rank with this rank, binomial assumptions optimizes NDC NDC G very well.",
                    "label": 0
                },
                {
                    "sent": "One thing we can do in the future is to use the rank binomial distributions and those ideas to optimize other metrics.",
                    "label": 0
                },
                {
                    "sent": "This often.",
                    "label": 0
                },
                {
                    "sent": "DCG does not generalize well.",
                    "label": 1
                },
                {
                    "sent": "It seems to focus too much on the top ranks in training and effects.",
                    "label": 1
                },
                {
                    "sent": "It's an inefficient use of training data, in fact, so we let let us to realize really that's too close to ND DCG in some sense, so we can recover the Lambda rank performance with less severe discount function.",
                    "label": 0
                },
                {
                    "sent": "That's it, thanks.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "In the pairwise context, the approximation where you have assumed Gaussian distribution on the scores, you decide the mean by the neural networks, but I'm not sure how you choose the variance there the the variance.",
                    "label": 0
                },
                {
                    "sent": "So the question is, it's clear how you set the mean of the Gaussian store score distributions I from the output of the neural net, how do you set the variances?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There's a section in the paper which I didn't have time to talk about today, which which shows how when the there's a degree of freedom in the parameters which basically affects this the score, the magnitude of this course.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you multiplied all the scores by some common factor, you would you would not change the.",
                    "label": 0
                },
                {
                    "sent": "It's impossible to change the ranking that way, right?",
                    "label": 0
                },
                {
                    "sent": "The scores will just grow in the sit by the same amount, but their relative rankings would remain the same.",
                    "label": 0
                },
                {
                    "sent": "So our model is free to vary the weights.",
                    "label": 0
                },
                {
                    "sent": "To in in that dimension, if you like in that degree of freedom but so and multiple stretching out the score.",
                    "label": 0
                },
                {
                    "sent": "The score access like that is the same thing as reducing the variance.",
                    "label": 0
                },
                {
                    "sent": "So in fact what happening is that as it's learning the weight vector is constantly adjusting the variance through that mechanism.",
                    "label": 0
                },
                {
                    "sent": "Is that clear?",
                    "label": 0
                },
                {
                    "sent": "So we don't.",
                    "label": 0
                },
                {
                    "sent": "We still quite sensitive to how you set the initial value of the variance at the beginning of learning, but once you set it off and it's an indispensable value, this mechanism comes into play.",
                    "label": 0
                },
                {
                    "sent": "So it's actually trying to control the scale of the score, which has the effect of controlling the variance.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}