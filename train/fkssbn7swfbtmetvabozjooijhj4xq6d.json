{
    "id": "fkssbn7swfbtmetvabozjooijhj4xq6d",
    "title": "The More the Merrier: Analysing the Affect of a Group of People in Images",
    "info": {
        "author": [
            "Roland Goecke, Faculty of Education, Science, Technology and Mathematics (ESTEM), University of Canberra"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_goecke_people_images/",
    "segmentation": [
        [
            "Alright, well thank you very much harder to follow Ursula, but I tried to do my best so this is actually work by abinash somewhere she couldn't be here today.",
            "It's all to joint work with Jordy Cohen and Nico.",
            "So we're basically interested in here and you might have seen the poster that we had yesterday and there will be another talk in the late morning sessions here on moving away from just looking at images or videos with single people onto sort of group.",
            "Analysis still image."
        ],
        [
            "Test.",
            "So since we're dealing with the images here, let's pose the problem as a expression analysis problem.",
            "If we look at existing methods around ensuring the expression from a from an image from a video, then we can basically categorize them.",
            "For example on the basis of whether they're posed or spontaneous expressions when they are discrete or bill, is it user continuous space in terms of the labeling, whether they are from a lab controlled or controlled conditions, or more in the wild, so unconstrained conditions."
        ],
        [
            "But if we now think about the large number of images that are basically posted, another just sort of figure a couple of weeks ago in a BBC News shows.",
            "Apparently there's 1.8 billion.",
            "Photos, images uploaded onto social media every single day and many of those are actually from social events.",
            "You know, from a wedding from a birthday from a graduation party, some kind of social event, basically.",
            "If we look at that, then there's basically another attribute that we can use as a for categorizing these classes, and that's between single subjects and a group of people.",
            "OK, so this is about inferring work towards infirm.",
            "The effect of a group of people."
        ],
        [
            "Some of the prior work, so it's a Nokia my son.",
            "Back in 2012.",
            "Some very interesting work on the slowness, the MIT Mood media so where there were four cameras and storage the MIT campus and the task was busy to infer the mood of people as they are passing by.",
            "And it's largely based on the averaging of the small intensities visible."
        ],
        [
            "Some of our own work, so I've been off work in 2012.",
            "In 2015 was basically starting from just looking at positive emotion.",
            "So what we call the group happiness intensity analysis and using a topic modeling approach, we basically combined both data driven attributes and many attributes necessary.",
            "It was purely just on the positive emotion and so OK, so I'm not going to go into details on that because you know, there's in the late morning we have another.",
            "Presentation on that one."
        ],
        [
            "Alright, so then, let's look at.",
            "So if you know the more general theory behind group effect, we can basically.",
            "So this goes back about 15 years when number of papers came out that suggested to break this down into a top down component.",
            "So the overall emotion of a group of is basically constructed by the uniqueness of individual members emotional expressions, and then as a bottom up component where the emotion is emerging at the group level.",
            "And then followed by individual participants of the group.",
            "In our tech paper earlier this year, we basically included a survey where we asked 149 subjects too.",
            "Look at various images of groups of people and to tell us what we are.",
            "Basically some of the factors in there that they took into consideration in terms of working out how happy they perceived their group to be.",
            "And there were a number of global factors around some of the scene that close.",
            "You know how close they were to each other and so on, but then also the local attributes around the individual facial expressions.",
            "The intensity of those, the matter of faces being included, the age, the gender and so on."
        ],
        [
            "So if we look at match and.",
            "It's a bit hard to see maybe, but so far we can see here that there's a number of fairly strong attributes.",
            "The longer the bar, the stronger those factors were, such as the first one.",
            "Here is the being a large number of people smiling in images.",
            "Or if roughly halfway down and overall this is over pleasant scene.",
            "As a nice background is nothing.",
            "That suggests that this is not a pleasant experience.",
            "Also we have if basically faces were not included.",
            "You know that that makes sense, and if you can't really see the face then your perception of the mood of the group is somewhat limited.",
            "But we also have another sort of other factors in there, such as.",
            "How closely were the faces together where they rush, centered and so on, whereas factors such as age for example or the gender didn't really play as strong a role."
        ],
        [
            "Alright, so when you then so wanted to analyze it a bit further and not just being limited to solve the question of positive affect there, But basically look at least as a three class problem of positive, neutral and negative classes and we have basically created a what we call the group effect database where we used images like actually keywords to search image databases such as Flickr, Google Images and also our own.",
            "Happy database.",
            "And then had three human annotators in Dependently label these and only if they agreed that we include those into the database and you can see these images, you know come from parties from work functions from protest rallies from funerals and so on.",
            "So lots of different groups situations in there."
        ],
        [
            "Alright, so then how do we go about analyzing this note?",
            "So we start with a image containing a group of people.",
            "We perform face alignment and then look at what we call high level features and specifically actually action units.",
            "I'm going to give you the details in a moment."
        ],
        [
            "We then also look at low level features because in the past for single person images they've been shown to be quite successful.",
            "And we also use some scene descriptors from the computer vision word that I used to try and grab basically the information that's important in terms of describing the scene.",
            "Alright, and then we use those and put them together."
        ],
        [
            "Alright, so let's look at the face analysis part.",
            "So the bottom up component for the face detection we use the mixture of pictorial structure framework for June Roman and we use this search tool box for facial action unit detection and then model of this as a bag of words content, where each phase in a group is considered a word and the group of people is considered document classic bag of word.",
            "Make it forwards framework.",
            "And we label this as the bag of words.",
            "AU for the action units.",
            "This."
        ],
        [
            "And then based on the survey, there's various attributes without OK.",
            "In the past there's been plenty of research that showed using low level features to be quite successful to actually describe those kind of attributes.",
            "So let's use the fork and APG local phase quantization features again and put that into a similar bag of word framework and we do not denote match with.",
            "And As for low level features?"
        ],
        [
            "Then for the scene analysis, so the top down component and the computer vision world there's two.",
            "Types of descriptors that are widely used, known as the gist descriptor and the centrist descriptor, and they basically compute statistics at the global levels of the entire image level.",
            "OK, which means they take into consideration not only the scene background, but also information about clothes.",
            "Or again might be helpful in terms of determining what's going on in the scene."
        ],
        [
            "Alright, so then, in terms of, you know we bring all these together and perform Fusion between the scene and the face features.",
            "And in particular, with guided by emotion bars, scene context model, which basically puts a low level, also low resolution holistic representation.",
            "So that's our signature.",
            "The scene descriptor as well as a detailed object level representation together, which is the phase analysis part.",
            "And we were comparing here a feature Fusion approach as well as a multiple kernel learning approach because they've been.",
            "Looking quite well in the past.",
            "So if we take our action unit back of words, we take our low level feature bag of words and either one of the.",
            "Seen descript us in there."
        ],
        [
            "So working on this experiment all on this group affect database OK.",
            "So and what's showing here, first of all, is a feature wise comparison.",
            "So just basically each feature on its own.",
            "How well would it work alright?",
            "And."
        ],
        [
            "One of the things we see that the high level features so the bag of words AU.",
            "Perform similarly well to the low level features overall.",
            "In the broad sense, if you just look at the final score at the end there, but there are differences between the individual classes."
        ],
        [
            "So the negative.",
            "Classes here, particularly for the low level, features dramatically.",
            "Underperforming and then of course."
        ],
        [
            "The question is, why is that the case?",
            "Here's what we think you know.",
            "We don't have conclusive proof of that, but necessary on a further analysis.",
            "What seems to be going on is the negative effect images of the images that were then labeled by human annotators as having a negative effect in the group there.",
            "Came from certain keywords such as violence such as protests and so on, so they actually picking up a lot of group images from let's say some kind of protest rallies and so on where you have a lot of faces that are actually non frontal.",
            "A lot of occlusion happening and so on.",
            "Well, that's then led to that.",
            "You basically the.",
            "Face detection work with the action approach was still able to find a sufficient number of these phases, but the low level approach was not really working well in that.",
            "To actually pick up the facial expressions and take that into consideration."
        ],
        [
            "Another point here is also that the scene descriptors themselves are actually doing.",
            "Quite well, you're not going to get as much information that is purely based on the scene descriptors, but there is complementary information in there."
        ],
        [
            "Not."
        ],
        [
            "Now let's look at some other Fusion experiments.",
            "OK, so first."
        ],
        [
            "All the feature Fusion approaches, so apologize for the you know the 2nd row should have been at the top, so just taking both of the back of words together basically and then combining them each individually with the scene descriptor.",
            "The gist of this interest one.",
            "And performance in our overall across all things of the average across all of the class."
        ],
        [
            "This is roughly similar OK, but again we have some interesting differences there between positive, neutral and negative classes."
        ],
        [
            "If we now look at the NCO so the multiple kernel learning approach here, then we can see that that gives a significant boost in terms of performance.",
            "Here again, accuracy is measured against the human labeling their classes.",
            "And that's actually pretty much a boost right across all of the classes, so it's not just specific to one class, but right across all three classes in there.",
            "So that goes to show that including that sort of.",
            "Information about the seniors as quite helpful actually in there."
        ],
        [
            "Best if we look at the three classes in particular again.",
            "So the negative side is still overall lower for regardless of which approach you use.",
            "OK, so again, that may well be due to the types of images that we have in the database at this point of time.",
            "So that's a bit of a caveat.",
            "Now that's something we need to look into further."
        ],
        [
            "Alright, so in conclusion then, so we've basically in this paper put together a new framework for inferring the affect of a group of people.",
            "They say GNU labeled database in there that currently contains 800 images, but we're working on the extending that further.",
            "We put together both the based on number theory of the top down as well as bottom up components, so both are seen descriptors as well as the face analysis descriptors in there and the work widgets suggested that the MKL based Fusion framework is quite a useful one.",
            "So extensions in terms of going from inches to videos.",
            "Also looking at just images again gives you know temporal information we want to add body post information there from other work that we've been doing.",
            "We know that body pose has quite a big element to playing this as well and then actually adding the intensities.",
            "In terms of expressions in there as well.",
            "So to kind of emulate a valence arousal labeling, because at the moment we are basically just looking at kind of alien side of things.",
            "And I think."
        ],
        [
            "I'll stop now, so any questions I'd be happy to take but also use this opportunity to have a little ad here for our workshop and challenge coming up and we're hiring a few positions as well.",
            "So if you're interested let me know."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, well thank you very much harder to follow Ursula, but I tried to do my best so this is actually work by abinash somewhere she couldn't be here today.",
                    "label": 0
                },
                {
                    "sent": "It's all to joint work with Jordy Cohen and Nico.",
                    "label": 0
                },
                {
                    "sent": "So we're basically interested in here and you might have seen the poster that we had yesterday and there will be another talk in the late morning sessions here on moving away from just looking at images or videos with single people onto sort of group.",
                    "label": 0
                },
                {
                    "sent": "Analysis still image.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Test.",
                    "label": 0
                },
                {
                    "sent": "So since we're dealing with the images here, let's pose the problem as a expression analysis problem.",
                    "label": 1
                },
                {
                    "sent": "If we look at existing methods around ensuring the expression from a from an image from a video, then we can basically categorize them.",
                    "label": 0
                },
                {
                    "sent": "For example on the basis of whether they're posed or spontaneous expressions when they are discrete or bill, is it user continuous space in terms of the labeling, whether they are from a lab controlled or controlled conditions, or more in the wild, so unconstrained conditions.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But if we now think about the large number of images that are basically posted, another just sort of figure a couple of weeks ago in a BBC News shows.",
                    "label": 1
                },
                {
                    "sent": "Apparently there's 1.8 billion.",
                    "label": 1
                },
                {
                    "sent": "Photos, images uploaded onto social media every single day and many of those are actually from social events.",
                    "label": 0
                },
                {
                    "sent": "You know, from a wedding from a birthday from a graduation party, some kind of social event, basically.",
                    "label": 1
                },
                {
                    "sent": "If we look at that, then there's basically another attribute that we can use as a for categorizing these classes, and that's between single subjects and a group of people.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is about inferring work towards infirm.",
                    "label": 0
                },
                {
                    "sent": "The effect of a group of people.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of the prior work, so it's a Nokia my son.",
                    "label": 0
                },
                {
                    "sent": "Back in 2012.",
                    "label": 0
                },
                {
                    "sent": "Some very interesting work on the slowness, the MIT Mood media so where there were four cameras and storage the MIT campus and the task was busy to infer the mood of people as they are passing by.",
                    "label": 0
                },
                {
                    "sent": "And it's largely based on the averaging of the small intensities visible.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some of our own work, so I've been off work in 2012.",
                    "label": 0
                },
                {
                    "sent": "In 2015 was basically starting from just looking at positive emotion.",
                    "label": 0
                },
                {
                    "sent": "So what we call the group happiness intensity analysis and using a topic modeling approach, we basically combined both data driven attributes and many attributes necessary.",
                    "label": 1
                },
                {
                    "sent": "It was purely just on the positive emotion and so OK, so I'm not going to go into details on that because you know, there's in the late morning we have another.",
                    "label": 1
                },
                {
                    "sent": "Presentation on that one.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so then, let's look at.",
                    "label": 0
                },
                {
                    "sent": "So if you know the more general theory behind group effect, we can basically.",
                    "label": 0
                },
                {
                    "sent": "So this goes back about 15 years when number of papers came out that suggested to break this down into a top down component.",
                    "label": 0
                },
                {
                    "sent": "So the overall emotion of a group of is basically constructed by the uniqueness of individual members emotional expressions, and then as a bottom up component where the emotion is emerging at the group level.",
                    "label": 1
                },
                {
                    "sent": "And then followed by individual participants of the group.",
                    "label": 0
                },
                {
                    "sent": "In our tech paper earlier this year, we basically included a survey where we asked 149 subjects too.",
                    "label": 0
                },
                {
                    "sent": "Look at various images of groups of people and to tell us what we are.",
                    "label": 0
                },
                {
                    "sent": "Basically some of the factors in there that they took into consideration in terms of working out how happy they perceived their group to be.",
                    "label": 0
                },
                {
                    "sent": "And there were a number of global factors around some of the scene that close.",
                    "label": 0
                },
                {
                    "sent": "You know how close they were to each other and so on, but then also the local attributes around the individual facial expressions.",
                    "label": 0
                },
                {
                    "sent": "The intensity of those, the matter of faces being included, the age, the gender and so on.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we look at match and.",
                    "label": 0
                },
                {
                    "sent": "It's a bit hard to see maybe, but so far we can see here that there's a number of fairly strong attributes.",
                    "label": 0
                },
                {
                    "sent": "The longer the bar, the stronger those factors were, such as the first one.",
                    "label": 0
                },
                {
                    "sent": "Here is the being a large number of people smiling in images.",
                    "label": 0
                },
                {
                    "sent": "Or if roughly halfway down and overall this is over pleasant scene.",
                    "label": 0
                },
                {
                    "sent": "As a nice background is nothing.",
                    "label": 0
                },
                {
                    "sent": "That suggests that this is not a pleasant experience.",
                    "label": 0
                },
                {
                    "sent": "Also we have if basically faces were not included.",
                    "label": 0
                },
                {
                    "sent": "You know that that makes sense, and if you can't really see the face then your perception of the mood of the group is somewhat limited.",
                    "label": 0
                },
                {
                    "sent": "But we also have another sort of other factors in there, such as.",
                    "label": 0
                },
                {
                    "sent": "How closely were the faces together where they rush, centered and so on, whereas factors such as age for example or the gender didn't really play as strong a role.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so when you then so wanted to analyze it a bit further and not just being limited to solve the question of positive affect there, But basically look at least as a three class problem of positive, neutral and negative classes and we have basically created a what we call the group effect database where we used images like actually keywords to search image databases such as Flickr, Google Images and also our own.",
                    "label": 1
                },
                {
                    "sent": "Happy database.",
                    "label": 0
                },
                {
                    "sent": "And then had three human annotators in Dependently label these and only if they agreed that we include those into the database and you can see these images, you know come from parties from work functions from protest rallies from funerals and so on.",
                    "label": 0
                },
                {
                    "sent": "So lots of different groups situations in there.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so then how do we go about analyzing this note?",
                    "label": 0
                },
                {
                    "sent": "So we start with a image containing a group of people.",
                    "label": 0
                },
                {
                    "sent": "We perform face alignment and then look at what we call high level features and specifically actually action units.",
                    "label": 0
                },
                {
                    "sent": "I'm going to give you the details in a moment.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then also look at low level features because in the past for single person images they've been shown to be quite successful.",
                    "label": 0
                },
                {
                    "sent": "And we also use some scene descriptors from the computer vision word that I used to try and grab basically the information that's important in terms of describing the scene.",
                    "label": 0
                },
                {
                    "sent": "Alright, and then we use those and put them together.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so let's look at the face analysis part.",
                    "label": 0
                },
                {
                    "sent": "So the bottom up component for the face detection we use the mixture of pictorial structure framework for June Roman and we use this search tool box for facial action unit detection and then model of this as a bag of words content, where each phase in a group is considered a word and the group of people is considered document classic bag of word.",
                    "label": 1
                },
                {
                    "sent": "Make it forwards framework.",
                    "label": 0
                },
                {
                    "sent": "And we label this as the bag of words.",
                    "label": 0
                },
                {
                    "sent": "AU for the action units.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then based on the survey, there's various attributes without OK.",
                    "label": 1
                },
                {
                    "sent": "In the past there's been plenty of research that showed using low level features to be quite successful to actually describe those kind of attributes.",
                    "label": 1
                },
                {
                    "sent": "So let's use the fork and APG local phase quantization features again and put that into a similar bag of word framework and we do not denote match with.",
                    "label": 0
                },
                {
                    "sent": "And As for low level features?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then for the scene analysis, so the top down component and the computer vision world there's two.",
                    "label": 0
                },
                {
                    "sent": "Types of descriptors that are widely used, known as the gist descriptor and the centrist descriptor, and they basically compute statistics at the global levels of the entire image level.",
                    "label": 1
                },
                {
                    "sent": "OK, which means they take into consideration not only the scene background, but also information about clothes.",
                    "label": 1
                },
                {
                    "sent": "Or again might be helpful in terms of determining what's going on in the scene.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so then, in terms of, you know we bring all these together and perform Fusion between the scene and the face features.",
                    "label": 1
                },
                {
                    "sent": "And in particular, with guided by emotion bars, scene context model, which basically puts a low level, also low resolution holistic representation.",
                    "label": 0
                },
                {
                    "sent": "So that's our signature.",
                    "label": 0
                },
                {
                    "sent": "The scene descriptor as well as a detailed object level representation together, which is the phase analysis part.",
                    "label": 1
                },
                {
                    "sent": "And we were comparing here a feature Fusion approach as well as a multiple kernel learning approach because they've been.",
                    "label": 0
                },
                {
                    "sent": "Looking quite well in the past.",
                    "label": 0
                },
                {
                    "sent": "So if we take our action unit back of words, we take our low level feature bag of words and either one of the.",
                    "label": 0
                },
                {
                    "sent": "Seen descript us in there.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So working on this experiment all on this group affect database OK.",
                    "label": 0
                },
                {
                    "sent": "So and what's showing here, first of all, is a feature wise comparison.",
                    "label": 0
                },
                {
                    "sent": "So just basically each feature on its own.",
                    "label": 0
                },
                {
                    "sent": "How well would it work alright?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One of the things we see that the high level features so the bag of words AU.",
                    "label": 0
                },
                {
                    "sent": "Perform similarly well to the low level features overall.",
                    "label": 1
                },
                {
                    "sent": "In the broad sense, if you just look at the final score at the end there, but there are differences between the individual classes.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the negative.",
                    "label": 0
                },
                {
                    "sent": "Classes here, particularly for the low level, features dramatically.",
                    "label": 0
                },
                {
                    "sent": "Underperforming and then of course.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The question is, why is that the case?",
                    "label": 0
                },
                {
                    "sent": "Here's what we think you know.",
                    "label": 0
                },
                {
                    "sent": "We don't have conclusive proof of that, but necessary on a further analysis.",
                    "label": 0
                },
                {
                    "sent": "What seems to be going on is the negative effect images of the images that were then labeled by human annotators as having a negative effect in the group there.",
                    "label": 1
                },
                {
                    "sent": "Came from certain keywords such as violence such as protests and so on, so they actually picking up a lot of group images from let's say some kind of protest rallies and so on where you have a lot of faces that are actually non frontal.",
                    "label": 0
                },
                {
                    "sent": "A lot of occlusion happening and so on.",
                    "label": 0
                },
                {
                    "sent": "Well, that's then led to that.",
                    "label": 1
                },
                {
                    "sent": "You basically the.",
                    "label": 0
                },
                {
                    "sent": "Face detection work with the action approach was still able to find a sufficient number of these phases, but the low level approach was not really working well in that.",
                    "label": 0
                },
                {
                    "sent": "To actually pick up the facial expressions and take that into consideration.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another point here is also that the scene descriptors themselves are actually doing.",
                    "label": 0
                },
                {
                    "sent": "Quite well, you're not going to get as much information that is purely based on the scene descriptors, but there is complementary information in there.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's look at some other Fusion experiments.",
                    "label": 0
                },
                {
                    "sent": "OK, so first.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the feature Fusion approaches, so apologize for the you know the 2nd row should have been at the top, so just taking both of the back of words together basically and then combining them each individually with the scene descriptor.",
                    "label": 0
                },
                {
                    "sent": "The gist of this interest one.",
                    "label": 0
                },
                {
                    "sent": "And performance in our overall across all things of the average across all of the class.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is roughly similar OK, but again we have some interesting differences there between positive, neutral and negative classes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we now look at the NCO so the multiple kernel learning approach here, then we can see that that gives a significant boost in terms of performance.",
                    "label": 0
                },
                {
                    "sent": "Here again, accuracy is measured against the human labeling their classes.",
                    "label": 0
                },
                {
                    "sent": "And that's actually pretty much a boost right across all of the classes, so it's not just specific to one class, but right across all three classes in there.",
                    "label": 0
                },
                {
                    "sent": "So that goes to show that including that sort of.",
                    "label": 0
                },
                {
                    "sent": "Information about the seniors as quite helpful actually in there.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best if we look at the three classes in particular again.",
                    "label": 0
                },
                {
                    "sent": "So the negative side is still overall lower for regardless of which approach you use.",
                    "label": 0
                },
                {
                    "sent": "OK, so again, that may well be due to the types of images that we have in the database at this point of time.",
                    "label": 0
                },
                {
                    "sent": "So that's a bit of a caveat.",
                    "label": 0
                },
                {
                    "sent": "Now that's something we need to look into further.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so in conclusion then, so we've basically in this paper put together a new framework for inferring the affect of a group of people.",
                    "label": 1
                },
                {
                    "sent": "They say GNU labeled database in there that currently contains 800 images, but we're working on the extending that further.",
                    "label": 0
                },
                {
                    "sent": "We put together both the based on number theory of the top down as well as bottom up components, so both are seen descriptors as well as the face analysis descriptors in there and the work widgets suggested that the MKL based Fusion framework is quite a useful one.",
                    "label": 0
                },
                {
                    "sent": "So extensions in terms of going from inches to videos.",
                    "label": 0
                },
                {
                    "sent": "Also looking at just images again gives you know temporal information we want to add body post information there from other work that we've been doing.",
                    "label": 0
                },
                {
                    "sent": "We know that body pose has quite a big element to playing this as well and then actually adding the intensities.",
                    "label": 0
                },
                {
                    "sent": "In terms of expressions in there as well.",
                    "label": 0
                },
                {
                    "sent": "So to kind of emulate a valence arousal labeling, because at the moment we are basically just looking at kind of alien side of things.",
                    "label": 0
                },
                {
                    "sent": "And I think.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll stop now, so any questions I'd be happy to take but also use this opportunity to have a little ad here for our workshop and challenge coming up and we're hiring a few positions as well.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested let me know.",
                    "label": 0
                }
            ]
        }
    }
}