{
    "id": "tcbbk4ybzuidjikixiicv5clhjizndcq",
    "title": "Predicting Abnormal Returns From News Using Text Classification",
    "info": {
        "author": [
            "Ronny Luss, Department of Operations Research and Financial Engineering, Princeton University"
        ],
        "published": "Aug. 21, 2009",
        "recorded": "July 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Computational Finance"
        ]
    },
    "url": "http://videolectures.net/amlcf09_luss_parf/",
    "segmentation": [
        [
            "I'm running this is joint work with Alex DEP.",
            "Ramone and I'll mention that in a month that won't actually be at Princeton anymore.",
            "I'm going to be writing.",
            "I'll be up starting a postdoc at Tel Aviv University, but Alex will still be at Princeton.",
            "And we did this with a lot of help from great research systems from 2 undergrads that just finished the Princeton.",
            "I want to mention Jonathan Lange and Kevin Pham.",
            "So.",
            "I'm gonna jump in."
        ],
        [
            "Right into the problem, the title is exactly what we're doing, so we call this market classification problem, so we have press releases coming in.",
            "So for example, Microsoft issues a press release Wednesday at 10:30 AM.",
            "Here is a press release, and our goal is to read that press release and make a bet.",
            "If Microsoft's price is going to have a jump or not in an hour, let's say 11:30 AM, so at 10:30 AM, I make the bet on what the price is going to be at 11:30 AM, but not on what?",
            "The sorry, not what the price is going to be.",
            "But whether or not the absolute return in that hour is going to be greater than or equal to some threshold row, which I'll define later.",
            "So it's a 10:30 AM.",
            "We have article an we have two types of information that we can use.",
            "One is the text that came and the way we look at text is a bag of words.",
            "We make a Dictionary of words, count up how many times they occur, and that's future vector.",
            "Also the article came out at 10:30.",
            "The market opened at 9:30.",
            "We have an hour of the prices of Microsoft so we can make some kind of historical time series and use that vector.",
            "So in this talk I'm going to be discussing first how I can either input into a model, this bag of words vector, and try and make this prediction, which that's a classic text classification problem where you have text and you make your plus or minus one according to some criteria and either that or we're going to just input the time series of returns into the model and try and make the prediction.",
            "So that's going to be the first part of the results I'll show, and then the interesting thing is trying to combine text Ann returns into one model.",
            "In order to hopefully increase your performance, and since I'm coming from an operations research Department, I'm also going to touch on some algorithms on how that's done.",
            "So first there's a few things to discuss before I can show you any of the results.",
            "First of all, the experiment."
        ],
        [
            "So set up.",
            "We want to make this as realistic as possible, so the way we set it up is with chronological moving window.",
            "So for example, will read a month of all the news that came out in month one and then test on all the news that comes out in month to train a month to test a month three and so forth.",
            "So everything's out of sample tested and then at the end will aggregate all the test results.",
            "So far results we're going to train on a year of news and tests on the following month of news.",
            "Of course these windows can be.",
            "Experimented with, yeah, yeah.",
            "Literally 9:30 remember is just the last hour from that ending story comes from.",
            "You know from so I'm going to pick a horizon, so that was just an example, but I'm going to pick her eyes and I'm going to try and predict is does the abnormal.",
            "Does the absolute return jump above a threshold in 10 minutes or 20 minutes?",
            "I'm going to pick a horizon for that.",
            "Yes, yes.",
            "Yeah, from whenever it came out.",
            "Whenever the article comes out, I'm going to look 10 minutes later trying to predict what happens 10 minutes later.",
            "Sorry.",
            "No, my input is exactly when it comes.",
            "The press release comes out.",
            "What about your pricing?",
            "You said you have five.",
            "I have prices that were prior to it coming out.",
            "So yeah, I'm reading the that's the last.",
            "Yeah, yes, only information, only information before the article, sorry.",
            "And now optimize or no, this is something that is completely up to experimentation.",
            "There's a market.",
            "There's a lot of things with this that are very much.",
            "I'll to experimentation, and that's one of the things that we really enjoyed about.",
            "This was how much more research it can bring out.",
            "So a few words about the data."
        ],
        [
            "We got a press release database from PR Newswire, which releases news releases for many companies.",
            "Eight years of data from 2000 through 2007, and we only consider news published during the Business day.",
            "'cause that's when we have prices so specific.",
            "We're going to be mostly concentrating on intraday predictions.",
            "And all the price data is taken from Wharton Research Data Services and these two graphs here show how much data we actually have.",
            "So on the right it shows the average training and testing per window.",
            "So the blue curve is how much training data you have per year.",
            "The red curve is per month.",
            "Now the X axis.",
            "I just want to explain here 'cause you're going to see this for all of the performance graphs I show.",
            "So if you can't, you probably can't see from the back, but it goes in 10 minute increments from zero to 250 minutes.",
            "So rather than predict what happens just in one hour, I'm going to make a prediction.",
            "What happens in 10 minutes, 20 minutes every 10 minute interval until 250 minutes, and these are all independent experiments.",
            "I'm going to look at what happened at those increments and see how it what happens over the horizon.",
            "How do you choose your 128?",
            "120 companies this what I mean by based on quantity of releases, because for each company that came out we have to do effort to get prices and the companies that had the most press releases.",
            "So we took a threshold no for the whole over the whole thing.",
            "For choosing how many which companies to use, yes, I just looked at how many press release do I have in my database for that, yes.",
            "So there must have been something.",
            "So what we should buy us?",
            "I'm sorry.",
            "Ownership bias to that degree, yes.",
            "And we're only companies that.",
            "That did not survive during that time that suddenly died out.",
            "Yeah, we did eliminate those."
        ],
        [
            "'cause it made the data messy.",
            "So this is text classification problems, so a little survey on this.",
            "The first thing up there is a survey on the last decade of different systems that have come out that mentions three different of basic ways that have been used.",
            "Naive Bayes methods, decision rules and support vector machines.",
            "And what I'm doing is closest to this last one by Mittermeier know Meyer and so they're looking 15 minutes into the future.",
            "We looked at a bunch of horizons were doing binary classification versus their multi classification.",
            "And very recently, actually just this spring coconut oil they're using support vector regression to forecast stock returns on 10K reports and see what happens.",
            "That's the most recent thing I've seen."
        ],
        [
            "The tool that we're going to be using for the classification is support vector machines, which I'm going to assume most people here are familiar with.",
            "If not for nonlinear classification, you would map using some projection your data from non linear space to another space where you can do linear classification and to choose the mapping.",
            "In essence, what is actually done, you choose a kernel function which is coming from literature.",
            "Which is actually in putting a matrix defines here.",
            "Kij is the inner product in your feature space up there.",
            "But I'm not going to get much into that.",
            "Hopefully everyone is familiar."
        ],
        [
            "OK, the last thing before I show the results is.",
            "What how are we going to valuate the performance so for intraday predictions and predicting these abnormal returns and to actually trade on these, we would want to use option data.",
            "But for intraday predictions we don't have options data because it's very expensive.",
            "So for now what we're doing is what we want to focus on.",
            "Is Sharpe ratio of this game.",
            "Of course we can use other you could focus on other measures as well.",
            "For here the game we're playing is every time a press release comes out.",
            "I'm going to make a bet on that on that press release, whether an abnormal return occurs or not.",
            "If I'm correct, I get a dollar.",
            "If I'm wrong, I lose a dollar.",
            "And of course there's biases towards the two different directions, but we're not taking that into account here.",
            "Other measures you could look at, for example, would be the classical accuracy.",
            "The reason we don't focus on accuracy is because there's no financial intuition we get for this application.",
            "For Sharpe ratio, we have an intuition on what this means for us.",
            "But I will be showing results for both of them, but everything I did for tuning parameters cross validation was done with Sharpe ratio.",
            "And last them what I mean by an abnormal return.",
            "This is another thing that you have to define.",
            "So the way we do it is by taking the historical data.",
            "So our one year of data before the month we're testing on is the historical data.",
            "I look at all the absolute returns that occur, sort them and I take for instance the 75th percentile is my threshold, so everything above that is an abnormal return.",
            "Everything below is not in this threshold is something you can play with an.",
            "You'll see different results and I'll show you.",
            "But for example, you can reference our paper.",
            "To see what happens when you move it from 75%.",
            "Sorry, you mentioned briefly that you're using intraday options data.",
            "No, we don't have intraday options data and that's why we're doing this.",
            "I will show you results at right after this using daily predictions where we do have options data to give more promise for doing this."
        ],
        [
            "OK, so here are the results for either.",
            "Using returns on the left or text on the right.",
            "So the first thing I want to point accuracy on the top Sharpe ratio on the bottom and the first thing to point out all these red curves here 50% for accuracy, 0 for Sharpe ratio.",
            "For that we're trying to predict the direction of the stock movement plus one.",
            "If it went out minus one.",
            "If it went down and it's clear we have no predictability for that as we would have expected.",
            "But for things such as volatility or these abnormal returns, it is known that there is some predictability and that's what we see here.",
            "So for returns we can see how much we get.",
            "Um?",
            "The explain all the curves in the text plots, 'cause that's a bit confusing.",
            "So first of all, for the returns because we have.",
            "To use the returns before the press release comes out, so we needed to take 40 minutes worth of data before it comes out.",
            "So we have to throw out all the articles that come out in the first 40 minutes of the day.",
            "So this data set is slightly smaller, so it's compare that against this data set the diamonds.",
            "Red diamonds on this plot.",
            "So that's the same data sets on for those two, so you can see the text is doing better then returns with the 75% thresholding.",
            "Now for the text, if you just use text, you can use the entire everything that came out during the day.",
            "And if you do that, that's the solid blue lines here.",
            "And we see that's when you do best, so you can the predictability on those articles earlier in the day really does make a difference.",
            "And Furthermore, you can even break up so we train on all the articles that came out from 9:30 to 4:00 o'clock.",
            "But then, how well did I do on the 1st 40 minutes?",
            "That would be the lines with the Circle solid line with the circle which is here and at the top there.",
            "So that you compare against the diamonds in the in these plots and it says that training with those articles in the beginning day was very important for the text classification.",
            "Yes.",
            "For the market open and just like trading, when the market opens we don't have price data on them.",
            "You know, that's another thing you could do.",
            "You could be here.",
            "We don't, yes.",
            "Just wanted.",
            "Be a normal entrance fee in any way.",
            "Be normalized with the market.",
            "I'm sorry.",
            "I'm assuming.",
            "They haven't been normalized with the market now.",
            "We tried doing that.",
            "We didn't see any.",
            "It didn't make too much differences, but so we left it as this.",
            "How?",
            "I'm sorry the data, so this is up to how you threshold we so we do balance it.",
            "We're not taking it with SVM.",
            "There's a big problem of figuring how to take into account unbalanced data.",
            "For this we so if you do 75th percentile and you have 20% five percent above it, 75% of the data is blow it.",
            "So we randomly balance the data, which is another open problem that.",
            "Should be looked at if you take it down 50% you wouldn't.",
            "That doesn't really define a true abnormal return, but it balances your data, but that doesn't seek the goal we're looking for.",
            "Related question at the first half, we actually checked how much should you are playing the speed game.",
            "So if you got the news, of course there will be a reaction right off the contract, so you probably would have to put in a day if let's say half a minute or 10 seconds or whatever you are able to trade and analyze and then look at the return.",
            "We haven't know.",
            "So things like this and transaction costs we don't.",
            "Really only transaction costs.",
            "Also, whether it's feasible to do that right?",
            "Having news from a company, which I usually always already have a spike in volatility.",
            "Christy, it's usually your reaction also.",
            "Partly how big would be that predictability?",
            "So it's simply saying is use one average.",
            "Volatility or the junk by advance?",
            "Such a strategy.",
            "So I'm sorry.",
            "Just having the information that there is news would create a spike in motility.",
            "Have you accounted for at least so?",
            "There's a lot of features that you could put into this, and I'll things like what time of the day it occurs, what day of the week, the volume of news these are all things that you can, so we right now have text kernels.",
            "I've returns kernels.",
            "I can make a Colonel from the day of the week.",
            "I can make a return from a new kernel based on the volume.",
            "These are just additional features.",
            "One basic way would be just make one big feature vector of everything.",
            "But that's the most negative.",
            "Here.",
            "We're going to combine kernel different kernels for the different types of features.",
            "Those are other things we tried day of the week, and things like that volume.",
            "I don't think I actually put in yet.",
            "Yes.",
            "I mean, it's very interesting way of looking at things.",
            "Programs generally with this, is that generally before announcement to share faster moving is always a problem in the market.",
            "Why the share price?",
            "You have MA you always see the SharePoint moving before the announcement.",
            "So is it because the market is efficient or is that they people front running it?",
            "So what you will get here is delayed reaction.",
            "And I mean even if the results are not understanding it does not invalidate what the research is.",
            "But it could also be that.",
            "A lot of it is priced in.",
            "Very efficient model.",
            "The question of efficient markets, I afraid to touch a button.",
            "Yep.",
            "Into the problem, yeah.",
            "She would those be right if the market stays the same and you are predicting that it's actually going up with you.",
            "You can do this correct or wrong.",
            "If I predict going up well for upper down.",
            "Oh no, we're just doing this binary, so it's for example.",
            "Oh, if it stayed the same, I think.",
            "Yeah, I think we stated that it's going up or yeah.",
            "I if it was here but that didn't for the Minutes did it often occur.",
            "I have to look at it, but I for now we had it that it's only two classes, so if it stayed the same, we picked a direction and on average by just analyzing attacks too well, I mean 70% exactly saying I'm sorry.",
            "Can you repeat?",
            "By the prediction I in 70%.",
            "Yeah for this yes.",
            "I can't read it myself, but yeah.",
            "The Y axis goes up to 15.",
            "Oh yeah, so this is completely we have this fictitious strategy of I get a dollar lose a dollar every prediction, so this is not realistic.",
            "For this.",
            "It gives me an intuition, but the magnitudes know.",
            "Right now it's not a real strategy.",
            "Dollar at current prices right?",
            "No no.",
            "No, this is a strategy where yeah, no, no, no.",
            "Not at all.",
            "Let me show you another.",
            "Let me show you another thing.",
            "Sorry.",
            "That's why we called it a fictitious strategy."
        ],
        [
            "60 minutes."
        ],
        [
            "How many trades would you make a day today?",
            "Trades in a day at the 16 minute.",
            "So 60 means, oh, this is the 60 minute here means I'm going to predict if an abnormal return occurs in 60 minutes.",
            "Right, and so how many trades a day depends on how many articles.",
            "I'm sorry, yeah.",
            "Oh yeah, there's a new trade off, you're saying?",
            "I mean, right wherever.",
            "At a 60 minute time horizon, how?",
            "How many trades would you actually?",
            "How many bets would you make a day?",
            "As many articles came out, I would have to.",
            "Look at the data for that.",
            "But for the reason we want to look at Sharpe ratio here, it's fictitious, but that we're hoping is what gives you a trade off for if you otherwise for the top curves I just show accuracy.",
            "I would really want to cross validate between some tradeoff of accuracy and recall.",
            "Yep.",
            "This will move upwards more than Rd.",
            "I'm predicting whether the absolute price change moves above Ro, so it's but yeah, either way, yeah.",
            "Don't predict option in your model, correct?",
            "No we don't.",
            "So you.",
            "So how do you evaluate your model when your model predicted movement more than row and the stock was flat?",
            "How do you count that?",
            "For that's the example here.",
            "We said if it was flat then we say it's up.",
            "It's we don't sorry, 5% of ties your credit yourself with making a correct prediction.",
            "No, so we bout that's the unbalanced part, right?",
            "Then it was seven if we used to like that I could say OK, just bet bet all the time that in this direction and you'll win.",
            "So here we balance the data.",
            "So that it only goes above the threshold 50% of the time down.",
            "Rolling out I randomly yes discard the data.",
            "Didn't make it right.",
            "We randomly discarded that.",
            "There is so far we didn't see another way to go around this other than looking at support vector machines.",
            "How throwing playing with penalization parameters for two different classes or whatnot, other methods.",
            "You could just use the confidence in picture on the SPN itself and say if that if that real value right at the very end you're taking with threshold love is above or below a certain value.",
            "That I make a trade.",
            "Otherwise they don't shave it all.",
            "That you could take."
        ],
        [
            "So for daily predictions I'll go quickly, hopefully.",
            "Now we can use.",
            "We do have daily options data, so we tried this option strategy Delta hedged covered call options.",
            "So the way this works is if we do predict an abnormal return by one call option on that stock and sell Delta shares of the stock today.",
            "Tomorrow you exit the positions.",
            "So by selling Delta shares of stock.",
            "What this means is the ideas you want to position.",
            "That's only sensitive to movements in volatility of your stock and not with respect to the stock movements itself which measures direction.",
            "So it's called keeping your position Delta neutral.",
            "So in the actual data and the predictions we did hear the profit and loss for first on the left.",
            "Here if you want to predict an abnormal return, the profit and loss of these types of predictions looks like this, it's a.",
            "It's a very rough smile up, which is exactly what you would want.",
            "So if you're correct that it jumps a lot in either direction, you make profit.",
            "If you're wrong, it stays around zero.",
            "You lose very little.",
            "However.",
            "For predicting if no abnormal return.",
            "If you're correct and it stays around zero, you make only little, but the potential to lose.",
            "If it does move way is a lot.",
            "So trying this.",
            "I'm sorry.",
            "The shortest majority we could find 3 months or yeah."
        ],
        [
            "So here are three different strategies we did according to this.",
            "So trade all means every time an article comes out, I trade on whatever.",
            "I predict long only only predicts only makes a bet if we were predicting an abnormal return and short only predicts a few, don't predict an abnormal return.",
            "So here are the sharp rationes we have and the best one is from long only.",
            "And the reason for this is because of the shape of the P&L there, that the amount you have potential to get can be a lot the amount you can lose is limited.",
            "However for short only your potential for loss is much greater and so that potential is what hurts you in the trade.",
            "All strategies.",
            "So this long only strategy actually has a lot of problems, we think.",
            "Also have to do with the fact that there's no bad news.",
            "My first guess.",
            "Why your shorts are you just don't want to trade on them because texture looking there is.",
            "There's no bad news in the texture both alright?",
            "These are corporate press releases.",
            "Oh no, it's newswire, it's PR Newswire, so it's anything that they released.",
            "But you also said.",
            "Press releases yes.",
            "Is it good or bad?",
            "And why that is why?",
            "Trade short, you should discount at least.",
            "And.",
            "I don't have a good answer for that quite I'm haven't yes.",
            "Stop wrong, yes.",
            "It's not going to be very good.",
            "No, it doesn't, so that's another huge open question.",
            "The feature selection for the dictionary I created my own manual dictionary for this.",
            "I tried some automated techniques in the beginning that didn't work so well, but there's still potential.",
            "That's not to say that's dead.",
            "Impianti means wide open for which features to use.",
            "Also, looking at articles is combinations of topics.",
            "Instead they have all these and using the topics that make up an article is your features.",
            "That's.",
            "Sorry.",
            "Yeah, absolutely."
        ],
        [
            "How much time do I have?",
            "0.",
            "OK, so the methods for combining kernels.",
            "This is so everything I showed you right now is just how to use text and use returns separately in support vector machines.",
            "So this is how you can combine the two together.",
            "And this came from the kernel Learning Framework Framework from Langford at all 2004.",
            "And solve this optimization problem one minimizing legacy of K or Omega CFK is defined.",
            "That's just support vector Machine is a function of the kernel K. So the idea is to look for the kernel that gives you the best upper bound given by support vector machines, and for tractability it's very important to find the Kappa in the optimization problem and the way it's done here is by looking for a positive linear combination of the kernels.",
            "And this was termed the multiple kernel learning problem.",
            "So it was formulate."
        ],
        [
            "In many different ways to give you different optimization techniques for it and the most recent one was from rectum amanji adult 2008.",
            "And this looks at the exact same problem I just showed you.",
            "Instead of legacy you have JVD and they replace the variable K with D as a combination of your coefficients for your kernels.",
            "And the way they solve this this optimization problem is by saying we can calculate the gradient here where it has this form.",
            "The important thing to know Alphastar is the optimal solution to the SVM at the current iterative D. So every time you calculated gradient you have to calculate a support vector machine every time you compute the objective function is poor vector machine.",
            "So for gradient methods that they use, it can be quite expensive 'cause you're calculating many support vector machines online searches.",
            "So we looked at another method to solve this problem."
        ],
        [
            "And when you want to use larger kernels and it's called the analytics center cutting plane method.",
            "Been around for a long time and the method goes as such.",
            "Suppose you have a feasible region, the entire Polygon start with.",
            "You choose a center in the middle of the Polygon and you draw cut through that center using first order optimality condition at that point, so you can tell is the optimal point on this side or this side for your problem.",
            "So you cut out this side of the region, make a center in what's left, draw cut and you keep producing it until you're within some tolerance.",
            "The question OK, so every iteration you compute one gradient for that condition.",
            "And how do you define the center?",
            "It's called the analytic center."
        ],
        [
            "1.",
            "So mathematically, here's what the algorithm looks like.",
            "You compute the analytics center as such.",
            "For each hyperplane you draw a log arhythmic barrier that pushes you away from the hyperplane.",
            "You solve that optimization problem is the analytic center problem.",
            "Now when you have very few kernels, then that's the number of kernels of dimension of that analytic center problem.",
            "So then that problem is relatively easy if you have many, many kernels, then that problem becomes harder to solve than the gradient methods will do better.",
            "So each iteration analytic center problem compute the gradient in the condition and you keep iterating and.",
            "This converges very."
        ],
        [
            "Fast in practice, almost linearly linearly in practice, but not probably.",
            "And so here is just comparison on how well it does versus this is a reduced gradient method from that rectum emoji paper.",
            "So we go dimensions 500 to 3000 with using just a few kernels.",
            "It's three 711 Ann, just to compare this time versus this time.",
            "The time that a CPM takes is much less because the number of support vector machines is much less.",
            "So just from the algorithms POV.",
            "If your optimization problem is rather low in dimension, an has a simple set of constraints.",
            "Start with such as linear constraints.",
            "You should look into these analytics center cutting plane methods."
        ],
        [
            "So then finally.",
            "The point of showing you these slides was to mix kernels between text and returns.",
            "And does it help?",
            "I've seen it used at least once, for example in biology.",
            "So here we're using one linear text, one linear absolute returns kernel for Gaussian text, and absolute returns kernels.",
            "A timestamp Colonel Colonel from the day of the week.",
            "And so we solve the emblem on these kernels to get a combination.",
            "And we plug that combines kernel into SVM and compare against the other results.",
            "So the multiple kernel results are the blue curve, the red is the text and the pink is the absolute returns results you saw before.",
            "So we see there is some.",
            "Increased performance, it's not towards the end of the horizon it's going away.",
            "And so it is useful.",
            "How much we have to do more analysis?",
            "Another important thing to look at is.",
            "So you see an increase in performance, but is it used?",
            "What's it using?",
            "Is it just using the text?",
            "Is it just using the absolute returns?",
            "So these first up to here is text and also an identity matrix.",
            "Here the last top 10% up here is using absolute returns kernels, so it is made.",
            "It is combining them to increase the performance is not magic and also the important thing.",
            "Again, these are independent experiments.",
            "Across time each horizon and it's relatively smooth.",
            "How much the kernels that are being used.",
            "It's not a random signal, yes.",
            "Do you have any intuition of why the identity matrix is?",
            "The general matrix can be just for scaling when you throw it in.",
            "It's by given sorry.",
            "Yeah, for it can scale because that's just for the self similarity so it can help scale those self similarity that's.",
            "Used within it, that's the only intuition we have for why.",
            "Which kernels had the highest waiting, so the highest kernels here were text kernels, Gaussian, linear.",
            "But in practice, if you do them by themselves, linear and Gaussian kernels were performing about as well as each other.",
            "Different parameter right?",
            "Parameterized differently, yeah.",
            "But also we can't.",
            "You can't read into how the weights on these don't say that you can't say this is more important than that one.",
            "'cause we looked at other results where depending on when you play with the threshold that returns are more predictable than text.",
            "If you take the threshold very low towards 55% for example text, it doesn't define a true abnormal return we saw for text.",
            "The text from that.",
            "But the weight might still be not small for text over there, so it's not.",
            "Gas.",
            "I'm sorry.",
            "Best Gaussian text panel here it was here it was.",
            "Yeah, for this text is better than returns, but from those other experiments that makes it's not clear to say just that this is better than that from this picture, just that it's being used."
        ],
        [
            "And so there's plenty of further directions.",
            "As I mentioned for this research, the Delta hedged covered call options, so we don't use fictitious strange strategy for the intraday predictions.",
            "If anyone knows how to actually get that data, predicting the direction of movements, maybe using multiple kernel learning could help.",
            "So far it hasn't the feature selection obviously is a huge problem and many other things to work on.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm running this is joint work with Alex DEP.",
                    "label": 0
                },
                {
                    "sent": "Ramone and I'll mention that in a month that won't actually be at Princeton anymore.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be writing.",
                    "label": 0
                },
                {
                    "sent": "I'll be up starting a postdoc at Tel Aviv University, but Alex will still be at Princeton.",
                    "label": 0
                },
                {
                    "sent": "And we did this with a lot of help from great research systems from 2 undergrads that just finished the Princeton.",
                    "label": 0
                },
                {
                    "sent": "I want to mention Jonathan Lange and Kevin Pham.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm gonna jump in.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right into the problem, the title is exactly what we're doing, so we call this market classification problem, so we have press releases coming in.",
                    "label": 0
                },
                {
                    "sent": "So for example, Microsoft issues a press release Wednesday at 10:30 AM.",
                    "label": 1
                },
                {
                    "sent": "Here is a press release, and our goal is to read that press release and make a bet.",
                    "label": 0
                },
                {
                    "sent": "If Microsoft's price is going to have a jump or not in an hour, let's say 11:30 AM, so at 10:30 AM, I make the bet on what the price is going to be at 11:30 AM, but not on what?",
                    "label": 0
                },
                {
                    "sent": "The sorry, not what the price is going to be.",
                    "label": 1
                },
                {
                    "sent": "But whether or not the absolute return in that hour is going to be greater than or equal to some threshold row, which I'll define later.",
                    "label": 0
                },
                {
                    "sent": "So it's a 10:30 AM.",
                    "label": 0
                },
                {
                    "sent": "We have article an we have two types of information that we can use.",
                    "label": 0
                },
                {
                    "sent": "One is the text that came and the way we look at text is a bag of words.",
                    "label": 0
                },
                {
                    "sent": "We make a Dictionary of words, count up how many times they occur, and that's future vector.",
                    "label": 0
                },
                {
                    "sent": "Also the article came out at 10:30.",
                    "label": 0
                },
                {
                    "sent": "The market opened at 9:30.",
                    "label": 1
                },
                {
                    "sent": "We have an hour of the prices of Microsoft so we can make some kind of historical time series and use that vector.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I'm going to be discussing first how I can either input into a model, this bag of words vector, and try and make this prediction, which that's a classic text classification problem where you have text and you make your plus or minus one according to some criteria and either that or we're going to just input the time series of returns into the model and try and make the prediction.",
                    "label": 0
                },
                {
                    "sent": "So that's going to be the first part of the results I'll show, and then the interesting thing is trying to combine text Ann returns into one model.",
                    "label": 0
                },
                {
                    "sent": "In order to hopefully increase your performance, and since I'm coming from an operations research Department, I'm also going to touch on some algorithms on how that's done.",
                    "label": 0
                },
                {
                    "sent": "So first there's a few things to discuss before I can show you any of the results.",
                    "label": 0
                },
                {
                    "sent": "First of all, the experiment.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So set up.",
                    "label": 0
                },
                {
                    "sent": "We want to make this as realistic as possible, so the way we set it up is with chronological moving window.",
                    "label": 1
                },
                {
                    "sent": "So for example, will read a month of all the news that came out in month one and then test on all the news that comes out in month to train a month to test a month three and so forth.",
                    "label": 0
                },
                {
                    "sent": "So everything's out of sample tested and then at the end will aggregate all the test results.",
                    "label": 0
                },
                {
                    "sent": "So far results we're going to train on a year of news and tests on the following month of news.",
                    "label": 1
                },
                {
                    "sent": "Of course these windows can be.",
                    "label": 0
                },
                {
                    "sent": "Experimented with, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Literally 9:30 remember is just the last hour from that ending story comes from.",
                    "label": 0
                },
                {
                    "sent": "You know from so I'm going to pick a horizon, so that was just an example, but I'm going to pick her eyes and I'm going to try and predict is does the abnormal.",
                    "label": 0
                },
                {
                    "sent": "Does the absolute return jump above a threshold in 10 minutes or 20 minutes?",
                    "label": 0
                },
                {
                    "sent": "I'm going to pick a horizon for that.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, from whenever it came out.",
                    "label": 0
                },
                {
                    "sent": "Whenever the article comes out, I'm going to look 10 minutes later trying to predict what happens 10 minutes later.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "No, my input is exactly when it comes.",
                    "label": 0
                },
                {
                    "sent": "The press release comes out.",
                    "label": 0
                },
                {
                    "sent": "What about your pricing?",
                    "label": 0
                },
                {
                    "sent": "You said you have five.",
                    "label": 0
                },
                {
                    "sent": "I have prices that were prior to it coming out.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'm reading the that's the last.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes, only information, only information before the article, sorry.",
                    "label": 0
                },
                {
                    "sent": "And now optimize or no, this is something that is completely up to experimentation.",
                    "label": 0
                },
                {
                    "sent": "There's a market.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of things with this that are very much.",
                    "label": 0
                },
                {
                    "sent": "I'll to experimentation, and that's one of the things that we really enjoyed about.",
                    "label": 0
                },
                {
                    "sent": "This was how much more research it can bring out.",
                    "label": 0
                },
                {
                    "sent": "So a few words about the data.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We got a press release database from PR Newswire, which releases news releases for many companies.",
                    "label": 0
                },
                {
                    "sent": "Eight years of data from 2000 through 2007, and we only consider news published during the Business day.",
                    "label": 1
                },
                {
                    "sent": "'cause that's when we have prices so specific.",
                    "label": 0
                },
                {
                    "sent": "We're going to be mostly concentrating on intraday predictions.",
                    "label": 1
                },
                {
                    "sent": "And all the price data is taken from Wharton Research Data Services and these two graphs here show how much data we actually have.",
                    "label": 0
                },
                {
                    "sent": "So on the right it shows the average training and testing per window.",
                    "label": 0
                },
                {
                    "sent": "So the blue curve is how much training data you have per year.",
                    "label": 0
                },
                {
                    "sent": "The red curve is per month.",
                    "label": 0
                },
                {
                    "sent": "Now the X axis.",
                    "label": 0
                },
                {
                    "sent": "I just want to explain here 'cause you're going to see this for all of the performance graphs I show.",
                    "label": 0
                },
                {
                    "sent": "So if you can't, you probably can't see from the back, but it goes in 10 minute increments from zero to 250 minutes.",
                    "label": 0
                },
                {
                    "sent": "So rather than predict what happens just in one hour, I'm going to make a prediction.",
                    "label": 0
                },
                {
                    "sent": "What happens in 10 minutes, 20 minutes every 10 minute interval until 250 minutes, and these are all independent experiments.",
                    "label": 0
                },
                {
                    "sent": "I'm going to look at what happened at those increments and see how it what happens over the horizon.",
                    "label": 0
                },
                {
                    "sent": "How do you choose your 128?",
                    "label": 0
                },
                {
                    "sent": "120 companies this what I mean by based on quantity of releases, because for each company that came out we have to do effort to get prices and the companies that had the most press releases.",
                    "label": 0
                },
                {
                    "sent": "So we took a threshold no for the whole over the whole thing.",
                    "label": 0
                },
                {
                    "sent": "For choosing how many which companies to use, yes, I just looked at how many press release do I have in my database for that, yes.",
                    "label": 0
                },
                {
                    "sent": "So there must have been something.",
                    "label": 0
                },
                {
                    "sent": "So what we should buy us?",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Ownership bias to that degree, yes.",
                    "label": 0
                },
                {
                    "sent": "And we're only companies that.",
                    "label": 0
                },
                {
                    "sent": "That did not survive during that time that suddenly died out.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we did eliminate those.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "'cause it made the data messy.",
                    "label": 0
                },
                {
                    "sent": "So this is text classification problems, so a little survey on this.",
                    "label": 0
                },
                {
                    "sent": "The first thing up there is a survey on the last decade of different systems that have come out that mentions three different of basic ways that have been used.",
                    "label": 0
                },
                {
                    "sent": "Naive Bayes methods, decision rules and support vector machines.",
                    "label": 1
                },
                {
                    "sent": "And what I'm doing is closest to this last one by Mittermeier know Meyer and so they're looking 15 minutes into the future.",
                    "label": 1
                },
                {
                    "sent": "We looked at a bunch of horizons were doing binary classification versus their multi classification.",
                    "label": 0
                },
                {
                    "sent": "And very recently, actually just this spring coconut oil they're using support vector regression to forecast stock returns on 10K reports and see what happens.",
                    "label": 1
                },
                {
                    "sent": "That's the most recent thing I've seen.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The tool that we're going to be using for the classification is support vector machines, which I'm going to assume most people here are familiar with.",
                    "label": 1
                },
                {
                    "sent": "If not for nonlinear classification, you would map using some projection your data from non linear space to another space where you can do linear classification and to choose the mapping.",
                    "label": 1
                },
                {
                    "sent": "In essence, what is actually done, you choose a kernel function which is coming from literature.",
                    "label": 0
                },
                {
                    "sent": "Which is actually in putting a matrix defines here.",
                    "label": 1
                },
                {
                    "sent": "Kij is the inner product in your feature space up there.",
                    "label": 0
                },
                {
                    "sent": "But I'm not going to get much into that.",
                    "label": 0
                },
                {
                    "sent": "Hopefully everyone is familiar.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the last thing before I show the results is.",
                    "label": 0
                },
                {
                    "sent": "What how are we going to valuate the performance so for intraday predictions and predicting these abnormal returns and to actually trade on these, we would want to use option data.",
                    "label": 0
                },
                {
                    "sent": "But for intraday predictions we don't have options data because it's very expensive.",
                    "label": 0
                },
                {
                    "sent": "So for now what we're doing is what we want to focus on.",
                    "label": 0
                },
                {
                    "sent": "Is Sharpe ratio of this game.",
                    "label": 1
                },
                {
                    "sent": "Of course we can use other you could focus on other measures as well.",
                    "label": 0
                },
                {
                    "sent": "For here the game we're playing is every time a press release comes out.",
                    "label": 0
                },
                {
                    "sent": "I'm going to make a bet on that on that press release, whether an abnormal return occurs or not.",
                    "label": 1
                },
                {
                    "sent": "If I'm correct, I get a dollar.",
                    "label": 0
                },
                {
                    "sent": "If I'm wrong, I lose a dollar.",
                    "label": 0
                },
                {
                    "sent": "And of course there's biases towards the two different directions, but we're not taking that into account here.",
                    "label": 0
                },
                {
                    "sent": "Other measures you could look at, for example, would be the classical accuracy.",
                    "label": 1
                },
                {
                    "sent": "The reason we don't focus on accuracy is because there's no financial intuition we get for this application.",
                    "label": 0
                },
                {
                    "sent": "For Sharpe ratio, we have an intuition on what this means for us.",
                    "label": 0
                },
                {
                    "sent": "But I will be showing results for both of them, but everything I did for tuning parameters cross validation was done with Sharpe ratio.",
                    "label": 0
                },
                {
                    "sent": "And last them what I mean by an abnormal return.",
                    "label": 0
                },
                {
                    "sent": "This is another thing that you have to define.",
                    "label": 0
                },
                {
                    "sent": "So the way we do it is by taking the historical data.",
                    "label": 0
                },
                {
                    "sent": "So our one year of data before the month we're testing on is the historical data.",
                    "label": 0
                },
                {
                    "sent": "I look at all the absolute returns that occur, sort them and I take for instance the 75th percentile is my threshold, so everything above that is an abnormal return.",
                    "label": 0
                },
                {
                    "sent": "Everything below is not in this threshold is something you can play with an.",
                    "label": 0
                },
                {
                    "sent": "You'll see different results and I'll show you.",
                    "label": 0
                },
                {
                    "sent": "But for example, you can reference our paper.",
                    "label": 0
                },
                {
                    "sent": "To see what happens when you move it from 75%.",
                    "label": 0
                },
                {
                    "sent": "Sorry, you mentioned briefly that you're using intraday options data.",
                    "label": 0
                },
                {
                    "sent": "No, we don't have intraday options data and that's why we're doing this.",
                    "label": 0
                },
                {
                    "sent": "I will show you results at right after this using daily predictions where we do have options data to give more promise for doing this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here are the results for either.",
                    "label": 0
                },
                {
                    "sent": "Using returns on the left or text on the right.",
                    "label": 0
                },
                {
                    "sent": "So the first thing I want to point accuracy on the top Sharpe ratio on the bottom and the first thing to point out all these red curves here 50% for accuracy, 0 for Sharpe ratio.",
                    "label": 0
                },
                {
                    "sent": "For that we're trying to predict the direction of the stock movement plus one.",
                    "label": 0
                },
                {
                    "sent": "If it went out minus one.",
                    "label": 0
                },
                {
                    "sent": "If it went down and it's clear we have no predictability for that as we would have expected.",
                    "label": 0
                },
                {
                    "sent": "But for things such as volatility or these abnormal returns, it is known that there is some predictability and that's what we see here.",
                    "label": 0
                },
                {
                    "sent": "So for returns we can see how much we get.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The explain all the curves in the text plots, 'cause that's a bit confusing.",
                    "label": 0
                },
                {
                    "sent": "So first of all, for the returns because we have.",
                    "label": 0
                },
                {
                    "sent": "To use the returns before the press release comes out, so we needed to take 40 minutes worth of data before it comes out.",
                    "label": 0
                },
                {
                    "sent": "So we have to throw out all the articles that come out in the first 40 minutes of the day.",
                    "label": 0
                },
                {
                    "sent": "So this data set is slightly smaller, so it's compare that against this data set the diamonds.",
                    "label": 0
                },
                {
                    "sent": "Red diamonds on this plot.",
                    "label": 0
                },
                {
                    "sent": "So that's the same data sets on for those two, so you can see the text is doing better then returns with the 75% thresholding.",
                    "label": 0
                },
                {
                    "sent": "Now for the text, if you just use text, you can use the entire everything that came out during the day.",
                    "label": 0
                },
                {
                    "sent": "And if you do that, that's the solid blue lines here.",
                    "label": 0
                },
                {
                    "sent": "And we see that's when you do best, so you can the predictability on those articles earlier in the day really does make a difference.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, you can even break up so we train on all the articles that came out from 9:30 to 4:00 o'clock.",
                    "label": 0
                },
                {
                    "sent": "But then, how well did I do on the 1st 40 minutes?",
                    "label": 0
                },
                {
                    "sent": "That would be the lines with the Circle solid line with the circle which is here and at the top there.",
                    "label": 0
                },
                {
                    "sent": "So that you compare against the diamonds in the in these plots and it says that training with those articles in the beginning day was very important for the text classification.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "For the market open and just like trading, when the market opens we don't have price data on them.",
                    "label": 0
                },
                {
                    "sent": "You know, that's another thing you could do.",
                    "label": 0
                },
                {
                    "sent": "You could be here.",
                    "label": 0
                },
                {
                    "sent": "We don't, yes.",
                    "label": 0
                },
                {
                    "sent": "Just wanted.",
                    "label": 0
                },
                {
                    "sent": "Be a normal entrance fee in any way.",
                    "label": 0
                },
                {
                    "sent": "Be normalized with the market.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming.",
                    "label": 0
                },
                {
                    "sent": "They haven't been normalized with the market now.",
                    "label": 0
                },
                {
                    "sent": "We tried doing that.",
                    "label": 0
                },
                {
                    "sent": "We didn't see any.",
                    "label": 0
                },
                {
                    "sent": "It didn't make too much differences, but so we left it as this.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "I'm sorry the data, so this is up to how you threshold we so we do balance it.",
                    "label": 0
                },
                {
                    "sent": "We're not taking it with SVM.",
                    "label": 0
                },
                {
                    "sent": "There's a big problem of figuring how to take into account unbalanced data.",
                    "label": 0
                },
                {
                    "sent": "For this we so if you do 75th percentile and you have 20% five percent above it, 75% of the data is blow it.",
                    "label": 0
                },
                {
                    "sent": "So we randomly balance the data, which is another open problem that.",
                    "label": 0
                },
                {
                    "sent": "Should be looked at if you take it down 50% you wouldn't.",
                    "label": 0
                },
                {
                    "sent": "That doesn't really define a true abnormal return, but it balances your data, but that doesn't seek the goal we're looking for.",
                    "label": 0
                },
                {
                    "sent": "Related question at the first half, we actually checked how much should you are playing the speed game.",
                    "label": 0
                },
                {
                    "sent": "So if you got the news, of course there will be a reaction right off the contract, so you probably would have to put in a day if let's say half a minute or 10 seconds or whatever you are able to trade and analyze and then look at the return.",
                    "label": 0
                },
                {
                    "sent": "We haven't know.",
                    "label": 0
                },
                {
                    "sent": "So things like this and transaction costs we don't.",
                    "label": 0
                },
                {
                    "sent": "Really only transaction costs.",
                    "label": 0
                },
                {
                    "sent": "Also, whether it's feasible to do that right?",
                    "label": 0
                },
                {
                    "sent": "Having news from a company, which I usually always already have a spike in volatility.",
                    "label": 0
                },
                {
                    "sent": "Christy, it's usually your reaction also.",
                    "label": 0
                },
                {
                    "sent": "Partly how big would be that predictability?",
                    "label": 0
                },
                {
                    "sent": "So it's simply saying is use one average.",
                    "label": 0
                },
                {
                    "sent": "Volatility or the junk by advance?",
                    "label": 0
                },
                {
                    "sent": "Such a strategy.",
                    "label": 0
                },
                {
                    "sent": "So I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Just having the information that there is news would create a spike in motility.",
                    "label": 0
                },
                {
                    "sent": "Have you accounted for at least so?",
                    "label": 0
                },
                {
                    "sent": "There's a lot of features that you could put into this, and I'll things like what time of the day it occurs, what day of the week, the volume of news these are all things that you can, so we right now have text kernels.",
                    "label": 0
                },
                {
                    "sent": "I've returns kernels.",
                    "label": 0
                },
                {
                    "sent": "I can make a Colonel from the day of the week.",
                    "label": 0
                },
                {
                    "sent": "I can make a return from a new kernel based on the volume.",
                    "label": 0
                },
                {
                    "sent": "These are just additional features.",
                    "label": 0
                },
                {
                    "sent": "One basic way would be just make one big feature vector of everything.",
                    "label": 0
                },
                {
                    "sent": "But that's the most negative.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "We're going to combine kernel different kernels for the different types of features.",
                    "label": 0
                },
                {
                    "sent": "Those are other things we tried day of the week, and things like that volume.",
                    "label": 0
                },
                {
                    "sent": "I don't think I actually put in yet.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's very interesting way of looking at things.",
                    "label": 0
                },
                {
                    "sent": "Programs generally with this, is that generally before announcement to share faster moving is always a problem in the market.",
                    "label": 0
                },
                {
                    "sent": "Why the share price?",
                    "label": 0
                },
                {
                    "sent": "You have MA you always see the SharePoint moving before the announcement.",
                    "label": 0
                },
                {
                    "sent": "So is it because the market is efficient or is that they people front running it?",
                    "label": 0
                },
                {
                    "sent": "So what you will get here is delayed reaction.",
                    "label": 0
                },
                {
                    "sent": "And I mean even if the results are not understanding it does not invalidate what the research is.",
                    "label": 0
                },
                {
                    "sent": "But it could also be that.",
                    "label": 0
                },
                {
                    "sent": "A lot of it is priced in.",
                    "label": 0
                },
                {
                    "sent": "Very efficient model.",
                    "label": 0
                },
                {
                    "sent": "The question of efficient markets, I afraid to touch a button.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Into the problem, yeah.",
                    "label": 0
                },
                {
                    "sent": "She would those be right if the market stays the same and you are predicting that it's actually going up with you.",
                    "label": 0
                },
                {
                    "sent": "You can do this correct or wrong.",
                    "label": 0
                },
                {
                    "sent": "If I predict going up well for upper down.",
                    "label": 0
                },
                {
                    "sent": "Oh no, we're just doing this binary, so it's for example.",
                    "label": 0
                },
                {
                    "sent": "Oh, if it stayed the same, I think.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think we stated that it's going up or yeah.",
                    "label": 0
                },
                {
                    "sent": "I if it was here but that didn't for the Minutes did it often occur.",
                    "label": 0
                },
                {
                    "sent": "I have to look at it, but I for now we had it that it's only two classes, so if it stayed the same, we picked a direction and on average by just analyzing attacks too well, I mean 70% exactly saying I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat?",
                    "label": 0
                },
                {
                    "sent": "By the prediction I in 70%.",
                    "label": 0
                },
                {
                    "sent": "Yeah for this yes.",
                    "label": 0
                },
                {
                    "sent": "I can't read it myself, but yeah.",
                    "label": 0
                },
                {
                    "sent": "The Y axis goes up to 15.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, so this is completely we have this fictitious strategy of I get a dollar lose a dollar every prediction, so this is not realistic.",
                    "label": 0
                },
                {
                    "sent": "For this.",
                    "label": 0
                },
                {
                    "sent": "It gives me an intuition, but the magnitudes know.",
                    "label": 0
                },
                {
                    "sent": "Right now it's not a real strategy.",
                    "label": 0
                },
                {
                    "sent": "Dollar at current prices right?",
                    "label": 0
                },
                {
                    "sent": "No no.",
                    "label": 0
                },
                {
                    "sent": "No, this is a strategy where yeah, no, no, no.",
                    "label": 0
                },
                {
                    "sent": "Not at all.",
                    "label": 0
                },
                {
                    "sent": "Let me show you another.",
                    "label": 0
                },
                {
                    "sent": "Let me show you another thing.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "That's why we called it a fictitious strategy.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "60 minutes.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How many trades would you make a day today?",
                    "label": 0
                },
                {
                    "sent": "Trades in a day at the 16 minute.",
                    "label": 0
                },
                {
                    "sent": "So 60 means, oh, this is the 60 minute here means I'm going to predict if an abnormal return occurs in 60 minutes.",
                    "label": 0
                },
                {
                    "sent": "Right, and so how many trades a day depends on how many articles.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, there's a new trade off, you're saying?",
                    "label": 0
                },
                {
                    "sent": "I mean, right wherever.",
                    "label": 0
                },
                {
                    "sent": "At a 60 minute time horizon, how?",
                    "label": 0
                },
                {
                    "sent": "How many trades would you actually?",
                    "label": 0
                },
                {
                    "sent": "How many bets would you make a day?",
                    "label": 0
                },
                {
                    "sent": "As many articles came out, I would have to.",
                    "label": 0
                },
                {
                    "sent": "Look at the data for that.",
                    "label": 0
                },
                {
                    "sent": "But for the reason we want to look at Sharpe ratio here, it's fictitious, but that we're hoping is what gives you a trade off for if you otherwise for the top curves I just show accuracy.",
                    "label": 0
                },
                {
                    "sent": "I would really want to cross validate between some tradeoff of accuracy and recall.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "This will move upwards more than Rd.",
                    "label": 0
                },
                {
                    "sent": "I'm predicting whether the absolute price change moves above Ro, so it's but yeah, either way, yeah.",
                    "label": 0
                },
                {
                    "sent": "Don't predict option in your model, correct?",
                    "label": 0
                },
                {
                    "sent": "No we don't.",
                    "label": 0
                },
                {
                    "sent": "So you.",
                    "label": 0
                },
                {
                    "sent": "So how do you evaluate your model when your model predicted movement more than row and the stock was flat?",
                    "label": 0
                },
                {
                    "sent": "How do you count that?",
                    "label": 0
                },
                {
                    "sent": "For that's the example here.",
                    "label": 0
                },
                {
                    "sent": "We said if it was flat then we say it's up.",
                    "label": 0
                },
                {
                    "sent": "It's we don't sorry, 5% of ties your credit yourself with making a correct prediction.",
                    "label": 0
                },
                {
                    "sent": "No, so we bout that's the unbalanced part, right?",
                    "label": 0
                },
                {
                    "sent": "Then it was seven if we used to like that I could say OK, just bet bet all the time that in this direction and you'll win.",
                    "label": 0
                },
                {
                    "sent": "So here we balance the data.",
                    "label": 0
                },
                {
                    "sent": "So that it only goes above the threshold 50% of the time down.",
                    "label": 0
                },
                {
                    "sent": "Rolling out I randomly yes discard the data.",
                    "label": 0
                },
                {
                    "sent": "Didn't make it right.",
                    "label": 0
                },
                {
                    "sent": "We randomly discarded that.",
                    "label": 0
                },
                {
                    "sent": "There is so far we didn't see another way to go around this other than looking at support vector machines.",
                    "label": 0
                },
                {
                    "sent": "How throwing playing with penalization parameters for two different classes or whatnot, other methods.",
                    "label": 0
                },
                {
                    "sent": "You could just use the confidence in picture on the SPN itself and say if that if that real value right at the very end you're taking with threshold love is above or below a certain value.",
                    "label": 0
                },
                {
                    "sent": "That I make a trade.",
                    "label": 0
                },
                {
                    "sent": "Otherwise they don't shave it all.",
                    "label": 0
                },
                {
                    "sent": "That you could take.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for daily predictions I'll go quickly, hopefully.",
                    "label": 0
                },
                {
                    "sent": "Now we can use.",
                    "label": 0
                },
                {
                    "sent": "We do have daily options data, so we tried this option strategy Delta hedged covered call options.",
                    "label": 1
                },
                {
                    "sent": "So the way this works is if we do predict an abnormal return by one call option on that stock and sell Delta shares of the stock today.",
                    "label": 1
                },
                {
                    "sent": "Tomorrow you exit the positions.",
                    "label": 0
                },
                {
                    "sent": "So by selling Delta shares of stock.",
                    "label": 0
                },
                {
                    "sent": "What this means is the ideas you want to position.",
                    "label": 0
                },
                {
                    "sent": "That's only sensitive to movements in volatility of your stock and not with respect to the stock movements itself which measures direction.",
                    "label": 0
                },
                {
                    "sent": "So it's called keeping your position Delta neutral.",
                    "label": 0
                },
                {
                    "sent": "So in the actual data and the predictions we did hear the profit and loss for first on the left.",
                    "label": 0
                },
                {
                    "sent": "Here if you want to predict an abnormal return, the profit and loss of these types of predictions looks like this, it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a very rough smile up, which is exactly what you would want.",
                    "label": 0
                },
                {
                    "sent": "So if you're correct that it jumps a lot in either direction, you make profit.",
                    "label": 0
                },
                {
                    "sent": "If you're wrong, it stays around zero.",
                    "label": 0
                },
                {
                    "sent": "You lose very little.",
                    "label": 1
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "For predicting if no abnormal return.",
                    "label": 0
                },
                {
                    "sent": "If you're correct and it stays around zero, you make only little, but the potential to lose.",
                    "label": 0
                },
                {
                    "sent": "If it does move way is a lot.",
                    "label": 0
                },
                {
                    "sent": "So trying this.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "The shortest majority we could find 3 months or yeah.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are three different strategies we did according to this.",
                    "label": 0
                },
                {
                    "sent": "So trade all means every time an article comes out, I trade on whatever.",
                    "label": 1
                },
                {
                    "sent": "I predict long only only predicts only makes a bet if we were predicting an abnormal return and short only predicts a few, don't predict an abnormal return.",
                    "label": 1
                },
                {
                    "sent": "So here are the sharp rationes we have and the best one is from long only.",
                    "label": 1
                },
                {
                    "sent": "And the reason for this is because of the shape of the P&L there, that the amount you have potential to get can be a lot the amount you can lose is limited.",
                    "label": 0
                },
                {
                    "sent": "However for short only your potential for loss is much greater and so that potential is what hurts you in the trade.",
                    "label": 0
                },
                {
                    "sent": "All strategies.",
                    "label": 1
                },
                {
                    "sent": "So this long only strategy actually has a lot of problems, we think.",
                    "label": 0
                },
                {
                    "sent": "Also have to do with the fact that there's no bad news.",
                    "label": 0
                },
                {
                    "sent": "My first guess.",
                    "label": 0
                },
                {
                    "sent": "Why your shorts are you just don't want to trade on them because texture looking there is.",
                    "label": 0
                },
                {
                    "sent": "There's no bad news in the texture both alright?",
                    "label": 0
                },
                {
                    "sent": "These are corporate press releases.",
                    "label": 0
                },
                {
                    "sent": "Oh no, it's newswire, it's PR Newswire, so it's anything that they released.",
                    "label": 0
                },
                {
                    "sent": "But you also said.",
                    "label": 0
                },
                {
                    "sent": "Press releases yes.",
                    "label": 0
                },
                {
                    "sent": "Is it good or bad?",
                    "label": 0
                },
                {
                    "sent": "And why that is why?",
                    "label": 0
                },
                {
                    "sent": "Trade short, you should discount at least.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I don't have a good answer for that quite I'm haven't yes.",
                    "label": 0
                },
                {
                    "sent": "Stop wrong, yes.",
                    "label": 0
                },
                {
                    "sent": "It's not going to be very good.",
                    "label": 0
                },
                {
                    "sent": "No, it doesn't, so that's another huge open question.",
                    "label": 0
                },
                {
                    "sent": "The feature selection for the dictionary I created my own manual dictionary for this.",
                    "label": 0
                },
                {
                    "sent": "I tried some automated techniques in the beginning that didn't work so well, but there's still potential.",
                    "label": 0
                },
                {
                    "sent": "That's not to say that's dead.",
                    "label": 0
                },
                {
                    "sent": "Impianti means wide open for which features to use.",
                    "label": 0
                },
                {
                    "sent": "Also, looking at articles is combinations of topics.",
                    "label": 0
                },
                {
                    "sent": "Instead they have all these and using the topics that make up an article is your features.",
                    "label": 0
                },
                {
                    "sent": "That's.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, absolutely.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How much time do I have?",
                    "label": 1
                },
                {
                    "sent": "0.",
                    "label": 0
                },
                {
                    "sent": "OK, so the methods for combining kernels.",
                    "label": 0
                },
                {
                    "sent": "This is so everything I showed you right now is just how to use text and use returns separately in support vector machines.",
                    "label": 0
                },
                {
                    "sent": "So this is how you can combine the two together.",
                    "label": 0
                },
                {
                    "sent": "And this came from the kernel Learning Framework Framework from Langford at all 2004.",
                    "label": 0
                },
                {
                    "sent": "And solve this optimization problem one minimizing legacy of K or Omega CFK is defined.",
                    "label": 0
                },
                {
                    "sent": "That's just support vector Machine is a function of the kernel K. So the idea is to look for the kernel that gives you the best upper bound given by support vector machines, and for tractability it's very important to find the Kappa in the optimization problem and the way it's done here is by looking for a positive linear combination of the kernels.",
                    "label": 1
                },
                {
                    "sent": "And this was termed the multiple kernel learning problem.",
                    "label": 0
                },
                {
                    "sent": "So it was formulate.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In many different ways to give you different optimization techniques for it and the most recent one was from rectum amanji adult 2008.",
                    "label": 1
                },
                {
                    "sent": "And this looks at the exact same problem I just showed you.",
                    "label": 0
                },
                {
                    "sent": "Instead of legacy you have JVD and they replace the variable K with D as a combination of your coefficients for your kernels.",
                    "label": 0
                },
                {
                    "sent": "And the way they solve this this optimization problem is by saying we can calculate the gradient here where it has this form.",
                    "label": 0
                },
                {
                    "sent": "The important thing to know Alphastar is the optimal solution to the SVM at the current iterative D. So every time you calculated gradient you have to calculate a support vector machine every time you compute the objective function is poor vector machine.",
                    "label": 1
                },
                {
                    "sent": "So for gradient methods that they use, it can be quite expensive 'cause you're calculating many support vector machines online searches.",
                    "label": 0
                },
                {
                    "sent": "So we looked at another method to solve this problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And when you want to use larger kernels and it's called the analytics center cutting plane method.",
                    "label": 1
                },
                {
                    "sent": "Been around for a long time and the method goes as such.",
                    "label": 1
                },
                {
                    "sent": "Suppose you have a feasible region, the entire Polygon start with.",
                    "label": 0
                },
                {
                    "sent": "You choose a center in the middle of the Polygon and you draw cut through that center using first order optimality condition at that point, so you can tell is the optimal point on this side or this side for your problem.",
                    "label": 0
                },
                {
                    "sent": "So you cut out this side of the region, make a center in what's left, draw cut and you keep producing it until you're within some tolerance.",
                    "label": 0
                },
                {
                    "sent": "The question OK, so every iteration you compute one gradient for that condition.",
                    "label": 1
                },
                {
                    "sent": "And how do you define the center?",
                    "label": 1
                },
                {
                    "sent": "It's called the analytic center.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "So mathematically, here's what the algorithm looks like.",
                    "label": 0
                },
                {
                    "sent": "You compute the analytics center as such.",
                    "label": 0
                },
                {
                    "sent": "For each hyperplane you draw a log arhythmic barrier that pushes you away from the hyperplane.",
                    "label": 0
                },
                {
                    "sent": "You solve that optimization problem is the analytic center problem.",
                    "label": 1
                },
                {
                    "sent": "Now when you have very few kernels, then that's the number of kernels of dimension of that analytic center problem.",
                    "label": 1
                },
                {
                    "sent": "So then that problem is relatively easy if you have many, many kernels, then that problem becomes harder to solve than the gradient methods will do better.",
                    "label": 0
                },
                {
                    "sent": "So each iteration analytic center problem compute the gradient in the condition and you keep iterating and.",
                    "label": 0
                },
                {
                    "sent": "This converges very.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fast in practice, almost linearly linearly in practice, but not probably.",
                    "label": 0
                },
                {
                    "sent": "And so here is just comparison on how well it does versus this is a reduced gradient method from that rectum emoji paper.",
                    "label": 0
                },
                {
                    "sent": "So we go dimensions 500 to 3000 with using just a few kernels.",
                    "label": 0
                },
                {
                    "sent": "It's three 711 Ann, just to compare this time versus this time.",
                    "label": 0
                },
                {
                    "sent": "The time that a CPM takes is much less because the number of support vector machines is much less.",
                    "label": 0
                },
                {
                    "sent": "So just from the algorithms POV.",
                    "label": 0
                },
                {
                    "sent": "If your optimization problem is rather low in dimension, an has a simple set of constraints.",
                    "label": 0
                },
                {
                    "sent": "Start with such as linear constraints.",
                    "label": 0
                },
                {
                    "sent": "You should look into these analytics center cutting plane methods.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then finally.",
                    "label": 0
                },
                {
                    "sent": "The point of showing you these slides was to mix kernels between text and returns.",
                    "label": 0
                },
                {
                    "sent": "And does it help?",
                    "label": 0
                },
                {
                    "sent": "I've seen it used at least once, for example in biology.",
                    "label": 0
                },
                {
                    "sent": "So here we're using one linear text, one linear absolute returns kernel for Gaussian text, and absolute returns kernels.",
                    "label": 1
                },
                {
                    "sent": "A timestamp Colonel Colonel from the day of the week.",
                    "label": 0
                },
                {
                    "sent": "And so we solve the emblem on these kernels to get a combination.",
                    "label": 0
                },
                {
                    "sent": "And we plug that combines kernel into SVM and compare against the other results.",
                    "label": 0
                },
                {
                    "sent": "So the multiple kernel results are the blue curve, the red is the text and the pink is the absolute returns results you saw before.",
                    "label": 0
                },
                {
                    "sent": "So we see there is some.",
                    "label": 0
                },
                {
                    "sent": "Increased performance, it's not towards the end of the horizon it's going away.",
                    "label": 0
                },
                {
                    "sent": "And so it is useful.",
                    "label": 0
                },
                {
                    "sent": "How much we have to do more analysis?",
                    "label": 0
                },
                {
                    "sent": "Another important thing to look at is.",
                    "label": 0
                },
                {
                    "sent": "So you see an increase in performance, but is it used?",
                    "label": 0
                },
                {
                    "sent": "What's it using?",
                    "label": 0
                },
                {
                    "sent": "Is it just using the text?",
                    "label": 0
                },
                {
                    "sent": "Is it just using the absolute returns?",
                    "label": 0
                },
                {
                    "sent": "So these first up to here is text and also an identity matrix.",
                    "label": 0
                },
                {
                    "sent": "Here the last top 10% up here is using absolute returns kernels, so it is made.",
                    "label": 0
                },
                {
                    "sent": "It is combining them to increase the performance is not magic and also the important thing.",
                    "label": 0
                },
                {
                    "sent": "Again, these are independent experiments.",
                    "label": 0
                },
                {
                    "sent": "Across time each horizon and it's relatively smooth.",
                    "label": 0
                },
                {
                    "sent": "How much the kernels that are being used.",
                    "label": 0
                },
                {
                    "sent": "It's not a random signal, yes.",
                    "label": 0
                },
                {
                    "sent": "Do you have any intuition of why the identity matrix is?",
                    "label": 0
                },
                {
                    "sent": "The general matrix can be just for scaling when you throw it in.",
                    "label": 0
                },
                {
                    "sent": "It's by given sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for it can scale because that's just for the self similarity so it can help scale those self similarity that's.",
                    "label": 0
                },
                {
                    "sent": "Used within it, that's the only intuition we have for why.",
                    "label": 0
                },
                {
                    "sent": "Which kernels had the highest waiting, so the highest kernels here were text kernels, Gaussian, linear.",
                    "label": 0
                },
                {
                    "sent": "But in practice, if you do them by themselves, linear and Gaussian kernels were performing about as well as each other.",
                    "label": 0
                },
                {
                    "sent": "Different parameter right?",
                    "label": 0
                },
                {
                    "sent": "Parameterized differently, yeah.",
                    "label": 0
                },
                {
                    "sent": "But also we can't.",
                    "label": 0
                },
                {
                    "sent": "You can't read into how the weights on these don't say that you can't say this is more important than that one.",
                    "label": 0
                },
                {
                    "sent": "'cause we looked at other results where depending on when you play with the threshold that returns are more predictable than text.",
                    "label": 0
                },
                {
                    "sent": "If you take the threshold very low towards 55% for example text, it doesn't define a true abnormal return we saw for text.",
                    "label": 0
                },
                {
                    "sent": "The text from that.",
                    "label": 0
                },
                {
                    "sent": "But the weight might still be not small for text over there, so it's not.",
                    "label": 0
                },
                {
                    "sent": "Gas.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Best Gaussian text panel here it was here it was.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for this text is better than returns, but from those other experiments that makes it's not clear to say just that this is better than that from this picture, just that it's being used.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so there's plenty of further directions.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned for this research, the Delta hedged covered call options, so we don't use fictitious strange strategy for the intraday predictions.",
                    "label": 1
                },
                {
                    "sent": "If anyone knows how to actually get that data, predicting the direction of movements, maybe using multiple kernel learning could help.",
                    "label": 1
                },
                {
                    "sent": "So far it hasn't the feature selection obviously is a huge problem and many other things to work on.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}