{
    "id": "ngncmx7oufbs6g45ulvnhr7og34pezj3",
    "title": "Some Challenging Machine Learning Problems in Computational Biology: Time-Varying Networks Inference and Sparse Structured Input-Out Learning",
    "info": {
        "author": [
            "Eric P. Xing, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Jan. 15, 2009",
        "recorded": "November 2008",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Biology->Genetics"
        ]
    },
    "url": "http://videolectures.net/cmulls08_xing_scml/",
    "segmentation": [
        [
            "We are.",
            "The Machine Learning Department and we talked about some machine learning challenges in computational biology."
        ],
        [
            "K thanks Steve.",
            "OK, it's not know where to find all the students.",
            "It's all here.",
            "Thanks for showing up.",
            "So Steve basically asked me to say he said basic.",
            "Some people, many of you guys are interested in machine learning in biology and he wants me to talk about some applications, some problems.",
            "But without saying what to talk about.",
            "So then I figured that.",
            "Well, I could talk on on four days.",
            "In fact, I'm going to give a class on computer mix next semester, which is all about this topic.",
            "But after awhile I thought maybe I should share with you some of the latest project going on in my group that is really integrating some machine learning issues.",
            "Some open combat problems with some challenging statistical open problems.",
            "I could also make the talk of our technical but.",
            "Just to honor the lunch spirit, I guess I'm going to make a little bit lighter of that and hopefully give you just the high level ideas rather than the detailed mathematical derivations and all that."
        ],
        [
            "So.",
            "Computational biology, so this area is actually a very old area and the study of quality biology could be as old as the field of statistics.",
            "But what are the modern challenges right now in Campbell?",
            "So here is what we are facing, so we are in the era where there are a lot of new inventions that help us to collect lots of biological data.",
            "And those datas are really complicated, for example that dynamic there are noisy.",
            "They are heterogeneous.",
            "And there are high dimension, though it could be a nightmare for a machine learning practitioner if he wants to just grab the off the shelf program and run a single pass and then smell some numbers you could get nothing out of it.",
            "But on the other hand, it could be a dream data set for those people who really want to develop new machine learning methodology or theory.",
            "And to answer challenging questions, I'm here.",
            "I actually listed Cup of Criterions viewed to be important.",
            "If you want to design such algorithms for Campbell problems.",
            "So what I'm going to do today is to pick out two particularly interesting new problems that hasn't been heavily studied yet in the field, and I'm going to.",
            "Mainly presented a problem and some preliminary solutions we had in our group, but I also welcome you to talk to us and if you are interested in working on these problems, either from a biological perspective from a pure statistical machine perspective, there are a lot of opportunities in these areas.",
            "So the first problem is about inferring."
        ],
        [
            "Time varying networks.",
            "So what this problem is about.",
            "So here is the rough setting.",
            "While given a data set which is collected from a time course of maybe some biological processes such as this, development of animal embryo and then we want to figure out what are the time specific networks that is driving the development of biological system in a time specific fashion.",
            "So why this problem is important?"
        ],
        [
            "Well, nowadays, as I mentioned, we have many techniques of collecting biological information.",
            "In particular, people want to take a look of the biological regulatory circuitry, incomplete existence, which are often represented by a network, and indeed we have many ways of measuring the linkages of this network in steady state format.",
            "For example, we can measure the interaction between protein pairs.",
            "We can measure the currencies of chemical reactions.",
            "Or we can even directly measure the interaction between some DNA proteins known as transcription factors, which regulates the activity of the genes.",
            "But most of these reactions are these measurements are taking place under steady state, meaning that you killed animal and you take a measurement.",
            "And that's for all.",
            "In the second time, you want to measure again, you lose.",
            "The system needs to reboot it and measure data central time point, which is not really give you a real time snapshot of the process.",
            "But biological systems are."
        ],
        [
            "Really, dynamical and changing all the time like I show in this picture.",
            "So this is the evolution of the embryo.",
            "We are interesting study and nowadays people can actually take a snapshot of the expression of the genes in this embryo, such as you know, here is the expression of a particular gene along the whole development processes and in different locations in a cell.",
            "So we can do a reasonable job.",
            "A measuring the intensity of these genes in the system.",
            "But we couldn't measure whether two genes are interacting or not, because this is not something that can be easily experimented."
        ],
        [
            "And we have some other systems such as this system which is describing the development of a cancer.",
            "This particular scientist in Berkeley Development System where she can inject some cancer cells taken from the patient into a virtual system and then after adding some nutritions, this particular subset of population of cells can grow like as if they are in the in the body and grow them into a cancer.",
            "And then after that stage.",
            "She can actually inject some other inhibitors or chemicals or things like that and revert the process to turn the whole thing back into normal.",
            "So ad hoc wise this is a very smart approach that can make you the impression that now you can revert the progression of cancer.",
            "But now people want to ask why this is happening.",
            "What is the biological reaction or processes that is underlying the reversal and progression of cancer?",
            "In a third example, I also have a postdoc who."
        ],
        [
            "Interested in studying the inflammatory response in the endo toxicated mice where she can also inject some toxicities into this miles and then wait for a few days until it dies and then take samples from not only different time points but also different organs in this animal and you can imagine that the regulatory events in different time and in different cellular system like tissue and organs could be quite different from each other and it's writable.",
            "Assume that you can have a single network that take care of all of this, so that's the problem we."
        ],
        [
            "Until now, really ask a bigger picture question as the following.",
            "So what is the path without his active under certain extracellular stimuli under certain point of dynamic processes?",
            "For example, how does this network response to a mental condition or under drug treatment or things like that?",
            "So all these really points you to the key issue about connecting estimate or inference condition specific topological structure among entities such as jeans so.",
            "Has this problem been addressed well?",
            "To some degree, yes.",
            "People have been inventing some classical method to answer problem similar to this.",
            "So here is a possible strategy.",
            "So I have the time."
        ],
        [
            "Iris data, and now I say I want to estimate a network of it.",
            "What would be the most straightforward will do it?",
            "Well, in the literature you can find the keyword Bayesian network and how Bayesian network can be applied to this problem.",
            "Well, you assume that all these examples, which is a high dimensional measurement of maybe 10,000 genes as ID samples from a distribution defined by the Bayesian network.",
            "You put some put together and then you do a maximum likelihood estimation.",
            "And the structure learning to get this network.",
            "So that's one approach, but you need to realize that this gives you a static network which really ignore the differences of topology under different time points.",
            "You may also heard that people use another model known as a dynamic Bayesian networks, right?",
            "And makes you feel that all OK. Now I can carry, take care of dynamics, but what is a dynamic Bayesian network?",
            "It is actually not quite dynamic 'cause what you do with the dynamic Bayesian network is to now put together not.",
            "Single time snapshots of the gene expression but pairwise snapshots of gene expressions.",
            "You put every pair of measurement as ID.",
            "Examples of a stationary transition model defined by the Bayesian network or by the Dynamic Bayesian network, and you do an estimation of the graph structure and the transition model based on ID samples of time slices.",
            "OK, any end you get a model like this which defines you the conditional probability distribution of gene expression at time T given time T -- 1 and the conditional distribution is defined by the graph.",
            "But that graph is invariant overtime.",
            "Therefore your Bayesian network model is a stationary model that is structurally not time invariant.",
            "OK, so these are the problem."
        ],
        [
            "And they are not quite sufficient to address our goal for estimating time specific graphs, which may gives you information about what interaction is active under certain timepoint.",
            "So our goal is to devise a. Algorithm that kind of reverse engineer temporal or maybe even spatial specific rewiring of the gene network.",
            "And again here is the context we want to, you know, use this data to estimate a sequence of graphs which may have time specific.",
            "Top apologies.",
            "OK, well if you look at this problem naively, you may notice that you may feel that this is really a you defined problem because of what what?",
            "Because if you really believe that.",
            "Network are time specific and each time point you get a unique network underlying example then you will face this issue.",
            "You look at time, .1 of T and you'll see why example and that correspond to a particular graph.",
            "How can you estimate a graph from only one example of observation, right?",
            "Because the next time you make measure, it's going to be at a different time and your graph is changing already, so this is the email defined statistical problem.",
            "So what I'm hoping at the end of the day is that after this talk, hopefully you can realize that there is a way to slightly relax this problem so that the problem can be approached using some simple statistical approaches.",
            "And here is the high level idea."
        ],
        [
            "Let's imagine that now we are dealing with a sequence of networks that is changing overtime, but the networks are not changing entirely randomly.",
            "Overtime in the sense that it is going to follow a evolution model which govern the way graph is changing in a way that they don't change much overtime.",
            "They may follow specific dynamics to allow maybe 5% of the edges, or maybe 1% of the edges changing overtime and for the remaining 95% of the edges they're going to be.",
            "Recurring overtime and therefore all the samples can be reused to estimate that part of the graph.",
            "So that's the high level idea.",
            "So if you want to be more formal, you can write down a transition model over graph evolution as a what is known as the temporal expansion graph model originally worked out by Steve in my group.",
            "And here you just know right down the conditional distribution of a graph at T given a graph at T -- 1 using a log linear model defined by some potential functions over graph characteristics.",
            "And I will be specific about what those characters can be in a second.",
            "And then after that you can also hang off the graph some observations using an emission model much like the way you deal with the hidden Markov model, and they can be a complicated model to define the node observations.",
            "Conditioning on the topology of the graph OK, after all this has been set up.",
            "Suppose you have infinite computing power.",
            "You can now ask the question of what is the conditional distribution of a particular node or particular graph at a particular time.",
            "Given that entire observation and marginalized out all the other graph, I don't care about, so this is like the forward backward algorithm in hidden Markov model, except that now the state space in here is huge.",
            "OK, it is the state space of the entire topological structure of the graph, so that's kind of the major setting.",
            "By using this assumption, we cannot at least formulate the problem that is estimating time specific graphs based on entire samples, just to say a few more words about such a model.",
            "For example, the transition model can."
        ],
        [
            "Defined on arbitrary design of dynamic potentials and potentials can be, say, continuity potential.",
            "Say the graph is not changing much overtime, the graph is following a reciprocity that makes say if I contact you the first time, you need to return me a call the second time, or transitivity.",
            "If I call you, you call the other guy I'm going to call the other guy the next time, and so on so forth.",
            "You can be very flexibly designing this, and there are standard way to estimate.",
            "Weights of all these potential.",
            "If you are given full observations of the sequence of graphs and that has been shown in one of."
        ],
        [
            "Early papers.",
            "And they."
        ],
        [
            "There's another nice property of this model which is known as nondegeneracy, which says that this graph is defining this distribution.",
            "Is defining a well behaving distribution of the temporal sequence of graphs in the sense that it is not.",
            "Having an abnormal concentration of the probabilistic mass over just a few graph configuration but non probability mass over other configurations.",
            "So this property is called degeneracy.",
            "Let's for this interest Timeskip order theory, but what is the virtue of that?",
            "The virtue of that is that after you see a few examples of this graph, the maximum likelihood estimation exists and can be obtained from the data.",
            "On the other hand, if you have a degenerate distribution, it can happen that if even if you observe infinite data, you can still not estimate the parameters of the graph.",
            "So this is just to give you a safeguard of the legitimacy of this model."
        ],
        [
            "Now we have a model.",
            "What can we do?",
            "Is that we can do a number of things you can do hypothesis testing, say I write down a graph evolution model.",
            "Then I'm observing this graph evolution sequences.",
            "Is this sequence generated from my model or otherwise?",
            "So I handle this test.",
            "I can do clustering of the nodes based on someone like this, But in this case I'm going to talk about one more specific application of this model, which is to learn the latent.",
            "Sequence of graph that is not observed from only data.",
            "So as I said, current approaches are mainly assuming time invariant structures and algorithms based on structural them or things like that are usually not globally optimal and also there isn't any known results.",
            "Or maybe there are not too much known results on guarantees on these algorithms and algorithm.",
            "I'm going to show you in a second hopefully offer you some progress along these directions.",
            "So here is the model of the Prob."
        ],
        [
            "Again, just to reiterate, we have a sequence of observations and we want to estimate time specific sequence of graphs."
        ],
        [
            "And we can make this problem a little bit more relaxed by assuming that the graphs are evolving over every airports rather than over every time point, so that for this few time points we have the same graph and we have multiple solutions.",
            "But in any case the number of revisions won't be more big enough to make a estimation without using other sample.",
            "OK. And so."
        ],
        [
            "Here is the first algorithm, which is again the thing you can do.",
            "First thing I think about we have this graphical model which is look like a HMM.",
            "Why don't we just do what we do in?",
            "Hmm, maybe we don't even want to think about forward backward because of the state space is too big.",
            "Let's do sampling so we can."
        ],
        [
            "Ask a query what is the conditional distribution of having changed a particular edge in the graph given the Markov blanket of this entire random variable.",
            "OK, so that proposed distribution can be written down in this complicated form, and in this form you need to do a number of non trivial things.",
            "First you need to compute the ratio between the partition functions.",
            "Related to this, node and partition functions has to be computed for every different configurations of this node.",
            "Remember that you are not proposing a new edge or removing an edge.",
            "You need to recompute the partition function, and that's going to be very complicated if you need to do it every time you sample a edge, right?",
            "And there are some other complications, and at the end of the day we found this algorithm to be extremely efficient.",
            "In fact, we can only scale this algorithm to about 20 nodes, and but nevertheless."
        ],
        [
            "The result wasn't bad if we can wait long enough, and being patient enough, we found that this time varying graph inference problem is indeed well defined.",
            "Unsolvable OK. For example here I have a few simulations which are simulated from a known time evolving graph model where the heater controls the degree of change.",
            "Overtime of the graph topology and the Theta is the degree of consistency between the observation and.",
            "Apology, so moving from that direction to this one.",
            "The graph is more dramatically evolving overtime, making the problem more difficult to estimate and going downward.",
            "You have less and less consistency between the data and the model.",
            "Therefore the problem can also be difficult, but in the end when applying the Gibbs sampling algorithm I just described which are supposedly doing exact inference, you can actually get a pretty good recovery of the graph topology in small setting.",
            "So here I compare.",
            "Our algorithm with a few other ways of solving the problem.",
            "So what are these other ways?",
            "Well, there isn't actually anything to compare with because there isn't any other algorithm that does time specific network recovery.",
            "OK, so we can do best is to assume that I'm going to recover a single graph out of the entire sequences as people do and then compare out of this single graph how many edges are actually appearing over the history of the graph evolution, right?",
            "So this is the result in here, which is pretty poor.",
            "OK, and what is the 2nd bar?",
            "Second bar is what we know what we call the static ground truth.",
            "Which means that well, I know that inference is itself a hard problem.",
            "Let's assume that we can do perfect inference.",
            "What we make perfect inference?",
            "Well, since I simulate the graph, actually record all the graph topology already.",
            "That's the ground truth.",
            "What if I can actually get the ground truth and then I want to extract a single graph out of it.",
            "All I can do is to superimpose all these two graphs at each time point and get a single graph.",
            "Then out of that single graph.",
            "How many edges are actually true?",
            "And again, this is below what we can estimate from a time invariant graph.",
            "OK, so that's the first algorithm which is just presented here for the sake of completeness, because it is not going to be algorithm this really feasible for real scale inference because the size of the graph is only in this case.",
            "I believe 20 nodes."
        ],
        [
            "The second algorithm, which we hope to be able to scale to a real size problem, is based on a recent technique known as a graph regression.",
            "So what is graph regression?",
            "Well, when people want to learn specific graphical models such as Gaussian graphical model, a graphical model Michael Random Fields, recently there has been this algorithm proposed for answering that task.",
            "Let's imagine the problem of learning a graph to be a task that is defined sequentially over each node in terms of learning the neighborhood of every node in the graph.",
            "OK, so say I have this eight node and I want to learn a graph out of it.",
            "One strategy says that you can now imagine I focus on this node and figure out the neighborhood of this node under in the original graph, and that can be casted as a. Regression problem.",
            "Either a logistic linear regression or a logistic regression, depending on whether you worry about the continuous graph or discrete graph.",
            "And since we want to have the graph to be sparse.",
            "Do to you know Interpretational reason or consistency guarantee we can put a L1 regularizer to make it a lot.",
            "Sorry question.",
            "So we do last.",
            "So over all other nodes with respect to OneNote.",
            "And as you know, under authority question, the irrelevant nodes will have their weights pushing to push this zero.",
            "Therefore we can now Thresh hold it and obtain the true edges related this related this particular node tool neighborhood, and then we do the same for the other node."
        ],
        [
            "And in the end we can actually get a full graph estimation, right?",
            "So this is accuracy is known as the graph, so it has a number of nice properties, including the exit to the consistency properties under a particular condition.",
            "So we want to.",
            "Ask whether this technique can be extended to estimating time specific graphs, so here is."
        ],
        [
            "A possible proposal.",
            "The second algorithm is known as the test logarithm.",
            "It stands for temporary smooth L1 regularised logistic regression.",
            "Which is really very similar to what you saw just now in graphical, so OK, so here is the cost function.",
            "Now instead of estimating the neighborhood of a node at a particular time point, I'm going to estimate the neighborhood of this node I over every time point in my sequence and therefore my loss function of course will be the Las Olas, the regression loss function over every time point.",
            "And every at every time point.",
            "Of course, I have a different graph.",
            "Therefore they have their unique coefficients in a regression standing for the structure at that time, and I'm going to give it L1 regularizer to make it sparse.",
            "But then, because I'm now assuming that the graphs are evolving overtime and therefore they are not completely independent overtime, one of the safe assumption or convenient assumption I can make is to assume that they really don't change overtime in the sense that their graph regressional coefficients are stable or not.",
            "Changing overtime or smooth overtime.",
            "Therefore, I have this total variation cost function which is defined over the differences between the regression coefficient at.",
            "Sometime point.",
            "OK, I'm going to do that for every adjacent time point.",
            "And here is the regularization coefficient.",
            "OK, so this is, you know, a convex program and you can turn it into a constraint convex option problem using like running duality.",
            "And there are standard solvers to solve this problem, and it's actually pretty efficient and we can now scale the algorithm to about 5000 nodes.",
            "Not bad, it's pretty convenient and simple approach, but to solve very nontrivial problem well.",
            "It turns out that these 5000 nodes is barely enough to cover a small species such as East, which contain which happened to contain 5000 genes.",
            "When we want to do.",
            "More complicated genome, such as the genome of human ultra software.",
            "We have about 20,000 genes or even more than that and this algorithm stop to behave nicely in a problem as big as that.",
            "It could end up waiting for weeks to see any number out of it.",
            "So we decide to also go through maybe another round of relaxation to make the problem even simpler."
        ],
        [
            "OK, the third algorithm is known as the kernel weighting.",
            "Approach for Grapher equation which is even more similar to the standard graph regression, except that now you use the samples in the smarter way.",
            "OK, look at that.",
            "So here we have the regressional loss function we have the L1 penalty over the coefficients but now since I'm going to estimate time specific graphs using all the examples in my time series, what I'm going to do is that if I'm focusing on time T, I'm going to assume that.",
            "Since the graph is not changing overtime, therefore my nearby samples should contribute to my estimator of this graph in some way.",
            "OK, and the way they contribute that maybe we can wait their importance and then treat them as if they are sample from the same distribution.",
            "OK, so here is a strategy I'm going to write down the regressional loss function over every time point, but for those time points which are different from my point of question, I'm going to give it a kernel relating.",
            "Function on top of that, the further this time point is away from the lower the weight it is and after this treatment effectively dealing with ID samples except that all the samples are being related and this leads to a even simpler graph regression problem.",
            "Overtime varying graphs and we can easily scale that to much bigger problems.",
            "In fact, some versions of this algorithm was already proposed by.",
            "John Lafferty and Larry Wasserman, and so in one of their early code paper, where they deal with continuous Gaussian graphical model estimation, overtime.",
            "And here we have a discrete version over time involving multiple random fields.",
            "OK, so just to keep up the presentation, here is the overall strategy."
        ],
        [
            "We have time specific graphical lasso and then at adjacent timepoint the regression coefficients smoothed by a second regularizer and that is to a constraint convex optimization problem where you have the loss function defined by the regression loss, the smoothness loss and sparsity loss and the Theta coefficients are now bounded.",
            "Bye.",
            "A box constraint or the differences between two adjacent states are bounded by bus constraint.",
            "So once you are here, you are in the in a nice area because there are standard routines in many convex operating software.",
            "To solve this problem.",
            "These are just standard problems in this area."
        ],
        [
            "So you may worry about how good this this algorithms are.",
            "Do we have any theoretical guarantee for these algorithms?",
            "It turns out that proving certain guarantees for these algorithms, even though it is already simplified from the original target model.",
            "Now we're doing regression.",
            "It is still quite man trivial.",
            "So far we've been successful in following what John and Larry date in their continuous version of time varying graph estimation using the kernel window approach, improving that our kernel weighting method for estimating time varying mark random fields.",
            "Having this structure, consistency guarantee OK.",
            "This is actually different from their guarantee and send out here well proving the consistency in the graph structure, not only in the value of the parameters.",
            "But you can see there are some empirical demonstration of.",
            "Suggesting that these bounds is actually meaningful because we actually getting one more samples, meaning that your sample dense and dense you are getting closer and closer to a full recovery.",
            "But we haven't been able to prove anything yet to the test language which is based on one more loss function on the Fusion penalty.",
            "And in fact even the basic few slots or algorithm has not yet been proven to be consistent at this point.",
            "So we're still trying to search for new techniques to to study that phenomenon.",
            "OK, so here."
        ],
        [
            "The algorithm and now let me show you some cool results along this line.",
            "So we get data from these processes.",
            "So there was a scientist who sampled the gene expression profiles from the egg all the way to the adulthood and he got 64 time points and we apply this time points to the algorithm."
        ],
        [
            "We got the following."
        ],
        [
            "Just sequence."
        ],
        [
            "Graphs and."
        ],
        [
            "You"
        ],
        [
            "As you can see that the."
        ],
        [
            "Density of the graph is."
        ],
        [
            "Aging."
        ],
        [
            "Stating"
        ],
        [
            "Along with."
        ],
        [
            "And here is a summary of the graph you got the summaries made, not individual genes, but functional groups of the jeans.",
            "And you can see that the connectivity between the functional groups changing overtime.",
            "So I'm not going to try to attempt interpreting this answer.",
            "This results in here because our focus here is the machine learning problems.",
            "I'm going to quickly go through what you can get out of this results and then move on to the next question.",
            "So here is of course we can get the transient interactions between genes."
        ],
        [
            "You can also visualize collapsing of all the time specific graphs and which makes them into another.",
            "Static graph and they can be demonstrated to have a very different behavior, such as no distributions, clustering coefficients to the static graph.",
            "You get trivially from the ID samples.",
            "You can also."
        ],
        [
            "So inspect the evolution of different network signatures.",
            "Here I just plug some of those curves.",
            "The degree, for example, the clustering coefficient sanso showing some interesting situational effects.",
            "It can be more space."
        ],
        [
            "Sific by asking what are the trends in the subgraphs in this big network and that can hopefully help biologists to ask what are the active pathways that is at work in particular time points during the biological processes.",
            "So these are all the questions I can go through even longer list, but."
        ],
        [
            "Wrap up with some future work and then move on to the second problem so we have an algorithm right now and we are about to apply this algorithm to some real challenging data and to see whether it is biologically meaningful.",
            "But even in addition to that, the algorithm itself is still pretty preliminary and we want to also ask a few more questions on that.",
            "For example, you can view this algorithm as a generic way of estimating dependent graphs or correlated graphs, and the chain of graphs is just one way for the graph to be related, and there are other ways Grafton related.",
            "For example, you could imagine a chain, a tree of graphs, and this correspond to the cell differentiation.",
            "For you have a stem cell in here, and they different differentiated into tissue specific cells.",
            "And every point they correspond to a different network, but since they are built on top of the same set of genes, the network shouldn't be dramatically different, right?",
            "And since you know the differentiation steps, you could use this.",
            "Train this tree to regularize the graph estimation.",
            "There are other problems such as detecting sudden changes in the graph right, and maybe even use this information to help active learning where actually sample get more samples from the processes and so on.",
            "So these are all.",
            "Algorithmics open questions and of course there are a number of theoretical open questions which we've been actively working on which concerned about the consistency, competence and stability and so forth for the estimator.",
            "OK."
        ],
        [
            "I think I finished the first problem.",
            "Any questions before I move on to the second one.",
            "Size of the ground phone number unfortunately."
        ],
        [
            "Point not.",
            "Yeah, that will be again very difficult.",
            "Open problem because once you worry about the size of the graph.",
            "You need to have a birth death process to introduce new nodes and kill old nodes, and that makes the inference problem much harder and so far we haven't really done that.",
            "But of course in this particular setting, you know, once you zoom into a particular Organism.",
            "That their size is not going to change in this.",
            "So we are fine in this context.",
            "Other questions.",
            "If you worry about techniques, how do we actually prove the things, and how do we actually solve the optimization problem?",
            "We should talk about offline 'cause there are a lot of her details underneath which I just swept under the rug.",
            "OK, so maybe given the time, let's quickly move into the second problem, which is again largely open and I would really welcome you to take a close look at this problem so."
        ],
        [
            "It's about structure, input and output learning.",
            "Everybody actually probably knows about this keyword, right?",
            "And we use structured input output.",
            "Learning for machine translation for image segmentation for a number of such tasks, and this problem is also pretty important in biology, as I show in this graph.",
            "So the problem in question is.",
            "Known as Association Analysis of disease genes.",
            "OK, so here is the old picture.",
            "Suppose that I'm the physician and I receive patients from in my clinic and measure his her phenotypes or traits.",
            "Say blood pressure.",
            "Body weights are susceptible to disease and things like that.",
            "And now I focus on one trade.",
            "Say this guy has diabetes or not having diabetes and then once you see enough such.",
            "Individual and also at the same time you collect their genetic sequences and there is a particular sequence called the genetic polymorphism sequences.",
            "Once you have this.",
            "Set of information.",
            "You can do a thing called a social analysis to exam.",
            "Which of these characters in his genome is statistically associated with a particular configuration of his phenotype may be among those people who has the diabetes.",
            "Many percent of the time.",
            "They have a seeing here, but for those normal people they may have a in here, so you can do this very simply by doing a pairwise statistical Association test, another P value and cut threshold, and then you get a conclusion.",
            "But unfortunately this is not.",
            "Real problem is not as simple as that.",
            "First of all, as I said, as a physician, I really don't want to look at only one traits.",
            "I want to collect a whole bunch of trade from this patient if he ever visit my clinic.",
            "Therefore I have a lot of measurements OK, and that turns into a multivariate complex syndrome.",
            "And Secondly, all these traits are not necessarily independent of each other.",
            "Your body weights and your blood pressure may be highly correlated.",
            "And it is unreasonable to just do individual test of each of these to the input features to detect Association.",
            "So and I can name a number of other questions, but that kind of leads us to already the question of how to do structured input output.",
            "So here the input is this what the input is also structured 'cause you're.",
            "Sequences in your Gino are not independent of each other.",
            "There are located on the physical piece of Chromosone and they couldn't swap arbitrarily in their order and all that right?",
            "So this is a structured input.",
            "The output again can be a network of phenotypes, so how can we do Association or causal analysis between these two entity?",
            "So we want to custom as a structured input output learning problem and in particularly want to custom as a sparse structure input operating problem because you really want to have.",
            "A sparse estimation of the causal relationship between these two entities.",
            "And for the reason that will be obviously in the second.",
            "OK, so here I already."
        ],
        [
            "Covered the Gino Anna fields."
        ],
        [
            "Pictures and here I just give you a particular phenotype network that we are working on right now from our collaborators in Pitt Medical School.",
            "So they studied large patient population of asthma and I think they collected 140 phenotypes and by using any simple graph fitting algorithm you can get a network of this and they actually already make sense because some sub graphs correspond to say quality of life and some sub graph.",
            "Respond to long phraseology and all things like that.",
            "And when you are ignoring all these dependencies, you may get a lot of false positive, false negative signals and so."
        ],
        [
            "The problem is as follows, so we have these two alternative way of viewing the problem, the classic away being one phenotype 1 gene and modern view being multiple phenotype, multiple correlated phenotypes and multiple causal genes in the classical setting.",
            "As I said, the standard way will be doing pairwise Association test OK, you ignore the dependencies between all these little slips and the result will be.",
            "You will be having a lot of false positives.",
            "Of course you can have a slightly more elegant way of doing a regression from all these input to the output using whatever regularization technique to make them sparse, but still that seems to be not sufficient.",
            "And here is the typical result people seek right when you do.",
            "Why social test?",
            "You'll see peaks all over the place.",
            "You're very likely to end up with 10,000 peaks or more, which is make the situation you know, feel hopeless to go on.",
            "But even if you do, the regression sparse regression, you get a lot of signals, and actually you may miss some signals because some of the hidden causal structure is causing two elements, not that's one.",
            "And if you analyze the one by one, you may lose that.",
            "And in the modern view, what we are going to propose is to define a new set of problem known as a structured regularised regression, which has the following virtue, as you will see.",
            "So here."
        ],
        [
            "Is just to set up the problem.",
            "The basic setting of the problem is as follows.",
            "We still view the relationship between the genetics between the genome and phenotype as a regression problem.",
            "OK, that's the basic structure.",
            "We have this input.",
            "Each individual are sampled on their genome.",
            "Annual turn out many observations at different locations, and each of them is called a. Geno, type of the polymorphism polymorphism, means that across different individuals they can be different and that differences may or may not cause consequences in the phenotype and the."
        ],
        [
            "Although structure is formulated for simplicity, just as a very simple linear regression, OK, of course you can make it slightly more complicated by adding polynomial terms in here too.",
            "Edit Tutanota at kernel function over there.",
            "That's fine, but in the end the features are related to the output.",
            "Using a linear function.",
            "That's the building block."
        ],
        [
            "And.",
            "People want to first of all address the problem of sparsity, because you're with a second, I'll be back to you in a second.",
            "So this regression problem is different from the kind of regression problem with seeing image or in LP just because of the size of the problem.",
            "Because the human genome contains 3 billion characters and a couple of million of them polymorphic and they should be all kind of features.",
            "OK, and when you have a problem of this size.",
            "You don't want to do linear regression because you will have a lot of false positive signals.",
            "You really want to regularize as best as you can, so lost so is obvious."
        ],
        [
            "Technique that people want to begin with.",
            "You got a question over there.",
            "Yeah OK, it's just the annual miracle representation of the state of the phenotype.",
            "Say you can call your father's genotype to be 0, your mothers to be 0 to be one, and so these are just two variants of the Geno type.",
            "OK, I can call it 10 or 20.",
            "That's fine too.",
            "So the number itself doesn't mean anything OK?",
            "And you can also create a hybrid which is combining your father and your mother's.",
            "If that different gives you a value of two, that's also fine.",
            "Population.",
            "Please know we look at the individuals most of the time.",
            "You could look family but which cannot afford it, OK?",
            "How do they come to 01?",
            "Because you have two chromosomes, right?",
            "I just didn't spend that.",
            "If they are the same in this way and that way I get the right one.",
            "If they are different than concert stage.",
            "But again, that number isn't important.",
            "You just imagine I have some measurement along the genome to be my teacher.",
            "That's all you need to know to set up this problem.",
            "OK, OK, so now sparse regression is the way to go.",
            "And then people also want to capture dependencies because as I said, these features may be tightly coupled.",
            "Coupled means that they may share the same response to a output to a prediction in in terms of using maybe the same beta.",
            "Efficiency and how do we enforce that constraint?",
            "Well, there is a technique called field, so technique where you can based on a known structure of dependencies, group the regression coefficients to force them to take the same value.",
            "OK, and that's called a few slots, so you probably see that already in our earlier network estimation problem where we use also if you so technique.",
            "But again that wasn't a very nice approach becausw.",
            "I know you have to.",
            "Make straw."
        ],
        [
            "Assumptions of the Fusion structure.",
            "For example, the network that the features are dependent must be next to each other, or they must be grouped in a certain way so that you know the group ahead of time.",
            "In in real biological entity, the dependencies between even the inputs are not a static deterministic entity.",
            "OK, maybe in you the two locals are independent of each other because they sense that they always Co occurrent, but in another individual they may not be depend on each other.",
            "And this phenomenon is known as the recombination in a few seconds UNC and therefore the block boundaries of this random variables.",
            "Input can be itself probabilistic.",
            "Then we want to have a more flexible way of encoding the constraints."
        ],
        [
            "OK so here is why it come from.",
            "So you have two chroma zones from your mother, two from the father and each contributes one to make the offspring.",
            "And in one case is you can get this, but sometimes there could be a recombination taking place in the middle.",
            "These two guys are changing material, therefore the offspring are like this.",
            "It's a hybrid from the parents.",
            "Now if you do."
        ],
        [
            "These after multiple generations from the ancestor chromosome, you will see really.",
            "That the defendant chromosomes are a mosaic of some common building blocks.",
            "Suppose that there are causal markers in the region then.",
            "If they are close enough, you can safely argue that they could always being called Co inheriting right, but only if they are far enough.",
            "Chances are something in the middle to be recombined is more likely and you see loss of dependencies among the inputs, But again, this is not a deterministic relationship.",
            "We want to have some more flexible way of encoding these tendency of being recombined.",
            "If they are far away.",
            "And not being recombined, if they are close to each other."
        ],
        [
            "So here."
        ],
        [
            "As a possible approach we can take, we are building on a technique known as a vision variable selection.",
            "Here you have the the predictor you have the response and let's for simplicity.",
            "Imagine the response is just a scalar.",
            "At this point the predictor being a high dimensional covering system and for each of the dimension in the input you have a beta which stands for the regression coefficients and this one of course correspond to the noise.",
            "In the predictor function.",
            "And."
        ],
        [
            "In Beijing regression framework, now we are going to set up some additional structure indicator functions which are denoted by C which says that conditioning on C beta will be active or inactive.",
            "Mean that it will be used or used.",
            "And then 'cause we?",
            "One troll.",
            "And also in the."
        ],
        [
            "In this case, if we assume the markers or the input features are independent each other, then we should see this indicator functions ID.",
            "Therefore they should all follow maybe a Bernoulli distribution for activity.",
            "But if we want to further assume that there are dependencies between all the input predictors, maybe it is reasonable to assume that the activity of the second marker should be dependent on the 1st marker in some way, and that's the basic motivating.",
            "Scenario in the subsequent model."
        ],
        [
            "Well defined, this prior known as the Markov chain prior, where the joint distribution of order seizes following a first order Markovian structure.",
            "OK, and.",
            "So the condition."
        ],
        [
            "Distribution of the next see is dependent on the 1st C and also based on some other input information.",
            "For example, if the two seas are representing to genotypes, states that are far away from each other, then the likelihood of them to be recombined should be reduced, otherwise they should have a higher Commission rate.",
            "So this spirit is captured in this."
        ],
        [
            "Miller, but maybe a graph can."
        ],
        [
            "Display it in a more explicit way so we have our coffee in structure overseas and we have input as the reconnection rates and the distances between the two markers and jointly define a joint distribution of the regression coefficients and you."
        ],
        [
            "Imagine we can keep sampling over this distribution, and in the end do something very similar to."
        ],
        [
            "And in the."
        ],
        [
            "And we have some interesting results that suggesting something right is happening.",
            "So here is a simulation experiment.",
            "We have a true model where some occasional spurts of response taking into effect.",
            "And this burst of responses are reasonably recovered using the block regularised regression.",
            "But the result using that."
        ],
        [
            "If you use."
        ],
        [
            "Independent Bernoulli prior you've got a lot of false positive signals.",
            "And if you further ignore the prior, just do the standard Ridge regression or."
        ],
        [
            "Not so you get again."
        ],
        [
            "A whole lot of other signals, so that's kind of.",
            "Simple validation and more."
        ],
        [
            "Create validation."
        ],
        [
            "Is provided in this detailed precision recall curve study.",
            "Essentially, we found that if you assume a low recombination rate across the genome, meaning that markers likes to be coupled if they are close to each other, then you will see that our algorithm is way above the other algorithm in terms of the Roc curve.",
            "But if your recombination rate become really, really high, mean that at every location were going to recombine that basically destroy the dependency structures among markers.",
            "OK, and as you can imagine that."
        ],
        [
            "Where are the same?",
            "There's no difference between different algorithms."
        ],
        [
            "OK, so.",
            "And here are some real data."
        ],
        [
            "Experiment which I want to skip.",
            "So what I told so far is that now we have a way to capture the structure input where the dependencies between these are not captured, but I still didn't talk about how to take care of the output if my output are multivariate and also dependent on each other, like I draw in this graph.",
            "So here is another approach.",
            "Again, we use the the basic class or structure for input, output mapping, but.",
            "Since there are responses in the output which might be dependent of each other.",
            "We may imagine the following scenario if there is phenotype in here and there is a phenotype here that are strongly correlated, then maybe this coefficient in the simplest case should influence this guy and that guy in the same way.",
            "Right, maybe there are all non zero.",
            "That's the Lestrange scenario.",
            "Most stringent narobi.",
            "They're all of the same value in their beta, right?",
            "So this could be a useful information to further regularize the model, which correspond to putting some more constraints on this beta matrix of regression coefficients."
        ],
        [
            "So here is the step the algorithm.",
            "So imagine that we have these two tightly coupled phenotypes.",
            "And want to do this regression and our approach will be to.",
            "Built a new cost function that is penalizing the Fusion penalty on the output.",
            "So here is the sign of the correlation which just tell you whether they should be of the same value.",
            "Make sure that they are absolute values measured rather than their assigned value.",
            "And then here are the rest are the standard lasso regression loss function and penalty function.",
            "So this called the graph constraint lost, so feels like a big cause.",
            "The constraint function is defined only on those pair of phenotypes which are connected by an edge in the phenotype network.",
            "So this called Network guided fields lasso.",
            "And you may imagine that the network doesn't have to be just the graph.",
            "They may be weighted graph.",
            "Therefore the strength of the coupling can also be used.",
            "Therefore we also have a graph weighted."
        ],
        [
            "Feels lost, all function here where here I have a weighting function F. It could be also designed by arbitrary kernel to reflect the strength of the influence from the weights.",
            "OK, and again after all this.",
            "Will have is still a pretty standard convex optimization problem.",
            "OK, and then we solve that use."
        ],
        [
            "Bing standard package."
        ],
        [
            "And here are some preliminary results.",
            "Say we have a bunch of phenotypes like this.",
            "OK in here for simplicity.",
            "Now I've ignored the dependencies between the inputs.",
            "I'm only worried about the dependencies among the outputs, just for simplicity, so I have a bunch of outputs and this is the correlational structure promoted as a heat map and if I binarize the contribution by a threshold I got this dependency structure.",
            "And I use this to simulate my response.",
            "OK, and I think these are the coefficients.",
            "On each of the phenotype and around this direction, overall the snips.",
            "OK, and so this is a ground truth we want to recover and this is the recovery using E is.",
            "Is the Richard question as soon as you imagine it's it's giving you positive signals all over the place.",
            "F is the lasso, and again you'll see a little bit of cleanup over this one, but again still have a lot of positive signals, and these three graphs are from different versions of the graph.",
            "Guided or graph waited.",
            "Few slots or algorithm and you can see that indeed you get results alot closer to that one.",
            "So the moral here is that you really want to make explicit use of the.",
            "Information already present in your data, such as dependencies between the responses, dependencies between the inputs and dependencies across them to add as many as necessary the constraints on your regression so that you can clean up unnecessary signals.",
            "And that's what we did in here.",
            "And again, you can see a Roc curve over a wide range."
        ],
        [
            "For tuning the regressional coefficients and again the algorithm is dominating over the existing ones."
        ],
        [
            "And we have some real examples.",
            "This is actually a small study on the real asthma data set and we did find some positive interesting signals which are believed to be clinically meaningful.",
            "They are actually looking at these phenotypes, so here you can see I think I have along this dimension or the genotypes.",
            "This dimension of the phenotypes they can see that this subset of phenotypes are sharing a single genotype responses, so that's the signal that is you really missed from a standard unstructured version of the regression.",
            "And again, remember that here I'm also.",
            "Emphasizing sparse structure equation, 'cause we always put a lasso penalty over there to make sure that our output are passing moenius.",
            "And it's nice thing about this approach."
        ],
        [
            "Should I stop here?",
            "Although I have a few more days to go on.",
            "Oh, OK, so since I started OK let me spend 5 more minutes just to wrap up.",
            "OK, so which is actually not very technical, but hopefully give you another insight of the same problem.",
            "So we do have a different solution to the problem I put up just now, although we haven't really apply that yet.",
            "So imagine that in the Regressional framework I talked about so far, we're really doing maximum likelihood estimation or regular sized version of that innocence.",
            "Right, because we really want to make sure that our joint likelihood of the input and output are maximized at our model.",
            "That's kind of the spirit in any regressional framework.",
            "And if you must notice that in recent years there is this trend of learning maximum margin models in machine learning for whatever purpose for SVM.",
            "For maximizing Markov network in structure prediction, can we use that as well for this problem?",
            "What the answer is, yes, you can use a model which are mainly focused on making best possible predictions rather than structure discovery.",
            "OK, for based on maximizing principle.",
            "But you really people use that model really for prediction, so I can make the best passing of the natural language sentences or best segmentation.",
            "But in terms of the Markov network structure, people usually don't pay much attention to that.",
            "It turns out that maybe you can also use that to.",
            "Those strategies cover because the best you predict, you should hope that maybe the structure can become more meaningful.",
            "So what I'm talking about in the next three slides is kind of along that line so I don't have time to go through detail.",
            "But here is a high level message."
        ],
        [
            "Maybe you already saw that in dreams.",
            "Talk in earlier lecture.",
            "So what is the major parroting of margin based distributed learning?",
            "What you see is the couple of the following we have.",
            "The SCM which is learning a single division boundary OK and over binary classification.",
            "And here is a objective function you need to solve for that problem.",
            "And sometimes people may like a more patient treatment of the model.",
            "So invasion prediction you don't do point prediction.",
            "You do model averaging.",
            "You do an expectation over distribution of models, and it turns out that one can do a similar thing here using what is known as the maximum entropy.",
            "This convention framework where you really learn a distribution of.",
            "Of the decision boundary.",
            "So here your prediction is expected over the distribution of the model and that distribution of the model.",
            "The QW can be actually also learned using a very similar function as this, where the loss function is not a KL divergent between your target function and some prior distribution of the weights, and your constraint is no longer.",
            "Data centric point constraint.",
            "It is going to be expectation constraint.",
            "Built on the learned model.",
            "Along the other direction, you can also make the SVM structure using the maximum margin Markov network trick.",
            "In which your prediction is now a arbitrary structured rule based on some discrete function.",
            "So here why is not a class label between 01 and between minus one positive way?",
            "It could be a code labeling sequence of the sentence, but we can again make that prediction as argmax of some linear predictor function, and to learn that.",
            "Wait, you can you know, follow up in Task Force approach and make it as a quadratic programming problem.",
            "OK, based on some maximum budget constraints.",
            "So what we recently workout with Gene is a combination of these two ideas.",
            "We want to model to be both structured and maximizing and also being averaged over multiple models.",
            "And this approach is known as the maximum entropy discrimination.",
            "Markov networks.",
            "It could be understood as the structured version of the Med framework plus some Asian ideas applied on top of the M3 network and in the end."
        ],
        [
            "This is the overall problem you need to solve to get there, you need to apply the structure to maximum entropy.",
            "In principle to set up this optimization problem where you minimize the KL divergences between the distribution of your model and a pretty solution order model plus some Slack function to allow misclassification or mislabeling, and then your constraint should be set so that your learned distribution are satisfying certain constraints.",
            "And the constraints are very similar to the SVM constraint, except that now they are all defined on expected margin rather than just the sample based single margins.",
            "So your margin will be.",
            "Taking average over P of W. And then your prediction is also different.",
            "Your prediction is now no longer based on just the F. The prediction function it is based on a weighted average over the predict function.",
            "Therefore you have a smooth distribution of predictors, some being more likely, something less likely, but your average over all of that and in the end you can expect a more robust predictive room.",
            "And so I think I can ignore this picture at the end of the."
        ],
        [
            "You will get a model which.",
            "Can be solved in close form and that gives you the solution to the model I just mentioned.",
            "Although the actual solution may be more complicated because here your post distribution of the weights are defined by some lounging coefficients which needs to be solved by solving this dual operating problem and we can show that if under certain condition this dual optimization problem can be identical to the one you solve in the maximizing Markov network.",
            "Therefore the answer network.",
            "Can be proved to be a special case of this one, but of course this one can be more general if you choose to use different priors and different loss functions."
        ],
        [
            "OK so here is what I'm trying to say, but at the end of the day, here is the new model with this following three advantages.",
            "First, it is going to be average model rather than a point estimator of the Markov network, and as a result you can prove an ice pack based bound to bound the generation error, and Secondly this model because it uses a prior distribution over the weights.",
            "It turns out that this."
        ],
        [
            "Prior distribution can be a proxy for you to introduce nice behaviors.",
            "For example, you can use it as a entropic regularizer to introduce certain bias if you want the multi sparse.",
            "For example, you can introduce a LA plus prior over the regressional weights over the model weights and in the end you will get a pretty nice shrinkage effect over different dimensions of the model and as a result in the end you will have a model which is nice in the sense that.",
            "Remember we do support vector machine, the major.",
            "Motivation for SVM are two folds.",
            "One is that you have the maximum margin and kernel trick.",
            "The other is that you have the support vectors, right?",
            "You have a few support vectors which makes your model dual sparse and this model of course has door sparsity 'cause you need to solve the support vector machine problem in the dual space.",
            "But in addition to that you have this very nice and Tropic regularizer which also push your solution vector to be primal sparse in the sense that.",
            "Along certain directions.",
            "OK, that type of itself will be pushed to zero to close to 0.",
            "Therefore you enjoy simultaneous dual and primal sparsity using this framework.",
            "And finally, of course it gives you a nicer framework to combine generative model and discrete model 'cause the way you design the prior distribution and the way you design the loss function as a KL between two distributions are able to put probabilities into the framework for designing arbitrary latent structures on top of the predictive models.",
            "OK, so we've been still trying to this is the model we just started to work on and we still have a lot of room on new problems to be tried on this problem and I believe that offers a third angle to the structured input output regression problem.",
            "Talk about and if you're interested again, you're welcome to play with that, even outside of biology could be applied to LP and vision problems as well."
        ],
        [
            "Eric, I'm sorry I had a class that was scheduled to start in this from 10 minutes ago.",
            "It's right time I'm done.",
            "OK, so thanks for here and that's all I'm talking about."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are.",
                    "label": 0
                },
                {
                    "sent": "The Machine Learning Department and we talked about some machine learning challenges in computational biology.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K thanks Steve.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not know where to find all the students.",
                    "label": 0
                },
                {
                    "sent": "It's all here.",
                    "label": 0
                },
                {
                    "sent": "Thanks for showing up.",
                    "label": 0
                },
                {
                    "sent": "So Steve basically asked me to say he said basic.",
                    "label": 0
                },
                {
                    "sent": "Some people, many of you guys are interested in machine learning in biology and he wants me to talk about some applications, some problems.",
                    "label": 0
                },
                {
                    "sent": "But without saying what to talk about.",
                    "label": 0
                },
                {
                    "sent": "So then I figured that.",
                    "label": 0
                },
                {
                    "sent": "Well, I could talk on on four days.",
                    "label": 0
                },
                {
                    "sent": "In fact, I'm going to give a class on computer mix next semester, which is all about this topic.",
                    "label": 0
                },
                {
                    "sent": "But after awhile I thought maybe I should share with you some of the latest project going on in my group that is really integrating some machine learning issues.",
                    "label": 0
                },
                {
                    "sent": "Some open combat problems with some challenging statistical open problems.",
                    "label": 0
                },
                {
                    "sent": "I could also make the talk of our technical but.",
                    "label": 0
                },
                {
                    "sent": "Just to honor the lunch spirit, I guess I'm going to make a little bit lighter of that and hopefully give you just the high level ideas rather than the detailed mathematical derivations and all that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Computational biology, so this area is actually a very old area and the study of quality biology could be as old as the field of statistics.",
                    "label": 0
                },
                {
                    "sent": "But what are the modern challenges right now in Campbell?",
                    "label": 0
                },
                {
                    "sent": "So here is what we are facing, so we are in the era where there are a lot of new inventions that help us to collect lots of biological data.",
                    "label": 0
                },
                {
                    "sent": "And those datas are really complicated, for example that dynamic there are noisy.",
                    "label": 0
                },
                {
                    "sent": "They are heterogeneous.",
                    "label": 0
                },
                {
                    "sent": "And there are high dimension, though it could be a nightmare for a machine learning practitioner if he wants to just grab the off the shelf program and run a single pass and then smell some numbers you could get nothing out of it.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, it could be a dream data set for those people who really want to develop new machine learning methodology or theory.",
                    "label": 0
                },
                {
                    "sent": "And to answer challenging questions, I'm here.",
                    "label": 0
                },
                {
                    "sent": "I actually listed Cup of Criterions viewed to be important.",
                    "label": 0
                },
                {
                    "sent": "If you want to design such algorithms for Campbell problems.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do today is to pick out two particularly interesting new problems that hasn't been heavily studied yet in the field, and I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Mainly presented a problem and some preliminary solutions we had in our group, but I also welcome you to talk to us and if you are interested in working on these problems, either from a biological perspective from a pure statistical machine perspective, there are a lot of opportunities in these areas.",
                    "label": 0
                },
                {
                    "sent": "So the first problem is about inferring.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time varying networks.",
                    "label": 0
                },
                {
                    "sent": "So what this problem is about.",
                    "label": 0
                },
                {
                    "sent": "So here is the rough setting.",
                    "label": 0
                },
                {
                    "sent": "While given a data set which is collected from a time course of maybe some biological processes such as this, development of animal embryo and then we want to figure out what are the time specific networks that is driving the development of biological system in a time specific fashion.",
                    "label": 0
                },
                {
                    "sent": "So why this problem is important?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, nowadays, as I mentioned, we have many techniques of collecting biological information.",
                    "label": 0
                },
                {
                    "sent": "In particular, people want to take a look of the biological regulatory circuitry, incomplete existence, which are often represented by a network, and indeed we have many ways of measuring the linkages of this network in steady state format.",
                    "label": 0
                },
                {
                    "sent": "For example, we can measure the interaction between protein pairs.",
                    "label": 0
                },
                {
                    "sent": "We can measure the currencies of chemical reactions.",
                    "label": 0
                },
                {
                    "sent": "Or we can even directly measure the interaction between some DNA proteins known as transcription factors, which regulates the activity of the genes.",
                    "label": 0
                },
                {
                    "sent": "But most of these reactions are these measurements are taking place under steady state, meaning that you killed animal and you take a measurement.",
                    "label": 0
                },
                {
                    "sent": "And that's for all.",
                    "label": 0
                },
                {
                    "sent": "In the second time, you want to measure again, you lose.",
                    "label": 0
                },
                {
                    "sent": "The system needs to reboot it and measure data central time point, which is not really give you a real time snapshot of the process.",
                    "label": 0
                },
                {
                    "sent": "But biological systems are.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really, dynamical and changing all the time like I show in this picture.",
                    "label": 0
                },
                {
                    "sent": "So this is the evolution of the embryo.",
                    "label": 0
                },
                {
                    "sent": "We are interesting study and nowadays people can actually take a snapshot of the expression of the genes in this embryo, such as you know, here is the expression of a particular gene along the whole development processes and in different locations in a cell.",
                    "label": 0
                },
                {
                    "sent": "So we can do a reasonable job.",
                    "label": 0
                },
                {
                    "sent": "A measuring the intensity of these genes in the system.",
                    "label": 0
                },
                {
                    "sent": "But we couldn't measure whether two genes are interacting or not, because this is not something that can be easily experimented.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have some other systems such as this system which is describing the development of a cancer.",
                    "label": 0
                },
                {
                    "sent": "This particular scientist in Berkeley Development System where she can inject some cancer cells taken from the patient into a virtual system and then after adding some nutritions, this particular subset of population of cells can grow like as if they are in the in the body and grow them into a cancer.",
                    "label": 0
                },
                {
                    "sent": "And then after that stage.",
                    "label": 0
                },
                {
                    "sent": "She can actually inject some other inhibitors or chemicals or things like that and revert the process to turn the whole thing back into normal.",
                    "label": 0
                },
                {
                    "sent": "So ad hoc wise this is a very smart approach that can make you the impression that now you can revert the progression of cancer.",
                    "label": 0
                },
                {
                    "sent": "But now people want to ask why this is happening.",
                    "label": 0
                },
                {
                    "sent": "What is the biological reaction or processes that is underlying the reversal and progression of cancer?",
                    "label": 0
                },
                {
                    "sent": "In a third example, I also have a postdoc who.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interested in studying the inflammatory response in the endo toxicated mice where she can also inject some toxicities into this miles and then wait for a few days until it dies and then take samples from not only different time points but also different organs in this animal and you can imagine that the regulatory events in different time and in different cellular system like tissue and organs could be quite different from each other and it's writable.",
                    "label": 0
                },
                {
                    "sent": "Assume that you can have a single network that take care of all of this, so that's the problem we.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Until now, really ask a bigger picture question as the following.",
                    "label": 0
                },
                {
                    "sent": "So what is the path without his active under certain extracellular stimuli under certain point of dynamic processes?",
                    "label": 1
                },
                {
                    "sent": "For example, how does this network response to a mental condition or under drug treatment or things like that?",
                    "label": 0
                },
                {
                    "sent": "So all these really points you to the key issue about connecting estimate or inference condition specific topological structure among entities such as jeans so.",
                    "label": 0
                },
                {
                    "sent": "Has this problem been addressed well?",
                    "label": 0
                },
                {
                    "sent": "To some degree, yes.",
                    "label": 0
                },
                {
                    "sent": "People have been inventing some classical method to answer problem similar to this.",
                    "label": 0
                },
                {
                    "sent": "So here is a possible strategy.",
                    "label": 0
                },
                {
                    "sent": "So I have the time.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Iris data, and now I say I want to estimate a network of it.",
                    "label": 0
                },
                {
                    "sent": "What would be the most straightforward will do it?",
                    "label": 0
                },
                {
                    "sent": "Well, in the literature you can find the keyword Bayesian network and how Bayesian network can be applied to this problem.",
                    "label": 0
                },
                {
                    "sent": "Well, you assume that all these examples, which is a high dimensional measurement of maybe 10,000 genes as ID samples from a distribution defined by the Bayesian network.",
                    "label": 0
                },
                {
                    "sent": "You put some put together and then you do a maximum likelihood estimation.",
                    "label": 0
                },
                {
                    "sent": "And the structure learning to get this network.",
                    "label": 0
                },
                {
                    "sent": "So that's one approach, but you need to realize that this gives you a static network which really ignore the differences of topology under different time points.",
                    "label": 0
                },
                {
                    "sent": "You may also heard that people use another model known as a dynamic Bayesian networks, right?",
                    "label": 0
                },
                {
                    "sent": "And makes you feel that all OK. Now I can carry, take care of dynamics, but what is a dynamic Bayesian network?",
                    "label": 0
                },
                {
                    "sent": "It is actually not quite dynamic 'cause what you do with the dynamic Bayesian network is to now put together not.",
                    "label": 0
                },
                {
                    "sent": "Single time snapshots of the gene expression but pairwise snapshots of gene expressions.",
                    "label": 0
                },
                {
                    "sent": "You put every pair of measurement as ID.",
                    "label": 0
                },
                {
                    "sent": "Examples of a stationary transition model defined by the Bayesian network or by the Dynamic Bayesian network, and you do an estimation of the graph structure and the transition model based on ID samples of time slices.",
                    "label": 0
                },
                {
                    "sent": "OK, any end you get a model like this which defines you the conditional probability distribution of gene expression at time T given time T -- 1 and the conditional distribution is defined by the graph.",
                    "label": 0
                },
                {
                    "sent": "But that graph is invariant overtime.",
                    "label": 0
                },
                {
                    "sent": "Therefore your Bayesian network model is a stationary model that is structurally not time invariant.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are the problem.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they are not quite sufficient to address our goal for estimating time specific graphs, which may gives you information about what interaction is active under certain timepoint.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to devise a. Algorithm that kind of reverse engineer temporal or maybe even spatial specific rewiring of the gene network.",
                    "label": 0
                },
                {
                    "sent": "And again here is the context we want to, you know, use this data to estimate a sequence of graphs which may have time specific.",
                    "label": 0
                },
                {
                    "sent": "Top apologies.",
                    "label": 0
                },
                {
                    "sent": "OK, well if you look at this problem naively, you may notice that you may feel that this is really a you defined problem because of what what?",
                    "label": 0
                },
                {
                    "sent": "Because if you really believe that.",
                    "label": 0
                },
                {
                    "sent": "Network are time specific and each time point you get a unique network underlying example then you will face this issue.",
                    "label": 0
                },
                {
                    "sent": "You look at time, .1 of T and you'll see why example and that correspond to a particular graph.",
                    "label": 0
                },
                {
                    "sent": "How can you estimate a graph from only one example of observation, right?",
                    "label": 0
                },
                {
                    "sent": "Because the next time you make measure, it's going to be at a different time and your graph is changing already, so this is the email defined statistical problem.",
                    "label": 0
                },
                {
                    "sent": "So what I'm hoping at the end of the day is that after this talk, hopefully you can realize that there is a way to slightly relax this problem so that the problem can be approached using some simple statistical approaches.",
                    "label": 0
                },
                {
                    "sent": "And here is the high level idea.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's imagine that now we are dealing with a sequence of networks that is changing overtime, but the networks are not changing entirely randomly.",
                    "label": 0
                },
                {
                    "sent": "Overtime in the sense that it is going to follow a evolution model which govern the way graph is changing in a way that they don't change much overtime.",
                    "label": 0
                },
                {
                    "sent": "They may follow specific dynamics to allow maybe 5% of the edges, or maybe 1% of the edges changing overtime and for the remaining 95% of the edges they're going to be.",
                    "label": 0
                },
                {
                    "sent": "Recurring overtime and therefore all the samples can be reused to estimate that part of the graph.",
                    "label": 0
                },
                {
                    "sent": "So that's the high level idea.",
                    "label": 0
                },
                {
                    "sent": "So if you want to be more formal, you can write down a transition model over graph evolution as a what is known as the temporal expansion graph model originally worked out by Steve in my group.",
                    "label": 0
                },
                {
                    "sent": "And here you just know right down the conditional distribution of a graph at T given a graph at T -- 1 using a log linear model defined by some potential functions over graph characteristics.",
                    "label": 0
                },
                {
                    "sent": "And I will be specific about what those characters can be in a second.",
                    "label": 0
                },
                {
                    "sent": "And then after that you can also hang off the graph some observations using an emission model much like the way you deal with the hidden Markov model, and they can be a complicated model to define the node observations.",
                    "label": 0
                },
                {
                    "sent": "Conditioning on the topology of the graph OK, after all this has been set up.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have infinite computing power.",
                    "label": 0
                },
                {
                    "sent": "You can now ask the question of what is the conditional distribution of a particular node or particular graph at a particular time.",
                    "label": 0
                },
                {
                    "sent": "Given that entire observation and marginalized out all the other graph, I don't care about, so this is like the forward backward algorithm in hidden Markov model, except that now the state space in here is huge.",
                    "label": 0
                },
                {
                    "sent": "OK, it is the state space of the entire topological structure of the graph, so that's kind of the major setting.",
                    "label": 0
                },
                {
                    "sent": "By using this assumption, we cannot at least formulate the problem that is estimating time specific graphs based on entire samples, just to say a few more words about such a model.",
                    "label": 0
                },
                {
                    "sent": "For example, the transition model can.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Defined on arbitrary design of dynamic potentials and potentials can be, say, continuity potential.",
                    "label": 0
                },
                {
                    "sent": "Say the graph is not changing much overtime, the graph is following a reciprocity that makes say if I contact you the first time, you need to return me a call the second time, or transitivity.",
                    "label": 0
                },
                {
                    "sent": "If I call you, you call the other guy I'm going to call the other guy the next time, and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "You can be very flexibly designing this, and there are standard way to estimate.",
                    "label": 0
                },
                {
                    "sent": "Weights of all these potential.",
                    "label": 0
                },
                {
                    "sent": "If you are given full observations of the sequence of graphs and that has been shown in one of.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Early papers.",
                    "label": 0
                },
                {
                    "sent": "And they.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's another nice property of this model which is known as nondegeneracy, which says that this graph is defining this distribution.",
                    "label": 0
                },
                {
                    "sent": "Is defining a well behaving distribution of the temporal sequence of graphs in the sense that it is not.",
                    "label": 0
                },
                {
                    "sent": "Having an abnormal concentration of the probabilistic mass over just a few graph configuration but non probability mass over other configurations.",
                    "label": 0
                },
                {
                    "sent": "So this property is called degeneracy.",
                    "label": 0
                },
                {
                    "sent": "Let's for this interest Timeskip order theory, but what is the virtue of that?",
                    "label": 0
                },
                {
                    "sent": "The virtue of that is that after you see a few examples of this graph, the maximum likelihood estimation exists and can be obtained from the data.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, if you have a degenerate distribution, it can happen that if even if you observe infinite data, you can still not estimate the parameters of the graph.",
                    "label": 0
                },
                {
                    "sent": "So this is just to give you a safeguard of the legitimacy of this model.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we have a model.",
                    "label": 0
                },
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "Is that we can do a number of things you can do hypothesis testing, say I write down a graph evolution model.",
                    "label": 0
                },
                {
                    "sent": "Then I'm observing this graph evolution sequences.",
                    "label": 0
                },
                {
                    "sent": "Is this sequence generated from my model or otherwise?",
                    "label": 0
                },
                {
                    "sent": "So I handle this test.",
                    "label": 0
                },
                {
                    "sent": "I can do clustering of the nodes based on someone like this, But in this case I'm going to talk about one more specific application of this model, which is to learn the latent.",
                    "label": 0
                },
                {
                    "sent": "Sequence of graph that is not observed from only data.",
                    "label": 0
                },
                {
                    "sent": "So as I said, current approaches are mainly assuming time invariant structures and algorithms based on structural them or things like that are usually not globally optimal and also there isn't any known results.",
                    "label": 0
                },
                {
                    "sent": "Or maybe there are not too much known results on guarantees on these algorithms and algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you in a second hopefully offer you some progress along these directions.",
                    "label": 0
                },
                {
                    "sent": "So here is the model of the Prob.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, just to reiterate, we have a sequence of observations and we want to estimate time specific sequence of graphs.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can make this problem a little bit more relaxed by assuming that the graphs are evolving over every airports rather than over every time point, so that for this few time points we have the same graph and we have multiple solutions.",
                    "label": 0
                },
                {
                    "sent": "But in any case the number of revisions won't be more big enough to make a estimation without using other sample.",
                    "label": 0
                },
                {
                    "sent": "OK. And so.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the first algorithm, which is again the thing you can do.",
                    "label": 0
                },
                {
                    "sent": "First thing I think about we have this graphical model which is look like a HMM.",
                    "label": 0
                },
                {
                    "sent": "Why don't we just do what we do in?",
                    "label": 0
                },
                {
                    "sent": "Hmm, maybe we don't even want to think about forward backward because of the state space is too big.",
                    "label": 0
                },
                {
                    "sent": "Let's do sampling so we can.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ask a query what is the conditional distribution of having changed a particular edge in the graph given the Markov blanket of this entire random variable.",
                    "label": 0
                },
                {
                    "sent": "OK, so that proposed distribution can be written down in this complicated form, and in this form you need to do a number of non trivial things.",
                    "label": 0
                },
                {
                    "sent": "First you need to compute the ratio between the partition functions.",
                    "label": 0
                },
                {
                    "sent": "Related to this, node and partition functions has to be computed for every different configurations of this node.",
                    "label": 0
                },
                {
                    "sent": "Remember that you are not proposing a new edge or removing an edge.",
                    "label": 0
                },
                {
                    "sent": "You need to recompute the partition function, and that's going to be very complicated if you need to do it every time you sample a edge, right?",
                    "label": 0
                },
                {
                    "sent": "And there are some other complications, and at the end of the day we found this algorithm to be extremely efficient.",
                    "label": 0
                },
                {
                    "sent": "In fact, we can only scale this algorithm to about 20 nodes, and but nevertheless.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The result wasn't bad if we can wait long enough, and being patient enough, we found that this time varying graph inference problem is indeed well defined.",
                    "label": 0
                },
                {
                    "sent": "Unsolvable OK. For example here I have a few simulations which are simulated from a known time evolving graph model where the heater controls the degree of change.",
                    "label": 0
                },
                {
                    "sent": "Overtime of the graph topology and the Theta is the degree of consistency between the observation and.",
                    "label": 0
                },
                {
                    "sent": "Apology, so moving from that direction to this one.",
                    "label": 0
                },
                {
                    "sent": "The graph is more dramatically evolving overtime, making the problem more difficult to estimate and going downward.",
                    "label": 0
                },
                {
                    "sent": "You have less and less consistency between the data and the model.",
                    "label": 0
                },
                {
                    "sent": "Therefore the problem can also be difficult, but in the end when applying the Gibbs sampling algorithm I just described which are supposedly doing exact inference, you can actually get a pretty good recovery of the graph topology in small setting.",
                    "label": 0
                },
                {
                    "sent": "So here I compare.",
                    "label": 0
                },
                {
                    "sent": "Our algorithm with a few other ways of solving the problem.",
                    "label": 0
                },
                {
                    "sent": "So what are these other ways?",
                    "label": 0
                },
                {
                    "sent": "Well, there isn't actually anything to compare with because there isn't any other algorithm that does time specific network recovery.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can do best is to assume that I'm going to recover a single graph out of the entire sequences as people do and then compare out of this single graph how many edges are actually appearing over the history of the graph evolution, right?",
                    "label": 0
                },
                {
                    "sent": "So this is the result in here, which is pretty poor.",
                    "label": 0
                },
                {
                    "sent": "OK, and what is the 2nd bar?",
                    "label": 0
                },
                {
                    "sent": "Second bar is what we know what we call the static ground truth.",
                    "label": 0
                },
                {
                    "sent": "Which means that well, I know that inference is itself a hard problem.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that we can do perfect inference.",
                    "label": 0
                },
                {
                    "sent": "What we make perfect inference?",
                    "label": 0
                },
                {
                    "sent": "Well, since I simulate the graph, actually record all the graph topology already.",
                    "label": 0
                },
                {
                    "sent": "That's the ground truth.",
                    "label": 0
                },
                {
                    "sent": "What if I can actually get the ground truth and then I want to extract a single graph out of it.",
                    "label": 0
                },
                {
                    "sent": "All I can do is to superimpose all these two graphs at each time point and get a single graph.",
                    "label": 0
                },
                {
                    "sent": "Then out of that single graph.",
                    "label": 0
                },
                {
                    "sent": "How many edges are actually true?",
                    "label": 0
                },
                {
                    "sent": "And again, this is below what we can estimate from a time invariant graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the first algorithm which is just presented here for the sake of completeness, because it is not going to be algorithm this really feasible for real scale inference because the size of the graph is only in this case.",
                    "label": 0
                },
                {
                    "sent": "I believe 20 nodes.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second algorithm, which we hope to be able to scale to a real size problem, is based on a recent technique known as a graph regression.",
                    "label": 0
                },
                {
                    "sent": "So what is graph regression?",
                    "label": 0
                },
                {
                    "sent": "Well, when people want to learn specific graphical models such as Gaussian graphical model, a graphical model Michael Random Fields, recently there has been this algorithm proposed for answering that task.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine the problem of learning a graph to be a task that is defined sequentially over each node in terms of learning the neighborhood of every node in the graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so say I have this eight node and I want to learn a graph out of it.",
                    "label": 0
                },
                {
                    "sent": "One strategy says that you can now imagine I focus on this node and figure out the neighborhood of this node under in the original graph, and that can be casted as a. Regression problem.",
                    "label": 0
                },
                {
                    "sent": "Either a logistic linear regression or a logistic regression, depending on whether you worry about the continuous graph or discrete graph.",
                    "label": 0
                },
                {
                    "sent": "And since we want to have the graph to be sparse.",
                    "label": 0
                },
                {
                    "sent": "Do to you know Interpretational reason or consistency guarantee we can put a L1 regularizer to make it a lot.",
                    "label": 0
                },
                {
                    "sent": "Sorry question.",
                    "label": 0
                },
                {
                    "sent": "So we do last.",
                    "label": 0
                },
                {
                    "sent": "So over all other nodes with respect to OneNote.",
                    "label": 0
                },
                {
                    "sent": "And as you know, under authority question, the irrelevant nodes will have their weights pushing to push this zero.",
                    "label": 0
                },
                {
                    "sent": "Therefore we can now Thresh hold it and obtain the true edges related this related this particular node tool neighborhood, and then we do the same for the other node.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the end we can actually get a full graph estimation, right?",
                    "label": 0
                },
                {
                    "sent": "So this is accuracy is known as the graph, so it has a number of nice properties, including the exit to the consistency properties under a particular condition.",
                    "label": 0
                },
                {
                    "sent": "So we want to.",
                    "label": 0
                },
                {
                    "sent": "Ask whether this technique can be extended to estimating time specific graphs, so here is.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A possible proposal.",
                    "label": 0
                },
                {
                    "sent": "The second algorithm is known as the test logarithm.",
                    "label": 0
                },
                {
                    "sent": "It stands for temporary smooth L1 regularised logistic regression.",
                    "label": 0
                },
                {
                    "sent": "Which is really very similar to what you saw just now in graphical, so OK, so here is the cost function.",
                    "label": 0
                },
                {
                    "sent": "Now instead of estimating the neighborhood of a node at a particular time point, I'm going to estimate the neighborhood of this node I over every time point in my sequence and therefore my loss function of course will be the Las Olas, the regression loss function over every time point.",
                    "label": 0
                },
                {
                    "sent": "And every at every time point.",
                    "label": 0
                },
                {
                    "sent": "Of course, I have a different graph.",
                    "label": 0
                },
                {
                    "sent": "Therefore they have their unique coefficients in a regression standing for the structure at that time, and I'm going to give it L1 regularizer to make it sparse.",
                    "label": 0
                },
                {
                    "sent": "But then, because I'm now assuming that the graphs are evolving overtime and therefore they are not completely independent overtime, one of the safe assumption or convenient assumption I can make is to assume that they really don't change overtime in the sense that their graph regressional coefficients are stable or not.",
                    "label": 0
                },
                {
                    "sent": "Changing overtime or smooth overtime.",
                    "label": 0
                },
                {
                    "sent": "Therefore, I have this total variation cost function which is defined over the differences between the regression coefficient at.",
                    "label": 0
                },
                {
                    "sent": "Sometime point.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to do that for every adjacent time point.",
                    "label": 0
                },
                {
                    "sent": "And here is the regularization coefficient.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is, you know, a convex program and you can turn it into a constraint convex option problem using like running duality.",
                    "label": 0
                },
                {
                    "sent": "And there are standard solvers to solve this problem, and it's actually pretty efficient and we can now scale the algorithm to about 5000 nodes.",
                    "label": 0
                },
                {
                    "sent": "Not bad, it's pretty convenient and simple approach, but to solve very nontrivial problem well.",
                    "label": 0
                },
                {
                    "sent": "It turns out that these 5000 nodes is barely enough to cover a small species such as East, which contain which happened to contain 5000 genes.",
                    "label": 0
                },
                {
                    "sent": "When we want to do.",
                    "label": 0
                },
                {
                    "sent": "More complicated genome, such as the genome of human ultra software.",
                    "label": 0
                },
                {
                    "sent": "We have about 20,000 genes or even more than that and this algorithm stop to behave nicely in a problem as big as that.",
                    "label": 0
                },
                {
                    "sent": "It could end up waiting for weeks to see any number out of it.",
                    "label": 0
                },
                {
                    "sent": "So we decide to also go through maybe another round of relaxation to make the problem even simpler.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, the third algorithm is known as the kernel weighting.",
                    "label": 0
                },
                {
                    "sent": "Approach for Grapher equation which is even more similar to the standard graph regression, except that now you use the samples in the smarter way.",
                    "label": 0
                },
                {
                    "sent": "OK, look at that.",
                    "label": 0
                },
                {
                    "sent": "So here we have the regressional loss function we have the L1 penalty over the coefficients but now since I'm going to estimate time specific graphs using all the examples in my time series, what I'm going to do is that if I'm focusing on time T, I'm going to assume that.",
                    "label": 0
                },
                {
                    "sent": "Since the graph is not changing overtime, therefore my nearby samples should contribute to my estimator of this graph in some way.",
                    "label": 0
                },
                {
                    "sent": "OK, and the way they contribute that maybe we can wait their importance and then treat them as if they are sample from the same distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is a strategy I'm going to write down the regressional loss function over every time point, but for those time points which are different from my point of question, I'm going to give it a kernel relating.",
                    "label": 0
                },
                {
                    "sent": "Function on top of that, the further this time point is away from the lower the weight it is and after this treatment effectively dealing with ID samples except that all the samples are being related and this leads to a even simpler graph regression problem.",
                    "label": 0
                },
                {
                    "sent": "Overtime varying graphs and we can easily scale that to much bigger problems.",
                    "label": 0
                },
                {
                    "sent": "In fact, some versions of this algorithm was already proposed by.",
                    "label": 0
                },
                {
                    "sent": "John Lafferty and Larry Wasserman, and so in one of their early code paper, where they deal with continuous Gaussian graphical model estimation, overtime.",
                    "label": 0
                },
                {
                    "sent": "And here we have a discrete version over time involving multiple random fields.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to keep up the presentation, here is the overall strategy.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have time specific graphical lasso and then at adjacent timepoint the regression coefficients smoothed by a second regularizer and that is to a constraint convex optimization problem where you have the loss function defined by the regression loss, the smoothness loss and sparsity loss and the Theta coefficients are now bounded.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "A box constraint or the differences between two adjacent states are bounded by bus constraint.",
                    "label": 0
                },
                {
                    "sent": "So once you are here, you are in the in a nice area because there are standard routines in many convex operating software.",
                    "label": 0
                },
                {
                    "sent": "To solve this problem.",
                    "label": 0
                },
                {
                    "sent": "These are just standard problems in this area.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you may worry about how good this this algorithms are.",
                    "label": 0
                },
                {
                    "sent": "Do we have any theoretical guarantee for these algorithms?",
                    "label": 0
                },
                {
                    "sent": "It turns out that proving certain guarantees for these algorithms, even though it is already simplified from the original target model.",
                    "label": 0
                },
                {
                    "sent": "Now we're doing regression.",
                    "label": 0
                },
                {
                    "sent": "It is still quite man trivial.",
                    "label": 0
                },
                {
                    "sent": "So far we've been successful in following what John and Larry date in their continuous version of time varying graph estimation using the kernel window approach, improving that our kernel weighting method for estimating time varying mark random fields.",
                    "label": 0
                },
                {
                    "sent": "Having this structure, consistency guarantee OK.",
                    "label": 0
                },
                {
                    "sent": "This is actually different from their guarantee and send out here well proving the consistency in the graph structure, not only in the value of the parameters.",
                    "label": 0
                },
                {
                    "sent": "But you can see there are some empirical demonstration of.",
                    "label": 0
                },
                {
                    "sent": "Suggesting that these bounds is actually meaningful because we actually getting one more samples, meaning that your sample dense and dense you are getting closer and closer to a full recovery.",
                    "label": 0
                },
                {
                    "sent": "But we haven't been able to prove anything yet to the test language which is based on one more loss function on the Fusion penalty.",
                    "label": 0
                },
                {
                    "sent": "And in fact even the basic few slots or algorithm has not yet been proven to be consistent at this point.",
                    "label": 0
                },
                {
                    "sent": "So we're still trying to search for new techniques to to study that phenomenon.",
                    "label": 0
                },
                {
                    "sent": "OK, so here.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The algorithm and now let me show you some cool results along this line.",
                    "label": 0
                },
                {
                    "sent": "So we get data from these processes.",
                    "label": 0
                },
                {
                    "sent": "So there was a scientist who sampled the gene expression profiles from the egg all the way to the adulthood and he got 64 time points and we apply this time points to the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We got the following.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just sequence.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphs and.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you can see that the.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Density of the graph is.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Aging.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stating",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Along with.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is a summary of the graph you got the summaries made, not individual genes, but functional groups of the jeans.",
                    "label": 0
                },
                {
                    "sent": "And you can see that the connectivity between the functional groups changing overtime.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to try to attempt interpreting this answer.",
                    "label": 0
                },
                {
                    "sent": "This results in here because our focus here is the machine learning problems.",
                    "label": 0
                },
                {
                    "sent": "I'm going to quickly go through what you can get out of this results and then move on to the next question.",
                    "label": 0
                },
                {
                    "sent": "So here is of course we can get the transient interactions between genes.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also visualize collapsing of all the time specific graphs and which makes them into another.",
                    "label": 0
                },
                {
                    "sent": "Static graph and they can be demonstrated to have a very different behavior, such as no distributions, clustering coefficients to the static graph.",
                    "label": 0
                },
                {
                    "sent": "You get trivially from the ID samples.",
                    "label": 0
                },
                {
                    "sent": "You can also.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So inspect the evolution of different network signatures.",
                    "label": 0
                },
                {
                    "sent": "Here I just plug some of those curves.",
                    "label": 0
                },
                {
                    "sent": "The degree, for example, the clustering coefficient sanso showing some interesting situational effects.",
                    "label": 0
                },
                {
                    "sent": "It can be more space.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sific by asking what are the trends in the subgraphs in this big network and that can hopefully help biologists to ask what are the active pathways that is at work in particular time points during the biological processes.",
                    "label": 0
                },
                {
                    "sent": "So these are all the questions I can go through even longer list, but.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wrap up with some future work and then move on to the second problem so we have an algorithm right now and we are about to apply this algorithm to some real challenging data and to see whether it is biologically meaningful.",
                    "label": 0
                },
                {
                    "sent": "But even in addition to that, the algorithm itself is still pretty preliminary and we want to also ask a few more questions on that.",
                    "label": 0
                },
                {
                    "sent": "For example, you can view this algorithm as a generic way of estimating dependent graphs or correlated graphs, and the chain of graphs is just one way for the graph to be related, and there are other ways Grafton related.",
                    "label": 0
                },
                {
                    "sent": "For example, you could imagine a chain, a tree of graphs, and this correspond to the cell differentiation.",
                    "label": 0
                },
                {
                    "sent": "For you have a stem cell in here, and they different differentiated into tissue specific cells.",
                    "label": 0
                },
                {
                    "sent": "And every point they correspond to a different network, but since they are built on top of the same set of genes, the network shouldn't be dramatically different, right?",
                    "label": 0
                },
                {
                    "sent": "And since you know the differentiation steps, you could use this.",
                    "label": 0
                },
                {
                    "sent": "Train this tree to regularize the graph estimation.",
                    "label": 0
                },
                {
                    "sent": "There are other problems such as detecting sudden changes in the graph right, and maybe even use this information to help active learning where actually sample get more samples from the processes and so on.",
                    "label": 0
                },
                {
                    "sent": "So these are all.",
                    "label": 0
                },
                {
                    "sent": "Algorithmics open questions and of course there are a number of theoretical open questions which we've been actively working on which concerned about the consistency, competence and stability and so forth for the estimator.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think I finished the first problem.",
                    "label": 0
                },
                {
                    "sent": "Any questions before I move on to the second one.",
                    "label": 0
                },
                {
                    "sent": "Size of the ground phone number unfortunately.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Point not.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that will be again very difficult.",
                    "label": 0
                },
                {
                    "sent": "Open problem because once you worry about the size of the graph.",
                    "label": 0
                },
                {
                    "sent": "You need to have a birth death process to introduce new nodes and kill old nodes, and that makes the inference problem much harder and so far we haven't really done that.",
                    "label": 0
                },
                {
                    "sent": "But of course in this particular setting, you know, once you zoom into a particular Organism.",
                    "label": 0
                },
                {
                    "sent": "That their size is not going to change in this.",
                    "label": 0
                },
                {
                    "sent": "So we are fine in this context.",
                    "label": 0
                },
                {
                    "sent": "Other questions.",
                    "label": 0
                },
                {
                    "sent": "If you worry about techniques, how do we actually prove the things, and how do we actually solve the optimization problem?",
                    "label": 0
                },
                {
                    "sent": "We should talk about offline 'cause there are a lot of her details underneath which I just swept under the rug.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe given the time, let's quickly move into the second problem, which is again largely open and I would really welcome you to take a close look at this problem so.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's about structure, input and output learning.",
                    "label": 0
                },
                {
                    "sent": "Everybody actually probably knows about this keyword, right?",
                    "label": 0
                },
                {
                    "sent": "And we use structured input output.",
                    "label": 0
                },
                {
                    "sent": "Learning for machine translation for image segmentation for a number of such tasks, and this problem is also pretty important in biology, as I show in this graph.",
                    "label": 0
                },
                {
                    "sent": "So the problem in question is.",
                    "label": 0
                },
                {
                    "sent": "Known as Association Analysis of disease genes.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is the old picture.",
                    "label": 0
                },
                {
                    "sent": "Suppose that I'm the physician and I receive patients from in my clinic and measure his her phenotypes or traits.",
                    "label": 0
                },
                {
                    "sent": "Say blood pressure.",
                    "label": 0
                },
                {
                    "sent": "Body weights are susceptible to disease and things like that.",
                    "label": 0
                },
                {
                    "sent": "And now I focus on one trade.",
                    "label": 0
                },
                {
                    "sent": "Say this guy has diabetes or not having diabetes and then once you see enough such.",
                    "label": 0
                },
                {
                    "sent": "Individual and also at the same time you collect their genetic sequences and there is a particular sequence called the genetic polymorphism sequences.",
                    "label": 0
                },
                {
                    "sent": "Once you have this.",
                    "label": 0
                },
                {
                    "sent": "Set of information.",
                    "label": 0
                },
                {
                    "sent": "You can do a thing called a social analysis to exam.",
                    "label": 0
                },
                {
                    "sent": "Which of these characters in his genome is statistically associated with a particular configuration of his phenotype may be among those people who has the diabetes.",
                    "label": 0
                },
                {
                    "sent": "Many percent of the time.",
                    "label": 0
                },
                {
                    "sent": "They have a seeing here, but for those normal people they may have a in here, so you can do this very simply by doing a pairwise statistical Association test, another P value and cut threshold, and then you get a conclusion.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately this is not.",
                    "label": 0
                },
                {
                    "sent": "Real problem is not as simple as that.",
                    "label": 0
                },
                {
                    "sent": "First of all, as I said, as a physician, I really don't want to look at only one traits.",
                    "label": 0
                },
                {
                    "sent": "I want to collect a whole bunch of trade from this patient if he ever visit my clinic.",
                    "label": 0
                },
                {
                    "sent": "Therefore I have a lot of measurements OK, and that turns into a multivariate complex syndrome.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, all these traits are not necessarily independent of each other.",
                    "label": 0
                },
                {
                    "sent": "Your body weights and your blood pressure may be highly correlated.",
                    "label": 0
                },
                {
                    "sent": "And it is unreasonable to just do individual test of each of these to the input features to detect Association.",
                    "label": 0
                },
                {
                    "sent": "So and I can name a number of other questions, but that kind of leads us to already the question of how to do structured input output.",
                    "label": 0
                },
                {
                    "sent": "So here the input is this what the input is also structured 'cause you're.",
                    "label": 0
                },
                {
                    "sent": "Sequences in your Gino are not independent of each other.",
                    "label": 0
                },
                {
                    "sent": "There are located on the physical piece of Chromosone and they couldn't swap arbitrarily in their order and all that right?",
                    "label": 0
                },
                {
                    "sent": "So this is a structured input.",
                    "label": 0
                },
                {
                    "sent": "The output again can be a network of phenotypes, so how can we do Association or causal analysis between these two entity?",
                    "label": 0
                },
                {
                    "sent": "So we want to custom as a structured input output learning problem and in particularly want to custom as a sparse structure input operating problem because you really want to have.",
                    "label": 0
                },
                {
                    "sent": "A sparse estimation of the causal relationship between these two entities.",
                    "label": 0
                },
                {
                    "sent": "And for the reason that will be obviously in the second.",
                    "label": 0
                },
                {
                    "sent": "OK, so here I already.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Covered the Gino Anna fields.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pictures and here I just give you a particular phenotype network that we are working on right now from our collaborators in Pitt Medical School.",
                    "label": 0
                },
                {
                    "sent": "So they studied large patient population of asthma and I think they collected 140 phenotypes and by using any simple graph fitting algorithm you can get a network of this and they actually already make sense because some sub graphs correspond to say quality of life and some sub graph.",
                    "label": 0
                },
                {
                    "sent": "Respond to long phraseology and all things like that.",
                    "label": 0
                },
                {
                    "sent": "And when you are ignoring all these dependencies, you may get a lot of false positive, false negative signals and so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is as follows, so we have these two alternative way of viewing the problem, the classic away being one phenotype 1 gene and modern view being multiple phenotype, multiple correlated phenotypes and multiple causal genes in the classical setting.",
                    "label": 0
                },
                {
                    "sent": "As I said, the standard way will be doing pairwise Association test OK, you ignore the dependencies between all these little slips and the result will be.",
                    "label": 0
                },
                {
                    "sent": "You will be having a lot of false positives.",
                    "label": 0
                },
                {
                    "sent": "Of course you can have a slightly more elegant way of doing a regression from all these input to the output using whatever regularization technique to make them sparse, but still that seems to be not sufficient.",
                    "label": 0
                },
                {
                    "sent": "And here is the typical result people seek right when you do.",
                    "label": 0
                },
                {
                    "sent": "Why social test?",
                    "label": 0
                },
                {
                    "sent": "You'll see peaks all over the place.",
                    "label": 0
                },
                {
                    "sent": "You're very likely to end up with 10,000 peaks or more, which is make the situation you know, feel hopeless to go on.",
                    "label": 0
                },
                {
                    "sent": "But even if you do, the regression sparse regression, you get a lot of signals, and actually you may miss some signals because some of the hidden causal structure is causing two elements, not that's one.",
                    "label": 0
                },
                {
                    "sent": "And if you analyze the one by one, you may lose that.",
                    "label": 0
                },
                {
                    "sent": "And in the modern view, what we are going to propose is to define a new set of problem known as a structured regularised regression, which has the following virtue, as you will see.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is just to set up the problem.",
                    "label": 0
                },
                {
                    "sent": "The basic setting of the problem is as follows.",
                    "label": 0
                },
                {
                    "sent": "We still view the relationship between the genetics between the genome and phenotype as a regression problem.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the basic structure.",
                    "label": 0
                },
                {
                    "sent": "We have this input.",
                    "label": 0
                },
                {
                    "sent": "Each individual are sampled on their genome.",
                    "label": 0
                },
                {
                    "sent": "Annual turn out many observations at different locations, and each of them is called a. Geno, type of the polymorphism polymorphism, means that across different individuals they can be different and that differences may or may not cause consequences in the phenotype and the.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Although structure is formulated for simplicity, just as a very simple linear regression, OK, of course you can make it slightly more complicated by adding polynomial terms in here too.",
                    "label": 0
                },
                {
                    "sent": "Edit Tutanota at kernel function over there.",
                    "label": 0
                },
                {
                    "sent": "That's fine, but in the end the features are related to the output.",
                    "label": 0
                },
                {
                    "sent": "Using a linear function.",
                    "label": 0
                },
                {
                    "sent": "That's the building block.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "People want to first of all address the problem of sparsity, because you're with a second, I'll be back to you in a second.",
                    "label": 0
                },
                {
                    "sent": "So this regression problem is different from the kind of regression problem with seeing image or in LP just because of the size of the problem.",
                    "label": 0
                },
                {
                    "sent": "Because the human genome contains 3 billion characters and a couple of million of them polymorphic and they should be all kind of features.",
                    "label": 0
                },
                {
                    "sent": "OK, and when you have a problem of this size.",
                    "label": 0
                },
                {
                    "sent": "You don't want to do linear regression because you will have a lot of false positive signals.",
                    "label": 0
                },
                {
                    "sent": "You really want to regularize as best as you can, so lost so is obvious.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Technique that people want to begin with.",
                    "label": 0
                },
                {
                    "sent": "You got a question over there.",
                    "label": 0
                },
                {
                    "sent": "Yeah OK, it's just the annual miracle representation of the state of the phenotype.",
                    "label": 0
                },
                {
                    "sent": "Say you can call your father's genotype to be 0, your mothers to be 0 to be one, and so these are just two variants of the Geno type.",
                    "label": 0
                },
                {
                    "sent": "OK, I can call it 10 or 20.",
                    "label": 0
                },
                {
                    "sent": "That's fine too.",
                    "label": 0
                },
                {
                    "sent": "So the number itself doesn't mean anything OK?",
                    "label": 0
                },
                {
                    "sent": "And you can also create a hybrid which is combining your father and your mother's.",
                    "label": 0
                },
                {
                    "sent": "If that different gives you a value of two, that's also fine.",
                    "label": 0
                },
                {
                    "sent": "Population.",
                    "label": 0
                },
                {
                    "sent": "Please know we look at the individuals most of the time.",
                    "label": 0
                },
                {
                    "sent": "You could look family but which cannot afford it, OK?",
                    "label": 0
                },
                {
                    "sent": "How do they come to 01?",
                    "label": 0
                },
                {
                    "sent": "Because you have two chromosomes, right?",
                    "label": 0
                },
                {
                    "sent": "I just didn't spend that.",
                    "label": 0
                },
                {
                    "sent": "If they are the same in this way and that way I get the right one.",
                    "label": 0
                },
                {
                    "sent": "If they are different than concert stage.",
                    "label": 0
                },
                {
                    "sent": "But again, that number isn't important.",
                    "label": 0
                },
                {
                    "sent": "You just imagine I have some measurement along the genome to be my teacher.",
                    "label": 0
                },
                {
                    "sent": "That's all you need to know to set up this problem.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so now sparse regression is the way to go.",
                    "label": 0
                },
                {
                    "sent": "And then people also want to capture dependencies because as I said, these features may be tightly coupled.",
                    "label": 0
                },
                {
                    "sent": "Coupled means that they may share the same response to a output to a prediction in in terms of using maybe the same beta.",
                    "label": 0
                },
                {
                    "sent": "Efficiency and how do we enforce that constraint?",
                    "label": 0
                },
                {
                    "sent": "Well, there is a technique called field, so technique where you can based on a known structure of dependencies, group the regression coefficients to force them to take the same value.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's called a few slots, so you probably see that already in our earlier network estimation problem where we use also if you so technique.",
                    "label": 0
                },
                {
                    "sent": "But again that wasn't a very nice approach becausw.",
                    "label": 0
                },
                {
                    "sent": "I know you have to.",
                    "label": 0
                },
                {
                    "sent": "Make straw.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Assumptions of the Fusion structure.",
                    "label": 0
                },
                {
                    "sent": "For example, the network that the features are dependent must be next to each other, or they must be grouped in a certain way so that you know the group ahead of time.",
                    "label": 0
                },
                {
                    "sent": "In in real biological entity, the dependencies between even the inputs are not a static deterministic entity.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe in you the two locals are independent of each other because they sense that they always Co occurrent, but in another individual they may not be depend on each other.",
                    "label": 0
                },
                {
                    "sent": "And this phenomenon is known as the recombination in a few seconds UNC and therefore the block boundaries of this random variables.",
                    "label": 0
                },
                {
                    "sent": "Input can be itself probabilistic.",
                    "label": 0
                },
                {
                    "sent": "Then we want to have a more flexible way of encoding the constraints.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so here is why it come from.",
                    "label": 0
                },
                {
                    "sent": "So you have two chroma zones from your mother, two from the father and each contributes one to make the offspring.",
                    "label": 0
                },
                {
                    "sent": "And in one case is you can get this, but sometimes there could be a recombination taking place in the middle.",
                    "label": 0
                },
                {
                    "sent": "These two guys are changing material, therefore the offspring are like this.",
                    "label": 0
                },
                {
                    "sent": "It's a hybrid from the parents.",
                    "label": 0
                },
                {
                    "sent": "Now if you do.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These after multiple generations from the ancestor chromosome, you will see really.",
                    "label": 0
                },
                {
                    "sent": "That the defendant chromosomes are a mosaic of some common building blocks.",
                    "label": 0
                },
                {
                    "sent": "Suppose that there are causal markers in the region then.",
                    "label": 0
                },
                {
                    "sent": "If they are close enough, you can safely argue that they could always being called Co inheriting right, but only if they are far enough.",
                    "label": 0
                },
                {
                    "sent": "Chances are something in the middle to be recombined is more likely and you see loss of dependencies among the inputs, But again, this is not a deterministic relationship.",
                    "label": 0
                },
                {
                    "sent": "We want to have some more flexible way of encoding these tendency of being recombined.",
                    "label": 0
                },
                {
                    "sent": "If they are far away.",
                    "label": 0
                },
                {
                    "sent": "And not being recombined, if they are close to each other.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a possible approach we can take, we are building on a technique known as a vision variable selection.",
                    "label": 0
                },
                {
                    "sent": "Here you have the the predictor you have the response and let's for simplicity.",
                    "label": 0
                },
                {
                    "sent": "Imagine the response is just a scalar.",
                    "label": 0
                },
                {
                    "sent": "At this point the predictor being a high dimensional covering system and for each of the dimension in the input you have a beta which stands for the regression coefficients and this one of course correspond to the noise.",
                    "label": 0
                },
                {
                    "sent": "In the predictor function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In Beijing regression framework, now we are going to set up some additional structure indicator functions which are denoted by C which says that conditioning on C beta will be active or inactive.",
                    "label": 0
                },
                {
                    "sent": "Mean that it will be used or used.",
                    "label": 0
                },
                {
                    "sent": "And then 'cause we?",
                    "label": 0
                },
                {
                    "sent": "One troll.",
                    "label": 0
                },
                {
                    "sent": "And also in the.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this case, if we assume the markers or the input features are independent each other, then we should see this indicator functions ID.",
                    "label": 0
                },
                {
                    "sent": "Therefore they should all follow maybe a Bernoulli distribution for activity.",
                    "label": 0
                },
                {
                    "sent": "But if we want to further assume that there are dependencies between all the input predictors, maybe it is reasonable to assume that the activity of the second marker should be dependent on the 1st marker in some way, and that's the basic motivating.",
                    "label": 0
                },
                {
                    "sent": "Scenario in the subsequent model.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well defined, this prior known as the Markov chain prior, where the joint distribution of order seizes following a first order Markovian structure.",
                    "label": 0
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                },
                {
                    "sent": "So the condition.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution of the next see is dependent on the 1st C and also based on some other input information.",
                    "label": 0
                },
                {
                    "sent": "For example, if the two seas are representing to genotypes, states that are far away from each other, then the likelihood of them to be recombined should be reduced, otherwise they should have a higher Commission rate.",
                    "label": 0
                },
                {
                    "sent": "So this spirit is captured in this.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Miller, but maybe a graph can.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Display it in a more explicit way so we have our coffee in structure overseas and we have input as the reconnection rates and the distances between the two markers and jointly define a joint distribution of the regression coefficients and you.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imagine we can keep sampling over this distribution, and in the end do something very similar to.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have some interesting results that suggesting something right is happening.",
                    "label": 0
                },
                {
                    "sent": "So here is a simulation experiment.",
                    "label": 0
                },
                {
                    "sent": "We have a true model where some occasional spurts of response taking into effect.",
                    "label": 0
                },
                {
                    "sent": "And this burst of responses are reasonably recovered using the block regularised regression.",
                    "label": 0
                },
                {
                    "sent": "But the result using that.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you use.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Independent Bernoulli prior you've got a lot of false positive signals.",
                    "label": 0
                },
                {
                    "sent": "And if you further ignore the prior, just do the standard Ridge regression or.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not so you get again.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A whole lot of other signals, so that's kind of.",
                    "label": 0
                },
                {
                    "sent": "Simple validation and more.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Create validation.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is provided in this detailed precision recall curve study.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we found that if you assume a low recombination rate across the genome, meaning that markers likes to be coupled if they are close to each other, then you will see that our algorithm is way above the other algorithm in terms of the Roc curve.",
                    "label": 0
                },
                {
                    "sent": "But if your recombination rate become really, really high, mean that at every location were going to recombine that basically destroy the dependency structures among markers.",
                    "label": 0
                },
                {
                    "sent": "OK, and as you can imagine that.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where are the same?",
                    "label": 0
                },
                {
                    "sent": "There's no difference between different algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "And here are some real data.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiment which I want to skip.",
                    "label": 0
                },
                {
                    "sent": "So what I told so far is that now we have a way to capture the structure input where the dependencies between these are not captured, but I still didn't talk about how to take care of the output if my output are multivariate and also dependent on each other, like I draw in this graph.",
                    "label": 0
                },
                {
                    "sent": "So here is another approach.",
                    "label": 0
                },
                {
                    "sent": "Again, we use the the basic class or structure for input, output mapping, but.",
                    "label": 0
                },
                {
                    "sent": "Since there are responses in the output which might be dependent of each other.",
                    "label": 0
                },
                {
                    "sent": "We may imagine the following scenario if there is phenotype in here and there is a phenotype here that are strongly correlated, then maybe this coefficient in the simplest case should influence this guy and that guy in the same way.",
                    "label": 0
                },
                {
                    "sent": "Right, maybe there are all non zero.",
                    "label": 0
                },
                {
                    "sent": "That's the Lestrange scenario.",
                    "label": 0
                },
                {
                    "sent": "Most stringent narobi.",
                    "label": 0
                },
                {
                    "sent": "They're all of the same value in their beta, right?",
                    "label": 0
                },
                {
                    "sent": "So this could be a useful information to further regularize the model, which correspond to putting some more constraints on this beta matrix of regression coefficients.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the step the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So imagine that we have these two tightly coupled phenotypes.",
                    "label": 0
                },
                {
                    "sent": "And want to do this regression and our approach will be to.",
                    "label": 0
                },
                {
                    "sent": "Built a new cost function that is penalizing the Fusion penalty on the output.",
                    "label": 0
                },
                {
                    "sent": "So here is the sign of the correlation which just tell you whether they should be of the same value.",
                    "label": 0
                },
                {
                    "sent": "Make sure that they are absolute values measured rather than their assigned value.",
                    "label": 0
                },
                {
                    "sent": "And then here are the rest are the standard lasso regression loss function and penalty function.",
                    "label": 0
                },
                {
                    "sent": "So this called the graph constraint lost, so feels like a big cause.",
                    "label": 0
                },
                {
                    "sent": "The constraint function is defined only on those pair of phenotypes which are connected by an edge in the phenotype network.",
                    "label": 0
                },
                {
                    "sent": "So this called Network guided fields lasso.",
                    "label": 0
                },
                {
                    "sent": "And you may imagine that the network doesn't have to be just the graph.",
                    "label": 0
                },
                {
                    "sent": "They may be weighted graph.",
                    "label": 0
                },
                {
                    "sent": "Therefore the strength of the coupling can also be used.",
                    "label": 0
                },
                {
                    "sent": "Therefore we also have a graph weighted.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feels lost, all function here where here I have a weighting function F. It could be also designed by arbitrary kernel to reflect the strength of the influence from the weights.",
                    "label": 0
                },
                {
                    "sent": "OK, and again after all this.",
                    "label": 0
                },
                {
                    "sent": "Will have is still a pretty standard convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we solve that use.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bing standard package.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are some preliminary results.",
                    "label": 0
                },
                {
                    "sent": "Say we have a bunch of phenotypes like this.",
                    "label": 0
                },
                {
                    "sent": "OK in here for simplicity.",
                    "label": 0
                },
                {
                    "sent": "Now I've ignored the dependencies between the inputs.",
                    "label": 0
                },
                {
                    "sent": "I'm only worried about the dependencies among the outputs, just for simplicity, so I have a bunch of outputs and this is the correlational structure promoted as a heat map and if I binarize the contribution by a threshold I got this dependency structure.",
                    "label": 0
                },
                {
                    "sent": "And I use this to simulate my response.",
                    "label": 0
                },
                {
                    "sent": "OK, and I think these are the coefficients.",
                    "label": 0
                },
                {
                    "sent": "On each of the phenotype and around this direction, overall the snips.",
                    "label": 0
                },
                {
                    "sent": "OK, and so this is a ground truth we want to recover and this is the recovery using E is.",
                    "label": 0
                },
                {
                    "sent": "Is the Richard question as soon as you imagine it's it's giving you positive signals all over the place.",
                    "label": 0
                },
                {
                    "sent": "F is the lasso, and again you'll see a little bit of cleanup over this one, but again still have a lot of positive signals, and these three graphs are from different versions of the graph.",
                    "label": 0
                },
                {
                    "sent": "Guided or graph waited.",
                    "label": 0
                },
                {
                    "sent": "Few slots or algorithm and you can see that indeed you get results alot closer to that one.",
                    "label": 0
                },
                {
                    "sent": "So the moral here is that you really want to make explicit use of the.",
                    "label": 0
                },
                {
                    "sent": "Information already present in your data, such as dependencies between the responses, dependencies between the inputs and dependencies across them to add as many as necessary the constraints on your regression so that you can clean up unnecessary signals.",
                    "label": 0
                },
                {
                    "sent": "And that's what we did in here.",
                    "label": 0
                },
                {
                    "sent": "And again, you can see a Roc curve over a wide range.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For tuning the regressional coefficients and again the algorithm is dominating over the existing ones.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have some real examples.",
                    "label": 0
                },
                {
                    "sent": "This is actually a small study on the real asthma data set and we did find some positive interesting signals which are believed to be clinically meaningful.",
                    "label": 0
                },
                {
                    "sent": "They are actually looking at these phenotypes, so here you can see I think I have along this dimension or the genotypes.",
                    "label": 0
                },
                {
                    "sent": "This dimension of the phenotypes they can see that this subset of phenotypes are sharing a single genotype responses, so that's the signal that is you really missed from a standard unstructured version of the regression.",
                    "label": 0
                },
                {
                    "sent": "And again, remember that here I'm also.",
                    "label": 0
                },
                {
                    "sent": "Emphasizing sparse structure equation, 'cause we always put a lasso penalty over there to make sure that our output are passing moenius.",
                    "label": 0
                },
                {
                    "sent": "And it's nice thing about this approach.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Should I stop here?",
                    "label": 0
                },
                {
                    "sent": "Although I have a few more days to go on.",
                    "label": 0
                },
                {
                    "sent": "Oh, OK, so since I started OK let me spend 5 more minutes just to wrap up.",
                    "label": 0
                },
                {
                    "sent": "OK, so which is actually not very technical, but hopefully give you another insight of the same problem.",
                    "label": 0
                },
                {
                    "sent": "So we do have a different solution to the problem I put up just now, although we haven't really apply that yet.",
                    "label": 0
                },
                {
                    "sent": "So imagine that in the Regressional framework I talked about so far, we're really doing maximum likelihood estimation or regular sized version of that innocence.",
                    "label": 0
                },
                {
                    "sent": "Right, because we really want to make sure that our joint likelihood of the input and output are maximized at our model.",
                    "label": 0
                },
                {
                    "sent": "That's kind of the spirit in any regressional framework.",
                    "label": 0
                },
                {
                    "sent": "And if you must notice that in recent years there is this trend of learning maximum margin models in machine learning for whatever purpose for SVM.",
                    "label": 0
                },
                {
                    "sent": "For maximizing Markov network in structure prediction, can we use that as well for this problem?",
                    "label": 0
                },
                {
                    "sent": "What the answer is, yes, you can use a model which are mainly focused on making best possible predictions rather than structure discovery.",
                    "label": 0
                },
                {
                    "sent": "OK, for based on maximizing principle.",
                    "label": 0
                },
                {
                    "sent": "But you really people use that model really for prediction, so I can make the best passing of the natural language sentences or best segmentation.",
                    "label": 0
                },
                {
                    "sent": "But in terms of the Markov network structure, people usually don't pay much attention to that.",
                    "label": 0
                },
                {
                    "sent": "It turns out that maybe you can also use that to.",
                    "label": 0
                },
                {
                    "sent": "Those strategies cover because the best you predict, you should hope that maybe the structure can become more meaningful.",
                    "label": 0
                },
                {
                    "sent": "So what I'm talking about in the next three slides is kind of along that line so I don't have time to go through detail.",
                    "label": 0
                },
                {
                    "sent": "But here is a high level message.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe you already saw that in dreams.",
                    "label": 0
                },
                {
                    "sent": "Talk in earlier lecture.",
                    "label": 0
                },
                {
                    "sent": "So what is the major parroting of margin based distributed learning?",
                    "label": 0
                },
                {
                    "sent": "What you see is the couple of the following we have.",
                    "label": 0
                },
                {
                    "sent": "The SCM which is learning a single division boundary OK and over binary classification.",
                    "label": 0
                },
                {
                    "sent": "And here is a objective function you need to solve for that problem.",
                    "label": 0
                },
                {
                    "sent": "And sometimes people may like a more patient treatment of the model.",
                    "label": 0
                },
                {
                    "sent": "So invasion prediction you don't do point prediction.",
                    "label": 0
                },
                {
                    "sent": "You do model averaging.",
                    "label": 0
                },
                {
                    "sent": "You do an expectation over distribution of models, and it turns out that one can do a similar thing here using what is known as the maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "This convention framework where you really learn a distribution of.",
                    "label": 0
                },
                {
                    "sent": "Of the decision boundary.",
                    "label": 0
                },
                {
                    "sent": "So here your prediction is expected over the distribution of the model and that distribution of the model.",
                    "label": 0
                },
                {
                    "sent": "The QW can be actually also learned using a very similar function as this, where the loss function is not a KL divergent between your target function and some prior distribution of the weights, and your constraint is no longer.",
                    "label": 0
                },
                {
                    "sent": "Data centric point constraint.",
                    "label": 0
                },
                {
                    "sent": "It is going to be expectation constraint.",
                    "label": 0
                },
                {
                    "sent": "Built on the learned model.",
                    "label": 0
                },
                {
                    "sent": "Along the other direction, you can also make the SVM structure using the maximum margin Markov network trick.",
                    "label": 0
                },
                {
                    "sent": "In which your prediction is now a arbitrary structured rule based on some discrete function.",
                    "label": 0
                },
                {
                    "sent": "So here why is not a class label between 01 and between minus one positive way?",
                    "label": 0
                },
                {
                    "sent": "It could be a code labeling sequence of the sentence, but we can again make that prediction as argmax of some linear predictor function, and to learn that.",
                    "label": 0
                },
                {
                    "sent": "Wait, you can you know, follow up in Task Force approach and make it as a quadratic programming problem.",
                    "label": 0
                },
                {
                    "sent": "OK, based on some maximum budget constraints.",
                    "label": 0
                },
                {
                    "sent": "So what we recently workout with Gene is a combination of these two ideas.",
                    "label": 0
                },
                {
                    "sent": "We want to model to be both structured and maximizing and also being averaged over multiple models.",
                    "label": 0
                },
                {
                    "sent": "And this approach is known as the maximum entropy discrimination.",
                    "label": 0
                },
                {
                    "sent": "Markov networks.",
                    "label": 0
                },
                {
                    "sent": "It could be understood as the structured version of the Med framework plus some Asian ideas applied on top of the M3 network and in the end.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the overall problem you need to solve to get there, you need to apply the structure to maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "In principle to set up this optimization problem where you minimize the KL divergences between the distribution of your model and a pretty solution order model plus some Slack function to allow misclassification or mislabeling, and then your constraint should be set so that your learned distribution are satisfying certain constraints.",
                    "label": 0
                },
                {
                    "sent": "And the constraints are very similar to the SVM constraint, except that now they are all defined on expected margin rather than just the sample based single margins.",
                    "label": 0
                },
                {
                    "sent": "So your margin will be.",
                    "label": 0
                },
                {
                    "sent": "Taking average over P of W. And then your prediction is also different.",
                    "label": 0
                },
                {
                    "sent": "Your prediction is now no longer based on just the F. The prediction function it is based on a weighted average over the predict function.",
                    "label": 0
                },
                {
                    "sent": "Therefore you have a smooth distribution of predictors, some being more likely, something less likely, but your average over all of that and in the end you can expect a more robust predictive room.",
                    "label": 0
                },
                {
                    "sent": "And so I think I can ignore this picture at the end of the.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You will get a model which.",
                    "label": 0
                },
                {
                    "sent": "Can be solved in close form and that gives you the solution to the model I just mentioned.",
                    "label": 0
                },
                {
                    "sent": "Although the actual solution may be more complicated because here your post distribution of the weights are defined by some lounging coefficients which needs to be solved by solving this dual operating problem and we can show that if under certain condition this dual optimization problem can be identical to the one you solve in the maximizing Markov network.",
                    "label": 0
                },
                {
                    "sent": "Therefore the answer network.",
                    "label": 0
                },
                {
                    "sent": "Can be proved to be a special case of this one, but of course this one can be more general if you choose to use different priors and different loss functions.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so here is what I'm trying to say, but at the end of the day, here is the new model with this following three advantages.",
                    "label": 0
                },
                {
                    "sent": "First, it is going to be average model rather than a point estimator of the Markov network, and as a result you can prove an ice pack based bound to bound the generation error, and Secondly this model because it uses a prior distribution over the weights.",
                    "label": 0
                },
                {
                    "sent": "It turns out that this.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior distribution can be a proxy for you to introduce nice behaviors.",
                    "label": 0
                },
                {
                    "sent": "For example, you can use it as a entropic regularizer to introduce certain bias if you want the multi sparse.",
                    "label": 0
                },
                {
                    "sent": "For example, you can introduce a LA plus prior over the regressional weights over the model weights and in the end you will get a pretty nice shrinkage effect over different dimensions of the model and as a result in the end you will have a model which is nice in the sense that.",
                    "label": 0
                },
                {
                    "sent": "Remember we do support vector machine, the major.",
                    "label": 0
                },
                {
                    "sent": "Motivation for SVM are two folds.",
                    "label": 0
                },
                {
                    "sent": "One is that you have the maximum margin and kernel trick.",
                    "label": 0
                },
                {
                    "sent": "The other is that you have the support vectors, right?",
                    "label": 0
                },
                {
                    "sent": "You have a few support vectors which makes your model dual sparse and this model of course has door sparsity 'cause you need to solve the support vector machine problem in the dual space.",
                    "label": 0
                },
                {
                    "sent": "But in addition to that you have this very nice and Tropic regularizer which also push your solution vector to be primal sparse in the sense that.",
                    "label": 0
                },
                {
                    "sent": "Along certain directions.",
                    "label": 0
                },
                {
                    "sent": "OK, that type of itself will be pushed to zero to close to 0.",
                    "label": 0
                },
                {
                    "sent": "Therefore you enjoy simultaneous dual and primal sparsity using this framework.",
                    "label": 0
                },
                {
                    "sent": "And finally, of course it gives you a nicer framework to combine generative model and discrete model 'cause the way you design the prior distribution and the way you design the loss function as a KL between two distributions are able to put probabilities into the framework for designing arbitrary latent structures on top of the predictive models.",
                    "label": 0
                },
                {
                    "sent": "OK, so we've been still trying to this is the model we just started to work on and we still have a lot of room on new problems to be tried on this problem and I believe that offers a third angle to the structured input output regression problem.",
                    "label": 0
                },
                {
                    "sent": "Talk about and if you're interested again, you're welcome to play with that, even outside of biology could be applied to LP and vision problems as well.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eric, I'm sorry I had a class that was scheduled to start in this from 10 minutes ago.",
                    "label": 0
                },
                {
                    "sent": "It's right time I'm done.",
                    "label": 0
                },
                {
                    "sent": "OK, so thanks for here and that's all I'm talking about.",
                    "label": 0
                }
            ]
        }
    }
}