{
    "id": "5tsmqllviv5qclll7vguah4gwu5b42ra",
    "title": "Learning Beautiful (and Ugly) Attributes",
    "info": {
        "author": [
            "Luca Marchesotti, Xerox Research Centre Europe, Xerox"
        ],
        "published": "April 3, 2014",
        "recorded": "September 2013",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/bmvc2013_marchesotti_learning_attributes/",
    "segmentation": [
        [
            "Good morning everyone.",
            "My name is Luca.",
            "I'm researching zero Search labs Europe.",
            "This is joint work with my colleague overflow on power Now."
        ],
        [
            "So the problem is the following.",
            "We have an image and."
        ],
        [
            "We want to build a machine that is capable of predicting if this image will be appreciated or not by people.",
            "This is a very challenging question even for humans, but several works in the last five years have shown that to some extent this image can be answered by a system learning machine that is capable of predicting score associated to the quality of the image.",
            "What we want to do is to go beyond these prediction.",
            "And simply saying why an image is considered as a good image or a body image and."
        ],
        [
            "Well, what we want to do is basically to overcome one of the major limitations of the work so far at the feature level.",
            "So basically you have two options.",
            "Either you handcraft your features.",
            "So basically, given a set of rules, photographic rules, like for instance the rule of thirds or common practices used by photographers, you design A feature capturing that specific rule OK.",
            "The problem is that these approaches on exhaustive and most importantly a good feature is that it's interpretable, so you can say that if you detect this feature, your image has good color, harmony, etc.",
            "On the other side of the spectrum, you have generic features that were tested a couple of years ago, and here I'm talking about the usual suspects or feature vector bag of visual words, sifting colors.",
            "All the techniques that.",
            "Andrew, this summer was presented was introducing this morning, so in this case the drawback is that the features are non interpretable, meaning that you don't really know what you're learning.",
            "OK, but you have improved performance is this."
        ],
        [
            "Scope of this work is."
        ],
        [
            "Bridge this gap and proposed features mid level features attributes that hopefully are Inter."
        ],
        [
            "Notable and they have improved performance is OK."
        ],
        [
            "So the main contribution of the paper is the following.",
            "We take a database that was recently introduced called Eva Aesthetic Visual Analysis Database.",
            "Which contains 3 main ingredients.",
            "The 1st is a lot of images, quarter of a million of images.",
            "Actually the 2nd is a lot of natural text associated to these images, so typically we're talking here about comments left by photographers regarding the properties of the images that you can see on the right and the third ingredient is a lot of scores, preference scores.",
            "Left by other photographers.",
            "OK, and we're talking about 200 two 150 individual scores for each image, which means that you have for every image in the corpus a distribution of of votes.",
            "Now what we're doing here is mainly connecting the dots.",
            "OK, so we're using these three things at the same time, and we're building a vocabulary of.",
            "Beautiful and ugly attributes so."
        ],
        [
            "The outline of the presentation is the following.",
            "We start with this database right containing these multi multi dimensional data, images, text and attractiveness data.",
            "We pull out the natural language part and we discovered we mind textual labels.",
            "OK, we do this with attractiveness scores in a minute.",
            "I will explain you how and then we have candidate labels under the form of unigrams and bigrams.",
            "You will use these labels to learn visual categorizers and finally we use them for whatever problem you can imagine.",
            "A classification, regression or ranking.",
            "OK, so let's start with the first part.",
            "How we discover the textual labels."
        ],
        [
            "Common approaches in the literature.",
            "You can use NLP templates.",
            "This was BBC 2009.",
            "You can use mutual information and basically do some feature selection and pull out the most discriminate labels for your problem.",
            "You can use Amazon Mechanical Turk or exploit an existing lexical database.",
            "OK, what we want to do is to have a minimum amount of supervision, so forget about Mechanical Turk or or.",
            "Or a database annotations.",
            "We want labels that explains what a good photo is.",
            "And we want it scalable, so we want to produce potentially a lot of labels.",
            "OK, so."
        ],
        [
            "The first thing that comes to mind when we're dealing with a large corpus of images, and we want no supervision, is to do these mining in a computer supervised way.",
            "So you think about these labels as latent topics, OK, latent topics.",
            "It means that you take an image.",
            "You take all the comments associated with this image, and you plug these your textual data into LSA framework.",
            "And here you can use really whatever textual features you want.",
            "You can use frequency counts.",
            "Probably better to use TF IDF, so your features are implicitly normalized.",
            "You plug it in and what you get through this.",
            "Basically factorization into these two matrices, first one and the second one is a set of latent topics now."
        ],
        [
            "If you look at this topic so we can say a few things about them so we can say that they more or less correlate with what we want to study.",
            "Aesthetic preference.",
            "For instance, I think you might agree with me that Z 35 motion, panning, blur, speed, movement etc already gives an impression of the image that that.",
            "To which these keywords are associated.",
            "We have some other topics like Z8 more related to the semantic of the image.",
            "OK, but this is."
        ],
        [
            "Not enough because these are two vagues.",
            "OK, so we can't really use these topics as they are for training visual categorizers OK."
        ],
        [
            "So the second thing that we tried was the following.",
            "So instead of doing this discovery in a completely unsupervised way, we injected some formal supervision by using the scores that we have for each image as a supervising entity.",
            "So let me explain a bit better what I mean by that.",
            "We have an image we take all the data, the natural text associated to it, and we also take this course.",
            "This course distribution.",
            "Actually we take the mean of this distribution.",
            "Case one, once we have this.",
            "Two things.",
            "Basically, we use our regression technique.",
            "This is an elastic net, but you can really use whatever regression technique that you want, provided that it's it's.",
            "Technically, which is flexible enough to do that, remind the amount of predictors that you can preserve, and this is this is a good choice.",
            "I mean, the elastic net is a good choice because as you can see, we have two regularization components.",
            "The first one is the L1 regularizer, the second one is the L2, and this is good because by balancing the amount of L1 and two regularization, you can really put 20.",
            "Many non relevant predictors and implicitly you can do a feature selection by regularising through well, one and two.",
            "Let's have a look at the results.",
            "Well these are some of the advantages that I mentioned about Elastic Net.",
            "It also worth it, is also worth mentioning that Elastic Net overcomes the problems of LASSO.",
            "Related to the.",
            "Correlated predictors so."
        ],
        [
            "Well, let's have a look at some results.",
            "Now before using unigram.",
            "So if we are taking.",
            "Single words as features.",
            "We get something which is much more precise than PSA.",
            "We get stuff like like, great focus, blurry, etc.",
            "But there's one additional problem here.",
            "All these potential labels don't have a polarity, so I don't really know if this is good for cues or bad focus.",
            "OK, I can guess it because these are negative unigram, so unique grams that correlate negatively with aesthetic scores.",
            "But we want more expressive labels, right?",
            "So what I do is I use a an approach which is very common in the semantic.",
            "Sorry in sentiment analysis.",
            "So instead of using unigrams you use bigrams so you are using words which are close to each other and with this very simple trick you can capture the polarity that we were missing with unigrams.",
            "For instance here.",
            "Now I can get two small too blurry.",
            "Great lightning, great composition, etc great.",
            "So we have.",
            "We have now built our set of labels at 0 cost, meaning that there's no manual intervention.",
            "Everything I showed you is automatically and actually these are the results that I get from the from the elastic net by ranking through the beta coefficients the bit are the regression weights right?",
            "So by simply re ranking?",
            "With the because I already get very very neat, very neat set of labels with no manual intervention OK."
        ],
        [
            "So let's recap, we have discovered the labels.",
            "Now we need to train a visual categorizers.",
            "Now trainer visual categorizers, you know with labels like cats and Dogs is already complicated.",
            "You can imagine you know training a categorizer with the bigram too little or too blurry.",
            "Can we really do this?",
            "So to understand if this question is as an answer.",
            "Basically we need to.",
            "Focus on 2 problems, number one which are the labels which needs which should be taken into account and second one which labels can be effectively learned.",
            "OK, so we came up with a very simple.",
            "A plain vanilla approach for tackling these these two questions."
        ],
        [
            "Let me explain what it is.",
            "So first of all, you train as many classifiers as you want.",
            "Sorry as you can and here we started with 3000 most discriminate labels OK, but potentially you should be able to train.",
            "Several thousands of this classifier and this is the reason why you need to really apply a classification pipeline, which which is lean and which is scalable.",
            "And my best advice is to use.",
            "Once again sifting color, spatial pyramid, feature vector, picou compression and SGD stochastic gradient descent so you can really scale up to a lot of images and a lot of classifiers.",
            "OK, the second thing.",
            "That advise you to do is then to re rank these classifiers based on performances and you can use whatever measure you can use the AUC, but probably it's even better top K. This is not really important now.",
            "The last thing that which is important is you then have to really pick the ones that are most interpretable by humans and there is where you need.",
            "There is the only point actually in the pipeline where you need a human to make this distinction.",
            "OK, if you do these three steps."
        ],
        [
            "These are the results that you get, or at least I got.",
            "This is a scape of labels that should that tells me what is beautiful or what is appreciated in a photography OK, at least from the point of view of these textual labels within the database that I analyzed.",
            "So this is not meant to generalize to every kind of photographic databases.",
            "This is important to be to be remembered.",
            "So we get something like great portrait black background, amazing capture, etc.",
            "Basically we're seeing things like color composition and lighting.",
            "Not surprising, that's good.",
            "And this."
        ],
        [
            "Is what is ugly?",
            "OK, so we get once again compositional features like distracting background or bad focus.",
            "Others are related to light.",
            "Again, camera flash.",
            "Very poor, too busy.",
            "So to have an idea of what we can learn visually."
        ],
        [
            "I put up some qualitative results and what you're seeing here are ranks OK of nine images.",
            "Actually, these are the top 9 images that I obtain if I re rank the my database using the visual classifier called great colors.",
            "OK, then there's a nice perspective.",
            "Very sharp, very cluttered.",
            "In color cast.",
            "OK.",
            "So."
        ],
        [
            "To wrap up some quality quantitative results, these were the ranks that I was talking to you about before for the ugly and the beautiful attributes.",
            "As you see, this is not.",
            "This is not this is expected.",
            "We have this long tail."
        ],
        [
            "The decrease of the results and if we're taking this, the first 60 attributes in this case, ugly attributes can be learned with lower precision than the beautiful ones.",
            "Then, and, uh."
        ],
        [
            "The thing that I wanted to tell you is about the prediction.",
            "Performance is.",
            "So when we are predicting those scores that I was showing you before, we are comparing with Fisher Vector which is the best baseline on this problem.",
            "As you see, the performances are a little bit.",
            "Less performing than the feature vector, this was."
        ],
        [
            "Expected because feature vector is a very high dimensional descriptor and descriptor of the attribute features is significantly lower now.",
            "Testing part here is that if we are prepared to pay these little decrease in performance is we gain an expression.",
            "OK, so we get we have the possibility to implement applications where this descriptor can can be interpreted."
        ],
        [
            "This is one of them, so forth annotation we have a set of images.",
            "OK, and you know, in the traditional setup we would be able to say if these images are good or bad.",
            "OK this is very tricky because if you tell your telling to a human that this photo on the left on the side here is bad, the first thing that it will tell you, it will be no.",
            "I like it OK and the system doesn't work.",
            "And what you're doing.",
            "Is not so interesting.",
            "OK, so a safer bet would be to forget about."
        ],
        [
            "Is binary answer and give to you a user a more qualitative interpretation.",
            "So you can say look this image is a great macro as great focus.",
            "OK, and this image needs more depth of field.",
            "OK, this image may be a bit more lights should be should be.",
            "Boat or a sharper focus, so it's a safer kind of answer.",
            "OK, and human tends to react better to this kind of this kind of interactions."
        ],
        [
            "So to wrap up and conclude, you want to implement.",
            "Techniques for studying eye level image quality, while certainly you need large scale databases, generically I dimensional features like feature vector and if you can learn content dependent models so you get rid of eventual semantic eventual biases introduced by the semantic of the image and certainly consider textual features because you know for many visual problems text even natural text as act as a label.",
            "And it's very powerful.",
            "So I stopped."
        ],
        [
            "Here, with this slide show of more qualitative results."
        ],
        [
            "I will be happy to take questions.",
            "Thanks a lot."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning everyone.",
                    "label": 0
                },
                {
                    "sent": "My name is Luca.",
                    "label": 0
                },
                {
                    "sent": "I'm researching zero Search labs Europe.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with my colleague overflow on power Now.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the problem is the following.",
                    "label": 0
                },
                {
                    "sent": "We have an image and.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to build a machine that is capable of predicting if this image will be appreciated or not by people.",
                    "label": 0
                },
                {
                    "sent": "This is a very challenging question even for humans, but several works in the last five years have shown that to some extent this image can be answered by a system learning machine that is capable of predicting score associated to the quality of the image.",
                    "label": 0
                },
                {
                    "sent": "What we want to do is to go beyond these prediction.",
                    "label": 0
                },
                {
                    "sent": "And simply saying why an image is considered as a good image or a body image and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, what we want to do is basically to overcome one of the major limitations of the work so far at the feature level.",
                    "label": 0
                },
                {
                    "sent": "So basically you have two options.",
                    "label": 0
                },
                {
                    "sent": "Either you handcraft your features.",
                    "label": 0
                },
                {
                    "sent": "So basically, given a set of rules, photographic rules, like for instance the rule of thirds or common practices used by photographers, you design A feature capturing that specific rule OK.",
                    "label": 0
                },
                {
                    "sent": "The problem is that these approaches on exhaustive and most importantly a good feature is that it's interpretable, so you can say that if you detect this feature, your image has good color, harmony, etc.",
                    "label": 1
                },
                {
                    "sent": "On the other side of the spectrum, you have generic features that were tested a couple of years ago, and here I'm talking about the usual suspects or feature vector bag of visual words, sifting colors.",
                    "label": 0
                },
                {
                    "sent": "All the techniques that.",
                    "label": 0
                },
                {
                    "sent": "Andrew, this summer was presented was introducing this morning, so in this case the drawback is that the features are non interpretable, meaning that you don't really know what you're learning.",
                    "label": 0
                },
                {
                    "sent": "OK, but you have improved performance is this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scope of this work is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bridge this gap and proposed features mid level features attributes that hopefully are Inter.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Notable and they have improved performance is OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main contribution of the paper is the following.",
                    "label": 0
                },
                {
                    "sent": "We take a database that was recently introduced called Eva Aesthetic Visual Analysis Database.",
                    "label": 1
                },
                {
                    "sent": "Which contains 3 main ingredients.",
                    "label": 0
                },
                {
                    "sent": "The 1st is a lot of images, quarter of a million of images.",
                    "label": 0
                },
                {
                    "sent": "Actually the 2nd is a lot of natural text associated to these images, so typically we're talking here about comments left by photographers regarding the properties of the images that you can see on the right and the third ingredient is a lot of scores, preference scores.",
                    "label": 0
                },
                {
                    "sent": "Left by other photographers.",
                    "label": 0
                },
                {
                    "sent": "OK, and we're talking about 200 two 150 individual scores for each image, which means that you have for every image in the corpus a distribution of of votes.",
                    "label": 0
                },
                {
                    "sent": "Now what we're doing here is mainly connecting the dots.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're using these three things at the same time, and we're building a vocabulary of.",
                    "label": 0
                },
                {
                    "sent": "Beautiful and ugly attributes so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The outline of the presentation is the following.",
                    "label": 0
                },
                {
                    "sent": "We start with this database right containing these multi multi dimensional data, images, text and attractiveness data.",
                    "label": 0
                },
                {
                    "sent": "We pull out the natural language part and we discovered we mind textual labels.",
                    "label": 1
                },
                {
                    "sent": "OK, we do this with attractiveness scores in a minute.",
                    "label": 0
                },
                {
                    "sent": "I will explain you how and then we have candidate labels under the form of unigrams and bigrams.",
                    "label": 0
                },
                {
                    "sent": "You will use these labels to learn visual categorizers and finally we use them for whatever problem you can imagine.",
                    "label": 1
                },
                {
                    "sent": "A classification, regression or ranking.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's start with the first part.",
                    "label": 0
                },
                {
                    "sent": "How we discover the textual labels.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Common approaches in the literature.",
                    "label": 1
                },
                {
                    "sent": "You can use NLP templates.",
                    "label": 0
                },
                {
                    "sent": "This was BBC 2009.",
                    "label": 0
                },
                {
                    "sent": "You can use mutual information and basically do some feature selection and pull out the most discriminate labels for your problem.",
                    "label": 1
                },
                {
                    "sent": "You can use Amazon Mechanical Turk or exploit an existing lexical database.",
                    "label": 1
                },
                {
                    "sent": "OK, what we want to do is to have a minimum amount of supervision, so forget about Mechanical Turk or or.",
                    "label": 0
                },
                {
                    "sent": "Or a database annotations.",
                    "label": 0
                },
                {
                    "sent": "We want labels that explains what a good photo is.",
                    "label": 0
                },
                {
                    "sent": "And we want it scalable, so we want to produce potentially a lot of labels.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first thing that comes to mind when we're dealing with a large corpus of images, and we want no supervision, is to do these mining in a computer supervised way.",
                    "label": 0
                },
                {
                    "sent": "So you think about these labels as latent topics, OK, latent topics.",
                    "label": 1
                },
                {
                    "sent": "It means that you take an image.",
                    "label": 0
                },
                {
                    "sent": "You take all the comments associated with this image, and you plug these your textual data into LSA framework.",
                    "label": 0
                },
                {
                    "sent": "And here you can use really whatever textual features you want.",
                    "label": 0
                },
                {
                    "sent": "You can use frequency counts.",
                    "label": 0
                },
                {
                    "sent": "Probably better to use TF IDF, so your features are implicitly normalized.",
                    "label": 0
                },
                {
                    "sent": "You plug it in and what you get through this.",
                    "label": 0
                },
                {
                    "sent": "Basically factorization into these two matrices, first one and the second one is a set of latent topics now.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you look at this topic so we can say a few things about them so we can say that they more or less correlate with what we want to study.",
                    "label": 0
                },
                {
                    "sent": "Aesthetic preference.",
                    "label": 0
                },
                {
                    "sent": "For instance, I think you might agree with me that Z 35 motion, panning, blur, speed, movement etc already gives an impression of the image that that.",
                    "label": 1
                },
                {
                    "sent": "To which these keywords are associated.",
                    "label": 0
                },
                {
                    "sent": "We have some other topics like Z8 more related to the semantic of the image.",
                    "label": 0
                },
                {
                    "sent": "OK, but this is.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not enough because these are two vagues.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can't really use these topics as they are for training visual categorizers OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the second thing that we tried was the following.",
                    "label": 0
                },
                {
                    "sent": "So instead of doing this discovery in a completely unsupervised way, we injected some formal supervision by using the scores that we have for each image as a supervising entity.",
                    "label": 0
                },
                {
                    "sent": "So let me explain a bit better what I mean by that.",
                    "label": 0
                },
                {
                    "sent": "We have an image we take all the data, the natural text associated to it, and we also take this course.",
                    "label": 0
                },
                {
                    "sent": "This course distribution.",
                    "label": 0
                },
                {
                    "sent": "Actually we take the mean of this distribution.",
                    "label": 0
                },
                {
                    "sent": "Case one, once we have this.",
                    "label": 0
                },
                {
                    "sent": "Two things.",
                    "label": 0
                },
                {
                    "sent": "Basically, we use our regression technique.",
                    "label": 0
                },
                {
                    "sent": "This is an elastic net, but you can really use whatever regression technique that you want, provided that it's it's.",
                    "label": 0
                },
                {
                    "sent": "Technically, which is flexible enough to do that, remind the amount of predictors that you can preserve, and this is this is a good choice.",
                    "label": 0
                },
                {
                    "sent": "I mean, the elastic net is a good choice because as you can see, we have two regularization components.",
                    "label": 0
                },
                {
                    "sent": "The first one is the L1 regularizer, the second one is the L2, and this is good because by balancing the amount of L1 and two regularization, you can really put 20.",
                    "label": 0
                },
                {
                    "sent": "Many non relevant predictors and implicitly you can do a feature selection by regularising through well, one and two.",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at the results.",
                    "label": 0
                },
                {
                    "sent": "Well these are some of the advantages that I mentioned about Elastic Net.",
                    "label": 0
                },
                {
                    "sent": "It also worth it, is also worth mentioning that Elastic Net overcomes the problems of LASSO.",
                    "label": 1
                },
                {
                    "sent": "Related to the.",
                    "label": 0
                },
                {
                    "sent": "Correlated predictors so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, let's have a look at some results.",
                    "label": 0
                },
                {
                    "sent": "Now before using unigram.",
                    "label": 0
                },
                {
                    "sent": "So if we are taking.",
                    "label": 0
                },
                {
                    "sent": "Single words as features.",
                    "label": 0
                },
                {
                    "sent": "We get something which is much more precise than PSA.",
                    "label": 0
                },
                {
                    "sent": "We get stuff like like, great focus, blurry, etc.",
                    "label": 0
                },
                {
                    "sent": "But there's one additional problem here.",
                    "label": 0
                },
                {
                    "sent": "All these potential labels don't have a polarity, so I don't really know if this is good for cues or bad focus.",
                    "label": 1
                },
                {
                    "sent": "OK, I can guess it because these are negative unigram, so unique grams that correlate negatively with aesthetic scores.",
                    "label": 0
                },
                {
                    "sent": "But we want more expressive labels, right?",
                    "label": 0
                },
                {
                    "sent": "So what I do is I use a an approach which is very common in the semantic.",
                    "label": 0
                },
                {
                    "sent": "Sorry in sentiment analysis.",
                    "label": 0
                },
                {
                    "sent": "So instead of using unigrams you use bigrams so you are using words which are close to each other and with this very simple trick you can capture the polarity that we were missing with unigrams.",
                    "label": 0
                },
                {
                    "sent": "For instance here.",
                    "label": 0
                },
                {
                    "sent": "Now I can get two small too blurry.",
                    "label": 0
                },
                {
                    "sent": "Great lightning, great composition, etc great.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "We have now built our set of labels at 0 cost, meaning that there's no manual intervention.",
                    "label": 0
                },
                {
                    "sent": "Everything I showed you is automatically and actually these are the results that I get from the from the elastic net by ranking through the beta coefficients the bit are the regression weights right?",
                    "label": 0
                },
                {
                    "sent": "So by simply re ranking?",
                    "label": 0
                },
                {
                    "sent": "With the because I already get very very neat, very neat set of labels with no manual intervention OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's recap, we have discovered the labels.",
                    "label": 0
                },
                {
                    "sent": "Now we need to train a visual categorizers.",
                    "label": 1
                },
                {
                    "sent": "Now trainer visual categorizers, you know with labels like cats and Dogs is already complicated.",
                    "label": 0
                },
                {
                    "sent": "You can imagine you know training a categorizer with the bigram too little or too blurry.",
                    "label": 0
                },
                {
                    "sent": "Can we really do this?",
                    "label": 0
                },
                {
                    "sent": "So to understand if this question is as an answer.",
                    "label": 0
                },
                {
                    "sent": "Basically we need to.",
                    "label": 0
                },
                {
                    "sent": "Focus on 2 problems, number one which are the labels which needs which should be taken into account and second one which labels can be effectively learned.",
                    "label": 1
                },
                {
                    "sent": "OK, so we came up with a very simple.",
                    "label": 0
                },
                {
                    "sent": "A plain vanilla approach for tackling these these two questions.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me explain what it is.",
                    "label": 0
                },
                {
                    "sent": "So first of all, you train as many classifiers as you want.",
                    "label": 1
                },
                {
                    "sent": "Sorry as you can and here we started with 3000 most discriminate labels OK, but potentially you should be able to train.",
                    "label": 0
                },
                {
                    "sent": "Several thousands of this classifier and this is the reason why you need to really apply a classification pipeline, which which is lean and which is scalable.",
                    "label": 0
                },
                {
                    "sent": "And my best advice is to use.",
                    "label": 0
                },
                {
                    "sent": "Once again sifting color, spatial pyramid, feature vector, picou compression and SGD stochastic gradient descent so you can really scale up to a lot of images and a lot of classifiers.",
                    "label": 0
                },
                {
                    "sent": "OK, the second thing.",
                    "label": 0
                },
                {
                    "sent": "That advise you to do is then to re rank these classifiers based on performances and you can use whatever measure you can use the AUC, but probably it's even better top K. This is not really important now.",
                    "label": 1
                },
                {
                    "sent": "The last thing that which is important is you then have to really pick the ones that are most interpretable by humans and there is where you need.",
                    "label": 0
                },
                {
                    "sent": "There is the only point actually in the pipeline where you need a human to make this distinction.",
                    "label": 0
                },
                {
                    "sent": "OK, if you do these three steps.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are the results that you get, or at least I got.",
                    "label": 0
                },
                {
                    "sent": "This is a scape of labels that should that tells me what is beautiful or what is appreciated in a photography OK, at least from the point of view of these textual labels within the database that I analyzed.",
                    "label": 0
                },
                {
                    "sent": "So this is not meant to generalize to every kind of photographic databases.",
                    "label": 0
                },
                {
                    "sent": "This is important to be to be remembered.",
                    "label": 0
                },
                {
                    "sent": "So we get something like great portrait black background, amazing capture, etc.",
                    "label": 0
                },
                {
                    "sent": "Basically we're seeing things like color composition and lighting.",
                    "label": 0
                },
                {
                    "sent": "Not surprising, that's good.",
                    "label": 0
                },
                {
                    "sent": "And this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is what is ugly?",
                    "label": 0
                },
                {
                    "sent": "OK, so we get once again compositional features like distracting background or bad focus.",
                    "label": 0
                },
                {
                    "sent": "Others are related to light.",
                    "label": 0
                },
                {
                    "sent": "Again, camera flash.",
                    "label": 0
                },
                {
                    "sent": "Very poor, too busy.",
                    "label": 0
                },
                {
                    "sent": "So to have an idea of what we can learn visually.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I put up some qualitative results and what you're seeing here are ranks OK of nine images.",
                    "label": 0
                },
                {
                    "sent": "Actually, these are the top 9 images that I obtain if I re rank the my database using the visual classifier called great colors.",
                    "label": 0
                },
                {
                    "sent": "OK, then there's a nice perspective.",
                    "label": 1
                },
                {
                    "sent": "Very sharp, very cluttered.",
                    "label": 0
                },
                {
                    "sent": "In color cast.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To wrap up some quality quantitative results, these were the ranks that I was talking to you about before for the ugly and the beautiful attributes.",
                    "label": 0
                },
                {
                    "sent": "As you see, this is not.",
                    "label": 0
                },
                {
                    "sent": "This is not this is expected.",
                    "label": 0
                },
                {
                    "sent": "We have this long tail.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The decrease of the results and if we're taking this, the first 60 attributes in this case, ugly attributes can be learned with lower precision than the beautiful ones.",
                    "label": 0
                },
                {
                    "sent": "Then, and, uh.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The thing that I wanted to tell you is about the prediction.",
                    "label": 0
                },
                {
                    "sent": "Performance is.",
                    "label": 0
                },
                {
                    "sent": "So when we are predicting those scores that I was showing you before, we are comparing with Fisher Vector which is the best baseline on this problem.",
                    "label": 1
                },
                {
                    "sent": "As you see, the performances are a little bit.",
                    "label": 0
                },
                {
                    "sent": "Less performing than the feature vector, this was.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Expected because feature vector is a very high dimensional descriptor and descriptor of the attribute features is significantly lower now.",
                    "label": 1
                },
                {
                    "sent": "Testing part here is that if we are prepared to pay these little decrease in performance is we gain an expression.",
                    "label": 0
                },
                {
                    "sent": "OK, so we get we have the possibility to implement applications where this descriptor can can be interpreted.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is one of them, so forth annotation we have a set of images.",
                    "label": 0
                },
                {
                    "sent": "OK, and you know, in the traditional setup we would be able to say if these images are good or bad.",
                    "label": 0
                },
                {
                    "sent": "OK this is very tricky because if you tell your telling to a human that this photo on the left on the side here is bad, the first thing that it will tell you, it will be no.",
                    "label": 0
                },
                {
                    "sent": "I like it OK and the system doesn't work.",
                    "label": 0
                },
                {
                    "sent": "And what you're doing.",
                    "label": 0
                },
                {
                    "sent": "Is not so interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, so a safer bet would be to forget about.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is binary answer and give to you a user a more qualitative interpretation.",
                    "label": 0
                },
                {
                    "sent": "So you can say look this image is a great macro as great focus.",
                    "label": 0
                },
                {
                    "sent": "OK, and this image needs more depth of field.",
                    "label": 0
                },
                {
                    "sent": "OK, this image may be a bit more lights should be should be.",
                    "label": 0
                },
                {
                    "sent": "Boat or a sharper focus, so it's a safer kind of answer.",
                    "label": 0
                },
                {
                    "sent": "OK, and human tends to react better to this kind of this kind of interactions.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to wrap up and conclude, you want to implement.",
                    "label": 0
                },
                {
                    "sent": "Techniques for studying eye level image quality, while certainly you need large scale databases, generically I dimensional features like feature vector and if you can learn content dependent models so you get rid of eventual semantic eventual biases introduced by the semantic of the image and certainly consider textual features because you know for many visual problems text even natural text as act as a label.",
                    "label": 1
                },
                {
                    "sent": "And it's very powerful.",
                    "label": 0
                },
                {
                    "sent": "So I stopped.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, with this slide show of more qualitative results.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will be happy to take questions.",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}