{
    "id": "qln3smenio32jqt5ae5uareo42ozay55",
    "title": "Parallel and Distributed Graph Cuts by Dual Decomposition",
    "info": {
        "author": [
            "Petter Strandmark, Centre for Mathematical Sciences, Lund University"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Mathematics->Graph Theory"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_strandmark_pdgc/",
    "segmentation": [
        [
            "But we'll go ahead and start with our first speaker.",
            "The paper is entitled parallel and distributed graph cuts by dual decomposition by Peter Astrand.",
            "Mark Frederick call.",
            "Thank you for the introduction.",
            "It's great to be here.",
            "So what me and my coauthor has been trying to do is to develop a parallel method of solving the graph cut problem."
        ],
        [
            "And the motivation behind his work is the ubiquity of graph cuts in low level vision.",
            "This slide.",
            "Shows example of the image denoising stereo depth estimation shape fitting an segmentation and all of these use graph cuts to solve the underlying optimization problems."
        ],
        [
            "So the underlying optimization problem is finding the minimum cut of the graph.",
            "So we have two special nodes as in T and we would like the cost of all seven edges between them to be as low as possible and we still want to eliminate all possible paths between SMT and they need this graph by cutting three edges.",
            "We can achieve the minimum cut of four.",
            "This is the problem we want to solve."
        ],
        [
            "And previous work to parallelize the graph cut algorithm has been the most paper at CPR 2008 by Andrew Delong and Yuri Barkov.",
            "And they described a parallel implementation of the push relabel method.",
            "And they achieve very good speedups.",
            "In this paper, we will focus on other methods using augmented paths, which is also very common in computer vision, and it is more suitable for sparse 2D graphs.",
            "There's also been attempts of running push relabel on graphics hardware.",
            "And I have had very mixed results in using CUDA cuts, which was published and also had severe 2008 in a workshop.",
            "It works for some values of regularization and for some values of regularization we could not get it to work.",
            "More on this later.",
            "There's also been other attempts, for example, recasting the optimization problem as an L1 optimization problem.",
            "But so far this has not been faster than augmenting paths."
        ],
        [
            "And there is an interesting paper at this year's Eve car by Leo and Son, called Parallel Graph cuts by adaptive bottom up merging.",
            "And what they do?",
            "They they split the large graph into several pieces.",
            "And then augmenting paths, or are found individually in parallel for each piece.",
            "And then they merge the pieces in a clever way and reuse the search trees.",
            "And if you do have a poster in the post session this evening, which you can check out and our approach also splits the graph into several pieces.",
            "But the solutions are constrained to be equal with dual variables instead.",
            "And in this way we do not require shared memory, unlike the previous approach, and we will see that this will be very useful."
        ],
        [
            "So we have an optimization problem.",
            "Which is a sum of two functions.",
            "Let's say we have an optimization problem like this.",
            "And X1 only enters in the first function and X2 only enters in the second function and the functions share a common variable Y which is the coupling between the two.",
            "We can reformulate this into.",
            "A completely equivalent problem where we have replaced Y with Y1 and Y2 and we have an added in constraint that they should be equal.",
            "The natural way to proceed now is to dualize this constraint by taking the dual.",
            "And there is dual function.",
            "Is a ministration problem of F1 and F2.",
            "Separately, and where this circle term here is the term arising from from the equality constraint.",
            "And the most important observation here, and the main point of this talk, is that evaluating the dual function.",
            "Is consists of solving two independent optimization problems and this allows us to introduce parallelism and we will now see how this applies to graphs."
        ],
        [
            "This is a typical grid graph with edge costs and the SMT connections here are not are not shown here, so you will have to imagine lots of SMT connections entering densely into these graphs.",
            "And we now split this graph while we duplicate the middle of column.",
            "That now we have decomposed our optimization problem into two smaller ones.",
            "With intention from the previous slides X one or the variables unique to the left problem X2 are unique to the right problem.",
            "And Y1 and Y2 are supposed to be similar.",
            "And we will have to multiply these edges in the overlap by 1/2 in order to minimize the exactly the same function.",
            "So we want these variables in the overlap to be equal.",
            "But solving this subproblem once will introduce some disagreements.",
            "And.",
            "Whenever we have disagreements.",
            "That's where our dual variables come in.",
            "So we will try to.",
            "To have to modify our dual variables as an edge costs to change the edge costs in order to force these variables.",
            "In the left and right problem to agree.",
            "And this can be thought of as costs being introduced to the overlapping node, forcing them towards each other.",
            "And it's also a gradient descent of the dual function.",
            "We have more details on this in our paper.",
            "So we can think of it as cost or we can think of it as a gradient descent of the dual funk."
        ],
        [
            "And a very important question is, will we obtain the global solution of the original problem?",
            "This can be seen in the following way.",
            "We can first rewrite the minimum cut problem as a linear program.",
            "Then we decompose the linear program.",
            "Then we take the dual of this linear program.",
            "And from this formulation we can obtain the original data, the decomposed minimum cut problem.",
            "And also I.",
            "More details are in the paper.",
            "Now standard optimization theory then tells us that.",
            "We have 0 Delta gap.",
            "We have a dual function.",
            "Our dual function has a maximum such that the constraints are met and we are guaranteed indeed to have.",
            "The global solution.",
            "This is nice."
        ],
        [
            "We can also show in the paper that if the original graph have integer weights.",
            "Which not only are integer, but are even integers then.",
            "There exist an integer vector maximizing the dual function.",
            "What this means is that maximizing the dual function can be done without any floating point arithmetic.",
            "So we can perform all these optimizations in integer arithmetics and still be sure that there exists an integer maximum and a global solution."
        ],
        [
            "Once again, the idea is that we start out with a graph.",
            "We split the graph into two or more parts.",
            "We constrain them to be equal on the overlap.",
            "And these are two independent optimization problems which are so that we have to solve this over and over again.",
            "Modifying the dual variables."
        ],
        [
            "And we're not restricted to splitting the graph into two pieces here.",
            "I have split the graph into four pieces, and the blue part apart.",
            "The blue colored nodes are part of two pieces, and the green ones are part of four."
        ],
        [
            "Four pieces.",
            "And this works in three dimensions as well.",
            "The red part in the middle are part of all eight pieces of the of the cube."
        ],
        [
            "Here are some results we tried to do with the composition approach for about 300 images in the Berkeley Segmentation Database.",
            "And we recorded a time for a single threaded approach and a multithreaded approach.",
            "And the median speed up for two processes was .6 and 4.",
            "Four processes.",
            "We had achieved a median speed up of 2045 and this is compared to the standard work of Columbus Grove.",
            "The maximum flow algorithm.",
            "Which we also use to solve the subproblems."
        ],
        [
            "And since we are solving the two optimization problems over and over again, it might not seem that there would be anything to gain from this.",
            "But this table shows that the first iteration is the iteration that really takes up most of the running time.",
            "The first iteration takes 245 milliseconds and many of the subsequent iterations take as little time as 80 microseconds.",
            "This is becausw not much of the graph changes between iteration, since we're only changing a couple of the dual variables, we don't have to modify the entire graph and we can efficiently reduce the flow and just resolve the graph.",
            "It's very efficient, and for this particular example it had convergence in 11 iterations."
        ],
        [
            "And the most important question, and one in question, I think one has to ask is is to speed up regularization dependent?",
            "But to the left there isn't easy problem with very low regularization and to the right there is a hard problem at a harder problem with a lot of regularization.",
            "And with low regularization, the problem essentially becomes a thresholding problem and a thresholding problem is trivial to parallelize, and I think this is an important .1 has to try it and we try this.",
            "And this figure shows a speedup of our method as a function of the regularization to the left.",
            "The problem is very close to thresholding.",
            "Enter the right.",
            "We have a much harder.",
            "It takes a lot of lot of more time to solve and it's a high regularization problem.",
            "And even though the absolute runtimes vary a lot, the relative speedup remains roughly constant."
        ],
        [
            "And we have tried to.",
            "I tried to make this method fail, so I constructed a graph where the edge costs are based on the gradient of the image and then I added source connections to the left part of the image.",
            "And sink connections to the right part of the image, and then I.",
            "Split the graph in the middle and this split is.",
            "Severs all the possible St paths.",
            "But this we still could achieve 30% speedup.",
            "With the parallel approach, even though the first iteration, nothing really happens because the two left part does not have any sync connections.",
            "But I think this is a good indication that the choice of the split is not crucial to performance."
        ],
        [
            "And now I would like to turn to a different application.",
            "As I've mentioned before, we do not require shared memory.",
            "Different parts of the graph can be stored on different computers, for example here in this figure, information about the yellow pixels is only have only have to be communicated between computer one and computer 2.",
            "Each computer here is responsible for its particular piece of the graph, and only has to communicate the values of the boundaries to the to ITS computer neighbors.",
            "And this allows us to solve very big."
        ],
        [
            "Graphs.",
            "First we try to 400 by 400 by 300 graph and we solve this split across four computers.",
            "And even though we had some network communication we could solve this graph in seven seconds.",
            "And the biggest graphs, one of a couple of big graphs arise in medical imaging.",
            "We solve the four dimensional andmore image segmentation problem using four computers.",
            "And it was about 100 * 100 * 30 * 19.",
            "And here we used 80 connectivity, which is just eight analog analog, 8 connectivity in 4 dimensions.",
            "And if we if we wanted to store this graph on a single computer, we would have required 12 gigabytes of memory.",
            "And the largest data set we used was roughly 500 by 500 by 2300, and storing this on a single computer would have required 131 gigabytes of memory.",
            "Still.",
            "We were able to solve this when we split this data across 636 computers and we were able to solve this graph globally.",
            "2K."
        ],
        [
            "Include.",
            "Doing the composition of graphs allows faster processing and the ability to solve larger graphs.",
            "And we have released source code if anyone is interested.",
            "Thank you for your attention.",
            "We have time for a question or two."
        ],
        [
            "Hello so I really like this work.",
            "I just have a couple of questions so do decomposition is based on the subgradient descent and one of the known problems with that is that the convergence tends to be slow an it's not guaranteed monotonic improvements overtime and as opposed to that there are other coordinate descent schemes which although are guaranteed moronic improvement but might not converge to the global solution.",
            "So have you sort of experimented with different.",
            "Kinds of methods to solve the relaxation or or.",
            "But it's true that they will decomposition can sometimes be very slow in convergence, although for this particular problem we have observed very quick convergence actually.",
            "So in for this particular application, we found that the scheme which we use in the paper, it's quite.",
            "It's quite a heuristic scheme, but it works very well in practice.",
            "OK, sorry, just one quick question.",
            "You mentioned that your graphs overlapping have like a column in common to them, just the choice of the amount of overlap that result in.",
            "Faster convergence or does that not matter in your experiments?",
            "I could just come up the amount of overlap is also dependent on what type of graph you have.",
            "If you have for example, have 16 connectivity in the graph, you would have to have at least two columns of overlap.",
            "Because there's it's not allowed to have an edge going from from 1/2 of the graph to the other, so it's dependent on what type of graph you have, how much overlap you need.",
            "OK, thank you.",
            "According to Martin Wainwright, Inkoma Gore of 2005.",
            "There are optimal for our tree RW or tree weighted methods are optimal for submodular graphs, so you could have one graph for every single edge, and then you could apply.",
            "Then you could just do dynamic programming in each of those.",
            "So on what's my question is on what size graphs do you want to use so that you can get advantage of the graph cutover dual decomposition based tree weighted stuff.",
            "'cause they're both guaranteed to be globally optimal.",
            "You think just are you asking about the size of the subgraphs in the problem?",
            "Because it would they would.",
            "We cannot split the graphs into 100 pieces and expect good performance, so this is really a method of explaining it into a couple of pieces to 36 pieces we saw.",
            "That's that's quite, that's stretching it.",
            "I think you could.",
            "I disagree.",
            "OK.",
            "It's it, the convergence becomes quite slow with lots of pieces.",
            "One more question, and then we should keep moving.",
            "OK, I apologize that may not have been listening adequately, but.",
            "Do you have any an algorithmic analysis of this?",
            "In other words, in terms of computational complexity.",
            "No, this kind of more the science of algorithms kind of analysis rather than.",
            "Kind of a heuristic and.",
            "The short answer is no, we do not.",
            "We do not prove that this guarantees a speedup.",
            "So we're not able to prove that this actually will become faster than a single thread.",
            "I'm less interested in a proof of speedup as opposed to.",
            "A first principle analysis of what you're actually doing in the process, it looks like divide and conquer applied to a graph algorithm.",
            "But Are you sure that it that you're actually mood changing complexity classes are doing something that actually moves you forward.",
            "But since since the method we are using to solve the subproblems, I'm not even sure that this method has been proven to running in polynomial time.",
            "I'm not sure so.",
            "No we don't.",
            "I think we need to keep moving.",
            "Sorry, so let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we'll go ahead and start with our first speaker.",
                    "label": 0
                },
                {
                    "sent": "The paper is entitled parallel and distributed graph cuts by dual decomposition by Peter Astrand.",
                    "label": 0
                },
                {
                    "sent": "Mark Frederick call.",
                    "label": 0
                },
                {
                    "sent": "Thank you for the introduction.",
                    "label": 0
                },
                {
                    "sent": "It's great to be here.",
                    "label": 0
                },
                {
                    "sent": "So what me and my coauthor has been trying to do is to develop a parallel method of solving the graph cut problem.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the motivation behind his work is the ubiquity of graph cuts in low level vision.",
                    "label": 0
                },
                {
                    "sent": "This slide.",
                    "label": 0
                },
                {
                    "sent": "Shows example of the image denoising stereo depth estimation shape fitting an segmentation and all of these use graph cuts to solve the underlying optimization problems.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the underlying optimization problem is finding the minimum cut of the graph.",
                    "label": 0
                },
                {
                    "sent": "So we have two special nodes as in T and we would like the cost of all seven edges between them to be as low as possible and we still want to eliminate all possible paths between SMT and they need this graph by cutting three edges.",
                    "label": 0
                },
                {
                    "sent": "We can achieve the minimum cut of four.",
                    "label": 0
                },
                {
                    "sent": "This is the problem we want to solve.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And previous work to parallelize the graph cut algorithm has been the most paper at CPR 2008 by Andrew Delong and Yuri Barkov.",
                    "label": 0
                },
                {
                    "sent": "And they described a parallel implementation of the push relabel method.",
                    "label": 1
                },
                {
                    "sent": "And they achieve very good speedups.",
                    "label": 0
                },
                {
                    "sent": "In this paper, we will focus on other methods using augmented paths, which is also very common in computer vision, and it is more suitable for sparse 2D graphs.",
                    "label": 0
                },
                {
                    "sent": "There's also been attempts of running push relabel on graphics hardware.",
                    "label": 0
                },
                {
                    "sent": "And I have had very mixed results in using CUDA cuts, which was published and also had severe 2008 in a workshop.",
                    "label": 0
                },
                {
                    "sent": "It works for some values of regularization and for some values of regularization we could not get it to work.",
                    "label": 0
                },
                {
                    "sent": "More on this later.",
                    "label": 0
                },
                {
                    "sent": "There's also been other attempts, for example, recasting the optimization problem as an L1 optimization problem.",
                    "label": 0
                },
                {
                    "sent": "But so far this has not been faster than augmenting paths.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there is an interesting paper at this year's Eve car by Leo and Son, called Parallel Graph cuts by adaptive bottom up merging.",
                    "label": 0
                },
                {
                    "sent": "And what they do?",
                    "label": 0
                },
                {
                    "sent": "They they split the large graph into several pieces.",
                    "label": 1
                },
                {
                    "sent": "And then augmenting paths, or are found individually in parallel for each piece.",
                    "label": 0
                },
                {
                    "sent": "And then they merge the pieces in a clever way and reuse the search trees.",
                    "label": 0
                },
                {
                    "sent": "And if you do have a poster in the post session this evening, which you can check out and our approach also splits the graph into several pieces.",
                    "label": 0
                },
                {
                    "sent": "But the solutions are constrained to be equal with dual variables instead.",
                    "label": 1
                },
                {
                    "sent": "And in this way we do not require shared memory, unlike the previous approach, and we will see that this will be very useful.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have an optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Which is a sum of two functions.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have an optimization problem like this.",
                    "label": 0
                },
                {
                    "sent": "And X1 only enters in the first function and X2 only enters in the second function and the functions share a common variable Y which is the coupling between the two.",
                    "label": 0
                },
                {
                    "sent": "We can reformulate this into.",
                    "label": 0
                },
                {
                    "sent": "A completely equivalent problem where we have replaced Y with Y1 and Y2 and we have an added in constraint that they should be equal.",
                    "label": 0
                },
                {
                    "sent": "The natural way to proceed now is to dualize this constraint by taking the dual.",
                    "label": 0
                },
                {
                    "sent": "And there is dual function.",
                    "label": 0
                },
                {
                    "sent": "Is a ministration problem of F1 and F2.",
                    "label": 0
                },
                {
                    "sent": "Separately, and where this circle term here is the term arising from from the equality constraint.",
                    "label": 0
                },
                {
                    "sent": "And the most important observation here, and the main point of this talk, is that evaluating the dual function.",
                    "label": 0
                },
                {
                    "sent": "Is consists of solving two independent optimization problems and this allows us to introduce parallelism and we will now see how this applies to graphs.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a typical grid graph with edge costs and the SMT connections here are not are not shown here, so you will have to imagine lots of SMT connections entering densely into these graphs.",
                    "label": 0
                },
                {
                    "sent": "And we now split this graph while we duplicate the middle of column.",
                    "label": 0
                },
                {
                    "sent": "That now we have decomposed our optimization problem into two smaller ones.",
                    "label": 0
                },
                {
                    "sent": "With intention from the previous slides X one or the variables unique to the left problem X2 are unique to the right problem.",
                    "label": 0
                },
                {
                    "sent": "And Y1 and Y2 are supposed to be similar.",
                    "label": 0
                },
                {
                    "sent": "And we will have to multiply these edges in the overlap by 1/2 in order to minimize the exactly the same function.",
                    "label": 0
                },
                {
                    "sent": "So we want these variables in the overlap to be equal.",
                    "label": 0
                },
                {
                    "sent": "But solving this subproblem once will introduce some disagreements.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Whenever we have disagreements.",
                    "label": 0
                },
                {
                    "sent": "That's where our dual variables come in.",
                    "label": 0
                },
                {
                    "sent": "So we will try to.",
                    "label": 0
                },
                {
                    "sent": "To have to modify our dual variables as an edge costs to change the edge costs in order to force these variables.",
                    "label": 0
                },
                {
                    "sent": "In the left and right problem to agree.",
                    "label": 0
                },
                {
                    "sent": "And this can be thought of as costs being introduced to the overlapping node, forcing them towards each other.",
                    "label": 0
                },
                {
                    "sent": "And it's also a gradient descent of the dual function.",
                    "label": 0
                },
                {
                    "sent": "We have more details on this in our paper.",
                    "label": 0
                },
                {
                    "sent": "So we can think of it as cost or we can think of it as a gradient descent of the dual funk.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And a very important question is, will we obtain the global solution of the original problem?",
                    "label": 0
                },
                {
                    "sent": "This can be seen in the following way.",
                    "label": 0
                },
                {
                    "sent": "We can first rewrite the minimum cut problem as a linear program.",
                    "label": 0
                },
                {
                    "sent": "Then we decompose the linear program.",
                    "label": 0
                },
                {
                    "sent": "Then we take the dual of this linear program.",
                    "label": 0
                },
                {
                    "sent": "And from this formulation we can obtain the original data, the decomposed minimum cut problem.",
                    "label": 0
                },
                {
                    "sent": "And also I.",
                    "label": 0
                },
                {
                    "sent": "More details are in the paper.",
                    "label": 0
                },
                {
                    "sent": "Now standard optimization theory then tells us that.",
                    "label": 0
                },
                {
                    "sent": "We have 0 Delta gap.",
                    "label": 0
                },
                {
                    "sent": "We have a dual function.",
                    "label": 0
                },
                {
                    "sent": "Our dual function has a maximum such that the constraints are met and we are guaranteed indeed to have.",
                    "label": 1
                },
                {
                    "sent": "The global solution.",
                    "label": 0
                },
                {
                    "sent": "This is nice.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can also show in the paper that if the original graph have integer weights.",
                    "label": 0
                },
                {
                    "sent": "Which not only are integer, but are even integers then.",
                    "label": 0
                },
                {
                    "sent": "There exist an integer vector maximizing the dual function.",
                    "label": 1
                },
                {
                    "sent": "What this means is that maximizing the dual function can be done without any floating point arithmetic.",
                    "label": 0
                },
                {
                    "sent": "So we can perform all these optimizations in integer arithmetics and still be sure that there exists an integer maximum and a global solution.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once again, the idea is that we start out with a graph.",
                    "label": 0
                },
                {
                    "sent": "We split the graph into two or more parts.",
                    "label": 0
                },
                {
                    "sent": "We constrain them to be equal on the overlap.",
                    "label": 1
                },
                {
                    "sent": "And these are two independent optimization problems which are so that we have to solve this over and over again.",
                    "label": 0
                },
                {
                    "sent": "Modifying the dual variables.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we're not restricted to splitting the graph into two pieces here.",
                    "label": 0
                },
                {
                    "sent": "I have split the graph into four pieces, and the blue part apart.",
                    "label": 0
                },
                {
                    "sent": "The blue colored nodes are part of two pieces, and the green ones are part of four.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four pieces.",
                    "label": 0
                },
                {
                    "sent": "And this works in three dimensions as well.",
                    "label": 0
                },
                {
                    "sent": "The red part in the middle are part of all eight pieces of the of the cube.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are some results we tried to do with the composition approach for about 300 images in the Berkeley Segmentation Database.",
                    "label": 1
                },
                {
                    "sent": "And we recorded a time for a single threaded approach and a multithreaded approach.",
                    "label": 0
                },
                {
                    "sent": "And the median speed up for two processes was .6 and 4.",
                    "label": 0
                },
                {
                    "sent": "Four processes.",
                    "label": 0
                },
                {
                    "sent": "We had achieved a median speed up of 2045 and this is compared to the standard work of Columbus Grove.",
                    "label": 0
                },
                {
                    "sent": "The maximum flow algorithm.",
                    "label": 0
                },
                {
                    "sent": "Which we also use to solve the subproblems.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And since we are solving the two optimization problems over and over again, it might not seem that there would be anything to gain from this.",
                    "label": 0
                },
                {
                    "sent": "But this table shows that the first iteration is the iteration that really takes up most of the running time.",
                    "label": 0
                },
                {
                    "sent": "The first iteration takes 245 milliseconds and many of the subsequent iterations take as little time as 80 microseconds.",
                    "label": 0
                },
                {
                    "sent": "This is becausw not much of the graph changes between iteration, since we're only changing a couple of the dual variables, we don't have to modify the entire graph and we can efficiently reduce the flow and just resolve the graph.",
                    "label": 0
                },
                {
                    "sent": "It's very efficient, and for this particular example it had convergence in 11 iterations.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the most important question, and one in question, I think one has to ask is is to speed up regularization dependent?",
                    "label": 0
                },
                {
                    "sent": "But to the left there isn't easy problem with very low regularization and to the right there is a hard problem at a harder problem with a lot of regularization.",
                    "label": 1
                },
                {
                    "sent": "And with low regularization, the problem essentially becomes a thresholding problem and a thresholding problem is trivial to parallelize, and I think this is an important .1 has to try it and we try this.",
                    "label": 0
                },
                {
                    "sent": "And this figure shows a speedup of our method as a function of the regularization to the left.",
                    "label": 0
                },
                {
                    "sent": "The problem is very close to thresholding.",
                    "label": 0
                },
                {
                    "sent": "Enter the right.",
                    "label": 0
                },
                {
                    "sent": "We have a much harder.",
                    "label": 0
                },
                {
                    "sent": "It takes a lot of lot of more time to solve and it's a high regularization problem.",
                    "label": 0
                },
                {
                    "sent": "And even though the absolute runtimes vary a lot, the relative speedup remains roughly constant.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have tried to.",
                    "label": 0
                },
                {
                    "sent": "I tried to make this method fail, so I constructed a graph where the edge costs are based on the gradient of the image and then I added source connections to the left part of the image.",
                    "label": 0
                },
                {
                    "sent": "And sink connections to the right part of the image, and then I.",
                    "label": 0
                },
                {
                    "sent": "Split the graph in the middle and this split is.",
                    "label": 0
                },
                {
                    "sent": "Severs all the possible St paths.",
                    "label": 1
                },
                {
                    "sent": "But this we still could achieve 30% speedup.",
                    "label": 0
                },
                {
                    "sent": "With the parallel approach, even though the first iteration, nothing really happens because the two left part does not have any sync connections.",
                    "label": 0
                },
                {
                    "sent": "But I think this is a good indication that the choice of the split is not crucial to performance.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now I would like to turn to a different application.",
                    "label": 0
                },
                {
                    "sent": "As I've mentioned before, we do not require shared memory.",
                    "label": 0
                },
                {
                    "sent": "Different parts of the graph can be stored on different computers, for example here in this figure, information about the yellow pixels is only have only have to be communicated between computer one and computer 2.",
                    "label": 0
                },
                {
                    "sent": "Each computer here is responsible for its particular piece of the graph, and only has to communicate the values of the boundaries to the to ITS computer neighbors.",
                    "label": 0
                },
                {
                    "sent": "And this allows us to solve very big.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphs.",
                    "label": 0
                },
                {
                    "sent": "First we try to 400 by 400 by 300 graph and we solve this split across four computers.",
                    "label": 0
                },
                {
                    "sent": "And even though we had some network communication we could solve this graph in seven seconds.",
                    "label": 0
                },
                {
                    "sent": "And the biggest graphs, one of a couple of big graphs arise in medical imaging.",
                    "label": 0
                },
                {
                    "sent": "We solve the four dimensional andmore image segmentation problem using four computers.",
                    "label": 0
                },
                {
                    "sent": "And it was about 100 * 100 * 30 * 19.",
                    "label": 0
                },
                {
                    "sent": "And here we used 80 connectivity, which is just eight analog analog, 8 connectivity in 4 dimensions.",
                    "label": 0
                },
                {
                    "sent": "And if we if we wanted to store this graph on a single computer, we would have required 12 gigabytes of memory.",
                    "label": 0
                },
                {
                    "sent": "And the largest data set we used was roughly 500 by 500 by 2300, and storing this on a single computer would have required 131 gigabytes of memory.",
                    "label": 0
                },
                {
                    "sent": "Still.",
                    "label": 0
                },
                {
                    "sent": "We were able to solve this when we split this data across 636 computers and we were able to solve this graph globally.",
                    "label": 0
                },
                {
                    "sent": "2K.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Include.",
                    "label": 0
                },
                {
                    "sent": "Doing the composition of graphs allows faster processing and the ability to solve larger graphs.",
                    "label": 1
                },
                {
                    "sent": "And we have released source code if anyone is interested.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "We have time for a question or two.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello so I really like this work.",
                    "label": 0
                },
                {
                    "sent": "I just have a couple of questions so do decomposition is based on the subgradient descent and one of the known problems with that is that the convergence tends to be slow an it's not guaranteed monotonic improvements overtime and as opposed to that there are other coordinate descent schemes which although are guaranteed moronic improvement but might not converge to the global solution.",
                    "label": 0
                },
                {
                    "sent": "So have you sort of experimented with different.",
                    "label": 0
                },
                {
                    "sent": "Kinds of methods to solve the relaxation or or.",
                    "label": 0
                },
                {
                    "sent": "But it's true that they will decomposition can sometimes be very slow in convergence, although for this particular problem we have observed very quick convergence actually.",
                    "label": 0
                },
                {
                    "sent": "So in for this particular application, we found that the scheme which we use in the paper, it's quite.",
                    "label": 0
                },
                {
                    "sent": "It's quite a heuristic scheme, but it works very well in practice.",
                    "label": 0
                },
                {
                    "sent": "OK, sorry, just one quick question.",
                    "label": 0
                },
                {
                    "sent": "You mentioned that your graphs overlapping have like a column in common to them, just the choice of the amount of overlap that result in.",
                    "label": 0
                },
                {
                    "sent": "Faster convergence or does that not matter in your experiments?",
                    "label": 0
                },
                {
                    "sent": "I could just come up the amount of overlap is also dependent on what type of graph you have.",
                    "label": 0
                },
                {
                    "sent": "If you have for example, have 16 connectivity in the graph, you would have to have at least two columns of overlap.",
                    "label": 0
                },
                {
                    "sent": "Because there's it's not allowed to have an edge going from from 1/2 of the graph to the other, so it's dependent on what type of graph you have, how much overlap you need.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "According to Martin Wainwright, Inkoma Gore of 2005.",
                    "label": 0
                },
                {
                    "sent": "There are optimal for our tree RW or tree weighted methods are optimal for submodular graphs, so you could have one graph for every single edge, and then you could apply.",
                    "label": 0
                },
                {
                    "sent": "Then you could just do dynamic programming in each of those.",
                    "label": 0
                },
                {
                    "sent": "So on what's my question is on what size graphs do you want to use so that you can get advantage of the graph cutover dual decomposition based tree weighted stuff.",
                    "label": 0
                },
                {
                    "sent": "'cause they're both guaranteed to be globally optimal.",
                    "label": 0
                },
                {
                    "sent": "You think just are you asking about the size of the subgraphs in the problem?",
                    "label": 0
                },
                {
                    "sent": "Because it would they would.",
                    "label": 0
                },
                {
                    "sent": "We cannot split the graphs into 100 pieces and expect good performance, so this is really a method of explaining it into a couple of pieces to 36 pieces we saw.",
                    "label": 0
                },
                {
                    "sent": "That's that's quite, that's stretching it.",
                    "label": 0
                },
                {
                    "sent": "I think you could.",
                    "label": 0
                },
                {
                    "sent": "I disagree.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "It's it, the convergence becomes quite slow with lots of pieces.",
                    "label": 0
                },
                {
                    "sent": "One more question, and then we should keep moving.",
                    "label": 0
                },
                {
                    "sent": "OK, I apologize that may not have been listening adequately, but.",
                    "label": 0
                },
                {
                    "sent": "Do you have any an algorithmic analysis of this?",
                    "label": 0
                },
                {
                    "sent": "In other words, in terms of computational complexity.",
                    "label": 0
                },
                {
                    "sent": "No, this kind of more the science of algorithms kind of analysis rather than.",
                    "label": 0
                },
                {
                    "sent": "Kind of a heuristic and.",
                    "label": 0
                },
                {
                    "sent": "The short answer is no, we do not.",
                    "label": 0
                },
                {
                    "sent": "We do not prove that this guarantees a speedup.",
                    "label": 0
                },
                {
                    "sent": "So we're not able to prove that this actually will become faster than a single thread.",
                    "label": 0
                },
                {
                    "sent": "I'm less interested in a proof of speedup as opposed to.",
                    "label": 0
                },
                {
                    "sent": "A first principle analysis of what you're actually doing in the process, it looks like divide and conquer applied to a graph algorithm.",
                    "label": 0
                },
                {
                    "sent": "But Are you sure that it that you're actually mood changing complexity classes are doing something that actually moves you forward.",
                    "label": 0
                },
                {
                    "sent": "But since since the method we are using to solve the subproblems, I'm not even sure that this method has been proven to running in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure so.",
                    "label": 0
                },
                {
                    "sent": "No we don't.",
                    "label": 0
                },
                {
                    "sent": "I think we need to keep moving.",
                    "label": 0
                },
                {
                    "sent": "Sorry, so let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}