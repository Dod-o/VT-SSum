{
    "id": "4dsgnagyceyrunqxvyzv65x3suexoqvc",
    "title": "Applying Electromagnetic Field Theory Concepts to Clustering with Constraints",
    "info": {
        "author": [
            "Michalis Vazirgiannis, Athens UEB"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_vazirgiannis_aeftccc/",
    "segmentation": [
        [
            "So I will present this paper.",
            "I you have to forgive me because I I am not one of the authors so I might not be able to.",
            "Discuss on the deep technical details, but I will try to convey the message of the paper.",
            "Um?",
            "As I said, my name is Roger Ganish.",
            "I'm coming from the Department of Informatics of the University."
        ],
        [
            "Reference.",
            "So let's try to motivate this this work.",
            "The issue is that.",
            "When we have voluminous data, we would like to do clustering and the and the dimensionality can be very tough problem to tackle with and we know the dimensionality cache problem.",
            "On the other hand, local distances in several cases affect more than.",
            "At the two objects they connect, for instance in cases of cancer cells in a body sensor depression, local changes have a greater effect.",
            "So the idea is that working by pairwise distances instead of having the absolute coordinates of the objects can give us better results.",
            "And another factor that can give us much better performance are the so-called constraints constraints.",
            "In terms of sentences that say these two objects must be in the same cluster or those two objects must not be in the same.",
            "Cluster.",
            "So, um."
        ],
        [
            "And then in many cases, a set of a set of objects, a set of vectors are converted into a graph, and then we we apply the clustering algorithms on the graph.",
            "This is quite quite a common practice, but in this case the the contribution or the novelty that the authors try to propose is that they want to find a novel scheme of.",
            "Computing the distances on the graph, assuming that the nodes, if they are connected by.",
            "By a constraint in the sense that, for instance, this node and that node should be in the same cluster.",
            "This is given by the analogy that they have a magnetic bond and they are of opposite charges.",
            "So they are so they're attracted, while in the case that they have.",
            "Same charges, they are.",
            "They're not attracted, and the idea is that.",
            "Sets magnetic bond and I remind this represents like a positive or negative constraint should affect the other neighboring edges to some extent like an electromagnetic field would do.",
            "So this is a basic idea.",
            "The basic idea is how the ideas of of electromagnetism could help us in computing the updated weights.",
            "On a data graph.",
            "Um?",
            "So you see, here we have a.",
            "A negative bond.",
            "Or a positive bond.",
            "And this somehow affects the neighborhood and what we're trying to do is to find to quantify this this effect and find the new weights."
        ],
        [
            "Um?",
            "Related work, there are several different approaches that can be that are in the in the biography for finding distances or distance metrics.",
            "One very known one is the one bike sync.",
            "But all well, what we do is that we change the weights of the of the dimensions it has.",
            "It presents several shortcomings.",
            "Another case is to integrate constraints in metric learning.",
            "In one approach, like Delanco Tal have done, but this also.",
            "Sense some shortcomings."
        ],
        [
            "And.",
            "There's another approach, the one.",
            "By cooling settle where we have semi supervised graph clustering.",
            "So what we do is we map the original data via kernel to a new space and we try to have them linearly so far."
        ],
        [
            "Boo.",
            "But let's try to specify or to be a bit more concrete on this approach.",
            "Let's assume that these are our data OK, and for some pairs of those data we have negative or positive constraints.",
            "Must link or cannot link constraints.",
            "So for instance this.",
            "This is a negative constraint.",
            "So there is a repulsive effect.",
            "They if they could move they would go away from each other.",
            "Whereas for instance here between 15 and 14.",
            "There is an attractive case, and so this this field here should affect all the neighboring.",
            "Let's say edges as you see here.",
            "The constraint forms some some angle with the other edges, so there is a kind of direction of the other edges to the constraint, and as we will see later on, we are trying to define so-called vertical and horizontal distance of an edge.",
            "Do a constraint.",
            "And so if if we're talking about the positive edge like this one, this means that this positive edge means that these two points should be in the same cluster, and then this should have an effect of.",
            "Using the weight of the neighboring edges such that the distances become closer and therefore the other points become more similar.",
            "The reverse is happening for the negative edges where we have what we call the escalation ratio, which is the ratio by which the.",
            "And the weight on the edge on the neighboring edges should increase."
        ],
        [
            "Um?",
            "So here we define as I mentioned before, to new concepts, the vertical distance and the horizontal distance between between an existing edge.",
            "U VR2 random.",
            "Let's say nodes in the graph S&T are two nodes in the graph that are connected by a by a positive or by negative constraint.",
            "And we define the vertical distance of the UV edge.",
            "The to the axis of the constraint and the horizontal.",
            "The horizontal distance between those two concepts.",
            "The details.",
            "Technical details are in the paper.",
            "And here we see that.",
            "The intuition is that if the vertical distance increases.",
            "Then the effect of the constraint.",
            "To the to the edge decreases both for the negative and the positive cases.",
            "If the horizontal distance is distance, distance increases.",
            "This means that it goes outside or far away from the constraint.",
            "Then this decreases for the negative constraints.",
            "Whereas the horizontal distance has no effect on the positive constraints.",
            "So you see, here is small animation.",
            "How the vertical distance?",
            "And their horizontal distance affect."
        ],
        [
            "The cases.",
            "Here we have the definition of the escalation ratio and the reduction ratio.",
            "I remind that the escalation ratio is.",
            "The is the degree to which the weight increases.",
            "In the case of a neighboring negative constraint, whereas the reduction ratio is the degree to which the weight of an edge decreases, thus increasing the similarity between the two nodes.",
            "Because of the positive constraint that is in the area.",
            "Um?",
            "So here are the QE.",
            "For instance, is the weight of the cannot link constraints you are is the weight of the must link constraint and these are simply formulations of the intuition.",
            "Here is the the edge for which we want to compute the the escalation or the reduction ratio, and this is the pair of nodes that are constrained that are connected with a with a constraint."
        ],
        [
            "So finally every constraint affects.",
            "Potentially all other veggies in the graph, right?",
            "And the closer the the edge to the constraints, the larger the effect.",
            "So the overall ratio or the overall effect of the constraints on the weight of.",
            "Um often edge is given by the normalized sum of the of the escalation ratio from all the constraints from all the positive constraints and minus the.",
            "The normalized reduction ratio from all the negative constraints, and then for even more normalization reasons we we come up with this final formula that gives us the weight between.",
            "Two nodes as it results becausw of the effect of the other constraints."
        ],
        [
            "And then, um.",
            "Yeah.",
            "The objective is to do clustering and we have a three phase framework.",
            "The first is to.",
            "To create the graph from the original data.",
            "I.",
            "And then on this graph we would like to modify the weights according to the scheme that I presented before and then on this modified weight graph, we apply clustering and we try to evaluate the results.",
            "So this is the electromagnetic field based clustering JMC framework.",
            "Alright, so this is the acronym."
        ],
        [
            "That we will use in the following slides.",
            "The graph construction.",
            "Um?",
            "Is another straightforward one.",
            "We extract.",
            "The VM nearest neighbors for each object and we construct the graph based on that.",
            "If the resulting graph is very sparse, we try to.",
            "Connect it more by adding new edges such that it is sufficiently connected.",
            "It's a technical detail, it can be done.",
            "The interesting thing is.",
            "Basically, implements the scheme that I presented before is to readjust the edge the edge weights depending on the effect of the positive and negative.",
            "And negative constraints that we have and then we have a new affinity matrix.",
            "We have a new similarity matrix between our data.",
            "Then on this matrix we employ the K shortest path distance as a distance matrix.",
            "For various reasons that are well explained in the paper.",
            "Which of course has a significant problem that it is very slow.",
            "So instead of using the the shortest path distance, we use the K shortest path distance.",
            "That gives us a more credible measurement, but it is much more complex to compute."
        ],
        [
            "And then the clustering process is the one that.",
            "Applies.",
            "One of a multitude of clustering algorithms.",
            "In this case, the authors have used the Kemah droids and the hierarchical clustering, but they only report the K Madrid results.",
            "Um?",
            "It is important to stress that even a small amount of constraints.",
            "Gives significant significantly better performance."
        ],
        [
            "Now in the next three to four slides, the authors described.",
            "A small contribution or a secondary contribution on on how to compute in an efficient way the case shortest path problem.",
            "So the idea is that what we do is we have the graph and we want to compute the K shortest path similarity matrix.",
            "So what we do is we split this in number of partitions.",
            "We compute the local similarity matrices and then we try to find.",
            "The original distances using intermediate points, the so-called hubs, which are points that are, let's say, in between the partitions and they are connected to all the partitions.",
            "One could say.",
            "And these hubs are the only way from one partition to the other.",
            "Of course we can understand that there is a kind of error introduced, but apparently we can tolerate it.",
            "So."
        ],
        [
            "In a schematic way they the authors follow a divide and conquer approach.",
            "So what they do is they compute the similarity matrix for each partition and then they they compute the.",
            "The total metrics by using those hubs they claim that this can be up to 25 with up to 20 times faster compared to the centralized KSD problem, and thus it is applicable to."
        ],
        [
            "So two large graphs here.",
            "There is a.",
            "There is another animation on how they tackle this problem.",
            "So we have.",
            "This is the original graph and this is.",
            "The similarity metrics that we have to find.",
            "What they do is they split the graph into six partitions.",
            "Let's say these consider that these are the hubs OK?",
            "These are the connecting, let's say, points they compute for each of these partitions their local similarity matrices and."
        ],
        [
            "Then what they do is they they compute the so called as matrix matrix, which is the similarity matrix between the hubs.",
            "OK. And then they use this matrix.",
            "Do.",
            "Compute distances pairwise B."
        ],
        [
            "In all the partitions and thus this is the distance matrix for the hubs.",
            "So far we have not completed our task."
        ],
        [
            "So if we now want to compute the K as the shortest path distance between two partitions, for instance.",
            "The top left and the bottom right."
        ],
        [
            "What we do is we update the distances from the First partition node one."
        ],
        [
            "To 2nd partition hubs through the 1st Hub.",
            "So you see here."
        ],
        [
            "What is going on?",
            "And then.",
            "You see that through through the hubs we can."
        ],
        [
            "Compute the distances of all those points to.",
            "To the bottom right partition.",
            "And then.",
            "Similarly, we can compute the distance."
        ],
        [
            "Is.",
            "In a reverse way.",
            "Now let's get today to the experimental part.",
            "The authors have used both synthetic and real world datasets.",
            "Here is a.",
            "Here are the real world datasets all coming from the UCI machine learning repository.",
            "You see, we have a variety of sizes, dimensionality's, number of clusters, etc."
        ],
        [
            "Um?",
            "And they compared their approach.",
            "The AMCC means to.",
            "To the majority, or to do all the other competing approaches of semi supervised clustering and the experimental setup is that they use the same constraint sets.",
            "They use constraints that are chosen at random and they represent a specific.",
            "Portion of the data set.",
            "So for instance, we assume 10% of the data for four, 10% of the total number of pairs we know if they should be in the same cluster or not."
        ],
        [
            "Here is a one set of experiments.",
            "And this set of experiment shows for each different datasets, the accuracy of the clustering, which means each pair of objects is considered correct if the two objects are in the same correctly or not in the same correctly, and there is a kind of.",
            "The accuracy.",
            "Is defined here OK in the paper?",
            "On the horizontal axis we have the.",
            "A number of constraints, so you see we have 20 forty 6080.",
            "Or 100% constraints.",
            "In this these colors here, resulting in different lines, represent the number of of.",
            "The number of K shortest distance is how many?",
            "What is the value of K in the computation of the K shortest distances?",
            "So we see that in some cases we have some interesting effect.",
            "Um?"
        ],
        [
            "And here is the comparison of the data of the of the AMC framework to the performance of other competing algorithms.",
            "And it is interesting that it outperforms the competing approaches for the Irish balance and Tiina Sphere datasets consistently.",
            "As you might see here, is.",
            "Our interest.",
            "It's significantly better.",
            "Whereas it loses.",
            "Significantly in in wine OK. And for the rest, it has a reasonable performance.",
            "I remind again that this is the basically the number of constraints that I use as additional notice.",
            "This is the accuracy, and these are the different competing algorithms.",
            "This is VMC algorithm."
        ],
        [
            "And this brings me to the conclusions so.",
            "Then the message of this paper, as far as I can transmit it on behalf of the authors is that they propose a novel scheme for modifying the weights.",
            "Of of a similarity matrix represented as a graph based on the intuition that.",
            "Is given by the electromagnetic, let's say field area, where the magnetic bonds are constraints, either positive or negative.",
            "The.",
            "The experiments show that this is a.",
            "This is a.",
            "This is not.",
            "This is an approach that gives a very good performance and they report here at least of future work items that I believe they're in a better position than me to explain.",
            "So thank you very much for your attention.",
            "Are there still at least high level questions?",
            "Did you enjoy giving this talk?",
            "Well, actually, you know, I was asked to kind of kind of a couple of days ago and I had to read, but you know, as we have some long-term collaboration with binoculars, who is one of the authors?",
            "I kind of understand what they're doing as my first degrees in physics.",
            "I kind of enjoy this electromagnetic thing, but that means you can actually answer your questions.",
            "So come off some of them, no.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will present this paper.",
                    "label": 0
                },
                {
                    "sent": "I you have to forgive me because I I am not one of the authors so I might not be able to.",
                    "label": 0
                },
                {
                    "sent": "Discuss on the deep technical details, but I will try to convey the message of the paper.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "As I said, my name is Roger Ganish.",
                    "label": 0
                },
                {
                    "sent": "I'm coming from the Department of Informatics of the University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reference.",
                    "label": 0
                },
                {
                    "sent": "So let's try to motivate this this work.",
                    "label": 0
                },
                {
                    "sent": "The issue is that.",
                    "label": 0
                },
                {
                    "sent": "When we have voluminous data, we would like to do clustering and the and the dimensionality can be very tough problem to tackle with and we know the dimensionality cache problem.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, local distances in several cases affect more than.",
                    "label": 1
                },
                {
                    "sent": "At the two objects they connect, for instance in cases of cancer cells in a body sensor depression, local changes have a greater effect.",
                    "label": 1
                },
                {
                    "sent": "So the idea is that working by pairwise distances instead of having the absolute coordinates of the objects can give us better results.",
                    "label": 0
                },
                {
                    "sent": "And another factor that can give us much better performance are the so-called constraints constraints.",
                    "label": 0
                },
                {
                    "sent": "In terms of sentences that say these two objects must be in the same cluster or those two objects must not be in the same.",
                    "label": 0
                },
                {
                    "sent": "Cluster.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then in many cases, a set of a set of objects, a set of vectors are converted into a graph, and then we we apply the clustering algorithms on the graph.",
                    "label": 0
                },
                {
                    "sent": "This is quite quite a common practice, but in this case the the contribution or the novelty that the authors try to propose is that they want to find a novel scheme of.",
                    "label": 0
                },
                {
                    "sent": "Computing the distances on the graph, assuming that the nodes, if they are connected by.",
                    "label": 0
                },
                {
                    "sent": "By a constraint in the sense that, for instance, this node and that node should be in the same cluster.",
                    "label": 0
                },
                {
                    "sent": "This is given by the analogy that they have a magnetic bond and they are of opposite charges.",
                    "label": 0
                },
                {
                    "sent": "So they are so they're attracted, while in the case that they have.",
                    "label": 0
                },
                {
                    "sent": "Same charges, they are.",
                    "label": 0
                },
                {
                    "sent": "They're not attracted, and the idea is that.",
                    "label": 0
                },
                {
                    "sent": "Sets magnetic bond and I remind this represents like a positive or negative constraint should affect the other neighboring edges to some extent like an electromagnetic field would do.",
                    "label": 0
                },
                {
                    "sent": "So this is a basic idea.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is how the ideas of of electromagnetism could help us in computing the updated weights.",
                    "label": 0
                },
                {
                    "sent": "On a data graph.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So you see, here we have a.",
                    "label": 0
                },
                {
                    "sent": "A negative bond.",
                    "label": 0
                },
                {
                    "sent": "Or a positive bond.",
                    "label": 0
                },
                {
                    "sent": "And this somehow affects the neighborhood and what we're trying to do is to find to quantify this this effect and find the new weights.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Related work, there are several different approaches that can be that are in the in the biography for finding distances or distance metrics.",
                    "label": 0
                },
                {
                    "sent": "One very known one is the one bike sync.",
                    "label": 0
                },
                {
                    "sent": "But all well, what we do is that we change the weights of the of the dimensions it has.",
                    "label": 0
                },
                {
                    "sent": "It presents several shortcomings.",
                    "label": 0
                },
                {
                    "sent": "Another case is to integrate constraints in metric learning.",
                    "label": 0
                },
                {
                    "sent": "In one approach, like Delanco Tal have done, but this also.",
                    "label": 0
                },
                {
                    "sent": "Sense some shortcomings.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "There's another approach, the one.",
                    "label": 0
                },
                {
                    "sent": "By cooling settle where we have semi supervised graph clustering.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we map the original data via kernel to a new space and we try to have them linearly so far.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Boo.",
                    "label": 0
                },
                {
                    "sent": "But let's try to specify or to be a bit more concrete on this approach.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that these are our data OK, and for some pairs of those data we have negative or positive constraints.",
                    "label": 0
                },
                {
                    "sent": "Must link or cannot link constraints.",
                    "label": 0
                },
                {
                    "sent": "So for instance this.",
                    "label": 0
                },
                {
                    "sent": "This is a negative constraint.",
                    "label": 0
                },
                {
                    "sent": "So there is a repulsive effect.",
                    "label": 0
                },
                {
                    "sent": "They if they could move they would go away from each other.",
                    "label": 0
                },
                {
                    "sent": "Whereas for instance here between 15 and 14.",
                    "label": 0
                },
                {
                    "sent": "There is an attractive case, and so this this field here should affect all the neighboring.",
                    "label": 0
                },
                {
                    "sent": "Let's say edges as you see here.",
                    "label": 0
                },
                {
                    "sent": "The constraint forms some some angle with the other edges, so there is a kind of direction of the other edges to the constraint, and as we will see later on, we are trying to define so-called vertical and horizontal distance of an edge.",
                    "label": 0
                },
                {
                    "sent": "Do a constraint.",
                    "label": 0
                },
                {
                    "sent": "And so if if we're talking about the positive edge like this one, this means that this positive edge means that these two points should be in the same cluster, and then this should have an effect of.",
                    "label": 0
                },
                {
                    "sent": "Using the weight of the neighboring edges such that the distances become closer and therefore the other points become more similar.",
                    "label": 0
                },
                {
                    "sent": "The reverse is happening for the negative edges where we have what we call the escalation ratio, which is the ratio by which the.",
                    "label": 0
                },
                {
                    "sent": "And the weight on the edge on the neighboring edges should increase.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So here we define as I mentioned before, to new concepts, the vertical distance and the horizontal distance between between an existing edge.",
                    "label": 0
                },
                {
                    "sent": "U VR2 random.",
                    "label": 0
                },
                {
                    "sent": "Let's say nodes in the graph S&T are two nodes in the graph that are connected by a by a positive or by negative constraint.",
                    "label": 0
                },
                {
                    "sent": "And we define the vertical distance of the UV edge.",
                    "label": 0
                },
                {
                    "sent": "The to the axis of the constraint and the horizontal.",
                    "label": 1
                },
                {
                    "sent": "The horizontal distance between those two concepts.",
                    "label": 0
                },
                {
                    "sent": "The details.",
                    "label": 0
                },
                {
                    "sent": "Technical details are in the paper.",
                    "label": 0
                },
                {
                    "sent": "And here we see that.",
                    "label": 0
                },
                {
                    "sent": "The intuition is that if the vertical distance increases.",
                    "label": 1
                },
                {
                    "sent": "Then the effect of the constraint.",
                    "label": 1
                },
                {
                    "sent": "To the to the edge decreases both for the negative and the positive cases.",
                    "label": 0
                },
                {
                    "sent": "If the horizontal distance is distance, distance increases.",
                    "label": 1
                },
                {
                    "sent": "This means that it goes outside or far away from the constraint.",
                    "label": 0
                },
                {
                    "sent": "Then this decreases for the negative constraints.",
                    "label": 0
                },
                {
                    "sent": "Whereas the horizontal distance has no effect on the positive constraints.",
                    "label": 1
                },
                {
                    "sent": "So you see, here is small animation.",
                    "label": 1
                },
                {
                    "sent": "How the vertical distance?",
                    "label": 0
                },
                {
                    "sent": "And their horizontal distance affect.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The cases.",
                    "label": 0
                },
                {
                    "sent": "Here we have the definition of the escalation ratio and the reduction ratio.",
                    "label": 0
                },
                {
                    "sent": "I remind that the escalation ratio is.",
                    "label": 0
                },
                {
                    "sent": "The is the degree to which the weight increases.",
                    "label": 0
                },
                {
                    "sent": "In the case of a neighboring negative constraint, whereas the reduction ratio is the degree to which the weight of an edge decreases, thus increasing the similarity between the two nodes.",
                    "label": 0
                },
                {
                    "sent": "Because of the positive constraint that is in the area.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So here are the QE.",
                    "label": 0
                },
                {
                    "sent": "For instance, is the weight of the cannot link constraints you are is the weight of the must link constraint and these are simply formulations of the intuition.",
                    "label": 1
                },
                {
                    "sent": "Here is the the edge for which we want to compute the the escalation or the reduction ratio, and this is the pair of nodes that are constrained that are connected with a with a constraint.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally every constraint affects.",
                    "label": 0
                },
                {
                    "sent": "Potentially all other veggies in the graph, right?",
                    "label": 0
                },
                {
                    "sent": "And the closer the the edge to the constraints, the larger the effect.",
                    "label": 0
                },
                {
                    "sent": "So the overall ratio or the overall effect of the constraints on the weight of.",
                    "label": 1
                },
                {
                    "sent": "Um often edge is given by the normalized sum of the of the escalation ratio from all the constraints from all the positive constraints and minus the.",
                    "label": 0
                },
                {
                    "sent": "The normalized reduction ratio from all the negative constraints, and then for even more normalization reasons we we come up with this final formula that gives us the weight between.",
                    "label": 0
                },
                {
                    "sent": "Two nodes as it results becausw of the effect of the other constraints.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then, um.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The objective is to do clustering and we have a three phase framework.",
                    "label": 0
                },
                {
                    "sent": "The first is to.",
                    "label": 0
                },
                {
                    "sent": "To create the graph from the original data.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "And then on this graph we would like to modify the weights according to the scheme that I presented before and then on this modified weight graph, we apply clustering and we try to evaluate the results.",
                    "label": 0
                },
                {
                    "sent": "So this is the electromagnetic field based clustering JMC framework.",
                    "label": 1
                },
                {
                    "sent": "Alright, so this is the acronym.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we will use in the following slides.",
                    "label": 0
                },
                {
                    "sent": "The graph construction.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Is another straightforward one.",
                    "label": 0
                },
                {
                    "sent": "We extract.",
                    "label": 0
                },
                {
                    "sent": "The VM nearest neighbors for each object and we construct the graph based on that.",
                    "label": 1
                },
                {
                    "sent": "If the resulting graph is very sparse, we try to.",
                    "label": 0
                },
                {
                    "sent": "Connect it more by adding new edges such that it is sufficiently connected.",
                    "label": 0
                },
                {
                    "sent": "It's a technical detail, it can be done.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is.",
                    "label": 0
                },
                {
                    "sent": "Basically, implements the scheme that I presented before is to readjust the edge the edge weights depending on the effect of the positive and negative.",
                    "label": 1
                },
                {
                    "sent": "And negative constraints that we have and then we have a new affinity matrix.",
                    "label": 1
                },
                {
                    "sent": "We have a new similarity matrix between our data.",
                    "label": 1
                },
                {
                    "sent": "Then on this matrix we employ the K shortest path distance as a distance matrix.",
                    "label": 0
                },
                {
                    "sent": "For various reasons that are well explained in the paper.",
                    "label": 0
                },
                {
                    "sent": "Which of course has a significant problem that it is very slow.",
                    "label": 0
                },
                {
                    "sent": "So instead of using the the shortest path distance, we use the K shortest path distance.",
                    "label": 0
                },
                {
                    "sent": "That gives us a more credible measurement, but it is much more complex to compute.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then the clustering process is the one that.",
                    "label": 1
                },
                {
                    "sent": "Applies.",
                    "label": 0
                },
                {
                    "sent": "One of a multitude of clustering algorithms.",
                    "label": 1
                },
                {
                    "sent": "In this case, the authors have used the Kemah droids and the hierarchical clustering, but they only report the K Madrid results.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "It is important to stress that even a small amount of constraints.",
                    "label": 1
                },
                {
                    "sent": "Gives significant significantly better performance.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now in the next three to four slides, the authors described.",
                    "label": 0
                },
                {
                    "sent": "A small contribution or a secondary contribution on on how to compute in an efficient way the case shortest path problem.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that what we do is we have the graph and we want to compute the K shortest path similarity matrix.",
                    "label": 1
                },
                {
                    "sent": "So what we do is we split this in number of partitions.",
                    "label": 0
                },
                {
                    "sent": "We compute the local similarity matrices and then we try to find.",
                    "label": 0
                },
                {
                    "sent": "The original distances using intermediate points, the so-called hubs, which are points that are, let's say, in between the partitions and they are connected to all the partitions.",
                    "label": 0
                },
                {
                    "sent": "One could say.",
                    "label": 0
                },
                {
                    "sent": "And these hubs are the only way from one partition to the other.",
                    "label": 1
                },
                {
                    "sent": "Of course we can understand that there is a kind of error introduced, but apparently we can tolerate it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In a schematic way they the authors follow a divide and conquer approach.",
                    "label": 0
                },
                {
                    "sent": "So what they do is they compute the similarity matrix for each partition and then they they compute the.",
                    "label": 1
                },
                {
                    "sent": "The total metrics by using those hubs they claim that this can be up to 25 with up to 20 times faster compared to the centralized KSD problem, and thus it is applicable to.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So two large graphs here.",
                    "label": 0
                },
                {
                    "sent": "There is a.",
                    "label": 0
                },
                {
                    "sent": "There is another animation on how they tackle this problem.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "This is the original graph and this is.",
                    "label": 0
                },
                {
                    "sent": "The similarity metrics that we have to find.",
                    "label": 0
                },
                {
                    "sent": "What they do is they split the graph into six partitions.",
                    "label": 0
                },
                {
                    "sent": "Let's say these consider that these are the hubs OK?",
                    "label": 0
                },
                {
                    "sent": "These are the connecting, let's say, points they compute for each of these partitions their local similarity matrices and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then what they do is they they compute the so called as matrix matrix, which is the similarity matrix between the hubs.",
                    "label": 0
                },
                {
                    "sent": "OK. And then they use this matrix.",
                    "label": 0
                },
                {
                    "sent": "Do.",
                    "label": 0
                },
                {
                    "sent": "Compute distances pairwise B.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In all the partitions and thus this is the distance matrix for the hubs.",
                    "label": 0
                },
                {
                    "sent": "So far we have not completed our task.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we now want to compute the K as the shortest path distance between two partitions, for instance.",
                    "label": 0
                },
                {
                    "sent": "The top left and the bottom right.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do is we update the distances from the First partition node one.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To 2nd partition hubs through the 1st Hub.",
                    "label": 0
                },
                {
                    "sent": "So you see here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is going on?",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "You see that through through the hubs we can.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compute the distances of all those points to.",
                    "label": 0
                },
                {
                    "sent": "To the bottom right partition.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Similarly, we can compute the distance.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "In a reverse way.",
                    "label": 0
                },
                {
                    "sent": "Now let's get today to the experimental part.",
                    "label": 0
                },
                {
                    "sent": "The authors have used both synthetic and real world datasets.",
                    "label": 1
                },
                {
                    "sent": "Here is a.",
                    "label": 0
                },
                {
                    "sent": "Here are the real world datasets all coming from the UCI machine learning repository.",
                    "label": 1
                },
                {
                    "sent": "You see, we have a variety of sizes, dimensionality's, number of clusters, etc.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And they compared their approach.",
                    "label": 0
                },
                {
                    "sent": "The AMCC means to.",
                    "label": 0
                },
                {
                    "sent": "To the majority, or to do all the other competing approaches of semi supervised clustering and the experimental setup is that they use the same constraint sets.",
                    "label": 1
                },
                {
                    "sent": "They use constraints that are chosen at random and they represent a specific.",
                    "label": 1
                },
                {
                    "sent": "Portion of the data set.",
                    "label": 0
                },
                {
                    "sent": "So for instance, we assume 10% of the data for four, 10% of the total number of pairs we know if they should be in the same cluster or not.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is a one set of experiments.",
                    "label": 0
                },
                {
                    "sent": "And this set of experiment shows for each different datasets, the accuracy of the clustering, which means each pair of objects is considered correct if the two objects are in the same correctly or not in the same correctly, and there is a kind of.",
                    "label": 0
                },
                {
                    "sent": "The accuracy.",
                    "label": 0
                },
                {
                    "sent": "Is defined here OK in the paper?",
                    "label": 0
                },
                {
                    "sent": "On the horizontal axis we have the.",
                    "label": 0
                },
                {
                    "sent": "A number of constraints, so you see we have 20 forty 6080.",
                    "label": 0
                },
                {
                    "sent": "Or 100% constraints.",
                    "label": 0
                },
                {
                    "sent": "In this these colors here, resulting in different lines, represent the number of of.",
                    "label": 0
                },
                {
                    "sent": "The number of K shortest distance is how many?",
                    "label": 1
                },
                {
                    "sent": "What is the value of K in the computation of the K shortest distances?",
                    "label": 0
                },
                {
                    "sent": "So we see that in some cases we have some interesting effect.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here is the comparison of the data of the of the AMC framework to the performance of other competing algorithms.",
                    "label": 1
                },
                {
                    "sent": "And it is interesting that it outperforms the competing approaches for the Irish balance and Tiina Sphere datasets consistently.",
                    "label": 1
                },
                {
                    "sent": "As you might see here, is.",
                    "label": 0
                },
                {
                    "sent": "Our interest.",
                    "label": 0
                },
                {
                    "sent": "It's significantly better.",
                    "label": 0
                },
                {
                    "sent": "Whereas it loses.",
                    "label": 0
                },
                {
                    "sent": "Significantly in in wine OK. And for the rest, it has a reasonable performance.",
                    "label": 0
                },
                {
                    "sent": "I remind again that this is the basically the number of constraints that I use as additional notice.",
                    "label": 0
                },
                {
                    "sent": "This is the accuracy, and these are the different competing algorithms.",
                    "label": 0
                },
                {
                    "sent": "This is VMC algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this brings me to the conclusions so.",
                    "label": 0
                },
                {
                    "sent": "Then the message of this paper, as far as I can transmit it on behalf of the authors is that they propose a novel scheme for modifying the weights.",
                    "label": 0
                },
                {
                    "sent": "Of of a similarity matrix represented as a graph based on the intuition that.",
                    "label": 0
                },
                {
                    "sent": "Is given by the electromagnetic, let's say field area, where the magnetic bonds are constraints, either positive or negative.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The experiments show that this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "This is not.",
                    "label": 0
                },
                {
                    "sent": "This is an approach that gives a very good performance and they report here at least of future work items that I believe they're in a better position than me to explain.",
                    "label": 0
                },
                {
                    "sent": "So thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "Are there still at least high level questions?",
                    "label": 0
                },
                {
                    "sent": "Did you enjoy giving this talk?",
                    "label": 0
                },
                {
                    "sent": "Well, actually, you know, I was asked to kind of kind of a couple of days ago and I had to read, but you know, as we have some long-term collaboration with binoculars, who is one of the authors?",
                    "label": 0
                },
                {
                    "sent": "I kind of understand what they're doing as my first degrees in physics.",
                    "label": 0
                },
                {
                    "sent": "I kind of enjoy this electromagnetic thing, but that means you can actually answer your questions.",
                    "label": 0
                },
                {
                    "sent": "So come off some of them, no.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}