{
    "id": "adjzcd32bewp32aiuddq5ki6545wuxe4",
    "title": "Priors over Recurrent Continuous Time Processes",
    "info": {
        "author": [
            "Ardavan Saeedi, University of British Columbia"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/nips2011_saeedi_time/",
    "segmentation": [
        [
            "Hello everyone, first I want to thank you my supervisor Alexandre Bouchard for his support and help for this work without his help winning this prize was impossible.",
            "So my talk is on players over recurrent continuous time processes.",
            "This is a as I said, this is joint work with Alexandra Chart Keteyian.",
            "We're from University of British Columbia."
        ],
        [
            "So I'll start with an example of data that we are interested in.",
            "Data from multiple sources or Ms patients.",
            "Ms is a complex neurological disease which is poorly understood.",
            "There are different measurements for measuring disability in Ms patients.",
            "The most commonly used is called EDSS.",
            "One characteristic of EDS is that it changed up properly.",
            "This means patients disability condition will jump from one media state to another radius state.",
            "Another characteristic of.",
            "Ms patients is that they undergo cycles of relapses and remissions and relapses.",
            "New neurological symptoms occur, new disability occurs at.",
            "EDSS increases and in remission periods, patients recover from these symptoms and as a result, the EDSS value decreases."
        ],
        [
            "It is a sequence is not Markovian, but adding a latent structure we can make it more convenient.",
            "As an example, here we have an observed sequence of ideas is for one patient on the left hand side on the right hand side we have a simple one example of a simple latent structure.",
            "We denote the state space of the latent structure with Omega.",
            "Here, each PD assist represents a group of latent states.",
            "For instance, the 1st four latent states are represented by idiots, and observations are only limited to edius values.",
            "So, but the problem here is."
        ],
        [
            "The latent structural complexity is unknown.",
            "That's due to complexity of the disease and our poor understanding of the disease.",
            "Another characteristic of the data is that since we are in a continuous time framework, there are there are transitions that we transitions can occur at anytime point.",
            "Moreover, radius values are only available at potentially unequal time intervals.",
            "For example, for one patient we have easiest values.",
            "At these time points and.",
            "That's all the measurements that we have for one patient."
        ],
        [
            "But we are not interested only in an estate are we are interested in general cases where we have data with the following properties where we have a latent structure with unknown complexity, where we have a latent process which is a joint process.",
            "We have recurrence or repeated patterns.",
            "We have a continuous time framework and finally we can have observations at potentially on equal time intervals.",
            "We are going to propose a nonparametric Bayesian model for such data for such situation."
        ],
        [
            "The outline of the remaining parts of this talk is as follows.",
            "I'll talk about some related nonparametric Bayesian models and talk about some background.",
            "I'll introduce the basic version of our model, the goal exponential process, and I'll extend the model to the hero tickle urgent, the AGP.",
            "I'll briefly talk about inference in partially observed sequences, or let's discuss the results of our experiments, and I'll conclude the talk with some.",
            "Remarks"
        ],
        [
            "There are some related nonparametric Bayesian models for transient processes.",
            "By transient I mean processes where the observation at timepoint S the effect of an observation at time point is on the on the prediction at time point T + S will decrease as X goes to Infinity.",
            "In other words, these these processes are forgetful.",
            "Examples include dependent regional processes, DDP, Ornstein, Uhlenbeck traditional processes.",
            "And stick breaking autoregressive processes.",
            "However, there are some nonparametric Bayesian models for recurrent processes, but they are in discrete time framework.",
            "Examples include informational and sticky HTP hmm.",
            "We are going to fill the gap for nonparametric Bayesian model for recurrent continuous time processes."
        ],
        [
            "Now I'm going to talk about some background on Markov processes.",
            "The Markov process with them state is characterized by the off diagonal element entries of a rate matrix.",
            "Array matrix is similar to the transition probability matrix for Markov.",
            "For Markov chain, the differences here we have one more degree of freedom for which for each row, in other words, the sum of off diagonal elements of each row is not necessarily equal to 1.",
            "So we have one more extra degree of freedom, which gives us the waiting time at each state."
        ],
        [
            "Samples from a Markov process or a list of pairs of latent states, denoted by time and waiting times denoted by JJ.",
            "All the latent informationfor end transitions are denoted by X, which is basically the list of pairs of Dayton and J in front.",
            "The first transition, an equal to 1 to the end transition in order to sample from a continuous time Markov process, we can use Adobe Gillespie algorithm.",
            "Given the rate matrix Q and the current state data or equal to Omega I, we can sample the waiting time until the next transition by sampling from an exponential distribution with the rate parameter equal to the sum of off diagonal elements of the row corresponding to the current state.",
            "So we sampled the waiting time an in order to sample the next state.",
            "We take the role of the current state, normalize it an sample from a multinomial.",
            "Distribution, so we sampled the next state again.",
            "Sample the waiting time and so."
        ],
        [
            "Now I'm going to introduce the basic version of our model.",
            "The goal exponential process."
        ],
        [
            "We want models with an adaptive complexity in in order to have that we allow for any number of states using an infinite dimensional rate matrix.",
            "Our goal and the topic of this talk is to develop priors on such infinite rate matrices."
        ],
        [
            "The high level idea of the model is that view of the overall elements for each row of the rate matrix as a positive measure and use more angama process.",
            "Basically the global process to generate each row of the rate matrix."
        ],
        [
            "Why do we need a gamma process in order to have a conjugate prior over the rate matrix?",
            "Will base the Priors on a global process and measure values the casting process with gamma distribution marginals?",
            "There are three parameters for a gamma process, a concentration parameter and based probability distribution, and the rate parameter.",
            "The first 2 parameters can be grouped in a finite base in a finite base measure denoted by edge, not.",
            "Some notation that will be useful, or the normalization constant of a measure denoted by norm of mu and the normalized measure mu bar.",
            ", processes similar to additional process but with one extra degree of freedom.",
            "This extra degree of freedom will allow us to control for the waiting time at each state.",
            "In fact, if you is sampled from a gamma distribution, mu bar is a drizzler process."
        ],
        [
            "Now I'm going to define the gamma exponential process by defining its generated model in GPS.",
            "the Rose operate matrix or obtained by sampling IID from a gamma process, and then events are generated from this rate matrix by using do Gillespie algorithm."
        ],
        [
            "Suppose it's not is the base measure with a countable support.",
            "We will relax this assumption later.",
            "Then for each row of the rate matrix, sample ID from a gamma process with this base measure.",
            "For example, here we have a sample of a simple base measure count with countable support.",
            "We sample for one row only guy this is this is a sample measure.",
            "We feel that the role corresponding to that corresponding to that state in the rate matrix.",
            "With these with this measure, for example here Mu Omega, Omega Two encodes the length of this stick.",
            "So."
        ],
        [
            "Given the rate given the rates and the current state.",
            "We can sample the waiting time until the next transition by sampling from an exponential distribution with the rate parameter equal to the norm.",
            "Of this, of the measure of the current state."
        ],
        [
            "In order to sample the next state from in order to sample the next state, you're going to take the role of the current state, normalize it, and sample from the normalized measure.",
            "In other words, we're going to sample from an infinite multinomial distribution."
        ],
        [
            "Now that we have defined the process, I'm going to explain some of its properties.",
            "The most important one is conjugacy, posterior of each row of the rate matrix.",
            "Given the events, is also gamma process with updated parameters.",
            "For now, we assume all the events are observed.",
            "We left the inference we left on observ sequences for the inference section of the talk.",
            "The sufficient statistics for parameters of her role given events are number of transitions from state data denoted by F of data and total waiting time at Stater denoted by T updated.",
            "It can be shown that GP is a conjugate family.",
            "And the posterior of each row given the events is a gamma process with updated parameters where the updated based measure is equal to edge, not plus the number of transition from state data and updated rate parameter is beta not plus the total waiting time at state data."
        ],
        [
            "The next property that I'm going to talk about is having a closed form predictive distribution.",
            "This is useful for having an infant, an efficient inference algorithm for finding the predictive distribution we are going to marginalized over Muse.",
            "The predictive distribution is the next state and the next waiting time given the events.",
            "So it can be shown the predictive distribution of a GP is given by the following formula.",
            "This means in order to sample the next state, you only need to sample from the normalized updated based measure of the current state, and in order to sample the next waiting time you only need to sample from a translated part of distribution given below with the parameters equal to the norm of updated based measure of the current state and the updated rate parameter."
        ],
        [
            "Now I'm going to extend the model too."
        ],
        [
            "Karakul version why do we need to do that to have there are at least two reasons to have their roles sharing formation on the popular States and to support the more important reason is to support only go with uncountable supports because two samples from a process with uncountable support will have disjoint supports with probability one that results in.",
            "So we cannot have a recurrent process because we cannot share the states among the."
        ],
        [
            "What's the solution?",
            "We are going to use a similar solution to hierarchical.",
            "During the process, we are going to use a random shared base measure with countable support for the Rose.",
            "Let's say we have the edge, not with uncountable support.",
            "We are going to sample from a global process with this base measure.",
            "Then you sample will have accountable support and we will use this as the shared based measure among the rows.",
            "And now we can sample from a process with this shirt based measure Fielder rank.",
            "Fill the rate matrix and sample you sample using a Douglas fee algorithm.",
            "So again, it can be shown at GP as a closed form predictive distribution similar to that of GP."
        ],
        [
            "Now I'm going to discuss inference in partially observed sequence."
        ],
        [
            "So in most applications the states are not directly nor fully observed.",
            "Instead we only have a set of measurements of a finite set of times.",
            "So here for instance we have observations at time points, T1 to TG, and recall the latent structure example that I introduced at the beginning of the talk.",
            "So here we can have different paths between these observations.",
            "This could be one latent at and another path could be this.",
            "So we are going to approximate the expectation over all paths that go through these colored passages here."
        ],
        [
            "The high level idea of our inference algorithm works by resampling the hidden Events X by first using a sequential Monte Carlo algorithm, SMC to construct proposal over sequence of hidden events.",
            "Then we are using a particle MCMC or PMC to compute an acceptance ratio that makes this proposal a valid MCMC move.",
            "For details of this inference algorithm, please come to our home."
        ],
        [
            "And finally, I'm going to discuss the results of our XP."
        ],
        [
            "Women's three evaluation datasets obtained by holding out each observation with a 10% probability.",
            "Here we have a sample data set.",
            "Let's say we have M sequences in time series we have.",
            "We can have an equal time intervals.",
            "We remove some observations.",
            "We reconstruct these observations and measure demeanor and for a cheap, either reconstruction was done using the base estimator and we compared our results to standard maximum likelihood rate matrix.",
            "Estimator learned by EM algorithm."
        ],
        [
            "So the first data set that we explored was a synthetic data set, used an airdash Rainier model to generate a random sparse matrix, and then we use a uniform noise to make your random rate matrix.",
            "We generated 1000 sequences.",
            "The results showed that our models likely underperform the email method that we believe.",
            "That's because the data is too simple for for our model.",
            "In other words, when you have a simple data, you don't need heavy machinery like a GP that we introduced here."
        ],
        [
            "Another data set that we explored was Emma Slater, said disease progression over three years in 72 Ms patients.",
            "The results showed a relative error reduction of 22% for our method compared to amateur."
        ],
        [
            "And finally we explored the RNA data set time series consisting of pads from one modern live to the root in a phylogenetic tree.",
            "The results showed that the error relatively reduction of 29%."
        ],
        [
            "So in conclusion, we introduced a nonparametric Bayesian model for continuous time recurrent processes.",
            "The model has some attractive properties such as conjugacy and closed form predictive distribution.",
            "We showed how inference can be done efficiently using MCMC methods, and our experiments showed the model is useful for analyzing real world datasets.",
            "And finally we are working on extending the model by adding a layer of decision making.",
            "The resulting model would be a partially observable Markov decision process or from DP."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everyone, first I want to thank you my supervisor Alexandre Bouchard for his support and help for this work without his help winning this prize was impossible.",
                    "label": 0
                },
                {
                    "sent": "So my talk is on players over recurrent continuous time processes.",
                    "label": 1
                },
                {
                    "sent": "This is a as I said, this is joint work with Alexandra Chart Keteyian.",
                    "label": 1
                },
                {
                    "sent": "We're from University of British Columbia.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll start with an example of data that we are interested in.",
                    "label": 1
                },
                {
                    "sent": "Data from multiple sources or Ms patients.",
                    "label": 1
                },
                {
                    "sent": "Ms is a complex neurological disease which is poorly understood.",
                    "label": 0
                },
                {
                    "sent": "There are different measurements for measuring disability in Ms patients.",
                    "label": 0
                },
                {
                    "sent": "The most commonly used is called EDSS.",
                    "label": 0
                },
                {
                    "sent": "One characteristic of EDS is that it changed up properly.",
                    "label": 0
                },
                {
                    "sent": "This means patients disability condition will jump from one media state to another radius state.",
                    "label": 0
                },
                {
                    "sent": "Another characteristic of.",
                    "label": 1
                },
                {
                    "sent": "Ms patients is that they undergo cycles of relapses and remissions and relapses.",
                    "label": 0
                },
                {
                    "sent": "New neurological symptoms occur, new disability occurs at.",
                    "label": 0
                },
                {
                    "sent": "EDSS increases and in remission periods, patients recover from these symptoms and as a result, the EDSS value decreases.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is a sequence is not Markovian, but adding a latent structure we can make it more convenient.",
                    "label": 1
                },
                {
                    "sent": "As an example, here we have an observed sequence of ideas is for one patient on the left hand side on the right hand side we have a simple one example of a simple latent structure.",
                    "label": 0
                },
                {
                    "sent": "We denote the state space of the latent structure with Omega.",
                    "label": 0
                },
                {
                    "sent": "Here, each PD assist represents a group of latent states.",
                    "label": 0
                },
                {
                    "sent": "For instance, the 1st four latent states are represented by idiots, and observations are only limited to edius values.",
                    "label": 0
                },
                {
                    "sent": "So, but the problem here is.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The latent structural complexity is unknown.",
                    "label": 0
                },
                {
                    "sent": "That's due to complexity of the disease and our poor understanding of the disease.",
                    "label": 0
                },
                {
                    "sent": "Another characteristic of the data is that since we are in a continuous time framework, there are there are transitions that we transitions can occur at anytime point.",
                    "label": 0
                },
                {
                    "sent": "Moreover, radius values are only available at potentially unequal time intervals.",
                    "label": 1
                },
                {
                    "sent": "For example, for one patient we have easiest values.",
                    "label": 0
                },
                {
                    "sent": "At these time points and.",
                    "label": 0
                },
                {
                    "sent": "That's all the measurements that we have for one patient.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we are not interested only in an estate are we are interested in general cases where we have data with the following properties where we have a latent structure with unknown complexity, where we have a latent process which is a joint process.",
                    "label": 1
                },
                {
                    "sent": "We have recurrence or repeated patterns.",
                    "label": 0
                },
                {
                    "sent": "We have a continuous time framework and finally we can have observations at potentially on equal time intervals.",
                    "label": 1
                },
                {
                    "sent": "We are going to propose a nonparametric Bayesian model for such data for such situation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The outline of the remaining parts of this talk is as follows.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about some related nonparametric Bayesian models and talk about some background.",
                    "label": 0
                },
                {
                    "sent": "I'll introduce the basic version of our model, the goal exponential process, and I'll extend the model to the hero tickle urgent, the AGP.",
                    "label": 0
                },
                {
                    "sent": "I'll briefly talk about inference in partially observed sequences, or let's discuss the results of our experiments, and I'll conclude the talk with some.",
                    "label": 0
                },
                {
                    "sent": "Remarks",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some related nonparametric Bayesian models for transient processes.",
                    "label": 0
                },
                {
                    "sent": "By transient I mean processes where the observation at timepoint S the effect of an observation at time point is on the on the prediction at time point T + S will decrease as X goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "In other words, these these processes are forgetful.",
                    "label": 0
                },
                {
                    "sent": "Examples include dependent regional processes, DDP, Ornstein, Uhlenbeck traditional processes.",
                    "label": 1
                },
                {
                    "sent": "And stick breaking autoregressive processes.",
                    "label": 1
                },
                {
                    "sent": "However, there are some nonparametric Bayesian models for recurrent processes, but they are in discrete time framework.",
                    "label": 0
                },
                {
                    "sent": "Examples include informational and sticky HTP hmm.",
                    "label": 0
                },
                {
                    "sent": "We are going to fill the gap for nonparametric Bayesian model for recurrent continuous time processes.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to talk about some background on Markov processes.",
                    "label": 0
                },
                {
                    "sent": "The Markov process with them state is characterized by the off diagonal element entries of a rate matrix.",
                    "label": 1
                },
                {
                    "sent": "Array matrix is similar to the transition probability matrix for Markov.",
                    "label": 0
                },
                {
                    "sent": "For Markov chain, the differences here we have one more degree of freedom for which for each row, in other words, the sum of off diagonal elements of each row is not necessarily equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So we have one more extra degree of freedom, which gives us the waiting time at each state.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Samples from a Markov process or a list of pairs of latent states, denoted by time and waiting times denoted by JJ.",
                    "label": 1
                },
                {
                    "sent": "All the latent informationfor end transitions are denoted by X, which is basically the list of pairs of Dayton and J in front.",
                    "label": 0
                },
                {
                    "sent": "The first transition, an equal to 1 to the end transition in order to sample from a continuous time Markov process, we can use Adobe Gillespie algorithm.",
                    "label": 0
                },
                {
                    "sent": "Given the rate matrix Q and the current state data or equal to Omega I, we can sample the waiting time until the next transition by sampling from an exponential distribution with the rate parameter equal to the sum of off diagonal elements of the row corresponding to the current state.",
                    "label": 0
                },
                {
                    "sent": "So we sampled the waiting time an in order to sample the next state.",
                    "label": 0
                },
                {
                    "sent": "We take the role of the current state, normalize it an sample from a multinomial.",
                    "label": 0
                },
                {
                    "sent": "Distribution, so we sampled the next state again.",
                    "label": 0
                },
                {
                    "sent": "Sample the waiting time and so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to introduce the basic version of our model.",
                    "label": 0
                },
                {
                    "sent": "The goal exponential process.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want models with an adaptive complexity in in order to have that we allow for any number of states using an infinite dimensional rate matrix.",
                    "label": 0
                },
                {
                    "sent": "Our goal and the topic of this talk is to develop priors on such infinite rate matrices.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The high level idea of the model is that view of the overall elements for each row of the rate matrix as a positive measure and use more angama process.",
                    "label": 0
                },
                {
                    "sent": "Basically the global process to generate each row of the rate matrix.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why do we need a gamma process in order to have a conjugate prior over the rate matrix?",
                    "label": 1
                },
                {
                    "sent": "Will base the Priors on a global process and measure values the casting process with gamma distribution marginals?",
                    "label": 0
                },
                {
                    "sent": "There are three parameters for a gamma process, a concentration parameter and based probability distribution, and the rate parameter.",
                    "label": 0
                },
                {
                    "sent": "The first 2 parameters can be grouped in a finite base in a finite base measure denoted by edge, not.",
                    "label": 0
                },
                {
                    "sent": "Some notation that will be useful, or the normalization constant of a measure denoted by norm of mu and the normalized measure mu bar.",
                    "label": 1
                },
                {
                    "sent": ", processes similar to additional process but with one extra degree of freedom.",
                    "label": 1
                },
                {
                    "sent": "This extra degree of freedom will allow us to control for the waiting time at each state.",
                    "label": 0
                },
                {
                    "sent": "In fact, if you is sampled from a gamma distribution, mu bar is a drizzler process.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to define the gamma exponential process by defining its generated model in GPS.",
                    "label": 0
                },
                {
                    "sent": "the Rose operate matrix or obtained by sampling IID from a gamma process, and then events are generated from this rate matrix by using do Gillespie algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Suppose it's not is the base measure with a countable support.",
                    "label": 1
                },
                {
                    "sent": "We will relax this assumption later.",
                    "label": 0
                },
                {
                    "sent": "Then for each row of the rate matrix, sample ID from a gamma process with this base measure.",
                    "label": 1
                },
                {
                    "sent": "For example, here we have a sample of a simple base measure count with countable support.",
                    "label": 0
                },
                {
                    "sent": "We sample for one row only guy this is this is a sample measure.",
                    "label": 0
                },
                {
                    "sent": "We feel that the role corresponding to that corresponding to that state in the rate matrix.",
                    "label": 0
                },
                {
                    "sent": "With these with this measure, for example here Mu Omega, Omega Two encodes the length of this stick.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Given the rate given the rates and the current state.",
                    "label": 1
                },
                {
                    "sent": "We can sample the waiting time until the next transition by sampling from an exponential distribution with the rate parameter equal to the norm.",
                    "label": 0
                },
                {
                    "sent": "Of this, of the measure of the current state.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to sample the next state from in order to sample the next state, you're going to take the role of the current state, normalize it, and sample from the normalized measure.",
                    "label": 0
                },
                {
                    "sent": "In other words, we're going to sample from an infinite multinomial distribution.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now that we have defined the process, I'm going to explain some of its properties.",
                    "label": 0
                },
                {
                    "sent": "The most important one is conjugacy, posterior of each row of the rate matrix.",
                    "label": 1
                },
                {
                    "sent": "Given the events, is also gamma process with updated parameters.",
                    "label": 1
                },
                {
                    "sent": "For now, we assume all the events are observed.",
                    "label": 1
                },
                {
                    "sent": "We left the inference we left on observ sequences for the inference section of the talk.",
                    "label": 0
                },
                {
                    "sent": "The sufficient statistics for parameters of her role given events are number of transitions from state data denoted by F of data and total waiting time at Stater denoted by T updated.",
                    "label": 1
                },
                {
                    "sent": "It can be shown that GP is a conjugate family.",
                    "label": 0
                },
                {
                    "sent": "And the posterior of each row given the events is a gamma process with updated parameters where the updated based measure is equal to edge, not plus the number of transition from state data and updated rate parameter is beta not plus the total waiting time at state data.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next property that I'm going to talk about is having a closed form predictive distribution.",
                    "label": 1
                },
                {
                    "sent": "This is useful for having an infant, an efficient inference algorithm for finding the predictive distribution we are going to marginalized over Muse.",
                    "label": 1
                },
                {
                    "sent": "The predictive distribution is the next state and the next waiting time given the events.",
                    "label": 0
                },
                {
                    "sent": "So it can be shown the predictive distribution of a GP is given by the following formula.",
                    "label": 1
                },
                {
                    "sent": "This means in order to sample the next state, you only need to sample from the normalized updated based measure of the current state, and in order to sample the next waiting time you only need to sample from a translated part of distribution given below with the parameters equal to the norm of updated based measure of the current state and the updated rate parameter.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to extend the model too.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Karakul version why do we need to do that to have there are at least two reasons to have their roles sharing formation on the popular States and to support the more important reason is to support only go with uncountable supports because two samples from a process with uncountable support will have disjoint supports with probability one that results in.",
                    "label": 0
                },
                {
                    "sent": "So we cannot have a recurrent process because we cannot share the states among the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's the solution?",
                    "label": 0
                },
                {
                    "sent": "We are going to use a similar solution to hierarchical.",
                    "label": 0
                },
                {
                    "sent": "During the process, we are going to use a random shared base measure with countable support for the Rose.",
                    "label": 1
                },
                {
                    "sent": "Let's say we have the edge, not with uncountable support.",
                    "label": 0
                },
                {
                    "sent": "We are going to sample from a global process with this base measure.",
                    "label": 0
                },
                {
                    "sent": "Then you sample will have accountable support and we will use this as the shared based measure among the rows.",
                    "label": 0
                },
                {
                    "sent": "And now we can sample from a process with this shirt based measure Fielder rank.",
                    "label": 0
                },
                {
                    "sent": "Fill the rate matrix and sample you sample using a Douglas fee algorithm.",
                    "label": 1
                },
                {
                    "sent": "So again, it can be shown at GP as a closed form predictive distribution similar to that of GP.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to discuss inference in partially observed sequence.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in most applications the states are not directly nor fully observed.",
                    "label": 1
                },
                {
                    "sent": "Instead we only have a set of measurements of a finite set of times.",
                    "label": 1
                },
                {
                    "sent": "So here for instance we have observations at time points, T1 to TG, and recall the latent structure example that I introduced at the beginning of the talk.",
                    "label": 0
                },
                {
                    "sent": "So here we can have different paths between these observations.",
                    "label": 0
                },
                {
                    "sent": "This could be one latent at and another path could be this.",
                    "label": 0
                },
                {
                    "sent": "So we are going to approximate the expectation over all paths that go through these colored passages here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The high level idea of our inference algorithm works by resampling the hidden Events X by first using a sequential Monte Carlo algorithm, SMC to construct proposal over sequence of hidden events.",
                    "label": 1
                },
                {
                    "sent": "Then we are using a particle MCMC or PMC to compute an acceptance ratio that makes this proposal a valid MCMC move.",
                    "label": 0
                },
                {
                    "sent": "For details of this inference algorithm, please come to our home.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, I'm going to discuss the results of our XP.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Women's three evaluation datasets obtained by holding out each observation with a 10% probability.",
                    "label": 1
                },
                {
                    "sent": "Here we have a sample data set.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have M sequences in time series we have.",
                    "label": 0
                },
                {
                    "sent": "We can have an equal time intervals.",
                    "label": 0
                },
                {
                    "sent": "We remove some observations.",
                    "label": 1
                },
                {
                    "sent": "We reconstruct these observations and measure demeanor and for a cheap, either reconstruction was done using the base estimator and we compared our results to standard maximum likelihood rate matrix.",
                    "label": 0
                },
                {
                    "sent": "Estimator learned by EM algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first data set that we explored was a synthetic data set, used an airdash Rainier model to generate a random sparse matrix, and then we use a uniform noise to make your random rate matrix.",
                    "label": 1
                },
                {
                    "sent": "We generated 1000 sequences.",
                    "label": 0
                },
                {
                    "sent": "The results showed that our models likely underperform the email method that we believe.",
                    "label": 0
                },
                {
                    "sent": "That's because the data is too simple for for our model.",
                    "label": 0
                },
                {
                    "sent": "In other words, when you have a simple data, you don't need heavy machinery like a GP that we introduced here.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another data set that we explored was Emma Slater, said disease progression over three years in 72 Ms patients.",
                    "label": 0
                },
                {
                    "sent": "The results showed a relative error reduction of 22% for our method compared to amateur.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally we explored the RNA data set time series consisting of pads from one modern live to the root in a phylogenetic tree.",
                    "label": 0
                },
                {
                    "sent": "The results showed that the error relatively reduction of 29%.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we introduced a nonparametric Bayesian model for continuous time recurrent processes.",
                    "label": 1
                },
                {
                    "sent": "The model has some attractive properties such as conjugacy and closed form predictive distribution.",
                    "label": 1
                },
                {
                    "sent": "We showed how inference can be done efficiently using MCMC methods, and our experiments showed the model is useful for analyzing real world datasets.",
                    "label": 1
                },
                {
                    "sent": "And finally we are working on extending the model by adding a layer of decision making.",
                    "label": 0
                },
                {
                    "sent": "The resulting model would be a partially observable Markov decision process or from DP.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}