{
    "id": "b7adsgupmr7kiaqmxm6k2y6b7vopgq2p",
    "title": "Formal Query Generation for Question Answering over Knowledge Bases",
    "info": {
        "author": [
            "Hamid Zafar, University of Bonn"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_zafar_knowledge_bases/",
    "segmentation": [
        [
            "Hello everyone, I'm home.",
            "It's a far from University of Bonn.",
            "I'm going to present our latest funding in the paper title for my query generation for question answering over Knowledge Graph.",
            "Now I'm going to talk about the introduction why we basically going to focus on their question.",
            "Answering over knowledge gives and also.",
            "What is the focus of the paper?",
            "Finally, I'm going to present the input."
        ],
        [
            "Result and short summary.",
            "So basically the question answering coming to you started working on the knowledge gap because it's been using a different application and it actually encapsulate a lot of information available on the web in a very structured way, which makes it much easier to provide the concepts answer to the question asked by the users."
        ],
        [
            "And I think it's really clear.",
            "The motivation for the question answering over knowledge."
        ],
        [
            "Graphs and the main goal is to transfer the question which are in the natural language and turn into a formal language.",
            "As you can see in this example, for example, we have the.",
            "What are some artists on this show who's opening term is send it on?",
            "So the final goal is to take this question and turn it into a sparkle query, for example and shoot it to a knowledge graph and the result is what the what the user is intended for.",
            "No."
        ],
        [
            "We have two common type of dark type of Arctic architecture in here.",
            "One is into an architecture which is mostly used by deep learning.",
            "Average is a single process mostly and the good thing is there is almost never propagation because there is only one step that do the job and the other thing is that the disadvantage is that.",
            "As of now, the support for the complex question and the composite question is very limited.",
            "So basically they focus on the the simple question.",
            "On the other hand, we have the pipeline architecture which consists of multiple components such as named entity disambiguation, relation extraction and query generation.",
            "The advantage of the pipeline architecture is that we have multiple components with limited focus, and we can reuse the component to create knew question answering.",
            "Systems, but this is the main disadvantage is that if one of the component in the earlier stage of the pipeline failed, the error would be propagated along the pipeline."
        ],
        [
            "Among the the component in the in the pipeline question answer component in the pipeline question answering query generation component is the one of the most vital when their own analysis from the sink paper show that this is the main reason for the failure in the question answering systems.",
            "So here we're going to focus only on the query generation component of.",
            "Good question answering.",
            "With the pipeline architecture, but and we define the requirements as follow, first of all it should be able to deal with the larger scale knowledge graph such as DB pedia or Freebase.",
            "Secondly, in order to somehow manage the verification along the pipeline, we would like to somehow manage noise in the input, and terribly it's desirable to have a model to identify the type of question and get rid of the manual identifications in using specific patterns.",
            "Finally, it should be strong enough to support composite and complex question, and of course at the end it's desirable to have a model that can consider the syntactical structure of the question to design."
        ],
        [
            "The gate the question in respect to the.",
            "Candidate queries the approach is called sparkle query generation XQG and the main hypothesis is that the formal interpretation of the question is of work in the Knowledge Graph which contain all the entity and relation that exists in the question.",
            "The input that we assume that we will receive 4S QG is the question which is already annotated with the LinkedIn."
        ],
        [
            "With the with the entity and relation from the Knowledge Graph, this is this is a picture that shows us, so we still have the same example as you can see.",
            "For example, the utterance artists can be linked to DB artist, DB artists, and so on and so forth.",
            "So for all the relation and entities in the question, we have a list of candidates which is like.",
            "On the other hand, we could most of the system consider only the top one, the top, the best linked item for each insurance.",
            "But we in order to handle the noise in the input, we consider Kaylie stuff item.",
            "For each insurance."
        ],
        [
            "This is the main architecture of our average.",
            "The first thing is that we take the question along the annotations.",
            "We first need to identify the type of the question because it would change the way that we need to create the query.",
            "Given that we will start with the query generation and create a sample accurate a set of candidate queries.",
            "At the end we will we have a ranking model that takes the candidate query and try to find the similarity between the.",
            "Candidate query and dependency paths to the structure of the input question.",
            "So."
        ],
        [
            "Difference module is the feature identification in the other question answering system.",
            "Usually people used manually crafted set of patterns to identify the type of question.",
            "For example, if it's if there is a word continent, they would consider that would be account query of or something like that.",
            "Here we use a very simple SVM model based on the TF IDF representation of the query and terrain.",
            "It actually between two different SVM for.",
            "Different purposes, the first thing is to establish the type of the question, which now here is brilliant.",
            "Can't or everything else could be leased, or a single item.",
            "And the second one, the second model is to identify if we have hidden relation in the question.",
            "For example, when we have a question, what is diversity of X&Y in the generated query?",
            "We would need to use the birthplace relation twice in relation relates to X&Y."
        ],
        [
            "Given that we need to generate a set of candidate query.",
            "For that we could start directly on the Knowledge Graph, but in order to to browse the Knowledge Graph is very time consuming.",
            "And in order to have a more scalable approach, we started with the idea that we can capture a sub gift that contains all the entity in relation the the list of candidates that we got from the input.",
            "An it's limited to one or two hop distance having this sub graph.",
            "We are sure that all of the candidate query related to the input can be generated from this sub graph."
        ],
        [
            "It would make it much, much faster than browsing the browsing the original language graph.",
            "We have we have two definition here work which is a sequence of edge along the note that they connect.",
            "Invalid work is the work that has only the set of entity relation that is related to the input question.",
            "So we are mapping the idea of valid work to the candidate query and say that every valid work has a. Syncing mapping to a sparkle query."
        ],
        [
            "For example, this is the sub graph that we extracted from the D pad here.",
            "As you can see that there is multiple entity in relation in here.",
            "From the from the input, but it's not clear what is actually the valid working here."
        ],
        [
            "We from from that subgraph we can extract 4 different valid work which are represented in different column in here.",
            "As you can see, the they are quite similar to each other, but.",
            "Perhaps there is only one or two relation, different.",
            "Or maybe the structure of the network are different.",
            "So this is as I said, each of the values work are equivalent to a valid SPARQL query, but at the end of the day we need to find a way to somehow find which of the candidate queries is the one that is intended by the user."
        ],
        [
            "For that, we're going to discuss.",
            "We introduce a ranking model in here, the ranking model.",
            "The goal is to take the semantic of the input question and consider that in order to compute the similarity between the candidate queries and the input question.",
            "As we seen in India."
        ],
        [
            "Sample one of the most distinctive feature that can help us to disambiguate the similarity between the multiple candidate query is the structure of the queries."
        ],
        [
            "Because sets of entity relation many of many of them are shared among the candidate queries."
        ],
        [
            "One way to do that is to use it is to use the Alicia model LCM model takes one token at a time from the input and it can be used.",
            "In a model to find the similarity between the input question and the candidate queries."
        ],
        [
            "But the problem with with lithium is that it doesn't actually consider the structure of this sentence, but only the order after work.",
            "To fix that, we use that realistic model, which is, as you can see in this picture, in order to compute the hidden state of the.",
            "And they sell.",
            "It needs to compute the state of its children.",
            "So instead of just depending on the on the latest on the other previous tokens, it actually depends on the.",
            "Children nodes."
        ],
        [
            "Let's say that for the for the input question, we needed to be representation, and for that we use dependency parsing tree.",
            "As you can see, this is the dependency parsing tree of the the sample that we."
        ],
        [
            "And this is a true representation of the candidate query that we had before for candidate queries, so that realistic model is supposed to be trained to.",
            "To find the one with them to find the one with the maximum similarity."
        ],
        [
            "And this is the overall architecture of the ranking model.",
            "We have a tier list TM for the query and one for the question.",
            "They both mapped input into a Latin representation an at the end we have our similarity function which is which aimed to.",
            "Give a high similarity.",
            "Give a higher score when the target query match with the question and gives local lower score when it doesn't match.",
            "So at the end we learn some Latin representation for the query in question that then we can use in the test set to to find 2 rank.",
            "Actually the.",
            "The candidate queries."
        ],
        [
            "Finally, in for the evaluation, we use the LC quiet data set, which has 5000 question answering answer pair with different complexity and different type of question.",
            "It has Boolean count and list question and the question have 1, two or three.",
            "Sets of triples.",
            "So quite complex questions.",
            "Comparing to other benchmarks.",
            "And for the baseline we use.",
            "It was quite a hard task to find the baseline system because to the best of my knowledge, I haven't seen any paper dedicated for the query generation, but we got the system.",
            "We've got the query generation part from two other systems, seen and analyzed would.",
            "And extracted that.",
            "The baseline for the ranking model.",
            "Also we used illicium."
        ],
        [
            "We define three scenarios in here.",
            "The first one is the top one, correct, which only takes the input where the presidents only annotated with the correct entity in relation.",
            "So instead of like.",
            "The top five or top ten output from the entity or relation linking.",
            "We only take the correct one.",
            "The second one is top five Earl plus correct, or Earl is a entity linking tools that we use in here to generate some more data for us.",
            "In this scenario, we we, we annotate the question with a list of candidates like 5 candidate parachute events and if the correct one was not existing in the be forcefully injected.",
            "And the last one is like fully functional.",
            "Question answering pipeline in which we use Earth for the entity in relation."
        ],
        [
            "Linking to.",
            "And here is the result.",
            "As you can see, two year lease terms outperform the illicium in both 3 scenarios.",
            "But in the in the second scenarios we get them.",
            "The best result and The thing is that in the second scenario we have more balanced set of a training set that contains.",
            "Correct and incorrect.",
            "Data as opposed to the first one that we mostly have only the correct one, and for the last one as well, we mostly have the incorrect one.",
            "And note that these are the midwife and measure measure.",
            "So the ranking model is pretty much you think the illicium in every three scenarios."
        ],
        [
            "And regarding the baselines, as I said, we use scene and alive would, but the result actually were provided by sync.",
            "So we didn't have generated the result.",
            "We took the result from the report and the result that we have just to be make sure that we can compare to result exactly.",
            "We also perform it on the same subset of the LC quad, which has 3000 question, not not the whole 5000 question.",
            "In here.",
            "As you can see, if you have a much better performance in respect to the to the baseline systems."
        ],
        [
            "Finally.",
            "Movie introduce a reusable and scalable approach in here it's.",
            "Make it much more easier for the question answering community to use.",
            "We use the component to generate to create knew question answering pipeline, it's able to analyze, manage the noisy annotation, which is the realistic job when we have a different component in the pipeline, we don't have to take only the best option that they can generate but also for example, the top five to top K of them.",
            "And we also exploit the structural similarity of the input question and the candidate query as opposed to the other.",
            "Other related work that takes.",
            "Manually crafted set of features.",
            "So if you have any question, I would be happy.",
            "Thanks for your took a simple question.",
            "Is it based on the Canary framework about which we had there was a Toyota should days ago?",
            "Because you say that you have a framework with components is the Canary framework.",
            "This is not active right now based off the Canary, but in the future we will definitely start merge integrated in in the Canary.",
            "At the moment it's your own framework, it's a I'm sorry at the moment it is your own framework for the combination of different components.",
            "No, this is all our work.",
            "OK thanks, so we have a baseline over the benchmark that you spoke about and I thought also that I emailed you that.",
            "So I was a bit disappointing hearing that you are not aware of any other baseline.",
            "Yeah, I think by the time that we were writing the paper we didn't get the get the result from you by the sun which we submit the paper.",
            "But we could definitely also consider that.",
            "Hi, so you're in the summer.",
            "You said that it's reusable and scalable.",
            "So usable.",
            "You have described how it so the user will, but I think I've had not get how it's scalable or your approach scalable.",
            "So maybe you can describe it a little bit more.",
            "OK.",
            "Regarding their scalability, I think I mentioned it in this part right here.",
            "The idea of the first capturing a sub give and then going for capturing the extracting the valid work.",
            "This can be done in a very timely fashion.",
            "So for example, for a given question with perhaps 5 candidate bittorrents, it would work in half a second or less.",
            "Yeah, but but that means you're efficient.",
            "Between doesn't mean that we are scalable, scalable would mean that if the graph is increasing, knowledge graph is increasing like double the size that actually would not cost double the size of the maximum double the size of the execution time.",
            "So scalable would mean something different in my opinion.",
            "Yeah I sent.",
            "So The thing is that we somehow try to show that given the size of the data systems, also size of the page here that we work to answer the data.",
            "The system was able to manage to manage to to answer the question given the given the noisy inputs.",
            "And there was this slide with a comparison with other baselines.",
            "And I was a bit surprised how how much worse they they perform than your system.",
            "Did you investigate?",
            "Why do you have some explanation?",
            "Yeah, so The thing is that for example, for the senior system, the query generation part is a very simplistic part and its pattern base.",
            "And it's also true for the for the next one and the type of patterns.",
            "Depends on the under benchmarking data set that we have, so it doesn't if it doesn't match the match.",
            "The pattern that manually crafted in their system, the system wouldn't be able to answer it.",
            "So what we did in here with try to get rid of the pattern based system and only focus on the undynamic query generation file.",
            "OK, I see.",
            "Another thing that you mentioned is that you answered the questions over DB pedia.",
            "did I get this correctly?",
            "Only so did you with this approach also work on other knowledge graphs then the pedia.",
            "How generic is it?",
            "Yeah, basically we can use it on any other knowledge graph.",
            "Perhaps a little bit of work, for example, for the case of Freebase.",
            "Perhaps we need to take care of the CBT nodes, and that would be all.",
            "OK, and can you also do it over multiple knowledge graphs?",
            "Like if you have the pedia in Freebase for example.",
            "We haven't considered it, but I think it should be also possible to consider that management OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, I'm home.",
                    "label": 0
                },
                {
                    "sent": "It's a far from University of Bonn.",
                    "label": 0
                },
                {
                    "sent": "I'm going to present our latest funding in the paper title for my query generation for question answering over Knowledge Graph.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about the introduction why we basically going to focus on their question.",
                    "label": 0
                },
                {
                    "sent": "Answering over knowledge gives and also.",
                    "label": 0
                },
                {
                    "sent": "What is the focus of the paper?",
                    "label": 0
                },
                {
                    "sent": "Finally, I'm going to present the input.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result and short summary.",
                    "label": 0
                },
                {
                    "sent": "So basically the question answering coming to you started working on the knowledge gap because it's been using a different application and it actually encapsulate a lot of information available on the web in a very structured way, which makes it much easier to provide the concepts answer to the question asked by the users.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I think it's really clear.",
                    "label": 0
                },
                {
                    "sent": "The motivation for the question answering over knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graphs and the main goal is to transfer the question which are in the natural language and turn into a formal language.",
                    "label": 0
                },
                {
                    "sent": "As you can see in this example, for example, we have the.",
                    "label": 0
                },
                {
                    "sent": "What are some artists on this show who's opening term is send it on?",
                    "label": 1
                },
                {
                    "sent": "So the final goal is to take this question and turn it into a sparkle query, for example and shoot it to a knowledge graph and the result is what the what the user is intended for.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have two common type of dark type of Arctic architecture in here.",
                    "label": 0
                },
                {
                    "sent": "One is into an architecture which is mostly used by deep learning.",
                    "label": 0
                },
                {
                    "sent": "Average is a single process mostly and the good thing is there is almost never propagation because there is only one step that do the job and the other thing is that the disadvantage is that.",
                    "label": 0
                },
                {
                    "sent": "As of now, the support for the complex question and the composite question is very limited.",
                    "label": 0
                },
                {
                    "sent": "So basically they focus on the the simple question.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we have the pipeline architecture which consists of multiple components such as named entity disambiguation, relation extraction and query generation.",
                    "label": 0
                },
                {
                    "sent": "The advantage of the pipeline architecture is that we have multiple components with limited focus, and we can reuse the component to create knew question answering.",
                    "label": 0
                },
                {
                    "sent": "Systems, but this is the main disadvantage is that if one of the component in the earlier stage of the pipeline failed, the error would be propagated along the pipeline.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Among the the component in the in the pipeline question answer component in the pipeline question answering query generation component is the one of the most vital when their own analysis from the sink paper show that this is the main reason for the failure in the question answering systems.",
                    "label": 0
                },
                {
                    "sent": "So here we're going to focus only on the query generation component of.",
                    "label": 0
                },
                {
                    "sent": "Good question answering.",
                    "label": 0
                },
                {
                    "sent": "With the pipeline architecture, but and we define the requirements as follow, first of all it should be able to deal with the larger scale knowledge graph such as DB pedia or Freebase.",
                    "label": 0
                },
                {
                    "sent": "Secondly, in order to somehow manage the verification along the pipeline, we would like to somehow manage noise in the input, and terribly it's desirable to have a model to identify the type of question and get rid of the manual identifications in using specific patterns.",
                    "label": 0
                },
                {
                    "sent": "Finally, it should be strong enough to support composite and complex question, and of course at the end it's desirable to have a model that can consider the syntactical structure of the question to design.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The gate the question in respect to the.",
                    "label": 0
                },
                {
                    "sent": "Candidate queries the approach is called sparkle query generation XQG and the main hypothesis is that the formal interpretation of the question is of work in the Knowledge Graph which contain all the entity and relation that exists in the question.",
                    "label": 0
                },
                {
                    "sent": "The input that we assume that we will receive 4S QG is the question which is already annotated with the LinkedIn.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the with the entity and relation from the Knowledge Graph, this is this is a picture that shows us, so we still have the same example as you can see.",
                    "label": 0
                },
                {
                    "sent": "For example, the utterance artists can be linked to DB artist, DB artists, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So for all the relation and entities in the question, we have a list of candidates which is like.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we could most of the system consider only the top one, the top, the best linked item for each insurance.",
                    "label": 0
                },
                {
                    "sent": "But we in order to handle the noise in the input, we consider Kaylie stuff item.",
                    "label": 0
                },
                {
                    "sent": "For each insurance.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the main architecture of our average.",
                    "label": 0
                },
                {
                    "sent": "The first thing is that we take the question along the annotations.",
                    "label": 0
                },
                {
                    "sent": "We first need to identify the type of the question because it would change the way that we need to create the query.",
                    "label": 0
                },
                {
                    "sent": "Given that we will start with the query generation and create a sample accurate a set of candidate queries.",
                    "label": 0
                },
                {
                    "sent": "At the end we will we have a ranking model that takes the candidate query and try to find the similarity between the.",
                    "label": 0
                },
                {
                    "sent": "Candidate query and dependency paths to the structure of the input question.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Difference module is the feature identification in the other question answering system.",
                    "label": 0
                },
                {
                    "sent": "Usually people used manually crafted set of patterns to identify the type of question.",
                    "label": 0
                },
                {
                    "sent": "For example, if it's if there is a word continent, they would consider that would be account query of or something like that.",
                    "label": 0
                },
                {
                    "sent": "Here we use a very simple SVM model based on the TF IDF representation of the query and terrain.",
                    "label": 0
                },
                {
                    "sent": "It actually between two different SVM for.",
                    "label": 0
                },
                {
                    "sent": "Different purposes, the first thing is to establish the type of the question, which now here is brilliant.",
                    "label": 0
                },
                {
                    "sent": "Can't or everything else could be leased, or a single item.",
                    "label": 0
                },
                {
                    "sent": "And the second one, the second model is to identify if we have hidden relation in the question.",
                    "label": 0
                },
                {
                    "sent": "For example, when we have a question, what is diversity of X&Y in the generated query?",
                    "label": 0
                },
                {
                    "sent": "We would need to use the birthplace relation twice in relation relates to X&Y.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given that we need to generate a set of candidate query.",
                    "label": 0
                },
                {
                    "sent": "For that we could start directly on the Knowledge Graph, but in order to to browse the Knowledge Graph is very time consuming.",
                    "label": 0
                },
                {
                    "sent": "And in order to have a more scalable approach, we started with the idea that we can capture a sub gift that contains all the entity in relation the the list of candidates that we got from the input.",
                    "label": 0
                },
                {
                    "sent": "An it's limited to one or two hop distance having this sub graph.",
                    "label": 0
                },
                {
                    "sent": "We are sure that all of the candidate query related to the input can be generated from this sub graph.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It would make it much, much faster than browsing the browsing the original language graph.",
                    "label": 0
                },
                {
                    "sent": "We have we have two definition here work which is a sequence of edge along the note that they connect.",
                    "label": 0
                },
                {
                    "sent": "Invalid work is the work that has only the set of entity relation that is related to the input question.",
                    "label": 0
                },
                {
                    "sent": "So we are mapping the idea of valid work to the candidate query and say that every valid work has a. Syncing mapping to a sparkle query.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, this is the sub graph that we extracted from the D pad here.",
                    "label": 0
                },
                {
                    "sent": "As you can see that there is multiple entity in relation in here.",
                    "label": 0
                },
                {
                    "sent": "From the from the input, but it's not clear what is actually the valid working here.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We from from that subgraph we can extract 4 different valid work which are represented in different column in here.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the they are quite similar to each other, but.",
                    "label": 0
                },
                {
                    "sent": "Perhaps there is only one or two relation, different.",
                    "label": 0
                },
                {
                    "sent": "Or maybe the structure of the network are different.",
                    "label": 0
                },
                {
                    "sent": "So this is as I said, each of the values work are equivalent to a valid SPARQL query, but at the end of the day we need to find a way to somehow find which of the candidate queries is the one that is intended by the user.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For that, we're going to discuss.",
                    "label": 0
                },
                {
                    "sent": "We introduce a ranking model in here, the ranking model.",
                    "label": 0
                },
                {
                    "sent": "The goal is to take the semantic of the input question and consider that in order to compute the similarity between the candidate queries and the input question.",
                    "label": 0
                },
                {
                    "sent": "As we seen in India.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample one of the most distinctive feature that can help us to disambiguate the similarity between the multiple candidate query is the structure of the queries.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because sets of entity relation many of many of them are shared among the candidate queries.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One way to do that is to use it is to use the Alicia model LCM model takes one token at a time from the input and it can be used.",
                    "label": 0
                },
                {
                    "sent": "In a model to find the similarity between the input question and the candidate queries.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the problem with with lithium is that it doesn't actually consider the structure of this sentence, but only the order after work.",
                    "label": 0
                },
                {
                    "sent": "To fix that, we use that realistic model, which is, as you can see in this picture, in order to compute the hidden state of the.",
                    "label": 0
                },
                {
                    "sent": "And they sell.",
                    "label": 0
                },
                {
                    "sent": "It needs to compute the state of its children.",
                    "label": 0
                },
                {
                    "sent": "So instead of just depending on the on the latest on the other previous tokens, it actually depends on the.",
                    "label": 0
                },
                {
                    "sent": "Children nodes.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say that for the for the input question, we needed to be representation, and for that we use dependency parsing tree.",
                    "label": 0
                },
                {
                    "sent": "As you can see, this is the dependency parsing tree of the the sample that we.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a true representation of the candidate query that we had before for candidate queries, so that realistic model is supposed to be trained to.",
                    "label": 0
                },
                {
                    "sent": "To find the one with them to find the one with the maximum similarity.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the overall architecture of the ranking model.",
                    "label": 0
                },
                {
                    "sent": "We have a tier list TM for the query and one for the question.",
                    "label": 0
                },
                {
                    "sent": "They both mapped input into a Latin representation an at the end we have our similarity function which is which aimed to.",
                    "label": 0
                },
                {
                    "sent": "Give a high similarity.",
                    "label": 0
                },
                {
                    "sent": "Give a higher score when the target query match with the question and gives local lower score when it doesn't match.",
                    "label": 0
                },
                {
                    "sent": "So at the end we learn some Latin representation for the query in question that then we can use in the test set to to find 2 rank.",
                    "label": 0
                },
                {
                    "sent": "Actually the.",
                    "label": 0
                },
                {
                    "sent": "The candidate queries.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, in for the evaluation, we use the LC quiet data set, which has 5000 question answering answer pair with different complexity and different type of question.",
                    "label": 0
                },
                {
                    "sent": "It has Boolean count and list question and the question have 1, two or three.",
                    "label": 0
                },
                {
                    "sent": "Sets of triples.",
                    "label": 0
                },
                {
                    "sent": "So quite complex questions.",
                    "label": 0
                },
                {
                    "sent": "Comparing to other benchmarks.",
                    "label": 0
                },
                {
                    "sent": "And for the baseline we use.",
                    "label": 0
                },
                {
                    "sent": "It was quite a hard task to find the baseline system because to the best of my knowledge, I haven't seen any paper dedicated for the query generation, but we got the system.",
                    "label": 0
                },
                {
                    "sent": "We've got the query generation part from two other systems, seen and analyzed would.",
                    "label": 0
                },
                {
                    "sent": "And extracted that.",
                    "label": 0
                },
                {
                    "sent": "The baseline for the ranking model.",
                    "label": 0
                },
                {
                    "sent": "Also we used illicium.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We define three scenarios in here.",
                    "label": 0
                },
                {
                    "sent": "The first one is the top one, correct, which only takes the input where the presidents only annotated with the correct entity in relation.",
                    "label": 0
                },
                {
                    "sent": "So instead of like.",
                    "label": 0
                },
                {
                    "sent": "The top five or top ten output from the entity or relation linking.",
                    "label": 0
                },
                {
                    "sent": "We only take the correct one.",
                    "label": 0
                },
                {
                    "sent": "The second one is top five Earl plus correct, or Earl is a entity linking tools that we use in here to generate some more data for us.",
                    "label": 0
                },
                {
                    "sent": "In this scenario, we we, we annotate the question with a list of candidates like 5 candidate parachute events and if the correct one was not existing in the be forcefully injected.",
                    "label": 0
                },
                {
                    "sent": "And the last one is like fully functional.",
                    "label": 0
                },
                {
                    "sent": "Question answering pipeline in which we use Earth for the entity in relation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Linking to.",
                    "label": 0
                },
                {
                    "sent": "And here is the result.",
                    "label": 0
                },
                {
                    "sent": "As you can see, two year lease terms outperform the illicium in both 3 scenarios.",
                    "label": 0
                },
                {
                    "sent": "But in the in the second scenarios we get them.",
                    "label": 0
                },
                {
                    "sent": "The best result and The thing is that in the second scenario we have more balanced set of a training set that contains.",
                    "label": 0
                },
                {
                    "sent": "Correct and incorrect.",
                    "label": 0
                },
                {
                    "sent": "Data as opposed to the first one that we mostly have only the correct one, and for the last one as well, we mostly have the incorrect one.",
                    "label": 0
                },
                {
                    "sent": "And note that these are the midwife and measure measure.",
                    "label": 0
                },
                {
                    "sent": "So the ranking model is pretty much you think the illicium in every three scenarios.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And regarding the baselines, as I said, we use scene and alive would, but the result actually were provided by sync.",
                    "label": 0
                },
                {
                    "sent": "So we didn't have generated the result.",
                    "label": 0
                },
                {
                    "sent": "We took the result from the report and the result that we have just to be make sure that we can compare to result exactly.",
                    "label": 0
                },
                {
                    "sent": "We also perform it on the same subset of the LC quad, which has 3000 question, not not the whole 5000 question.",
                    "label": 0
                },
                {
                    "sent": "In here.",
                    "label": 0
                },
                {
                    "sent": "As you can see, if you have a much better performance in respect to the to the baseline systems.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally.",
                    "label": 0
                },
                {
                    "sent": "Movie introduce a reusable and scalable approach in here it's.",
                    "label": 0
                },
                {
                    "sent": "Make it much more easier for the question answering community to use.",
                    "label": 0
                },
                {
                    "sent": "We use the component to generate to create knew question answering pipeline, it's able to analyze, manage the noisy annotation, which is the realistic job when we have a different component in the pipeline, we don't have to take only the best option that they can generate but also for example, the top five to top K of them.",
                    "label": 0
                },
                {
                    "sent": "And we also exploit the structural similarity of the input question and the candidate query as opposed to the other.",
                    "label": 0
                },
                {
                    "sent": "Other related work that takes.",
                    "label": 0
                },
                {
                    "sent": "Manually crafted set of features.",
                    "label": 0
                },
                {
                    "sent": "So if you have any question, I would be happy.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your took a simple question.",
                    "label": 0
                },
                {
                    "sent": "Is it based on the Canary framework about which we had there was a Toyota should days ago?",
                    "label": 0
                },
                {
                    "sent": "Because you say that you have a framework with components is the Canary framework.",
                    "label": 0
                },
                {
                    "sent": "This is not active right now based off the Canary, but in the future we will definitely start merge integrated in in the Canary.",
                    "label": 0
                },
                {
                    "sent": "At the moment it's your own framework, it's a I'm sorry at the moment it is your own framework for the combination of different components.",
                    "label": 0
                },
                {
                    "sent": "No, this is all our work.",
                    "label": 0
                },
                {
                    "sent": "OK thanks, so we have a baseline over the benchmark that you spoke about and I thought also that I emailed you that.",
                    "label": 0
                },
                {
                    "sent": "So I was a bit disappointing hearing that you are not aware of any other baseline.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think by the time that we were writing the paper we didn't get the get the result from you by the sun which we submit the paper.",
                    "label": 0
                },
                {
                    "sent": "But we could definitely also consider that.",
                    "label": 0
                },
                {
                    "sent": "Hi, so you're in the summer.",
                    "label": 0
                },
                {
                    "sent": "You said that it's reusable and scalable.",
                    "label": 0
                },
                {
                    "sent": "So usable.",
                    "label": 0
                },
                {
                    "sent": "You have described how it so the user will, but I think I've had not get how it's scalable or your approach scalable.",
                    "label": 0
                },
                {
                    "sent": "So maybe you can describe it a little bit more.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Regarding their scalability, I think I mentioned it in this part right here.",
                    "label": 0
                },
                {
                    "sent": "The idea of the first capturing a sub give and then going for capturing the extracting the valid work.",
                    "label": 0
                },
                {
                    "sent": "This can be done in a very timely fashion.",
                    "label": 0
                },
                {
                    "sent": "So for example, for a given question with perhaps 5 candidate bittorrents, it would work in half a second or less.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but but that means you're efficient.",
                    "label": 0
                },
                {
                    "sent": "Between doesn't mean that we are scalable, scalable would mean that if the graph is increasing, knowledge graph is increasing like double the size that actually would not cost double the size of the maximum double the size of the execution time.",
                    "label": 0
                },
                {
                    "sent": "So scalable would mean something different in my opinion.",
                    "label": 0
                },
                {
                    "sent": "Yeah I sent.",
                    "label": 0
                },
                {
                    "sent": "So The thing is that we somehow try to show that given the size of the data systems, also size of the page here that we work to answer the data.",
                    "label": 0
                },
                {
                    "sent": "The system was able to manage to manage to to answer the question given the given the noisy inputs.",
                    "label": 0
                },
                {
                    "sent": "And there was this slide with a comparison with other baselines.",
                    "label": 0
                },
                {
                    "sent": "And I was a bit surprised how how much worse they they perform than your system.",
                    "label": 0
                },
                {
                    "sent": "Did you investigate?",
                    "label": 0
                },
                {
                    "sent": "Why do you have some explanation?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so The thing is that for example, for the senior system, the query generation part is a very simplistic part and its pattern base.",
                    "label": 0
                },
                {
                    "sent": "And it's also true for the for the next one and the type of patterns.",
                    "label": 0
                },
                {
                    "sent": "Depends on the under benchmarking data set that we have, so it doesn't if it doesn't match the match.",
                    "label": 0
                },
                {
                    "sent": "The pattern that manually crafted in their system, the system wouldn't be able to answer it.",
                    "label": 0
                },
                {
                    "sent": "So what we did in here with try to get rid of the pattern based system and only focus on the undynamic query generation file.",
                    "label": 0
                },
                {
                    "sent": "OK, I see.",
                    "label": 0
                },
                {
                    "sent": "Another thing that you mentioned is that you answered the questions over DB pedia.",
                    "label": 0
                },
                {
                    "sent": "did I get this correctly?",
                    "label": 0
                },
                {
                    "sent": "Only so did you with this approach also work on other knowledge graphs then the pedia.",
                    "label": 0
                },
                {
                    "sent": "How generic is it?",
                    "label": 0
                },
                {
                    "sent": "Yeah, basically we can use it on any other knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "Perhaps a little bit of work, for example, for the case of Freebase.",
                    "label": 0
                },
                {
                    "sent": "Perhaps we need to take care of the CBT nodes, and that would be all.",
                    "label": 0
                },
                {
                    "sent": "OK, and can you also do it over multiple knowledge graphs?",
                    "label": 0
                },
                {
                    "sent": "Like if you have the pedia in Freebase for example.",
                    "label": 0
                },
                {
                    "sent": "We haven't considered it, but I think it should be also possible to consider that management OK.",
                    "label": 0
                }
            ]
        }
    }
}