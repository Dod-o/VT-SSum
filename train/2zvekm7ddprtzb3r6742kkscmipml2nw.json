{
    "id": "2zvekm7ddprtzb3r6742kkscmipml2nw",
    "title": "Robust approachability and regret minimization in games with partial monitoring",
    "info": {
        "author": [
            "Vianney Perchet, Probabilities and Random Models Laboratory, Universit\u00e9 Pierre et Marie Curie (UPMC)"
        ],
        "published": "Aug. 2, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/colt2011_perchet_robust/",
    "segmentation": [
        [
            "So I put my beauty as ridiculous.",
            "Explained yesterday is used for the multicriteria optimization, that is, when you want to control at the same time several quantities, or if you like.",
            "If you have several objectives that you want to optimize at the same time."
        ],
        [
            "So the good thing about a possibility is that it doesn't require any treatment or do objectives like choosing an order of the objective and abusing first.",
            "The first one and the second one the third one or not requires that you consider convex or linear combination of your deal that you minimize.",
            "And so I'm going to speak about our business.",
            "We are partial monitoring that appears when you have some interest in certainties on your pay off all your data.",
            "So we assume that they are not totally absorbed.",
            "For example, you instead of seeing will pay off for that are you just receive a noisy feedback about it, or some partial observation like in."
        ],
        [
            "It's.",
            "So let's forget about her business and personal development.",
            "An those kind of program without question with ring can be formalized as a repeated game between the decision maker and nature.",
            "So it's a repeated game and at ROM T the decision maker choose an action that is 80 in some set, a finite set a.",
            "Why would you do that?",
            "In fact, in address?",
            "I'll online learning.",
            "The decision maker should.",
            "Through this action at random and they would not buy XTZ law of 18 and extend belongs to the probability to set operated discussion over air, which is Delta of a.",
            "So at each run this will make your true selection a team and at the same times nature choose direction which is BT.",
            "So just do couple of action, generates a payoff which it will depends of course abundant bus action.",
            "So as Jake stolen yesterday, this payoff is a vector which has D component and each one of these components can see it as one of the quantities that we want to control simultaneously, or one of your objectives that we want to optimize.",
            "So funny.",
            "We can represent the overall objective of addition Maker as a target set C, so it's a subset of early and the aim of the decision maker is to construct an algorithm such that no matter what the natural does, the average payoff converge to this Etsy?",
            "So for simplification, I might consider the expected version of this problem when the payoff will consider expected payoff instead of the real payoff.",
            "But this does not change."
        ],
        [
            "Using.",
            "So I push ability has been defined by Blackwell and also characterized convex, approachable set.",
            "And I'm going to cut it.",
            "Blackwell condition and you say that the set C is applicable if and if for every move Y of nature there exist to move X of the decision maker such that the payoff is in C. So this is a very important theorem.",
            "It's very very used in game theory because of the following interpretation.",
            "You can say that.",
            "Additionally, can fulfill simultaneously in the adversarial sequential framework lots of objectives if and only if you can do that in a non stochastic framework.",
            "That means that we can do it when the data or the action of the nature or ID and additional maker knows there's a lot of their objection.",
            "So another beautiful thing about this theorem is that.",
            "It's very simple statement is very used and the proof is so simple.",
            "So forget about this part is almost obvious."
        ],
        [
            "Going to focus about the sufficiency sufficiency part sorry.",
            "And by the way, and I was saying is that the rate is optimal so.",
            "Zoning question is how do you construct not possibility strategy?",
            "So assume so.",
            "This is the set C that you want to approach.",
            "Assume it from T you have edge payoff is around here.",
            "What you want at the end is that sequence average payoff converge to see.",
            "So what do you want?",
            "You want the next stage you average payoff is closer to see the net."
        ],
        [
            "So you want this is a projection of 80, so we watch that you average payoff is in this direction.",
            "OK, and if you want that your average for the next stage is in this direction."
        ],
        [
            "You just have to ensure that the following next payoff is on the other side of this hyperplane.",
            "OK, so fine idea build constructing an argument probability algorithm just fizzle two at any at every stage.",
            "Find some X such that no matter what natural does, the payoff is on this side of the plane.",
            "And how do you do that?",
            "If possible, yes, thanks to Blackwell condition.",
            "Backward conditions say that for every action Y of nature there is some X so that the payoff is in C. So for every why, some extra large payoff is on this side of the plane.",
            "And now using some min Max theorem you can switch the quantifier.",
            "So if this is for every why is there some X that will pay off is around here there's some extra just for every why we pay office in here."
        ],
        [
            "And this is exactly backward strategy.",
            "Just that you choose this this X.",
            "And no, if you want to compute this algorithm, what you have to do is to find this X.",
            "So you have to find to solve a min Max program, which is just a linear program.",
            "So let's go back to uncertainties.",
            "Assume that you will pay off that stage.",
            "D is not observed.",
            "You only information you got about this payoff is that it belongs to some set.",
            "But that will be denoted by M of why?",
            "So again, this subset of Eddy so."
        ],
        [
            "A good example of this framework is the partial monitoring, where you assume that the decisionmaker receive of each stage random signal Estey who's load depends on both X&Y.",
            "S should be also affected.",
            "So for example, in the bonded framework, your signal is just to pay off, but you do not observe.",
            "You pay off, you would get if you had chosen direction.",
            "So if we consider 2 action of nature Y&Y prime such that no matter what the decision maker makes.",
            "You'll receive the same signals.",
            "These two actions of.",
            "Net in nature are undistinguishable by the decision player decision maker.",
            "So if you if you want this to action, wipes are undistinguishable.",
            "So they are in the same equivalence class for the decision maker.",
            "So in this game, what the decision maker can know is that at runty it's payoff belongs to set M of like Steve YT, which is denoted like.",
            "That is also possible payoff that are that are.",
            "That can be generated by these choices.",
            "Football X and the equivalent class of why?",
            "So now in this framework you we have a game between decision maker and Nature, where at each stage the payoff is a set.",
            "The set M of XTYT.",
            "So what does approachability means in this framework?",
            "We were best possibility.",
            "It means you should find some extra algorithmics reject no matter what nature does you average set, so the right stage, the set of original converge to see this is the same thing as.",
            "Usual.",
            "But now if you want to Mail explanation where does that mean that never said converge to see this means that the first point in your veg state converts to see.",
            "So you might think if you want that the first point of some set converge to see you just have to apply Blackwell strategy to further assist.",
            "With influence."
        ],
        [
            "Unfortunately he did not work, so let's look at some easy control example where the decision makers for action, which are red, blue, green and yellow, and the nature or just one action be.",
            "If they make you choose action air alright, alright then it's payoff is already set over here.",
            "If it's choose Blues and payoff is a blue set to green and yellow.",
            "So now I'm going to show that the Blackwell strategy applied to the first point does not work.",
            "So assume that."
        ],
        [
            "And the third stage.",
            "It was red that has been played no.",
            "The furthest point in this set is empty one.",
            "OK, so if you want to apply black."
        ],
        [
            "Strategy just have to find some action such that the payoff is on the other side of your hyperplane H. For example, play blue."
        ],
        [
            "So at first Asia you play Blu Ray Dolan first Agent Blue second stage, so average payoff is well, is rich between red and blue, so this is in Brown.",
            "The first point is still there, two~ so finding.",
            "Tell you to play Blue again because reasons other side of H. So I."
        ],
        [
            "The next stage, the average payoff would be once served right onto S blue.",
            "So now it's like that little service payoff, and at this stage you can see that the first point is no longer at the top, but at the bottom.",
            "So no BlackBerry strategies to do.",
            "OK, you should find some some action such that the payoff is on the upper side of H, like red, so differing stage."
        ],
        [
            "Ruby red."
        ],
        [
            "We read again, I'm sorry."
        ],
        [
            "Then blue, then red and then blue.",
            "So we were going to."
        ],
        [
            "Acylates around here."
        ],
        [
            "You're not going to approach your sexy.",
            "But there's an easy strategy to approach.",
            "Just play one of green and one yellow at."
        ],
        [
            "Every stage and you pay off expected payoff will always busy set, which is included in C, so she is actually.",
            "Approachable So what do we learn from this control example?",
            "We learned that we should not focus on payoff.",
            "But only on.",
            "The sequence of action here playing red or blue was never a good thing.",
            "To that domain I need."
        ],
        [
            "So I'm going to give some insights of the other main result or main result is to characterize convex sets that are robust, approachable, and provide.",
            "And the possibilities strategy that has fixed computational complexity.",
            "And it has some rates of convergence, which that is independent of.",
            "AB&S so.",
            "Let's consider this this game decision maker of two action top and bottom.",
            "And Nature 2 action left and right.",
            "So if they could make it true, stop in nature choose left.",
            "The payoff is green.",
            "If you stop an already needs topping, the rights that will pay off will be random.",
            "Here we have some loose ends with this green set and we want to approach the.",
            "Caesar portable.",
            "So let's just assume for the moment that the third stage.",
            "Top left was played, so the payoff is green, so there's payoff is here in Brown."
        ],
        [
            "Now assume that second stage it's top right that is played, so the payoff is is ready, so it's payoff which is arranged between green and red is around here.",
            "Noah."
        ],
        [
            "Suffering stage.",
            "Let's say that is yellow display.",
            "The payoff is running here.",
            "I know it's a state."
        ],
        [
            "Blue we are around here.",
            "And again."
        ],
        [
            "It's blue, so here.",
            "The the average be off stage five is included in C, so if the game will handle at the after five stage will be very good thing we will be in the average set will be inside.",
            "So what I want to say is that we are happy that the average set is in C."
        ],
        [
            "And why is the average set in C?",
            "It's a trivial thing is just because this convex combination.",
            "Of red, green, yellow and blue is included in C, which is exactly the average.",
            "So, but before I said OK, forget about the payoff, just look at the action.",
            "So the important part here is not that this convex combination of set is included in C is just as this.",
            "The the weight 151 fifty 155th is a good a good weights if you want their weights such that that then shows that if you.",
            "If you compute the expectation of N with respect to those weights, your payoff is in C. So finally what I want to say is just forget about the payoff and what we want to do is to find strategies such that your your distribution of."
        ],
        [
            "Action, which is those weights converge to the set C. Setelah why, because if the condition of action belongs to see Tilda, then by definition of CWC that you expected payoff is in C. So now I'm going to when I say it's just OK.",
            "Forget about Georgia game, just consider an abstract game where what you want to do is to make the distribution converge to some set Citadel.",
            "So if you look at the same.",
            "Sequence that was played at the first time.",
            "We know that for some green was place where we are in the top top of this pretty top, which is the simplex over 4.",
            "Election as you can stage."
        ],
        [
            "Which was top rated top right which place so?",
            "Sorry, so I'm playing.",
            "This mission is around here."
        ],
        [
            "So this."
        ],
        [
            "Stage it moves."
        ],
        [
            "4th and five and five stage.",
            "You're in city LA.",
            "So why is it a good reduction?",
            "Because you see."
        ],
        [
            "On the left is that game you pay off assets.",
            "So it's complicated, but on the rights abstract game the payoff is just a point.",
            "Select ID in this game.",
            "We don't have any uncertainties.",
            "This is a game with full monitoring."
        ],
        [
            "So what what we have done is that we took a game with uncertainties, with partial monitoring and we say OK, don't look at this game.",
            "Look at this image game if you want, which is with full monitoring.",
            "This game is the same action A&B and instead of looking at the set of payoff.",
            "We just look at a single point which is.",
            "The total product between X&Y.",
            "And if you would define the image set city of C, then you can prove very easy to show that to see that C is always approachable if and only if this image sets it into is approachable.",
            "But since we are in full monitoring.",
            "We know that City City is approachable if, underneath Blackwell condition hold that means As for every why.",
            "Every move wires natural like some move X or the sneaker such that product we don't see it either.",
            "The definition of the fact that XY belongs to city that is just that M of XY is included in C. So finally we have the necessary and sufficient condition for responsibility, which tells you that the convex sets convex C is obvious, approachable if and only if for every move way of nature exist to move X position maker such that.",
            "M of XY is included in T. And this is.",
            "The generalization of Blackwell condition because if you're informing terranium, you observe your payoff, so M of XY is just a Singleton air of XY.",
            "So the fact that the secret on aerofex wise, including see just means that F of XY is included in T, so this is exactly Blackwell condition in for monitoring."
        ],
        [
            "So what main point is that we have some rates.",
            "So for responsibility, I said that would be pretty can be reduced to a possibility.",
            "So we have the same rates.",
            "So the distance of the first point to see.",
            "Is bounded by some constant that depends on the game.",
            "Times 1 / sqrt T and if we consider partial monitoring.",
            "Then we have the same condition of opportunity.",
            "This was the M of XY.",
            "Before so the distance is bounded by another constant Times 1 / T to the power one sees.",
            "Why is the difference between those two rates would simply be cause in passion littering you don't observe why, so you have to lose some time to explore in order to estimate.",
            "This this said not to estimate your your current class.",
            "You have to make some exploration or like just like inbound it.",
            "So you lose a bit of time and give you this rate of 131 sees.",
            "But we don't have lower bond, but it's probably almost surely in fact.",
            "That is one of your teachers are 11 certain white because in some specific case we know that we have some lower bound and summer bourbon for the same thing."
        ],
        [
            "So now some application I can use this.",
            "This tool opportunity tool to build strategies.",
            "There's no regret with special monitoring.",
            "So if I want to stay regret so not to pay off, I just feel really number.",
            "And then regret with special metering is simply the difference between the average playoff.",
            "The decision maker got and what he would have got for sure.",
            "If it had always played the same action X.",
            "So here this is the expression for the accelerates.",
            "This quantity is A is a average piece of position maker God and this is what he would have got for sure.",
            "So that's the minimum.",
            "If you had always played X. I know just like the way it's not the exact same definition as a flowing talk, so that's why it would be some differences anyway.",
            "So here I just think that we know that there exist strategies that have no external regret.",
            "We know that, but it's rather complicated.",
            "Proof completed, took some some pages, but with the tool the possibility tool we can get this result into line.",
            "How do we do that?",
            "Just define an abstract.",
            "Vector payoff and just got air which is on the 1st component.",
            "You have to rip it off.",
            "Another segment component you have is direct mass on B. OK undefined, see like that.",
            "I know I'm just saying that if this average payoff converge to set C, then we have no no external regret.",
            "Why?",
            "Because the the average vector payoff is on the 1st column first component you get the.",
            "A rich payoff and also second component, you get the average American dissolution of nature.",
            "So if so, if this?",
            "This vector belongs to C. Then it's easy to see that the external regret is smaller than 0, so we don't have any.",
            "Extra great, so we have a strategy such that the bond is 131 seats.",
            "Which is known results.",
            "But anyways just take two trying to prove it.",
            "And that's it, thanks.",
            "So how does in the rates?",
            "How does the dimensionality there must be some complexity parameter that enters?"
        ],
        [
            "Those bones you mean here?",
            "Yeah, it appears in the constant.",
            "In this constant it's.",
            "We need a second Times Square root of the quality of eight times quality of B.",
            "And in this.",
            "Consent is much more complicated because this set is not exactly the universal.",
            "You have some transformation to make, but due to the fact that games with partial metering, a very complicated structure that has no that simple, so I cannot will take me lots of time to explain so.",
            "So it just depends on the game, but it's not.",
            "That's no easy expression.",
            "Any other questions?",
            "OK, let's thank Benny."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I put my beauty as ridiculous.",
                    "label": 0
                },
                {
                    "sent": "Explained yesterday is used for the multicriteria optimization, that is, when you want to control at the same time several quantities, or if you like.",
                    "label": 0
                },
                {
                    "sent": "If you have several objectives that you want to optimize at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the good thing about a possibility is that it doesn't require any treatment or do objectives like choosing an order of the objective and abusing first.",
                    "label": 1
                },
                {
                    "sent": "The first one and the second one the third one or not requires that you consider convex or linear combination of your deal that you minimize.",
                    "label": 1
                },
                {
                    "sent": "And so I'm going to speak about our business.",
                    "label": 1
                },
                {
                    "sent": "We are partial monitoring that appears when you have some interest in certainties on your pay off all your data.",
                    "label": 1
                },
                {
                    "sent": "So we assume that they are not totally absorbed.",
                    "label": 1
                },
                {
                    "sent": "For example, you instead of seeing will pay off for that are you just receive a noisy feedback about it, or some partial observation like in.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "So let's forget about her business and personal development.",
                    "label": 0
                },
                {
                    "sent": "An those kind of program without question with ring can be formalized as a repeated game between the decision maker and nature.",
                    "label": 0
                },
                {
                    "sent": "So it's a repeated game and at ROM T the decision maker choose an action that is 80 in some set, a finite set a.",
                    "label": 0
                },
                {
                    "sent": "Why would you do that?",
                    "label": 0
                },
                {
                    "sent": "In fact, in address?",
                    "label": 0
                },
                {
                    "sent": "I'll online learning.",
                    "label": 0
                },
                {
                    "sent": "The decision maker should.",
                    "label": 0
                },
                {
                    "sent": "Through this action at random and they would not buy XTZ law of 18 and extend belongs to the probability to set operated discussion over air, which is Delta of a.",
                    "label": 0
                },
                {
                    "sent": "So at each run this will make your true selection a team and at the same times nature choose direction which is BT.",
                    "label": 0
                },
                {
                    "sent": "So just do couple of action, generates a payoff which it will depends of course abundant bus action.",
                    "label": 0
                },
                {
                    "sent": "So as Jake stolen yesterday, this payoff is a vector which has D component and each one of these components can see it as one of the quantities that we want to control simultaneously, or one of your objectives that we want to optimize.",
                    "label": 0
                },
                {
                    "sent": "So funny.",
                    "label": 0
                },
                {
                    "sent": "We can represent the overall objective of addition Maker as a target set C, so it's a subset of early and the aim of the decision maker is to construct an algorithm such that no matter what the natural does, the average payoff converge to this Etsy?",
                    "label": 1
                },
                {
                    "sent": "So for simplification, I might consider the expected version of this problem when the payoff will consider expected payoff instead of the real payoff.",
                    "label": 0
                },
                {
                    "sent": "But this does not change.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using.",
                    "label": 0
                },
                {
                    "sent": "So I push ability has been defined by Blackwell and also characterized convex, approachable set.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to cut it.",
                    "label": 0
                },
                {
                    "sent": "Blackwell condition and you say that the set C is applicable if and if for every move Y of nature there exist to move X of the decision maker such that the payoff is in C. So this is a very important theorem.",
                    "label": 0
                },
                {
                    "sent": "It's very very used in game theory because of the following interpretation.",
                    "label": 0
                },
                {
                    "sent": "You can say that.",
                    "label": 0
                },
                {
                    "sent": "Additionally, can fulfill simultaneously in the adversarial sequential framework lots of objectives if and only if you can do that in a non stochastic framework.",
                    "label": 1
                },
                {
                    "sent": "That means that we can do it when the data or the action of the nature or ID and additional maker knows there's a lot of their objection.",
                    "label": 0
                },
                {
                    "sent": "So another beautiful thing about this theorem is that.",
                    "label": 0
                },
                {
                    "sent": "It's very simple statement is very used and the proof is so simple.",
                    "label": 0
                },
                {
                    "sent": "So forget about this part is almost obvious.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to focus about the sufficiency sufficiency part sorry.",
                    "label": 0
                },
                {
                    "sent": "And by the way, and I was saying is that the rate is optimal so.",
                    "label": 0
                },
                {
                    "sent": "Zoning question is how do you construct not possibility strategy?",
                    "label": 0
                },
                {
                    "sent": "So assume so.",
                    "label": 0
                },
                {
                    "sent": "This is the set C that you want to approach.",
                    "label": 0
                },
                {
                    "sent": "Assume it from T you have edge payoff is around here.",
                    "label": 0
                },
                {
                    "sent": "What you want at the end is that sequence average payoff converge to see.",
                    "label": 0
                },
                {
                    "sent": "So what do you want?",
                    "label": 0
                },
                {
                    "sent": "You want the next stage you average payoff is closer to see the net.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you want this is a projection of 80, so we watch that you average payoff is in this direction.",
                    "label": 0
                },
                {
                    "sent": "OK, and if you want that your average for the next stage is in this direction.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You just have to ensure that the following next payoff is on the other side of this hyperplane.",
                    "label": 1
                },
                {
                    "sent": "OK, so fine idea build constructing an argument probability algorithm just fizzle two at any at every stage.",
                    "label": 0
                },
                {
                    "sent": "Find some X such that no matter what natural does, the payoff is on this side of the plane.",
                    "label": 0
                },
                {
                    "sent": "And how do you do that?",
                    "label": 0
                },
                {
                    "sent": "If possible, yes, thanks to Blackwell condition.",
                    "label": 0
                },
                {
                    "sent": "Backward conditions say that for every action Y of nature there is some X so that the payoff is in C. So for every why, some extra large payoff is on this side of the plane.",
                    "label": 0
                },
                {
                    "sent": "And now using some min Max theorem you can switch the quantifier.",
                    "label": 0
                },
                {
                    "sent": "So if this is for every why is there some X that will pay off is around here there's some extra just for every why we pay office in here.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is exactly backward strategy.",
                    "label": 0
                },
                {
                    "sent": "Just that you choose this this X.",
                    "label": 0
                },
                {
                    "sent": "And no, if you want to compute this algorithm, what you have to do is to find this X.",
                    "label": 0
                },
                {
                    "sent": "So you have to find to solve a min Max program, which is just a linear program.",
                    "label": 0
                },
                {
                    "sent": "So let's go back to uncertainties.",
                    "label": 0
                },
                {
                    "sent": "Assume that you will pay off that stage.",
                    "label": 0
                },
                {
                    "sent": "D is not observed.",
                    "label": 0
                },
                {
                    "sent": "You only information you got about this payoff is that it belongs to some set.",
                    "label": 0
                },
                {
                    "sent": "But that will be denoted by M of why?",
                    "label": 0
                },
                {
                    "sent": "So again, this subset of Eddy so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A good example of this framework is the partial monitoring, where you assume that the decisionmaker receive of each stage random signal Estey who's load depends on both X&Y.",
                    "label": 0
                },
                {
                    "sent": "S should be also affected.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the bonded framework, your signal is just to pay off, but you do not observe.",
                    "label": 0
                },
                {
                    "sent": "You pay off, you would get if you had chosen direction.",
                    "label": 0
                },
                {
                    "sent": "So if we consider 2 action of nature Y&Y prime such that no matter what the decision maker makes.",
                    "label": 0
                },
                {
                    "sent": "You'll receive the same signals.",
                    "label": 0
                },
                {
                    "sent": "These two actions of.",
                    "label": 0
                },
                {
                    "sent": "Net in nature are undistinguishable by the decision player decision maker.",
                    "label": 0
                },
                {
                    "sent": "So if you if you want this to action, wipes are undistinguishable.",
                    "label": 0
                },
                {
                    "sent": "So they are in the same equivalence class for the decision maker.",
                    "label": 0
                },
                {
                    "sent": "So in this game, what the decision maker can know is that at runty it's payoff belongs to set M of like Steve YT, which is denoted like.",
                    "label": 0
                },
                {
                    "sent": "That is also possible payoff that are that are.",
                    "label": 0
                },
                {
                    "sent": "That can be generated by these choices.",
                    "label": 0
                },
                {
                    "sent": "Football X and the equivalent class of why?",
                    "label": 0
                },
                {
                    "sent": "So now in this framework you we have a game between decision maker and Nature, where at each stage the payoff is a set.",
                    "label": 0
                },
                {
                    "sent": "The set M of XTYT.",
                    "label": 0
                },
                {
                    "sent": "So what does approachability means in this framework?",
                    "label": 0
                },
                {
                    "sent": "We were best possibility.",
                    "label": 0
                },
                {
                    "sent": "It means you should find some extra algorithmics reject no matter what nature does you average set, so the right stage, the set of original converge to see this is the same thing as.",
                    "label": 0
                },
                {
                    "sent": "Usual.",
                    "label": 0
                },
                {
                    "sent": "But now if you want to Mail explanation where does that mean that never said converge to see this means that the first point in your veg state converts to see.",
                    "label": 0
                },
                {
                    "sent": "So you might think if you want that the first point of some set converge to see you just have to apply Blackwell strategy to further assist.",
                    "label": 0
                },
                {
                    "sent": "With influence.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unfortunately he did not work, so let's look at some easy control example where the decision makers for action, which are red, blue, green and yellow, and the nature or just one action be.",
                    "label": 0
                },
                {
                    "sent": "If they make you choose action air alright, alright then it's payoff is already set over here.",
                    "label": 0
                },
                {
                    "sent": "If it's choose Blues and payoff is a blue set to green and yellow.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to show that the Blackwell strategy applied to the first point does not work.",
                    "label": 1
                },
                {
                    "sent": "So assume that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the third stage.",
                    "label": 0
                },
                {
                    "sent": "It was red that has been played no.",
                    "label": 0
                },
                {
                    "sent": "The furthest point in this set is empty one.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you want to apply black.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Strategy just have to find some action such that the payoff is on the other side of your hyperplane H. For example, play blue.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So at first Asia you play Blu Ray Dolan first Agent Blue second stage, so average payoff is well, is rich between red and blue, so this is in Brown.",
                    "label": 0
                },
                {
                    "sent": "The first point is still there, two~ so finding.",
                    "label": 0
                },
                {
                    "sent": "Tell you to play Blue again because reasons other side of H. So I.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next stage, the average payoff would be once served right onto S blue.",
                    "label": 1
                },
                {
                    "sent": "So now it's like that little service payoff, and at this stage you can see that the first point is no longer at the top, but at the bottom.",
                    "label": 1
                },
                {
                    "sent": "So no BlackBerry strategies to do.",
                    "label": 0
                },
                {
                    "sent": "OK, you should find some some action such that the payoff is on the upper side of H, like red, so differing stage.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ruby red.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We read again, I'm sorry.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then blue, then red and then blue.",
                    "label": 0
                },
                {
                    "sent": "So we were going to.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Acylates around here.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're not going to approach your sexy.",
                    "label": 0
                },
                {
                    "sent": "But there's an easy strategy to approach.",
                    "label": 0
                },
                {
                    "sent": "Just play one of green and one yellow at.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Every stage and you pay off expected payoff will always busy set, which is included in C, so she is actually.",
                    "label": 0
                },
                {
                    "sent": "Approachable So what do we learn from this control example?",
                    "label": 0
                },
                {
                    "sent": "We learned that we should not focus on payoff.",
                    "label": 1
                },
                {
                    "sent": "But only on.",
                    "label": 1
                },
                {
                    "sent": "The sequence of action here playing red or blue was never a good thing.",
                    "label": 0
                },
                {
                    "sent": "To that domain I need.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to give some insights of the other main result or main result is to characterize convex sets that are robust, approachable, and provide.",
                    "label": 1
                },
                {
                    "sent": "And the possibilities strategy that has fixed computational complexity.",
                    "label": 0
                },
                {
                    "sent": "And it has some rates of convergence, which that is independent of.",
                    "label": 0
                },
                {
                    "sent": "AB&S so.",
                    "label": 0
                },
                {
                    "sent": "Let's consider this this game decision maker of two action top and bottom.",
                    "label": 0
                },
                {
                    "sent": "And Nature 2 action left and right.",
                    "label": 0
                },
                {
                    "sent": "So if they could make it true, stop in nature choose left.",
                    "label": 0
                },
                {
                    "sent": "The payoff is green.",
                    "label": 0
                },
                {
                    "sent": "If you stop an already needs topping, the rights that will pay off will be random.",
                    "label": 0
                },
                {
                    "sent": "Here we have some loose ends with this green set and we want to approach the.",
                    "label": 0
                },
                {
                    "sent": "Caesar portable.",
                    "label": 0
                },
                {
                    "sent": "So let's just assume for the moment that the third stage.",
                    "label": 1
                },
                {
                    "sent": "Top left was played, so the payoff is green, so there's payoff is here in Brown.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now assume that second stage it's top right that is played, so the payoff is is ready, so it's payoff which is arranged between green and red is around here.",
                    "label": 0
                },
                {
                    "sent": "Noah.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suffering stage.",
                    "label": 0
                },
                {
                    "sent": "Let's say that is yellow display.",
                    "label": 0
                },
                {
                    "sent": "The payoff is running here.",
                    "label": 0
                },
                {
                    "sent": "I know it's a state.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Blue we are around here.",
                    "label": 0
                },
                {
                    "sent": "And again.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's blue, so here.",
                    "label": 0
                },
                {
                    "sent": "The the average be off stage five is included in C, so if the game will handle at the after five stage will be very good thing we will be in the average set will be inside.",
                    "label": 0
                },
                {
                    "sent": "So what I want to say is that we are happy that the average set is in C.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And why is the average set in C?",
                    "label": 0
                },
                {
                    "sent": "It's a trivial thing is just because this convex combination.",
                    "label": 0
                },
                {
                    "sent": "Of red, green, yellow and blue is included in C, which is exactly the average.",
                    "label": 0
                },
                {
                    "sent": "So, but before I said OK, forget about the payoff, just look at the action.",
                    "label": 0
                },
                {
                    "sent": "So the important part here is not that this convex combination of set is included in C is just as this.",
                    "label": 0
                },
                {
                    "sent": "The the weight 151 fifty 155th is a good a good weights if you want their weights such that that then shows that if you.",
                    "label": 0
                },
                {
                    "sent": "If you compute the expectation of N with respect to those weights, your payoff is in C. So finally what I want to say is just forget about the payoff and what we want to do is to find strategies such that your your distribution of.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action, which is those weights converge to the set C. Setelah why, because if the condition of action belongs to see Tilda, then by definition of CWC that you expected payoff is in C. So now I'm going to when I say it's just OK.",
                    "label": 0
                },
                {
                    "sent": "Forget about Georgia game, just consider an abstract game where what you want to do is to make the distribution converge to some set Citadel.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the same.",
                    "label": 0
                },
                {
                    "sent": "Sequence that was played at the first time.",
                    "label": 0
                },
                {
                    "sent": "We know that for some green was place where we are in the top top of this pretty top, which is the simplex over 4.",
                    "label": 0
                },
                {
                    "sent": "Election as you can stage.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which was top rated top right which place so?",
                    "label": 0
                },
                {
                    "sent": "Sorry, so I'm playing.",
                    "label": 0
                },
                {
                    "sent": "This mission is around here.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stage it moves.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "4th and five and five stage.",
                    "label": 0
                },
                {
                    "sent": "You're in city LA.",
                    "label": 0
                },
                {
                    "sent": "So why is it a good reduction?",
                    "label": 0
                },
                {
                    "sent": "Because you see.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the left is that game you pay off assets.",
                    "label": 0
                },
                {
                    "sent": "So it's complicated, but on the rights abstract game the payoff is just a point.",
                    "label": 0
                },
                {
                    "sent": "Select ID in this game.",
                    "label": 0
                },
                {
                    "sent": "We don't have any uncertainties.",
                    "label": 0
                },
                {
                    "sent": "This is a game with full monitoring.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what what we have done is that we took a game with uncertainties, with partial monitoring and we say OK, don't look at this game.",
                    "label": 0
                },
                {
                    "sent": "Look at this image game if you want, which is with full monitoring.",
                    "label": 0
                },
                {
                    "sent": "This game is the same action A&B and instead of looking at the set of payoff.",
                    "label": 0
                },
                {
                    "sent": "We just look at a single point which is.",
                    "label": 0
                },
                {
                    "sent": "The total product between X&Y.",
                    "label": 0
                },
                {
                    "sent": "And if you would define the image set city of C, then you can prove very easy to show that to see that C is always approachable if and only if this image sets it into is approachable.",
                    "label": 0
                },
                {
                    "sent": "But since we are in full monitoring.",
                    "label": 0
                },
                {
                    "sent": "We know that City City is approachable if, underneath Blackwell condition hold that means As for every why.",
                    "label": 0
                },
                {
                    "sent": "Every move wires natural like some move X or the sneaker such that product we don't see it either.",
                    "label": 0
                },
                {
                    "sent": "The definition of the fact that XY belongs to city that is just that M of XY is included in C. So finally we have the necessary and sufficient condition for responsibility, which tells you that the convex sets convex C is obvious, approachable if and only if for every move way of nature exist to move X position maker such that.",
                    "label": 0
                },
                {
                    "sent": "M of XY is included in T. And this is.",
                    "label": 0
                },
                {
                    "sent": "The generalization of Blackwell condition because if you're informing terranium, you observe your payoff, so M of XY is just a Singleton air of XY.",
                    "label": 0
                },
                {
                    "sent": "So the fact that the secret on aerofex wise, including see just means that F of XY is included in T, so this is exactly Blackwell condition in for monitoring.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what main point is that we have some rates.",
                    "label": 0
                },
                {
                    "sent": "So for responsibility, I said that would be pretty can be reduced to a possibility.",
                    "label": 0
                },
                {
                    "sent": "So we have the same rates.",
                    "label": 0
                },
                {
                    "sent": "So the distance of the first point to see.",
                    "label": 0
                },
                {
                    "sent": "Is bounded by some constant that depends on the game.",
                    "label": 0
                },
                {
                    "sent": "Times 1 / sqrt T and if we consider partial monitoring.",
                    "label": 0
                },
                {
                    "sent": "Then we have the same condition of opportunity.",
                    "label": 0
                },
                {
                    "sent": "This was the M of XY.",
                    "label": 0
                },
                {
                    "sent": "Before so the distance is bounded by another constant Times 1 / T to the power one sees.",
                    "label": 0
                },
                {
                    "sent": "Why is the difference between those two rates would simply be cause in passion littering you don't observe why, so you have to lose some time to explore in order to estimate.",
                    "label": 0
                },
                {
                    "sent": "This this said not to estimate your your current class.",
                    "label": 0
                },
                {
                    "sent": "You have to make some exploration or like just like inbound it.",
                    "label": 0
                },
                {
                    "sent": "So you lose a bit of time and give you this rate of 131 sees.",
                    "label": 0
                },
                {
                    "sent": "But we don't have lower bond, but it's probably almost surely in fact.",
                    "label": 0
                },
                {
                    "sent": "That is one of your teachers are 11 certain white because in some specific case we know that we have some lower bound and summer bourbon for the same thing.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now some application I can use this.",
                    "label": 0
                },
                {
                    "sent": "This tool opportunity tool to build strategies.",
                    "label": 0
                },
                {
                    "sent": "There's no regret with special monitoring.",
                    "label": 0
                },
                {
                    "sent": "So if I want to stay regret so not to pay off, I just feel really number.",
                    "label": 0
                },
                {
                    "sent": "And then regret with special metering is simply the difference between the average playoff.",
                    "label": 0
                },
                {
                    "sent": "The decision maker got and what he would have got for sure.",
                    "label": 0
                },
                {
                    "sent": "If it had always played the same action X.",
                    "label": 0
                },
                {
                    "sent": "So here this is the expression for the accelerates.",
                    "label": 0
                },
                {
                    "sent": "This quantity is A is a average piece of position maker God and this is what he would have got for sure.",
                    "label": 0
                },
                {
                    "sent": "So that's the minimum.",
                    "label": 0
                },
                {
                    "sent": "If you had always played X. I know just like the way it's not the exact same definition as a flowing talk, so that's why it would be some differences anyway.",
                    "label": 0
                },
                {
                    "sent": "So here I just think that we know that there exist strategies that have no external regret.",
                    "label": 0
                },
                {
                    "sent": "We know that, but it's rather complicated.",
                    "label": 0
                },
                {
                    "sent": "Proof completed, took some some pages, but with the tool the possibility tool we can get this result into line.",
                    "label": 0
                },
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "Just define an abstract.",
                    "label": 0
                },
                {
                    "sent": "Vector payoff and just got air which is on the 1st component.",
                    "label": 0
                },
                {
                    "sent": "You have to rip it off.",
                    "label": 0
                },
                {
                    "sent": "Another segment component you have is direct mass on B. OK undefined, see like that.",
                    "label": 0
                },
                {
                    "sent": "I know I'm just saying that if this average payoff converge to set C, then we have no no external regret.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because the the average vector payoff is on the 1st column first component you get the.",
                    "label": 0
                },
                {
                    "sent": "A rich payoff and also second component, you get the average American dissolution of nature.",
                    "label": 0
                },
                {
                    "sent": "So if so, if this?",
                    "label": 0
                },
                {
                    "sent": "This vector belongs to C. Then it's easy to see that the external regret is smaller than 0, so we don't have any.",
                    "label": 0
                },
                {
                    "sent": "Extra great, so we have a strategy such that the bond is 131 seats.",
                    "label": 0
                },
                {
                    "sent": "Which is known results.",
                    "label": 0
                },
                {
                    "sent": "But anyways just take two trying to prove it.",
                    "label": 0
                },
                {
                    "sent": "And that's it, thanks.",
                    "label": 0
                },
                {
                    "sent": "So how does in the rates?",
                    "label": 0
                },
                {
                    "sent": "How does the dimensionality there must be some complexity parameter that enters?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those bones you mean here?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it appears in the constant.",
                    "label": 0
                },
                {
                    "sent": "In this constant it's.",
                    "label": 0
                },
                {
                    "sent": "We need a second Times Square root of the quality of eight times quality of B.",
                    "label": 0
                },
                {
                    "sent": "And in this.",
                    "label": 0
                },
                {
                    "sent": "Consent is much more complicated because this set is not exactly the universal.",
                    "label": 0
                },
                {
                    "sent": "You have some transformation to make, but due to the fact that games with partial metering, a very complicated structure that has no that simple, so I cannot will take me lots of time to explain so.",
                    "label": 0
                },
                {
                    "sent": "So it just depends on the game, but it's not.",
                    "label": 0
                },
                {
                    "sent": "That's no easy expression.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank Benny.",
                    "label": 0
                }
            ]
        }
    }
}