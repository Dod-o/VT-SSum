{
    "id": "jgcwhb7fnrm4qh3aqej7i6noevofsfl5",
    "title": "Usage of SVM for a Triggering Mechanism for Higgs Boson Detection",
    "info": {
        "author": [
            "Klemen Kenda, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Dec. 8, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2017_kenda_higgs_boson/",
    "segmentation": [
        [
            "OK, so we will dig a little bit into another field of high energy physics and I will be presenting Q our work on the usage of support vector machines as a triggering mechanism for Higgs boson detection."
        ],
        [
            "So the motivation why a data scientist with approaches problem arises from this picture, which is a picture of an event happening in the Atlas detector, which was the detector that was trying to detect the existence of this Higgs bozon as, as you can see already on this picture, it is really a mess and this means that when 2 protons collect together, there is a bunch of events, a bunch of different particles and signals that runs out of it.",
            "And firstly we need to catch everything that happens and after this of course we need to analyze and see.",
            "Whether this is important for us or not?"
        ],
        [
            "So the brief.",
            "So we will go through the presentation.",
            "We will give a brief introduction of the high energy physics and the Higgs Bozon search.",
            "Then we will look at the data, present this as a machine learning problem and then we will see how we worked on adjusting color SVM method to.",
            "Work as good as possible, so to be near the current state of the art, and then finally we will conclude our."
        ],
        [
            "Sentation so the search of these particles started more than 50 years ago when the existence of it was theorized by tree physicists, and two of them, approximately 50 years later, won a Nobel Prize for physics, and basically what we're looking for is this particle.",
            "This here is a standard model of elementary particles, and all of them have been observed before, but this one was sort of not, and the idea was.",
            "To confirm that this model is correct and to see this particle.",
            "So how do we detect this particle?",
            "We detect it in a way in this big machines these are quite a few kilometers in diameter, and in these machines we accelerate two streams of photon in these big rings and all these two streams of photons, they travel in the opposite directions and once they reach a big enough energy, so the energy that is supposed to be good enough that the Higgs bozon might arise out of it, because this is a particle with or really big mass.",
            "Then we try to collide these beams together and once a collision happens alot of things can happen and one of those things is also this Higgs bozon and we cannot observe this particle because it decays almost immediately.",
            "But we can observe what are these decays, decay products and this is basically what this detector does."
        ],
        [
            "The picture is really big, 25 by 44 meters in size, so here's a picture of two persons so that you can imagine how big this machine really is.",
            "So around here at the center, the collision happens and then all around there many different detectors that can detect these elementary."
        ],
        [
            "Particles, and so this is a cross section of this machine, and the particles that we can observe here are the ones that we know quite well.",
            "For example electron neutral proton, photons, moons and of course neutrinos.",
            "They escape our detector and they make us problems later."
        ],
        [
            "OK, so in 2012 when they started this machine of course they did not yet use machine learning techniques to detect events where a Higgs boson might be involved.",
            "So they firstly used just basic statistical approaches and for this they needed some really nice decay channels and one of these nice decay channels is this one where Higgs Bozon the case into two photons.",
            "Because why is it nice just because of the fact that the background that is here you can see it's really?",
            "We can interpret it.",
            "We can even approximate it analytically, and when they were putting in day to day after day, slowly this bump started to rise.",
            "Here at this energy and this was the first indication that something might be happening there, and everybody was hoping.",
            "Of course, this might be the proof of the Higgs Bozon.",
            "Then they look another channel when Higgs Bozon finally decays into four laptops and again they have, the theory has told us what this background would look like and this bump here.",
            "That was not.",
            "Assumed by the theory, this is some anomaly as we were talking before, and this anomaly represents another possibility.",
            "Another proof that this might be a Higgs bozon.",
            "So once there was enough evidence gained that this Higgs bozon might exist, then they said yes, really something is going on there that is statistically."
        ],
        [
            "Edificant OK and then we go further to a little bit more.",
            "Dirty events which we cannot analyze so nicely.",
            "We see, for example, this one where Hicks the case into two power leptons and the problem here is we can see this black line represents the background and the red line represents the signal.",
            "So the signal is those events where Higgs Bozon was involved and background are those signals where Higgs Bozon was not involved.",
            "We can see that, for example, if we get somewhere in here, we cannot really tell whether this event belongs to the signal or to the background, and because of this we need to use some.",
            "A little bit more sophisticated methods.",
            "This decay was the one that we have looked and this this data that we used originates from a public challenge organized by Cargill and it's called Hicks Machine Learning Challenge that."
        ],
        [
            "Lunch was actually quite successful because it connected scientists from high energy physics and data data science and they have come up with better methods that they have used before.",
            "OK, basically what we are doing is supervised learning and more accurately classification and we for this we need of course some labeled data.",
            "It's impossible to get labeled data out of the detector.",
            "Becausw even expert human user cannot say whether this is signalr or not.",
            "Therefore they accumulate all the knowledge that they had on the high energy physics and they created of course a simulator of what would be expected to happen in this detector.",
            "So the data set is quite large.",
            "Quarter of a million events.",
            "30 features each and some additional metadata.",
            "So the first thing to do here was of course, to check the data set first to see whether through the data set we have the same statistical properties.",
            "And then we did some depicting by one component by 1 feature.",
            "So for example, this is, I think the overall available energy of 1 collision of particles and the signal is depicted in yellow and the background in green.",
            "And from all these pictures actually we see.",
            "The team almost impossible to say anything about the event.",
            "Very little we can say about the event if we look only at one feature."
        ],
        [
            "OK, just to prove ourselves that with more features we can do a little bit more.",
            "We did principal component analysis and here are some plots by different components and we can see already here that there are some areas that are clearly belong here for the signal and some areas that clearly belong to the background.",
            "So this was the proof that we are working in a good direction that bad."
        ],
        [
            "Results can be achieved with techniques that will take the whole feature vector into account, so the definition of the problem is quite standard.",
            "We have labeled data set that includes features label antweight and this weight is actually the probability of an event happening in our simulator.",
            "They think about this Higgs bozon is that it?",
            "These events are really rare and the algorithm that we're building is the first algorithm that means the data after it happens and there's really a huge stream of data becausw you will know that kind of physics is one of the scientific fields that really does generate this big data.",
            "There are 40,000,000 events happening.",
            "It's second here and we need even to store this data.",
            "We need to decide what is relevant for us and what is not.",
            "Yeah, so basically we're looking for the classification function classification algorithm that will do this classification as good as possible according to the selected metrics.",
            "And as I mentioned."
        ],
        [
            "Before this algorithm, we are not actually maximising here precision recall or F1 score or any other standard measures for classification.",
            "But the physics physicists physicists have come up with another measure which is called average median significance and this measure.",
            "Basically what it does is that it favorise recall in front of the precision.",
            "So as the events are rare we don't want to leave any event out, but we don't care if we have some more in our.",
            "Database.",
            "So about the evaluation as the SVM takes quite a lot of time to learn on such a huge data set, we have used just normal splitting, not cross validation for our."
        ],
        [
            "Our purpose is.",
            "OK, so the state of the art method in these fields are gradient boosting and deep neural networks and why they are so successful is because of their intense intrinsic property that they sort of introduced non linearity into the feature space, right?",
            "They've curved the space so that the classification works better.",
            "And to overcome this with our SVM of course what we did to us extensive feature engineering.",
            "So we simply did transformations by one or two features and the transformations work according to these functions.",
            "We have also included missing values, cluster IDs and as a new features and this feature selection we just.",
            "Took an approach of naked eye and we have just seen where there were after which threshold.",
            "There are a lot of features below and we have said OK, this is may be relevant for us.",
            "This maybe it's not the best approach which I will comment a little bit later."
        ],
        [
            "OK, so we did a lot of experiments we have created in the beginning 17 different datasets from the original provided by the by the simulator of the Atlas detector.",
            "And then we did a little bit of transformation by man variable and transformations by two variables.",
            "An in between there are some additional data set that might be relevant for us, but they have proven not to be very successful."
        ],
        [
            "So the first experiments were taken with linear kernel of the SVM and we have seen that we have improved our original score, which is this one for approximately 25%.",
            "So these datasets work sort of the best.",
            "Also this one, and these are all data set that includes transformation by one and by two variables altogether.",
            "OK when we tried."
        ],
        [
            "So use different kernels within the SVM.",
            "We have found out that actually we have improved the score by additional almost 10% and we have found out that actually this data set which only has transformations by one variable, is more successful.",
            "And the answer is of course in that that already the kernel the RBF in this case combines these variables together OK. Why are the score difference than this here?",
            "This initial experiments were done with only 10% of the training set and this was done with 90%.",
            "We have used the other 10% for the evaluation."
        ],
        [
            "OK, and when we put all the things together with our methods and state of the art methods, we can see that our method, which is this one SVM with RBF kernel on the transformations of by one variable, works quite good in comparison with this referencing methods.",
            "But this is state of the art which is much better.",
            "We should mention here that this XG boost method basically sold, so gradient boosting trees like this one here.",
            "But the only difference is difference is that this method is actually optimized for this AMS evaluation measure, so This is why this score is better.",
            "Because if you look at this score, except of course of the recall, our method works better.",
            "So there was some more place for the improvement."
        ],
        [
            "So in this improvement was done by just stopped."
        ],
        [
            "Imagine the threshold within the SVM classifier.",
            "There are of course other things that we can do, but they at least building connection that would already optimize this.",
            "AMS metrics would be would be much, much more difficult.",
            "So we came up to the score 3.45, which puts us quite near to the state of the art.",
            "Which is 3.74.",
            "So we were really happy, happy with these results and what is really nice is that these results were actually better than the method they have used in CERN in Geneva before this machine learning challenge.",
            "OK."
        ],
        [
            "So to conclude."
        ],
        [
            "This presentation we have done data scientist introspection into high energy physics.",
            "We didn't care much about what physics was beside behind 'cause already.",
            "The experts from physics physics did that.",
            "We approach this from a purely data driven point of view.",
            "We have tested the support vector machines and we've got much better results than the other competitors that have reported using calcium.",
            "In this challenge we have come quite close to the state of the art, but probably.",
            "Actually boost cannot be cannot be achieved with tweaking the SVM.",
            "What is Dhoni's from our work is that at least with linear SVM we can interpret which features are really relevant and that might give some introspection.",
            "Some additional knowledge to the physicist.",
            "OK, so thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we will dig a little bit into another field of high energy physics and I will be presenting Q our work on the usage of support vector machines as a triggering mechanism for Higgs boson detection.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the motivation why a data scientist with approaches problem arises from this picture, which is a picture of an event happening in the Atlas detector, which was the detector that was trying to detect the existence of this Higgs bozon as, as you can see already on this picture, it is really a mess and this means that when 2 protons collect together, there is a bunch of events, a bunch of different particles and signals that runs out of it.",
                    "label": 0
                },
                {
                    "sent": "And firstly we need to catch everything that happens and after this of course we need to analyze and see.",
                    "label": 0
                },
                {
                    "sent": "Whether this is important for us or not?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the brief.",
                    "label": 0
                },
                {
                    "sent": "So we will go through the presentation.",
                    "label": 0
                },
                {
                    "sent": "We will give a brief introduction of the high energy physics and the Higgs Bozon search.",
                    "label": 0
                },
                {
                    "sent": "Then we will look at the data, present this as a machine learning problem and then we will see how we worked on adjusting color SVM method to.",
                    "label": 0
                },
                {
                    "sent": "Work as good as possible, so to be near the current state of the art, and then finally we will conclude our.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sentation so the search of these particles started more than 50 years ago when the existence of it was theorized by tree physicists, and two of them, approximately 50 years later, won a Nobel Prize for physics, and basically what we're looking for is this particle.",
                    "label": 1
                },
                {
                    "sent": "This here is a standard model of elementary particles, and all of them have been observed before, but this one was sort of not, and the idea was.",
                    "label": 0
                },
                {
                    "sent": "To confirm that this model is correct and to see this particle.",
                    "label": 0
                },
                {
                    "sent": "So how do we detect this particle?",
                    "label": 0
                },
                {
                    "sent": "We detect it in a way in this big machines these are quite a few kilometers in diameter, and in these machines we accelerate two streams of photon in these big rings and all these two streams of photons, they travel in the opposite directions and once they reach a big enough energy, so the energy that is supposed to be good enough that the Higgs bozon might arise out of it, because this is a particle with or really big mass.",
                    "label": 0
                },
                {
                    "sent": "Then we try to collide these beams together and once a collision happens alot of things can happen and one of those things is also this Higgs bozon and we cannot observe this particle because it decays almost immediately.",
                    "label": 0
                },
                {
                    "sent": "But we can observe what are these decays, decay products and this is basically what this detector does.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The picture is really big, 25 by 44 meters in size, so here's a picture of two persons so that you can imagine how big this machine really is.",
                    "label": 0
                },
                {
                    "sent": "So around here at the center, the collision happens and then all around there many different detectors that can detect these elementary.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particles, and so this is a cross section of this machine, and the particles that we can observe here are the ones that we know quite well.",
                    "label": 0
                },
                {
                    "sent": "For example electron neutral proton, photons, moons and of course neutrinos.",
                    "label": 0
                },
                {
                    "sent": "They escape our detector and they make us problems later.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in 2012 when they started this machine of course they did not yet use machine learning techniques to detect events where a Higgs boson might be involved.",
                    "label": 0
                },
                {
                    "sent": "So they firstly used just basic statistical approaches and for this they needed some really nice decay channels and one of these nice decay channels is this one where Higgs Bozon the case into two photons.",
                    "label": 0
                },
                {
                    "sent": "Because why is it nice just because of the fact that the background that is here you can see it's really?",
                    "label": 0
                },
                {
                    "sent": "We can interpret it.",
                    "label": 0
                },
                {
                    "sent": "We can even approximate it analytically, and when they were putting in day to day after day, slowly this bump started to rise.",
                    "label": 0
                },
                {
                    "sent": "Here at this energy and this was the first indication that something might be happening there, and everybody was hoping.",
                    "label": 0
                },
                {
                    "sent": "Of course, this might be the proof of the Higgs Bozon.",
                    "label": 0
                },
                {
                    "sent": "Then they look another channel when Higgs Bozon finally decays into four laptops and again they have, the theory has told us what this background would look like and this bump here.",
                    "label": 0
                },
                {
                    "sent": "That was not.",
                    "label": 0
                },
                {
                    "sent": "Assumed by the theory, this is some anomaly as we were talking before, and this anomaly represents another possibility.",
                    "label": 0
                },
                {
                    "sent": "Another proof that this might be a Higgs bozon.",
                    "label": 0
                },
                {
                    "sent": "So once there was enough evidence gained that this Higgs bozon might exist, then they said yes, really something is going on there that is statistically.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Edificant OK and then we go further to a little bit more.",
                    "label": 0
                },
                {
                    "sent": "Dirty events which we cannot analyze so nicely.",
                    "label": 0
                },
                {
                    "sent": "We see, for example, this one where Hicks the case into two power leptons and the problem here is we can see this black line represents the background and the red line represents the signal.",
                    "label": 0
                },
                {
                    "sent": "So the signal is those events where Higgs Bozon was involved and background are those signals where Higgs Bozon was not involved.",
                    "label": 0
                },
                {
                    "sent": "We can see that, for example, if we get somewhere in here, we cannot really tell whether this event belongs to the signal or to the background, and because of this we need to use some.",
                    "label": 0
                },
                {
                    "sent": "A little bit more sophisticated methods.",
                    "label": 0
                },
                {
                    "sent": "This decay was the one that we have looked and this this data that we used originates from a public challenge organized by Cargill and it's called Hicks Machine Learning Challenge that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lunch was actually quite successful because it connected scientists from high energy physics and data data science and they have come up with better methods that they have used before.",
                    "label": 0
                },
                {
                    "sent": "OK, basically what we are doing is supervised learning and more accurately classification and we for this we need of course some labeled data.",
                    "label": 0
                },
                {
                    "sent": "It's impossible to get labeled data out of the detector.",
                    "label": 0
                },
                {
                    "sent": "Becausw even expert human user cannot say whether this is signalr or not.",
                    "label": 0
                },
                {
                    "sent": "Therefore they accumulate all the knowledge that they had on the high energy physics and they created of course a simulator of what would be expected to happen in this detector.",
                    "label": 0
                },
                {
                    "sent": "So the data set is quite large.",
                    "label": 0
                },
                {
                    "sent": "Quarter of a million events.",
                    "label": 0
                },
                {
                    "sent": "30 features each and some additional metadata.",
                    "label": 0
                },
                {
                    "sent": "So the first thing to do here was of course, to check the data set first to see whether through the data set we have the same statistical properties.",
                    "label": 0
                },
                {
                    "sent": "And then we did some depicting by one component by 1 feature.",
                    "label": 0
                },
                {
                    "sent": "So for example, this is, I think the overall available energy of 1 collision of particles and the signal is depicted in yellow and the background in green.",
                    "label": 0
                },
                {
                    "sent": "And from all these pictures actually we see.",
                    "label": 0
                },
                {
                    "sent": "The team almost impossible to say anything about the event.",
                    "label": 0
                },
                {
                    "sent": "Very little we can say about the event if we look only at one feature.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, just to prove ourselves that with more features we can do a little bit more.",
                    "label": 0
                },
                {
                    "sent": "We did principal component analysis and here are some plots by different components and we can see already here that there are some areas that are clearly belong here for the signal and some areas that clearly belong to the background.",
                    "label": 0
                },
                {
                    "sent": "So this was the proof that we are working in a good direction that bad.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results can be achieved with techniques that will take the whole feature vector into account, so the definition of the problem is quite standard.",
                    "label": 0
                },
                {
                    "sent": "We have labeled data set that includes features label antweight and this weight is actually the probability of an event happening in our simulator.",
                    "label": 0
                },
                {
                    "sent": "They think about this Higgs bozon is that it?",
                    "label": 0
                },
                {
                    "sent": "These events are really rare and the algorithm that we're building is the first algorithm that means the data after it happens and there's really a huge stream of data becausw you will know that kind of physics is one of the scientific fields that really does generate this big data.",
                    "label": 0
                },
                {
                    "sent": "There are 40,000,000 events happening.",
                    "label": 0
                },
                {
                    "sent": "It's second here and we need even to store this data.",
                    "label": 0
                },
                {
                    "sent": "We need to decide what is relevant for us and what is not.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so basically we're looking for the classification function classification algorithm that will do this classification as good as possible according to the selected metrics.",
                    "label": 1
                },
                {
                    "sent": "And as I mentioned.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before this algorithm, we are not actually maximising here precision recall or F1 score or any other standard measures for classification.",
                    "label": 0
                },
                {
                    "sent": "But the physics physicists physicists have come up with another measure which is called average median significance and this measure.",
                    "label": 0
                },
                {
                    "sent": "Basically what it does is that it favorise recall in front of the precision.",
                    "label": 0
                },
                {
                    "sent": "So as the events are rare we don't want to leave any event out, but we don't care if we have some more in our.",
                    "label": 0
                },
                {
                    "sent": "Database.",
                    "label": 0
                },
                {
                    "sent": "So about the evaluation as the SVM takes quite a lot of time to learn on such a huge data set, we have used just normal splitting, not cross validation for our.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our purpose is.",
                    "label": 0
                },
                {
                    "sent": "OK, so the state of the art method in these fields are gradient boosting and deep neural networks and why they are so successful is because of their intense intrinsic property that they sort of introduced non linearity into the feature space, right?",
                    "label": 0
                },
                {
                    "sent": "They've curved the space so that the classification works better.",
                    "label": 0
                },
                {
                    "sent": "And to overcome this with our SVM of course what we did to us extensive feature engineering.",
                    "label": 0
                },
                {
                    "sent": "So we simply did transformations by one or two features and the transformations work according to these functions.",
                    "label": 1
                },
                {
                    "sent": "We have also included missing values, cluster IDs and as a new features and this feature selection we just.",
                    "label": 1
                },
                {
                    "sent": "Took an approach of naked eye and we have just seen where there were after which threshold.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of features below and we have said OK, this is may be relevant for us.",
                    "label": 0
                },
                {
                    "sent": "This maybe it's not the best approach which I will comment a little bit later.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we did a lot of experiments we have created in the beginning 17 different datasets from the original provided by the by the simulator of the Atlas detector.",
                    "label": 0
                },
                {
                    "sent": "And then we did a little bit of transformation by man variable and transformations by two variables.",
                    "label": 0
                },
                {
                    "sent": "An in between there are some additional data set that might be relevant for us, but they have proven not to be very successful.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first experiments were taken with linear kernel of the SVM and we have seen that we have improved our original score, which is this one for approximately 25%.",
                    "label": 0
                },
                {
                    "sent": "So these datasets work sort of the best.",
                    "label": 0
                },
                {
                    "sent": "Also this one, and these are all data set that includes transformation by one and by two variables altogether.",
                    "label": 0
                },
                {
                    "sent": "OK when we tried.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So use different kernels within the SVM.",
                    "label": 0
                },
                {
                    "sent": "We have found out that actually we have improved the score by additional almost 10% and we have found out that actually this data set which only has transformations by one variable, is more successful.",
                    "label": 0
                },
                {
                    "sent": "And the answer is of course in that that already the kernel the RBF in this case combines these variables together OK. Why are the score difference than this here?",
                    "label": 0
                },
                {
                    "sent": "This initial experiments were done with only 10% of the training set and this was done with 90%.",
                    "label": 0
                },
                {
                    "sent": "We have used the other 10% for the evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and when we put all the things together with our methods and state of the art methods, we can see that our method, which is this one SVM with RBF kernel on the transformations of by one variable, works quite good in comparison with this referencing methods.",
                    "label": 0
                },
                {
                    "sent": "But this is state of the art which is much better.",
                    "label": 0
                },
                {
                    "sent": "We should mention here that this XG boost method basically sold, so gradient boosting trees like this one here.",
                    "label": 0
                },
                {
                    "sent": "But the only difference is difference is that this method is actually optimized for this AMS evaluation measure, so This is why this score is better.",
                    "label": 0
                },
                {
                    "sent": "Because if you look at this score, except of course of the recall, our method works better.",
                    "label": 0
                },
                {
                    "sent": "So there was some more place for the improvement.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this improvement was done by just stopped.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imagine the threshold within the SVM classifier.",
                    "label": 0
                },
                {
                    "sent": "There are of course other things that we can do, but they at least building connection that would already optimize this.",
                    "label": 0
                },
                {
                    "sent": "AMS metrics would be would be much, much more difficult.",
                    "label": 0
                },
                {
                    "sent": "So we came up to the score 3.45, which puts us quite near to the state of the art.",
                    "label": 0
                },
                {
                    "sent": "Which is 3.74.",
                    "label": 0
                },
                {
                    "sent": "So we were really happy, happy with these results and what is really nice is that these results were actually better than the method they have used in CERN in Geneva before this machine learning challenge.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This presentation we have done data scientist introspection into high energy physics.",
                    "label": 1
                },
                {
                    "sent": "We didn't care much about what physics was beside behind 'cause already.",
                    "label": 0
                },
                {
                    "sent": "The experts from physics physics did that.",
                    "label": 1
                },
                {
                    "sent": "We approach this from a purely data driven point of view.",
                    "label": 1
                },
                {
                    "sent": "We have tested the support vector machines and we've got much better results than the other competitors that have reported using calcium.",
                    "label": 0
                },
                {
                    "sent": "In this challenge we have come quite close to the state of the art, but probably.",
                    "label": 0
                },
                {
                    "sent": "Actually boost cannot be cannot be achieved with tweaking the SVM.",
                    "label": 0
                },
                {
                    "sent": "What is Dhoni's from our work is that at least with linear SVM we can interpret which features are really relevant and that might give some introspection.",
                    "label": 0
                },
                {
                    "sent": "Some additional knowledge to the physicist.",
                    "label": 0
                },
                {
                    "sent": "OK, so thank you.",
                    "label": 0
                }
            ]
        }
    }
}