{
    "id": "lcvkehiy3mpbe4jkeydt6tduf7s2ueca",
    "title": "Sequence learning with hidden units in spiking neural networks",
    "info": {
        "author": [
            "Johanni Brea, Department of Physiology, University of Bern"
        ],
        "published": "Sept. 6, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Neural Networks"
        ]
    },
    "url": "http://videolectures.net/nips2011_brea_neural/",
    "segmentation": [
        [
            "I will nervous system has an amazing capability to learn complex sequences like the sequence of movements required to learn a song on the violin.",
            "In this study, we want to convince you that we can build a network of spiking neurons with hidden units and.",
            "A nice biologically realistic learning rule to learn interesting sequences.",
            "We used are."
        ],
        [
            "The current network of stochastic spiking neurons.",
            "This network produces spatial temporal spike patterns.",
            "During learning, the visible neurons are claimed to sample sequences of the target distribution.",
            "The model shall adapt its parameters.",
            "For example, the synaptic weights such that the model distribution approaches the target distribution over learning with only visible units.",
            "This system can learn only boring sequences.",
            "Including hidden units, things become more interesting, but the learning task also becomes more challenging."
        ],
        [
            "So in contrast to the Boltzmann machine that also uses hidden units but postulates the Boltzmann distribution, we started with the definition of the neuronal dynamics.",
            "We use the stochastic spike Response Model, also known as generalized linear model.",
            "This defines our model distribution with this model distribution we arrived as stochastic gradient descent learning rule on the kupec liable divergance from target to model distribution.",
            "Even though things tend to be more complicated with hidden units, we were excited to find a nice learning rule.",
            "It consists of a pre term and the post term local and a modulating global factor.",
            "We also showed that an online approximation exists.",
            "The learning rule is consistent with spike timing dependent plasticity.",
            "So presynaptic spike followed by a postsynaptic spike leads to potentiation and we get depression otherwise.",
            "From a machine learning perspective, the learning rule can be seen as an implementation of the EM algorithm with important sampling it in the expectation step.",
            "The global factor plays the role of the importance weight.",
            "It is worthwhile to notice that our learning rule not only implements a nontrivial machine learning task, but also does it in a biologically realistic way."
        ],
        [
            "Here we show a very simple example of our learning rule with the Delta target distribution containing this V pattern.",
            "The other panels show an overlay of 20 recalls after training different systems.",
            "With only visible units and either as simple as symmetric help rule or our learning rule applied to only visible units, we cannot learn the sequence.",
            "With hidden units but only read out learning, which is some sort of reservoir computing.",
            "The sequence also cannot be learned properly.",
            "We can learn the sequence perfectly with hidden units and learning all the synaptic weights with our learning rule.",
            "To summarize, we need hidden units.",
            "We need to train only to learn all the synaptic weights.",
            "And there is a nice biologically realistic learning rule to learn interesting sequences.",
            "So the hidden units today on stage Volta Cynanchum Pascal Fister.",
            "If you're interested in more details, you'll find our post Red T 19 thanks for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will nervous system has an amazing capability to learn complex sequences like the sequence of movements required to learn a song on the violin.",
                    "label": 0
                },
                {
                    "sent": "In this study, we want to convince you that we can build a network of spiking neurons with hidden units and.",
                    "label": 1
                },
                {
                    "sent": "A nice biologically realistic learning rule to learn interesting sequences.",
                    "label": 0
                },
                {
                    "sent": "We used are.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The current network of stochastic spiking neurons.",
                    "label": 0
                },
                {
                    "sent": "This network produces spatial temporal spike patterns.",
                    "label": 0
                },
                {
                    "sent": "During learning, the visible neurons are claimed to sample sequences of the target distribution.",
                    "label": 1
                },
                {
                    "sent": "The model shall adapt its parameters.",
                    "label": 1
                },
                {
                    "sent": "For example, the synaptic weights such that the model distribution approaches the target distribution over learning with only visible units.",
                    "label": 0
                },
                {
                    "sent": "This system can learn only boring sequences.",
                    "label": 1
                },
                {
                    "sent": "Including hidden units, things become more interesting, but the learning task also becomes more challenging.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in contrast to the Boltzmann machine that also uses hidden units but postulates the Boltzmann distribution, we started with the definition of the neuronal dynamics.",
                    "label": 0
                },
                {
                    "sent": "We use the stochastic spike Response Model, also known as generalized linear model.",
                    "label": 1
                },
                {
                    "sent": "This defines our model distribution with this model distribution we arrived as stochastic gradient descent learning rule on the kupec liable divergance from target to model distribution.",
                    "label": 0
                },
                {
                    "sent": "Even though things tend to be more complicated with hidden units, we were excited to find a nice learning rule.",
                    "label": 0
                },
                {
                    "sent": "It consists of a pre term and the post term local and a modulating global factor.",
                    "label": 0
                },
                {
                    "sent": "We also showed that an online approximation exists.",
                    "label": 0
                },
                {
                    "sent": "The learning rule is consistent with spike timing dependent plasticity.",
                    "label": 0
                },
                {
                    "sent": "So presynaptic spike followed by a postsynaptic spike leads to potentiation and we get depression otherwise.",
                    "label": 0
                },
                {
                    "sent": "From a machine learning perspective, the learning rule can be seen as an implementation of the EM algorithm with important sampling it in the expectation step.",
                    "label": 0
                },
                {
                    "sent": "The global factor plays the role of the importance weight.",
                    "label": 0
                },
                {
                    "sent": "It is worthwhile to notice that our learning rule not only implements a nontrivial machine learning task, but also does it in a biologically realistic way.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here we show a very simple example of our learning rule with the Delta target distribution containing this V pattern.",
                    "label": 0
                },
                {
                    "sent": "The other panels show an overlay of 20 recalls after training different systems.",
                    "label": 1
                },
                {
                    "sent": "With only visible units and either as simple as symmetric help rule or our learning rule applied to only visible units, we cannot learn the sequence.",
                    "label": 1
                },
                {
                    "sent": "With hidden units but only read out learning, which is some sort of reservoir computing.",
                    "label": 0
                },
                {
                    "sent": "The sequence also cannot be learned properly.",
                    "label": 0
                },
                {
                    "sent": "We can learn the sequence perfectly with hidden units and learning all the synaptic weights with our learning rule.",
                    "label": 0
                },
                {
                    "sent": "To summarize, we need hidden units.",
                    "label": 0
                },
                {
                    "sent": "We need to train only to learn all the synaptic weights.",
                    "label": 0
                },
                {
                    "sent": "And there is a nice biologically realistic learning rule to learn interesting sequences.",
                    "label": 0
                },
                {
                    "sent": "So the hidden units today on stage Volta Cynanchum Pascal Fister.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in more details, you'll find our post Red T 19 thanks for your attention.",
                    "label": 0
                }
            ]
        }
    }
}