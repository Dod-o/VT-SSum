{
    "id": "msgb6o6eofap27gvyf6ajgrgbop2v53d",
    "title": "Box Drawings for Learning with Imbalanced Data",
    "info": {
        "author": [
            "Siong Thye Goh, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Oct. 8, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Knowledge Extraction",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/kdd2014_thye_goh_imbalanced_data/",
    "segmentation": [
        [
            "My name is Sam Tiger and this is the training what with my advisers into routine.",
            "We sitting over there.",
            "I'm going to be talking about a firm classifier that we call box drawings which are kind of logical classifier."
        ],
        [
            "Think of a massively imbalanced classification problems.",
            "We have a few positive examples, floating aceo negative examples.",
            "This is really common, for instance when you want to investigate when machine break and most of your data are from machines that are working.",
            "We are building blocks from classifiers for imbalance problems.",
            "They are made from a union or access parallel rectangles.",
            "And we want it to be accessed by alert because it helps with interpretability.",
            "These are not black box classifiers.",
            "People can really see inside these classifiers."
        ],
        [
            "The usual way to do this is by using this country, which is top down greedy.",
            "We can also use the pre method which greedily peels off subset of data, but this is too greedy for us.",
            "And it has other problems that I will tell you about."
        ],
        [
            "In fact, great list is to be answers.",
            "It is often hard to get anything except your model that always predicts the majority class, and that means that our classifier might say that are princesses havoc in waste.",
            "An Princess Fiona from Shrek, and we don't want that to happen.",
            "This is true even if you fed up with like crazy with algorithms parameter an, since we are interested in the minority class.",
            "Why don't we protect them?",
            "If you're truly interested in the minority class, we should give them more priority.",
            "We're going to do this by putting them in the boxes."
        ],
        [
            "So we propose two approaches.",
            "The first is called the exact boxes which optimized with accuracy, annex regularised by the number of boxes.",
            "Is formula based on MIP?",
            "Ann is useful for not huge problems.",
            "An itself isn't the problem that we care about.",
            "And XS go standard compared with the cause itself is actually the problem that we want.",
            "The second approach is called fast boxes, which is an approximation method to the boxes.",
            "Ann, you first characterize the minority class before we perform discrimination.",
            "Anne.",
            "The first approach doesn't require any additional assumption, but the second approach requires a condition that is, the features have to be continuous."
        ],
        [
            "OK, now let's move onto is about this algorithm.",
            "It's algorithm that will create box drawing classifiers.",
            "We consider minority class minority datapoint to correctly classify every section in at least one box.",
            "Animosity and majority example is correct is correctly classified.",
            "It doesn't recite any box.",
            "That after the set of union of excess polar rectangles, this is the objective function of pizza boxes.",
            "The first term is accuracy.",
            "For the past examples, the second term is accuracy.",
            "For the negative examples and the last term is for regularising the number of boxes."
        ],
        [
            "This is formulation for exam boxes.",
            "I'm not going to go into detail here."
        ],
        [
            "But the main point is that this equation are linear.",
            "They all they all work together in a linear way to find optimal sets of boxes.",
            "Because they're all linear, we can solve this for not huge problems and get a ghost and classifier.",
            "Selling both pass and accurate, and we can compare other matters to the results to determine how optimally are."
        ],
        [
            "And then you get solution like this.",
            "Where there are few boxes perfectly placed around the positive examples."
        ],
        [
            "And now let's move onto 1st boxes."
        ],
        [
            "First boxes consists of three main stages.",
            "The first stage is a clustering stage where we characterize the positive data."
        ],
        [
            "This is basically K means.",
            "Assume continuous features.",
            "The second stage is called Dividing Space Stage which decide which point will influence each boundary.",
            "An the last stages, boundary extension stage that expand each box to give priority to the positive data."
        ],
        [
            "In dividing space stage, each boundary is determined by 1 dimensional supervised learning using data close to the boundary.",
            "We have an optical solution for each division boundary.",
            "The calculation is really nice.",
            "Each region boundary can be done in parallel.",
            "The diagram shows that to decide the final location of the boundary, we only use the points that lies in the region that are shaded.",
            "You can do clustering on a big scale.",
            "Then this method can scale to large datasets becausw you can just pass one division boundary to each processor."
        ],
        [
            "At the boundary expansion stage, we push division boundary for each box outwards as a form of regularization.",
            "This is that is also a final option.",
            "Push to almost the next negative point.",
            "The solution is still analytical.",
            "This is because we use an exponential loss.",
            "To do it, we introduce a weighting factor that gives a negative data less priority.",
            "We also penalized points that diagonally away from the corner edge."
        ],
        [
            "And this is a summary of all algorithm.",
            "So we first number the features to be between minus one and one.",
            "And then we cluster the minor minority data into K clusters, taking center division into consideration.",
            "And we construct the minimum enclosing box for each clusters and pick which day to participate in each division boundary calculation.",
            "We compute division boundaries analytically and separately.",
            "And we perform an expansion.",
            "If you want an.",
            "Finally, a normalized by rescaling this feature spec."
        ],
        [
            "And then we conduct some experiments."
        ],
        [
            "Then we compare them with some algorithms such as logistic regression, SVM, Random Forest at the booth, and some distant trees model."
        ],
        [
            "OK. OK, is often but not always, want the best performer.",
            "However, solution is often more interpretable."
        ],
        [
            "In the paper we have one of these big comparison tables with a whole lot of datasets and a lot of algorithms.",
            "And a table basically shows two points first.",
            "OK. That the first boxes has capability to produce very complex models just as complex as SVM.",
            "So we're not losing in terms of accuracy, respect to the other methods.",
            "The accuracy is good.",
            "But the really nice thing is that the fact that we are restricted producing interpretable models doesn't seem to be hurting us.",
            "That's a really nice part.",
            "We don't have to sacrifice accuracy for interpretability."
        ],
        [
            "If you try to get them in fast boxes works better.",
            "We notice something really obvious but important."
        ],
        [
            "Intuitively, it the class is more imbalanced, the positive data tend to cluster together, enhance our assumption, tends to hold.",
            "Each dot on the plot represent the ranking of our algorithm for particle data set.",
            "Lower ranking represents that our method is better.",
            "We can see a rough trend that as imbalanced ratio increases, the ranking decreases, which means we do better."
        ],
        [
            "Now, what about the boxes method is very good.",
            "It's either the top or second top performer for the data set, try.",
            "The message that we get this set restricting the algorithm to produce about scrolling classifier does not generally seems to hinder performance.",
            "But well, selecting optimal K for easy boxes is difficult, so we use the kitchen by cross validation in our first boxes algorithm and then apply it in the box method."
        ],
        [
            "To wrap up, we have proposed two methods for producing.",
            "Box problem classifiers.",
            "He said boxes and fast boxes.",
            "And the takeaway is that we can infer both interpret ability and accuracy.",
            "You should not assume that you need to sacrifice one to get the other.",
            "You can very often get both."
        ],
        [
            "Anne, thank you for listening."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Sam Tiger and this is the training what with my advisers into routine.",
                    "label": 0
                },
                {
                    "sent": "We sitting over there.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be talking about a firm classifier that we call box drawings which are kind of logical classifier.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Think of a massively imbalanced classification problems.",
                    "label": 1
                },
                {
                    "sent": "We have a few positive examples, floating aceo negative examples.",
                    "label": 1
                },
                {
                    "sent": "This is really common, for instance when you want to investigate when machine break and most of your data are from machines that are working.",
                    "label": 0
                },
                {
                    "sent": "We are building blocks from classifiers for imbalance problems.",
                    "label": 0
                },
                {
                    "sent": "They are made from a union or access parallel rectangles.",
                    "label": 0
                },
                {
                    "sent": "And we want it to be accessed by alert because it helps with interpretability.",
                    "label": 0
                },
                {
                    "sent": "These are not black box classifiers.",
                    "label": 0
                },
                {
                    "sent": "People can really see inside these classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The usual way to do this is by using this country, which is top down greedy.",
                    "label": 1
                },
                {
                    "sent": "We can also use the pre method which greedily peels off subset of data, but this is too greedy for us.",
                    "label": 0
                },
                {
                    "sent": "And it has other problems that I will tell you about.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In fact, great list is to be answers.",
                    "label": 0
                },
                {
                    "sent": "It is often hard to get anything except your model that always predicts the majority class, and that means that our classifier might say that are princesses havoc in waste.",
                    "label": 1
                },
                {
                    "sent": "An Princess Fiona from Shrek, and we don't want that to happen.",
                    "label": 1
                },
                {
                    "sent": "This is true even if you fed up with like crazy with algorithms parameter an, since we are interested in the minority class.",
                    "label": 1
                },
                {
                    "sent": "Why don't we protect them?",
                    "label": 0
                },
                {
                    "sent": "If you're truly interested in the minority class, we should give them more priority.",
                    "label": 0
                },
                {
                    "sent": "We're going to do this by putting them in the boxes.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we propose two approaches.",
                    "label": 0
                },
                {
                    "sent": "The first is called the exact boxes which optimized with accuracy, annex regularised by the number of boxes.",
                    "label": 1
                },
                {
                    "sent": "Is formula based on MIP?",
                    "label": 1
                },
                {
                    "sent": "Ann is useful for not huge problems.",
                    "label": 1
                },
                {
                    "sent": "An itself isn't the problem that we care about.",
                    "label": 0
                },
                {
                    "sent": "And XS go standard compared with the cause itself is actually the problem that we want.",
                    "label": 0
                },
                {
                    "sent": "The second approach is called fast boxes, which is an approximation method to the boxes.",
                    "label": 0
                },
                {
                    "sent": "Ann, you first characterize the minority class before we perform discrimination.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The first approach doesn't require any additional assumption, but the second approach requires a condition that is, the features have to be continuous.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now let's move onto is about this algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's algorithm that will create box drawing classifiers.",
                    "label": 1
                },
                {
                    "sent": "We consider minority class minority datapoint to correctly classify every section in at least one box.",
                    "label": 0
                },
                {
                    "sent": "Animosity and majority example is correct is correctly classified.",
                    "label": 1
                },
                {
                    "sent": "It doesn't recite any box.",
                    "label": 0
                },
                {
                    "sent": "That after the set of union of excess polar rectangles, this is the objective function of pizza boxes.",
                    "label": 1
                },
                {
                    "sent": "The first term is accuracy.",
                    "label": 0
                },
                {
                    "sent": "For the past examples, the second term is accuracy.",
                    "label": 0
                },
                {
                    "sent": "For the negative examples and the last term is for regularising the number of boxes.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is formulation for exam boxes.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into detail here.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the main point is that this equation are linear.",
                    "label": 0
                },
                {
                    "sent": "They all they all work together in a linear way to find optimal sets of boxes.",
                    "label": 0
                },
                {
                    "sent": "Because they're all linear, we can solve this for not huge problems and get a ghost and classifier.",
                    "label": 0
                },
                {
                    "sent": "Selling both pass and accurate, and we can compare other matters to the results to determine how optimally are.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you get solution like this.",
                    "label": 0
                },
                {
                    "sent": "Where there are few boxes perfectly placed around the positive examples.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now let's move onto 1st boxes.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First boxes consists of three main stages.",
                    "label": 0
                },
                {
                    "sent": "The first stage is a clustering stage where we characterize the positive data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is basically K means.",
                    "label": 0
                },
                {
                    "sent": "Assume continuous features.",
                    "label": 0
                },
                {
                    "sent": "The second stage is called Dividing Space Stage which decide which point will influence each boundary.",
                    "label": 1
                },
                {
                    "sent": "An the last stages, boundary extension stage that expand each box to give priority to the positive data.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In dividing space stage, each boundary is determined by 1 dimensional supervised learning using data close to the boundary.",
                    "label": 1
                },
                {
                    "sent": "We have an optical solution for each division boundary.",
                    "label": 0
                },
                {
                    "sent": "The calculation is really nice.",
                    "label": 0
                },
                {
                    "sent": "Each region boundary can be done in parallel.",
                    "label": 0
                },
                {
                    "sent": "The diagram shows that to decide the final location of the boundary, we only use the points that lies in the region that are shaded.",
                    "label": 0
                },
                {
                    "sent": "You can do clustering on a big scale.",
                    "label": 0
                },
                {
                    "sent": "Then this method can scale to large datasets becausw you can just pass one division boundary to each processor.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At the boundary expansion stage, we push division boundary for each box outwards as a form of regularization.",
                    "label": 1
                },
                {
                    "sent": "This is that is also a final option.",
                    "label": 1
                },
                {
                    "sent": "Push to almost the next negative point.",
                    "label": 0
                },
                {
                    "sent": "The solution is still analytical.",
                    "label": 0
                },
                {
                    "sent": "This is because we use an exponential loss.",
                    "label": 0
                },
                {
                    "sent": "To do it, we introduce a weighting factor that gives a negative data less priority.",
                    "label": 0
                },
                {
                    "sent": "We also penalized points that diagonally away from the corner edge.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is a summary of all algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we first number the features to be between minus one and one.",
                    "label": 1
                },
                {
                    "sent": "And then we cluster the minor minority data into K clusters, taking center division into consideration.",
                    "label": 1
                },
                {
                    "sent": "And we construct the minimum enclosing box for each clusters and pick which day to participate in each division boundary calculation.",
                    "label": 1
                },
                {
                    "sent": "We compute division boundaries analytically and separately.",
                    "label": 0
                },
                {
                    "sent": "And we perform an expansion.",
                    "label": 0
                },
                {
                    "sent": "If you want an.",
                    "label": 0
                },
                {
                    "sent": "Finally, a normalized by rescaling this feature spec.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we conduct some experiments.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we compare them with some algorithms such as logistic regression, SVM, Random Forest at the booth, and some distant trees model.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. OK, is often but not always, want the best performer.",
                    "label": 0
                },
                {
                    "sent": "However, solution is often more interpretable.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the paper we have one of these big comparison tables with a whole lot of datasets and a lot of algorithms.",
                    "label": 0
                },
                {
                    "sent": "And a table basically shows two points first.",
                    "label": 0
                },
                {
                    "sent": "OK. That the first boxes has capability to produce very complex models just as complex as SVM.",
                    "label": 1
                },
                {
                    "sent": "So we're not losing in terms of accuracy, respect to the other methods.",
                    "label": 0
                },
                {
                    "sent": "The accuracy is good.",
                    "label": 0
                },
                {
                    "sent": "But the really nice thing is that the fact that we are restricted producing interpretable models doesn't seem to be hurting us.",
                    "label": 0
                },
                {
                    "sent": "That's a really nice part.",
                    "label": 0
                },
                {
                    "sent": "We don't have to sacrifice accuracy for interpretability.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you try to get them in fast boxes works better.",
                    "label": 0
                },
                {
                    "sent": "We notice something really obvious but important.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Intuitively, it the class is more imbalanced, the positive data tend to cluster together, enhance our assumption, tends to hold.",
                    "label": 0
                },
                {
                    "sent": "Each dot on the plot represent the ranking of our algorithm for particle data set.",
                    "label": 0
                },
                {
                    "sent": "Lower ranking represents that our method is better.",
                    "label": 0
                },
                {
                    "sent": "We can see a rough trend that as imbalanced ratio increases, the ranking decreases, which means we do better.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, what about the boxes method is very good.",
                    "label": 0
                },
                {
                    "sent": "It's either the top or second top performer for the data set, try.",
                    "label": 0
                },
                {
                    "sent": "The message that we get this set restricting the algorithm to produce about scrolling classifier does not generally seems to hinder performance.",
                    "label": 1
                },
                {
                    "sent": "But well, selecting optimal K for easy boxes is difficult, so we use the kitchen by cross validation in our first boxes algorithm and then apply it in the box method.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To wrap up, we have proposed two methods for producing.",
                    "label": 0
                },
                {
                    "sent": "Box problem classifiers.",
                    "label": 0
                },
                {
                    "sent": "He said boxes and fast boxes.",
                    "label": 0
                },
                {
                    "sent": "And the takeaway is that we can infer both interpret ability and accuracy.",
                    "label": 0
                },
                {
                    "sent": "You should not assume that you need to sacrifice one to get the other.",
                    "label": 0
                },
                {
                    "sent": "You can very often get both.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne, thank you for listening.",
                    "label": 0
                }
            ]
        }
    }
}