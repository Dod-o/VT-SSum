{
    "id": "vq74ucbdpgmxa4m4alkdbm6fzhgg2igs",
    "title": "A matrix product algorithm for the far-from-equilibrium evolution of dynamical processes on networks",
    "info": {
        "author": [
            "Caterina De Bacco, University of Paris-Sud 11"
        ],
        "published": "March 7, 2016",
        "recorded": "December 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Physics->Statistical Physics"
        ]
    },
    "url": "http://videolectures.net/netadis2015_de_bacco_dynamical_processes/",
    "segmentation": [
        [
            "Good morning everybody.",
            "Thanks the organizer for inviting me.",
            "I want to talk to you about the work that I've been doing with my supervisor, schedule France Aran collaborator Thomas Bartell at University Parachute.",
            "During my PhD.",
            "We were interesting to describe the far from equilibrium dynamic of dynamical process on a network, so the idea is that you have a network and you have some variables attached to each node.",
            "For instance, here they can take.",
            "Red or black values and these values evolve in time.",
            "So for instance, you start here with a random combination of red and black and the way they evolve in time is described by probability transition.",
            "That is WA function that we assume being Markovian.",
            "So this W is a function of the state of the neighborhood of that considering node at a previous time step.",
            "So you can have a generic dynamic so we didn't specify anything about this W. So Red can turn into a block, block into and into red and vice versa and whatever.",
            "So suppose you start with this initial condition."
        ],
        [
            "You have all at the next time step, some red have become black, some later become red and some app staying the same."
        ],
        [
            "You keep evolving.",
            "Anne."
        ],
        [
            "Eventually you may ask some questions about these dynamics, for instance when relevant question is.",
            "At a later time step, what is the probability that the old network is red or black?",
            "Or you can ask questions such as what is the probability that a given node has that particular value, say red at the given time step in the future.",
            "So regardless whether you are in a stationary point, in stationary point, you are in equilibrium.",
            "We make no assumption about that, so we're interested to describe the entire dynamic.",
            "So the far from equilibrium.",
            "Then on."
        ],
        [
            "So ideally to answer all those questions, you would access the joint probability distribution of an entire ensemble of North nodes, and each of these variables is a time trajectory of length capital T. So accessing this quantity actually is practically impossible because it an exponential complexity both in the number of nodes and in the duration of your process."
        ],
        [
            "So the idea is to find a suitable approximation method to tackle at least approximately this problem.",
            "So 1 first reduction is to introduce approximation, that is, that is been proven quite successful in the in analyzing the static case, and this is the cavity method.",
            "So the first approximation we introduce is to use to work with two variable function to neighboring variable function that are these mu IJ that are function of the trajectory up to 20 of a given node Ann.",
            "The trajectory at a previous up to the previous time step of one of his neighbors, and these are called usually messages because the cavity method usually allows an algorithmic implementation in terms of message passing algorithm.",
            "So the idea of making this first step."
        ],
        [
            "Is that actually the dynamic Abbott equation allows you to tackle to reduce the complexity, at least in the number of nodes?"
        ],
        [
            "The problem is that we still have a complexity in time because this message is this function, our function of an entire trying trajectory.",
            "So there are an exponential number of them exponentially in T. So how?"
        ],
        [
            "Our idea is to represent these messages as.",
            "Matrix product representation.",
            "So the idea is that instead of working with this general function.",
            "We suppose that this function can be parameterized effectively as a product of matrices.",
            "So why do we do that?",
            "Well, we tried to make an analogy with what has been done successfully in another context of physics, mainly in quantum many particle physics where you have many particle interacting with them and you want to find the ground state of the Hamiltonian.",
            "In that case, you have complexity in space because they are strongly interactive.",
            "But they successfully find good approximation of these ground state by parameterising the state function of the miltonia as a matrix product like we do.",
            "So basically the idea is that we instead have a complexity that is in time instead of in space.",
            "But the problem there parameter is parameterization is a similar shape.",
            "So at the moment is just a reparameterization in answers that we tried so at the moment the equation as it is, as still the exponential complexity.",
            "So how to reduce it?"
        ],
        [
            "We exploit the technique of linear algebra that is quite a general technique is called singular value decomposition and this allows you to split each of the matrices appearing in this product as a product of three matrices that have some properties.",
            "Anne.",
            "Order one of these three matrices that is diagonal as four entries singular values you order in decreasing order.",
            "This singular values and then you neglect the smallest one.",
            "So basically you truncate the dimension of your matrices appearing this product in a controlled way because you have to see the singular values as containing the information so the biggest singular values contain the most important information.",
            "If you want to put it qualitative so there is, then to reduce.",
            "The complexity from exponential to polynomial, by performing this truncation."
        ],
        [
            "So these other problem can be tackled in this way with a control truncation that depends on the type of truncation criteria that you decide to fix."
        ],
        [
            "So just to give you a sketch of how the algorithm works, you can actually implement it as a message passing algorithm.",
            "So you basically input as the answer to initialize randomly your matrix.",
            "Here, matrices at the first time step they're just numbers and then their dimension grows with time, but in a controlled way depending on what you decide to fix as a truncation.",
            "So you fix for this message passing iteration the 1st.",
            "The answers you have for for the matrices and then you update inserting the given probability transition that you decide, and then in output it will give you a new set of matrices and you continue this one until you want to find some observable and calculate marginal for instance."
        ],
        [
            "So if you want to know more about that, please take a look to the paper we uploaded online in the next week.",
            "So I think we will put a new version with the numerical results.",
            "So at the moment you have the theory few numerical results, but in the future we will add more so.",
            "Yeah, so if you have any question I will be here during the workshop so."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "Thanks the organizer for inviting me.",
                    "label": 0
                },
                {
                    "sent": "I want to talk to you about the work that I've been doing with my supervisor, schedule France Aran collaborator Thomas Bartell at University Parachute.",
                    "label": 0
                },
                {
                    "sent": "During my PhD.",
                    "label": 0
                },
                {
                    "sent": "We were interesting to describe the far from equilibrium dynamic of dynamical process on a network, so the idea is that you have a network and you have some variables attached to each node.",
                    "label": 0
                },
                {
                    "sent": "For instance, here they can take.",
                    "label": 0
                },
                {
                    "sent": "Red or black values and these values evolve in time.",
                    "label": 0
                },
                {
                    "sent": "So for instance, you start here with a random combination of red and black and the way they evolve in time is described by probability transition.",
                    "label": 0
                },
                {
                    "sent": "That is WA function that we assume being Markovian.",
                    "label": 0
                },
                {
                    "sent": "So this W is a function of the state of the neighborhood of that considering node at a previous time step.",
                    "label": 0
                },
                {
                    "sent": "So you can have a generic dynamic so we didn't specify anything about this W. So Red can turn into a block, block into and into red and vice versa and whatever.",
                    "label": 0
                },
                {
                    "sent": "So suppose you start with this initial condition.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have all at the next time step, some red have become black, some later become red and some app staying the same.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You keep evolving.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eventually you may ask some questions about these dynamics, for instance when relevant question is.",
                    "label": 0
                },
                {
                    "sent": "At a later time step, what is the probability that the old network is red or black?",
                    "label": 0
                },
                {
                    "sent": "Or you can ask questions such as what is the probability that a given node has that particular value, say red at the given time step in the future.",
                    "label": 0
                },
                {
                    "sent": "So regardless whether you are in a stationary point, in stationary point, you are in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "We make no assumption about that, so we're interested to describe the entire dynamic.",
                    "label": 0
                },
                {
                    "sent": "So the far from equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Then on.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So ideally to answer all those questions, you would access the joint probability distribution of an entire ensemble of North nodes, and each of these variables is a time trajectory of length capital T. So accessing this quantity actually is practically impossible because it an exponential complexity both in the number of nodes and in the duration of your process.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is to find a suitable approximation method to tackle at least approximately this problem.",
                    "label": 0
                },
                {
                    "sent": "So 1 first reduction is to introduce approximation, that is, that is been proven quite successful in the in analyzing the static case, and this is the cavity method.",
                    "label": 0
                },
                {
                    "sent": "So the first approximation we introduce is to use to work with two variable function to neighboring variable function that are these mu IJ that are function of the trajectory up to 20 of a given node Ann.",
                    "label": 0
                },
                {
                    "sent": "The trajectory at a previous up to the previous time step of one of his neighbors, and these are called usually messages because the cavity method usually allows an algorithmic implementation in terms of message passing algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the idea of making this first step.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that actually the dynamic Abbott equation allows you to tackle to reduce the complexity, at least in the number of nodes?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is that we still have a complexity in time because this message is this function, our function of an entire trying trajectory.",
                    "label": 0
                },
                {
                    "sent": "So there are an exponential number of them exponentially in T. So how?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our idea is to represent these messages as.",
                    "label": 0
                },
                {
                    "sent": "Matrix product representation.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that instead of working with this general function.",
                    "label": 0
                },
                {
                    "sent": "We suppose that this function can be parameterized effectively as a product of matrices.",
                    "label": 0
                },
                {
                    "sent": "So why do we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, we tried to make an analogy with what has been done successfully in another context of physics, mainly in quantum many particle physics where you have many particle interacting with them and you want to find the ground state of the Hamiltonian.",
                    "label": 0
                },
                {
                    "sent": "In that case, you have complexity in space because they are strongly interactive.",
                    "label": 1
                },
                {
                    "sent": "But they successfully find good approximation of these ground state by parameterising the state function of the miltonia as a matrix product like we do.",
                    "label": 0
                },
                {
                    "sent": "So basically the idea is that we instead have a complexity that is in time instead of in space.",
                    "label": 0
                },
                {
                    "sent": "But the problem there parameter is parameterization is a similar shape.",
                    "label": 0
                },
                {
                    "sent": "So at the moment is just a reparameterization in answers that we tried so at the moment the equation as it is, as still the exponential complexity.",
                    "label": 0
                },
                {
                    "sent": "So how to reduce it?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We exploit the technique of linear algebra that is quite a general technique is called singular value decomposition and this allows you to split each of the matrices appearing in this product as a product of three matrices that have some properties.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Order one of these three matrices that is diagonal as four entries singular values you order in decreasing order.",
                    "label": 0
                },
                {
                    "sent": "This singular values and then you neglect the smallest one.",
                    "label": 0
                },
                {
                    "sent": "So basically you truncate the dimension of your matrices appearing this product in a controlled way because you have to see the singular values as containing the information so the biggest singular values contain the most important information.",
                    "label": 0
                },
                {
                    "sent": "If you want to put it qualitative so there is, then to reduce.",
                    "label": 0
                },
                {
                    "sent": "The complexity from exponential to polynomial, by performing this truncation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these other problem can be tackled in this way with a control truncation that depends on the type of truncation criteria that you decide to fix.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to give you a sketch of how the algorithm works, you can actually implement it as a message passing algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you basically input as the answer to initialize randomly your matrix.",
                    "label": 0
                },
                {
                    "sent": "Here, matrices at the first time step they're just numbers and then their dimension grows with time, but in a controlled way depending on what you decide to fix as a truncation.",
                    "label": 0
                },
                {
                    "sent": "So you fix for this message passing iteration the 1st.",
                    "label": 0
                },
                {
                    "sent": "The answers you have for for the matrices and then you update inserting the given probability transition that you decide, and then in output it will give you a new set of matrices and you continue this one until you want to find some observable and calculate marginal for instance.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you want to know more about that, please take a look to the paper we uploaded online in the next week.",
                    "label": 0
                },
                {
                    "sent": "So I think we will put a new version with the numerical results.",
                    "label": 0
                },
                {
                    "sent": "So at the moment you have the theory few numerical results, but in the future we will add more so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if you have any question I will be here during the workshop so.",
                    "label": 0
                }
            ]
        }
    }
}