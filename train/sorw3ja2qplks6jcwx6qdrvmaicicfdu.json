{
    "id": "sorw3ja2qplks6jcwx6qdrvmaicicfdu",
    "title": "VLX-Stories: building an online Event Knowledge Base with Emerging Entity detection",
    "info": {
        "author": [
            "D\u00e8lia Fern\u00e1ndez, UPC- BARCELONA TECH"
        ],
        "published": "Dec. 10, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_fernandez_vlx_stories/",
    "segmentation": [
        [
            "OK so I will present the Linksys stories which is an online event knowledge base that it's currently in use and deployed in production and being used in many countries.",
            "So let's start."
        ],
        [
            "So."
        ],
        [
            "Basically, the way in which people consume news has been changing during the last years, so online news is currently the main source of information for a lot of people, and this also made the weighing with media publishers and journalists have to search for information and be aware of what is trending right now.",
            "This has been changing right?",
            "So there are tools like for example."
        ],
        [
            "Nails or Yahoo nails.",
            "Which gate news and help navigate.",
            "But these tools doesn't have advanced Ann."
        ],
        [
            "Gun stores to.",
            "Anne.",
            "To help journey."
        ],
        [
            "At least an media publishers.",
            "So we need better tools that help not only aggregate and navigate, but also search the structure, summarize and relate different news events solo."
        ],
        [
            "It's a star.",
            "Here we propose while we explain Billings stories, which is an end to end pipeline that transforms, you know structured data from news feeds to an instructor knowledge representation, which is answering the main journalistic questions of The Who, what, where and when.",
            "So in this framework we define an event and as aggregation of at least five news articles describing the same story."
        ],
        [
            "So we split the pipeline in two main parts, first one consisting of an detection, which would be something similar as Google News which aggregates different news articles and then the second part is when representation where we try to understand the main entities behind an event Anna structure this information."
        ],
        [
            "So that's an overview of the pipeline.",
            "I distinguish these two main parts, first one from our fits crawler with the articles, and then we represented Charticle as a vector and we cluster this information and then once we have this class tickle cluster representing events, we extract the information about the entities that are describing this event.",
            "Anna structure it in an event ontology.",
            "So for that we disambiguate the mentions of entities using a knowledge graph which is."
        ],
        [
            "Billings knowledge graph.",
            "That's the knowledge graph of the company Billings, which is currently it currently has around 3 million entities, an 30 million RDF triples and it's multilingual.",
            "It currently has 11 languages, so this knowledge Graph was initially populated with data from wiki data, Wikipedia infoboxes and also freeways an.",
            "It's also growing as I will explain with emerging entities that are detected with feelings of stories.",
            "So here we have an example or more or less the information you may find for an entity like NYC."
        ],
        [
            "So well, I will structure the next steps of The Dalles, focusing first on event detection.",
            "Then I want representation, and I will continue with some analytics on the system.",
            "The usage and conclusions."
        ],
        [
            "So, well, first event detection I will go with step or step in the pipeline."
        ],
        [
            "So first we have the news feeds growler, so from a manually generated list of over 4000 errors fits week struck the particles.",
            "These fields belong to 7 countries.",
            "An notice that these countries are also multilingual, so we have for example United States but also Spain and Portugal.",
            "So category is manually assigned to its feet.",
            "This categories like Sports, politics, entertainment etc.",
            "And this system is crawling over 3000 feeds an hour.",
            "So this way we have like current articles."
        ],
        [
            "During the system in real time, then for each article we parse it and we extract the title, description and the full text Ann.",
            "Using NLP techniques, we extract the name entities COM announce an non chunks.",
            "So then we do artikkel feature vector representation using lack of works alike approach.",
            "But instead of using all the words in the text we use these keywords as has been proven before, it's more effective to in order to classify news articles.",
            "And also each one of the keywords has a weight within a score.",
            "That is, is buying the TF IDF.",
            "But we also give more weights to those keywords appearing in the title and description and also the whole vector has a time factor applied which favors newest documents were articles to be clustered together.",
            "So."
        ],
        [
            "Once we have or vector representation, we have to cluster them.",
            "So first we have the task of tracking.",
            "So we want to know if the article that it's incoming the system belongs to an already detected event.",
            "If it is the case it is clustered together and we do that.",
            "With Canadians.",
            "Never an if it's not.",
            "We put together all the articles that are not cluster.",
            "In any event an with DB scan with deck.",
            "New incoming events.",
            "So basically we would have a lot of news and the output of it."
        ],
        [
            "Is a cluster with those articles talking about the same story?",
            "So."
        ],
        [
            "We wanted to evaluate this first part, which is the topic detection and tracking park.",
            "To do that we use the UCI news aggregator data set, but notice that we couldn't use the whole data set because many articling URLs were broken and also because over definition definition of event requires for at least five particles to be clustering the same event.",
            "We had to discuss some events, so after this we evaluated the system an.",
            "Notice that we have precision detecting events of the 81% and we prior precision over recall.",
            "Recall in the sense that we have a high artikkel precision when assigning it to clusters, but the records should be improved as many articles are not classified into an event."
        ],
        [
            "So second part is the event representation where we try to detect the main agents and locations involved in the event.",
            "An instructor this information."
        ],
        [
            "So well, first part at tries to extract those main entities which represent the event.",
            "This is done with pattern instruction approach that was inspired in the work by Lee Hanzi.",
            "So for example, from this news, from the Zakim Boran Facebook case, will struck the.",
            "These entities, well, this mentions of entities that we see here and then we want."
        ],
        [
            "To map.",
            "This store entities so we link it to entities in our Knowledge Graph, but notice that many times.",
            "We find any mentions of entities that don't have entities in the Knowledge Graph, so this is a very common thing when dealing with news."
        ],
        [
            "So we had to add some dynamics in order to add these entities in our knowledge base so well."
        ],
        [
            "We had these emerging entity detector which currently at the text merging entities belonging to people.",
            "So we have a set of filters in order to select those.",
            "Aging ended this and then."
        ],
        [
            "We struck the event semantic pattern, but notice that these entities are still not structure."
        ],
        [
            "So we design ontology inspire in the journalistic WS which tries to answer The Who, what, where and what of each event.",
            "So we select those entities that are of type people organization at as the main involved subjects which are answering the whole and it is of type.",
            "Location are answering the where then to answer the what right now we select one of the titles among.",
            "All the articles in the cluster.",
            "To to answer this and the when is answer with the date of the first article detected in the event.",
            "Also entities of type event are classified as the topic an.",
            "We use the fit categories to assign a category to the event and also like context and the semantic pattern is also keep.",
            "So articles would be would be giving us additional context on the event."
        ],
        [
            "So for example, for the example we have here.",
            "This."
        ],
        [
            "OK, so we wanted to evaluate a day capabilities to detect emerging entities of our system.",
            "So to do that we selected a set of events that were that had already been detected by your system.",
            "So we have over 600 bands.",
            "We also wanted to test their multilingual capabilities, that's why we pick events from different countries with different languages.",
            "So after we pick these events we listed.",
            "All the entities detected describing these events, and we raised those representing people of Thai people.",
            "And then we check if redoing all the even representation part the system was capable of creating again the entity of this person and we see that a 778% is detected again.",
            "So."
        ],
        [
            "So finally some system analytics.",
            "And well, as I was saying, this system is currently deployed in production worldwide.",
            "Andwith attacked an average of over 300 events a day an we classify into clustering more than 70,000 eleven articles.",
            "So this will this has been deployed for over a year."
        ],
        [
            "Ann, also we evaluated the capacities of emerging entity detection, so we have an average of 67 emerging entities being detected every day and then after like doing some validation of the correctness of these entities, we see that 75% of these entities are really new entities.",
            "At 22% are olias of entities that were already in our knowledge graph an around the 10% are errors due to the name entity recognition system."
        ],
        [
            "So well, maybe some of you so Monday or demo.",
            "We were displaying the dashboard interface that we used to display the ontology information.",
            "So."
        ],
        [
            "If you notice here we have all the main parse answering The Who, what, where, also the category context, semantic pattern and also some graph which helps knowing the social impact and how the story is evolving.",
            "Anne."
        ],
        [
            "And well, in the product application we mix the events information with trends.",
            "So we have an external system that it scrolling Twitter and Google search and we compute an escort to know which entities are more relevant on real time.",
            "And we make this information with the number of articles being published.",
            "So we compute trending score for its event an also.",
            "So our customers are in general media publishers, so they we know which which are the articles that they are publishing and we mix this information so they also know how the competence is reporting the same event or which information they should be sharing on Twitter, Facebook in order to have more impact.",
            "So if anyone is interested I can show you or dashboard later well also.",
            "All this information is returned with API calls to our customers.",
            "That and they integrate it to their systems."
        ],
        [
            "So, well, we generate the tool that fulfills the needed that we say at the beginning it aggregates.",
            "It helps navigate and search among events.",
            "It also structures event information giving a summary that answers The Who, what, where and helps relate news.",
            "And so the main contributions of the system is the new generation of any ban knowledge base with emerging entity detection capabilities and the large scale deployment of the system.",
            "So in future work we plan to add more countries into the system.",
            "As it is a multilingual system, we actually have already done and see if you saw the demo instead of seven countries.",
            "We currently have 20 countries already an.",
            "Also we are working on extracting triple information from the events in order to describe the actions involved in the event an we also working on improving the recall on event detection.",
            "So."
        ],
        [
            "That's all, thank you.",
            "Question.",
            "So we added this American candy is required.",
            "At least entities already exist in other knowledge grows.",
            "So I missed the beginning, sorry.",
            "Emerging in division in footwear that these entities already exist.",
            "So actually our Knowledge Graph also like.",
            "Easy and data or what emerging entities or both, so an experience.",
            "Or maybe it.",
            "You're right, yeah.",
            "Yes, correctly yeah yeah so.",
            "Yeah, you we crawl excellent knowledge basis in order to add the entities that this knowledge base is already have.",
            "And the nice part about this system is that we can also add entities before this.",
            "Also these external knowledge bases have it.",
            "And also.",
            "R. Yeah.",
            "Starts talking then.",
            "Other people are saying.",
            "Yeah, we are not doing that right now.",
            "That would be something very nice to do.",
            "Yes, I'm stuck here.",
            "Load your system with kind of a hypothesis.",
            "Basically.",
            "Why is the weights so that basically you're looking for confirmation or or model of that?",
            "My focus is like for example, yeah.",
            "News events that actually just like that, is that possible overlay?",
            "I think it's very difficult, so we then generate and any band and we run all the entities representing events for Phillip pattern.",
            "So you have to see it in a lot of news in a time window.",
            "So I think it's very difficult to find.",
            "If it's not like everybody is saying the same thing.",
            "I don't know.",
            "Yeah.",
            "Text.",
            "That track they require is that you identified or real astounding in every event and the realities value says whether or not that really happened.",
            "So for example, in stories about March, like.",
            "I would like everything.",
            "Is expected that he will testify at Congress.",
            "And sometimes these events that are written about it never happened before giving the written about because it's afraid if they might happen.",
            "Yeah.",
            "Well, so I think that well in the part we are working right now that we want to suck triples describing really what's going on in the event.",
            "That would be something nice to study.",
            "As you may have contradictions an maybe if you have time stamps, you can say like, OK, these people were saying this may happen, but that's what actually happened.",
            "So maybe in the future we can do that.",
            "And I would have one last question.",
            "You're in which data, for example, you have a large number of events as well, which are precisely described in terms of the what would be well structured is attractive.",
            "Are you aiming to link to that as well?",
            "So can you in your own knowledge graph, which I understand is private.",
            "Yeah, can you still link to so?",
            "Yeah, so if we detect so we are well in wiki data we could like detect an event being reported there an link it.",
            "So for example I don't know we have entities like Brexit that are describing the topic.",
            "And also we crawl Wikipedia current events so when we see new entities describing topics will link it.",
            "So I guess that from Wikipedia current events we could link to wiki data and also struck this information.",
            "We're not exactly doing that, but we could.",
            "Thanks again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I will present the Linksys stories which is an online event knowledge base that it's currently in use and deployed in production and being used in many countries.",
                    "label": 0
                },
                {
                    "sent": "So let's start.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, the way in which people consume news has been changing during the last years, so online news is currently the main source of information for a lot of people, and this also made the weighing with media publishers and journalists have to search for information and be aware of what is trending right now.",
                    "label": 0
                },
                {
                    "sent": "This has been changing right?",
                    "label": 0
                },
                {
                    "sent": "So there are tools like for example.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nails or Yahoo nails.",
                    "label": 0
                },
                {
                    "sent": "Which gate news and help navigate.",
                    "label": 0
                },
                {
                    "sent": "But these tools doesn't have advanced Ann.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gun stores to.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "To help journey.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At least an media publishers.",
                    "label": 0
                },
                {
                    "sent": "So we need better tools that help not only aggregate and navigate, but also search the structure, summarize and relate different news events solo.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a star.",
                    "label": 0
                },
                {
                    "sent": "Here we propose while we explain Billings stories, which is an end to end pipeline that transforms, you know structured data from news feeds to an instructor knowledge representation, which is answering the main journalistic questions of The Who, what, where and when.",
                    "label": 1
                },
                {
                    "sent": "So in this framework we define an event and as aggregation of at least five news articles describing the same story.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we split the pipeline in two main parts, first one consisting of an detection, which would be something similar as Google News which aggregates different news articles and then the second part is when representation where we try to understand the main entities behind an event Anna structure this information.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's an overview of the pipeline.",
                    "label": 0
                },
                {
                    "sent": "I distinguish these two main parts, first one from our fits crawler with the articles, and then we represented Charticle as a vector and we cluster this information and then once we have this class tickle cluster representing events, we extract the information about the entities that are describing this event.",
                    "label": 0
                },
                {
                    "sent": "Anna structure it in an event ontology.",
                    "label": 0
                },
                {
                    "sent": "So for that we disambiguate the mentions of entities using a knowledge graph which is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Billings knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "That's the knowledge graph of the company Billings, which is currently it currently has around 3 million entities, an 30 million RDF triples and it's multilingual.",
                    "label": 1
                },
                {
                    "sent": "It currently has 11 languages, so this knowledge Graph was initially populated with data from wiki data, Wikipedia infoboxes and also freeways an.",
                    "label": 1
                },
                {
                    "sent": "It's also growing as I will explain with emerging entities that are detected with feelings of stories.",
                    "label": 0
                },
                {
                    "sent": "So here we have an example or more or less the information you may find for an entity like NYC.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So well, I will structure the next steps of The Dalles, focusing first on event detection.",
                    "label": 1
                },
                {
                    "sent": "Then I want representation, and I will continue with some analytics on the system.",
                    "label": 0
                },
                {
                    "sent": "The usage and conclusions.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, well, first event detection I will go with step or step in the pipeline.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first we have the news feeds growler, so from a manually generated list of over 4000 errors fits week struck the particles.",
                    "label": 0
                },
                {
                    "sent": "These fields belong to 7 countries.",
                    "label": 0
                },
                {
                    "sent": "An notice that these countries are also multilingual, so we have for example United States but also Spain and Portugal.",
                    "label": 0
                },
                {
                    "sent": "So category is manually assigned to its feet.",
                    "label": 0
                },
                {
                    "sent": "This categories like Sports, politics, entertainment etc.",
                    "label": 0
                },
                {
                    "sent": "And this system is crawling over 3000 feeds an hour.",
                    "label": 0
                },
                {
                    "sent": "So this way we have like current articles.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "During the system in real time, then for each article we parse it and we extract the title, description and the full text Ann.",
                    "label": 0
                },
                {
                    "sent": "Using NLP techniques, we extract the name entities COM announce an non chunks.",
                    "label": 0
                },
                {
                    "sent": "So then we do artikkel feature vector representation using lack of works alike approach.",
                    "label": 0
                },
                {
                    "sent": "But instead of using all the words in the text we use these keywords as has been proven before, it's more effective to in order to classify news articles.",
                    "label": 0
                },
                {
                    "sent": "And also each one of the keywords has a weight within a score.",
                    "label": 0
                },
                {
                    "sent": "That is, is buying the TF IDF.",
                    "label": 0
                },
                {
                    "sent": "But we also give more weights to those keywords appearing in the title and description and also the whole vector has a time factor applied which favors newest documents were articles to be clustered together.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once we have or vector representation, we have to cluster them.",
                    "label": 0
                },
                {
                    "sent": "So first we have the task of tracking.",
                    "label": 0
                },
                {
                    "sent": "So we want to know if the article that it's incoming the system belongs to an already detected event.",
                    "label": 0
                },
                {
                    "sent": "If it is the case it is clustered together and we do that.",
                    "label": 0
                },
                {
                    "sent": "With Canadians.",
                    "label": 0
                },
                {
                    "sent": "Never an if it's not.",
                    "label": 0
                },
                {
                    "sent": "We put together all the articles that are not cluster.",
                    "label": 0
                },
                {
                    "sent": "In any event an with DB scan with deck.",
                    "label": 0
                },
                {
                    "sent": "New incoming events.",
                    "label": 0
                },
                {
                    "sent": "So basically we would have a lot of news and the output of it.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a cluster with those articles talking about the same story?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We wanted to evaluate this first part, which is the topic detection and tracking park.",
                    "label": 1
                },
                {
                    "sent": "To do that we use the UCI news aggregator data set, but notice that we couldn't use the whole data set because many articling URLs were broken and also because over definition definition of event requires for at least five particles to be clustering the same event.",
                    "label": 0
                },
                {
                    "sent": "We had to discuss some events, so after this we evaluated the system an.",
                    "label": 0
                },
                {
                    "sent": "Notice that we have precision detecting events of the 81% and we prior precision over recall.",
                    "label": 0
                },
                {
                    "sent": "Recall in the sense that we have a high artikkel precision when assigning it to clusters, but the records should be improved as many articles are not classified into an event.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So second part is the event representation where we try to detect the main agents and locations involved in the event.",
                    "label": 0
                },
                {
                    "sent": "An instructor this information.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So well, first part at tries to extract those main entities which represent the event.",
                    "label": 0
                },
                {
                    "sent": "This is done with pattern instruction approach that was inspired in the work by Lee Hanzi.",
                    "label": 0
                },
                {
                    "sent": "So for example, from this news, from the Zakim Boran Facebook case, will struck the.",
                    "label": 0
                },
                {
                    "sent": "These entities, well, this mentions of entities that we see here and then we want.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To map.",
                    "label": 0
                },
                {
                    "sent": "This store entities so we link it to entities in our Knowledge Graph, but notice that many times.",
                    "label": 0
                },
                {
                    "sent": "We find any mentions of entities that don't have entities in the Knowledge Graph, so this is a very common thing when dealing with news.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we had to add some dynamics in order to add these entities in our knowledge base so well.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We had these emerging entity detector which currently at the text merging entities belonging to people.",
                    "label": 0
                },
                {
                    "sent": "So we have a set of filters in order to select those.",
                    "label": 0
                },
                {
                    "sent": "Aging ended this and then.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We struck the event semantic pattern, but notice that these entities are still not structure.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we design ontology inspire in the journalistic WS which tries to answer The Who, what, where and what of each event.",
                    "label": 0
                },
                {
                    "sent": "So we select those entities that are of type people organization at as the main involved subjects which are answering the whole and it is of type.",
                    "label": 0
                },
                {
                    "sent": "Location are answering the where then to answer the what right now we select one of the titles among.",
                    "label": 0
                },
                {
                    "sent": "All the articles in the cluster.",
                    "label": 0
                },
                {
                    "sent": "To to answer this and the when is answer with the date of the first article detected in the event.",
                    "label": 0
                },
                {
                    "sent": "Also entities of type event are classified as the topic an.",
                    "label": 0
                },
                {
                    "sent": "We use the fit categories to assign a category to the event and also like context and the semantic pattern is also keep.",
                    "label": 0
                },
                {
                    "sent": "So articles would be would be giving us additional context on the event.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, for the example we have here.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we wanted to evaluate a day capabilities to detect emerging entities of our system.",
                    "label": 0
                },
                {
                    "sent": "So to do that we selected a set of events that were that had already been detected by your system.",
                    "label": 0
                },
                {
                    "sent": "So we have over 600 bands.",
                    "label": 0
                },
                {
                    "sent": "We also wanted to test their multilingual capabilities, that's why we pick events from different countries with different languages.",
                    "label": 0
                },
                {
                    "sent": "So after we pick these events we listed.",
                    "label": 0
                },
                {
                    "sent": "All the entities detected describing these events, and we raised those representing people of Thai people.",
                    "label": 0
                },
                {
                    "sent": "And then we check if redoing all the even representation part the system was capable of creating again the entity of this person and we see that a 778% is detected again.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally some system analytics.",
                    "label": 1
                },
                {
                    "sent": "And well, as I was saying, this system is currently deployed in production worldwide.",
                    "label": 0
                },
                {
                    "sent": "Andwith attacked an average of over 300 events a day an we classify into clustering more than 70,000 eleven articles.",
                    "label": 0
                },
                {
                    "sent": "So this will this has been deployed for over a year.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ann, also we evaluated the capacities of emerging entity detection, so we have an average of 67 emerging entities being detected every day and then after like doing some validation of the correctness of these entities, we see that 75% of these entities are really new entities.",
                    "label": 0
                },
                {
                    "sent": "At 22% are olias of entities that were already in our knowledge graph an around the 10% are errors due to the name entity recognition system.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So well, maybe some of you so Monday or demo.",
                    "label": 0
                },
                {
                    "sent": "We were displaying the dashboard interface that we used to display the ontology information.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you notice here we have all the main parse answering The Who, what, where, also the category context, semantic pattern and also some graph which helps knowing the social impact and how the story is evolving.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And well, in the product application we mix the events information with trends.",
                    "label": 0
                },
                {
                    "sent": "So we have an external system that it scrolling Twitter and Google search and we compute an escort to know which entities are more relevant on real time.",
                    "label": 0
                },
                {
                    "sent": "And we make this information with the number of articles being published.",
                    "label": 0
                },
                {
                    "sent": "So we compute trending score for its event an also.",
                    "label": 0
                },
                {
                    "sent": "So our customers are in general media publishers, so they we know which which are the articles that they are publishing and we mix this information so they also know how the competence is reporting the same event or which information they should be sharing on Twitter, Facebook in order to have more impact.",
                    "label": 0
                },
                {
                    "sent": "So if anyone is interested I can show you or dashboard later well also.",
                    "label": 0
                },
                {
                    "sent": "All this information is returned with API calls to our customers.",
                    "label": 1
                },
                {
                    "sent": "That and they integrate it to their systems.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, well, we generate the tool that fulfills the needed that we say at the beginning it aggregates.",
                    "label": 0
                },
                {
                    "sent": "It helps navigate and search among events.",
                    "label": 0
                },
                {
                    "sent": "It also structures event information giving a summary that answers The Who, what, where and helps relate news.",
                    "label": 0
                },
                {
                    "sent": "And so the main contributions of the system is the new generation of any ban knowledge base with emerging entity detection capabilities and the large scale deployment of the system.",
                    "label": 1
                },
                {
                    "sent": "So in future work we plan to add more countries into the system.",
                    "label": 0
                },
                {
                    "sent": "As it is a multilingual system, we actually have already done and see if you saw the demo instead of seven countries.",
                    "label": 0
                },
                {
                    "sent": "We currently have 20 countries already an.",
                    "label": 1
                },
                {
                    "sent": "Also we are working on extracting triple information from the events in order to describe the actions involved in the event an we also working on improving the recall on event detection.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all, thank you.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So we added this American candy is required.",
                    "label": 0
                },
                {
                    "sent": "At least entities already exist in other knowledge grows.",
                    "label": 0
                },
                {
                    "sent": "So I missed the beginning, sorry.",
                    "label": 0
                },
                {
                    "sent": "Emerging in division in footwear that these entities already exist.",
                    "label": 0
                },
                {
                    "sent": "So actually our Knowledge Graph also like.",
                    "label": 0
                },
                {
                    "sent": "Easy and data or what emerging entities or both, so an experience.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it.",
                    "label": 0
                },
                {
                    "sent": "You're right, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, correctly yeah yeah so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you we crawl excellent knowledge basis in order to add the entities that this knowledge base is already have.",
                    "label": 0
                },
                {
                    "sent": "And the nice part about this system is that we can also add entities before this.",
                    "label": 0
                },
                {
                    "sent": "Also these external knowledge bases have it.",
                    "label": 0
                },
                {
                    "sent": "And also.",
                    "label": 0
                },
                {
                    "sent": "R. Yeah.",
                    "label": 0
                },
                {
                    "sent": "Starts talking then.",
                    "label": 0
                },
                {
                    "sent": "Other people are saying.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we are not doing that right now.",
                    "label": 0
                },
                {
                    "sent": "That would be something very nice to do.",
                    "label": 0
                },
                {
                    "sent": "Yes, I'm stuck here.",
                    "label": 0
                },
                {
                    "sent": "Load your system with kind of a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "Why is the weights so that basically you're looking for confirmation or or model of that?",
                    "label": 0
                },
                {
                    "sent": "My focus is like for example, yeah.",
                    "label": 0
                },
                {
                    "sent": "News events that actually just like that, is that possible overlay?",
                    "label": 0
                },
                {
                    "sent": "I think it's very difficult, so we then generate and any band and we run all the entities representing events for Phillip pattern.",
                    "label": 0
                },
                {
                    "sent": "So you have to see it in a lot of news in a time window.",
                    "label": 0
                },
                {
                    "sent": "So I think it's very difficult to find.",
                    "label": 0
                },
                {
                    "sent": "If it's not like everybody is saying the same thing.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Text.",
                    "label": 0
                },
                {
                    "sent": "That track they require is that you identified or real astounding in every event and the realities value says whether or not that really happened.",
                    "label": 0
                },
                {
                    "sent": "So for example, in stories about March, like.",
                    "label": 0
                },
                {
                    "sent": "I would like everything.",
                    "label": 0
                },
                {
                    "sent": "Is expected that he will testify at Congress.",
                    "label": 0
                },
                {
                    "sent": "And sometimes these events that are written about it never happened before giving the written about because it's afraid if they might happen.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Well, so I think that well in the part we are working right now that we want to suck triples describing really what's going on in the event.",
                    "label": 0
                },
                {
                    "sent": "That would be something nice to study.",
                    "label": 0
                },
                {
                    "sent": "As you may have contradictions an maybe if you have time stamps, you can say like, OK, these people were saying this may happen, but that's what actually happened.",
                    "label": 0
                },
                {
                    "sent": "So maybe in the future we can do that.",
                    "label": 0
                },
                {
                    "sent": "And I would have one last question.",
                    "label": 0
                },
                {
                    "sent": "You're in which data, for example, you have a large number of events as well, which are precisely described in terms of the what would be well structured is attractive.",
                    "label": 0
                },
                {
                    "sent": "Are you aiming to link to that as well?",
                    "label": 0
                },
                {
                    "sent": "So can you in your own knowledge graph, which I understand is private.",
                    "label": 0
                },
                {
                    "sent": "Yeah, can you still link to so?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if we detect so we are well in wiki data we could like detect an event being reported there an link it.",
                    "label": 0
                },
                {
                    "sent": "So for example I don't know we have entities like Brexit that are describing the topic.",
                    "label": 0
                },
                {
                    "sent": "And also we crawl Wikipedia current events so when we see new entities describing topics will link it.",
                    "label": 0
                },
                {
                    "sent": "So I guess that from Wikipedia current events we could link to wiki data and also struck this information.",
                    "label": 0
                },
                {
                    "sent": "We're not exactly doing that, but we could.",
                    "label": 0
                },
                {
                    "sent": "Thanks again.",
                    "label": 0
                }
            ]
        }
    }
}