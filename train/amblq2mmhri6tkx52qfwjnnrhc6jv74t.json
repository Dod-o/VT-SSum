{
    "id": "amblq2mmhri6tkx52qfwjnnrhc6jv74t",
    "title": "Speeding up Graph Edit Distance Computation with a Bipartite Heuristic",
    "info": {
        "author": [
            "Kaspar Riesen, University of Bern"
        ],
        "published": "Sept. 5, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Mathematics->Graph Theory"
        ]
    },
    "url": "http://videolectures.net/mlg07_riesen_sugedc/",
    "segmentation": [
        [
            "So hello everyone, and welcome to my talk about speeding up graph edit distance computation with bipartite heuristic.",
            "My name is Kasper reason and I'm a PhD student of Professor Bunker at the University of Bern in Switzerland."
        ],
        [
            "So here's the outline of my talk.",
            "First of all, I will talk about the general concept of graph edit distance, since this is our basic graph matching paradigm that we apply on our Institute.",
            "Next I will talk about that research algorithm for computing the graph edit distance, which is sort of a standard procedure for computing the graph edit distance.",
            "Then I will talk briefly about Moncus algorithm, which is an algorithm for solving the assignment problem in polynomial time and then the."
        ],
        [
            "Main contribution of this work here is that we show how we can use this algorithm as a heuristic for graph, edit distance and finally I will show you some experimental results achieved with our proposal and draw some conclusions.",
            "So as I mentioned before, the main contribution of this work here is that we provide not the first, of course, but we provide and you Horace tick for speeding up exact graph edit distance computation."
        ],
        [
            "So I suppose all of you know this standard definition of graphs given here, but nevertheless I made this slide for the sake of completeness of course.",
            "And there's one thing that I really want to point out here, and this concerns the label alphabet, so of both the notes in there, just so we allow any kind of labels so the nodes and edges can be labeled with integers or reals.",
            "They can be labeled with real wages.",
            "We allow discrete symbols, we allow strings allow also.",
            "Unlabeled nodes and edges, of course, and hence the patterns to be transformed into graphs and manifold, and they range from physical networks like the Internet.",
            "Logical networks like websites to color images or fingerprint images, shape codes, graphical symbols, letters and itches, and of course also chemical structures.",
            "So the reason for this flexibility in our definition here."
        ],
        [
            "Is based on the matching paradigm that we apply in this graph.",
            "Edit distance.",
            "So graph edit distance.",
            "We basically defined this similarity of graphs by the minimum amount of distortion that is needed to transform one graph into another.",
            "So these distortions are basically given by edit operations and they consist here of deletions, insertions and substitutions of both nodes and edges.",
            "So in other applications other.",
            "Edit operations like splitting or merging of nodes could be useful, but they are not considered in this work here.",
            "So, um.",
            "A sequence of such edit operations which transforms a given graph completely into another graph is commonly referred to as an edit path, so here's a small toy example.",
            "We have this graph."
        ],
        [
            "She won."
        ],
        [
            "So we delete."
        ],
        [
            "Some edge isn't."
        ],
        [
            "Out and we insert some notes and that just and we possibly substitute some nodes and edges means we re label them.",
            "And finally we have transformed Chaewon completely into G2 and this is a possible edit path for transforming chaewon into G2.",
            "So obviously between two given graphs not only one but a number of different such edit paths exist.",
            "So for instance, one can think of an edit path where we delete all the nodes and edges here and insert all the notes in there just here this would be.",
            "A possible edit path to."
        ],
        [
            "So formally.",
            "The graph edit distance.",
            "Between G1 as the source graph and Chi two as the target graph is defined by the minimum cost edit path between G1 and G2 among all possible edit passes.",
            "So obviously we have to define a cost function C, which measures the strength of a given edit operation, and this cost function takes.",
            "Of course the node or edge label information into account.",
            "That is, if you substitute 2 notes with very similar labels, this should lead to.",
            "Low cost while substituting two nodes or edges with very dissimilar labels that should be reflected with higher costs.",
            "So I think we can conclude that graph edit Distance provides us with a very general similarity model for graphs."
        ],
        [
            "So let's have a look at the applications.",
            "Of graph edit distance.",
            "So first of all we can define of course K&N classifier in the domain of graphs, which is very easy.",
            "But Furthermore we can also define edit distance based graph kernels.",
            "So for instance we use often as a reference system.",
            "This trivial graph kernel in conjunction with a support vector machine to descend you have to transform that.",
            "This similarity model graph edit distance into a similarity model.",
            "Then a second approach is to extend existing.",
            "Graph kernels like the random walk kernel with graph edit distance.",
            "For instance the random walk Edit kernel proposed by Michel Neuhaus in his PhD.",
            "And finally we can also make an explicit embedding of the graphs into real vector spaces by means of prototype selection graph edit distance.",
            "Which is in fact the main line of research research in my PhD.",
            "So finally, of course we can also apply graph cluster clustering in the domain of graphs based on graph edit distance.",
            "So the applications are manifold.",
            "But one problem that arises."
        ],
        [
            "You are working with graph edit distance is its complexity, which is in fact exponential in the number of nodes of the involved graphs.",
            "If you want to do it exactly so it's well known that for graphs with unique node labels, the complexity is linear, but we do not consider this special class of graphs here.",
            "But all kinds of graphs.",
            "So the computation of exact graph distance is usually carried out by means of tree search algorithm, which explores the space of all possible mappings of the nodes and edges of G1 through the nodes and edges of G2.",
            "So Please note that the edit operations on edges are always implied by edit operations under a chase."
        ],
        [
            "Notes.",
            "So the idea of such a tree search algorithm is to represent the underlying optimization problem in a tree data structure, where the root node represents the starting point of our optimization.",
            "In the nodes represent partial solutions means partial edit path is transforming.",
            "This graph not completely into this graph, and leaf nodes represents.",
            "Complete edit passes means complete solutions.",
            "Transforming G1 completely into T2.",
            "Such a search tree is usually constructed dynamically at runtime by creating such successor nodes linked by edges to the currently considered node, and we use usually a Ristic function which is used to determine the node P in the search tree used for further expand."
        ],
        [
            "Some more formally.",
            "For each note in the search tree for each node Pena search tree.",
            "This sum here is computed.",
            "That is, a cheapie GFP is the cost of the partial edit path accumulated so far.",
            "So in this small toy example here we have these three node operations plus the implied edge operations, of course, and then H is an estimation of the future cost to reach a leaf node from P from P on so, and it is well known if this estimation is a lower bound of the true costs, we will find the exact graph edit distance.",
            "So of course there are different ways now to define this function here.",
            "One extreme would be that we define H always to 0 for all the piece.",
            "This is very efficient of course, because we do not compute anything at all.",
            "But it's also very inaccurate.",
            "The other extreme would be that we compute not a lower bound after future cost, but we compute the exact graph edit distance to reach a leaf node.",
            "This is very accurate this estimation, but also very inefficient of course.",
            "So somewhere in between these two extremes one could define an estimation."
        ],
        [
            "And the task to be solved is how do we estimate such a lower bound for the future cost efficiently and accurately?",
            "So and in this work here we propose a newhire istick which is based on."
        ],
        [
            "The assignment problem.",
            "So the assignment problem is stated as finding an optimal assignment of N elements of a set as one set.",
            "Here 2 N elements of set as two set.",
            "So we introduce costs for each of these assignments and then the optimal assignment is a permutation P of the integers.",
            "Want to end that minimize this sum here?"
        ],
        [
            "So obviously we can solve this problem with an N * N cost matrix, where each entry represents the cost of 1 assignment.",
            "So then the assignment problem can be stated as finding a set of an independent elements of this cost function such that the sum of these elements is minimum.",
            "Here's a small example.",
            "Each entry represents the cost of 1 assignment here are in this table all possible independent permutations and we see that we have two minimum cost node assignments.",
            "So solving this problem here in a brute force manner will lead to a time complexity which is."
        ],
        [
            "Hi, but there exists an algorithm which solves assignment problem in polynomial time.",
            "So it's Mom Chris algorithm sometimes refer to as Hungarian method or Hungarian algorithm.",
            "So what it basically does it finds a new matrix which is equivalent to the initial cost matrix.",
            "But the new matrix has an independent zero elements marked with a star.",
            "So what you're basically doing is we are adding in subtracting constants from rows and columns.",
            "From this initial cost matrix and marking independent sets of zeros with star, so, and finally we find this independent zeros, which corresponds exactly to the assignments."
        ],
        [
            "So.",
            "I think it's quite obvious that we can now use Microsoft algorithm for estimating a lower bound for the future costs.",
            "So the problem of estimating a lower bound from P to reach a leaf node can be seen as an assignment problem.",
            "So the question is how can we assign the unprocessed nodes of G1 to the emphasis note of G2 such that the resulting edit costs are minimal.",
            "So here in this small toy example, let us assume these two node operations have been performed now.",
            "So the unprocessed nodes of chaewon RDS and here are the unprocessed nodes of G. Two, so the question is now, how can we assign them to each other uniquely and we want also to allow that some of the notes here could be deleted in some of the nodes here can be inserted marked with this epsilon node here."
        ],
        [
            "So and of course we make no use of monstrous algorithm to solve this task.",
            "So what we do is we define a node cost matrix.",
            "So let us assume we won and we two are the sets of the unprocessed nodes of G1 and G2 respectively.",
            "So we define an N + M * N + M node cost matrix.",
            "So the left upper corner here represents the cost of all possible note substitutions.",
            "Then hear the diagonal of the right upper corner represents the cost of all possible node deletions and here.",
            "In the left bottom corner we have the cost of all possible node insertions.",
            "So and of course we can now run monkeys algorithm on this cost matrix, and what we get is the minimum cost node assignment for the unprocessed nodes of both."
        ],
        [
            "Graphs so, and in order to obtain the bipartite heuristic that we want to apply, we construct an edge cost matrix with the unprocessed edges of both graphs and then logically.",
            "And then for each open note P in the search tree, we run monkeys algorithm twice, once with the node cosmetics and ones with the edge cost matrix with young process nodes and edges, and we accumulate both minimum costs of the assignments and this serves us as a lower bound for the future cost to reach a leaf node."
        ],
        [
            "OK, so in order.",
            "To investigate the speedup empirically, we use four different graph datasets so far, so the letter the image to fingerprint in the molecule data set.",
            "We computed the edit edit distances between graphs once with the bipartite eristic, and runs without bipartite heuristic, and then we measured the mean computation time and the mean number of open passes in the search tree during the graph matching process."
        ],
        [
            "So here's the first data set which consists of graphs that represent capital let line drawings.",
            "It's a sort of artificial data set.",
            "We have different distortion levels, and we have 15 classes.",
            "We performed about 560,000 matchings, and as you see here.",
            "It's the plain version of the algorithm that means without the heuristic, and here we bipartite version of the algorithm and what we see is that we are 30, three times faster than the version without the bipartite heuristic, and we mean number of open passes is 7 times smaller with the bypass."
        ],
        [
            "That heuristic, so the next data set is the image data set which consists of graphs representing color images out of five classes.",
            "So in order to obtain these graphs, we first segmented images into regions and represent these regions by region adjacency graph, where each node is attributed with a color histogram.",
            "And here we see that both versions on these very small graphs perform in the same time terminates in the same time.",
            "But we expand only the half of open the half of the search tree.",
            "So here we can say that the.",
            "Computational overhead for computing our bipartite heuristics is completely compensated by a faster tree traversal."
        ],
        [
            "So in the next data set which is a molecule data set which consists of graphs representing molecules out of two classes, active and inactive, we performed only 21,000 matching so far.",
            "So here we see.",
            "In order to construct graphs out of these molecules, we represent atoms as nodes in the current phones is edges, and here we see that we are almost 2000 times faster with our heuristic and we expanded 120 times less passes during the search."
        ],
        [
            "And on the last data set.",
            "Which is the fingerprint data set which consists of graphs representing fingerprint images out of four classes.",
            "Here again, we see that we are 16 times faster and we have almost five times less open passes here."
        ],
        [
            "So, um.",
            "To conclude, this experimental results, we can say that thanks to the bipartite heuristic, we can achieve significant speedups for exact graph edit distance.",
            "But of course this is not the only heuristic.",
            "There are other heuristics, and it's part of our future work to compare our procedure here with with other heuristics.",
            "But one interesting point is that further speedups can be achieved if we resort now to suboptimal.",
            "Algorithms so suboptimal means that we do not necessarily find the exact graph edit distance."
        ],
        [
            "So and one possibility.",
            "Is actually to transform this heuristic here into a self contained suboptimal graph matching procedure?"
        ],
        [
            "And I think this is quite interesting thing so.",
            "What we are doing is we define a node cost matrix for whole graphs.",
            "Now not for not only for the unprocessed unprocessed nodes of G1 and G2, but for whole graphs.",
            "What we get is this node cost matrix here, which is the same as before.",
            "So here denotes substitutions node deletions, node insertions and now there is no need for a search tree anymore in this procedure."
        ],
        [
            "So what we're doing is we're on Microsoft algorithm and we find the optimal node assignment by considering the node operations only or the local edge structure only, and then at the end when we have fun, we have found the optimal node assignment.",
            "We add the implied edge operations or the cost of them to the optimal node assignment.",
            "So this is in contrast with the exact graph edit distance where we add these implied.",
            "Edge operations at runtime.",
            "Dynamically when we're constructing the tree.",
            "Here we have no opportunity to do so dynamically.",
            "We have to add them at the end and this is direct.",
            "Consequence of this.",
            "Is that the edit distance found by our algorithm here need not necessarily correspond to the exact value, but it's suboptimal graph edit distance so it's equal or be tired an exact graphitic distance so, however.",
            "A significant speedup can be."
        ],
        [
            "Spectr it.",
            "And it was part of our future work to find out whether or not the sub optimal distance remains sufficiently accurate for pattern recognition and machine learning applications.",
            "And actually it's no longer future work because we have tested it on several datasets, not only on these datasets here and it works quite well.",
            "We have another paper about this, which was which is in the proceedings of Chi PR this year.",
            "So you will see that with this algorithm here you can achieve significant speedups, and the classification results of, for instance, the graph embedding procedure, or KNN classifier is nearly not affected.",
            "So sometimes it's even increased with the suboptimal a distances and this is.",
            "Very interesting effect of this suboptimal distance, but I don't know if I have time to talk about this.",
            "Maybe you can ask me later why this is like."
        ],
        [
            "Is so.",
            "This was my talk, so let me draw conclusions.",
            "You propose here and you holistic, but it's among Chris algorithm for speeding up exact graph edit distance over her Ristic finds an optimal node and an optimal edge assignment for the unprocessed nodes and edges in polynomial time.",
            "So then our heuristic helps in speeding up exact graph edit distance substantially, and the most interesting point for me is the last.",
            "So the proposed heuristic can be used for fast sub optimal graph matching.",
            "Procedure.",
            "So this was my talk.",
            "Thank you for your attention and flat answer."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hello everyone, and welcome to my talk about speeding up graph edit distance computation with bipartite heuristic.",
                    "label": 0
                },
                {
                    "sent": "My name is Kasper reason and I'm a PhD student of Professor Bunker at the University of Bern in Switzerland.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "First of all, I will talk about the general concept of graph edit distance, since this is our basic graph matching paradigm that we apply on our Institute.",
                    "label": 1
                },
                {
                    "sent": "Next I will talk about that research algorithm for computing the graph edit distance, which is sort of a standard procedure for computing the graph edit distance.",
                    "label": 1
                },
                {
                    "sent": "Then I will talk briefly about Moncus algorithm, which is an algorithm for solving the assignment problem in polynomial time and then the.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Main contribution of this work here is that we show how we can use this algorithm as a heuristic for graph, edit distance and finally I will show you some experimental results achieved with our proposal and draw some conclusions.",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned before, the main contribution of this work here is that we provide not the first, of course, but we provide and you Horace tick for speeding up exact graph edit distance computation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I suppose all of you know this standard definition of graphs given here, but nevertheless I made this slide for the sake of completeness of course.",
                    "label": 0
                },
                {
                    "sent": "And there's one thing that I really want to point out here, and this concerns the label alphabet, so of both the notes in there, just so we allow any kind of labels so the nodes and edges can be labeled with integers or reals.",
                    "label": 0
                },
                {
                    "sent": "They can be labeled with real wages.",
                    "label": 0
                },
                {
                    "sent": "We allow discrete symbols, we allow strings allow also.",
                    "label": 0
                },
                {
                    "sent": "Unlabeled nodes and edges, of course, and hence the patterns to be transformed into graphs and manifold, and they range from physical networks like the Internet.",
                    "label": 0
                },
                {
                    "sent": "Logical networks like websites to color images or fingerprint images, shape codes, graphical symbols, letters and itches, and of course also chemical structures.",
                    "label": 0
                },
                {
                    "sent": "So the reason for this flexibility in our definition here.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is based on the matching paradigm that we apply in this graph.",
                    "label": 0
                },
                {
                    "sent": "Edit distance.",
                    "label": 0
                },
                {
                    "sent": "So graph edit distance.",
                    "label": 0
                },
                {
                    "sent": "We basically defined this similarity of graphs by the minimum amount of distortion that is needed to transform one graph into another.",
                    "label": 1
                },
                {
                    "sent": "So these distortions are basically given by edit operations and they consist here of deletions, insertions and substitutions of both nodes and edges.",
                    "label": 0
                },
                {
                    "sent": "So in other applications other.",
                    "label": 0
                },
                {
                    "sent": "Edit operations like splitting or merging of nodes could be useful, but they are not considered in this work here.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "A sequence of such edit operations which transforms a given graph completely into another graph is commonly referred to as an edit path, so here's a small toy example.",
                    "label": 0
                },
                {
                    "sent": "We have this graph.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "She won.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we delete.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some edge isn't.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out and we insert some notes and that just and we possibly substitute some nodes and edges means we re label them.",
                    "label": 1
                },
                {
                    "sent": "And finally we have transformed Chaewon completely into G2 and this is a possible edit path for transforming chaewon into G2.",
                    "label": 0
                },
                {
                    "sent": "So obviously between two given graphs not only one but a number of different such edit paths exist.",
                    "label": 0
                },
                {
                    "sent": "So for instance, one can think of an edit path where we delete all the nodes and edges here and insert all the notes in there just here this would be.",
                    "label": 0
                },
                {
                    "sent": "A possible edit path to.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So formally.",
                    "label": 0
                },
                {
                    "sent": "The graph edit distance.",
                    "label": 0
                },
                {
                    "sent": "Between G1 as the source graph and Chi two as the target graph is defined by the minimum cost edit path between G1 and G2 among all possible edit passes.",
                    "label": 0
                },
                {
                    "sent": "So obviously we have to define a cost function C, which measures the strength of a given edit operation, and this cost function takes.",
                    "label": 0
                },
                {
                    "sent": "Of course the node or edge label information into account.",
                    "label": 0
                },
                {
                    "sent": "That is, if you substitute 2 notes with very similar labels, this should lead to.",
                    "label": 0
                },
                {
                    "sent": "Low cost while substituting two nodes or edges with very dissimilar labels that should be reflected with higher costs.",
                    "label": 0
                },
                {
                    "sent": "So I think we can conclude that graph edit Distance provides us with a very general similarity model for graphs.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's have a look at the applications.",
                    "label": 0
                },
                {
                    "sent": "Of graph edit distance.",
                    "label": 0
                },
                {
                    "sent": "So first of all we can define of course K&N classifier in the domain of graphs, which is very easy.",
                    "label": 0
                },
                {
                    "sent": "But Furthermore we can also define edit distance based graph kernels.",
                    "label": 0
                },
                {
                    "sent": "So for instance we use often as a reference system.",
                    "label": 0
                },
                {
                    "sent": "This trivial graph kernel in conjunction with a support vector machine to descend you have to transform that.",
                    "label": 1
                },
                {
                    "sent": "This similarity model graph edit distance into a similarity model.",
                    "label": 1
                },
                {
                    "sent": "Then a second approach is to extend existing.",
                    "label": 1
                },
                {
                    "sent": "Graph kernels like the random walk kernel with graph edit distance.",
                    "label": 1
                },
                {
                    "sent": "For instance the random walk Edit kernel proposed by Michel Neuhaus in his PhD.",
                    "label": 0
                },
                {
                    "sent": "And finally we can also make an explicit embedding of the graphs into real vector spaces by means of prototype selection graph edit distance.",
                    "label": 1
                },
                {
                    "sent": "Which is in fact the main line of research research in my PhD.",
                    "label": 0
                },
                {
                    "sent": "So finally, of course we can also apply graph cluster clustering in the domain of graphs based on graph edit distance.",
                    "label": 0
                },
                {
                    "sent": "So the applications are manifold.",
                    "label": 0
                },
                {
                    "sent": "But one problem that arises.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You are working with graph edit distance is its complexity, which is in fact exponential in the number of nodes of the involved graphs.",
                    "label": 1
                },
                {
                    "sent": "If you want to do it exactly so it's well known that for graphs with unique node labels, the complexity is linear, but we do not consider this special class of graphs here.",
                    "label": 0
                },
                {
                    "sent": "But all kinds of graphs.",
                    "label": 1
                },
                {
                    "sent": "So the computation of exact graph distance is usually carried out by means of tree search algorithm, which explores the space of all possible mappings of the nodes and edges of G1 through the nodes and edges of G2.",
                    "label": 0
                },
                {
                    "sent": "So Please note that the edit operations on edges are always implied by edit operations under a chase.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Notes.",
                    "label": 0
                },
                {
                    "sent": "So the idea of such a tree search algorithm is to represent the underlying optimization problem in a tree data structure, where the root node represents the starting point of our optimization.",
                    "label": 1
                },
                {
                    "sent": "In the nodes represent partial solutions means partial edit path is transforming.",
                    "label": 0
                },
                {
                    "sent": "This graph not completely into this graph, and leaf nodes represents.",
                    "label": 0
                },
                {
                    "sent": "Complete edit passes means complete solutions.",
                    "label": 1
                },
                {
                    "sent": "Transforming G1 completely into T2.",
                    "label": 0
                },
                {
                    "sent": "Such a search tree is usually constructed dynamically at runtime by creating such successor nodes linked by edges to the currently considered node, and we use usually a Ristic function which is used to determine the node P in the search tree used for further expand.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some more formally.",
                    "label": 0
                },
                {
                    "sent": "For each note in the search tree for each node Pena search tree.",
                    "label": 1
                },
                {
                    "sent": "This sum here is computed.",
                    "label": 0
                },
                {
                    "sent": "That is, a cheapie GFP is the cost of the partial edit path accumulated so far.",
                    "label": 0
                },
                {
                    "sent": "So in this small toy example here we have these three node operations plus the implied edge operations, of course, and then H is an estimation of the future cost to reach a leaf node from P from P on so, and it is well known if this estimation is a lower bound of the true costs, we will find the exact graph edit distance.",
                    "label": 1
                },
                {
                    "sent": "So of course there are different ways now to define this function here.",
                    "label": 0
                },
                {
                    "sent": "One extreme would be that we define H always to 0 for all the piece.",
                    "label": 0
                },
                {
                    "sent": "This is very efficient of course, because we do not compute anything at all.",
                    "label": 0
                },
                {
                    "sent": "But it's also very inaccurate.",
                    "label": 0
                },
                {
                    "sent": "The other extreme would be that we compute not a lower bound after future cost, but we compute the exact graph edit distance to reach a leaf node.",
                    "label": 0
                },
                {
                    "sent": "This is very accurate this estimation, but also very inefficient of course.",
                    "label": 0
                },
                {
                    "sent": "So somewhere in between these two extremes one could define an estimation.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the task to be solved is how do we estimate such a lower bound for the future cost efficiently and accurately?",
                    "label": 0
                },
                {
                    "sent": "So and in this work here we propose a newhire istick which is based on.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The assignment problem.",
                    "label": 0
                },
                {
                    "sent": "So the assignment problem is stated as finding an optimal assignment of N elements of a set as one set.",
                    "label": 0
                },
                {
                    "sent": "Here 2 N elements of set as two set.",
                    "label": 0
                },
                {
                    "sent": "So we introduce costs for each of these assignments and then the optimal assignment is a permutation P of the integers.",
                    "label": 0
                },
                {
                    "sent": "Want to end that minimize this sum here?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So obviously we can solve this problem with an N * N cost matrix, where each entry represents the cost of 1 assignment.",
                    "label": 0
                },
                {
                    "sent": "So then the assignment problem can be stated as finding a set of an independent elements of this cost function such that the sum of these elements is minimum.",
                    "label": 1
                },
                {
                    "sent": "Here's a small example.",
                    "label": 0
                },
                {
                    "sent": "Each entry represents the cost of 1 assignment here are in this table all possible independent permutations and we see that we have two minimum cost node assignments.",
                    "label": 0
                },
                {
                    "sent": "So solving this problem here in a brute force manner will lead to a time complexity which is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, but there exists an algorithm which solves assignment problem in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "So it's Mom Chris algorithm sometimes refer to as Hungarian method or Hungarian algorithm.",
                    "label": 0
                },
                {
                    "sent": "So what it basically does it finds a new matrix which is equivalent to the initial cost matrix.",
                    "label": 0
                },
                {
                    "sent": "But the new matrix has an independent zero elements marked with a star.",
                    "label": 0
                },
                {
                    "sent": "So what you're basically doing is we are adding in subtracting constants from rows and columns.",
                    "label": 0
                },
                {
                    "sent": "From this initial cost matrix and marking independent sets of zeros with star, so, and finally we find this independent zeros, which corresponds exactly to the assignments.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I think it's quite obvious that we can now use Microsoft algorithm for estimating a lower bound for the future costs.",
                    "label": 0
                },
                {
                    "sent": "So the problem of estimating a lower bound from P to reach a leaf node can be seen as an assignment problem.",
                    "label": 0
                },
                {
                    "sent": "So the question is how can we assign the unprocessed nodes of G1 to the emphasis note of G2 such that the resulting edit costs are minimal.",
                    "label": 0
                },
                {
                    "sent": "So here in this small toy example, let us assume these two node operations have been performed now.",
                    "label": 0
                },
                {
                    "sent": "So the unprocessed nodes of chaewon RDS and here are the unprocessed nodes of G. Two, so the question is now, how can we assign them to each other uniquely and we want also to allow that some of the notes here could be deleted in some of the nodes here can be inserted marked with this epsilon node here.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So and of course we make no use of monstrous algorithm to solve this task.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we define a node cost matrix.",
                    "label": 0
                },
                {
                    "sent": "So let us assume we won and we two are the sets of the unprocessed nodes of G1 and G2 respectively.",
                    "label": 1
                },
                {
                    "sent": "So we define an N + M * N + M node cost matrix.",
                    "label": 0
                },
                {
                    "sent": "So the left upper corner here represents the cost of all possible note substitutions.",
                    "label": 0
                },
                {
                    "sent": "Then hear the diagonal of the right upper corner represents the cost of all possible node deletions and here.",
                    "label": 0
                },
                {
                    "sent": "In the left bottom corner we have the cost of all possible node insertions.",
                    "label": 0
                },
                {
                    "sent": "So and of course we can now run monkeys algorithm on this cost matrix, and what we get is the minimum cost node assignment for the unprocessed nodes of both.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphs so, and in order to obtain the bipartite heuristic that we want to apply, we construct an edge cost matrix with the unprocessed edges of both graphs and then logically.",
                    "label": 0
                },
                {
                    "sent": "And then for each open note P in the search tree, we run monkeys algorithm twice, once with the node cosmetics and ones with the edge cost matrix with young process nodes and edges, and we accumulate both minimum costs of the assignments and this serves us as a lower bound for the future cost to reach a leaf node.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in order.",
                    "label": 0
                },
                {
                    "sent": "To investigate the speedup empirically, we use four different graph datasets so far, so the letter the image to fingerprint in the molecule data set.",
                    "label": 0
                },
                {
                    "sent": "We computed the edit edit distances between graphs once with the bipartite eristic, and runs without bipartite heuristic, and then we measured the mean computation time and the mean number of open passes in the search tree during the graph matching process.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the first data set which consists of graphs that represent capital let line drawings.",
                    "label": 0
                },
                {
                    "sent": "It's a sort of artificial data set.",
                    "label": 0
                },
                {
                    "sent": "We have different distortion levels, and we have 15 classes.",
                    "label": 0
                },
                {
                    "sent": "We performed about 560,000 matchings, and as you see here.",
                    "label": 0
                },
                {
                    "sent": "It's the plain version of the algorithm that means without the heuristic, and here we bipartite version of the algorithm and what we see is that we are 30, three times faster than the version without the bipartite heuristic, and we mean number of open passes is 7 times smaller with the bypass.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That heuristic, so the next data set is the image data set which consists of graphs representing color images out of five classes.",
                    "label": 0
                },
                {
                    "sent": "So in order to obtain these graphs, we first segmented images into regions and represent these regions by region adjacency graph, where each node is attributed with a color histogram.",
                    "label": 0
                },
                {
                    "sent": "And here we see that both versions on these very small graphs perform in the same time terminates in the same time.",
                    "label": 0
                },
                {
                    "sent": "But we expand only the half of open the half of the search tree.",
                    "label": 0
                },
                {
                    "sent": "So here we can say that the.",
                    "label": 0
                },
                {
                    "sent": "Computational overhead for computing our bipartite heuristics is completely compensated by a faster tree traversal.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the next data set which is a molecule data set which consists of graphs representing molecules out of two classes, active and inactive, we performed only 21,000 matching so far.",
                    "label": 0
                },
                {
                    "sent": "So here we see.",
                    "label": 0
                },
                {
                    "sent": "In order to construct graphs out of these molecules, we represent atoms as nodes in the current phones is edges, and here we see that we are almost 2000 times faster with our heuristic and we expanded 120 times less passes during the search.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on the last data set.",
                    "label": 0
                },
                {
                    "sent": "Which is the fingerprint data set which consists of graphs representing fingerprint images out of four classes.",
                    "label": 0
                },
                {
                    "sent": "Here again, we see that we are 16 times faster and we have almost five times less open passes here.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "To conclude, this experimental results, we can say that thanks to the bipartite heuristic, we can achieve significant speedups for exact graph edit distance.",
                    "label": 1
                },
                {
                    "sent": "But of course this is not the only heuristic.",
                    "label": 0
                },
                {
                    "sent": "There are other heuristics, and it's part of our future work to compare our procedure here with with other heuristics.",
                    "label": 0
                },
                {
                    "sent": "But one interesting point is that further speedups can be achieved if we resort now to suboptimal.",
                    "label": 0
                },
                {
                    "sent": "Algorithms so suboptimal means that we do not necessarily find the exact graph edit distance.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and one possibility.",
                    "label": 0
                },
                {
                    "sent": "Is actually to transform this heuristic here into a self contained suboptimal graph matching procedure?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I think this is quite interesting thing so.",
                    "label": 0
                },
                {
                    "sent": "What we are doing is we define a node cost matrix for whole graphs.",
                    "label": 0
                },
                {
                    "sent": "Now not for not only for the unprocessed unprocessed nodes of G1 and G2, but for whole graphs.",
                    "label": 0
                },
                {
                    "sent": "What we get is this node cost matrix here, which is the same as before.",
                    "label": 0
                },
                {
                    "sent": "So here denotes substitutions node deletions, node insertions and now there is no need for a search tree anymore in this procedure.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we're doing is we're on Microsoft algorithm and we find the optimal node assignment by considering the node operations only or the local edge structure only, and then at the end when we have fun, we have found the optimal node assignment.",
                    "label": 0
                },
                {
                    "sent": "We add the implied edge operations or the cost of them to the optimal node assignment.",
                    "label": 0
                },
                {
                    "sent": "So this is in contrast with the exact graph edit distance where we add these implied.",
                    "label": 0
                },
                {
                    "sent": "Edge operations at runtime.",
                    "label": 0
                },
                {
                    "sent": "Dynamically when we're constructing the tree.",
                    "label": 0
                },
                {
                    "sent": "Here we have no opportunity to do so dynamically.",
                    "label": 0
                },
                {
                    "sent": "We have to add them at the end and this is direct.",
                    "label": 0
                },
                {
                    "sent": "Consequence of this.",
                    "label": 0
                },
                {
                    "sent": "Is that the edit distance found by our algorithm here need not necessarily correspond to the exact value, but it's suboptimal graph edit distance so it's equal or be tired an exact graphitic distance so, however.",
                    "label": 1
                },
                {
                    "sent": "A significant speedup can be.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spectr it.",
                    "label": 0
                },
                {
                    "sent": "And it was part of our future work to find out whether or not the sub optimal distance remains sufficiently accurate for pattern recognition and machine learning applications.",
                    "label": 0
                },
                {
                    "sent": "And actually it's no longer future work because we have tested it on several datasets, not only on these datasets here and it works quite well.",
                    "label": 0
                },
                {
                    "sent": "We have another paper about this, which was which is in the proceedings of Chi PR this year.",
                    "label": 0
                },
                {
                    "sent": "So you will see that with this algorithm here you can achieve significant speedups, and the classification results of, for instance, the graph embedding procedure, or KNN classifier is nearly not affected.",
                    "label": 0
                },
                {
                    "sent": "So sometimes it's even increased with the suboptimal a distances and this is.",
                    "label": 0
                },
                {
                    "sent": "Very interesting effect of this suboptimal distance, but I don't know if I have time to talk about this.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can ask me later why this is like.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is so.",
                    "label": 0
                },
                {
                    "sent": "This was my talk, so let me draw conclusions.",
                    "label": 0
                },
                {
                    "sent": "You propose here and you holistic, but it's among Chris algorithm for speeding up exact graph edit distance over her Ristic finds an optimal node and an optimal edge assignment for the unprocessed nodes and edges in polynomial time.",
                    "label": 1
                },
                {
                    "sent": "So then our heuristic helps in speeding up exact graph edit distance substantially, and the most interesting point for me is the last.",
                    "label": 1
                },
                {
                    "sent": "So the proposed heuristic can be used for fast sub optimal graph matching.",
                    "label": 0
                },
                {
                    "sent": "Procedure.",
                    "label": 0
                },
                {
                    "sent": "So this was my talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention and flat answer.",
                    "label": 0
                }
            ]
        }
    }
}