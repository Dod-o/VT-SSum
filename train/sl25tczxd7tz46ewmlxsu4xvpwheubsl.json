{
    "id": "sl25tczxd7tz46ewmlxsu4xvpwheubsl",
    "title": "Discussion of Erik Sudderth's talk: NPB Hype or Hope?",
    "info": {
        "author": [
            "Yann LeCun, Computer Science Department, New York University (NYU)"
        ],
        "published": "Jan. 24, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_lecun_discussant/",
    "segmentation": [
        [
            "Here we go OK."
        ],
        [
            "Alright, so you know MPB managers think of AP is, you know, it's hierarchical feedback processing.",
            "It's another example of analysis by synthesis, which is a sort of time honored way of doing recognition is actually actually been incredibly unsuccessful so far, at least within computer vision, in the sense that most of the models in computer vision that people came up with in the 70s eighties were actually along those lines, there were no probabilistic.",
            "They're not infinite, but they were.",
            "And that is the synthesis.",
            "They basically disappeared at least in the sort of dominant models that are being used today in computer vision.",
            "So I'm sort of concentrating towards.",
            "You guys can't even hear me, right?",
            "So.",
            "I know.",
            "I feel more authoritative like this.",
            "So you know, in Elizabeth synthesis you start from.",
            "You know some category and then you generate features and you have some sort of way of dreaming of features that you don't observe from the variables you start from because you cannot have generate pixels from say categories.",
            "If you start from the top level and it has to be the stochastic because it's a, it's a one to many mapping.",
            "Did I send me to one?",
            "It's one too many, so if you don't know how, how big to make to make your model making potential potentially infinite and rely on vision magic to save you.",
            "But you know that is best.",
            "Synthesis is very slow and MPs even slower.",
            "And for vision, when you do with pixel, it's kind of.",
            "Did you say how long it takes to run your?",
            "Think like an hour, OK?"
        ],
        [
            "Right, so if you look at so, there's always been some sort of love hate relationship between neuroscience and computer vision and and in the last 15 years or so.",
            "Sort of hate relationship with machine learning.",
            "And those are brain use MPV.",
            "So if you look at the dominant models for object recognition called so called a model of the ventral pathway for recognition, they actually completely feedforward is not to say that the brain doesn't have feedback.",
            "It has a lot of feedback.",
            "If it has more feedback and feedforward, but there's a lot of evidence that sort of very simple sort of scene parsing or recognition.",
            "Tasks that we perform as humans or animals perform are essentially feedforward there, not sort of, you know.",
            "Inference type probabilistic inference type type.",
            "Things that go on there sort of really, really fast, in fact.",
            "You know you can.",
            "Your temporal cortex is aware of which object you're looking at in less than 100 milliseconds, and if you kind of figure out how many computational steps that would take for a neuron that essentially has, you know a few milliseconds of delay.",
            "It's only a few steps.",
            "So there's no time for, you know, complicated inference algorithm for the kind of test that we do every day that you allow us to navigate around, grab things and stuff like that.",
            "So we at least have one example of a system that at least doesn't work pretty well, doesn't use MPV.",
            "Or at least four for sort of basic recognition tasks."
        ],
        [
            "So, so the the dominant model has come to to become kind of the other way around.",
            "Hierarchical feedforward processing and one reason for this is that most scenes are completely non ambiguous.",
            "You don't actually need probabilities at all, you know it's completely obvious what you know what's in the scene here to most people, and it's a.",
            "It's a minute to one mapping.",
            "There's, you know there's no need to kind of dream up things you don't observe now it's not to say that your visual system cannot actually dream up things again.",
            "It's not to say that.",
            "In ambiguous situations, you can't do things like control completion and inference.",
            "Complicated completion, in fact you're doing it right now you're you know whole part of your visual field actually doesn't have any data, because there's a bundle of fibers that goes through your eye rather that place, so you don't see it, but you know it to you.",
            "It looks like a continuous image, so somehow you know you're doing this unconsciously, or at least in the high level of representation, and it doesn't look like you're.",
            "It looks like there's been some sort of confusion going on, but you know, is it using something like in PB?"
        ],
        [
            "So so again, sort of two.",
            "Strike the nail on the head.",
            "That's the sort of dominant model for object recognition, or at least the first few stages of it.",
            "There are sort of slightly more refined steps after afterwards usually, but there are essentially.",
            "Based on sort of simple filtering, so nonlinear steps and so in future pulling, there's very little probabilistic quantities being manipulated, and you know there's kind of a stack of search filter that sort of produces categories, and you know I'm not talking particularly about things like convolutional Nets, which you would expect me to mention, but but things like, you know, learn as inexperienced Canales VM and you know sort of derived models from this, which are very widely used for all the.",
            "Computer vision competitions.",
            "When you look down deep down inside, that's pretty much what they do.",
            "There's a little bit of sort of relaxation for kind of part of models on top of it, usually."
        ],
        [
            "Um?",
            "And in fact, when you look back at where those models come from indirectly, even though the people in computer vision would not necessarily admit that.",
            "A lot of it is really inspired by neuroscience.",
            "When you look at the sort of basic architecture of this.",
            "In fact, it's based on classic work by human whistle.",
            "In the 60s, Nobel Prize winning work on the architecture of the visual cortex."
        ],
        [
            "So in effect though, when you look at sort of an ideal combination of things, what would be my ideal model of vision would be something a bit like this where you going to have both path you have the feedforward path that goes fast inference.",
            "But how the hell do you train this?",
            "And to train it you have to have some sort of generative path.",
            "That sort of producers targets for it or produces you know good inferences so that you can train the Fast forward inference.",
            "So I think in fact the Fed foreign influence is the result of some sort of, you know.",
            "Learning algorithm that relies on some sort of generative model, which I don't think is users potentially infinite models.",
            "It's you know.",
            "In the case of neuroscience, we can have a finite brain case, but but but using some sort of, you know.",
            "Something you could interpret as some sort of probabilistic inference."
        ],
        [
            "That"
        ],
        [
            "So some of the things we've done are, you know, consistent.",
            "They're not particularly cold, or you can always, you know, they sort of energy model, but you can always take exponentials of energy models and normalize them if you really want probabilities.",
            "But their bids on this idea that you want to have a fast inference path and sort of perhaps slower but more appropriate feedback mechanism to do to sort of generate targets or to reconstruct, and it's sort of a good basis for unsupervised running as as Eric mentioned.",
            "And you know, with a sort of blurry in of.",
            "Vision, you know all those models look somewhat similar with the mathematical details that are very different."
        ],
        [
            "So whenever things that that some of us have done, you know you know the other room down there perhaps is things like you know, methods that sort of combining feedforward and feedback.",
            "To build hierarchical models, but that we can so that we can run the inference both ways.",
            "But so far we've sort of concentrated on just running the inference forward and just using the feedback for training.",
            "So things like this.",
            "This is going to sequence.",
            "Anne."
        ],
        [
            "And this sequence consists in, you know, training unsupervised layer by layer and then sort of getting rid of the feedback altogether.",
            "Because you're only interested in the Fast forward inference.",
            "Eventually ethical model will keep everything, so there might be some convergence between.",
            "You know fit for modeling feedback model eventually."
        ],
        [
            "So without.",
            "Let me give you a few examples of how this works in practice, so you know, as I said, it's kind of the dominant model for object recognition and detection, so these are all kinds of pedestrian detector systems, and there's a standard set called the INRIA data set that people use for this, and most of them have to say are not probably stick at all.",
            "Some of them use kind of latent variables, structure prediction, or things of that type.",
            "Some of them use kind of elastic models, but very simple ones.",
            "With sort of movable parts, so most of them use kind of very simple features, handcrafted feature extraction and you know some sort of non maximum suppression for for detection, but this one here is.",
            "This is the best one.",
            "So this is our sort of precision recall curve backwards, so this is sort of the number of false positives for this number of positive per image and this is the miss rate and so the best systems are down there and this is our system and it's a completely feedforward, completely trained end to end.",
            "Convolutional network, which doesn't manipulate any probability whatsoever and doesn't have any kind of latent variables with so ever.",
            "Yes, talk about segmentation, yes."
        ],
        [
            "So let's talk about segmentation.",
            "So in fact I'm not going to talk about segmentation.",
            "We're going to talk about the problem that Eric originally mentioned and said he was not going to actually.",
            "Describe or whatever is more scene parsing, so C parsing is the problem of labeling every pixel of the image with the object of the category of the object it belongs to.",
            "And what you'd like is you like to do that.",
            "To do that and sort of outline the battery of the objects more less accurately, but you're less interested in getting the boundary right.",
            "And as to getting the categories right on the boundary approximately right."
        ],
        [
            "So we've used again the completely feed forward approach to this very large convolutional Nets.",
            "Also where all the features are trained.",
            "This just a succession of filters, nonlinearity and pulling on multi scaling pyramid.",
            "In fact this is work mostly done by Clima Farbe who is standing right there and."
        ],
        [
            "And you have to sort of turn your head on the side here, because this is kind of a picture of the entire system, so I don't hide it apart from you.",
            "So most of the computation is this convolutional Nets.",
            "That sort of essentially labels every region in the image by a fairly large feature vector, and that's trained supervised.",
            "With sort of labeled images from the same data set that Eric was talking about, and then there is another process on top of it.",
            "Some sort of tree kind of labeling that basically serves to sort of outline the the segments properly.",
            "And that's using a very simple sort of what we call that recover minimum optimal tree cover."
        ],
        [
            "And here is a cool thing that we basically beat everyone with this system, including the systems that are based on.",
            "You know that I can't the other way around that do sort of generate more generative model.",
            "So Professor Portugal Gold al model.",
            "Which is fairly sophisticated graphical model probability graphical model from ethnic group.",
            "And then various other other models and one difference you see is that not only your model works better, it's way way, way faster, so those things depending on the complexity of the scene will run between 10 seconds in 10 minutes.",
            "Or system runs in about 1 second on a standard laptop Macintosh.",
            "And we tested that that on various standard datasets that I use for scene parsing.",
            "So this is the age category stand for background data set which for which there is quite a bit of results and there's really two sets of results.",
            "One is pixel accuracy and the other one the other one is category accuracy.",
            "So this counts this one sort of equalizes the the contribution to the error of categories independently of how frequent they are.",
            "So here you can get pretty good results, but just guessing with the Sky and the ground is essentially.",
            "Because most of the pixels are Sky or road or whatever, whereas here you can have to detect the the objects that are fairly aware as well, and so we do quite a bit better than other techniques on the on this measure.",
            "This is another datasets actually super set of this, an with a different set of labels, but the basic images are actually the pretty much the same and again we have much better results than anybody else and this is the Barcelona data set.",
            "This one's 170 categories.",
            "Again we get better results than everybody else."
        ],
        [
            "And you know these are kind of a few examples of labelings of that system where you know you can have.",
            "This is with the 33 category example where you can detect Windows, roads, people, trees, grass fields, whatever."
        ],
        [
            "And the cool thing is that because it's all very simple calculation, we can actually implement this in hardware piece of hardware about this big they can run this thing at about 50 milliseconds per frame.",
            "So it's about, you know it's the size of my my hand.",
            "Essentially, let's go to cameras and stuck to it, and eventually you'll be able to carry this around and do full see real time full scene labeling and 50 milliseconds per frame.",
            "It's a."
        ],
        [
            "It looks like this is based on a few programmable gate array.",
            "Again the implemented by Kimura Bay and you know works pretty well.",
            "Not only the well, it works best.",
            "So that's pretty much all I wanted to say, so there's sort of a lot of competition.",
            "In the systems and you know, I realized this is more technological, an less mathematical then sort of many of you have been used to, but for for the kind of topics that are discussed here, there's very cool method, NPV, which is quite interesting.",
            "I mean there's a cool aspect of it that it allows you to essentially not worry about model selection.",
            "She's going to cool, but in practice the things we do to do feature running unsupervised.",
            "Scooting and we use prosecuting with a fixed number of features and it fixed sparsity parameter.",
            "If we use MPV we could have a potentially infinite number of features and we didn't have to.",
            "We wouldn't have to tune or sparsity parameter because that we come out naturally of vision inference, but we pay a huge price for this and the supplies are not ready to pay.",
            "And it's not clear to me that it actually makes a difference in terms of performance.",
            "If it made a difference in performance, then it may be a surprise that people would be ready to pay, but it's not clear to me that it does, and so I think it may be a challenge for this community to prove that it actually does make a difference, so it might ease a little bit the model selection procedure, but there's nothing wrong with doing cross validation.",
            "So the way we select the number of features we use on the sparsity coefficient we use is just cross validation, and so if you know so, you can think of this as a little manual and pedestrian, but on the other hand it's pretty fast and it works pretty well so.",
            "You know, I think it's a challenge to this community to show that you can do better than that with the techniques and.",
            "And you know, of course I'm putting myself on my territory here.",
            "I mean, there's a lot of applications of NPD that for which NP is by far the best thing.",
            "And you know, kind of discussing that.",
            "But but at least for perception, that's kind of that's kind of my point.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we go OK.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so you know MPB managers think of AP is, you know, it's hierarchical feedback processing.",
                    "label": 0
                },
                {
                    "sent": "It's another example of analysis by synthesis, which is a sort of time honored way of doing recognition is actually actually been incredibly unsuccessful so far, at least within computer vision, in the sense that most of the models in computer vision that people came up with in the 70s eighties were actually along those lines, there were no probabilistic.",
                    "label": 0
                },
                {
                    "sent": "They're not infinite, but they were.",
                    "label": 0
                },
                {
                    "sent": "And that is the synthesis.",
                    "label": 0
                },
                {
                    "sent": "They basically disappeared at least in the sort of dominant models that are being used today in computer vision.",
                    "label": 0
                },
                {
                    "sent": "So I'm sort of concentrating towards.",
                    "label": 0
                },
                {
                    "sent": "You guys can't even hear me, right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I know.",
                    "label": 0
                },
                {
                    "sent": "I feel more authoritative like this.",
                    "label": 0
                },
                {
                    "sent": "So you know, in Elizabeth synthesis you start from.",
                    "label": 0
                },
                {
                    "sent": "You know some category and then you generate features and you have some sort of way of dreaming of features that you don't observe from the variables you start from because you cannot have generate pixels from say categories.",
                    "label": 0
                },
                {
                    "sent": "If you start from the top level and it has to be the stochastic because it's a, it's a one to many mapping.",
                    "label": 0
                },
                {
                    "sent": "Did I send me to one?",
                    "label": 0
                },
                {
                    "sent": "It's one too many, so if you don't know how, how big to make to make your model making potential potentially infinite and rely on vision magic to save you.",
                    "label": 1
                },
                {
                    "sent": "But you know that is best.",
                    "label": 1
                },
                {
                    "sent": "Synthesis is very slow and MPs even slower.",
                    "label": 0
                },
                {
                    "sent": "And for vision, when you do with pixel, it's kind of.",
                    "label": 0
                },
                {
                    "sent": "Did you say how long it takes to run your?",
                    "label": 0
                },
                {
                    "sent": "Think like an hour, OK?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so if you look at so, there's always been some sort of love hate relationship between neuroscience and computer vision and and in the last 15 years or so.",
                    "label": 0
                },
                {
                    "sent": "Sort of hate relationship with machine learning.",
                    "label": 0
                },
                {
                    "sent": "And those are brain use MPV.",
                    "label": 1
                },
                {
                    "sent": "So if you look at the dominant models for object recognition called so called a model of the ventral pathway for recognition, they actually completely feedforward is not to say that the brain doesn't have feedback.",
                    "label": 1
                },
                {
                    "sent": "It has a lot of feedback.",
                    "label": 0
                },
                {
                    "sent": "If it has more feedback and feedforward, but there's a lot of evidence that sort of very simple sort of scene parsing or recognition.",
                    "label": 0
                },
                {
                    "sent": "Tasks that we perform as humans or animals perform are essentially feedforward there, not sort of, you know.",
                    "label": 0
                },
                {
                    "sent": "Inference type probabilistic inference type type.",
                    "label": 0
                },
                {
                    "sent": "Things that go on there sort of really, really fast, in fact.",
                    "label": 0
                },
                {
                    "sent": "You know you can.",
                    "label": 0
                },
                {
                    "sent": "Your temporal cortex is aware of which object you're looking at in less than 100 milliseconds, and if you kind of figure out how many computational steps that would take for a neuron that essentially has, you know a few milliseconds of delay.",
                    "label": 0
                },
                {
                    "sent": "It's only a few steps.",
                    "label": 0
                },
                {
                    "sent": "So there's no time for, you know, complicated inference algorithm for the kind of test that we do every day that you allow us to navigate around, grab things and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "So we at least have one example of a system that at least doesn't work pretty well, doesn't use MPV.",
                    "label": 0
                },
                {
                    "sent": "Or at least four for sort of basic recognition tasks.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so the the dominant model has come to to become kind of the other way around.",
                    "label": 0
                },
                {
                    "sent": "Hierarchical feedforward processing and one reason for this is that most scenes are completely non ambiguous.",
                    "label": 1
                },
                {
                    "sent": "You don't actually need probabilities at all, you know it's completely obvious what you know what's in the scene here to most people, and it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a minute to one mapping.",
                    "label": 0
                },
                {
                    "sent": "There's, you know there's no need to kind of dream up things you don't observe now it's not to say that your visual system cannot actually dream up things again.",
                    "label": 0
                },
                {
                    "sent": "It's not to say that.",
                    "label": 0
                },
                {
                    "sent": "In ambiguous situations, you can't do things like control completion and inference.",
                    "label": 0
                },
                {
                    "sent": "Complicated completion, in fact you're doing it right now you're you know whole part of your visual field actually doesn't have any data, because there's a bundle of fibers that goes through your eye rather that place, so you don't see it, but you know it to you.",
                    "label": 0
                },
                {
                    "sent": "It looks like a continuous image, so somehow you know you're doing this unconsciously, or at least in the high level of representation, and it doesn't look like you're.",
                    "label": 0
                },
                {
                    "sent": "It looks like there's been some sort of confusion going on, but you know, is it using something like in PB?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so again, sort of two.",
                    "label": 0
                },
                {
                    "sent": "Strike the nail on the head.",
                    "label": 0
                },
                {
                    "sent": "That's the sort of dominant model for object recognition, or at least the first few stages of it.",
                    "label": 1
                },
                {
                    "sent": "There are sort of slightly more refined steps after afterwards usually, but there are essentially.",
                    "label": 0
                },
                {
                    "sent": "Based on sort of simple filtering, so nonlinear steps and so in future pulling, there's very little probabilistic quantities being manipulated, and you know there's kind of a stack of search filter that sort of produces categories, and you know I'm not talking particularly about things like convolutional Nets, which you would expect me to mention, but but things like, you know, learn as inexperienced Canales VM and you know sort of derived models from this, which are very widely used for all the.",
                    "label": 0
                },
                {
                    "sent": "Computer vision competitions.",
                    "label": 0
                },
                {
                    "sent": "When you look down deep down inside, that's pretty much what they do.",
                    "label": 0
                },
                {
                    "sent": "There's a little bit of sort of relaxation for kind of part of models on top of it, usually.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And in fact, when you look back at where those models come from indirectly, even though the people in computer vision would not necessarily admit that.",
                    "label": 0
                },
                {
                    "sent": "A lot of it is really inspired by neuroscience.",
                    "label": 0
                },
                {
                    "sent": "When you look at the sort of basic architecture of this.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's based on classic work by human whistle.",
                    "label": 0
                },
                {
                    "sent": "In the 60s, Nobel Prize winning work on the architecture of the visual cortex.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in effect though, when you look at sort of an ideal combination of things, what would be my ideal model of vision would be something a bit like this where you going to have both path you have the feedforward path that goes fast inference.",
                    "label": 1
                },
                {
                    "sent": "But how the hell do you train this?",
                    "label": 1
                },
                {
                    "sent": "And to train it you have to have some sort of generative path.",
                    "label": 0
                },
                {
                    "sent": "That sort of producers targets for it or produces you know good inferences so that you can train the Fast forward inference.",
                    "label": 0
                },
                {
                    "sent": "So I think in fact the Fed foreign influence is the result of some sort of, you know.",
                    "label": 0
                },
                {
                    "sent": "Learning algorithm that relies on some sort of generative model, which I don't think is users potentially infinite models.",
                    "label": 0
                },
                {
                    "sent": "It's you know.",
                    "label": 0
                },
                {
                    "sent": "In the case of neuroscience, we can have a finite brain case, but but but using some sort of, you know.",
                    "label": 0
                },
                {
                    "sent": "Something you could interpret as some sort of probabilistic inference.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So some of the things we've done are, you know, consistent.",
                    "label": 0
                },
                {
                    "sent": "They're not particularly cold, or you can always, you know, they sort of energy model, but you can always take exponentials of energy models and normalize them if you really want probabilities.",
                    "label": 0
                },
                {
                    "sent": "But their bids on this idea that you want to have a fast inference path and sort of perhaps slower but more appropriate feedback mechanism to do to sort of generate targets or to reconstruct, and it's sort of a good basis for unsupervised running as as Eric mentioned.",
                    "label": 0
                },
                {
                    "sent": "And you know, with a sort of blurry in of.",
                    "label": 0
                },
                {
                    "sent": "Vision, you know all those models look somewhat similar with the mathematical details that are very different.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So whenever things that that some of us have done, you know you know the other room down there perhaps is things like you know, methods that sort of combining feedforward and feedback.",
                    "label": 0
                },
                {
                    "sent": "To build hierarchical models, but that we can so that we can run the inference both ways.",
                    "label": 0
                },
                {
                    "sent": "But so far we've sort of concentrated on just running the inference forward and just using the feedback for training.",
                    "label": 0
                },
                {
                    "sent": "So things like this.",
                    "label": 0
                },
                {
                    "sent": "This is going to sequence.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this sequence consists in, you know, training unsupervised layer by layer and then sort of getting rid of the feedback altogether.",
                    "label": 0
                },
                {
                    "sent": "Because you're only interested in the Fast forward inference.",
                    "label": 0
                },
                {
                    "sent": "Eventually ethical model will keep everything, so there might be some convergence between.",
                    "label": 0
                },
                {
                    "sent": "You know fit for modeling feedback model eventually.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So without.",
                    "label": 0
                },
                {
                    "sent": "Let me give you a few examples of how this works in practice, so you know, as I said, it's kind of the dominant model for object recognition and detection, so these are all kinds of pedestrian detector systems, and there's a standard set called the INRIA data set that people use for this, and most of them have to say are not probably stick at all.",
                    "label": 0
                },
                {
                    "sent": "Some of them use kind of latent variables, structure prediction, or things of that type.",
                    "label": 0
                },
                {
                    "sent": "Some of them use kind of elastic models, but very simple ones.",
                    "label": 0
                },
                {
                    "sent": "With sort of movable parts, so most of them use kind of very simple features, handcrafted feature extraction and you know some sort of non maximum suppression for for detection, but this one here is.",
                    "label": 0
                },
                {
                    "sent": "This is the best one.",
                    "label": 0
                },
                {
                    "sent": "So this is our sort of precision recall curve backwards, so this is sort of the number of false positives for this number of positive per image and this is the miss rate and so the best systems are down there and this is our system and it's a completely feedforward, completely trained end to end.",
                    "label": 0
                },
                {
                    "sent": "Convolutional network, which doesn't manipulate any probability whatsoever and doesn't have any kind of latent variables with so ever.",
                    "label": 0
                },
                {
                    "sent": "Yes, talk about segmentation, yes.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's talk about segmentation.",
                    "label": 0
                },
                {
                    "sent": "So in fact I'm not going to talk about segmentation.",
                    "label": 0
                },
                {
                    "sent": "We're going to talk about the problem that Eric originally mentioned and said he was not going to actually.",
                    "label": 0
                },
                {
                    "sent": "Describe or whatever is more scene parsing, so C parsing is the problem of labeling every pixel of the image with the object of the category of the object it belongs to.",
                    "label": 1
                },
                {
                    "sent": "And what you'd like is you like to do that.",
                    "label": 0
                },
                {
                    "sent": "To do that and sort of outline the battery of the objects more less accurately, but you're less interested in getting the boundary right.",
                    "label": 0
                },
                {
                    "sent": "And as to getting the categories right on the boundary approximately right.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've used again the completely feed forward approach to this very large convolutional Nets.",
                    "label": 0
                },
                {
                    "sent": "Also where all the features are trained.",
                    "label": 0
                },
                {
                    "sent": "This just a succession of filters, nonlinearity and pulling on multi scaling pyramid.",
                    "label": 0
                },
                {
                    "sent": "In fact this is work mostly done by Clima Farbe who is standing right there and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you have to sort of turn your head on the side here, because this is kind of a picture of the entire system, so I don't hide it apart from you.",
                    "label": 0
                },
                {
                    "sent": "So most of the computation is this convolutional Nets.",
                    "label": 0
                },
                {
                    "sent": "That sort of essentially labels every region in the image by a fairly large feature vector, and that's trained supervised.",
                    "label": 0
                },
                {
                    "sent": "With sort of labeled images from the same data set that Eric was talking about, and then there is another process on top of it.",
                    "label": 0
                },
                {
                    "sent": "Some sort of tree kind of labeling that basically serves to sort of outline the the segments properly.",
                    "label": 0
                },
                {
                    "sent": "And that's using a very simple sort of what we call that recover minimum optimal tree cover.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is a cool thing that we basically beat everyone with this system, including the systems that are based on.",
                    "label": 0
                },
                {
                    "sent": "You know that I can't the other way around that do sort of generate more generative model.",
                    "label": 0
                },
                {
                    "sent": "So Professor Portugal Gold al model.",
                    "label": 0
                },
                {
                    "sent": "Which is fairly sophisticated graphical model probability graphical model from ethnic group.",
                    "label": 0
                },
                {
                    "sent": "And then various other other models and one difference you see is that not only your model works better, it's way way, way faster, so those things depending on the complexity of the scene will run between 10 seconds in 10 minutes.",
                    "label": 0
                },
                {
                    "sent": "Or system runs in about 1 second on a standard laptop Macintosh.",
                    "label": 0
                },
                {
                    "sent": "And we tested that that on various standard datasets that I use for scene parsing.",
                    "label": 0
                },
                {
                    "sent": "So this is the age category stand for background data set which for which there is quite a bit of results and there's really two sets of results.",
                    "label": 0
                },
                {
                    "sent": "One is pixel accuracy and the other one the other one is category accuracy.",
                    "label": 0
                },
                {
                    "sent": "So this counts this one sort of equalizes the the contribution to the error of categories independently of how frequent they are.",
                    "label": 0
                },
                {
                    "sent": "So here you can get pretty good results, but just guessing with the Sky and the ground is essentially.",
                    "label": 0
                },
                {
                    "sent": "Because most of the pixels are Sky or road or whatever, whereas here you can have to detect the the objects that are fairly aware as well, and so we do quite a bit better than other techniques on the on this measure.",
                    "label": 0
                },
                {
                    "sent": "This is another datasets actually super set of this, an with a different set of labels, but the basic images are actually the pretty much the same and again we have much better results than anybody else and this is the Barcelona data set.",
                    "label": 0
                },
                {
                    "sent": "This one's 170 categories.",
                    "label": 0
                },
                {
                    "sent": "Again we get better results than everybody else.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you know these are kind of a few examples of labelings of that system where you know you can have.",
                    "label": 0
                },
                {
                    "sent": "This is with the 33 category example where you can detect Windows, roads, people, trees, grass fields, whatever.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the cool thing is that because it's all very simple calculation, we can actually implement this in hardware piece of hardware about this big they can run this thing at about 50 milliseconds per frame.",
                    "label": 0
                },
                {
                    "sent": "So it's about, you know it's the size of my my hand.",
                    "label": 0
                },
                {
                    "sent": "Essentially, let's go to cameras and stuck to it, and eventually you'll be able to carry this around and do full see real time full scene labeling and 50 milliseconds per frame.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It looks like this is based on a few programmable gate array.",
                    "label": 0
                },
                {
                    "sent": "Again the implemented by Kimura Bay and you know works pretty well.",
                    "label": 0
                },
                {
                    "sent": "Not only the well, it works best.",
                    "label": 0
                },
                {
                    "sent": "So that's pretty much all I wanted to say, so there's sort of a lot of competition.",
                    "label": 0
                },
                {
                    "sent": "In the systems and you know, I realized this is more technological, an less mathematical then sort of many of you have been used to, but for for the kind of topics that are discussed here, there's very cool method, NPV, which is quite interesting.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a cool aspect of it that it allows you to essentially not worry about model selection.",
                    "label": 0
                },
                {
                    "sent": "She's going to cool, but in practice the things we do to do feature running unsupervised.",
                    "label": 0
                },
                {
                    "sent": "Scooting and we use prosecuting with a fixed number of features and it fixed sparsity parameter.",
                    "label": 0
                },
                {
                    "sent": "If we use MPV we could have a potentially infinite number of features and we didn't have to.",
                    "label": 0
                },
                {
                    "sent": "We wouldn't have to tune or sparsity parameter because that we come out naturally of vision inference, but we pay a huge price for this and the supplies are not ready to pay.",
                    "label": 0
                },
                {
                    "sent": "And it's not clear to me that it actually makes a difference in terms of performance.",
                    "label": 0
                },
                {
                    "sent": "If it made a difference in performance, then it may be a surprise that people would be ready to pay, but it's not clear to me that it does, and so I think it may be a challenge for this community to prove that it actually does make a difference, so it might ease a little bit the model selection procedure, but there's nothing wrong with doing cross validation.",
                    "label": 0
                },
                {
                    "sent": "So the way we select the number of features we use on the sparsity coefficient we use is just cross validation, and so if you know so, you can think of this as a little manual and pedestrian, but on the other hand it's pretty fast and it works pretty well so.",
                    "label": 0
                },
                {
                    "sent": "You know, I think it's a challenge to this community to show that you can do better than that with the techniques and.",
                    "label": 0
                },
                {
                    "sent": "And you know, of course I'm putting myself on my territory here.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's a lot of applications of NPD that for which NP is by far the best thing.",
                    "label": 0
                },
                {
                    "sent": "And you know, kind of discussing that.",
                    "label": 0
                },
                {
                    "sent": "But but at least for perception, that's kind of that's kind of my point.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}