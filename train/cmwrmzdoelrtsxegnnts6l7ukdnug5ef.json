{
    "id": "cmwrmzdoelrtsxegnnts6l7ukdnug5ef",
    "title": "Real-time Image Enhancement Using Edge-Optimized a-trous Wavelets",
    "info": {
        "author": [
            "Hendrik Lensch, T\u00fcbingen University"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_lensch_wavelets/",
    "segmentation": [
        [
            "As you can see, I'm a computer graphics person, so my background is not in learning, so let's see what we can do with that so.",
            "What I want to present today is work we've done on edge, avoiding wavelets and we found them a extremely powerful tool for doing image processing, like getting contrast enhancement with almost no artifacts or actually getting edge preserving filtering at different levels and."
        ],
        [
            "So a brief overview.",
            "I will give her motivation of why we started looking into that process of edge awarding methods, and then introduce the problem of a true wavelet transforms edge avoiding methods at optimized bracelets for better contrast enhancement and then finally look at the some application of all that for real time.",
            "Monocular depth cue enhancement so they can actually get the information of stereo images at monocular.",
            "Images so."
        ],
        [
            "Why did we start all that?",
            "So we have the problem in computer graphics that we want to simulate light transport.",
            "That is, we are sending out light Rays or photons and want to estimate what the overall intensity is in an image.",
            "And if you have a very very short time budget, then the number of photos you can send might actually reach to that particular level.",
            "So you have a highly noisy picture.",
            "And in order to get any decent image out of that you have to do.",
            "Some image reconstruction which is denoising or in this case actually it's a averaging over some larger region and we use the edge, avoiding a true wavelets in order to get these pictures out of that.",
            "Now here you see some details which come from some other texture as well, but the overall lighting is correctly interpolated in real time."
        ],
        [
            "So even more important here, for example, in this region here there's only indirect light hitting the scene.",
            "That is very very few photons come in and you see here that we have a very sparse distribution of photons and we need a very large filter kernel in order to get a smoothed more or less correct illumination so that we can look into the interior of things.",
            "So."
        ],
        [
            "Of all, here's a real time snapshot, so this is what the global illumination produces.",
            "We can simulate light transport, but using the filtering technique we actually can produce gamma correctly looking images where we have all the global illumination effects like light bouncing off some walls, being involved, correctly reproduced, and.",
            "Here's another noisy input, so every surface you see, which is already clear here, is directly illuminated.",
            "Everything else is indirectly illuminated by one bounds of the war, for example, and after some.",
            "Real filtering we can real time get this kind of reconstruction results, which, remarkably look much better, and I'm going to get the relationship to photography, computational photography just a moment."
        ],
        [
            "So what do we have here?",
            "As an input?",
            "We do simulations of three dimensional scenes, so clearly we can relatively quickly render an image where we, for example, have the geometry that is the normal per pixel or the position per pixel involved, and then we can get this very noisy looking image from a Monte Carlo simulation and this might contain high frequency.",
            "For example forecast cheddar's which are just there due to the elimination, not as a geometry.",
            "This is our input."
        ],
        [
            "And now we went ahead and managed and created this framework which allows us to combine the given information, namely the geometry as normals and positions plus the noisy input image.",
            "Combine that using at rewarding filtering and apply that multiple times until we get a close to noise free but still feature preserving image out of that, and if he learn, apply the detail texture on top.",
            "We can even make this brick look as realistic efficient, so the question is like what is this iterative filtering like?",
            "It has to support pretty broad filters becausw here we've seen that we have very few photons in a large neighborhood and in order to get it smooth.",
            "Signal there we have to support filter sizes of let's say 100 * 100 pixels for example."
        ],
        [
            "Oh well, something you can easily do is just apply wavelet filter.",
            "That's great, fast and easy and just to give you a glimpse what we could do.",
            "We have the input pixels here we apply, for example a Goshen filter with a 4 * 4 pixel support and get on the next level filtered version.",
            "Now with the traditional decimating wavelet transform, what you would do is you would at the second level reduce your sampling rate by a factor of 2.",
            "In each dimension, of course you know you have a low frequency signal in front of you.",
            "That means at the next level you can actually apply again in four times or 5 * 5 filter in order to then produce the next higher or quarter level of your favorite, and that's what makes these decimated wavelet really really fast.",
            "Your overall effort is sort of in the order of the number of pixels times 2 actually so, but there's 11 big caveat here.",
            "Namely."
        ],
        [
            "If you do that, you lose information about spatial information of edges features.",
            "OK, so you have here, for example, one edge and the edge is now located between these two pixels.",
            "If you.",
            "Go one step further course in your way flat."
        ],
        [
            "Well, you're half your edge somewhere between this pixel and that pixel, so that gets somehow spread out, and if you go."
        ],
        [
            "One step further, you have absolutely no clue exactly where that edge was, and that's a huge difficulty for us since we would need to interpolate illumination up to the edge of an object note."
        ],
        [
            "Yeah, food so.",
            "One way would be OK, let's do simply undecimated wavelet transform.",
            "It's simple as well.",
            "We do a Gaussian filter.",
            "Get now information at every pixel.",
            "However, at the next step we would need to increase the filter size by a factor of 2.",
            "In each dimension, then, would mean we would have to filter now like four times as many samples in the next iteration, and again four times as many samples and the next answer for so forth.",
            "So if you are having a five level hierarchy, then you have like quite a number of samples to compute for every output pixel, but now you at least know where exactly the edges between those filtered pixels, so that's way too slow.",
            "Nobody will implement that in real time.",
            "But the."
        ],
        [
            "There's a trick called true wavelet transform, which simply means with holds and holds we can produce in the following way so.",
            "We have at the first level we do simply convolution with a 5 * 5 filter.",
            "Then the next level we know while our information is sort of low pass filtered.",
            "So rather than computing the next convolution on every pixel, we simply introduce holds at every other pixel.",
            "And simply convolve now with twice as large filter size but with exactly as many samples as we had in the very first iteration and in the next iteration we would have four times the filter size, but again just 5 * 5 samples under the support of this kernel to be evaluated.",
            "And now we can."
        ],
        [
            "Move that over and for every pixel will compute the result with."
        ],
        [
            "Different input pixels, so now we're actually computationally wise, almost as fast as the undecimated transform.",
            "Your sort of like factor 3 slower, but not factor 100 for example, and we have all the information we need.",
            "Adds a pixel location.",
            "So here."
        ],
        [
            "How the algorithm?",
            "Actually it could be implemented.",
            "It's extremely simple, so everything you have is you have your input signal, you compute a convolution with this convolved image.",
            "You compute the difference to your original input and then you simply iterate and now the clue was their true wavelet transform, simply as you take exactly the same filter locations, only multiply their XY locations by factor of 2.",
            "So then you get your photo and your wife.",
            "It is nothing else then all your details plus 3/4 level.",
            "If you want to do filtering now on top that is."
        ],
        [
            "You would like to change and emphasize.",
            "High frequencies or dampen them venue actually just going to do a re composition by simply using your courses level plus a scalar times your computer detail it so each detail level is nothing else than in picture full resolution picture.",
            "Storing the detail for this frequency band if you want and you can now nicely control them.",
            "What we used is our edge optimized wavelet or edge avoiding methods."
        ],
        [
            "To begin with, which is nothing else than applying a bilateral filter at each step and the bilateral filter simply takes the value difference between neighboring pixels and put this into a gorsha.",
            "And we can now actually combine multiple different features like the intensity or the normals or the positions and simply get the product of multiple of these cautions.",
            "And by that we can.",
            "Now coming from this noisy picture.",
            "Produce a smooth version where we have all the edges of the geometry correctly being preserved.",
            "So."
        ],
        [
            "Here is 1 example.",
            "We have a noisy input picture.",
            "Now this is a real photograph shot as a very short exposure time and closed aperture."
        ],
        [
            "We found sort of get in the first level.",
            "Most of the noise being separated, but we still have relatively sharp features in the course.",
            "In version he goes."
        ],
        [
            "The further you see that gets even smoother, but still having sharp features."
        ],
        [
            "And so forth and so forth.",
            "So we can do that.",
            "Lots and lots of time.",
            "Now next I want to show you."
        ],
        [
            "How different is behavior of this?",
            "Edge avoiding a true effort is compared to other wavelet transform, so we have on top here over the noisy input.",
            "This is our solution.",
            "Clearly it's not perfect, so you see low frequency wobbling up here, but this is the best you can actually get from that kind of noisy input.",
            "If you would just use traditional codici wavelets and sort of remove all higher detailed terms with that, then clearly this doesn't stop at any age.",
            "So you get this very blurry noisy.",
            "Thing out of that?"
        ],
        [
            "If you apply edge avoiding wavelets but decimated wavelet when I said you cannot represent the information where an edges anymore and this can, he can actually directly see here for example at the bottom of this.",
            "Light source there.",
            "The edge was exactly at a not so nice position for the decimated wavelet, so that you cannot keep the edge.",
            "Correctly represented and therefore you get bleeding across some edges, but some edges are still pretty sure, so this doesn't really work.",
            "Only the true version."
        ],
        [
            "And of course, one could have argued OK if you want to do smoothing, why not just apply a large bilateral filter?",
            "And that's what we try to do here.",
            "Bilateral filter is 90 * 90 pixel size produces very actively similar results.",
            "However 141 the.",
            "Time to computing and ninety 1090 bilateral filter is huge.",
            "Even though there are now techniques out which can do that in constant time, it's still difficult to do, and the other thing is.",
            "Yep, there are.",
            "Some features are not correctly represented becausw the bilateral filter can only be tuned to one kind of edges and with the multi scale approach of wavelet we were able to actually correctly adapt to all kinds of different features strength which we can find in the image.",
            "Yes, that's exactly the problem.",
            "Why you doing cannot do that with my left foot.",
            "OK, so."
        ],
        [
            "Furthermore to once again show that we really need to have the full resolution at the details.",
            "This if you want to do contrast enhancement, that is, you multiply your details with affective larger than one, and if you have this kind of checkerboard pattern, this starts a liaising with your sampling pattern of your decimated wavelet and therefore you sometimes get over bright features and sometimes averaged features so.",
            "You cannot control that for real only.",
            "If you really have it available at every pixel, you have the full information available.",
            "OK, so Speaking of contrast."
        ],
        [
            "Lancement they have to be extremely careful, namely we had.",
            "The arm, the variance to be set for the Goshen of the difference in intensity.",
            "And now this is a free parameter and parameter actually typically is just set one per image or once per level, but this actually is not sufficient to get good results.",
            "If you want to contrast enhancement if you.",
            "Take the variance to broad to week, then you actually get Halos because you approximate a sharp edge by a smooth filter version and then your differences will be added up on top and so you get the hollows.",
            "If you do it the other way round, you approximate a smooth transition by sharp transition.",
            "You get exactly the inverse effect of a gradient reversal, because then you now add negative details on top of that.",
            "And what we simply did is try to figure out per pixel what is a good edge weight, like how broad in the value range do you need to apply your bilateral filter.",
            "So."
        ],
        [
            "How do we do that?",
            "Well, this is relatively simple, So what do we want to do and reach with varying or Sigma?",
            "Would like to.",
            "Make sure that.",
            "Almost all information is kept in the core scale and very little information is transferred to the detail level.",
            "So the easiest thing would now be to say OK, the detail level should be 0, but then of course we would always take a Sigma which is so huge that we don't do any filtering at all, so therefore we have this tradeoff between reducing the detail for the next level and keeping information at the course level between or.",
            "Mott making the course level 2 noise.",
            "And if you just like apply this.",
            "Every function and just try 4 different sigmas per pixel.",
            "You actually get a very good map and then you have per pixel information of how sharp the feature is at this particular point and this can be computed at almost no time at all.",
            "If you anybody have loaded or your input data."
        ],
        [
            "And with that we can now show, for example, how the differences.",
            "So here we have standard a true wavelet transform.",
            "Here we have edge optimized transform.",
            "Clearly the course are you are.",
            "The less detail is inside your wavelet transform.",
            "OK, so.",
            "Features are gone.",
            "However, you still have relatively sharp outlines.",
            "For most of this stuff, while here with the standard caution transform, you actually get blurry and blurry blurry.",
            "If you."
        ],
        [
            "It's a detail level.",
            "You now see exactly what our edge optimization is doing, namely trying to keep as much of the edge information in the course level and very little in the detail level.",
            "So our detail layer has still some information around the edges, but only that information which cannot be transported at the next course of level anymore.",
            "And this is what makes it extremely strong too."
        ],
        [
            "Show that we actually gain information by that and have a better separation of what is detail for what is actually core information of the image and what is actually some other detail which could be removed.",
            "We try to do denoising by shrinkage, so it's clearly isn't a state of the art denoising operator, we just applied it before.",
            "It was pretty handy in our case, so you calculated the.",
            "Mean variance of the noise and then using the paper by Chung and Fetterly figured out a.",
            "Shrinking threshold which would optimize the risk of removing information from the image.",
            "But on the other hand, optimizing the risk of removing or the benefit of removing most of the noise, and this can be nicely calculated from our data from our detail level from our course level and performance, of course."
        ],
        [
            "And if you apply that, we figure out that well given this noisy input, simply a true wafer transform using this faithful shrinkage gives us this piece in R, and simply doing a different reference transform, namely Edge optimized a true, we can keep more information in the course level and therefore going to reduce and remove more of the noise."
        ],
        [
            "If you zoom in, you can clearly see the differences between the relatively good reconstruction here and the quite blurry reconstruction cause.",
            "The algorithm cannot discern between real feature and noise at that level.",
            "OK, so."
        ],
        [
            "Here's another application, so all that runs at 100 Hertz per megapixel, so we can actually in real time let's somebody age from young to old and back, so that's relatively freaky.",
            "If you look at your face and such a mirror, or at your hand and get surprised how old you already are.",
            "I think this is something which is very useful to have.",
            "For example, inside your viewfinder of your video camera, so that you know why you shoot what the picture will actually look like.",
            "So here are some."
        ],
        [
            "Yeah, zoom in on other things that we can do contrast enhancement almost without any artifacts.",
            "And we can do of."
        ],
        [
            "Hours smoothing with by preserving the edges, which simplifies the image.",
            "A large survey, for example, in computer vision algorithm can now more easily pick out the main structures.",
            "So."
        ],
        [
            "Of course I have been lots and lots of other techniques for doing contract management, and the very reason mostly very, very well performing.",
            "Paper by custom Solomon at Seacroft 2010.",
            "So we were qualitatively exactly at the same level, but we are about 100 times faster, so they used GPU implementation and we use the GPU implementation and just cause our computational load is so much less because it's simple wavelet transform.",
            "We actually perform, we are better and we could also."
        ],
        [
            "Boost the contrast even slightly further.",
            "So."
        ],
        [
            "To summarize, the benefits of edge optimization is it's fast, fast, fast, so it's like a very very powerful image processing filter which runs at 100 frames a second, and it's simple to implement, and you can have arbitrary filter sizes.",
            "You can do multi scale analysis of your images and so you can avoid ringing and so forth and so forth.",
            "Now for the remainder of my talk."
        ],
        [
            "To give to one particular application scenario.",
            "Namely, monocular depth cues.",
            "So the idea is stereo cameras are getting more and more popular, but the rim of 3D displays or even steer this place is not growing at the same size.",
            "Especially, typically the resolution of serial displays are either relatively low, have a lens array, or you have to wear shutter glasses for the stereo effect.",
            "So now the question is, what do we do with this additional information of a stereo camera and the idea we had was OK?",
            "Let's use this data information to embed depth cues into a traditional image so that we can actually."
        ],
        [
            "Get enhanced image.",
            "So here's one picture created from stereo camera where we simulated a tilt shift effect just using the desktop, and Furthermore we introduced the contrast enhance."
        ],
        [
            "And so compared to the input image of one eye."
        ],
        [
            "So if you get a completely different impression of what the scene is, how big the scene is, because here you have a shallow depth of field and a shallow depth of field typically corresponds to a scene pretty close to your eye, and therefore we get different impression at the human of what the scene size, XL."
        ],
        [
            "So.",
            "Big."
        ],
        [
            "If we have boosted the color, we have boosted the color contrast on purpose, actually."
        ],
        [
            "Yep."
        ],
        [
            "So another one is we would like to use that information and try to change the image such that we can guide where the user going to look inside the scene.",
            "OK, that could be for example useful in St applications where you have the original.",
            "Well, there's lots of detail where you can actually do depth of field rendering and local contrast enhancement, and in order to your notice objects which are close by and.",
            "Potentially dangerous, much much earlier.",
            "OK, so here is once again the difference between the person being overly sharp.",
            "I think they're here is now completely contrived to make it really visible, but it also works at very very subtle differently.",
            "So the idea is we would like to create images.",
            "Where typically humans cannot say oh this is not a real image or this not to take photograph, but they are somehow ordered and still we can guide the user towards parts of the scene to investigate those part earlier than the rest of the scene."
        ],
        [
            "And for that we need to integrate desk use.",
            "So traditionally if you close one eye, you still get a good impression of what the distance to object is, and this is due to object size.",
            "You know have learned about relations of objects and their sizes, and typically you see occlusions, so therefore you can directly say OK, this object is in front of another.",
            "And there are a couple of those properties actually can hardly be modified.",
            "However, what we can easily change is sharpness.",
            "We can blur parts of the image very easily.",
            "We can do contrast enhancement and we can do a color separation and change those all depending on the depth of the pixel.",
            "And Furthermore we can also change occlusion.",
            "The appearance of occlusion to some extent and."
        ],
        [
            "Um?",
            "Clearly all those features could be done with whatever technique you want, but we have now we went ahead and now put all that into the edge optimized wavelet transform framework.",
            "So we use actually.",
            "Edge optimized wavelets in order to be free, fine, and blur the death map, we blur and decompose.",
            "Actually, the input image and do both.",
            "A bilateral true vapor transform and Gordon are true favorite.",
            "Some form of the input image and so now combining all these different.",
            "Yeah, Bafel, it's actually we can produce local contrast enhancement Dessel field.",
            "We can change the saturation and even do unsharp masking.",
            "All that.",
            "Just based on doing a very fully transform once or twice per input image."
        ],
        [
            "So one thing we also did is we optimized our depth Maps so if you take a stereo camera and no matter what kind of stereo algorithm you choose, you typically have some holes in there.",
            "You have noise in there and we simply.",
            "Decompose the current depth estimate.",
            "In this decomposition, recognize those pixels for which we know that we don't have any reliable information, and we also decompose the original color input and then did a cross bilateral filtering in order to improve on the quality of the edges inside our depth map."
        ],
        [
            "OK, so here's like input here is typical holes.",
            "You want to see, namely, most often they do to stereo shadow.",
            "That is, one part is included and this included in another image, and there's absolutely no correspondence finding happening.",
            "However, we can very easily using the Bayflite trance."
        ],
        [
            "And fill holes of almost any size.",
            "They might still look pretty weird, but after we do the cross bilateral filtering with the real color image, we actually have all the edges of your death Maps nicely aligned with the color image, and then we have a relatively good quality depth map."
        ],
        [
            "And with the quality depth map, we can now do all kinds of depth dependent enhancements.",
            "Namely, for example, do the contrast enhancement only at the front of the church basically and remove the contrast here in background area for example.",
            "What do you do with saturation?",
            "Does it get more saturated as you get farther away?"
        ],
        [
            "That's something I'm going to show later on.",
            "OK, so here's another input and we now can also do something which is called."
        ],
        [
            "Unset my thing off the depth buffer so where we now totally artificially.",
            "Get introduced black borders around death Discontinuity's you can damn that effect in birthday."
        ],
        [
            "You did that here just now."
        ],
        [
            "To make sure that you see the effects at the same time, we also."
        ],
        [
            "Some country."
        ],
        [
            "Enhancement.",
            "And if you now carefully tune how much of which affect you actually want to show, and then you."
        ],
        [
            "It actually interesting and here we get to the contrast enhancement and color contrast.",
            "So this is a steam shot."
        ],
        [
            "And if we now reduce the contrast in the background and improve it in the foreground, you now have a.",
            "Extreme concentration of the focus of the user towards the foreground object.",
            "And this is exactly what we now wanted to."
        ],
        [
            "Figure out if we can introduce all these depth cues.",
            "Do they help in image understanding and we set up a user study where the users we were asked to find a bowl and figure out if there's a board present in the image, or if there's no more present in the image.",
            "And of course, we could sort of apply some feature detector and simply draw a frame around the ball, or pointed with the error, or highlighters brightly, but this would sort of destroy the image of war so.",
            "Therefore we wanted to sort of introduce subtle."
        ],
        [
            "Different so here you see two of the input image is not altered and sliding contrast enhanced.",
            "And then we simply had a user study asking like or measuring how quick people responded to finding the ball and so we had lots and lots of different scenes with football at different locations and make sure."
        ],
        [
            "That the user cannot learn it and it happened that clearly, as perception people would have stayed from the beginning that if you combine multiple desk use then you can actually guide the user pretty well towards a particular scene.",
            "Namely if you have depth of field plus pilot level plus conscious enhancement then you actually are can guide where and in which order the user will interpret an image.",
            "And the main idea was, however, that we don't destroy the image completely."
        ],
        [
            "So therefore we made in different tests.",
            "That is what's happening if for whatever reason, we are focusing on completely wrong part of the scene.",
            "And now we sort of here has a new picture where we did.",
            "Depth of field rendering with the bilateral filter and here with the Goron filter.",
            "And it turns out that with the bilateral filter, we actually of course can keep the servers of objects much much."
        ],
        [
            "And not surprisingly, we then actually got faster response time.",
            "That is, if we do something wrong, and estimating where the optic should be, where the user should look at, it's not so bad we still get relatively good user response.",
            "And then."
        ],
        [
            "And I want to just show you.",
            "A video relatively similar to what we've seen earlier today where we can do a refocusing, but at the same time we also ordered the.",
            "The contrast.",
            "And you actually can now see how interesting features you can actually produce by that.",
            "So at some point, even the bridge in the background will actually be sharpened, pronounced.",
            "So it's very subtle, so if I just presented you one frame of that, you probably would not object.",
            "But just like being able to control that precisely, it's something I think which opened really new realms.",
            "And it sort of shows."
        ],
        [
            "What you can do with stereo information if you just have the right processing and in my opinion the processing tool of edge warding and edge optimized wavelets is really really powerful because you can do things which have otherwise been really really complicated to achieve and quite costly computational wise and now cheap and easy to be done.",
            "And one interesting question for me, for example is since we have now these edge optimized a true wavelets.",
            "They form a very good basis and compressing or and representing image content.",
            "Very, very precisely.",
            "This must have some reflection in computational learning, where you actually anyway use priors like L1 norm or a total variation which come pretty close to that.",
            "But here you have sort of representing your data already, considering those kinds of measures.",
            "Thank you very much.",
            "So."
        ],
        [
            "Through the true and just do the non subsampled bilateral filter.",
            "Multiple times multiple times we get the exact same answer or about slower.",
            "So we do some approximation.",
            "Doing the whole EPC holds so big cause of course there is some edge information that is even after the filtered version.",
            "There is not guaranteed that the frequency is lower than the sampling rate.",
            "We improved on that by using a gadget sampling.",
            "So we didn't.",
            "We always used 5 * 5 samples per kernel, but we sort of did them so that we can hide some of the high frequencies, but otherwise it should be exactly the same, only that the biological filter version would run way way longer.",
            "So I was wondering.",
            "I mean, you're so fast.",
            "I mean, if you could try to any applications on mobile devices and cell phones.",
            "So so far we haven't tried using it on mobile devices.",
            "Um, that shouldn't be any problem at all, so we just play around now with the Tegra chip and try to apply there.",
            "It should be doable.",
            "Yeah, so the question is if there is something going on.",
            "If there are any any disadvantages?",
            "If they just explained, if you don't carefully put your samples, you might see occasionally some aliasing happening, so therefore you have to better.",
            "Yeah, take your correct sampling pattern.",
            "The others of course you have a couple of additional parameters now because you're doing a multi scale analysis and you have to fine tune those parameters.",
            "One big disadvantage is actually that you need space or memory be cause you are storing now for the true benefit transform.",
            "The image as many times as you have levels where of course the decimated wavelet sort of shrinks it down.",
            "Said you just have twice your original memory footprint.",
            "Now we have like 8 times the memory footprint, which for a 12 megapixel image can.",
            "Be hurtful.",
            "And what we're gonna stereo camera using?",
            "So we had two 1 one was the.",
            "Fuji.",
            "I thought Fuji didn't allow you to get the two images out of.",
            "I think we had that somehow arranged exactly and the other one was really just a set of Rick.",
            "Yeah.",
            "The rig worked much better becausw there.",
            "We actually were able to get control the optics or put the optics once to one particular configuration, calibrate everything while the other camera, just like constantly changed.",
            "And you doing that's offline, that's not part of your well.",
            "OK, so we didn't put any effort in that, so we took a real time stereo matching algorithm from Daimler, actually so.",
            "Did the joint bilateral upsampling yourself?",
            "It's actually no upsampling, so we got that at that resolution, we just filled it up and.",
            "OK, the question is if we if we did recoloring we.",
            "Even tried well we have tried it very initially at some point when we first played around with your true idea and.",
            "They would work fine so I didn't see any any further problem, but we haven't investigated that particular approach any further.",
            "Future directions you want to look into other things so clearly I think the future directions could be too, of course apply to mobile devices and make it available to broader for the class of algorithms, sort of by sort of optimizing it also on the CPU version or the GPU will even further there's clearly some space there.",
            "And then I hope that as soon as that's done, everybody can start playing around with it.",
            "I think the really interesting question is the question I had here where.",
            "Um?"
        ],
        [
            "How can we actually use a representation like this in order to improve on any optimization technology?",
            "So if you have, I mean we know that for example, sparsity prior typically requires you some to use some wavelet basis.",
            "I mean here we have a very particular way for basis which unfortunately slightly data dependent.",
            "Becausw those edge weights sort of depend on what kind of data you have in front of yourself.",
            "But if anyone can get him from how to fool that into the optimization, I think you now have a basis which is very, very compact afterwards and represents your data much better than any other regular basis.",
            "And therefore should have some improvements in.",
            "Yeah, in the resulting optimization.",
            "At least in efficiency.",
            "Yeah, I think just.",
            "I think what would be interesting is as a user or something like this.",
            "I think it's really cool you can do real time and move it, but of course if I was using this I would like to be able to have this as a plug in, like an after effects where I can direct where the cursor, right?",
            "That's pretty neat, I think that's the really cool part.",
            "I could edit the way I want to display my stereo image as a single image on the screen.",
            "That's quite interesting.",
            "So.",
            "Yeah, one other application which clearly probably some of you will see sooner or later is really applying this monocular depth cue thing in cars and replacing the rearview mirror, still giving some impression of death even though it's just a 2D display.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you can see, I'm a computer graphics person, so my background is not in learning, so let's see what we can do with that so.",
                    "label": 0
                },
                {
                    "sent": "What I want to present today is work we've done on edge, avoiding wavelets and we found them a extremely powerful tool for doing image processing, like getting contrast enhancement with almost no artifacts or actually getting edge preserving filtering at different levels and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a brief overview.",
                    "label": 0
                },
                {
                    "sent": "I will give her motivation of why we started looking into that process of edge awarding methods, and then introduce the problem of a true wavelet transforms edge avoiding methods at optimized bracelets for better contrast enhancement and then finally look at the some application of all that for real time.",
                    "label": 0
                },
                {
                    "sent": "Monocular depth cue enhancement so they can actually get the information of stereo images at monocular.",
                    "label": 0
                },
                {
                    "sent": "Images so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why did we start all that?",
                    "label": 0
                },
                {
                    "sent": "So we have the problem in computer graphics that we want to simulate light transport.",
                    "label": 0
                },
                {
                    "sent": "That is, we are sending out light Rays or photons and want to estimate what the overall intensity is in an image.",
                    "label": 0
                },
                {
                    "sent": "And if you have a very very short time budget, then the number of photos you can send might actually reach to that particular level.",
                    "label": 0
                },
                {
                    "sent": "So you have a highly noisy picture.",
                    "label": 0
                },
                {
                    "sent": "And in order to get any decent image out of that you have to do.",
                    "label": 0
                },
                {
                    "sent": "Some image reconstruction which is denoising or in this case actually it's a averaging over some larger region and we use the edge, avoiding a true wavelets in order to get these pictures out of that.",
                    "label": 0
                },
                {
                    "sent": "Now here you see some details which come from some other texture as well, but the overall lighting is correctly interpolated in real time.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So even more important here, for example, in this region here there's only indirect light hitting the scene.",
                    "label": 0
                },
                {
                    "sent": "That is very very few photons come in and you see here that we have a very sparse distribution of photons and we need a very large filter kernel in order to get a smoothed more or less correct illumination so that we can look into the interior of things.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of all, here's a real time snapshot, so this is what the global illumination produces.",
                    "label": 0
                },
                {
                    "sent": "We can simulate light transport, but using the filtering technique we actually can produce gamma correctly looking images where we have all the global illumination effects like light bouncing off some walls, being involved, correctly reproduced, and.",
                    "label": 0
                },
                {
                    "sent": "Here's another noisy input, so every surface you see, which is already clear here, is directly illuminated.",
                    "label": 0
                },
                {
                    "sent": "Everything else is indirectly illuminated by one bounds of the war, for example, and after some.",
                    "label": 0
                },
                {
                    "sent": "Real filtering we can real time get this kind of reconstruction results, which, remarkably look much better, and I'm going to get the relationship to photography, computational photography just a moment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do we have here?",
                    "label": 0
                },
                {
                    "sent": "As an input?",
                    "label": 0
                },
                {
                    "sent": "We do simulations of three dimensional scenes, so clearly we can relatively quickly render an image where we, for example, have the geometry that is the normal per pixel or the position per pixel involved, and then we can get this very noisy looking image from a Monte Carlo simulation and this might contain high frequency.",
                    "label": 1
                },
                {
                    "sent": "For example forecast cheddar's which are just there due to the elimination, not as a geometry.",
                    "label": 0
                },
                {
                    "sent": "This is our input.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now we went ahead and managed and created this framework which allows us to combine the given information, namely the geometry as normals and positions plus the noisy input image.",
                    "label": 0
                },
                {
                    "sent": "Combine that using at rewarding filtering and apply that multiple times until we get a close to noise free but still feature preserving image out of that, and if he learn, apply the detail texture on top.",
                    "label": 0
                },
                {
                    "sent": "We can even make this brick look as realistic efficient, so the question is like what is this iterative filtering like?",
                    "label": 0
                },
                {
                    "sent": "It has to support pretty broad filters becausw here we've seen that we have very few photons in a large neighborhood and in order to get it smooth.",
                    "label": 0
                },
                {
                    "sent": "Signal there we have to support filter sizes of let's say 100 * 100 pixels for example.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh well, something you can easily do is just apply wavelet filter.",
                    "label": 0
                },
                {
                    "sent": "That's great, fast and easy and just to give you a glimpse what we could do.",
                    "label": 0
                },
                {
                    "sent": "We have the input pixels here we apply, for example a Goshen filter with a 4 * 4 pixel support and get on the next level filtered version.",
                    "label": 0
                },
                {
                    "sent": "Now with the traditional decimating wavelet transform, what you would do is you would at the second level reduce your sampling rate by a factor of 2.",
                    "label": 1
                },
                {
                    "sent": "In each dimension, of course you know you have a low frequency signal in front of you.",
                    "label": 0
                },
                {
                    "sent": "That means at the next level you can actually apply again in four times or 5 * 5 filter in order to then produce the next higher or quarter level of your favorite, and that's what makes these decimated wavelet really really fast.",
                    "label": 0
                },
                {
                    "sent": "Your overall effort is sort of in the order of the number of pixels times 2 actually so, but there's 11 big caveat here.",
                    "label": 0
                },
                {
                    "sent": "Namely.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you do that, you lose information about spatial information of edges features.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have here, for example, one edge and the edge is now located between these two pixels.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Go one step further course in your way flat.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, you're half your edge somewhere between this pixel and that pixel, so that gets somehow spread out, and if you go.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One step further, you have absolutely no clue exactly where that edge was, and that's a huge difficulty for us since we would need to interpolate illumination up to the edge of an object note.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, food so.",
                    "label": 0
                },
                {
                    "sent": "One way would be OK, let's do simply undecimated wavelet transform.",
                    "label": 0
                },
                {
                    "sent": "It's simple as well.",
                    "label": 0
                },
                {
                    "sent": "We do a Gaussian filter.",
                    "label": 1
                },
                {
                    "sent": "Get now information at every pixel.",
                    "label": 1
                },
                {
                    "sent": "However, at the next step we would need to increase the filter size by a factor of 2.",
                    "label": 0
                },
                {
                    "sent": "In each dimension, then, would mean we would have to filter now like four times as many samples in the next iteration, and again four times as many samples and the next answer for so forth.",
                    "label": 0
                },
                {
                    "sent": "So if you are having a five level hierarchy, then you have like quite a number of samples to compute for every output pixel, but now you at least know where exactly the edges between those filtered pixels, so that's way too slow.",
                    "label": 0
                },
                {
                    "sent": "Nobody will implement that in real time.",
                    "label": 0
                },
                {
                    "sent": "But the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a trick called true wavelet transform, which simply means with holds and holds we can produce in the following way so.",
                    "label": 1
                },
                {
                    "sent": "We have at the first level we do simply convolution with a 5 * 5 filter.",
                    "label": 1
                },
                {
                    "sent": "Then the next level we know while our information is sort of low pass filtered.",
                    "label": 0
                },
                {
                    "sent": "So rather than computing the next convolution on every pixel, we simply introduce holds at every other pixel.",
                    "label": 0
                },
                {
                    "sent": "And simply convolve now with twice as large filter size but with exactly as many samples as we had in the very first iteration and in the next iteration we would have four times the filter size, but again just 5 * 5 samples under the support of this kernel to be evaluated.",
                    "label": 1
                },
                {
                    "sent": "And now we can.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move that over and for every pixel will compute the result with.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different input pixels, so now we're actually computationally wise, almost as fast as the undecimated transform.",
                    "label": 0
                },
                {
                    "sent": "Your sort of like factor 3 slower, but not factor 100 for example, and we have all the information we need.",
                    "label": 0
                },
                {
                    "sent": "Adds a pixel location.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How the algorithm?",
                    "label": 0
                },
                {
                    "sent": "Actually it could be implemented.",
                    "label": 0
                },
                {
                    "sent": "It's extremely simple, so everything you have is you have your input signal, you compute a convolution with this convolved image.",
                    "label": 0
                },
                {
                    "sent": "You compute the difference to your original input and then you simply iterate and now the clue was their true wavelet transform, simply as you take exactly the same filter locations, only multiply their XY locations by factor of 2.",
                    "label": 0
                },
                {
                    "sent": "So then you get your photo and your wife.",
                    "label": 0
                },
                {
                    "sent": "It is nothing else then all your details plus 3/4 level.",
                    "label": 0
                },
                {
                    "sent": "If you want to do filtering now on top that is.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You would like to change and emphasize.",
                    "label": 0
                },
                {
                    "sent": "High frequencies or dampen them venue actually just going to do a re composition by simply using your courses level plus a scalar times your computer detail it so each detail level is nothing else than in picture full resolution picture.",
                    "label": 0
                },
                {
                    "sent": "Storing the detail for this frequency band if you want and you can now nicely control them.",
                    "label": 0
                },
                {
                    "sent": "What we used is our edge optimized wavelet or edge avoiding methods.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To begin with, which is nothing else than applying a bilateral filter at each step and the bilateral filter simply takes the value difference between neighboring pixels and put this into a gorsha.",
                    "label": 0
                },
                {
                    "sent": "And we can now actually combine multiple different features like the intensity or the normals or the positions and simply get the product of multiple of these cautions.",
                    "label": 0
                },
                {
                    "sent": "And by that we can.",
                    "label": 0
                },
                {
                    "sent": "Now coming from this noisy picture.",
                    "label": 0
                },
                {
                    "sent": "Produce a smooth version where we have all the edges of the geometry correctly being preserved.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is 1 example.",
                    "label": 0
                },
                {
                    "sent": "We have a noisy input picture.",
                    "label": 0
                },
                {
                    "sent": "Now this is a real photograph shot as a very short exposure time and closed aperture.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We found sort of get in the first level.",
                    "label": 0
                },
                {
                    "sent": "Most of the noise being separated, but we still have relatively sharp features in the course.",
                    "label": 0
                },
                {
                    "sent": "In version he goes.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The further you see that gets even smoother, but still having sharp features.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so forth and so forth.",
                    "label": 0
                },
                {
                    "sent": "So we can do that.",
                    "label": 0
                },
                {
                    "sent": "Lots and lots of time.",
                    "label": 0
                },
                {
                    "sent": "Now next I want to show you.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How different is behavior of this?",
                    "label": 0
                },
                {
                    "sent": "Edge avoiding a true effort is compared to other wavelet transform, so we have on top here over the noisy input.",
                    "label": 1
                },
                {
                    "sent": "This is our solution.",
                    "label": 0
                },
                {
                    "sent": "Clearly it's not perfect, so you see low frequency wobbling up here, but this is the best you can actually get from that kind of noisy input.",
                    "label": 0
                },
                {
                    "sent": "If you would just use traditional codici wavelets and sort of remove all higher detailed terms with that, then clearly this doesn't stop at any age.",
                    "label": 0
                },
                {
                    "sent": "So you get this very blurry noisy.",
                    "label": 0
                },
                {
                    "sent": "Thing out of that?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you apply edge avoiding wavelets but decimated wavelet when I said you cannot represent the information where an edges anymore and this can, he can actually directly see here for example at the bottom of this.",
                    "label": 0
                },
                {
                    "sent": "Light source there.",
                    "label": 0
                },
                {
                    "sent": "The edge was exactly at a not so nice position for the decimated wavelet, so that you cannot keep the edge.",
                    "label": 0
                },
                {
                    "sent": "Correctly represented and therefore you get bleeding across some edges, but some edges are still pretty sure, so this doesn't really work.",
                    "label": 0
                },
                {
                    "sent": "Only the true version.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And of course, one could have argued OK if you want to do smoothing, why not just apply a large bilateral filter?",
                    "label": 0
                },
                {
                    "sent": "And that's what we try to do here.",
                    "label": 0
                },
                {
                    "sent": "Bilateral filter is 90 * 90 pixel size produces very actively similar results.",
                    "label": 0
                },
                {
                    "sent": "However 141 the.",
                    "label": 0
                },
                {
                    "sent": "Time to computing and ninety 1090 bilateral filter is huge.",
                    "label": 1
                },
                {
                    "sent": "Even though there are now techniques out which can do that in constant time, it's still difficult to do, and the other thing is.",
                    "label": 0
                },
                {
                    "sent": "Yep, there are.",
                    "label": 0
                },
                {
                    "sent": "Some features are not correctly represented becausw the bilateral filter can only be tuned to one kind of edges and with the multi scale approach of wavelet we were able to actually correctly adapt to all kinds of different features strength which we can find in the image.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's exactly the problem.",
                    "label": 0
                },
                {
                    "sent": "Why you doing cannot do that with my left foot.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Furthermore to once again show that we really need to have the full resolution at the details.",
                    "label": 0
                },
                {
                    "sent": "This if you want to do contrast enhancement, that is, you multiply your details with affective larger than one, and if you have this kind of checkerboard pattern, this starts a liaising with your sampling pattern of your decimated wavelet and therefore you sometimes get over bright features and sometimes averaged features so.",
                    "label": 0
                },
                {
                    "sent": "You cannot control that for real only.",
                    "label": 0
                },
                {
                    "sent": "If you really have it available at every pixel, you have the full information available.",
                    "label": 0
                },
                {
                    "sent": "OK, so Speaking of contrast.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lancement they have to be extremely careful, namely we had.",
                    "label": 0
                },
                {
                    "sent": "The arm, the variance to be set for the Goshen of the difference in intensity.",
                    "label": 0
                },
                {
                    "sent": "And now this is a free parameter and parameter actually typically is just set one per image or once per level, but this actually is not sufficient to get good results.",
                    "label": 0
                },
                {
                    "sent": "If you want to contrast enhancement if you.",
                    "label": 0
                },
                {
                    "sent": "Take the variance to broad to week, then you actually get Halos because you approximate a sharp edge by a smooth filter version and then your differences will be added up on top and so you get the hollows.",
                    "label": 0
                },
                {
                    "sent": "If you do it the other way round, you approximate a smooth transition by sharp transition.",
                    "label": 0
                },
                {
                    "sent": "You get exactly the inverse effect of a gradient reversal, because then you now add negative details on top of that.",
                    "label": 0
                },
                {
                    "sent": "And what we simply did is try to figure out per pixel what is a good edge weight, like how broad in the value range do you need to apply your bilateral filter.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, this is relatively simple, So what do we want to do and reach with varying or Sigma?",
                    "label": 0
                },
                {
                    "sent": "Would like to.",
                    "label": 0
                },
                {
                    "sent": "Make sure that.",
                    "label": 0
                },
                {
                    "sent": "Almost all information is kept in the core scale and very little information is transferred to the detail level.",
                    "label": 0
                },
                {
                    "sent": "So the easiest thing would now be to say OK, the detail level should be 0, but then of course we would always take a Sigma which is so huge that we don't do any filtering at all, so therefore we have this tradeoff between reducing the detail for the next level and keeping information at the course level between or.",
                    "label": 0
                },
                {
                    "sent": "Mott making the course level 2 noise.",
                    "label": 0
                },
                {
                    "sent": "And if you just like apply this.",
                    "label": 0
                },
                {
                    "sent": "Every function and just try 4 different sigmas per pixel.",
                    "label": 0
                },
                {
                    "sent": "You actually get a very good map and then you have per pixel information of how sharp the feature is at this particular point and this can be computed at almost no time at all.",
                    "label": 0
                },
                {
                    "sent": "If you anybody have loaded or your input data.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with that we can now show, for example, how the differences.",
                    "label": 0
                },
                {
                    "sent": "So here we have standard a true wavelet transform.",
                    "label": 0
                },
                {
                    "sent": "Here we have edge optimized transform.",
                    "label": 0
                },
                {
                    "sent": "Clearly the course are you are.",
                    "label": 0
                },
                {
                    "sent": "The less detail is inside your wavelet transform.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Features are gone.",
                    "label": 0
                },
                {
                    "sent": "However, you still have relatively sharp outlines.",
                    "label": 0
                },
                {
                    "sent": "For most of this stuff, while here with the standard caution transform, you actually get blurry and blurry blurry.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's a detail level.",
                    "label": 0
                },
                {
                    "sent": "You now see exactly what our edge optimization is doing, namely trying to keep as much of the edge information in the course level and very little in the detail level.",
                    "label": 1
                },
                {
                    "sent": "So our detail layer has still some information around the edges, but only that information which cannot be transported at the next course of level anymore.",
                    "label": 0
                },
                {
                    "sent": "And this is what makes it extremely strong too.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show that we actually gain information by that and have a better separation of what is detail for what is actually core information of the image and what is actually some other detail which could be removed.",
                    "label": 0
                },
                {
                    "sent": "We try to do denoising by shrinkage, so it's clearly isn't a state of the art denoising operator, we just applied it before.",
                    "label": 1
                },
                {
                    "sent": "It was pretty handy in our case, so you calculated the.",
                    "label": 1
                },
                {
                    "sent": "Mean variance of the noise and then using the paper by Chung and Fetterly figured out a.",
                    "label": 1
                },
                {
                    "sent": "Shrinking threshold which would optimize the risk of removing information from the image.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, optimizing the risk of removing or the benefit of removing most of the noise, and this can be nicely calculated from our data from our detail level from our course level and performance, of course.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you apply that, we figure out that well given this noisy input, simply a true wafer transform using this faithful shrinkage gives us this piece in R, and simply doing a different reference transform, namely Edge optimized a true, we can keep more information in the course level and therefore going to reduce and remove more of the noise.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you zoom in, you can clearly see the differences between the relatively good reconstruction here and the quite blurry reconstruction cause.",
                    "label": 0
                },
                {
                    "sent": "The algorithm cannot discern between real feature and noise at that level.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's another application, so all that runs at 100 Hertz per megapixel, so we can actually in real time let's somebody age from young to old and back, so that's relatively freaky.",
                    "label": 0
                },
                {
                    "sent": "If you look at your face and such a mirror, or at your hand and get surprised how old you already are.",
                    "label": 0
                },
                {
                    "sent": "I think this is something which is very useful to have.",
                    "label": 0
                },
                {
                    "sent": "For example, inside your viewfinder of your video camera, so that you know why you shoot what the picture will actually look like.",
                    "label": 0
                },
                {
                    "sent": "So here are some.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, zoom in on other things that we can do contrast enhancement almost without any artifacts.",
                    "label": 0
                },
                {
                    "sent": "And we can do of.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hours smoothing with by preserving the edges, which simplifies the image.",
                    "label": 0
                },
                {
                    "sent": "A large survey, for example, in computer vision algorithm can now more easily pick out the main structures.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course I have been lots and lots of other techniques for doing contract management, and the very reason mostly very, very well performing.",
                    "label": 0
                },
                {
                    "sent": "Paper by custom Solomon at Seacroft 2010.",
                    "label": 0
                },
                {
                    "sent": "So we were qualitatively exactly at the same level, but we are about 100 times faster, so they used GPU implementation and we use the GPU implementation and just cause our computational load is so much less because it's simple wavelet transform.",
                    "label": 0
                },
                {
                    "sent": "We actually perform, we are better and we could also.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Boost the contrast even slightly further.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To summarize, the benefits of edge optimization is it's fast, fast, fast, so it's like a very very powerful image processing filter which runs at 100 frames a second, and it's simple to implement, and you can have arbitrary filter sizes.",
                    "label": 1
                },
                {
                    "sent": "You can do multi scale analysis of your images and so you can avoid ringing and so forth and so forth.",
                    "label": 0
                },
                {
                    "sent": "Now for the remainder of my talk.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To give to one particular application scenario.",
                    "label": 0
                },
                {
                    "sent": "Namely, monocular depth cues.",
                    "label": 0
                },
                {
                    "sent": "So the idea is stereo cameras are getting more and more popular, but the rim of 3D displays or even steer this place is not growing at the same size.",
                    "label": 1
                },
                {
                    "sent": "Especially, typically the resolution of serial displays are either relatively low, have a lens array, or you have to wear shutter glasses for the stereo effect.",
                    "label": 0
                },
                {
                    "sent": "So now the question is, what do we do with this additional information of a stereo camera and the idea we had was OK?",
                    "label": 0
                },
                {
                    "sent": "Let's use this data information to embed depth cues into a traditional image so that we can actually.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get enhanced image.",
                    "label": 0
                },
                {
                    "sent": "So here's one picture created from stereo camera where we simulated a tilt shift effect just using the desktop, and Furthermore we introduced the contrast enhance.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so compared to the input image of one eye.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you get a completely different impression of what the scene is, how big the scene is, because here you have a shallow depth of field and a shallow depth of field typically corresponds to a scene pretty close to your eye, and therefore we get different impression at the human of what the scene size, XL.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Big.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we have boosted the color, we have boosted the color contrast on purpose, actually.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So another one is we would like to use that information and try to change the image such that we can guide where the user going to look inside the scene.",
                    "label": 0
                },
                {
                    "sent": "OK, that could be for example useful in St applications where you have the original.",
                    "label": 0
                },
                {
                    "sent": "Well, there's lots of detail where you can actually do depth of field rendering and local contrast enhancement, and in order to your notice objects which are close by and.",
                    "label": 0
                },
                {
                    "sent": "Potentially dangerous, much much earlier.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is once again the difference between the person being overly sharp.",
                    "label": 0
                },
                {
                    "sent": "I think they're here is now completely contrived to make it really visible, but it also works at very very subtle differently.",
                    "label": 0
                },
                {
                    "sent": "So the idea is we would like to create images.",
                    "label": 0
                },
                {
                    "sent": "Where typically humans cannot say oh this is not a real image or this not to take photograph, but they are somehow ordered and still we can guide the user towards parts of the scene to investigate those part earlier than the rest of the scene.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for that we need to integrate desk use.",
                    "label": 0
                },
                {
                    "sent": "So traditionally if you close one eye, you still get a good impression of what the distance to object is, and this is due to object size.",
                    "label": 1
                },
                {
                    "sent": "You know have learned about relations of objects and their sizes, and typically you see occlusions, so therefore you can directly say OK, this object is in front of another.",
                    "label": 0
                },
                {
                    "sent": "And there are a couple of those properties actually can hardly be modified.",
                    "label": 1
                },
                {
                    "sent": "However, what we can easily change is sharpness.",
                    "label": 0
                },
                {
                    "sent": "We can blur parts of the image very easily.",
                    "label": 0
                },
                {
                    "sent": "We can do contrast enhancement and we can do a color separation and change those all depending on the depth of the pixel.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore we can also change occlusion.",
                    "label": 0
                },
                {
                    "sent": "The appearance of occlusion to some extent and.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Clearly all those features could be done with whatever technique you want, but we have now we went ahead and now put all that into the edge optimized wavelet transform framework.",
                    "label": 0
                },
                {
                    "sent": "So we use actually.",
                    "label": 0
                },
                {
                    "sent": "Edge optimized wavelets in order to be free, fine, and blur the death map, we blur and decompose.",
                    "label": 0
                },
                {
                    "sent": "Actually, the input image and do both.",
                    "label": 0
                },
                {
                    "sent": "A bilateral true vapor transform and Gordon are true favorite.",
                    "label": 0
                },
                {
                    "sent": "Some form of the input image and so now combining all these different.",
                    "label": 0
                },
                {
                    "sent": "Yeah, Bafel, it's actually we can produce local contrast enhancement Dessel field.",
                    "label": 0
                },
                {
                    "sent": "We can change the saturation and even do unsharp masking.",
                    "label": 0
                },
                {
                    "sent": "All that.",
                    "label": 0
                },
                {
                    "sent": "Just based on doing a very fully transform once or twice per input image.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one thing we also did is we optimized our depth Maps so if you take a stereo camera and no matter what kind of stereo algorithm you choose, you typically have some holes in there.",
                    "label": 0
                },
                {
                    "sent": "You have noise in there and we simply.",
                    "label": 0
                },
                {
                    "sent": "Decompose the current depth estimate.",
                    "label": 0
                },
                {
                    "sent": "In this decomposition, recognize those pixels for which we know that we don't have any reliable information, and we also decompose the original color input and then did a cross bilateral filtering in order to improve on the quality of the edges inside our depth map.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's like input here is typical holes.",
                    "label": 0
                },
                {
                    "sent": "You want to see, namely, most often they do to stereo shadow.",
                    "label": 0
                },
                {
                    "sent": "That is, one part is included and this included in another image, and there's absolutely no correspondence finding happening.",
                    "label": 0
                },
                {
                    "sent": "However, we can very easily using the Bayflite trance.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And fill holes of almost any size.",
                    "label": 0
                },
                {
                    "sent": "They might still look pretty weird, but after we do the cross bilateral filtering with the real color image, we actually have all the edges of your death Maps nicely aligned with the color image, and then we have a relatively good quality depth map.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And with the quality depth map, we can now do all kinds of depth dependent enhancements.",
                    "label": 0
                },
                {
                    "sent": "Namely, for example, do the contrast enhancement only at the front of the church basically and remove the contrast here in background area for example.",
                    "label": 1
                },
                {
                    "sent": "What do you do with saturation?",
                    "label": 0
                },
                {
                    "sent": "Does it get more saturated as you get farther away?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's something I'm going to show later on.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's another input and we now can also do something which is called.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unset my thing off the depth buffer so where we now totally artificially.",
                    "label": 0
                },
                {
                    "sent": "Get introduced black borders around death Discontinuity's you can damn that effect in birthday.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You did that here just now.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To make sure that you see the effects at the same time, we also.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some country.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Enhancement.",
                    "label": 0
                },
                {
                    "sent": "And if you now carefully tune how much of which affect you actually want to show, and then you.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It actually interesting and here we get to the contrast enhancement and color contrast.",
                    "label": 0
                },
                {
                    "sent": "So this is a steam shot.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if we now reduce the contrast in the background and improve it in the foreground, you now have a.",
                    "label": 0
                },
                {
                    "sent": "Extreme concentration of the focus of the user towards the foreground object.",
                    "label": 0
                },
                {
                    "sent": "And this is exactly what we now wanted to.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Figure out if we can introduce all these depth cues.",
                    "label": 0
                },
                {
                    "sent": "Do they help in image understanding and we set up a user study where the users we were asked to find a bowl and figure out if there's a board present in the image, or if there's no more present in the image.",
                    "label": 0
                },
                {
                    "sent": "And of course, we could sort of apply some feature detector and simply draw a frame around the ball, or pointed with the error, or highlighters brightly, but this would sort of destroy the image of war so.",
                    "label": 0
                },
                {
                    "sent": "Therefore we wanted to sort of introduce subtle.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different so here you see two of the input image is not altered and sliding contrast enhanced.",
                    "label": 0
                },
                {
                    "sent": "And then we simply had a user study asking like or measuring how quick people responded to finding the ball and so we had lots and lots of different scenes with football at different locations and make sure.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That the user cannot learn it and it happened that clearly, as perception people would have stayed from the beginning that if you combine multiple desk use then you can actually guide the user pretty well towards a particular scene.",
                    "label": 0
                },
                {
                    "sent": "Namely if you have depth of field plus pilot level plus conscious enhancement then you actually are can guide where and in which order the user will interpret an image.",
                    "label": 0
                },
                {
                    "sent": "And the main idea was, however, that we don't destroy the image completely.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So therefore we made in different tests.",
                    "label": 0
                },
                {
                    "sent": "That is what's happening if for whatever reason, we are focusing on completely wrong part of the scene.",
                    "label": 1
                },
                {
                    "sent": "And now we sort of here has a new picture where we did.",
                    "label": 0
                },
                {
                    "sent": "Depth of field rendering with the bilateral filter and here with the Goron filter.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that with the bilateral filter, we actually of course can keep the servers of objects much much.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And not surprisingly, we then actually got faster response time.",
                    "label": 0
                },
                {
                    "sent": "That is, if we do something wrong, and estimating where the optic should be, where the user should look at, it's not so bad we still get relatively good user response.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I want to just show you.",
                    "label": 0
                },
                {
                    "sent": "A video relatively similar to what we've seen earlier today where we can do a refocusing, but at the same time we also ordered the.",
                    "label": 0
                },
                {
                    "sent": "The contrast.",
                    "label": 0
                },
                {
                    "sent": "And you actually can now see how interesting features you can actually produce by that.",
                    "label": 0
                },
                {
                    "sent": "So at some point, even the bridge in the background will actually be sharpened, pronounced.",
                    "label": 0
                },
                {
                    "sent": "So it's very subtle, so if I just presented you one frame of that, you probably would not object.",
                    "label": 0
                },
                {
                    "sent": "But just like being able to control that precisely, it's something I think which opened really new realms.",
                    "label": 0
                },
                {
                    "sent": "And it sort of shows.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you can do with stereo information if you just have the right processing and in my opinion the processing tool of edge warding and edge optimized wavelets is really really powerful because you can do things which have otherwise been really really complicated to achieve and quite costly computational wise and now cheap and easy to be done.",
                    "label": 0
                },
                {
                    "sent": "And one interesting question for me, for example is since we have now these edge optimized a true wavelets.",
                    "label": 0
                },
                {
                    "sent": "They form a very good basis and compressing or and representing image content.",
                    "label": 0
                },
                {
                    "sent": "Very, very precisely.",
                    "label": 0
                },
                {
                    "sent": "This must have some reflection in computational learning, where you actually anyway use priors like L1 norm or a total variation which come pretty close to that.",
                    "label": 0
                },
                {
                    "sent": "But here you have sort of representing your data already, considering those kinds of measures.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through the true and just do the non subsampled bilateral filter.",
                    "label": 0
                },
                {
                    "sent": "Multiple times multiple times we get the exact same answer or about slower.",
                    "label": 0
                },
                {
                    "sent": "So we do some approximation.",
                    "label": 0
                },
                {
                    "sent": "Doing the whole EPC holds so big cause of course there is some edge information that is even after the filtered version.",
                    "label": 0
                },
                {
                    "sent": "There is not guaranteed that the frequency is lower than the sampling rate.",
                    "label": 0
                },
                {
                    "sent": "We improved on that by using a gadget sampling.",
                    "label": 0
                },
                {
                    "sent": "So we didn't.",
                    "label": 0
                },
                {
                    "sent": "We always used 5 * 5 samples per kernel, but we sort of did them so that we can hide some of the high frequencies, but otherwise it should be exactly the same, only that the biological filter version would run way way longer.",
                    "label": 0
                },
                {
                    "sent": "So I was wondering.",
                    "label": 0
                },
                {
                    "sent": "I mean, you're so fast.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you could try to any applications on mobile devices and cell phones.",
                    "label": 0
                },
                {
                    "sent": "So so far we haven't tried using it on mobile devices.",
                    "label": 0
                },
                {
                    "sent": "Um, that shouldn't be any problem at all, so we just play around now with the Tegra chip and try to apply there.",
                    "label": 0
                },
                {
                    "sent": "It should be doable.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is if there is something going on.",
                    "label": 0
                },
                {
                    "sent": "If there are any any disadvantages?",
                    "label": 0
                },
                {
                    "sent": "If they just explained, if you don't carefully put your samples, you might see occasionally some aliasing happening, so therefore you have to better.",
                    "label": 0
                },
                {
                    "sent": "Yeah, take your correct sampling pattern.",
                    "label": 0
                },
                {
                    "sent": "The others of course you have a couple of additional parameters now because you're doing a multi scale analysis and you have to fine tune those parameters.",
                    "label": 0
                },
                {
                    "sent": "One big disadvantage is actually that you need space or memory be cause you are storing now for the true benefit transform.",
                    "label": 0
                },
                {
                    "sent": "The image as many times as you have levels where of course the decimated wavelet sort of shrinks it down.",
                    "label": 0
                },
                {
                    "sent": "Said you just have twice your original memory footprint.",
                    "label": 0
                },
                {
                    "sent": "Now we have like 8 times the memory footprint, which for a 12 megapixel image can.",
                    "label": 0
                },
                {
                    "sent": "Be hurtful.",
                    "label": 0
                },
                {
                    "sent": "And what we're gonna stereo camera using?",
                    "label": 0
                },
                {
                    "sent": "So we had two 1 one was the.",
                    "label": 0
                },
                {
                    "sent": "Fuji.",
                    "label": 0
                },
                {
                    "sent": "I thought Fuji didn't allow you to get the two images out of.",
                    "label": 0
                },
                {
                    "sent": "I think we had that somehow arranged exactly and the other one was really just a set of Rick.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "The rig worked much better becausw there.",
                    "label": 0
                },
                {
                    "sent": "We actually were able to get control the optics or put the optics once to one particular configuration, calibrate everything while the other camera, just like constantly changed.",
                    "label": 0
                },
                {
                    "sent": "And you doing that's offline, that's not part of your well.",
                    "label": 0
                },
                {
                    "sent": "OK, so we didn't put any effort in that, so we took a real time stereo matching algorithm from Daimler, actually so.",
                    "label": 0
                },
                {
                    "sent": "Did the joint bilateral upsampling yourself?",
                    "label": 0
                },
                {
                    "sent": "It's actually no upsampling, so we got that at that resolution, we just filled it up and.",
                    "label": 0
                },
                {
                    "sent": "OK, the question is if we if we did recoloring we.",
                    "label": 0
                },
                {
                    "sent": "Even tried well we have tried it very initially at some point when we first played around with your true idea and.",
                    "label": 0
                },
                {
                    "sent": "They would work fine so I didn't see any any further problem, but we haven't investigated that particular approach any further.",
                    "label": 0
                },
                {
                    "sent": "Future directions you want to look into other things so clearly I think the future directions could be too, of course apply to mobile devices and make it available to broader for the class of algorithms, sort of by sort of optimizing it also on the CPU version or the GPU will even further there's clearly some space there.",
                    "label": 0
                },
                {
                    "sent": "And then I hope that as soon as that's done, everybody can start playing around with it.",
                    "label": 0
                },
                {
                    "sent": "I think the really interesting question is the question I had here where.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How can we actually use a representation like this in order to improve on any optimization technology?",
                    "label": 1
                },
                {
                    "sent": "So if you have, I mean we know that for example, sparsity prior typically requires you some to use some wavelet basis.",
                    "label": 0
                },
                {
                    "sent": "I mean here we have a very particular way for basis which unfortunately slightly data dependent.",
                    "label": 0
                },
                {
                    "sent": "Becausw those edge weights sort of depend on what kind of data you have in front of yourself.",
                    "label": 0
                },
                {
                    "sent": "But if anyone can get him from how to fool that into the optimization, I think you now have a basis which is very, very compact afterwards and represents your data much better than any other regular basis.",
                    "label": 0
                },
                {
                    "sent": "And therefore should have some improvements in.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in the resulting optimization.",
                    "label": 0
                },
                {
                    "sent": "At least in efficiency.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think just.",
                    "label": 0
                },
                {
                    "sent": "I think what would be interesting is as a user or something like this.",
                    "label": 1
                },
                {
                    "sent": "I think it's really cool you can do real time and move it, but of course if I was using this I would like to be able to have this as a plug in, like an after effects where I can direct where the cursor, right?",
                    "label": 0
                },
                {
                    "sent": "That's pretty neat, I think that's the really cool part.",
                    "label": 0
                },
                {
                    "sent": "I could edit the way I want to display my stereo image as a single image on the screen.",
                    "label": 0
                },
                {
                    "sent": "That's quite interesting.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, one other application which clearly probably some of you will see sooner or later is really applying this monocular depth cue thing in cars and replacing the rearview mirror, still giving some impression of death even though it's just a 2D display.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}