{
    "id": "px4ruulyhwby5lftmlweuusyspnciu6x",
    "title": "Modeling Transition Patterns Between Events for Temporal Human Action Segmentation and Classification",
    "info": {
        "presenter": [
            "Yelin Kim, Department of Electrical Engineering and Computer Science, University of Michigan"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_kim_human_action/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "I'm getting getting Kim.",
            "I'm a PhD student at the University of Michigan, Ann Arbor, working with Professor Emily, Mower Provost.",
            "This is the work that I conducted with issue minqing seen Emily and Seaway Ann.",
            "I did this research during my summer internship last year at GE Global Research at Computer Vision Lab."
        ],
        [
            "So there are gigantic volume of video data these days due to the large camera networks that we have and wide availability of video cameras like those on our phones or on our variables like Google Glasses.",
            "And it is really important to retrieve some information from those video data in order to understand what kind of events happened during this videos.",
            "So even requ."
        ],
        [
            "This system identifies the events of interest during these large video collections.",
            "And it is important for applications in video indexing or retrievals for multimedia applications or surveillance systems.",
            "There are two essential steps in event recognition systems.",
            "Number one is the localization of events of interest, so we want to know when did the event of interest happen given the video and #2.",
            "Is the classification of the events that we want to know what actually happened during this identify temporal segments.",
            "So these two are the two essential steps for event recognition systems."
        ],
        [
            "So most of the previous methods treated this event localization where you want to find this temporal segments of event of interest and the classification of the event that you want to identify what kind of events actually happened during this temporal segment as a separate problems.",
            "The recent work.",
            "The recent work of Hawaii at Cpl 2013 found that it's actually really effective if you jointly localize and classify the events together.",
            "Because localization and classification are interrelated problems and if you can find the segmentation or localization better than you can better improve the classification performance.",
            "And at the same time, when you classify better, you can also make better or precise localization of the events as well.",
            "So these two are can be jointly segmented and classified.",
            "And the Y and showing have shown that this joint segmentation and classification can improve the performance of event recognition systems."
        ],
        [
            "The key novelty of our work, the main difference of our work, is that we tackle this doing segmentation and classification problem where we explicitly model the event transition information by introducing the two important concepts about this.",
            "Number one is the event transition segments, #2 is event transition probabilities.",
            "And we found that it can really improve the performance very well."
        ],
        [
            "So event transitions segments captures the current patterns between the two consecutive events of interest.",
            "Event transition probabilities model the transition probability between these two consecutive events.",
            "So let me get up this gram or what does it mean so?"
        ],
        [
            "Let me briefly describe why we think this event transition information is important for event recognition.",
            "A lot of facial expression recognition studies have found that when you explicitly model the onset and offset of the facial expressions, you can actually better model the system and the improve the facial expression recognition is the onset means that you have the contraction of the muscles and the strength of the expressions goes higher and the offset is when you become relaxing back and your expression become more neutral.",
            "An A lot of human behaviors actually has a lot of transition patterns.",
            "If you think about you crossing arms and chest from the resting position, there is always the transition patterns that you need to move your upper arms awkward.",
            "So there there is very hard or there's very low probability that your arms go downward, and then you can crossing arms chest on the next frame, right?",
            "So we know that there is a unique and distinguishable patterns that exist between the two consecutive events.",
            "And it's also important for human action events, because when you cursing arms and chest, there is always the nature of the human action.",
            "Is that it always highly varying, right?",
            "Like I crossing arms and chest is different from you crossing arms and chest like this, but those are all crossing arms and says that we want to identify right?",
            "So what we want to do is that use utilize and leverage this information of transitioning patterns so that we can better.",
            "You are better event, better build event recognition system for human action events."
        ],
        [
            "So the contributions of our work are threefold.",
            "Number one will propose a temporal segmentation and classification method that tackle this problem jointly using the transition patterns between the events of interest.",
            "And we improve the human action detection accuracy for the two datasets.",
            "Number one is our collected smartroom data set and #2 is the publicly available CMU Med data set.",
            "And the third is that we demonstrate the importance of transition patterns, particularly for this human action events, which is really hard to recognize forgiven video."
        ],
        [
            "So let me describe about my proposed method.",
            "So in the training phase we have this set of training videos which you know about the segmentation schemes, which means that we know where the segment happened.",
            "We know the segmentation starting and ending points as well as we know the class labels of each of the segments for the training data.",
            "So we first extract the per frame human pose estimation cues, which I'll describe at the data slide later, such as and.",
            "Then we compute the segment level features for each of the segments like mean, standard deviation and linear linear regression coefficients.",
            "So once we calculate the segment level features for each of the segments that we already have, the labels, we trained the segment SVM as similar to the method that Hawaii proposed an we learn the weights of this SVM SVM and we learn for each of the classes Y.",
            "The main difference of our training phase compared to the whys method is that our why the class label Y has this has this event transition segments where the segment on segments goes from one state to another.",
            "So there there are more segments compared to the original method of why."
        ],
        [
            "For the testing phase, let me briefly describe about the overview of the inference page and also the some of the notations so that I can describe about our formula easier so when we have a given video test video where we don't know about where did the event actually happened and how many segments actually happen.",
            "We want to find the number of segments, which means the number of segments of event of interest, which is.",
            "We represent this K and we want to find this segment point the starting and ending points of this event.",
            "Segments that we're interested in, which is denoted as St.",
            "So the starting point S1 will be the zero, which is the start of the video and the SK plus one which is the last segment will be the length of the video and we will represent segment labels.",
            "As Whitey.",
            "And this is the example for the smart data, which I'll describe in more detail later, and we have the set of normal crossing arms, arms and chest touching face, arms and hips at all those things as a event, and also the transitions from one event to the other as the transition segments."
        ],
        [
            "So more specifically, we formulate an optimization function so that we can segment an classify are based on our knowledge about the transition information.",
            "So let me briefly describe about what why this proposed in his deep lot 2013 paper.",
            "So statement teaching goal is to identify this K, which is the number of segments as T, the segmenting points an YT the segment labels.",
            "And eat all the citie term is defined as this filtering filter hingeless where you're looking at the SPM score difference between the winning class and the all the other classes other than the winning class.",
            "OK, So what he proposes to use to minimize this aside term so that the you find the winning class where you want to find the segmentation that the winning class difference is much better much higher compared to the other classes.",
            "And once you formulate this documentation goal, you can formulate this dynamic programming based on the truncated time series from X0 to frame U.",
            "So what we do, what they did was to define the this XI term for this video from zero to U as FU and that it look at this L which is the segment length of the last segment.",
            "From F U -- L plus the term, the term from U2L where where the segment length L can be from Elm into elmax where L mean is the minimum length of the training segments from our training data, an L Max is the maximum length of the segments from our training data as well.",
            "So the main difference from our work.",
            "Is that our proposed method?",
            "We utilized this wiit of ISP which is the SVM scored the winning class and then we introduced this new term which is looking at the transition probability from one segment to the other.",
            "So Gamma is just a parameter of self transition probability.",
            "And Pete, this YT is the class label of each of the segments and YT minus one is the class label of the previous segments.",
            "So what you do is that you're looking at all the transition probability of each of the segments and tried to maximize the speed of the pattern matching score of SBM as well as the transition probability from one segment to the other.",
            "So in order to solve this new segmentation goal, we need to modify the original dynamic programming method that who I introduced.",
            "So we described we define this WIT 5X minus Delta U.",
            "So this is the segment from you minus L frame to U&WY is the class label of that segment and this error term is has the has the parameter of UNL the segment length and why the segment label OK.",
            "So we define this FU&YK.",
            "So in order to solve this problem, we need to know about the each of the segment labels, right?",
            "So we define this FUYK which is which is the.",
            "The score the SVM matching score plus look transition probability of the segment.",
            "Of the given segmentation scheme for the truncate time series from zero to U and then we solve this dynamic programming too.",
            "Solve the optimization function that we define."
        ],
        [
            "So let me describe about the experimental results."
        ],
        [
            "So data that we used are two parts.",
            "Number one is the smart room data set where we collected at the GE.",
            "So this is for suspicious behavior recognition.",
            "So the actions that we have is what has been known in the social science studies that related to the suspicious behaviors.",
            "Ann because Ann we used the model algorithm which was proposed in Cpl 2013 by a stop to identify the 2D coordinate of the poses and this is a very challenging problem given the LGB camera that we have at the 2D space.",
            "So there are some variations based on your lighting or clothing and appearance.",
            "There are different estimated cues of modern algorithm for the data.",
            "So we divide this to the clean data and the noisy data for the things that we don't have a good pose estimation cues so that we can find the how our algorithm performs given the estimated cues.",
            "And we also use the same new meta data set which is publicly available data set which contains a lot of human action data."
        ],
        [
            "And as I said, our algorithm will identify the event transition segments in addition to the original segments of events of interest.",
            "So in order to compare the perform our performance with the previous method of why with make the transition from our estimated segments to the.",
            "This event segments by considering these transition segments for each of the events as the event segments and compare that with Hawaii."
        ],
        [
            "And we also for performance measure.",
            "We measured the frame level event recognition rate as well as the event level recognition late so frame level recognition rate.",
            "We just measure the precision recall and F measure and for event recognition rate we utilize this method.",
            "This rate, composed by Juan, which is the ratio of events segments that are correctly identified by counting the number of correct frames that overlaps with the event segments.",
            "50% of the event segments."
        ],
        [
            "So the this is the result of the smart room data set that I showed you all year.",
            "So when you see the clean data set when we don't have much noises in the pose estimation cues, you can see we get the significant improvement compared to the whys method.",
            "Given the action events where transition parents are important.",
            "And also for noisy data.",
            "Although the performance overall performance that both of our algorithm as well as Hawaii's algorithm is not very good due to the low quality of the post estimation in this clothing and appearance cues, we still get the improvement compared to the whys method.",
            "By utilizing this event transition information.",
            "An event.",
            "Transition segments.",
            "For steam, you met data.",
            "We also show see the improvement in.",
            "This is the example of the same new Med data set and ground.",
            "This is the grantors and our segmentation results in Hawaii's segmentation results.",
            "For each of the events documents where the color represents each of the event classes.",
            "And you can see that there are huge improvement there.",
            "Improvement from the for the frame level position and the available events level recognition rate also improved slightly, but it's not really significant as the frame level."
        ],
        [
            "Also.",
            "We analyzed that the difference in the results of CMU Med data set in the small room data that is due to the due to two reasons.",
            "So number one is the same numeric data set.",
            "The transition segments were not explicitly labeled, so it only contains the human action events segments and the neutral segment.",
            "So in order to apply, apply our method to this theme unit data set.",
            "We estimate the transition segments by making the 1/3 of each of the segments to the onset and offset, and the peak event of the four hour transition segment.",
            "And because our method, the main contribution of algorithm, is the the information that we gain from the utilizing this transition segments, the estimated transition segments were were not only can give the marginal performance gain compared to the smart room data set.",
            "Another reason is because of the difference in the visual features.",
            "So CMU MIT data is that it provides 3D or skeletons that's collected through the Connect Microsoft Connect.",
            "However, our data set is from the 2D LG camera, so the difference between the visual features results with or without death can result in this difference in the performance gain.",
            "The conclusion of our."
        ],
        [
            "Work is that we explicitly model this event transition segments which it has to be shown that in the facial expression recognition studies, and we utilize this method for human action event recognition systems, and we show that it can improve the state of the art performance on the joint segmentation and classification task.",
            "The future work includes two things.",
            "Number one is the automatic methods that can learn there's transition probabilities automatically for all set of pairwise event transitions.",
            "Rather than the predefined events documents that we already know, the transition probabilities and #2 is we're looking at this segmentation and classification of audiovisual cues, which is the main focus of my business."
        ],
        [
            "We want to thank you for the fundings for more Phil and Peter and greet you.",
            "Who are the computer Vision lab project leaders and all the members at the Computer Vision Lab at the Global Research?"
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm getting getting Kim.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at the University of Michigan, Ann Arbor, working with Professor Emily, Mower Provost.",
                    "label": 1
                },
                {
                    "sent": "This is the work that I conducted with issue minqing seen Emily and Seaway Ann.",
                    "label": 0
                },
                {
                    "sent": "I did this research during my summer internship last year at GE Global Research at Computer Vision Lab.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are gigantic volume of video data these days due to the large camera networks that we have and wide availability of video cameras like those on our phones or on our variables like Google Glasses.",
                    "label": 0
                },
                {
                    "sent": "And it is really important to retrieve some information from those video data in order to understand what kind of events happened during this videos.",
                    "label": 0
                },
                {
                    "sent": "So even requ.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This system identifies the events of interest during these large video collections.",
                    "label": 1
                },
                {
                    "sent": "And it is important for applications in video indexing or retrievals for multimedia applications or surveillance systems.",
                    "label": 0
                },
                {
                    "sent": "There are two essential steps in event recognition systems.",
                    "label": 1
                },
                {
                    "sent": "Number one is the localization of events of interest, so we want to know when did the event of interest happen given the video and #2.",
                    "label": 1
                },
                {
                    "sent": "Is the classification of the events that we want to know what actually happened during this identify temporal segments.",
                    "label": 0
                },
                {
                    "sent": "So these two are the two essential steps for event recognition systems.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So most of the previous methods treated this event localization where you want to find this temporal segments of event of interest and the classification of the event that you want to identify what kind of events actually happened during this temporal segment as a separate problems.",
                    "label": 1
                },
                {
                    "sent": "The recent work.",
                    "label": 1
                },
                {
                    "sent": "The recent work of Hawaii at Cpl 2013 found that it's actually really effective if you jointly localize and classify the events together.",
                    "label": 1
                },
                {
                    "sent": "Because localization and classification are interrelated problems and if you can find the segmentation or localization better than you can better improve the classification performance.",
                    "label": 0
                },
                {
                    "sent": "And at the same time, when you classify better, you can also make better or precise localization of the events as well.",
                    "label": 0
                },
                {
                    "sent": "So these two are can be jointly segmented and classified.",
                    "label": 0
                },
                {
                    "sent": "And the Y and showing have shown that this joint segmentation and classification can improve the performance of event recognition systems.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The key novelty of our work, the main difference of our work, is that we tackle this doing segmentation and classification problem where we explicitly model the event transition information by introducing the two important concepts about this.",
                    "label": 1
                },
                {
                    "sent": "Number one is the event transition segments, #2 is event transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "And we found that it can really improve the performance very well.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So event transitions segments captures the current patterns between the two consecutive events of interest.",
                    "label": 1
                },
                {
                    "sent": "Event transition probabilities model the transition probability between these two consecutive events.",
                    "label": 1
                },
                {
                    "sent": "So let me get up this gram or what does it mean so?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me briefly describe why we think this event transition information is important for event recognition.",
                    "label": 1
                },
                {
                    "sent": "A lot of facial expression recognition studies have found that when you explicitly model the onset and offset of the facial expressions, you can actually better model the system and the improve the facial expression recognition is the onset means that you have the contraction of the muscles and the strength of the expressions goes higher and the offset is when you become relaxing back and your expression become more neutral.",
                    "label": 1
                },
                {
                    "sent": "An A lot of human behaviors actually has a lot of transition patterns.",
                    "label": 0
                },
                {
                    "sent": "If you think about you crossing arms and chest from the resting position, there is always the transition patterns that you need to move your upper arms awkward.",
                    "label": 0
                },
                {
                    "sent": "So there there is very hard or there's very low probability that your arms go downward, and then you can crossing arms chest on the next frame, right?",
                    "label": 0
                },
                {
                    "sent": "So we know that there is a unique and distinguishable patterns that exist between the two consecutive events.",
                    "label": 0
                },
                {
                    "sent": "And it's also important for human action events, because when you cursing arms and chest, there is always the nature of the human action.",
                    "label": 0
                },
                {
                    "sent": "Is that it always highly varying, right?",
                    "label": 0
                },
                {
                    "sent": "Like I crossing arms and chest is different from you crossing arms and chest like this, but those are all crossing arms and says that we want to identify right?",
                    "label": 1
                },
                {
                    "sent": "So what we want to do is that use utilize and leverage this information of transitioning patterns so that we can better.",
                    "label": 0
                },
                {
                    "sent": "You are better event, better build event recognition system for human action events.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the contributions of our work are threefold.",
                    "label": 1
                },
                {
                    "sent": "Number one will propose a temporal segmentation and classification method that tackle this problem jointly using the transition patterns between the events of interest.",
                    "label": 1
                },
                {
                    "sent": "And we improve the human action detection accuracy for the two datasets.",
                    "label": 0
                },
                {
                    "sent": "Number one is our collected smartroom data set and #2 is the publicly available CMU Med data set.",
                    "label": 0
                },
                {
                    "sent": "And the third is that we demonstrate the importance of transition patterns, particularly for this human action events, which is really hard to recognize forgiven video.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me describe about my proposed method.",
                    "label": 1
                },
                {
                    "sent": "So in the training phase we have this set of training videos which you know about the segmentation schemes, which means that we know where the segment happened.",
                    "label": 0
                },
                {
                    "sent": "We know the segmentation starting and ending points as well as we know the class labels of each of the segments for the training data.",
                    "label": 1
                },
                {
                    "sent": "So we first extract the per frame human pose estimation cues, which I'll describe at the data slide later, such as and.",
                    "label": 0
                },
                {
                    "sent": "Then we compute the segment level features for each of the segments like mean, standard deviation and linear linear regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "So once we calculate the segment level features for each of the segments that we already have, the labels, we trained the segment SVM as similar to the method that Hawaii proposed an we learn the weights of this SVM SVM and we learn for each of the classes Y.",
                    "label": 0
                },
                {
                    "sent": "The main difference of our training phase compared to the whys method is that our why the class label Y has this has this event transition segments where the segment on segments goes from one state to another.",
                    "label": 0
                },
                {
                    "sent": "So there there are more segments compared to the original method of why.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the testing phase, let me briefly describe about the overview of the inference page and also the some of the notations so that I can describe about our formula easier so when we have a given video test video where we don't know about where did the event actually happened and how many segments actually happen.",
                    "label": 0
                },
                {
                    "sent": "We want to find the number of segments, which means the number of segments of event of interest, which is.",
                    "label": 1
                },
                {
                    "sent": "We represent this K and we want to find this segment point the starting and ending points of this event.",
                    "label": 0
                },
                {
                    "sent": "Segments that we're interested in, which is denoted as St.",
                    "label": 0
                },
                {
                    "sent": "So the starting point S1 will be the zero, which is the start of the video and the SK plus one which is the last segment will be the length of the video and we will represent segment labels.",
                    "label": 0
                },
                {
                    "sent": "As Whitey.",
                    "label": 1
                },
                {
                    "sent": "And this is the example for the smart data, which I'll describe in more detail later, and we have the set of normal crossing arms, arms and chest touching face, arms and hips at all those things as a event, and also the transitions from one event to the other as the transition segments.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So more specifically, we formulate an optimization function so that we can segment an classify are based on our knowledge about the transition information.",
                    "label": 0
                },
                {
                    "sent": "So let me briefly describe about what why this proposed in his deep lot 2013 paper.",
                    "label": 0
                },
                {
                    "sent": "So statement teaching goal is to identify this K, which is the number of segments as T, the segmenting points an YT the segment labels.",
                    "label": 0
                },
                {
                    "sent": "And eat all the citie term is defined as this filtering filter hingeless where you're looking at the SPM score difference between the winning class and the all the other classes other than the winning class.",
                    "label": 0
                },
                {
                    "sent": "OK, So what he proposes to use to minimize this aside term so that the you find the winning class where you want to find the segmentation that the winning class difference is much better much higher compared to the other classes.",
                    "label": 0
                },
                {
                    "sent": "And once you formulate this documentation goal, you can formulate this dynamic programming based on the truncated time series from X0 to frame U.",
                    "label": 0
                },
                {
                    "sent": "So what we do, what they did was to define the this XI term for this video from zero to U as FU and that it look at this L which is the segment length of the last segment.",
                    "label": 0
                },
                {
                    "sent": "From F U -- L plus the term, the term from U2L where where the segment length L can be from Elm into elmax where L mean is the minimum length of the training segments from our training data, an L Max is the maximum length of the segments from our training data as well.",
                    "label": 0
                },
                {
                    "sent": "So the main difference from our work.",
                    "label": 0
                },
                {
                    "sent": "Is that our proposed method?",
                    "label": 1
                },
                {
                    "sent": "We utilized this wiit of ISP which is the SVM scored the winning class and then we introduced this new term which is looking at the transition probability from one segment to the other.",
                    "label": 0
                },
                {
                    "sent": "So Gamma is just a parameter of self transition probability.",
                    "label": 0
                },
                {
                    "sent": "And Pete, this YT is the class label of each of the segments and YT minus one is the class label of the previous segments.",
                    "label": 0
                },
                {
                    "sent": "So what you do is that you're looking at all the transition probability of each of the segments and tried to maximize the speed of the pattern matching score of SBM as well as the transition probability from one segment to the other.",
                    "label": 0
                },
                {
                    "sent": "So in order to solve this new segmentation goal, we need to modify the original dynamic programming method that who I introduced.",
                    "label": 0
                },
                {
                    "sent": "So we described we define this WIT 5X minus Delta U.",
                    "label": 0
                },
                {
                    "sent": "So this is the segment from you minus L frame to U&WY is the class label of that segment and this error term is has the has the parameter of UNL the segment length and why the segment label OK.",
                    "label": 0
                },
                {
                    "sent": "So we define this FU&YK.",
                    "label": 0
                },
                {
                    "sent": "So in order to solve this problem, we need to know about the each of the segment labels, right?",
                    "label": 0
                },
                {
                    "sent": "So we define this FUYK which is which is the.",
                    "label": 0
                },
                {
                    "sent": "The score the SVM matching score plus look transition probability of the segment.",
                    "label": 0
                },
                {
                    "sent": "Of the given segmentation scheme for the truncate time series from zero to U and then we solve this dynamic programming too.",
                    "label": 0
                },
                {
                    "sent": "Solve the optimization function that we define.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me describe about the experimental results.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So data that we used are two parts.",
                    "label": 0
                },
                {
                    "sent": "Number one is the smart room data set where we collected at the GE.",
                    "label": 0
                },
                {
                    "sent": "So this is for suspicious behavior recognition.",
                    "label": 1
                },
                {
                    "sent": "So the actions that we have is what has been known in the social science studies that related to the suspicious behaviors.",
                    "label": 0
                },
                {
                    "sent": "Ann because Ann we used the model algorithm which was proposed in Cpl 2013 by a stop to identify the 2D coordinate of the poses and this is a very challenging problem given the LGB camera that we have at the 2D space.",
                    "label": 0
                },
                {
                    "sent": "So there are some variations based on your lighting or clothing and appearance.",
                    "label": 0
                },
                {
                    "sent": "There are different estimated cues of modern algorithm for the data.",
                    "label": 0
                },
                {
                    "sent": "So we divide this to the clean data and the noisy data for the things that we don't have a good pose estimation cues so that we can find the how our algorithm performs given the estimated cues.",
                    "label": 0
                },
                {
                    "sent": "And we also use the same new meta data set which is publicly available data set which contains a lot of human action data.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And as I said, our algorithm will identify the event transition segments in addition to the original segments of events of interest.",
                    "label": 0
                },
                {
                    "sent": "So in order to compare the perform our performance with the previous method of why with make the transition from our estimated segments to the.",
                    "label": 1
                },
                {
                    "sent": "This event segments by considering these transition segments for each of the events as the event segments and compare that with Hawaii.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we also for performance measure.",
                    "label": 0
                },
                {
                    "sent": "We measured the frame level event recognition rate as well as the event level recognition late so frame level recognition rate.",
                    "label": 0
                },
                {
                    "sent": "We just measure the precision recall and F measure and for event recognition rate we utilize this method.",
                    "label": 0
                },
                {
                    "sent": "This rate, composed by Juan, which is the ratio of events segments that are correctly identified by counting the number of correct frames that overlaps with the event segments.",
                    "label": 1
                },
                {
                    "sent": "50% of the event segments.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the this is the result of the smart room data set that I showed you all year.",
                    "label": 0
                },
                {
                    "sent": "So when you see the clean data set when we don't have much noises in the pose estimation cues, you can see we get the significant improvement compared to the whys method.",
                    "label": 0
                },
                {
                    "sent": "Given the action events where transition parents are important.",
                    "label": 0
                },
                {
                    "sent": "And also for noisy data.",
                    "label": 0
                },
                {
                    "sent": "Although the performance overall performance that both of our algorithm as well as Hawaii's algorithm is not very good due to the low quality of the post estimation in this clothing and appearance cues, we still get the improvement compared to the whys method.",
                    "label": 0
                },
                {
                    "sent": "By utilizing this event transition information.",
                    "label": 0
                },
                {
                    "sent": "An event.",
                    "label": 0
                },
                {
                    "sent": "Transition segments.",
                    "label": 0
                },
                {
                    "sent": "For steam, you met data.",
                    "label": 0
                },
                {
                    "sent": "We also show see the improvement in.",
                    "label": 0
                },
                {
                    "sent": "This is the example of the same new Med data set and ground.",
                    "label": 0
                },
                {
                    "sent": "This is the grantors and our segmentation results in Hawaii's segmentation results.",
                    "label": 0
                },
                {
                    "sent": "For each of the events documents where the color represents each of the event classes.",
                    "label": 0
                },
                {
                    "sent": "And you can see that there are huge improvement there.",
                    "label": 0
                },
                {
                    "sent": "Improvement from the for the frame level position and the available events level recognition rate also improved slightly, but it's not really significant as the frame level.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "We analyzed that the difference in the results of CMU Med data set in the small room data that is due to the due to two reasons.",
                    "label": 0
                },
                {
                    "sent": "So number one is the same numeric data set.",
                    "label": 0
                },
                {
                    "sent": "The transition segments were not explicitly labeled, so it only contains the human action events segments and the neutral segment.",
                    "label": 1
                },
                {
                    "sent": "So in order to apply, apply our method to this theme unit data set.",
                    "label": 0
                },
                {
                    "sent": "We estimate the transition segments by making the 1/3 of each of the segments to the onset and offset, and the peak event of the four hour transition segment.",
                    "label": 0
                },
                {
                    "sent": "And because our method, the main contribution of algorithm, is the the information that we gain from the utilizing this transition segments, the estimated transition segments were were not only can give the marginal performance gain compared to the smart room data set.",
                    "label": 0
                },
                {
                    "sent": "Another reason is because of the difference in the visual features.",
                    "label": 0
                },
                {
                    "sent": "So CMU MIT data is that it provides 3D or skeletons that's collected through the Connect Microsoft Connect.",
                    "label": 0
                },
                {
                    "sent": "However, our data set is from the 2D LG camera, so the difference between the visual features results with or without death can result in this difference in the performance gain.",
                    "label": 0
                },
                {
                    "sent": "The conclusion of our.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work is that we explicitly model this event transition segments which it has to be shown that in the facial expression recognition studies, and we utilize this method for human action event recognition systems, and we show that it can improve the state of the art performance on the joint segmentation and classification task.",
                    "label": 1
                },
                {
                    "sent": "The future work includes two things.",
                    "label": 0
                },
                {
                    "sent": "Number one is the automatic methods that can learn there's transition probabilities automatically for all set of pairwise event transitions.",
                    "label": 1
                },
                {
                    "sent": "Rather than the predefined events documents that we already know, the transition probabilities and #2 is we're looking at this segmentation and classification of audiovisual cues, which is the main focus of my business.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We want to thank you for the fundings for more Phil and Peter and greet you.",
                    "label": 0
                },
                {
                    "sent": "Who are the computer Vision lab project leaders and all the members at the Computer Vision Lab at the Global Research?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}