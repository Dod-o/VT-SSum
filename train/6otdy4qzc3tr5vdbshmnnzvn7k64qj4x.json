{
    "id": "6otdy4qzc3tr5vdbshmnnzvn7k64qj4x",
    "title": "Towards Scalable Critical Alert Mining",
    "info": {
        "author": [
            "Bo Zong, University of California, Santa Barbara"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_zong_alert_mining/",
    "segmentation": [
        [
            "Hi everyone, I'm both from UCSB.",
            "This talk is about one important topic.",
            "Critical alert mining."
        ],
        [
            "We are living in a world of complex systems this season.",
            "Systems could be nuclear power plants, computer networks, so software systems, aircraft systems, etc etc.",
            "While these systems are very powerful and can benefit us, they also bring risks to our daily life.",
            "Any Mail functions in this complex systems might result in serious damage to an individual or company or even public safety.",
            "For example, if something goes wrong in nuclear power plant, that might be related to disaster.",
            "At the same time, the complexity of these complex systems is very high, such that it's impossible for human beings to manually check what's going on inside of the systems.",
            "Therefore we need automated system management to manage these compact systems.",
            "To achieve automated system management, what we really do is we first deploy sensors into those complex systems to collect data about the performance of small components.",
            "Tons of data will be generated from those sensors, but the massive amount of modern data cannot directly tell us what's going on or any insight from his underlying systems.",
            "Therefore we need big data analytics to extract knowledge out of those massive amount of data and enable automated system management."
        ],
        [
            "Let's take it, yeah, why example from computer network to see what our monitoring data for more complex system.",
            "Let's say we have a data center using monitoring software, we can collect the data of about the performance of the small components.",
            "Those small components could come from application level.",
            "For example number of Mongo, DB backup jobs.",
            "They can also come from hardware level, for example SDA, right time, CPU usage and etc etc the volume.",
            "Windows monitoring data could be very large.",
            "For example, one data center of 120 servers, kind of small data center can generate more than 40 gigabyte monitoring data per day."
        ],
        [
            "To detect the malfunctions in complex systems.",
            "We really first check if the performance of small components work in a right way or not.",
            "Let's take a computer network network as example and we really will come up with some performance rules for small components for the performance of small small component violated those rules, alerts will pop up, and here just a list of example alerts.",
            "One possible, or could be number Mongo DB backup jobs is too high, or memory usage too high, etc etc.",
            "If there are few alerts, we still can handle it just manually check them one by one and fix it without without problem.",
            "However, in reality, complex systems could have many issues.",
            "For example, a data center 120 servers over example will general alot of monitoring data and from those data we can further collect more than 20 K alerts per day.",
            "Obviously we have no energy, no time to check them one by one, but what we can do is we can first check those most critical and important alerts.",
            "Now the question is, what are critical learns?",
            "Critical alerts alerts will trigger or cause a large number of other alerts in the same system."
        ],
        [
            "Here is example from data center and this is from our real data example, so relevant disk read latency at Server a trigger a large number of other alerts and this is just a few examples and you can see this alerts distributed into different servers and the impact of the weather alert propagated in the network.",
            "This alert is definitely critical if we address the problem behind this red alert or the following errors automatically disappear.",
            "Of course we should focus on this order.",
            "Now the question is how to efficiently find those critical alerts from a massive amount of modern data.",
            "This work, our work this work is aiming to address this question."
        ],
        [
            "So look, let's first have a look at the overview of our solution.",
            "This is a pipeline.",
            "We propose to enable scalable critical alert mining.",
            "In this pipeline.",
            "There are three steps.",
            "The first step we were given the history learn log or aim to learn the dependencies between small components.",
            "And we call these dependencies dependency rules.",
            "In the second step, while given the learning rules and newly incoming problems alerts, we aim to connect those alerts and build a alert graph.",
            "In the third step, well given alert graph and user issued queries, we aim to discover a critical alerts in real time.",
            "In this work, remaining focus on the 3rd part that is, given a graph and user queries, we aim to develop efficient solutions and discover the critical alerts.",
            "Since the input of the third step is alert graph, so let's first look at what are large graphs?"
        ],
        [
            "Paragraphs are directly as cyclic.",
            "And which means no cycles inside nodes, alerts derived from monitoring data.",
            "Edges indicate the probabilistic dependency between alerts.",
            "And the edges had direction.",
            "That direction is always from older alert to a younger Lord of course the weight of edges indicated probability the probability that dependency will hold.",
            "So this is example of graph.",
            "The edge from A to C of 8.9 means A has probability point night to be the cause of C. Now, given a large graph, how can we decide one alert is critical?"
        ],
        [
            "In this work we use game, so the assumption is if alert you is addressed all the alerts caused by you will disappear.",
            "Then given a subset of alerts or they will be addressed.",
            "What's the probability that an individual you will disappear?",
            "We use this equation to calculate this probability.",
            "The semantic meaning is the cause of you will disappear given S is addressed.",
            "No, given a set of alerts S address, we can define a game of S game.",
            "Ask, quantify the benefit of dressing S and this is equation.",
            "In this equation we have the function FSU function access.",
            "You quantified the impact from as to alert you.",
            "If this function F FSU is a probability, probability will discuss above the game.",
            "Where is the expected number of alerts will disappear given the alerts in S is addressed."
        ],
        [
            "Now we are ready to define critical load mining problem.",
            "Given a graph G and number of alerts, we want to get get one to get the output is subset of nodes or alerts such as the game wears is maximized.",
            "This problem is NP hard.",
            "Therefore in this work we aim to propose efficient effective approximation algorithm to address this question.",
            "Before we jump to the technical part at 1st, I have a brief discussion about related problems.",
            "In general, is that two related problems quite close to our work?",
            "WHI is influence maximization.",
            "Critical Alert mining is not sharply hard as influence maximization things are underlying alert graphs attacks.",
            "Therefore we have more opportunities to develop efficient algorithm to address this problem.",
            "The second really problem is based network influence.",
            "Creation Network influence enables fast conditional probability compute computation, but it cannot efficiently solve the top K queries, which is a situation critical load mining faces."
        ],
        [
            "Now let's come to the solution.",
            "The most straightforward solution is a naive strategy, so this general idea well give alert graph while trying to find the subset S, we decompose the search process into multiple iterations, each.",
            "Each iteration we're trying to find the alert you if we put into the result set, which will bring the largest incremental gain.",
            "In this example, at very beginning, as is empty and without a such alert, we put it inside, put into South and in the second iteration for being such alert, we put into there, and if we just want to alerts, then we're done.",
            "So the good side of this algorithms it provides an optimal solution.",
            "The drawback of this algorithm is it has serious efficiency issue.",
            "It's time complexity of this algorithm is more than quadratic time, which means if the underlying graph is very large, then it's very difficult to scale up.",
            "Now the question is, can we speed up as a greedy algorithm while we preserve the approximation ratio?",
            "Where?"
        ],
        [
            "Do this by bounden pruning algorithm.",
            "So here's the general idea.",
            "Instead of computer exact equipment.",
            "Again, for each node, let's first do some fast bound estimation.",
            "For example, for the two nodes and see we calculate their upper bound and lower bound like this, and we find the upper bound of C is even smaller than the lower bound away.",
            "Then we can simply prove it, because they can never be the one we bring largest gain.",
            "The question is, what's a good lower bound upper bound for our problem?",
            "In this work, we propose local gain as a lower bound.",
            "Some gain as upper bound, and you can find the details about these two games in your paper.",
            "The drawback of this idea is pruning is just pruning, which means in the worst cases we cannot prove anything, then it's degenerate back to the original naive algorithm.",
            "We still have the efficiency issue.",
            "The question you never mind is, can we trade a little bit approximate approximation quality for better efficiency?"
        ],
        [
            "And we do this by tree approximation.",
            "First is our observation.",
            "If the underlying alert graph is a tree instead of a general decks that even like naive greedy algorithm can run in linear time.",
            "However, in general case alert graphs decks.",
            "Which means we cannot do that.",
            "So the idea is, can we specify the learn graph into trees such as preserving most of information of the large graphs and we implement this intuition by maximum directly spanning tree, so maximum direct spanning trees are trees derived from the large graph such that they can spend all the nodes in alert graphs and some of the edges is maximized."
        ],
        [
            "So how can we get a maximum spanning tree formula graph?",
            "Here's the general general idea, so we are given a large graph.",
            "We look at look at each node and fortunate we just select the incoming edge over the largest incremental gain.",
            "In this case it's like this.",
            "And this algorithm is linear, so pretty fast.",
            "Based on history, we further estimated the game.",
            "Then based on the estimated gain, we infer critical alerts.",
            "This this algorithm is pretty fast, but it has some issues like accuracy loss is relatively high.",
            "Partially from the edge selection process.",
            "For example, if one of multiple edges, if some edges relatively smaller than the largest weight edge, it will never be get selected, which is unfair to address."
        ],
        [
            "That's issue we use.",
            "What proposed multi tree approximation.",
            "So here's the general idea.",
            "We have a large graph G and we use carefully designed sampling algorithm.",
            "Sample multiple trees from each tree we do the gain estimation.",
            "And then finally we aggregated.",
            "Those gain becomes the average gain based on the average gain.",
            "Then we do we infer the critical alerts and you can find more details about the sampling algorithm from our paper."
        ],
        [
            "So here's the summary of our algorithm.",
            "In general, BMP is faster than the baseline.",
            "The naive algorithm, however, we can see multitree approximation is even faster, but we have to pay some point one quality loss in terms of object function and a single tree extremely fast 5000 times faster.",
            "However, we have two more quality loss."
        ],
        [
            "Let me conclude my talk.",
            "First, we identify very important problem.",
            "Critical mining in a big area of automated system management.",
            "2nd, we propose a pipeline to enable scalable critical load mining.",
            "3rd Critical Alert Mining is a hard problem.",
            "In this work, we propose a practical solution which worked well in practice in our data.",
            "So here are a few directions that we want to explore in future.",
            "The first direction is about domain knowledge.",
            "In this work we didn't consider domain knowledge intuitively.",
            "If we incorporate domain knowledge into a mining process, we can further improve the quality of the discovered critical alerts.",
            "However, it's how to incorporate the domain knowledge into the mining process.",
            "It's another travel problem.",
            "Second direction is learned pattern mining.",
            "The idea is if two groups alerts following the same dependency pattern, they might come back to the same problem.",
            "If we can find such a pattern, we can build a mapping from the pattern domain to a problem that domain.",
            "Then we have the query problem.",
            "The idea is if we have already have a solution for one problem.",
            "Now if we meet this problem again, we just use existing solution solution to solve it.",
            "However, the challenges for the mining problem.",
            "What's a pattern we desire to achieve this kind of goal for the query problem is how can we query such a pattern in efficient manner?"
        ],
        [
            "So that's my talk today, and thanks for your attention and free to take questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, I'm both from UCSB.",
                    "label": 0
                },
                {
                    "sent": "This talk is about one important topic.",
                    "label": 0
                },
                {
                    "sent": "Critical alert mining.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are living in a world of complex systems this season.",
                    "label": 0
                },
                {
                    "sent": "Systems could be nuclear power plants, computer networks, so software systems, aircraft systems, etc etc.",
                    "label": 0
                },
                {
                    "sent": "While these systems are very powerful and can benefit us, they also bring risks to our daily life.",
                    "label": 0
                },
                {
                    "sent": "Any Mail functions in this complex systems might result in serious damage to an individual or company or even public safety.",
                    "label": 0
                },
                {
                    "sent": "For example, if something goes wrong in nuclear power plant, that might be related to disaster.",
                    "label": 1
                },
                {
                    "sent": "At the same time, the complexity of these complex systems is very high, such that it's impossible for human beings to manually check what's going on inside of the systems.",
                    "label": 0
                },
                {
                    "sent": "Therefore we need automated system management to manage these compact systems.",
                    "label": 0
                },
                {
                    "sent": "To achieve automated system management, what we really do is we first deploy sensors into those complex systems to collect data about the performance of small components.",
                    "label": 0
                },
                {
                    "sent": "Tons of data will be generated from those sensors, but the massive amount of modern data cannot directly tell us what's going on or any insight from his underlying systems.",
                    "label": 0
                },
                {
                    "sent": "Therefore we need big data analytics to extract knowledge out of those massive amount of data and enable automated system management.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's take it, yeah, why example from computer network to see what our monitoring data for more complex system.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have a data center using monitoring software, we can collect the data of about the performance of the small components.",
                    "label": 0
                },
                {
                    "sent": "Those small components could come from application level.",
                    "label": 0
                },
                {
                    "sent": "For example number of Mongo, DB backup jobs.",
                    "label": 1
                },
                {
                    "sent": "They can also come from hardware level, for example SDA, right time, CPU usage and etc etc the volume.",
                    "label": 0
                },
                {
                    "sent": "Windows monitoring data could be very large.",
                    "label": 1
                },
                {
                    "sent": "For example, one data center of 120 servers, kind of small data center can generate more than 40 gigabyte monitoring data per day.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To detect the malfunctions in complex systems.",
                    "label": 0
                },
                {
                    "sent": "We really first check if the performance of small components work in a right way or not.",
                    "label": 0
                },
                {
                    "sent": "Let's take a computer network network as example and we really will come up with some performance rules for small components for the performance of small small component violated those rules, alerts will pop up, and here just a list of example alerts.",
                    "label": 0
                },
                {
                    "sent": "One possible, or could be number Mongo DB backup jobs is too high, or memory usage too high, etc etc.",
                    "label": 0
                },
                {
                    "sent": "If there are few alerts, we still can handle it just manually check them one by one and fix it without without problem.",
                    "label": 0
                },
                {
                    "sent": "However, in reality, complex systems could have many issues.",
                    "label": 1
                },
                {
                    "sent": "For example, a data center 120 servers over example will general alot of monitoring data and from those data we can further collect more than 20 K alerts per day.",
                    "label": 0
                },
                {
                    "sent": "Obviously we have no energy, no time to check them one by one, but what we can do is we can first check those most critical and important alerts.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, what are critical learns?",
                    "label": 0
                },
                {
                    "sent": "Critical alerts alerts will trigger or cause a large number of other alerts in the same system.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is example from data center and this is from our real data example, so relevant disk read latency at Server a trigger a large number of other alerts and this is just a few examples and you can see this alerts distributed into different servers and the impact of the weather alert propagated in the network.",
                    "label": 0
                },
                {
                    "sent": "This alert is definitely critical if we address the problem behind this red alert or the following errors automatically disappear.",
                    "label": 0
                },
                {
                    "sent": "Of course we should focus on this order.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how to efficiently find those critical alerts from a massive amount of modern data.",
                    "label": 1
                },
                {
                    "sent": "This work, our work this work is aiming to address this question.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So look, let's first have a look at the overview of our solution.",
                    "label": 0
                },
                {
                    "sent": "This is a pipeline.",
                    "label": 0
                },
                {
                    "sent": "We propose to enable scalable critical alert mining.",
                    "label": 1
                },
                {
                    "sent": "In this pipeline.",
                    "label": 0
                },
                {
                    "sent": "There are three steps.",
                    "label": 0
                },
                {
                    "sent": "The first step we were given the history learn log or aim to learn the dependencies between small components.",
                    "label": 1
                },
                {
                    "sent": "And we call these dependencies dependency rules.",
                    "label": 0
                },
                {
                    "sent": "In the second step, while given the learning rules and newly incoming problems alerts, we aim to connect those alerts and build a alert graph.",
                    "label": 0
                },
                {
                    "sent": "In the third step, well given alert graph and user issued queries, we aim to discover a critical alerts in real time.",
                    "label": 1
                },
                {
                    "sent": "In this work, remaining focus on the 3rd part that is, given a graph and user queries, we aim to develop efficient solutions and discover the critical alerts.",
                    "label": 0
                },
                {
                    "sent": "Since the input of the third step is alert graph, so let's first look at what are large graphs?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Paragraphs are directly as cyclic.",
                    "label": 0
                },
                {
                    "sent": "And which means no cycles inside nodes, alerts derived from monitoring data.",
                    "label": 1
                },
                {
                    "sent": "Edges indicate the probabilistic dependency between alerts.",
                    "label": 1
                },
                {
                    "sent": "And the edges had direction.",
                    "label": 0
                },
                {
                    "sent": "That direction is always from older alert to a younger Lord of course the weight of edges indicated probability the probability that dependency will hold.",
                    "label": 0
                },
                {
                    "sent": "So this is example of graph.",
                    "label": 0
                },
                {
                    "sent": "The edge from A to C of 8.9 means A has probability point night to be the cause of C. Now, given a large graph, how can we decide one alert is critical?",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this work we use game, so the assumption is if alert you is addressed all the alerts caused by you will disappear.",
                    "label": 0
                },
                {
                    "sent": "Then given a subset of alerts or they will be addressed.",
                    "label": 1
                },
                {
                    "sent": "What's the probability that an individual you will disappear?",
                    "label": 1
                },
                {
                    "sent": "We use this equation to calculate this probability.",
                    "label": 0
                },
                {
                    "sent": "The semantic meaning is the cause of you will disappear given S is addressed.",
                    "label": 1
                },
                {
                    "sent": "No, given a set of alerts S address, we can define a game of S game.",
                    "label": 1
                },
                {
                    "sent": "Ask, quantify the benefit of dressing S and this is equation.",
                    "label": 0
                },
                {
                    "sent": "In this equation we have the function FSU function access.",
                    "label": 0
                },
                {
                    "sent": "You quantified the impact from as to alert you.",
                    "label": 0
                },
                {
                    "sent": "If this function F FSU is a probability, probability will discuss above the game.",
                    "label": 0
                },
                {
                    "sent": "Where is the expected number of alerts will disappear given the alerts in S is addressed.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we are ready to define critical load mining problem.",
                    "label": 0
                },
                {
                    "sent": "Given a graph G and number of alerts, we want to get get one to get the output is subset of nodes or alerts such as the game wears is maximized.",
                    "label": 0
                },
                {
                    "sent": "This problem is NP hard.",
                    "label": 0
                },
                {
                    "sent": "Therefore in this work we aim to propose efficient effective approximation algorithm to address this question.",
                    "label": 0
                },
                {
                    "sent": "Before we jump to the technical part at 1st, I have a brief discussion about related problems.",
                    "label": 0
                },
                {
                    "sent": "In general, is that two related problems quite close to our work?",
                    "label": 0
                },
                {
                    "sent": "WHI is influence maximization.",
                    "label": 0
                },
                {
                    "sent": "Critical Alert mining is not sharply hard as influence maximization things are underlying alert graphs attacks.",
                    "label": 1
                },
                {
                    "sent": "Therefore we have more opportunities to develop efficient algorithm to address this problem.",
                    "label": 0
                },
                {
                    "sent": "The second really problem is based network influence.",
                    "label": 1
                },
                {
                    "sent": "Creation Network influence enables fast conditional probability compute computation, but it cannot efficiently solve the top K queries, which is a situation critical load mining faces.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's come to the solution.",
                    "label": 0
                },
                {
                    "sent": "The most straightforward solution is a naive strategy, so this general idea well give alert graph while trying to find the subset S, we decompose the search process into multiple iterations, each.",
                    "label": 0
                },
                {
                    "sent": "Each iteration we're trying to find the alert you if we put into the result set, which will bring the largest incremental gain.",
                    "label": 1
                },
                {
                    "sent": "In this example, at very beginning, as is empty and without a such alert, we put it inside, put into South and in the second iteration for being such alert, we put into there, and if we just want to alerts, then we're done.",
                    "label": 0
                },
                {
                    "sent": "So the good side of this algorithms it provides an optimal solution.",
                    "label": 1
                },
                {
                    "sent": "The drawback of this algorithm is it has serious efficiency issue.",
                    "label": 0
                },
                {
                    "sent": "It's time complexity of this algorithm is more than quadratic time, which means if the underlying graph is very large, then it's very difficult to scale up.",
                    "label": 1
                },
                {
                    "sent": "Now the question is, can we speed up as a greedy algorithm while we preserve the approximation ratio?",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do this by bounden pruning algorithm.",
                    "label": 1
                },
                {
                    "sent": "So here's the general idea.",
                    "label": 0
                },
                {
                    "sent": "Instead of computer exact equipment.",
                    "label": 0
                },
                {
                    "sent": "Again, for each node, let's first do some fast bound estimation.",
                    "label": 0
                },
                {
                    "sent": "For example, for the two nodes and see we calculate their upper bound and lower bound like this, and we find the upper bound of C is even smaller than the lower bound away.",
                    "label": 0
                },
                {
                    "sent": "Then we can simply prove it, because they can never be the one we bring largest gain.",
                    "label": 0
                },
                {
                    "sent": "The question is, what's a good lower bound upper bound for our problem?",
                    "label": 0
                },
                {
                    "sent": "In this work, we propose local gain as a lower bound.",
                    "label": 0
                },
                {
                    "sent": "Some gain as upper bound, and you can find the details about these two games in your paper.",
                    "label": 0
                },
                {
                    "sent": "The drawback of this idea is pruning is just pruning, which means in the worst cases we cannot prove anything, then it's degenerate back to the original naive algorithm.",
                    "label": 0
                },
                {
                    "sent": "We still have the efficiency issue.",
                    "label": 0
                },
                {
                    "sent": "The question you never mind is, can we trade a little bit approximate approximation quality for better efficiency?",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we do this by tree approximation.",
                    "label": 0
                },
                {
                    "sent": "First is our observation.",
                    "label": 0
                },
                {
                    "sent": "If the underlying alert graph is a tree instead of a general decks that even like naive greedy algorithm can run in linear time.",
                    "label": 1
                },
                {
                    "sent": "However, in general case alert graphs decks.",
                    "label": 0
                },
                {
                    "sent": "Which means we cannot do that.",
                    "label": 0
                },
                {
                    "sent": "So the idea is, can we specify the learn graph into trees such as preserving most of information of the large graphs and we implement this intuition by maximum directly spanning tree, so maximum direct spanning trees are trees derived from the large graph such that they can spend all the nodes in alert graphs and some of the edges is maximized.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can we get a maximum spanning tree formula graph?",
                    "label": 1
                },
                {
                    "sent": "Here's the general general idea, so we are given a large graph.",
                    "label": 0
                },
                {
                    "sent": "We look at look at each node and fortunate we just select the incoming edge over the largest incremental gain.",
                    "label": 0
                },
                {
                    "sent": "In this case it's like this.",
                    "label": 0
                },
                {
                    "sent": "And this algorithm is linear, so pretty fast.",
                    "label": 0
                },
                {
                    "sent": "Based on history, we further estimated the game.",
                    "label": 0
                },
                {
                    "sent": "Then based on the estimated gain, we infer critical alerts.",
                    "label": 1
                },
                {
                    "sent": "This this algorithm is pretty fast, but it has some issues like accuracy loss is relatively high.",
                    "label": 1
                },
                {
                    "sent": "Partially from the edge selection process.",
                    "label": 0
                },
                {
                    "sent": "For example, if one of multiple edges, if some edges relatively smaller than the largest weight edge, it will never be get selected, which is unfair to address.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's issue we use.",
                    "label": 0
                },
                {
                    "sent": "What proposed multi tree approximation.",
                    "label": 0
                },
                {
                    "sent": "So here's the general idea.",
                    "label": 0
                },
                {
                    "sent": "We have a large graph G and we use carefully designed sampling algorithm.",
                    "label": 0
                },
                {
                    "sent": "Sample multiple trees from each tree we do the gain estimation.",
                    "label": 1
                },
                {
                    "sent": "And then finally we aggregated.",
                    "label": 0
                },
                {
                    "sent": "Those gain becomes the average gain based on the average gain.",
                    "label": 0
                },
                {
                    "sent": "Then we do we infer the critical alerts and you can find more details about the sampling algorithm from our paper.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the summary of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "In general, BMP is faster than the baseline.",
                    "label": 1
                },
                {
                    "sent": "The naive algorithm, however, we can see multitree approximation is even faster, but we have to pay some point one quality loss in terms of object function and a single tree extremely fast 5000 times faster.",
                    "label": 1
                },
                {
                    "sent": "However, we have two more quality loss.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me conclude my talk.",
                    "label": 0
                },
                {
                    "sent": "First, we identify very important problem.",
                    "label": 0
                },
                {
                    "sent": "Critical mining in a big area of automated system management.",
                    "label": 0
                },
                {
                    "sent": "2nd, we propose a pipeline to enable scalable critical load mining.",
                    "label": 0
                },
                {
                    "sent": "3rd Critical Alert Mining is a hard problem.",
                    "label": 1
                },
                {
                    "sent": "In this work, we propose a practical solution which worked well in practice in our data.",
                    "label": 0
                },
                {
                    "sent": "So here are a few directions that we want to explore in future.",
                    "label": 0
                },
                {
                    "sent": "The first direction is about domain knowledge.",
                    "label": 0
                },
                {
                    "sent": "In this work we didn't consider domain knowledge intuitively.",
                    "label": 0
                },
                {
                    "sent": "If we incorporate domain knowledge into a mining process, we can further improve the quality of the discovered critical alerts.",
                    "label": 0
                },
                {
                    "sent": "However, it's how to incorporate the domain knowledge into the mining process.",
                    "label": 0
                },
                {
                    "sent": "It's another travel problem.",
                    "label": 0
                },
                {
                    "sent": "Second direction is learned pattern mining.",
                    "label": 0
                },
                {
                    "sent": "The idea is if two groups alerts following the same dependency pattern, they might come back to the same problem.",
                    "label": 1
                },
                {
                    "sent": "If we can find such a pattern, we can build a mapping from the pattern domain to a problem that domain.",
                    "label": 0
                },
                {
                    "sent": "Then we have the query problem.",
                    "label": 1
                },
                {
                    "sent": "The idea is if we have already have a solution for one problem.",
                    "label": 0
                },
                {
                    "sent": "Now if we meet this problem again, we just use existing solution solution to solve it.",
                    "label": 0
                },
                {
                    "sent": "However, the challenges for the mining problem.",
                    "label": 0
                },
                {
                    "sent": "What's a pattern we desire to achieve this kind of goal for the query problem is how can we query such a pattern in efficient manner?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's my talk today, and thanks for your attention and free to take questions.",
                    "label": 0
                }
            ]
        }
    }
}