{
    "id": "4mxkjajop4vuctvrwrccyeit4pl35nmb",
    "title": "Fourier-Information Duality in the Identity Management Problem",
    "info": {
        "author": [
            "Xiaoye Jiang, Institute for Computational and Mathematical Engineering, Stanford University"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_jiang_fourier/",
    "segmentation": [
        [
            "So let's start with a simple illustration of the identity management problem.",
            "The identity management problem arise from multi object tracking context.",
            "Suppose we have several moving targets that move in a sensor field an as those people move around.",
            "Sometimes their positions may get too close to each other.",
            "When such things happen, we may unable to tell who is who.",
            "But later on we may observe some identities on particular position, as in this example, where we have observed goofy assert as the third position, and this observation evidence actually can help us to clarify the ambiguities in the associations about target identities with their social associate with positions.",
            "Because if we want to ask the question, where is the best we can answer this question?"
        ],
        [
            "Because if we look closely at the track, four will see that only possible position that base can end up would be the third and fourth position, since one of them has already been occupied by Goofy.",
            "So this has to be end up in the in the in the last position.",
            "So this simple illustration example actually reflects some combinatorial properties in our problem.",
            "If we reason both in the mixing events and observation events together, this can help us to clarify the associations about target identity with their positions."
        ],
        [
            "So existing approaches for model, the uncertainties in the identity management problem.",
            "They model using distributions over permutations.",
            "So the permutations are all bijective mappings from one to N to one to lamely they map from identity's, want to end two positions 12 N. And of course there are in factorial permutations which is grows super exponentially fast.",
            "That will make the problem on trackable for all but very small N. So existing approaches for compact summarizing distributions over this big space of permutations fall into many two categories.",
            "The Fourier approach and the information approach."
        ],
        [
            "So our contributions in this work are threefold.",
            "So first of all we identify that duality relationship exists in the free approach with information approach and 2nd we explore the problem of converting from one form of representation to the other and based on the converting problem.",
            "So the solution of the converting problem would design A hybrid approach.",
            "Where we adaptively use either free approach or information approach to help keep track of the associations about the identity's with their positions."
        ],
        [
            "So let's begin with the free approach.",
            "So the free approach works by collapsing a distribution over permutations by summarizing using low order marginals.",
            "So let's say if we have a permutation of three people identities of three people with associate with their positions, we have a distribution of three factorials base which is 6 numbers an we can summarize the distribution of the six numbers by using a three by three table, where the IG entry of the table summarizes the marginal probability of that of A is mapped to one, for example.",
            "The margin properties just summation of the of the distribution over permutations that that the permutation Maps 8 one.",
            "So this approach you will see that by using all the square numbers you competitive summarize the distribution over permutations."
        ],
        [
            "But since you use only in fact and square numbers to summarize the distribution over over permutations, which also is of a factorial size, of course you lose something, so it turns out the 1st order marginal can be generalized to higher order cases where we summarize the distribution using second order marginals which we use actually North of order N squared by N squared user matrix of size.",
            "In square by square, where the entry actually represents the marginal probability of a pair of targets is mapped to a pair of positions.",
            "And by using only still polynomial number of numbers, we actually can still completely summarize the distribution over permutations.",
            "Of course, such an approach can be generalized to NTH order, but if we use NTH order marginal, we are exactly storing the explicitly the distribution, so there is a trade off between the complexity and accuracy."
        ],
        [
            "On the other hand, information approach works by parameterized distribution over permutations using exponential family.",
            "Basically, if we.",
            "For example, let's say the 1st order information matrix, which is of size N by N, and if we want to know the probability that ABC is mapped to 134 that we're going to extract the corresponding entries in the information matrix and sum them up and takes potential.",
            "Here, the probability is only proportional because we need to use the normalizing constant, which is a summation of all these exponentials so that the probability.",
            "It goes to one so that really means the probability."
        ],
        [
            "Asian."
        ],
        [
            "An of course, such information approach can be generalized to high orders, where we use 2nd order or third order high order information matrix to parameterized distribution over permutations.",
            "So now we have two forms of representation.",
            "One is Fourier, the other information and now the question arises of how do we?",
            "How about these two representations fit into the operations required for the identity management problem in terms of accuracy and complexity?"
        ],
        [
            "So a commonly used model for modeling the identity management problem is this Markov model, where we actually we have two components, essential components in the model where one is called the mixing model where such a mixing model characterized targets may swap their identity tracksmith swept their identity with certain probability which model the mixing events were two targets make.",
            "They can't get too close to each other and there is another component called the observation model where certain identity or particular position is observed.",
            "And our problem is going to maintain distribution posterior distribution over permutations that keep track of the associations between target identities with their positions."
        ],
        [
            "So let's look at the mixing model.",
            "Well, a simple mixing model can take the form of convolution, where if we assume that for example 22 tracks may swap their identity's IJ and then we have a distribution over permutations that with probability P nothing happens and with probability 1 -- P the IJ may swap an after this.",
            "After using this mixing model, we are going to update the distribution over associations of identities to tracks using the convolution.",
            "Anne."
        ],
        [
            "An A simple example to illustrate the idea is that suppose originally the distribution H over which the assignment of ABC 2 tracks 123 is just.",
            "It's just indicated distribution means we are sure that ABC are located at one to three respectively, an.",
            "Now if a mixing event happens, which means track one to make swap their identity's, then we're going to convolve the distribution edge with M. Which welcome to get the distribution of the mixing or become .5 if of Sigma if Sigma equals ABC map to 123 and .5 if ABC map 2213."
        ],
        [
            "It turns out if we use the Fourier approach to compare summarize the distribution of mutations where we are actually using a lower order marginal to summarize the distribution over permutations, then originally the marginal for little edge is the capital edge here, which is a identity matrix an the lower the marginal for M for the little M is the capital M. Where it's a mixing matrix, it turns out after the mixing event, we can still actually accurately represent the marginal distribution.",
            "The posterior using the low order marginals, but such a property does not hold for the information approach where actually we are going to use.",
            "1st Order information metrics are not enough to accurately represent the distribution after the mixing event."
        ],
        [
            "So we have the two propositions where the first proposition is talking about the Fourier approach on the mixing event where the marginal can be still marginal can be still accurately represented by the further information approach this is."
        ],
        [
            "Not the case.",
            "We have for the observation model, well, a typical observation says that we observe Red Bull on track one, and now we are going to look at the color histogram of the identity's.",
            "Suppose ABC has certain amount of color colors in their history histograms respectively.",
            "Then we are going to build a likelihood function based on the color histogram information and we are going to perform.",
            "Up base in posterior to calculate the posterior distribution.",
            "Anne."
        ],
        [
            "It turns out that in contrary to the, in contrast to the mixing model, the observation model actually the information representation, can accurately accurately characterize the distribution.",
            "But for the Fourier, it cannot, using only first lower order information cannot compactly summarize the distribution.",
            "So in this sense, the mixing model free approach is good.",
            "Information approach is bad, but for the observation model it's the other way around."
        ],
        [
            "There are certain some other.",
            "Operations that we need to do with the with the two approach.",
            "For example, we we often need to do normalizing, normalizing, computing and normalizing constant so that the distribution actually sums up equal to 1.",
            "It turns out the normalizing step is quite easy for the free approach, but it's very hard for the information approach and also based on the representation we summarize on the permutations we.",
            "Want to find out which Sigma which permutation is a large, has the largest probability.",
            "It turns out this problem is a maximizing maximal matching problem for both foreign information approach."
        ],
        [
            "So here this table summarizes the complexity for the two approaches on the two on the four operations required for the modeling, the identity management problem we actually see.",
            "There are some duality relationship exists where fully approach is good for mixing by baffle.",
            "Observation while the information approach is doing."
        ],
        [
            "An also we can explore some more deep theoretical results about the two representations, so it turns out the free approach is doing.",
            "We are essentially doing our two projection of a distribution over permutations.",
            "Too low order frequency subspaces, so it's an L2 projection, but the information representation we are essentially projecting a distribution to a linear subspace using a kind of different metric.",
            "Of KL divergent metric, where if we have a distribution edge when we can project Edge to a low order subspace represented by Q using the KL divergent metric and turns out solution of this optimization program, the information form representation naturally arise."
        ],
        [
            "So basically, because of both forms can be can be interpreted as projections, too low order subspaces.",
            "We have.",
            "The Pythagorean theorem holds for both cases where the magic actually different for Fourier anevo information, where for the Fourier the metric we are using our two.",
            "But for the information we are going to use a K or diverges."
        ],
        [
            "So now I'm going to talk about the hybrid approach, where we essentially need to figure out how to switch between the two domains.",
            "And it turns out, given the information matrix, we can calculate the marginal by this expression, where the perm actually means the permanent of a matrix, whereas you may, as all you should know, that determinant is a summation of.",
            "Of products of entries that lie in different rows and columns, and there is a factor of minus 1 to the power of number, depends on whether the permutation is even or odd.",
            "The permanent matrix permanent is just removing the minus one power factor where it's just summation of all products of entries that like in different rows and columns.",
            "An so for the.",
            "For the other way around where we have marginal probability Q, we can also compute the information matrix by solving this optimization program where we we solve for distribution Q that whose marginal is exactly exactly capital Q but using.",
            "Kill diversions matrix.",
            "So it turns out."
        ],
        [
            "In both the conversion from Fourier to information or the other way around, there is a.",
            "Essential step involved in converting that is computing the matrix permanent.",
            "Things out there are.",
            "Well, metric permanent, quite unlucky from the matrix determinant.",
            "It's very hard to compute.",
            "It's actually shown to be NP hard where there are so naive algorithm will scale super exponentially.",
            "But there was a cleverly.",
            "Design algorithm called Riser algorithm which is known to be the fast so far that scales exponentially.",
            "Luckily there are some FP Ross algorithm or some belief propagation algorithm which can.",
            "Perform very good in practice that can approximate the matrix permanent very fast.",
            "And also for the problem of whether we should switch from one form of representation to the other.",
            "There are certain rules that we can consider.",
            "For example, we can consider based on the accuracy since phrase accurate for mixing an information is accurate for observation.",
            "So we can based on the accuracy to decide which domain which form of representation to use.",
            "And there are other.",
            "Considerations such as smoothness based switching or lock box, which is that we tested in our experiments where the smoothness switching is basically because the free approach is good at characterizing smooth distributions while the information is good at capitalizing picky distributions, we can.",
            "George, which formal representation to use based on the smoothness of the distribution.",
            "Anlab block switching is just look her time steps to see which.",
            "Formal representation should we use?",
            "And last we can for practical use of the of the most forms of representation to keep track of the associations we can adaptive factorized problems into smaller sizes, because if we if we really see the data, real data of several moving targets targets moving in the diploid sensor networks, you will typically see that certain targets.",
            "To move together and then separate again.",
            "So I mean, there are some clustering behavior that exists in the movement patterns which we can explore to divide, design, divide and conquer."
        ],
        [
            "Ouch.",
            "So we actually simulate some data from the game game engine an there are complexity complex, very complex move movement patterns in the simulation an from the simulated data we can control the mixing event and observation event.",
            "Say whenever two persons to get too close to each other.",
            "We claim there was a mixing vent and whenever a person is separate from all the other target, we claim their result observation event."
        ],
        [
            "Here the two plots actually shows some running time analysis.",
            "Results so the first left plot is about the matrix permanent computation, where there are two.",
            "Two algorithm, namely not even a riser algorithm which scale at least exponentially.",
            "So they really scales very bad and they cannot handle very large and but for the.",
            "Irrational belief propagation algorithm.",
            "They can still scale quite well an by using the hybrid approach we typically see the running time of the hybrid approach behave well.",
            "The running time for the hybrid approach is longer than the free and information alone, but typically it's lower than some high order free approach.",
            "Let's say second order or third order free approach.",
            "This is due to the fact that the conversion between 2 forms of representation is really time."
        ],
        [
            "Doing however, if you look at the accuracy of the of the different approaches will see typically see that the hyper approach in law in lots of cases can beat.",
            "Either free approach or information approach alone.",
            "This is because if you use only one formal representation, errors may propagate where we quickly.",
            "If, for example, if you use Fourier approach in the in the observation steps, errors may propagate very, very quick."
        ],
        [
            "And to see this, we actually keep track of the errors in distribution.",
            "I mean in the space of permutations where the white intervals actually denote the mixing mixing events, while the great interval.",
            "Actually they know the condition the condition survey for the observation models.",
            "So we will typically see the the free approach where here is depicting red color.",
            "The can shrink error in the mixing step, but the information will propagate error up in the observation step while the information approach is doing somehow the object.",
            "But for the hybrid approach, some in lots of cases we can control the errors very well."
        ],
        [
            "And there are.",
            "We also tested some variations of the algorithms based on different matrix permanent estimation algorithm.",
            "For example, we use different matrix permanent algorithm.",
            "We typically see the errors in running time behavior very similar and we use a different switching rules an also the errors.",
            "The errors are very similar but the running time may be quite different."
        ],
        [
            "And we also tested the adaptive with long adaptive approach, where the adaptive approach adaptively factorized problem into independent components which scale very well for large."
        ],
        [
            "Problems.",
            "So in conclusion, we have established connections between free approach and information approach, and we proposed Noble hybrid approach based on the existing approach and somehow we generalize the hybrid approach to high orders.",
            "Thanks, thank you very much.",
            "Maybe we have one or two small short questions.",
            "Time 4.",
            "Question.",
            "So in summary, among the three switching strategies, which one would you recommend?",
            "I think the the third one.",
            "So how much K did you use?",
            "Typically less than 2010 between 10 or 20 minutes?",
            "And this task is.",
            "As I understand it is for real news real time evaluation.",
            "It's based on some simulated simulated data, so it's for about size of 20.",
            "You still need 10 or 10 seconds for 20 minutes template.",
            "Internal 20 means that.",
            "How in the stream of data where you log the mixing and observation event there are 10s of mixings and 10s of observations because well, it's reasonable to assume that.",
            "Well, we talking Mixon observe, Mixon observe.",
            "It's not going to happen like that.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's start with a simple illustration of the identity management problem.",
                    "label": 0
                },
                {
                    "sent": "The identity management problem arise from multi object tracking context.",
                    "label": 1
                },
                {
                    "sent": "Suppose we have several moving targets that move in a sensor field an as those people move around.",
                    "label": 0
                },
                {
                    "sent": "Sometimes their positions may get too close to each other.",
                    "label": 0
                },
                {
                    "sent": "When such things happen, we may unable to tell who is who.",
                    "label": 0
                },
                {
                    "sent": "But later on we may observe some identities on particular position, as in this example, where we have observed goofy assert as the third position, and this observation evidence actually can help us to clarify the ambiguities in the associations about target identities with their social associate with positions.",
                    "label": 0
                },
                {
                    "sent": "Because if we want to ask the question, where is the best we can answer this question?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because if we look closely at the track, four will see that only possible position that base can end up would be the third and fourth position, since one of them has already been occupied by Goofy.",
                    "label": 0
                },
                {
                    "sent": "So this has to be end up in the in the in the last position.",
                    "label": 0
                },
                {
                    "sent": "So this simple illustration example actually reflects some combinatorial properties in our problem.",
                    "label": 0
                },
                {
                    "sent": "If we reason both in the mixing events and observation events together, this can help us to clarify the associations about target identity with their positions.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So existing approaches for model, the uncertainties in the identity management problem.",
                    "label": 1
                },
                {
                    "sent": "They model using distributions over permutations.",
                    "label": 0
                },
                {
                    "sent": "So the permutations are all bijective mappings from one to N to one to lamely they map from identity's, want to end two positions 12 N. And of course there are in factorial permutations which is grows super exponentially fast.",
                    "label": 0
                },
                {
                    "sent": "That will make the problem on trackable for all but very small N. So existing approaches for compact summarizing distributions over this big space of permutations fall into many two categories.",
                    "label": 0
                },
                {
                    "sent": "The Fourier approach and the information approach.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our contributions in this work are threefold.",
                    "label": 0
                },
                {
                    "sent": "So first of all we identify that duality relationship exists in the free approach with information approach and 2nd we explore the problem of converting from one form of representation to the other and based on the converting problem.",
                    "label": 0
                },
                {
                    "sent": "So the solution of the converting problem would design A hybrid approach.",
                    "label": 0
                },
                {
                    "sent": "Where we adaptively use either free approach or information approach to help keep track of the associations about the identity's with their positions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's begin with the free approach.",
                    "label": 0
                },
                {
                    "sent": "So the free approach works by collapsing a distribution over permutations by summarizing using low order marginals.",
                    "label": 0
                },
                {
                    "sent": "So let's say if we have a permutation of three people identities of three people with associate with their positions, we have a distribution of three factorials base which is 6 numbers an we can summarize the distribution of the six numbers by using a three by three table, where the IG entry of the table summarizes the marginal probability of that of A is mapped to one, for example.",
                    "label": 0
                },
                {
                    "sent": "The margin properties just summation of the of the distribution over permutations that that the permutation Maps 8 one.",
                    "label": 0
                },
                {
                    "sent": "So this approach you will see that by using all the square numbers you competitive summarize the distribution over permutations.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But since you use only in fact and square numbers to summarize the distribution over over permutations, which also is of a factorial size, of course you lose something, so it turns out the 1st order marginal can be generalized to higher order cases where we summarize the distribution using second order marginals which we use actually North of order N squared by N squared user matrix of size.",
                    "label": 1
                },
                {
                    "sent": "In square by square, where the entry actually represents the marginal probability of a pair of targets is mapped to a pair of positions.",
                    "label": 0
                },
                {
                    "sent": "And by using only still polynomial number of numbers, we actually can still completely summarize the distribution over permutations.",
                    "label": 0
                },
                {
                    "sent": "Of course, such an approach can be generalized to NTH order, but if we use NTH order marginal, we are exactly storing the explicitly the distribution, so there is a trade off between the complexity and accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, information approach works by parameterized distribution over permutations using exponential family.",
                    "label": 0
                },
                {
                    "sent": "Basically, if we.",
                    "label": 0
                },
                {
                    "sent": "For example, let's say the 1st order information matrix, which is of size N by N, and if we want to know the probability that ABC is mapped to 134 that we're going to extract the corresponding entries in the information matrix and sum them up and takes potential.",
                    "label": 0
                },
                {
                    "sent": "Here, the probability is only proportional because we need to use the normalizing constant, which is a summation of all these exponentials so that the probability.",
                    "label": 0
                },
                {
                    "sent": "It goes to one so that really means the probability.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Asian.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An of course, such information approach can be generalized to high orders, where we use 2nd order or third order high order information matrix to parameterized distribution over permutations.",
                    "label": 1
                },
                {
                    "sent": "So now we have two forms of representation.",
                    "label": 0
                },
                {
                    "sent": "One is Fourier, the other information and now the question arises of how do we?",
                    "label": 0
                },
                {
                    "sent": "How about these two representations fit into the operations required for the identity management problem in terms of accuracy and complexity?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a commonly used model for modeling the identity management problem is this Markov model, where we actually we have two components, essential components in the model where one is called the mixing model where such a mixing model characterized targets may swap their identity tracksmith swept their identity with certain probability which model the mixing events were two targets make.",
                    "label": 1
                },
                {
                    "sent": "They can't get too close to each other and there is another component called the observation model where certain identity or particular position is observed.",
                    "label": 0
                },
                {
                    "sent": "And our problem is going to maintain distribution posterior distribution over permutations that keep track of the associations between target identities with their positions.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at the mixing model.",
                    "label": 0
                },
                {
                    "sent": "Well, a simple mixing model can take the form of convolution, where if we assume that for example 22 tracks may swap their identity's IJ and then we have a distribution over permutations that with probability P nothing happens and with probability 1 -- P the IJ may swap an after this.",
                    "label": 0
                },
                {
                    "sent": "After using this mixing model, we are going to update the distribution over associations of identities to tracks using the convolution.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An A simple example to illustrate the idea is that suppose originally the distribution H over which the assignment of ABC 2 tracks 123 is just.",
                    "label": 0
                },
                {
                    "sent": "It's just indicated distribution means we are sure that ABC are located at one to three respectively, an.",
                    "label": 0
                },
                {
                    "sent": "Now if a mixing event happens, which means track one to make swap their identity's, then we're going to convolve the distribution edge with M. Which welcome to get the distribution of the mixing or become .5 if of Sigma if Sigma equals ABC map to 123 and .5 if ABC map 2213.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It turns out if we use the Fourier approach to compare summarize the distribution of mutations where we are actually using a lower order marginal to summarize the distribution over permutations, then originally the marginal for little edge is the capital edge here, which is a identity matrix an the lower the marginal for M for the little M is the capital M. Where it's a mixing matrix, it turns out after the mixing event, we can still actually accurately represent the marginal distribution.",
                    "label": 1
                },
                {
                    "sent": "The posterior using the low order marginals, but such a property does not hold for the information approach where actually we are going to use.",
                    "label": 0
                },
                {
                    "sent": "1st Order information metrics are not enough to accurately represent the distribution after the mixing event.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have the two propositions where the first proposition is talking about the Fourier approach on the mixing event where the marginal can be still marginal can be still accurately represented by the further information approach this is.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not the case.",
                    "label": 0
                },
                {
                    "sent": "We have for the observation model, well, a typical observation says that we observe Red Bull on track one, and now we are going to look at the color histogram of the identity's.",
                    "label": 0
                },
                {
                    "sent": "Suppose ABC has certain amount of color colors in their history histograms respectively.",
                    "label": 0
                },
                {
                    "sent": "Then we are going to build a likelihood function based on the color histogram information and we are going to perform.",
                    "label": 0
                },
                {
                    "sent": "Up base in posterior to calculate the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out that in contrary to the, in contrast to the mixing model, the observation model actually the information representation, can accurately accurately characterize the distribution.",
                    "label": 0
                },
                {
                    "sent": "But for the Fourier, it cannot, using only first lower order information cannot compactly summarize the distribution.",
                    "label": 0
                },
                {
                    "sent": "So in this sense, the mixing model free approach is good.",
                    "label": 0
                },
                {
                    "sent": "Information approach is bad, but for the observation model it's the other way around.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are certain some other.",
                    "label": 0
                },
                {
                    "sent": "Operations that we need to do with the with the two approach.",
                    "label": 1
                },
                {
                    "sent": "For example, we we often need to do normalizing, normalizing, computing and normalizing constant so that the distribution actually sums up equal to 1.",
                    "label": 0
                },
                {
                    "sent": "It turns out the normalizing step is quite easy for the free approach, but it's very hard for the information approach and also based on the representation we summarize on the permutations we.",
                    "label": 0
                },
                {
                    "sent": "Want to find out which Sigma which permutation is a large, has the largest probability.",
                    "label": 0
                },
                {
                    "sent": "It turns out this problem is a maximizing maximal matching problem for both foreign information approach.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here this table summarizes the complexity for the two approaches on the two on the four operations required for the modeling, the identity management problem we actually see.",
                    "label": 0
                },
                {
                    "sent": "There are some duality relationship exists where fully approach is good for mixing by baffle.",
                    "label": 0
                },
                {
                    "sent": "Observation while the information approach is doing.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An also we can explore some more deep theoretical results about the two representations, so it turns out the free approach is doing.",
                    "label": 0
                },
                {
                    "sent": "We are essentially doing our two projection of a distribution over permutations.",
                    "label": 0
                },
                {
                    "sent": "Too low order frequency subspaces, so it's an L2 projection, but the information representation we are essentially projecting a distribution to a linear subspace using a kind of different metric.",
                    "label": 0
                },
                {
                    "sent": "Of KL divergent metric, where if we have a distribution edge when we can project Edge to a low order subspace represented by Q using the KL divergent metric and turns out solution of this optimization program, the information form representation naturally arise.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically, because of both forms can be can be interpreted as projections, too low order subspaces.",
                    "label": 0
                },
                {
                    "sent": "We have.",
                    "label": 0
                },
                {
                    "sent": "The Pythagorean theorem holds for both cases where the magic actually different for Fourier anevo information, where for the Fourier the metric we are using our two.",
                    "label": 0
                },
                {
                    "sent": "But for the information we are going to use a K or diverges.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I'm going to talk about the hybrid approach, where we essentially need to figure out how to switch between the two domains.",
                    "label": 0
                },
                {
                    "sent": "And it turns out, given the information matrix, we can calculate the marginal by this expression, where the perm actually means the permanent of a matrix, whereas you may, as all you should know, that determinant is a summation of.",
                    "label": 0
                },
                {
                    "sent": "Of products of entries that lie in different rows and columns, and there is a factor of minus 1 to the power of number, depends on whether the permutation is even or odd.",
                    "label": 0
                },
                {
                    "sent": "The permanent matrix permanent is just removing the minus one power factor where it's just summation of all products of entries that like in different rows and columns.",
                    "label": 0
                },
                {
                    "sent": "An so for the.",
                    "label": 0
                },
                {
                    "sent": "For the other way around where we have marginal probability Q, we can also compute the information matrix by solving this optimization program where we we solve for distribution Q that whose marginal is exactly exactly capital Q but using.",
                    "label": 0
                },
                {
                    "sent": "Kill diversions matrix.",
                    "label": 0
                },
                {
                    "sent": "So it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In both the conversion from Fourier to information or the other way around, there is a.",
                    "label": 0
                },
                {
                    "sent": "Essential step involved in converting that is computing the matrix permanent.",
                    "label": 0
                },
                {
                    "sent": "Things out there are.",
                    "label": 0
                },
                {
                    "sent": "Well, metric permanent, quite unlucky from the matrix determinant.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to compute.",
                    "label": 0
                },
                {
                    "sent": "It's actually shown to be NP hard where there are so naive algorithm will scale super exponentially.",
                    "label": 0
                },
                {
                    "sent": "But there was a cleverly.",
                    "label": 0
                },
                {
                    "sent": "Design algorithm called Riser algorithm which is known to be the fast so far that scales exponentially.",
                    "label": 0
                },
                {
                    "sent": "Luckily there are some FP Ross algorithm or some belief propagation algorithm which can.",
                    "label": 0
                },
                {
                    "sent": "Perform very good in practice that can approximate the matrix permanent very fast.",
                    "label": 0
                },
                {
                    "sent": "And also for the problem of whether we should switch from one form of representation to the other.",
                    "label": 0
                },
                {
                    "sent": "There are certain rules that we can consider.",
                    "label": 0
                },
                {
                    "sent": "For example, we can consider based on the accuracy since phrase accurate for mixing an information is accurate for observation.",
                    "label": 0
                },
                {
                    "sent": "So we can based on the accuracy to decide which domain which form of representation to use.",
                    "label": 0
                },
                {
                    "sent": "And there are other.",
                    "label": 0
                },
                {
                    "sent": "Considerations such as smoothness based switching or lock box, which is that we tested in our experiments where the smoothness switching is basically because the free approach is good at characterizing smooth distributions while the information is good at capitalizing picky distributions, we can.",
                    "label": 0
                },
                {
                    "sent": "George, which formal representation to use based on the smoothness of the distribution.",
                    "label": 0
                },
                {
                    "sent": "Anlab block switching is just look her time steps to see which.",
                    "label": 0
                },
                {
                    "sent": "Formal representation should we use?",
                    "label": 0
                },
                {
                    "sent": "And last we can for practical use of the of the most forms of representation to keep track of the associations we can adaptive factorized problems into smaller sizes, because if we if we really see the data, real data of several moving targets targets moving in the diploid sensor networks, you will typically see that certain targets.",
                    "label": 0
                },
                {
                    "sent": "To move together and then separate again.",
                    "label": 0
                },
                {
                    "sent": "So I mean, there are some clustering behavior that exists in the movement patterns which we can explore to divide, design, divide and conquer.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ouch.",
                    "label": 0
                },
                {
                    "sent": "So we actually simulate some data from the game game engine an there are complexity complex, very complex move movement patterns in the simulation an from the simulated data we can control the mixing event and observation event.",
                    "label": 0
                },
                {
                    "sent": "Say whenever two persons to get too close to each other.",
                    "label": 0
                },
                {
                    "sent": "We claim there was a mixing vent and whenever a person is separate from all the other target, we claim their result observation event.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here the two plots actually shows some running time analysis.",
                    "label": 0
                },
                {
                    "sent": "Results so the first left plot is about the matrix permanent computation, where there are two.",
                    "label": 0
                },
                {
                    "sent": "Two algorithm, namely not even a riser algorithm which scale at least exponentially.",
                    "label": 0
                },
                {
                    "sent": "So they really scales very bad and they cannot handle very large and but for the.",
                    "label": 0
                },
                {
                    "sent": "Irrational belief propagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "They can still scale quite well an by using the hybrid approach we typically see the running time of the hybrid approach behave well.",
                    "label": 0
                },
                {
                    "sent": "The running time for the hybrid approach is longer than the free and information alone, but typically it's lower than some high order free approach.",
                    "label": 0
                },
                {
                    "sent": "Let's say second order or third order free approach.",
                    "label": 0
                },
                {
                    "sent": "This is due to the fact that the conversion between 2 forms of representation is really time.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing however, if you look at the accuracy of the of the different approaches will see typically see that the hyper approach in law in lots of cases can beat.",
                    "label": 0
                },
                {
                    "sent": "Either free approach or information approach alone.",
                    "label": 0
                },
                {
                    "sent": "This is because if you use only one formal representation, errors may propagate where we quickly.",
                    "label": 0
                },
                {
                    "sent": "If, for example, if you use Fourier approach in the in the observation steps, errors may propagate very, very quick.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to see this, we actually keep track of the errors in distribution.",
                    "label": 0
                },
                {
                    "sent": "I mean in the space of permutations where the white intervals actually denote the mixing mixing events, while the great interval.",
                    "label": 0
                },
                {
                    "sent": "Actually they know the condition the condition survey for the observation models.",
                    "label": 0
                },
                {
                    "sent": "So we will typically see the the free approach where here is depicting red color.",
                    "label": 0
                },
                {
                    "sent": "The can shrink error in the mixing step, but the information will propagate error up in the observation step while the information approach is doing somehow the object.",
                    "label": 0
                },
                {
                    "sent": "But for the hybrid approach, some in lots of cases we can control the errors very well.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are.",
                    "label": 0
                },
                {
                    "sent": "We also tested some variations of the algorithms based on different matrix permanent estimation algorithm.",
                    "label": 1
                },
                {
                    "sent": "For example, we use different matrix permanent algorithm.",
                    "label": 0
                },
                {
                    "sent": "We typically see the errors in running time behavior very similar and we use a different switching rules an also the errors.",
                    "label": 1
                },
                {
                    "sent": "The errors are very similar but the running time may be quite different.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also tested the adaptive with long adaptive approach, where the adaptive approach adaptively factorized problem into independent components which scale very well for large.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems.",
                    "label": 0
                },
                {
                    "sent": "So in conclusion, we have established connections between free approach and information approach, and we proposed Noble hybrid approach based on the existing approach and somehow we generalize the hybrid approach to high orders.",
                    "label": 0
                },
                {
                    "sent": "Thanks, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Maybe we have one or two small short questions.",
                    "label": 0
                },
                {
                    "sent": "Time 4.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So in summary, among the three switching strategies, which one would you recommend?",
                    "label": 0
                },
                {
                    "sent": "I think the the third one.",
                    "label": 0
                },
                {
                    "sent": "So how much K did you use?",
                    "label": 0
                },
                {
                    "sent": "Typically less than 2010 between 10 or 20 minutes?",
                    "label": 0
                },
                {
                    "sent": "And this task is.",
                    "label": 0
                },
                {
                    "sent": "As I understand it is for real news real time evaluation.",
                    "label": 0
                },
                {
                    "sent": "It's based on some simulated simulated data, so it's for about size of 20.",
                    "label": 0
                },
                {
                    "sent": "You still need 10 or 10 seconds for 20 minutes template.",
                    "label": 0
                },
                {
                    "sent": "Internal 20 means that.",
                    "label": 0
                },
                {
                    "sent": "How in the stream of data where you log the mixing and observation event there are 10s of mixings and 10s of observations because well, it's reasonable to assume that.",
                    "label": 0
                },
                {
                    "sent": "Well, we talking Mixon observe, Mixon observe.",
                    "label": 0
                },
                {
                    "sent": "It's not going to happen like that.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}