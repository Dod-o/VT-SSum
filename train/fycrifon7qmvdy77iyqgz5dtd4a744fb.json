{
    "id": "fycrifon7qmvdy77iyqgz5dtd4a744fb",
    "title": "A Game Theoretic Approach To Jointly Learn Shape Categories and Contextual Similarities",
    "info": {
        "author": [
            "Andrea Torsello, Department of Computer Science, Ca' Foscari University of Venice"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_torsello_gta/",
    "segmentation": [
        [
            "So we presenting joint work with and whether I could have them on the topic of learning.",
            "Similarities that are relevant to the particular context, in particular with categories that we do have in a in a certain database that will be and will be concentrating on a shape database.",
            "In this case and the ship application."
        ],
        [
            "But just to go into some motivation, there is a.",
            "It's very well known in our at least, there is strong evidence in the psychology research that.",
            "The category information.",
            "The actual underlying categories.",
            "Strongly influence the perceptions of what we have similarities, so similarity is in the sense of very important midlevel representation.",
            "To get try to to preach the semantic gap, but also we have all sorts of influences that the underlying semantic have on the the way we compute similarities.",
            "There are important things like variation in common to class are perceived as less important for object of the class and then they are for objectivity.",
            "Class so we could not just.",
            "Make the same penalize the same type of operation everywhere in our object space and on their end.",
            "On the other extreme of this problem, we have that multiple classes that each object can be assigned to multiple classes and pair.",
            "The similarities are two sets of objects do have at least the perception.",
            "Similarity is determined by the class used for comparison, which is usually determined by the in sample of the object we see.",
            "So the context in which we see things and.",
            "The context in which we do the comparison.",
            "I will actually strongly influence the actual similarity information we get from that, and there is an interesting important point here.",
            "Is that knowledge about the underlying class structure is required in the sense to quick to actually create the similarities?",
            "But normally configures are learned through experience.",
            "I mean we have as humans we have the user experience to start categorizing our world and dividing it and organizing it into things and configuration.",
            "With that we know and in that sense, experience doesn't comes before work tasks and Kathy agrees in that sense, for for the actual tasks are known here.",
            "But here we actually we want to do something a bit different.",
            "We want to be able to estimate the categories in directly from when.",
            "We first see the task that is, we want to do a joint work of doing unsupervised estimation of the of the categories present and the estimation of the similarities and the the context under contextual similarities within the categories that are present."
        ],
        [
            "So there is a huge chicken and egg problem here because of course.",
            "The similarities might be known to know in order to estimate class structure.",
            "If you don't know how similar things are happening, you say what the structure the structure are in another provides way, but on the other hand, without cost structure, we don't really have similarities, at least not perceptually relevant contextual similarities, which is what we think is important to get.",
            "Do they get because this category?",
            "So the problem here is that data clustering and contextual similarities should be learned simultaneously, and there is another problem is that when comparison is based on matching which is very common when we can separate the object into parts and then try to see how parts fit together.",
            "Then the matching context that we just keep for granted actually makes sense only on the correct or similar complex, so it's no point trying to match human limb with the trunk of a with with the wheels of car and the any matching in that in that direction.",
            "I imagine in a completely wrong context will bear no meaning and thus will bear no relevance in similarity information."
        ],
        [
            "So just to go a little bit into a more into what we've actually been doing, we're trying to do a category in fluent mesh on a particular high level representation of shape.",
            "This, however, representation of shape is disconnected.",
            "Scanner Skeletonwitch is a very coarse, but very robust skeletal based representation of shape.",
            "Which allows for contextual measurement in the sense that it is part matching a system where the actual similarity ends up being an edit distance of the.",
            "The graph structure you extract from the skeleton and the point here is that the context similarity can extract it here just by learning the added cost that are related to a particular category.",
            "So once you do have the category, and in this case the one we have in the same category that the variation within this category will actually tell you will actually allow you to know will actually give you some information about the edit cost you should use within this category, and then you when you match your query shape for database shape you can apply those costs that are there will be different in depending on what.",
            "And what target category we're using?",
            "And of course the edit operation depend on the variability within the class and try to of course follow the idea that very common variation should not be penalized much.",
            "The interesting thing one actually it's the of the main problem with with common approaches with this contextual similarity, is that the roles of shaping comparison is asymmetric.",
            "When we do a query shape wherein we compared to a database shape, of course the database shape tells us what is the context we're looking for.",
            "So if you want to see if this shape matches to a cat, we want to see it in the context of cats in there.",
            "There is no point in trying to match any query shape to occur in the context of our car, 'cause we know that matches in the wrong context will meet will bear no real meaning and the end result is this distance is computed in the context in this content.",
            "In this context will actually be asymmetric themselves, so we.",
            "You definitely were not even in.",
            "In a metric space much less than in the usual Euclidean space will will like so we will have to be able to have some some way to deal with this asymmetric similarities we obtain through the context."
        ],
        [
            "So what is the proposed approach?",
            "Well, as UCL say very high level there.",
            "The low level details have been presented earlier on the during the bus session.",
            "So the idea here is that class membership can in a sense we considered, whereas a little latent variable.",
            "So what we are proposing it's nothing but pretty good here, chattering from a very high level perspective.",
            "It's basically a form of VM on but on similarity space.",
            "So we're trying to.",
            "To create classes great great groups where the group is, the group membership is a latent variable, but we do have some Merc requirements to do this.",
            "Well of course, being an M we alternate between estimation maximization.",
            "The estimation is the over the IE step is basically the class estimation and that is pretty much performed through pairwise clustering where we need an.",
            "But there are two or three.",
            "Main problems here.",
            "One is that we don't just need the class.",
            "The class structure.",
            "At the end, we also need a measure of membership between innocence.",
            "We need something that will give you the best of the posterior of the latent variable.",
            "So the anyways question everything that we want to use needs to be able to do to give us move plus membership information measurement across membership information.",
            "The other important.",
            "A requirement here is of course it has to be able to deal with asymmetric similarities because context will introduce a symmetries.",
            "And to do this because we are using a game theoretic questioning approach derived from a dominant sets an it has all this nice nice properties.",
            "It will give you can deal with any form of similarity or dissimilarity's you can use asymmetric negative anything doesn't really matter and it will give gives us a measure of class membership which can be interpreted as a normalized posterior of the latent variable.",
            "And the other part, of course, is the maximization.",
            "What is equivalent of a melon M step, which is the similarity of date where we actually update our contextual model.",
            "And this is of course the way we will.",
            "It ends up being a weight of learn this.",
            "They already did, it cost, so we use the membership to index and wait in the.",
            "The viability so that the viability information, and thus the edit costs will be weighed by the cost membership we have here.",
            "And of course, this will give us a symmetric similarity.",
            "So as we've seen, the different context will be will impose asymmetry in the update of the similarity.",
            "An interesting general problem that we're facing is that some context cannot be determined.",
            "Sometime it's our problem.",
            "Our approach is not perfect, and can we simply the context there are correct.",
            "Antique classes there, but we cannot see it.",
            "We have some outliers that are not real outliers, but we feel it there.",
            "Outliers but other times that is not the case there.",
            "We just might have elements of not good.",
            "Classes are too few elements to actually learn how to create their own context.",
            "So in a sense in this situation is much better to say.",
            "I don't know then just say something completely random.",
            "So another interesting approach, interesting properties.",
            "Our approach is that it's not the.",
            "Pairwise clustering is not partitioned based, so we can actually deal with outliers.",
            "We can say I don't know.",
            "Honestly, say I don't know when we're in rather than just assign it randomly.",
            "Now just a good idea."
        ],
        [
            "Creation we have applied this to a ship classification task.",
            "We have a little bit of a 1000 shape divided into 50 categories and what we do extract.",
            "Automatically, exactly, Kathy goes out of it.",
            "We we, we do have extracted 6060 categories so we do have a little bit more that we do have have split some shape classes here you can see but important thing is that as you see the precision is always very high, so it's mostly splitting between high variability, context, context that are not completely merged rather than.",
            "Lower than mixing structures that some sexual that are mixed, but they're very perceptually similar, although there they do have semantic difference semantically different figures."
        ],
        [
            "So here is just a rundown of the extracted configuration.",
            "Here we have.",
            "Some quantitative measurement of what we're doing and we inducing hey thing here is as we generate the method that we start from a completely symmetric.",
            "Completely symmetric similarity.",
            "Again, we then we render it more and more asymmetric as we introduce more and more information about the context and we do.",
            "We do see an improvement in all the indices.",
            "This corrected run index is corrected by the to not penalize outliers.",
            "When we say don't, I don't know that's just the only real difference.",
            "Without an index we compare it with other.",
            "Pairwise questionnaire approach to see where this is the performance and we definitely perform better in this context in the valuation of the exotic."
        ],
        [
            "Degrees, but even more important, our more interesting is the precision recall curve we do obtain and, well, this three are the three time steps of the overall algorithm, and we see that in the initial approach is not.",
            "This level, but as we do.",
            "I can't actually information.",
            "We do get much better performance and we do get much better performance of most.",
            "Competing algorithms, this is foreground focus, very similar approach.",
            "It tries to learn both contexts and similarity similarities related to them, but definitely very low performance in comparison.",
            "Another very strongly performing algorithm is later is a little label propagation approach, but that only learn similarities never learns categories.",
            "It performs very well with an adaptive kernel, but as long as you fix the kernel it actually performed poorly.",
            "Poorly, so if we probably try, lesson learned that I have to apply this in some form of.",
            "Adaptive kernel here.",
            "In our learning process as well.",
            "Anne.",
            "This is about it just about."
        ],
        [
            "Open question that remain with this approach, perhaps.",
            "So very open.",
            "Question about.",
            "About the whole idea of learning contextual similarity and the first is something that really got really bugs me a bit because it's not very clear at this point is how much is prior knowledge of category necessary to produce semantic gap, and if so, how much of it, and if not, how can we get get there?",
            "Of course this is a huge question and not and definitely open ended, but.",
            "Human as humans, we do learn the categories, so we might just take along the time and a lot of experiments.",
            "Learn the categories at the same time, then bridge the gap.",
            "And of course probably cannot be completely unsupervised because we do categorize differently in different cultures, but at least something so it's.",
            "There is some supervising information in the semantic gap there.",
            "Then we have two related over question is whether similarity comes before after category evaluation, which is again probably more.",
            "Ethical or psychological question here, but similarity is a very good mid level representation.",
            "We all like to use it, but at least I do.",
            "But it's not clear whether we are actually comparable.",
            "Where it comes before or at the same time as Kathy evaluation or whether category evolution comes after dinner at an early stage and related.",
            "That is, whether it's a similarity is the main representation or so, or where it should be.",
            "Device from feature models that characterize the configuration.",
            "In a sense, we do use a feature model, or at least a little bit lower level representation to feed to get back on the M step from the cathedral information to the.",
            "It's a similarity, and the other, I think, open question.",
            "I thought very interesting is where are symmetries introduced by the context is important or not?",
            "Whether the fact that context, the role of the Office of Query and it'll be shape is completely different.",
            "It's just a byproduct of the of toy example we're doing we're dealing with, or it is important to have a way to deal with this symmetry."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we presenting joint work with and whether I could have them on the topic of learning.",
                    "label": 0
                },
                {
                    "sent": "Similarities that are relevant to the particular context, in particular with categories that we do have in a in a certain database that will be and will be concentrating on a shape database.",
                    "label": 0
                },
                {
                    "sent": "In this case and the ship application.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But just to go into some motivation, there is a.",
                    "label": 0
                },
                {
                    "sent": "It's very well known in our at least, there is strong evidence in the psychology research that.",
                    "label": 0
                },
                {
                    "sent": "The category information.",
                    "label": 0
                },
                {
                    "sent": "The actual underlying categories.",
                    "label": 0
                },
                {
                    "sent": "Strongly influence the perceptions of what we have similarities, so similarity is in the sense of very important midlevel representation.",
                    "label": 0
                },
                {
                    "sent": "To get try to to preach the semantic gap, but also we have all sorts of influences that the underlying semantic have on the the way we compute similarities.",
                    "label": 0
                },
                {
                    "sent": "There are important things like variation in common to class are perceived as less important for object of the class and then they are for objectivity.",
                    "label": 1
                },
                {
                    "sent": "Class so we could not just.",
                    "label": 0
                },
                {
                    "sent": "Make the same penalize the same type of operation everywhere in our object space and on their end.",
                    "label": 0
                },
                {
                    "sent": "On the other extreme of this problem, we have that multiple classes that each object can be assigned to multiple classes and pair.",
                    "label": 0
                },
                {
                    "sent": "The similarities are two sets of objects do have at least the perception.",
                    "label": 1
                },
                {
                    "sent": "Similarity is determined by the class used for comparison, which is usually determined by the in sample of the object we see.",
                    "label": 0
                },
                {
                    "sent": "So the context in which we see things and.",
                    "label": 0
                },
                {
                    "sent": "The context in which we do the comparison.",
                    "label": 1
                },
                {
                    "sent": "I will actually strongly influence the actual similarity information we get from that, and there is an interesting important point here.",
                    "label": 1
                },
                {
                    "sent": "Is that knowledge about the underlying class structure is required in the sense to quick to actually create the similarities?",
                    "label": 0
                },
                {
                    "sent": "But normally configures are learned through experience.",
                    "label": 0
                },
                {
                    "sent": "I mean we have as humans we have the user experience to start categorizing our world and dividing it and organizing it into things and configuration.",
                    "label": 0
                },
                {
                    "sent": "With that we know and in that sense, experience doesn't comes before work tasks and Kathy agrees in that sense, for for the actual tasks are known here.",
                    "label": 0
                },
                {
                    "sent": "But here we actually we want to do something a bit different.",
                    "label": 0
                },
                {
                    "sent": "We want to be able to estimate the categories in directly from when.",
                    "label": 0
                },
                {
                    "sent": "We first see the task that is, we want to do a joint work of doing unsupervised estimation of the of the categories present and the estimation of the similarities and the the context under contextual similarities within the categories that are present.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is a huge chicken and egg problem here because of course.",
                    "label": 1
                },
                {
                    "sent": "The similarities might be known to know in order to estimate class structure.",
                    "label": 1
                },
                {
                    "sent": "If you don't know how similar things are happening, you say what the structure the structure are in another provides way, but on the other hand, without cost structure, we don't really have similarities, at least not perceptually relevant contextual similarities, which is what we think is important to get.",
                    "label": 0
                },
                {
                    "sent": "Do they get because this category?",
                    "label": 0
                },
                {
                    "sent": "So the problem here is that data clustering and contextual similarities should be learned simultaneously, and there is another problem is that when comparison is based on matching which is very common when we can separate the object into parts and then try to see how parts fit together.",
                    "label": 1
                },
                {
                    "sent": "Then the matching context that we just keep for granted actually makes sense only on the correct or similar complex, so it's no point trying to match human limb with the trunk of a with with the wheels of car and the any matching in that in that direction.",
                    "label": 0
                },
                {
                    "sent": "I imagine in a completely wrong context will bear no meaning and thus will bear no relevance in similarity information.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to go a little bit into a more into what we've actually been doing, we're trying to do a category in fluent mesh on a particular high level representation of shape.",
                    "label": 0
                },
                {
                    "sent": "This, however, representation of shape is disconnected.",
                    "label": 0
                },
                {
                    "sent": "Scanner Skeletonwitch is a very coarse, but very robust skeletal based representation of shape.",
                    "label": 0
                },
                {
                    "sent": "Which allows for contextual measurement in the sense that it is part matching a system where the actual similarity ends up being an edit distance of the.",
                    "label": 0
                },
                {
                    "sent": "The graph structure you extract from the skeleton and the point here is that the context similarity can extract it here just by learning the added cost that are related to a particular category.",
                    "label": 0
                },
                {
                    "sent": "So once you do have the category, and in this case the one we have in the same category that the variation within this category will actually tell you will actually allow you to know will actually give you some information about the edit cost you should use within this category, and then you when you match your query shape for database shape you can apply those costs that are there will be different in depending on what.",
                    "label": 0
                },
                {
                    "sent": "And what target category we're using?",
                    "label": 0
                },
                {
                    "sent": "And of course the edit operation depend on the variability within the class and try to of course follow the idea that very common variation should not be penalized much.",
                    "label": 1
                },
                {
                    "sent": "The interesting thing one actually it's the of the main problem with with common approaches with this contextual similarity, is that the roles of shaping comparison is asymmetric.",
                    "label": 1
                },
                {
                    "sent": "When we do a query shape wherein we compared to a database shape, of course the database shape tells us what is the context we're looking for.",
                    "label": 1
                },
                {
                    "sent": "So if you want to see if this shape matches to a cat, we want to see it in the context of cats in there.",
                    "label": 0
                },
                {
                    "sent": "There is no point in trying to match any query shape to occur in the context of our car, 'cause we know that matches in the wrong context will meet will bear no real meaning and the end result is this distance is computed in the context in this content.",
                    "label": 0
                },
                {
                    "sent": "In this context will actually be asymmetric themselves, so we.",
                    "label": 0
                },
                {
                    "sent": "You definitely were not even in.",
                    "label": 0
                },
                {
                    "sent": "In a metric space much less than in the usual Euclidean space will will like so we will have to be able to have some some way to deal with this asymmetric similarities we obtain through the context.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the proposed approach?",
                    "label": 0
                },
                {
                    "sent": "Well, as UCL say very high level there.",
                    "label": 0
                },
                {
                    "sent": "The low level details have been presented earlier on the during the bus session.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that class membership can in a sense we considered, whereas a little latent variable.",
                    "label": 1
                },
                {
                    "sent": "So what we are proposing it's nothing but pretty good here, chattering from a very high level perspective.",
                    "label": 1
                },
                {
                    "sent": "It's basically a form of VM on but on similarity space.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to.",
                    "label": 1
                },
                {
                    "sent": "To create classes great great groups where the group is, the group membership is a latent variable, but we do have some Merc requirements to do this.",
                    "label": 0
                },
                {
                    "sent": "Well of course, being an M we alternate between estimation maximization.",
                    "label": 1
                },
                {
                    "sent": "The estimation is the over the IE step is basically the class estimation and that is pretty much performed through pairwise clustering where we need an.",
                    "label": 0
                },
                {
                    "sent": "But there are two or three.",
                    "label": 1
                },
                {
                    "sent": "Main problems here.",
                    "label": 0
                },
                {
                    "sent": "One is that we don't just need the class.",
                    "label": 0
                },
                {
                    "sent": "The class structure.",
                    "label": 0
                },
                {
                    "sent": "At the end, we also need a measure of membership between innocence.",
                    "label": 0
                },
                {
                    "sent": "We need something that will give you the best of the posterior of the latent variable.",
                    "label": 0
                },
                {
                    "sent": "So the anyways question everything that we want to use needs to be able to do to give us move plus membership information measurement across membership information.",
                    "label": 0
                },
                {
                    "sent": "The other important.",
                    "label": 0
                },
                {
                    "sent": "A requirement here is of course it has to be able to deal with asymmetric similarities because context will introduce a symmetries.",
                    "label": 0
                },
                {
                    "sent": "And to do this because we are using a game theoretic questioning approach derived from a dominant sets an it has all this nice nice properties.",
                    "label": 0
                },
                {
                    "sent": "It will give you can deal with any form of similarity or dissimilarity's you can use asymmetric negative anything doesn't really matter and it will give gives us a measure of class membership which can be interpreted as a normalized posterior of the latent variable.",
                    "label": 1
                },
                {
                    "sent": "And the other part, of course, is the maximization.",
                    "label": 0
                },
                {
                    "sent": "What is equivalent of a melon M step, which is the similarity of date where we actually update our contextual model.",
                    "label": 0
                },
                {
                    "sent": "And this is of course the way we will.",
                    "label": 0
                },
                {
                    "sent": "It ends up being a weight of learn this.",
                    "label": 0
                },
                {
                    "sent": "They already did, it cost, so we use the membership to index and wait in the.",
                    "label": 0
                },
                {
                    "sent": "The viability so that the viability information, and thus the edit costs will be weighed by the cost membership we have here.",
                    "label": 0
                },
                {
                    "sent": "And of course, this will give us a symmetric similarity.",
                    "label": 0
                },
                {
                    "sent": "So as we've seen, the different context will be will impose asymmetry in the update of the similarity.",
                    "label": 0
                },
                {
                    "sent": "An interesting general problem that we're facing is that some context cannot be determined.",
                    "label": 0
                },
                {
                    "sent": "Sometime it's our problem.",
                    "label": 0
                },
                {
                    "sent": "Our approach is not perfect, and can we simply the context there are correct.",
                    "label": 0
                },
                {
                    "sent": "Antique classes there, but we cannot see it.",
                    "label": 0
                },
                {
                    "sent": "We have some outliers that are not real outliers, but we feel it there.",
                    "label": 0
                },
                {
                    "sent": "Outliers but other times that is not the case there.",
                    "label": 0
                },
                {
                    "sent": "We just might have elements of not good.",
                    "label": 0
                },
                {
                    "sent": "Classes are too few elements to actually learn how to create their own context.",
                    "label": 0
                },
                {
                    "sent": "So in a sense in this situation is much better to say.",
                    "label": 0
                },
                {
                    "sent": "I don't know then just say something completely random.",
                    "label": 0
                },
                {
                    "sent": "So another interesting approach, interesting properties.",
                    "label": 0
                },
                {
                    "sent": "Our approach is that it's not the.",
                    "label": 0
                },
                {
                    "sent": "Pairwise clustering is not partitioned based, so we can actually deal with outliers.",
                    "label": 0
                },
                {
                    "sent": "We can say I don't know.",
                    "label": 0
                },
                {
                    "sent": "Honestly, say I don't know when we're in rather than just assign it randomly.",
                    "label": 0
                },
                {
                    "sent": "Now just a good idea.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Creation we have applied this to a ship classification task.",
                    "label": 0
                },
                {
                    "sent": "We have a little bit of a 1000 shape divided into 50 categories and what we do extract.",
                    "label": 0
                },
                {
                    "sent": "Automatically, exactly, Kathy goes out of it.",
                    "label": 0
                },
                {
                    "sent": "We we, we do have extracted 6060 categories so we do have a little bit more that we do have have split some shape classes here you can see but important thing is that as you see the precision is always very high, so it's mostly splitting between high variability, context, context that are not completely merged rather than.",
                    "label": 0
                },
                {
                    "sent": "Lower than mixing structures that some sexual that are mixed, but they're very perceptually similar, although there they do have semantic difference semantically different figures.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is just a rundown of the extracted configuration.",
                    "label": 0
                },
                {
                    "sent": "Here we have.",
                    "label": 0
                },
                {
                    "sent": "Some quantitative measurement of what we're doing and we inducing hey thing here is as we generate the method that we start from a completely symmetric.",
                    "label": 0
                },
                {
                    "sent": "Completely symmetric similarity.",
                    "label": 0
                },
                {
                    "sent": "Again, we then we render it more and more asymmetric as we introduce more and more information about the context and we do.",
                    "label": 0
                },
                {
                    "sent": "We do see an improvement in all the indices.",
                    "label": 0
                },
                {
                    "sent": "This corrected run index is corrected by the to not penalize outliers.",
                    "label": 0
                },
                {
                    "sent": "When we say don't, I don't know that's just the only real difference.",
                    "label": 0
                },
                {
                    "sent": "Without an index we compare it with other.",
                    "label": 0
                },
                {
                    "sent": "Pairwise questionnaire approach to see where this is the performance and we definitely perform better in this context in the valuation of the exotic.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Degrees, but even more important, our more interesting is the precision recall curve we do obtain and, well, this three are the three time steps of the overall algorithm, and we see that in the initial approach is not.",
                    "label": 0
                },
                {
                    "sent": "This level, but as we do.",
                    "label": 0
                },
                {
                    "sent": "I can't actually information.",
                    "label": 0
                },
                {
                    "sent": "We do get much better performance and we do get much better performance of most.",
                    "label": 1
                },
                {
                    "sent": "Competing algorithms, this is foreground focus, very similar approach.",
                    "label": 1
                },
                {
                    "sent": "It tries to learn both contexts and similarity similarities related to them, but definitely very low performance in comparison.",
                    "label": 0
                },
                {
                    "sent": "Another very strongly performing algorithm is later is a little label propagation approach, but that only learn similarities never learns categories.",
                    "label": 0
                },
                {
                    "sent": "It performs very well with an adaptive kernel, but as long as you fix the kernel it actually performed poorly.",
                    "label": 0
                },
                {
                    "sent": "Poorly, so if we probably try, lesson learned that I have to apply this in some form of.",
                    "label": 0
                },
                {
                    "sent": "Adaptive kernel here.",
                    "label": 0
                },
                {
                    "sent": "In our learning process as well.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This is about it just about.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Open question that remain with this approach, perhaps.",
                    "label": 0
                },
                {
                    "sent": "So very open.",
                    "label": 0
                },
                {
                    "sent": "Question about.",
                    "label": 0
                },
                {
                    "sent": "About the whole idea of learning contextual similarity and the first is something that really got really bugs me a bit because it's not very clear at this point is how much is prior knowledge of category necessary to produce semantic gap, and if so, how much of it, and if not, how can we get get there?",
                    "label": 1
                },
                {
                    "sent": "Of course this is a huge question and not and definitely open ended, but.",
                    "label": 0
                },
                {
                    "sent": "Human as humans, we do learn the categories, so we might just take along the time and a lot of experiments.",
                    "label": 1
                },
                {
                    "sent": "Learn the categories at the same time, then bridge the gap.",
                    "label": 0
                },
                {
                    "sent": "And of course probably cannot be completely unsupervised because we do categorize differently in different cultures, but at least something so it's.",
                    "label": 0
                },
                {
                    "sent": "There is some supervising information in the semantic gap there.",
                    "label": 0
                },
                {
                    "sent": "Then we have two related over question is whether similarity comes before after category evaluation, which is again probably more.",
                    "label": 0
                },
                {
                    "sent": "Ethical or psychological question here, but similarity is a very good mid level representation.",
                    "label": 0
                },
                {
                    "sent": "We all like to use it, but at least I do.",
                    "label": 0
                },
                {
                    "sent": "But it's not clear whether we are actually comparable.",
                    "label": 0
                },
                {
                    "sent": "Where it comes before or at the same time as Kathy evaluation or whether category evolution comes after dinner at an early stage and related.",
                    "label": 1
                },
                {
                    "sent": "That is, whether it's a similarity is the main representation or so, or where it should be.",
                    "label": 0
                },
                {
                    "sent": "Device from feature models that characterize the configuration.",
                    "label": 0
                },
                {
                    "sent": "In a sense, we do use a feature model, or at least a little bit lower level representation to feed to get back on the M step from the cathedral information to the.",
                    "label": 1
                },
                {
                    "sent": "It's a similarity, and the other, I think, open question.",
                    "label": 0
                },
                {
                    "sent": "I thought very interesting is where are symmetries introduced by the context is important or not?",
                    "label": 0
                },
                {
                    "sent": "Whether the fact that context, the role of the Office of Query and it'll be shape is completely different.",
                    "label": 0
                },
                {
                    "sent": "It's just a byproduct of the of toy example we're doing we're dealing with, or it is important to have a way to deal with this symmetry.",
                    "label": 0
                }
            ]
        }
    }
}