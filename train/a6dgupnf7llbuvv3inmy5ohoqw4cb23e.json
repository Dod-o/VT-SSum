{
    "id": "a6dgupnf7llbuvv3inmy5ohoqw4cb23e",
    "title": "Generalization theory of two-part code MDL estimator",
    "info": {
        "author": [
            "Tong Zhang, Department of Statistics, Rutgers, The State University of New Jersey"
        ],
        "published": "Aug. 13, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_zhang_gtt/",
    "segmentation": [
        [
            "OK, so the outline.",
            "There's three parts of this talk, basically from more abstract to less abstract.",
            "First is the more extra part, basics more of more general information theoretic inequality, which is some people know like pacbase analysis.",
            "In that flavor it's a little bit more general form of the original pacbase.",
            "So then that can be solved for many problems and the second part is application of that to the MDL is a more general form of M DL2 parts code talker code.",
            "Essentially from that information theoretic inequality can get bound for this nonparametric MDL that I have two parts I will talk about the global entropy and the local local entropy.",
            "Then this part is related to some pretty well known earlier results of.",
            "Real with Tom Cover and Andrew Barrett.",
            "That's almost 20 years now then the third part will just try to apply.",
            "Basically the second part to a specific problem.",
            "This problem because the recently they draw a lot of interest.",
            "There are specific workshop about learning sparsity, so we will see what we can do with DL here.",
            "Essentially we just say if apply this bound to a specific formulation of MDL and give you some results.",
            "On the sparse learning.",
            "Setting so that gives you a concrete example of that, so therefore this is most aspect.",
            "This is a little bit less the specific MDR, but it's more general idea on this one specific example of MDR."
        ],
        [
            "More specific problem.",
            "OK, so notations notations I want use Z to represent data that is specially in the first part is more abstract version.",
            "Then we won't talk about density estimation, that's the estimation.",
            "Basically you have unknown true density.",
            "P Star Star is the truth which we want to estimate.",
            "Then we have a model parameter.",
            "Model is Theta.",
            "In this talk we call it Theta.",
            "Theta is just belongs to some set.",
            "For example if I have.",
            "Model distribution is P Theta ZP theaters index density index by Theta Act on the data Z.",
            "So that's a notation and then you have a loss function given a Theta and Z, you can say what is allowed suffered by this data, and sometimes either you eventually want to talk about density estimation, But the first part we talked, or loss when you have a log log loss with density, you can talk about the density estimation that the second or third.",
            "Part that you have a prior on it.",
            "This is different than the traditional analysis in the sense that we're going to talk about the randomized estimator.",
            "For example, pack base and this type of stuff talking about you started with some prior knowledge, so you believe what the distribution of theater would be then what your estimator will be a sample dependent randomization measure on this fact.",
            "So you're instead of estimated one particular Theta which will do.",
            "In the default setting, but in the more general setting you can talk about I, my estimator is a random measure on that space and this is random density with regard to the prior and you want to say this is your estimator, then eventually you draw from this random measure.",
            "When you compute the truth data and this is the expectation over Theta.",
            "Under this prior.",
            "Eventually it's just notation and we will talk about KL Divergent because they this is something.",
            "Which appears in the analysis and in the formulation, and this one essentially is.",
            "If you have a W is your whatever posterior or your randomisation measure is a expecting after log W, so that's what you are.",
            "Care divergences with with."
        ],
        [
            "Original Prior is so estimation problem.",
            "In this setting you have a lot of notations.",
            "I hope you can still remember some.",
            "The estimator is given observed data as as is the number of these basic training data and then you have a sample dependent randomization match.",
            "I mentioned your instead of estimated single Theta.",
            "You estimate distribution over SEAT which is your output and then if you have a distribution over Theta your.",
            "Base your quality of is from basically drawn Theta from this measure and you take the average averages.",
            "Your quality.",
            "For example this one if a loss function Theta with better truth that is your loss of data then this part means you draw with direct to this this randomization measure and given randomization measure this one will be your expected loss of your.",
            "Measure, so that's a setting, so this one, typically in the standard setting.",
            "This one will be a point measure, which means you have a single Theta.",
            "Here you just say you can have."
        ],
        [
            "Random seed, that's only difference.",
            "Now we talk about information theoretical inequalities in the more general setting.",
            "Then we will talk about more specific setting later.",
            "So if you didn't get it, it's not a big deal because it will come again over and over and it 3 times right off this.",
            "Basically, this is the information theoretic inequality.",
            "It's as I said, it's like, Pack base is just a little bit more general.",
            "So let us be these samples.",
            "Basically the training examples from some distribution and here is inequality and the right hand side will be your according to.",
            "This is true for any randomization measure.",
            "Therefore you can optimize.",
            "Typically what is done in this kind of literature is you provide bounds and bound is pretty nice on the right hand side and then this one is true for all W. Left hand side is can be regarded as the generalization error.",
            "Right hand side is the test error.",
            "Here is the test error because this is your randomization measure evaluated on your empirical distribution.",
            "This is on the true distribution and I'll talk a little bit later and then you add Cal Divergance.",
            "So so the right hand side would be your test error would be your.",
            "Nice nice kind of generalization error.",
            "Right hand side is your training error plus complexity.",
            "Measure this W we switch the pie.",
            "Is the complexity measure of your W. If this is a large you don't have good generalization.",
            "If it's more than you got generalization, this is true for all W. Therefore you can minimize."
        ],
        [
            "Right on the side here I just do some remark left underside what it is.",
            "This is expected to risk.",
            "Roughly, it's it's the expectational of L minus variance, and that's actually typical.",
            "Even you do empirical process analysis, you will see this, but I don't want to go over.",
            "Basically this form is something like you can.",
            "You can think that as the true expected risk of your Z minus the variance of your thing and for them DL it's become Rd eye vergence which is distance like Highlander Distance, Rd distance and so on.",
            "So you can combine those distance.",
            "The right hand side will be observed risk, which is the empirical risk plus your that complexity.",
            "Carol divergance.",
            "This can be applied to generous this estimation problem, loss function minimization problem.",
            "In particular, what we are interested in here is nonparametric MDL analysis.",
            "Then you can talk about Bayesian method can be analyzed, some empirical process and so on.",
            "You can also analyze this way.",
            "So there are different ways to this can be applied to.",
            "But what we are interested in here is."
        ],
        [
            "The first part.",
            "One thing I mentioned that that part is global, so called Global Bond.",
            "Here is a localized bound.",
            "What does that mean?",
            "This one almost the same.",
            "Expected at Alpha, but this one is like the original part plus localization term this term.",
            "You just need to remember this is basically.",
            "Different, this actually it's very small.",
            "If Theta else it is large.",
            "Let's say for some city with large risk.",
            "This part penalty expectation to the minus large will be expanding system or that thing you need to remember for the MDR case this won't be always negative.",
            "What does that mean?",
            "Negative if this is negative means right hand side is smaller so you can gain something out of that and will give a more concrete example.",
            "At this level it's maybe not exactly.",
            "Easy to see, but eventually we will see.",
            "Basically this is useful especially for when we look at the sparse sparse function estimation.",
            "You will see they have become very different if you don't use this term."
        ],
        [
            "Plus this term it becomes quite different now.",
            "As I mentioned, once you have that general bound, you can do the minimization of that bound.",
            "That's generally people do.",
            "When people derive learning bounds, general minimization of the right hand side is like this.",
            "This gives you an estimator.",
            "You basically find something to get the good left hand side, which is your generalization error.",
            "You just try to minimize the right hand side, which is your observed error plus complexity.",
            "So you can.",
            "You can choose general your minimizations through a set of measures and in the MPL.",
            "I will specifically the discrete measure.",
            "Basically the point measure on distributor side, so that's what MDL setting is and then will immediately to the next next slide.",
            "But then you have a general setting about doing it this way.",
            "If you do the localization it doesn't change this estimator.",
            "Eventually this one is.",
            "Estimate works for both block global and local localized measure because localization doesn't have another term."
        ],
        [
            "So special case that will be the second part.",
            "This is a more general.",
            "Probably you don't get too much, but hopefully this part gets a little bit more concrete.",
            "Next part is also a little bit more concrete.",
            "Special case is a two part code MD estimation.",
            "So what it is you consider discrete parameter space first.",
            "Basically just say 123 but doesn't matter it just discrete.",
            "Then you consider a prior.",
            "Remember we set the prior pair one Pi 2 on this.",
            "Parameter space when I say prior is some basically the larger equals zero, each pie and the sum of \u03c0 is 1.",
            "So that's a prior.",
            "So for two part code MPL, the idea is following.",
            "First you want coding length of your model is one over your prior log so that the coding length of your model, each model K you associated with prior.",
            "And this is your coding lens.",
            "This can be coded and then given this Model K you have coding length of your data.",
            "This is a coding length of your data.",
            "The log likelihood negative log likelihood is accordingly.",
            "Over data, so MTR principle basically say I want to minimize combined coding length of the Model K and the data given the model.",
            "So that's why I'm the operating support and what is the formulation and the formulation exactly like before, but in a special special."
        ],
        [
            "The case OK, so two part code MDI estimator is given by that this is the coding lines of data given the model.",
            "This is coalescer model.",
            "I have a tuning parameter Lambda.",
            "I will comment here but essentially take argument you find the model with the smallest coding less of your model that's here.",
            "Plus, uh, and you penalize a little bit more.",
            "Plus you you have the coordinates of the data.",
            "Lambda is the balance between the two parts to say.",
            "Whether you want to over penalize your model coding lines.",
            "In fact, it's actually good to our penalize your coding lines of your model because that game your stability.",
            "If you don't do that, it could fail in some setting.",
            "It's not always failed, but it could.",
            "I will probably say a little bit about that, but essentially we have Lambda larger than one.",
            "Which means you want to trust your prior more.",
            "You give you more stability.",
            "So it's avoid overfitting, so that's the main purpose of that.",
            "Essentially, you want to say I want to balance this part.",
            "I try to have overall penalization of my coding.",
            "Lots of data and coding lines of your model try to balance that.",
            "So this is special case of the."
        ],
        [
            "Of this formula, which we talk about earlier.",
            "Therefore we can use that that information theoretic inequality to analyze MDL, specifically of this formula, because this W."
        ],
        [
            "The point is that.",
            "W is a set of point measures.",
            "At some KK is 12345 and that gives you exactly this formulation and because of that you can use the analysis previous developer just to."
        ],
        [
            "Apply to here and I'll just give you the result.",
            "Oh, so one thing I mentioned, the left hand side for the."
        ],
        [
            "For the if you look at the symbol, here is the left hand side.",
            "What is the least left side?"
        ],
        [
            "Here is a so called Joe Rd distance.",
            "No distances.",
            "The more well known is 0.50 = 0.5, which is Hollinger distance, but in general you can have a role equals 0.1.",
            "So give your divergance.",
            "Kel Divergent, which is more familiar version of that will be is D0 actually no equalizer zero or one give UCL but they just reverse whether it's QP or PQ.",
            "But essentially KL is this and in general you have a more general form and 0.5 is called Hollinger, which also commonly used.",
            "But generally you can consider all these show last clarity findings essentially.",
            "There is a distance between two distributions, so that's all you need to know.",
            "A general bound of low divergent company value because the left hand side on that equation helps."
        ],
        [
            "Would be the road I vergence, so here is what you have now.",
            "You have MPI estimator which is the give you remember the two part code.",
            "MD is a Lambda, Lambda is balancing the two parts.",
            "Then this is the expected generalization perform.",
            "This is the truth.",
            "This issue, MDL estimator.",
            "This is the expect generalization.",
            "You basically expect the road I vergence of your MPR estimator and you'll choose over South as is the training examples smaller than a constant one Lambda larger than one times this quantity.",
            "This quantity is you take the best model.",
            "This one is expected.",
            "All diversions.",
            "So if you have a model which have very close to P. Star with scale divergance.",
            "And the packet also is not too small.",
            "Then this quantity is small, because this part divided by N so.",
            "There are also one result of areas of similar sort divided by.",
            "Lee and Baron.",
            "It's around the titer result in the sense for the nonparametric mini Max rate.",
            "If they can be achieved.",
            "Basically, this one gives you the right rate.",
            "It doesn't work for the parametric setting.",
            "That's where the localization comes, but in the sparse learning is actually a mixture of nonparametric parametric.",
            "Therefore you need the localization to get good thing good behavior, so convergence behavior determined by prior I'm saying is local if well well behaved prior is locali around P stock.",
            "Oh basically, means that.",
            "So you have that power is 1.",
            "Oh OK, so you reverse that.",
            "Questions OK, I think so.",
            "You're basically you reverse the.",
            "Basically you can have K which is not IK specially good prior and this close to P style you can get good convergence."
        ],
        [
            "If your Lambda equals one, that's not the case, and this is localization.",
            "Localizations only thing is this term is changed to a localized term.",
            "It's a complicated here, but essentially this smaller than one, so that's what you need, and if you get parametric rate 1 / N, you have to do this.",
            "This one will never get your parametric rate 1 / N, But this one will give you that that I'll show you the result in this sparse learning what you."
        ],
        [
            "Get from these two pounds.",
            "If a Lambda discourse, one against has to be global structure, you can divide bound similarly, but this one is more complicated.",
            "This one is like the number larger than one case, but this one it becomes can be large and that is depend on the global structure, which means that actually just locally well behaved.",
            "For example, even I put P start with the prior 1 / 4 one Lambda larger than one.",
            "I can have a good estimate because of the previous result.",
            "But one the standard MPL Lambda equals one, which you balanced coding less exactly then actually it doesn't perform well if it can fail.",
            "Basically, it does not observe.",
            "Basically only estimate P style with very small probability.",
            "In this case I don't want to."
        ],
        [
            "Go over that.",
            "I would just go to the third because the time constraint, essentially, the pointer is alarmed larger than one is useful, at least for some problems.",
            "So we will talk about Lambda larger one larger than one.",
            "When we look at the sparse learning.",
            "So sparse learning is actually regression problem.",
            "It's conditional density estimation, not the exact estimation.",
            "Z is X&Y, input is X, outputs Y conditional density estimation, which means it's Gaussian, so you have.",
            "This is Aurora theater Theater is a weight vector times your XI and you have added noise, noise, sequence, square and then you generate Y.",
            "This is standard regression setting and then you want to find Theta.",
            "Theta is D dimensional vector.",
            "The interesting case which recently is that the number of dimension is much larger than North.",
            "That's something we want and the city is also sparse.",
            "See the sparse means that the zero norm of data number of nonzeros is much smaller than the optimal system.",
            "So basically this is a setting learning sparse linear."
        ],
        [
            "What you do is MDR MDR.",
            "Basically, you just code first.",
            "If we apply that, we do a discrete data.",
            "This is minor thing if you want to use continuous is OK, but for our theory just let's look at the discrete coding of data.",
            "Each component you have the components, each component as discrete value.",
            "Basically it's a multiply of some.",
            "Delta so Theta J over Delta is an integer, and for each one if K is this one larger than zero.",
            "Basically you code settle with zero with very large probability.",
            "D Remember is very very large and therefore this is very large, probably to code so you think it's very likely theater will goes to zero.",
            "Very unlikely.",
            "City is going to go into not zero, so that's your coding.",
            "You don't need to know the number of.",
            "Now there are coefficients, because that's actually not important.",
            "When you develop an, this actually works fine.",
            "State know that Delta is is this guy.",
            "She is now."
        ],
        [
            "Property mentions relatives here sorry."
        ],
        [
            "Yeah, right, that's a large right?",
            "So this is a large DDD is small.",
            "It's a sequence noise divided by square root of.",
            "Basically this is the point of this price.",
            "It doesn't depend on the number of non zero coefficients and other things so you can develop other priors as well.",
            "This is the one prior you can do and for the whole price product prior its product, each individual one, and so conditional density estimation becomes this one.",
            "Is this MDL formulation.",
            "And the you minimize data.",
            "You can over discrete if you want to.",
            "Crossover continues.",
            "Here is a modified version which I."
        ],
        [
            "The same behavior you can modify later, but it really doesn't have to.",
            "This guy is a modified version of just just give you an idea of what the penalty likes.",
            "So this is a typical regression term.",
            "This one is alarmed at Times Sigma Square and now you have something like sum of log of Delta plus D times.",
            "System.",
            "So that's essentially is your MPL.",
            "Again, you can choose Delta Delta, become a Sigma over square root of this small number.",
            "These large number and this becomes your MDL.",
            "It's more intuitive version than."
        ],
        [
            "That at least washer.",
            "But essentially they are behave."
        ],
        [
            "Are there similar because this one is just making this a little bit smoother version?"
        ],
        [
            "Alpha of this guy.",
            "So here is what it is is like, I'm the estimation.",
            "I'm talking about theories in the discrete setting, but you can use continues, and this is nonconvex optimization, by the way, so it's not convex.",
            "And if you do nonconvex certain, say, give you some benefit, it does give you some benefits.",
            "That's what I'm coming compared with combat CL.",
            "One path following algorithm, you can solve that.",
            "There are ways to solve that.",
            "Particular, there's freedom as one version called Generalized Part Secret.",
            "There other method?"
        ],
        [
            "To solve."
        ],
        [
            "Non convex optimized."
        ],
        [
            "Problem like these.",
            "So, but I'm not talking about the numerical part, I'm more talking about the bounds, so global empty outbound.",
            "So what you get just apply that bound.",
            "Try to analyze here.",
            "I will assume that role distance is equivalent to the.",
            "For those smaller equivalent to the KL Divergent, and that's true.",
            "So therefore the left hand side throw distance KL divergences.",
            "This setting, this is becomes least squares, become KL divergent sand in that particular case you just change the audition, become care divergent multiplied by C in this setting is truly I don't want to go over that, I just need to work on workout something and then then then they are there is info over maximum pluses penalty.",
            "So this is a global penalty what it is.",
            "If you look at this penalty, what it is is that the first you have number of nonzero components times logged in, so you have a log defect log in factor.",
            "Secondly you have Jay over all the sum plus one plus Theta J.",
            "If CJ is 0 this one is 0 right?",
            "So this one effects only some over the components of city which is not zero.",
            "So you only look at the steel is proportional to 6 zero but still is log sheet.",
            "You have a log Seattle Opti log North, which is OK."
        ],
        [
            "But you can do better if you do the localized bound, so here the localized bound you modify, roughly something like similar, but this one is.",
            "You cannot get this no logged in here, so you can get Theta zero.",
            "Basically non zero components, only square City Square over N plus adicional.",
            "The nice thing about these things is the following.",
            "This is so one 1:30 is large.",
            "This one can never large the log D, right?",
            "So this one is never larger than log because this is smaller than One South.",
            "But this one can be much smaller, especially when this guy is larger than the noise threshold logged over, and it's like typically like noise threshold.",
            "Once he makes much larger than that, this becomes exponentially small.",
            "This becomes much smaller than one, therefore experience more in North 130 is not too small.",
            "So that's the point.",
            "This can be much much."
        ],
        [
            "Are compared with that and I will just briefly give combination without one.",
            "You have this log D factor here.",
            "So if each each each of this parameter is much larger than the more it stretch code that you don't have this logged in, so that's a difference.",
            "Anyway, so.",
            "And then actually it's expansion is small in this D in this case.",
            "So basically you have you have a rate which is largely."
        ],
        [
            "OK, anyway, so there's some summaries so probably will be quick, but essentially there's three parts.",
            "Why is general inequality nice?",
            "Empty outline specific application?",
            "Offer to the learning sparsity."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the outline.",
                    "label": 0
                },
                {
                    "sent": "There's three parts of this talk, basically from more abstract to less abstract.",
                    "label": 0
                },
                {
                    "sent": "First is the more extra part, basics more of more general information theoretic inequality, which is some people know like pacbase analysis.",
                    "label": 0
                },
                {
                    "sent": "In that flavor it's a little bit more general form of the original pacbase.",
                    "label": 1
                },
                {
                    "sent": "So then that can be solved for many problems and the second part is application of that to the MDL is a more general form of M DL2 parts code talker code.",
                    "label": 0
                },
                {
                    "sent": "Essentially from that information theoretic inequality can get bound for this nonparametric MDL that I have two parts I will talk about the global entropy and the local local entropy.",
                    "label": 1
                },
                {
                    "sent": "Then this part is related to some pretty well known earlier results of.",
                    "label": 0
                },
                {
                    "sent": "Real with Tom Cover and Andrew Barrett.",
                    "label": 0
                },
                {
                    "sent": "That's almost 20 years now then the third part will just try to apply.",
                    "label": 0
                },
                {
                    "sent": "Basically the second part to a specific problem.",
                    "label": 0
                },
                {
                    "sent": "This problem because the recently they draw a lot of interest.",
                    "label": 0
                },
                {
                    "sent": "There are specific workshop about learning sparsity, so we will see what we can do with DL here.",
                    "label": 0
                },
                {
                    "sent": "Essentially we just say if apply this bound to a specific formulation of MDL and give you some results.",
                    "label": 0
                },
                {
                    "sent": "On the sparse learning.",
                    "label": 0
                },
                {
                    "sent": "Setting so that gives you a concrete example of that, so therefore this is most aspect.",
                    "label": 0
                },
                {
                    "sent": "This is a little bit less the specific MDR, but it's more general idea on this one specific example of MDR.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More specific problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so notations notations I want use Z to represent data that is specially in the first part is more abstract version.",
                    "label": 0
                },
                {
                    "sent": "Then we won't talk about density estimation, that's the estimation.",
                    "label": 0
                },
                {
                    "sent": "Basically you have unknown true density.",
                    "label": 1
                },
                {
                    "sent": "P Star Star is the truth which we want to estimate.",
                    "label": 1
                },
                {
                    "sent": "Then we have a model parameter.",
                    "label": 0
                },
                {
                    "sent": "Model is Theta.",
                    "label": 0
                },
                {
                    "sent": "In this talk we call it Theta.",
                    "label": 0
                },
                {
                    "sent": "Theta is just belongs to some set.",
                    "label": 0
                },
                {
                    "sent": "For example if I have.",
                    "label": 1
                },
                {
                    "sent": "Model distribution is P Theta ZP theaters index density index by Theta Act on the data Z.",
                    "label": 0
                },
                {
                    "sent": "So that's a notation and then you have a loss function given a Theta and Z, you can say what is allowed suffered by this data, and sometimes either you eventually want to talk about density estimation, But the first part we talked, or loss when you have a log log loss with density, you can talk about the density estimation that the second or third.",
                    "label": 0
                },
                {
                    "sent": "Part that you have a prior on it.",
                    "label": 0
                },
                {
                    "sent": "This is different than the traditional analysis in the sense that we're going to talk about the randomized estimator.",
                    "label": 1
                },
                {
                    "sent": "For example, pack base and this type of stuff talking about you started with some prior knowledge, so you believe what the distribution of theater would be then what your estimator will be a sample dependent randomization measure on this fact.",
                    "label": 0
                },
                {
                    "sent": "So you're instead of estimated one particular Theta which will do.",
                    "label": 0
                },
                {
                    "sent": "In the default setting, but in the more general setting you can talk about I, my estimator is a random measure on that space and this is random density with regard to the prior and you want to say this is your estimator, then eventually you draw from this random measure.",
                    "label": 0
                },
                {
                    "sent": "When you compute the truth data and this is the expectation over Theta.",
                    "label": 0
                },
                {
                    "sent": "Under this prior.",
                    "label": 0
                },
                {
                    "sent": "Eventually it's just notation and we will talk about KL Divergent because they this is something.",
                    "label": 0
                },
                {
                    "sent": "Which appears in the analysis and in the formulation, and this one essentially is.",
                    "label": 0
                },
                {
                    "sent": "If you have a W is your whatever posterior or your randomisation measure is a expecting after log W, so that's what you are.",
                    "label": 0
                },
                {
                    "sent": "Care divergences with with.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Original Prior is so estimation problem.",
                    "label": 0
                },
                {
                    "sent": "In this setting you have a lot of notations.",
                    "label": 0
                },
                {
                    "sent": "I hope you can still remember some.",
                    "label": 0
                },
                {
                    "sent": "The estimator is given observed data as as is the number of these basic training data and then you have a sample dependent randomization match.",
                    "label": 1
                },
                {
                    "sent": "I mentioned your instead of estimated single Theta.",
                    "label": 0
                },
                {
                    "sent": "You estimate distribution over SEAT which is your output and then if you have a distribution over Theta your.",
                    "label": 0
                },
                {
                    "sent": "Base your quality of is from basically drawn Theta from this measure and you take the average averages.",
                    "label": 0
                },
                {
                    "sent": "Your quality.",
                    "label": 0
                },
                {
                    "sent": "For example this one if a loss function Theta with better truth that is your loss of data then this part means you draw with direct to this this randomization measure and given randomization measure this one will be your expected loss of your.",
                    "label": 1
                },
                {
                    "sent": "Measure, so that's a setting, so this one, typically in the standard setting.",
                    "label": 0
                },
                {
                    "sent": "This one will be a point measure, which means you have a single Theta.",
                    "label": 0
                },
                {
                    "sent": "Here you just say you can have.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Random seed, that's only difference.",
                    "label": 0
                },
                {
                    "sent": "Now we talk about information theoretical inequalities in the more general setting.",
                    "label": 0
                },
                {
                    "sent": "Then we will talk about more specific setting later.",
                    "label": 0
                },
                {
                    "sent": "So if you didn't get it, it's not a big deal because it will come again over and over and it 3 times right off this.",
                    "label": 0
                },
                {
                    "sent": "Basically, this is the information theoretic inequality.",
                    "label": 0
                },
                {
                    "sent": "It's as I said, it's like, Pack base is just a little bit more general.",
                    "label": 0
                },
                {
                    "sent": "So let us be these samples.",
                    "label": 0
                },
                {
                    "sent": "Basically the training examples from some distribution and here is inequality and the right hand side will be your according to.",
                    "label": 0
                },
                {
                    "sent": "This is true for any randomization measure.",
                    "label": 0
                },
                {
                    "sent": "Therefore you can optimize.",
                    "label": 0
                },
                {
                    "sent": "Typically what is done in this kind of literature is you provide bounds and bound is pretty nice on the right hand side and then this one is true for all W. Left hand side is can be regarded as the generalization error.",
                    "label": 0
                },
                {
                    "sent": "Right hand side is the test error.",
                    "label": 0
                },
                {
                    "sent": "Here is the test error because this is your randomization measure evaluated on your empirical distribution.",
                    "label": 0
                },
                {
                    "sent": "This is on the true distribution and I'll talk a little bit later and then you add Cal Divergance.",
                    "label": 0
                },
                {
                    "sent": "So so the right hand side would be your test error would be your.",
                    "label": 0
                },
                {
                    "sent": "Nice nice kind of generalization error.",
                    "label": 0
                },
                {
                    "sent": "Right hand side is your training error plus complexity.",
                    "label": 0
                },
                {
                    "sent": "Measure this W we switch the pie.",
                    "label": 0
                },
                {
                    "sent": "Is the complexity measure of your W. If this is a large you don't have good generalization.",
                    "label": 0
                },
                {
                    "sent": "If it's more than you got generalization, this is true for all W. Therefore you can minimize.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right on the side here I just do some remark left underside what it is.",
                    "label": 0
                },
                {
                    "sent": "This is expected to risk.",
                    "label": 0
                },
                {
                    "sent": "Roughly, it's it's the expectational of L minus variance, and that's actually typical.",
                    "label": 0
                },
                {
                    "sent": "Even you do empirical process analysis, you will see this, but I don't want to go over.",
                    "label": 0
                },
                {
                    "sent": "Basically this form is something like you can.",
                    "label": 0
                },
                {
                    "sent": "You can think that as the true expected risk of your Z minus the variance of your thing and for them DL it's become Rd eye vergence which is distance like Highlander Distance, Rd distance and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can combine those distance.",
                    "label": 0
                },
                {
                    "sent": "The right hand side will be observed risk, which is the empirical risk plus your that complexity.",
                    "label": 1
                },
                {
                    "sent": "Carol divergance.",
                    "label": 0
                },
                {
                    "sent": "This can be applied to generous this estimation problem, loss function minimization problem.",
                    "label": 1
                },
                {
                    "sent": "In particular, what we are interested in here is nonparametric MDL analysis.",
                    "label": 0
                },
                {
                    "sent": "Then you can talk about Bayesian method can be analyzed, some empirical process and so on.",
                    "label": 0
                },
                {
                    "sent": "You can also analyze this way.",
                    "label": 1
                },
                {
                    "sent": "So there are different ways to this can be applied to.",
                    "label": 0
                },
                {
                    "sent": "But what we are interested in here is.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first part.",
                    "label": 0
                },
                {
                    "sent": "One thing I mentioned that that part is global, so called Global Bond.",
                    "label": 0
                },
                {
                    "sent": "Here is a localized bound.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "This one almost the same.",
                    "label": 0
                },
                {
                    "sent": "Expected at Alpha, but this one is like the original part plus localization term this term.",
                    "label": 0
                },
                {
                    "sent": "You just need to remember this is basically.",
                    "label": 0
                },
                {
                    "sent": "Different, this actually it's very small.",
                    "label": 0
                },
                {
                    "sent": "If Theta else it is large.",
                    "label": 0
                },
                {
                    "sent": "Let's say for some city with large risk.",
                    "label": 1
                },
                {
                    "sent": "This part penalty expectation to the minus large will be expanding system or that thing you need to remember for the MDR case this won't be always negative.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "Negative if this is negative means right hand side is smaller so you can gain something out of that and will give a more concrete example.",
                    "label": 0
                },
                {
                    "sent": "At this level it's maybe not exactly.",
                    "label": 0
                },
                {
                    "sent": "Easy to see, but eventually we will see.",
                    "label": 0
                },
                {
                    "sent": "Basically this is useful especially for when we look at the sparse sparse function estimation.",
                    "label": 0
                },
                {
                    "sent": "You will see they have become very different if you don't use this term.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Plus this term it becomes quite different now.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, once you have that general bound, you can do the minimization of that bound.",
                    "label": 0
                },
                {
                    "sent": "That's generally people do.",
                    "label": 0
                },
                {
                    "sent": "When people derive learning bounds, general minimization of the right hand side is like this.",
                    "label": 1
                },
                {
                    "sent": "This gives you an estimator.",
                    "label": 0
                },
                {
                    "sent": "You basically find something to get the good left hand side, which is your generalization error.",
                    "label": 0
                },
                {
                    "sent": "You just try to minimize the right hand side, which is your observed error plus complexity.",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "You can choose general your minimizations through a set of measures and in the MPL.",
                    "label": 1
                },
                {
                    "sent": "I will specifically the discrete measure.",
                    "label": 0
                },
                {
                    "sent": "Basically the point measure on distributor side, so that's what MDL setting is and then will immediately to the next next slide.",
                    "label": 0
                },
                {
                    "sent": "But then you have a general setting about doing it this way.",
                    "label": 0
                },
                {
                    "sent": "If you do the localization it doesn't change this estimator.",
                    "label": 0
                },
                {
                    "sent": "Eventually this one is.",
                    "label": 0
                },
                {
                    "sent": "Estimate works for both block global and local localized measure because localization doesn't have another term.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So special case that will be the second part.",
                    "label": 0
                },
                {
                    "sent": "This is a more general.",
                    "label": 0
                },
                {
                    "sent": "Probably you don't get too much, but hopefully this part gets a little bit more concrete.",
                    "label": 0
                },
                {
                    "sent": "Next part is also a little bit more concrete.",
                    "label": 0
                },
                {
                    "sent": "Special case is a two part code MD estimation.",
                    "label": 0
                },
                {
                    "sent": "So what it is you consider discrete parameter space first.",
                    "label": 0
                },
                {
                    "sent": "Basically just say 123 but doesn't matter it just discrete.",
                    "label": 0
                },
                {
                    "sent": "Then you consider a prior.",
                    "label": 0
                },
                {
                    "sent": "Remember we set the prior pair one Pi 2 on this.",
                    "label": 0
                },
                {
                    "sent": "Parameter space when I say prior is some basically the larger equals zero, each pie and the sum of \u03c0 is 1.",
                    "label": 0
                },
                {
                    "sent": "So that's a prior.",
                    "label": 0
                },
                {
                    "sent": "So for two part code MPL, the idea is following.",
                    "label": 0
                },
                {
                    "sent": "First you want coding length of your model is one over your prior log so that the coding length of your model, each model K you associated with prior.",
                    "label": 0
                },
                {
                    "sent": "And this is your coding lens.",
                    "label": 0
                },
                {
                    "sent": "This can be coded and then given this Model K you have coding length of your data.",
                    "label": 0
                },
                {
                    "sent": "This is a coding length of your data.",
                    "label": 0
                },
                {
                    "sent": "The log likelihood negative log likelihood is accordingly.",
                    "label": 0
                },
                {
                    "sent": "Over data, so MTR principle basically say I want to minimize combined coding length of the Model K and the data given the model.",
                    "label": 1
                },
                {
                    "sent": "So that's why I'm the operating support and what is the formulation and the formulation exactly like before, but in a special special.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The case OK, so two part code MDI estimator is given by that this is the coding lines of data given the model.",
                    "label": 0
                },
                {
                    "sent": "This is coalescer model.",
                    "label": 0
                },
                {
                    "sent": "I have a tuning parameter Lambda.",
                    "label": 0
                },
                {
                    "sent": "I will comment here but essentially take argument you find the model with the smallest coding less of your model that's here.",
                    "label": 0
                },
                {
                    "sent": "Plus, uh, and you penalize a little bit more.",
                    "label": 0
                },
                {
                    "sent": "Plus you you have the coordinates of the data.",
                    "label": 1
                },
                {
                    "sent": "Lambda is the balance between the two parts to say.",
                    "label": 1
                },
                {
                    "sent": "Whether you want to over penalize your model coding lines.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's actually good to our penalize your coding lines of your model because that game your stability.",
                    "label": 0
                },
                {
                    "sent": "If you don't do that, it could fail in some setting.",
                    "label": 0
                },
                {
                    "sent": "It's not always failed, but it could.",
                    "label": 0
                },
                {
                    "sent": "I will probably say a little bit about that, but essentially we have Lambda larger than one.",
                    "label": 0
                },
                {
                    "sent": "Which means you want to trust your prior more.",
                    "label": 1
                },
                {
                    "sent": "You give you more stability.",
                    "label": 0
                },
                {
                    "sent": "So it's avoid overfitting, so that's the main purpose of that.",
                    "label": 0
                },
                {
                    "sent": "Essentially, you want to say I want to balance this part.",
                    "label": 0
                },
                {
                    "sent": "I try to have overall penalization of my coding.",
                    "label": 0
                },
                {
                    "sent": "Lots of data and coding lines of your model try to balance that.",
                    "label": 0
                },
                {
                    "sent": "So this is special case of the.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this formula, which we talk about earlier.",
                    "label": 0
                },
                {
                    "sent": "Therefore we can use that that information theoretic inequality to analyze MDL, specifically of this formula, because this W.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The point is that.",
                    "label": 0
                },
                {
                    "sent": "W is a set of point measures.",
                    "label": 1
                },
                {
                    "sent": "At some KK is 12345 and that gives you exactly this formulation and because of that you can use the analysis previous developer just to.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apply to here and I'll just give you the result.",
                    "label": 0
                },
                {
                    "sent": "Oh, so one thing I mentioned, the left hand side for the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the if you look at the symbol, here is the left hand side.",
                    "label": 0
                },
                {
                    "sent": "What is the least left side?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is a so called Joe Rd distance.",
                    "label": 0
                },
                {
                    "sent": "No distances.",
                    "label": 0
                },
                {
                    "sent": "The more well known is 0.50 = 0.5, which is Hollinger distance, but in general you can have a role equals 0.1.",
                    "label": 0
                },
                {
                    "sent": "So give your divergance.",
                    "label": 0
                },
                {
                    "sent": "Kel Divergent, which is more familiar version of that will be is D0 actually no equalizer zero or one give UCL but they just reverse whether it's QP or PQ.",
                    "label": 0
                },
                {
                    "sent": "But essentially KL is this and in general you have a more general form and 0.5 is called Hollinger, which also commonly used.",
                    "label": 0
                },
                {
                    "sent": "But generally you can consider all these show last clarity findings essentially.",
                    "label": 0
                },
                {
                    "sent": "There is a distance between two distributions, so that's all you need to know.",
                    "label": 0
                },
                {
                    "sent": "A general bound of low divergent company value because the left hand side on that equation helps.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Would be the road I vergence, so here is what you have now.",
                    "label": 0
                },
                {
                    "sent": "You have MPI estimator which is the give you remember the two part code.",
                    "label": 0
                },
                {
                    "sent": "MD is a Lambda, Lambda is balancing the two parts.",
                    "label": 0
                },
                {
                    "sent": "Then this is the expected generalization perform.",
                    "label": 0
                },
                {
                    "sent": "This is the truth.",
                    "label": 0
                },
                {
                    "sent": "This issue, MDL estimator.",
                    "label": 0
                },
                {
                    "sent": "This is the expect generalization.",
                    "label": 0
                },
                {
                    "sent": "You basically expect the road I vergence of your MPR estimator and you'll choose over South as is the training examples smaller than a constant one Lambda larger than one times this quantity.",
                    "label": 0
                },
                {
                    "sent": "This quantity is you take the best model.",
                    "label": 0
                },
                {
                    "sent": "This one is expected.",
                    "label": 0
                },
                {
                    "sent": "All diversions.",
                    "label": 0
                },
                {
                    "sent": "So if you have a model which have very close to P. Star with scale divergance.",
                    "label": 0
                },
                {
                    "sent": "And the packet also is not too small.",
                    "label": 0
                },
                {
                    "sent": "Then this quantity is small, because this part divided by N so.",
                    "label": 0
                },
                {
                    "sent": "There are also one result of areas of similar sort divided by.",
                    "label": 0
                },
                {
                    "sent": "Lee and Baron.",
                    "label": 0
                },
                {
                    "sent": "It's around the titer result in the sense for the nonparametric mini Max rate.",
                    "label": 0
                },
                {
                    "sent": "If they can be achieved.",
                    "label": 0
                },
                {
                    "sent": "Basically, this one gives you the right rate.",
                    "label": 0
                },
                {
                    "sent": "It doesn't work for the parametric setting.",
                    "label": 0
                },
                {
                    "sent": "That's where the localization comes, but in the sparse learning is actually a mixture of nonparametric parametric.",
                    "label": 0
                },
                {
                    "sent": "Therefore you need the localization to get good thing good behavior, so convergence behavior determined by prior I'm saying is local if well well behaved prior is locali around P stock.",
                    "label": 0
                },
                {
                    "sent": "Oh basically, means that.",
                    "label": 0
                },
                {
                    "sent": "So you have that power is 1.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, so you reverse that.",
                    "label": 0
                },
                {
                    "sent": "Questions OK, I think so.",
                    "label": 0
                },
                {
                    "sent": "You're basically you reverse the.",
                    "label": 0
                },
                {
                    "sent": "Basically you can have K which is not IK specially good prior and this close to P style you can get good convergence.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If your Lambda equals one, that's not the case, and this is localization.",
                    "label": 0
                },
                {
                    "sent": "Localizations only thing is this term is changed to a localized term.",
                    "label": 0
                },
                {
                    "sent": "It's a complicated here, but essentially this smaller than one, so that's what you need, and if you get parametric rate 1 / N, you have to do this.",
                    "label": 0
                },
                {
                    "sent": "This one will never get your parametric rate 1 / N, But this one will give you that that I'll show you the result in this sparse learning what you.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Get from these two pounds.",
                    "label": 0
                },
                {
                    "sent": "If a Lambda discourse, one against has to be global structure, you can divide bound similarly, but this one is more complicated.",
                    "label": 0
                },
                {
                    "sent": "This one is like the number larger than one case, but this one it becomes can be large and that is depend on the global structure, which means that actually just locally well behaved.",
                    "label": 0
                },
                {
                    "sent": "For example, even I put P start with the prior 1 / 4 one Lambda larger than one.",
                    "label": 0
                },
                {
                    "sent": "I can have a good estimate because of the previous result.",
                    "label": 0
                },
                {
                    "sent": "But one the standard MPL Lambda equals one, which you balanced coding less exactly then actually it doesn't perform well if it can fail.",
                    "label": 0
                },
                {
                    "sent": "Basically, it does not observe.",
                    "label": 0
                },
                {
                    "sent": "Basically only estimate P style with very small probability.",
                    "label": 0
                },
                {
                    "sent": "In this case I don't want to.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go over that.",
                    "label": 0
                },
                {
                    "sent": "I would just go to the third because the time constraint, essentially, the pointer is alarmed larger than one is useful, at least for some problems.",
                    "label": 0
                },
                {
                    "sent": "So we will talk about Lambda larger one larger than one.",
                    "label": 0
                },
                {
                    "sent": "When we look at the sparse learning.",
                    "label": 1
                },
                {
                    "sent": "So sparse learning is actually regression problem.",
                    "label": 1
                },
                {
                    "sent": "It's conditional density estimation, not the exact estimation.",
                    "label": 0
                },
                {
                    "sent": "Z is X&Y, input is X, outputs Y conditional density estimation, which means it's Gaussian, so you have.",
                    "label": 0
                },
                {
                    "sent": "This is Aurora theater Theater is a weight vector times your XI and you have added noise, noise, sequence, square and then you generate Y.",
                    "label": 1
                },
                {
                    "sent": "This is standard regression setting and then you want to find Theta.",
                    "label": 1
                },
                {
                    "sent": "Theta is D dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "The interesting case which recently is that the number of dimension is much larger than North.",
                    "label": 0
                },
                {
                    "sent": "That's something we want and the city is also sparse.",
                    "label": 0
                },
                {
                    "sent": "See the sparse means that the zero norm of data number of nonzeros is much smaller than the optimal system.",
                    "label": 0
                },
                {
                    "sent": "So basically this is a setting learning sparse linear.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you do is MDR MDR.",
                    "label": 0
                },
                {
                    "sent": "Basically, you just code first.",
                    "label": 0
                },
                {
                    "sent": "If we apply that, we do a discrete data.",
                    "label": 0
                },
                {
                    "sent": "This is minor thing if you want to use continuous is OK, but for our theory just let's look at the discrete coding of data.",
                    "label": 0
                },
                {
                    "sent": "Each component you have the components, each component as discrete value.",
                    "label": 0
                },
                {
                    "sent": "Basically it's a multiply of some.",
                    "label": 0
                },
                {
                    "sent": "Delta so Theta J over Delta is an integer, and for each one if K is this one larger than zero.",
                    "label": 0
                },
                {
                    "sent": "Basically you code settle with zero with very large probability.",
                    "label": 0
                },
                {
                    "sent": "D Remember is very very large and therefore this is very large, probably to code so you think it's very likely theater will goes to zero.",
                    "label": 0
                },
                {
                    "sent": "Very unlikely.",
                    "label": 0
                },
                {
                    "sent": "City is going to go into not zero, so that's your coding.",
                    "label": 0
                },
                {
                    "sent": "You don't need to know the number of.",
                    "label": 0
                },
                {
                    "sent": "Now there are coefficients, because that's actually not important.",
                    "label": 0
                },
                {
                    "sent": "When you develop an, this actually works fine.",
                    "label": 0
                },
                {
                    "sent": "State know that Delta is is this guy.",
                    "label": 0
                },
                {
                    "sent": "She is now.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Property mentions relatives here sorry.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, right, that's a large right?",
                    "label": 0
                },
                {
                    "sent": "So this is a large DDD is small.",
                    "label": 0
                },
                {
                    "sent": "It's a sequence noise divided by square root of.",
                    "label": 0
                },
                {
                    "sent": "Basically this is the point of this price.",
                    "label": 0
                },
                {
                    "sent": "It doesn't depend on the number of non zero coefficients and other things so you can develop other priors as well.",
                    "label": 0
                },
                {
                    "sent": "This is the one prior you can do and for the whole price product prior its product, each individual one, and so conditional density estimation becomes this one.",
                    "label": 1
                },
                {
                    "sent": "Is this MDL formulation.",
                    "label": 0
                },
                {
                    "sent": "And the you minimize data.",
                    "label": 0
                },
                {
                    "sent": "You can over discrete if you want to.",
                    "label": 0
                },
                {
                    "sent": "Crossover continues.",
                    "label": 0
                },
                {
                    "sent": "Here is a modified version which I.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same behavior you can modify later, but it really doesn't have to.",
                    "label": 0
                },
                {
                    "sent": "This guy is a modified version of just just give you an idea of what the penalty likes.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical regression term.",
                    "label": 0
                },
                {
                    "sent": "This one is alarmed at Times Sigma Square and now you have something like sum of log of Delta plus D times.",
                    "label": 0
                },
                {
                    "sent": "System.",
                    "label": 0
                },
                {
                    "sent": "So that's essentially is your MPL.",
                    "label": 0
                },
                {
                    "sent": "Again, you can choose Delta Delta, become a Sigma over square root of this small number.",
                    "label": 0
                },
                {
                    "sent": "These large number and this becomes your MDL.",
                    "label": 0
                },
                {
                    "sent": "It's more intuitive version than.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That at least washer.",
                    "label": 0
                },
                {
                    "sent": "But essentially they are behave.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are there similar because this one is just making this a little bit smoother version?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alpha of this guy.",
                    "label": 0
                },
                {
                    "sent": "So here is what it is is like, I'm the estimation.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about theories in the discrete setting, but you can use continues, and this is nonconvex optimization, by the way, so it's not convex.",
                    "label": 1
                },
                {
                    "sent": "And if you do nonconvex certain, say, give you some benefit, it does give you some benefits.",
                    "label": 0
                },
                {
                    "sent": "That's what I'm coming compared with combat CL.",
                    "label": 0
                },
                {
                    "sent": "One path following algorithm, you can solve that.",
                    "label": 1
                },
                {
                    "sent": "There are ways to solve that.",
                    "label": 0
                },
                {
                    "sent": "Particular, there's freedom as one version called Generalized Part Secret.",
                    "label": 0
                },
                {
                    "sent": "There other method?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To solve.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Non convex optimized.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem like these.",
                    "label": 0
                },
                {
                    "sent": "So, but I'm not talking about the numerical part, I'm more talking about the bounds, so global empty outbound.",
                    "label": 0
                },
                {
                    "sent": "So what you get just apply that bound.",
                    "label": 0
                },
                {
                    "sent": "Try to analyze here.",
                    "label": 0
                },
                {
                    "sent": "I will assume that role distance is equivalent to the.",
                    "label": 1
                },
                {
                    "sent": "For those smaller equivalent to the KL Divergent, and that's true.",
                    "label": 0
                },
                {
                    "sent": "So therefore the left hand side throw distance KL divergences.",
                    "label": 0
                },
                {
                    "sent": "This setting, this is becomes least squares, become KL divergent sand in that particular case you just change the audition, become care divergent multiplied by C in this setting is truly I don't want to go over that, I just need to work on workout something and then then then they are there is info over maximum pluses penalty.",
                    "label": 0
                },
                {
                    "sent": "So this is a global penalty what it is.",
                    "label": 0
                },
                {
                    "sent": "If you look at this penalty, what it is is that the first you have number of nonzero components times logged in, so you have a log defect log in factor.",
                    "label": 0
                },
                {
                    "sent": "Secondly you have Jay over all the sum plus one plus Theta J.",
                    "label": 0
                },
                {
                    "sent": "If CJ is 0 this one is 0 right?",
                    "label": 0
                },
                {
                    "sent": "So this one effects only some over the components of city which is not zero.",
                    "label": 0
                },
                {
                    "sent": "So you only look at the steel is proportional to 6 zero but still is log sheet.",
                    "label": 0
                },
                {
                    "sent": "You have a log Seattle Opti log North, which is OK.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you can do better if you do the localized bound, so here the localized bound you modify, roughly something like similar, but this one is.",
                    "label": 0
                },
                {
                    "sent": "You cannot get this no logged in here, so you can get Theta zero.",
                    "label": 0
                },
                {
                    "sent": "Basically non zero components, only square City Square over N plus adicional.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about these things is the following.",
                    "label": 0
                },
                {
                    "sent": "This is so one 1:30 is large.",
                    "label": 0
                },
                {
                    "sent": "This one can never large the log D, right?",
                    "label": 0
                },
                {
                    "sent": "So this one is never larger than log because this is smaller than One South.",
                    "label": 0
                },
                {
                    "sent": "But this one can be much smaller, especially when this guy is larger than the noise threshold logged over, and it's like typically like noise threshold.",
                    "label": 0
                },
                {
                    "sent": "Once he makes much larger than that, this becomes exponentially small.",
                    "label": 0
                },
                {
                    "sent": "This becomes much smaller than one, therefore experience more in North 130 is not too small.",
                    "label": 0
                },
                {
                    "sent": "So that's the point.",
                    "label": 0
                },
                {
                    "sent": "This can be much much.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are compared with that and I will just briefly give combination without one.",
                    "label": 0
                },
                {
                    "sent": "You have this log D factor here.",
                    "label": 0
                },
                {
                    "sent": "So if each each each of this parameter is much larger than the more it stretch code that you don't have this logged in, so that's a difference.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so.",
                    "label": 0
                },
                {
                    "sent": "And then actually it's expansion is small in this D in this case.",
                    "label": 0
                },
                {
                    "sent": "So basically you have you have a rate which is largely.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, anyway, so there's some summaries so probably will be quick, but essentially there's three parts.",
                    "label": 0
                },
                {
                    "sent": "Why is general inequality nice?",
                    "label": 0
                },
                {
                    "sent": "Empty outline specific application?",
                    "label": 0
                },
                {
                    "sent": "Offer to the learning sparsity.",
                    "label": 0
                }
            ]
        }
    }
}