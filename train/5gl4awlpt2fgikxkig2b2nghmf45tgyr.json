{
    "id": "5gl4awlpt2fgikxkig2b2nghmf45tgyr",
    "title": "Mask-based Light Field Capture and Display",
    "info": {
        "author": [
            "Douglas Lanman, MIT Media Lab, School of Architecture + Planning, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_lanman_mbl/",
    "segmentation": [
        [
            "So today I guess I'm here sort of representing the more sort of hardware oriented side of computational photography.",
            "A lot of the work we do with the chemical group at the Media Lab is really considering imaging as a system, and so you know the title of this course is based on computational tography.",
            "Actually now we're looking at computational displays, and many of the concepts you're seeing in tomography and image reconstruction and optimization actually can be displayed."
        ],
        [
            "Applied equally well in the display space, so maybe you'll find this inspirational, so stepping aside rather than looking at traditional 2 dimensional imaging problems, what we're actually looking at is sort of, you know now there's all this buzz against 3D.",
            "Let's actually look at the three dimensional imaging problem, whether you like it or not, this is what the industry has pushed their weight behind, and so if you try to make a 3 dimensional imaging system right all the way from a general scene to the viewer, just as with imaging, you just need to think about this as a perceptual problem at the end of the day, we don't care what we capture, we don't care what we display so long as the perceptual cues for depth.",
            "Color another luminance effects are delivered correctly to an audience, right?",
            "And so for three dimensional imaging, the key cues are binocular disparity and also motion parallax.",
            "One might argue you can walk around the room wherever your eyes are located.",
            "They see two disparate images.",
            "If you can achieve that, at least the 1st order, you can have a very faithful death."
        ],
        [
            "So how do we do this using current technology?",
            "Well, if you look at what film studios are doing, you know they sort of look at the bag of tricks we have our last 100 years.",
            "They say OK, if we want multiple view photography, let's throw a bunch of cameras at the problem.",
            "We have to synchronize them.",
            "We have to color calibrate them.",
            "But the end of the day we can capture both binocular disparity as well as multiple multiview, parallax and then all of you have been to the theater recently.",
            "You see that the solution they're using to display this content to you is not entirely clever.",
            "It's hundreds of years old and that's using some sort of selection process.",
            "You wear a pair of glasses.",
            "The right and left.",
            "I have two some two different filters, whether multiplexed in color, domain, time, domain, what have you they function to select the right eye image in the left eye image, right?",
            "So the problem with all this is we're not using contact compact cameras that are easy to calibrate and operate or not using devices that are free of encumbrance to the user.",
            "If you walk through an airport you look at yourself."
        ],
        [
            "You're not going to wear special glasses, so before I go any further sort of coming from the graphics side of things, especially, we're looking at designing optical systems for displays and imaging and 1st order.",
            "We can model those as Ray optics systems, right?",
            "So we can ignore the facts of refraction and sorry of diffraction, and we can just trace Rays through systems and in graphics this is done using a parameterisation called the light field, which probably many of you are familiar with.",
            "It's a very simple concept.",
            "If I want to parameterise the radiance of a wavefront path passing through space.",
            "The surface normal of that wavefront is array.",
            "The radiance along that Ray is a four dimensional function which you can discretize and story in what is known as a light field, right?",
            "So the radiance in Watts for story and that sort of thing is just this light field that's a four dimensional function, right?",
            "So this is fundamentally the data structure we're using to represent multiview imagery.",
            "This is what a camera is capturing.",
            "1 camera captures a 2 dimensional slice of this 4 dimensional function and then also we're modifying displays to admit such a function.",
            "So into the in the limits of geometrical optics.",
            "Does in fact recreate multiple multiple views?",
            "The other thing is in this work were primarily thinking about adding attenuators to cameras, right?",
            "You could think about adding multiple refractive lens elements, but in this work we said the simplest optical element one could think of is an attenuating mask or a volumetric attenuator, and so we."
        ],
        [
            "In some way of representing attenuation in a volume on a light field, and so you can use a similar sort of shieldfield or attenuation function.",
            "So this is a four dimensional data structure."
        ],
        [
            "That acts on the light field, right?",
            "So there is no similar concept.",
            "You have a light field passing through some window.",
            "It goes through an object and it transmits to another side.",
            "This geometric propagation free space is a shear of this 4 dimensional function and in the plane of the occluder it's just multiplication.",
            "It's very trivial now in the first half of this talk I'll be using sort of signal processing frameworks to understand how to capture light fields.",
            "In the latter half will be using linear algebra, and so the main thing to look at courseware.",
            "Ignoring reflection, reflection, refraction and scattering.",
            "But also you can look at this all in the frequency domain and this sort of frequency domain analysis of light fields allows us to very easily design light field cameras using masks.",
            "And so I just want to point out that the light field spectrum.",
            "Again, this is a four dimensional function upon attenuation by a volume of volumetric attenuator is just given by the convolution of the incident light field and the convolution of this volumetric attenuation function and so this will become more clear once we start trying to build cameras."
        ],
        [
            "These principles and so now I'm going to go back and probably be overly pedantic and describe why cameras are not 3 dimensional and so using a light field framework we see that if we have a sensor, some stack of optical elements in a scene, right?",
            "Conventional photography projects this out.",
            "We all know that we get a 2 dimensional projection of a 3D World.",
            "But why exactly does that occur?",
            "And so you can use light fields to analyze this.",
            "Typically in computation photography we choose the first plane in this too plain parameterisation to be on the sensor.",
            "The 2nd on the aperture, and now it's obvious what's happening here.",
            "The four dimensional lightfield passing through the optical elements is.",
            "Projected down to a 2 dimensional slice right?",
            "So this is just like a tomographic principle.",
            "We've taken a orthographic projection of the light field, so moving ahead, how exactly could we capture 3 dimensional image using a single large aperture camera when we need to prevent this projection operator from occurring, we need to record a four dimensional function onto a 2 dimensional sensor.",
            "So fundamentally you need to do some type of multiplexing right?",
            "So you can pursue temporal multiplexing like Sam was describing.",
            "Or of course spatial multiplexing.",
            "And these concepts are very old, right?",
            "So if you talk about a 3 dimensional camera?",
            "The first one was proposed actually in 1903, and this has been reinvented over the following century and actually in the SIGGRAPH community.",
            "This has been reinvented more recently, about Frederick lives in 1903 published the first method for both recording 3 dimensional imagery and displaying it, and the idea is known as the Parallax barrier.",
            "So for those you have young children, you may have seen the Gallup book.",
            "This is based on a similar technology.",
            "You have a sensor or a display device slightly in front of it.",
            "You put in array of pin holes or slits, right?",
            "And now you can see that by moving the sensor array back.",
            "We've eliminated this projection operating.",
            "Operation from occurring and individual pixel here no longer integrates over a full hemisphere.",
            "It only integrates over a small angle, so each pixel now has an instantaneous field of view, which is very small, so you can take this 2 dimensional image and demultiplex it to be a four dimensional light field.",
            "So we've now built a light field camera just using a mask in 1908.",
            "Very similar concept was proposed by Nobel Laureate no less.",
            "Just replace each of these pin holes with a lenslet, so placing a small lenslet array over a sensor you can now with a very short exposure capture this 4 dimensional light field.",
            "Right now, remember this 4 dimensional light field can be decoded to give us a perspective projection from any point on the entrance aperture.",
            "So if I choose two points, I can have a stereoscopic viewpoint of the scene at least over the entrance aperture my lens.",
            "And so the main concept behind all of this is that spatial multiplexing of course gives up something.",
            "So to capture light field we have to compromise spatial resolution to gain angular resolution, and that's the whole game we see in the cigarette communities.",
            "How do you design light field cameras that using temporal and spatial multiplexing?"
        ],
        [
            "Give a high Fidelity representation.",
            "Now the exact same analysis applies to displays, which is why I'm arguing that all the principles we're seeing competition photography can be ported over the display world in the display system.",
            "The key component here is we need to think about the audience, and so again conventional displays throw up you're too plain parameterisation along the sensor axis.",
            "We can parameterise a lightfield coordinate you slightly in front at some known distance.",
            "We have a second plane and now you can see why.",
            "In fact 2 dimensional displays cannot have projected general light field just because by design A pixel on a display device emits uniformly.",
            "Approximately in all directions.",
            "So once again we go back to that patent from Frederick lives in 1903 and this is in fact if you go to trade shows nowadays you say, OK, I'm wearing glasses in a theater.",
            "How do I get rid of those glasses in the future?",
            "You know, when we go to buy a 3 dimensional television, they're basically all at the moment based on two technologies, and so placing a parallax barrier again slightly in front of the sensor allows you to map a pixel which used to admit uniformly in all directions into a small angle, right?",
            "So now you can take a 2 dimensional device and display of four dimensional function.",
            "So if you're if you have two eyes located different positions, they see different sub elements of the display and therefore they can see different images.",
            "Very simple concept, again all based on attenuation.",
            "Again you can replace those pin holes or slits with lenses you can make you make a much brighter display.",
            "But the key problem here is, again, we're trading spatial resolution for Angular resolution.",
            "So if we want to have, say, 5 different viewpoints in front of the display, each of which provides stereoscopic views, then we need 10 images to be multiplexed behind each lens.",
            "So we give up the spatial resolution by a factor of 10, right?",
            "So even though we have HTTPS Now, we're back to something that's just 100 pixels in."
        ],
        [
            "Right, so we need to somehow solve this multiplexing problem, But if you go to manufacturers today and you say build me a 3D camera, building A3 to display that doesn't require glasses.",
            "They will in fact propose these two solutions.",
            "So Nintendo in the spring is selling a device based on parallax barriers and it's a simple concept.",
            "You make a sensor display slightly in front of your place.",
            "These array of slits that's 1903 nineteen 08.",
            "We have the lenslet and if you look at this trade space, you know if you're an engineer and you say, OK, we're going to build and sell a 3 dimensional display device.",
            "You might immediately think the lenses are the best solution because they don't attenuate light.",
            "But you gain a lot with a pinhole array, right?",
            "Even though the pinhole array attenuates light leading long exposures and Jim displays lens, let's lose resolution permanently, right?",
            "So most of the content we have for displays and cameras is 2 dimensional in nature, so Nintendo is actually chosen not to use a lenslet array, and Phillips tried in the 90s and 2000 and failed because they tried using Lenslet San.",
            "When you display a 2 dimensional image, your resolution is equal to the number of lens.",
            "Let's no longer the number of pixels on the underlying display.",
            "So what we're really seeing in the market is that we're using.",
            "Two layer LCD devices and sharp was very clever and bet on this in the 90s and actually a lot of the cell phones were seeing and I think Fujifilm has a camera and also there's displays you can buy for laptops.",
            "They're all based on dual layer LCD's and the reason is most of the time you don't want to see 3D content, you just disable this barrier.",
            "You make it completely transparent, now you have a conventional high resolution to display.",
            "You can do the same thing for light field capture and then you can turn the barrier on.",
            "Now the problem is when you're actually multiplexing views say you have just two views.",
            "It'll be half the brightness and half the resolution, right?",
            "So the real game we want to play, and this is something we've been doing in our lab in MIT for several years now.",
            "Is to find masks attenuation based functions that allow us to capture and display 4 dimensional light fields using some sort of pattern that transmits much more light, right?",
            "So since 1903 when these concepts were invented, several things have changed.",
            "First of all, we have high resolution programmable spatial light modulators that are also very high speed, right?",
            "Whereas when photographs thought about this, he could print one mask.",
            "Game over in addition, we also have ubiquitous computation, so we can change these masks depending on what we're trying to capture, and so this will label a lot of interesting applications, hopefully have time to go through them, but I'll just give you a brief."
        ],
        [
            "The results.",
            "So remember the basic idea here is that if you want to use a single mask to Multiplex of four dimensional light filled onto a 2D sensor, you can use an array of pin holes, pays slightly in front of the sensor.",
            "It turns out and we'll see why in a minute you can actually replace each pinhole with a generalized pattern that has some unique properties in the frequency domain.",
            "So each pinhole is now replaced by a small tile and you'll see of course that this transmits much more light on average.",
            "This mask transmits 50% of light, so it cost 1 exposure stop in the camera, but allows you to actually cover the exact same date as a pinhole array.",
            "So you go from needing.",
            "You know one minute long exposures to 1 second or less, right?",
            "So this makes single shot light field capture possible using masks.",
            "So this pattern solves that game of finding a replacement for pin holes.",
            "Now it's interesting we have a recent work that's coming out at SIGGRAPH Asia in just next week.",
            "Is that if you try to use this pattern to generalize parallax barriers for light field display, it actually doesn't work and it turns out that you're doing some sort of frequency domain heterodyning with this pattern, an because you can't have a negative value displayed on LCD.",
            "This pattern no longer works, and so the recent work representing.",
            "Is to actually find a different generalization of parallax barriers for light field display and so what's interesting is this sort of pattern.",
            "Again, we have two LCD layers.",
            "If you display this sort of pattern, something very similar to this on the two layers, you can actually emit this general multiview light field and what you'll notice is there very different in the case of light field display, we have a periodic pattern that's nonadaptive no matter what the image content is falling on the sensor.",
            "This pattern is identical, right?",
            "And it's also static overtime.",
            "All those properties flip.",
            "When we look at light field displays, this is of course a non periodic pattern.",
            "It's content adaptive.",
            "You can see that the image we're trying to display somehow gets involved into our mask and these also have to change overtime and so it's interesting that as we take concepts from computational photography into computational displays, certain concepts do not port and that has to do with the limitations of negative light and also the limitations of human perception when we design computational cameras, the encoder and decoder are completely under our control.",
            "We can change the optics and the algorithm for displays we no longer have that freedom.",
            "We can be as clever as we want in the optics in the encoding, but the decoder is always a human visual system, and so this discrepancy makes the computational imaging for displays.",
            "I think somewhat more interesting."
        ],
        [
            "And so moving ahead hopefully have enough time to get through all this, but I want to explain the basic concept behind how these lightfield capture masks are does."
        ],
        [
            "Find.",
            "And so, just to point this out, for those of you haven't seen this light field cameras basically reinvent the concept that was invented in 1903.",
            "Sorry it's not up there by Frederic Ives, the basic ideas we're going to take a camera and we're going to put a mask behind it that functions like a parallax barrier.",
            "So in the cigarette community, this was reinvented around 2005, and So what happened is they took a medium format camera and then placed a lenslet array, just like Lippmann proposed in 1908, that was micro machine, so this is simply a digital version.",
            "Of something invented 100 years ago of what they did with that was entirely new though, and so you can build these things very inexpensively.",
            "Also at Mitsubishi we also developed a very similar camera, but exploiting the masks.",
            "Remember, masks have much more flexibility because they're cheap and also programmable if implemented with LCD's you can actually go back to a conventional camera, whereas a design like this you permanently compromised."
        ],
        [
            "Resolution.",
            "So now that we sort of go back to this trivial diagram of how a camera works, we can actually perform a light filled analysis.",
            "So what I'm trying to answer here is how does image formation occur in the frequency domain?",
            "So remember we have this two plane parameterisation of the light field.",
            "EU plane parameterise is the intersection with the sensor, the S plane parameterized.",
            "The intersection with the aperture plane of the lens, right?",
            "So the image falling on the sensor before projection right before you average over the angles?",
            "Is this 4 dimensional light field?",
            "Now we all took signal processing or probably many of us.",
            "You can always take avoid transform so you don't have to have an intuition for what this is, but because we have a four dimensional 2 dimensional light field in Flatland falling on the sensor, we have some light filled factor spectrum that falls on the sensor.",
            "You can engineer the system to essentially provide a bandpass filter effect.",
            "So what we're assuming in the following analysis is that the light field falling on the sensor is band limited, right, so?"
        ],
        [
            "Next thing to realize is what happens when we don't have a mask present, right?",
            "So this is a frequency domain interpretation of how image image Ng occurs, right?",
            "What normally happens?",
            "We have a pixel and it integrates overall angles.",
            "It turns out this is a concept related to something known as the voice projection slice theorem.",
            "In tomography you can think of a camera as being very equivalent to a CT scanner.",
            "What happens is the sensor, because it measures the average value in angle.",
            "What it's doing is extracting a slice in the frequency domain.",
            "Along the spatial F sub U axis.",
            "Right, and so if I have a very high resolution sensor, the light field falling on the sensor is actually oversampled, and So what if you want to think about how image formation occurs when you take a photograph.",
            "This slice occurs and then you take an inverse Fourier transform.",
            "That's the image you receive, right?",
            "And so most cameras today.",
            "I have very high resolution, and So what we're going to do is exploit this oversampling somehow.",
            "We need to use lenses or masks to move the unsampled components, the unsampled spatio angular frequencies of light field.",
            "Into this oversampled sensor bandwidth, right and so this was a work from Mitsubishi in 2007.",
            "If you just look at the shieldfield I mentioned that very early in the talk this 4 dimensional volumetric attenuation function.",
            "If you look at a shield filled of a single planar attenuator lying in front of a sensor, then what occurs in the frequency domain?",
            "You have multiplication in the space in the Ray domain, which means you have convolution in the frequency domain, so a mask slightly in front of the sensor ends up being convolution along a slanted line and so what's interesting is if you go back and think about.",
            "Frederic Ives invention.",
            "Using this framework, he displayed a mass containing a uniform array of pin holes, right?",
            "So if I have a Dirac comb, it's fully transform is also a Dirac comb, which means what's happens is the.",
            "When I take a photograph with a pinhole array, I'm can."
        ],
        [
            "Evolving my baseband light filled with this slanted Dirac comb.",
            "So this is the frequency domain interpretation of parallax barriers, and so what's interesting is if you get this distance just right and the pin hole spacing just right, you'll see that you take this baseband light filled and modulate it into the over simple oversampled sensor bandwidth, right?",
            "So now the process I can do is I can take a photograph with my mask tickets for trans."
        ],
        [
            "Form.",
            "Then reshape."
        ],
        [
            "I thought about this a couple years ago and I said, well, this is very nice.",
            "It's a nice theoretical framework, but at the end of the day it doesn't give you any new pattern, right?",
            "It's just explaining how panels work using a frequency domain interpretation.",
            "So now what we want to do is play a game we know to capture a heterodyne lightfield using a single 2 dimensional sensor in one mask.",
            "We need that mask to avoid transform, which is a 2 dimensional Dirac cone.",
            "Right so Frederick, I've proposed pinhole arrays.",
            "We know that these are self dual, so this works.",
            "In 2007 Mitsubishi proposed this sum of sinusoids pattern right?",
            "And so it turns out that if you just express each pair of impulses in the frequency domain as a spatial frequency at some orientation that allows you this pattern to also represent a uniform series of impulses in the frequency domain.",
            "Now it turns out this pattern, while passing slightly more light, is actually just a truncated Fourier series of a pinhole, so it's actually only marginally better than a pinhole.",
            "And So what we did is try to find pattern."
        ],
        [
            "That transmit more light, and so if you just look at the."
        ],
        [
            "Patterns can holes in the science of sinusoids.",
            "Code are both periodic.",
            "Right so they."
        ],
        [
            "You can ask well what is the family of periodic functions that also produce a 2 dimensional impulse train right?",
            "And so thinking back to signal processing, I think it's chapter four of Oppenheim and Wilsky.",
            "Actually, if you tile any random function, tile it so we make a periodic function, then we always get a uniform.",
            "Sorry, an impulse train in the frequency domain, but the amplitude and phase of each impulse are given by the discrete for a series coefficients of an individual tile.",
            "Right, So what this means is to capture light field.",
            "We would like these impulses to be equal amplitude, right?",
            "So what we want is a tiling pattern that is broadband, right?",
            "So the the entire class of patterns which can capture light field are given by tiles which are have a broadband for a transform and so if."
        ],
        [
            "Go to the literature actually in radio astronomy they have a pattern which has a lot of properties that are beneficial.",
            "It's called a modifying modified, uniformly redundant array.",
            "Now this is just one solution you could use, but it has some nice properties.",
            "For instance it's binary, so you can print it at very high contrast using commercial offset printers.",
            "It also transmits 50% of light so long as the dimensions here are prime length, so it gives us a closed form solution to capture."
        ],
        [
            "Light filled in a single stop and so, just to summarize, this originally had pin holes.",
            "It turns out this sum of sinusoids passes slightly more light.",
            "I mean significantly more in light, but it's just a truncated for a series, so the more angles you capture, the worst this performances.",
            "Whereas with these tiled broadband codes you actually always have a 50% duty cycle, right?",
            "So with very short exposures we can now capture light fields using mass."
        ],
        [
            "And so we went ahead and built this using the Mitsubishi camera is very simple.",
            "You just go to the print shop, ask them to print this pattern.",
            "They ask you what is this?",
            "Why are you printing it?",
            "You say just."
        ],
        [
            "Martin print it.",
            "Here's what the photograph looks like.",
            "So if you believe me what I've presented so far, this 2 dimensional photograph actually contains the parallax of views, right?",
            "So by decoding this image, I can actually see slightly behind objects, and what Stanford showed in 2005 is not because I can do that.",
            "I can also make a synthetic focal stack right?",
            "So if you apply the foyer domain decoding I described first, we take avoid transform of this image."
        ],
        [
            "You'll see a bunch of peaks and each peak here is coming from one of those impulses due to the foyer transform action of the mask, right?",
            "So we just take all the regions within this way, transform, reshape them into a four dimensional data structure and then in."
        ],
        [
            "So I transform and that gives us an array of images.",
            "So we took a single image from the camera and now one of these images corresponds to a small viewpoint somewhere different on the aperture."
        ],
        [
            "Right, and so from that you can actually create a focal stack, and because you can create a focal stack, you can now estimate depth.",
            "You can make an all focus image.",
            "You can do all these things in computational photography that people have been doing in the last few years.",
            "And so a nutshell.",
            "That's mask based light field photography, right?",
            "So because we're within one stop of lenses, we can now have all the flexibility and programmability of masks without the losses."
        ],
        [
            "In curd by optics.",
            "So at this point we had a couple of small follow on projects that just explored the space that's enabled by large format light field capture.",
            "Because we can print these masks very large compared to lenses, we can do a lot of weird things."
        ],
        [
            "And so, coming from sort of a computer vision background in my earlier sort of Masters Phase I thought a lot about 3D scanning, so he said, well, you know, in 3D scanning this sort of the brute force solution is just to buy a bunch of cameras, right?",
            "And if I calibrate these very carefully, I can intersect the tangent cones to each surface and I'll get get an estimate of the object shape known as the visual hole.",
            "Right now.",
            "Actually this is being proposed for three dimensional television systems, so there are several European efforts where they buy hundreds of cameras, they synchronize them.",
            "They have these big rooms.",
            "Full of blue cloth segment.",
            "The actor right?",
            "So what we want to do is make this very cheap, and so the first thing to make it cheap is to not use cameras.",
            "Let's use lights, because in many applications light sources and cameras are dual."
        ],
        [
            "So now we can rearrange this light array and make a somewhat very strange camera.",
            "So here we have an array of light sources.",
            "We have a diffuser in a camera, so in some ways you can think of this as an enormous light field camera.",
            "This is a sensor and this is the aperture of the lens.",
            "If we wanted to reconstruct the shape of this object, we could turn a light on, it would cast a shadow.",
            "We could repeat that process and once again we can recover the visual hole.",
            "And this is basically exactly how CT scanner works, right?",
            "This is just an optical version of that right now.",
            "The problem with this is because we have an individual point of projection that's time multiplexed.",
            "We can no longer scan.",
            "Dynamic scenes, right?",
            "Just like CT scanners, have trouble that scanning dynamic objects.",
            "So what we'd like to do is be able to handle the case of simultaneous projections.",
            "Right, and so to handle this.",
            "You know this could you could you could make this a machine learning problem.",
            "You could say, OK, I have all these shadows multiplexed.",
            "Let's try to decompose that right?",
            "And as you add more and more lights, that decomposition is going very difficult to do, especially if you have any realistic noise model for the camera.",
            "So instead we use this large format light field camera.",
            "So we say, let's just parameterized this as a light field.",
            "If we could somehow capture the light field over a meter wide region.",
            "Then we could just query that light field right in the light field tells us an individual Ray what the intensity is, right?",
            "So if we take a four dimensional light field, 2 dimensional slices will be the shadows.",
            "So in a single instant we can measure all of the shadows from all the light sources right?",
            "So this would allow you to make a CT scanner with no moving parts."
        ],
        [
            "So how do you capture this?",
            "Well, you just use exactly the solution we already have, right?",
            "We can just play some ask either with pinhole array or now one of these highly transmitting patterns slightly in front of the sensor plane.",
            "Right, so when a CT scanner would have coded pattern slightly around the sensor and now in the single instant you can recover the visual hole."
        ],
        [
            "Right, because you have the attenuation map directly, so you just take the received light field divided by a calibration light field that gives you the Shieldfield 2 dimensional slices of that will in fact be the shadows.",
            "So this is single shot visual and now you can replace the."
        ],
        [
            "With the broadband pattern, so we'd like to build things by hand in our group at MIT, so we took this idea and just directly instantiate it.",
            "I mean, there's just the direct idea made real, so we take a camera large sheet of paper slightly in front of it.",
            "We placed one of these enormous masks right, and so here you have all the benefits if you try to do this with lenses.",
            "Do it right.",
            "It cost you several $1000 to have custom made.",
            "But if you really think about the see T application lenses don't work right because you can't have a refractive optical element for X Rays, so this is sort of prototyping aceti type scanner.",
            "Here you can see if we have all the lights on we have multiplexed shadows, but now the inversion problem, right?",
            "You could think in the inversion the condition matrix has been improved by having this high frequency modulation."
        ],
        [
            "Alright, so here's just an example of what happens.",
            "You put an object in."
        ],
        [
            "The system you take a single exposure, so this is just a quarter of a second.",
            "Now if you had pin holes, this would take a 62nd or longer exposure, right?",
            "So this is allow fundamentally allowing single shot dynamic scenes.",
            "If you zoom into this, you'll see that there's some strange modulation occurring here.",
            "Again, this is all decoded in the frequency domain, just like the example I showed earlier for light field."
        ],
        [
            "Camera here you can see again we get a set of images.",
            "Now this what these images represent is the image seen from each light source."
        ],
        [
            "So we can take that and again run the visual whole algorithm.",
            "Whoops, it's playing already.",
            "And you get a result, right?",
            "And so this is a very coarse result because we have just one camera, right?",
            "So we're using one camera as if it was 36 cameras and you have some artifacts due to the fact that we're using limited baseline tomography, right?",
            "We're not getting a full 100 degrees set of projections.",
            "We're only getting about 40 degrees."
        ],
        [
            "OK, so now that we've found a generalization of parallax barriers, we can now efficiently reconstruct objects because we can make very large masks that have very short exposure times, and so we took this idea in a different direction."
        ],
        [
            "Another project, and again I'm just trying to show how concepts from computational tography can now move into completely different spaces, and so let's step back again at the Media Lab.",
            "We sort of think a lot about human computer interaction, so we said well, are there any repercussions of this work in that domain?",
            "And so if you think about the state of the art, we have Apple.",
            "Here's a representative.",
            "They were very successful in taking the idea presented at Ted just a few years ago by Jeff Hahn and commercializing that product and thereby pushing into the market.",
            "So multi touch is now sort of a defacto thing that people assume will be in their devices.",
            "Just in the last few years, we've also seen gesture based interfaces emerge right.",
            "And most of these involve having some widget in your hand except for connect.",
            "Right and then the other sort of display trend.",
            "We're seeing our lighting sensitive displays right?",
            "So most of your laptops, your cell phones.",
            "If you have an iPhone, you'll notice that it changes its brightness depending on the ambient illumination, right?",
            "And you can also imagine displays that take that to sort of an extreme, and use that ambient light sensor to actually make displays that respond to lighting.",
            "So this is some SIGGRAPH work from several years ago, and So what we said is OK, we have all these things, and in a few minutes will see how it's related to this mask concept."
        ],
        [
            "We're going to make a single device that combines this because fundamentally all of these use optical sensors, right?",
            "So one way of implementing multi touch is to use embedded photodetector arrays and a lot of the reason this is occurring is 'cause Apple has most of the patents on capacitive, multi touch and so now you're seeing optical multi touch where each pixel has a photo detector, right?",
            "And then the photo textures you occlude determine the position of your finger.",
            "Also you can do time of flight which is also an optical method and ambient light sensor is just a photodiode.",
            "So basically combine all these devices into one thing.",
            "And this one thing is a single LCD panel that at one instant in time measures the incident 4 dimensional light field.",
            "So it's like a multi view camera array spanning the aperture right?",
            "The display surface and at the other instant in time it simply displays a normal 2D image.",
            "So let me describe how we built this.",
            "So the basic idea."
        ],
        [
            "Fairly straightforward extension of what we did right.",
            "The previous example I showed you with the idea of capturing the shape of an object and to do that we had a light source array, right?",
            "Because when you turn on a light fundamentally it passes through the mask, gets modulated, falls on the sensor if array just passes through and include are it does not right.",
            "So we can measure the shadows.",
            "But really why did we need this light source array at all?",
            "Right?",
            "Y&CT scanners.",
            "Don't you just have some ambient illumination source, right?",
            "So if we just turn on a light source, we also get some sort of reflected light field.",
            "And the reflected light field could be used to reconstruct the shape as well.",
            "So the question is, why can't we just build this system will look pretty much can if you zoom into this mask.",
            "Here you'll see the problem is if we have a Ray of light approaching at normal incidence, it will fall in the sensor right?",
            "So if we put a parallax barrier here, we'd be able to measure the incident 40 light field.",
            "But then if we have an angle Ray of light coming in to speak steep angle, it will fall in the same sensor element which will violate the assumptions built into the demosaicing algorithm for the light fields.",
            "And so all you have to do to make this work is at an angle limiting film.",
            "Right, so if you put an angle limiting film, that problem solved.",
            "Now the next step is to use one of these optical multi touch.",
            "So get rid of the camera and diffuser and you just have a large large format sensor that also has a backlight embedded in it and there's actually patents from Apple.",
            "Sharpen planer on this exact device which was the inspiration of the work on the backlight embedded backlight.",
            "So now the last step here is we can replace the mask with an LCD right?",
            "And so now this gives us a very thin display device, it's only slightly thicker than a normal display, but what we can do is we can display when the backlight is off the heterodyne code.",
            "Right and then with the ambient illumination in the room, we can capture light field."
        ],
        [
            "But then we can turn the backlight on and use that LCD panel as a display device, right?",
            "So we can have a single thin LCD panel that can see not just one image but an array of images spanning the display surface.",
            "And we can also display a normal normal image content, and we can alternate between the two and."
        ],
        [
            "Time division Fashion Time Multiplex fashion.",
            "So we built this at the time.",
            "Sharp wasn't willing to share their LCD panel if since changed their opinion and so we actually cheated and we made one of these large format sensors using the same trick of a diffuser and cameras.",
            "But really, there's no reason this can't be as thin as the gap between the sensor in the display.",
            "So we hacked this apart 'cause we like building things.",
            "We have an LCD panel stripped apart, the diffuser cameras and light."
        ],
        [
            "Box, and here's the result.",
            "Let me just play this.",
            "So again, remember, this is like a sequence of projects where first we found a way to use masks to capture light fields, and once we could do that, we can make very large format devices because it's just a printed pattern.",
            "But those masks, unlike parallax barriers, transmit much more light, so at each instant in time every single frame.",
            "This backlight is oscillating, but it's actually 120 Hertz.",
            "The human eye can't perceive it.",
            "So at 60 Hertz we're decoding the light field.",
            "We're taking a light field photograph.",
            "And then we're using that array of cameras to synthesize a focal stack like I showed you earlier.",
            "So at each instant in time we have a focal stack.",
            "We can then run a depth from focus algorithm, so we now have a depth map at 60 Hertz.",
            "We can do blob tracking on the depth Maps we can track every object in 3D in front of the display, and so now without any capacitive devices we can do multi touch interaction.",
            "And we can have this blob tracker basically driving this very simple example.",
            "So here the lateral translation of your hand controls the rotation matrix.",
            "The scale of the object is controlled by the depth of the hand, right?",
            "So this is fundamentally showing multi touch and gesture based interaction, right?",
            "So if you try doing this with like a Microsoft Connect in a capacitive device, some sort of Frankenstein device you have problems near the display device where you can't handover between the two sensors because the field of view isn't available."
        ],
        [
            "Another thing you can do here is implement sort of what I think is beyond a 3 dimensional display, right?",
            "Imagine 10 years down the road we all have 3D TV's that work without glasses.",
            "If you go to a museum and you have a vase with Flowers in it next to the virtual representation of that, the real face will look much more faithful because it responds to ambient lighting, right?",
            "And so this example.",
            "Here is what we call light filled transfer.",
            "We have a virtual scene and we're shining an actual flashlight at the display surface.",
            "But remember, we're measuring the four dimensional light field.",
            "At every at 60 Hertz so we can take this set of raise their intensities and colors and continue propagating those Rays into the virtual scene.",
            "So real lighting sources can interact with virtual content."
        ],
        [
            "So that's the buy screen.",
            "So we played around with cameras a lot, and at this point we said, well, you know, parallel experience.",
            "Have two applications.",
            "They're not really used a lot for light field capture.",
            "Typically people use lenses and they just say we're interested in application.",
            "We don't care that we lose spatial resolution or we don't care about having flexibility, but the real place you see parallax barriers in light field display, right?",
            "If you go to trade shows and you look for glasses free 3D TV's, many of them actually use a parallax barrier, just like Nintendo is doing in a few months.",
            "So that way you can revert back to the 2D mode, so we had all this theory and we said, well, Gee, can't we just put a heterodyne code in front of a normal display and get a 3 dimensional display?"
        ],
        [
            "It turns out you can't, so you can definitely put it there."
        ],
        [
            "Exterior.",
            "And so I just want to show for the input side the problem reverses, right normally."
        ],
        [
            "We have is we have a sensor looking at the world through a barrier and we decode this 2D image to give us the light field.",
            "But in display the problem is exactly the opposite.",
            "We know the 40 light field we want to admit but we only have a 2 dimensional sensor in some known attenuation pattern.",
            "So you have to find the encoding for the sensor and the mask pattern to omit the 40 light field."
        ],
        [
            "OK, so the input to a 3D TV is actually not 3D at all, they're misnamed, they're actually 4 dimensional devices, and the way to think about that is if I have a true 3D TV and I close one eye and I look at this scene that has a green sphere in the plane of the display and a red one in front, and a blue one behind as I walked to the right, I perceive parallax, right?",
            "This is not surprised I have horizontal parallax as I move my head up and down I have vertical parallax, right?",
            "So the impact consortium the standard for Multiview 3D is in fact."
        ],
        [
            "A light field and it's a 2D array of 2D images, right?",
            "So if the light field concept wasn't clear earlier, hopefully this is what I actually give at each frame to a 3D display is a 2D array of images describing the horizontal and vertical view parallax, so it's a four dimensional light field using the parallax barrier solution I keep."
        ],
        [
            "Opening all you have to do to display this content is make a set of pin holes and each panel is separated by three pixels horizontally and vertically, and then this would be displayed on the front or rear LCD panel.",
            "It actually."
        ],
        [
            "Doesn't matter, and on the other LCD panel you display a set of interlaced images.",
            "Right, and so this is just like that gallop book that your children might have when you stand at a distance.",
            "You're seeing this pattern through a pinhole array and as you walk to the right, the pinhole array is affectively sliding and then it's appetizing and giving you the sub image right?",
            "So the green sphere which is in the plane of this display has no disparity, whereas the red sphere right has this horizontal parallax at the edge, which is why you see this dappling pattern right?",
            "So this is traditional parallel experience.",
            "Now the problem."
        ],
        [
            "And this is something intended, will have to confront is when you go to 3D mode.",
            "This mask is incredibly dim, right?",
            "It transmits very little light, just one 9th of the light.",
            "Even if you had."
        ],
        [
            "Transparency for the open elements."
        ],
        [
            "Right, so for this project we actually tried using heterodyne and for reasons I won't explain now it failed and so we said, well, let's just step back for a minute.",
            "Remember that since 1903 we have high speed programmable high resolution LCD panels and we also have computation.",
            "So maybe there's something that can be done to make something equivalent to heterodyne codes for display, and so it actually turns out you can do that and you just start with first principles.",
            "You say if I have two liquid crystal panels, what I have is a light box followed by two masks.",
            "Have a couple minutes.",
            "OK, great.",
            "So if I have a Ray of light leaving the light box.",
            "Right, it just gets modulated twice.",
            "So if I display a transparency pattern on each layer, they emitted light field.",
            "You can think of as a matrix.",
            "And this, amid light field, is given by the product of the two attenuations.",
            "Now we have sort of an optimization problem we want to solve.",
            "We have a target lightfield, we're trying to approximate.",
            "We're free to control the transparency on these two layers.",
            "Right, and so one result we show in this paper we're presenting.",
            "First of all is that if you choose the correct coordinate system only in one coordinate system, you can express the emitted light field as the outer product of the two mask transparency functions, right?",
            "So you can see here that the emitted light field in this coordinate parameterization is given by the outer product of the pinhole array and the interlaced images, and so now you can immediately see why pinhole arrays are low resolution and also dim.",
            "Right, but this gives us a new insight into mass based light field display.",
            "It turns out parallax barriers are not just light deficient.",
            "The rank deficient, because I can express the target light field as an outer product.",
            "That means the space of light fields that can create have to be rank one, right?",
            "And if you actually measure a real light field, they're not rank one, right?",
            "So we have this problem where for 100 years we've been using two layer devices, but fundamentally they cannot display light fields, at least not in the in the L2 norm sense very accurately so.",
            "What we did is we said right?"
        ],
        [
            "One way to solve this is to use temporal multiplexing, and so in 2000 Ken Perlin from my you had a very interesting paper where you said let's just use high speed LCDS and let's shift the pin holes overtime, right?",
            "And in this new framework we've proposed, you can see what happens is what we're doing is we're getting a second outer product that's coming because we have a high speed LCD panel.",
            "The human eye integrates, say, at 60 Hertz, but if we have 240 Hertz LCD panel, we display 4 images that get averaged together, right?",
            "So we can build a full resolution lightfield matrix.",
            "Which means if we allow ourselves to display 4 images over the exposure time of the eye, we can do a rank four approximation of a light field, right?",
            "So when you see all these bullet points when you go to Best Buy that say this is 120 Hertz.",
            "LCD is sort of meaningless.",
            "They try to market it for motion deblurring, but they should really market for is rank every frame rate you buy is buying you matrix rank.",
            "And so we're actually calling this high rank displays, and so we hope manufacturers call these high rank displays because the general public will have to learn what rank is.",
            "So we're going to form this outer product composition, but you still see the problem is an individual pixel here is very dim, because over the entire exposure time it's only open once, right?",
            "So this is a heuristic construction of the lightfield matrix.",
            "It's a heuristic decomposition.",
            "The one key, the second key contribution."
        ],
        [
            "Paper is to say, well, let's break all these heuristics we've had for 100 years, and let's just assume we can display anything on the two layers.",
            "Overtime, right?",
            "And so being in a machine learning community, you already know where we went with this, but some of this was new to me, so it took us a little while, but we said OK, well, this is easy.",
            "We have a target light filled matrix.",
            "We want to find a factorization in two other matrices.",
            "The columns of this matrix represent the rear layer.",
            "The rows represent the outer layer, right?",
            "So the question is now or sorry.",
            "The benefit here is that we can have pixels open for a longer time.",
            "So the display can become much brighter."
        ],
        [
            "Right, and so really, this is a very easy problem.",
            "Many of the room would probably have many ways of solving this.",
            "We sort of used a textbook solution.",
            "We said, look, we're trying to decompose a matrix into a sum of outer."
        ],
        [
            "Products."
        ],
        [
            "It would just be singular value decomposition done, except you have to deal with the negative light issue.",
            "If you ran a singular value composition you would have negative values in these matrices which you cannot display practically."
        ],
        [
            "So we have to solve a non negative matrix factorization.",
            "We chose to minimize the L2 norm, which again is probably the wrong thing to do because in computational photography that might be OK for computational displays.",
            "This should really be a perceptual error metric that we're optimizing, but we chose L2 norm because we have all the machinery for that and then we just run."
        ],
        [
            "Non negative matrix factorization, but one thing."
        ],
        [
            "The ad is a weight matrix, so in this formulation we've been very general.",
            "So far we've we've accounted for the target lightfield by specifying this target matrix.",
            "We've accounted for the display limitations by specifying the resolution both in time and space of each layer.",
            "Well, we haven't accounted for his prior knowledge of the viewers.",
            "For instance, if we only have someone standing to the right and left, there's no reason we need to reconstruct the central view with any accuracy whatsoever, right?",
            "So, to make this call?"
        ],
        [
            "In general, we actually allow a weight matrix.",
            "Right, and so this weight matrix could be provided by an eye tracker, for instance.",
            "Or you could just not define it and go ahead and try to admit the light filled correctly, but this buys you a lot of freedom to make the display brighter than conventional parallax berries, so at the end of the day we have L2 optimization over awaited factorization, so we just run weighted nonnegative matrix factorization.",
            "It's pretty straightforward.",
            "The benefit of the weights here is that we also need to."
        ],
        [
            "Or the whole matrix you out, otherwise you couldn't fit this into memory."
        ],
        [
            "The other benefit is we can find."
        ],
        [
            "A low rank approximation, so if you for instance you can only afford to buy 120 Hertz LCD panel, we can give you a rank two decomposition of light field, but your neighbor who bought a 240 Hertz would rank 40 composition right?",
            "When this decoder on the TV will do the best it can."
        ],
        [
            "Sense of rank.",
            "So again, here's the target lightfield."
        ],
        [
            "I coded up just a very simple solver here.",
            "It's rather slow, but it's just a weighted update rule that takes into it.",
            "This is the standard one you'll see from a Daniel in Sebastian Song from the 90s only as the weight matrix.",
            "We start with random."
        ],
        [
            "Toys for all the masks."
        ],
        [
            "And then we descend."
        ],
        [
            "At."
        ],
        [
            "And so you can see."
        ],
        [
            "Bye."
        ],
        [
            "A large number of iterations, so multiplicative update rule, we actually reconstruct the target light field.",
            "So we found that generalization of heterodyne codes that emits more."
        ],
        [
            "Right and so then, in the interest of time, I'll just show you the results.",
            "Here's what the front mask looks like, and so now you can see this is nothing like a heterodyne code, and it's nothing like a pinhole array, but it passes much more light, so we found a way to make displays brighter as well as to."
        ],
        [
            "Populate fields using masks, and here's the real layer which also and so in the paper we actually describe this."
        ],
        [
            "It's clear structure.",
            "You see it from the optimization result.",
            "It turns out what's happening here is it's making a local."
        ],
        [
            "Parallax barrier I don't have."
        ],
        [
            "Can you explain how that works but has to do with the aperture ambiguity problem?",
            "And so here's the emitted light field.",
            "You notice it has some amount of noise because the NMF has converged to a local stationary point.",
            "So you either have to reset it and find a better result, or you just accept the noise.",
            "If it's perceptually insignificant."
        ],
        [
            "And so then, just to summarize, there are two benefits to this technique, right?",
            "We can increase the brightness by trying to increase the target lightfield brightness or we can find a low rank decomposition increase the frame rate and so."
        ],
        [
            "We actually built this.",
            "It's fairly easy, just rip apart some LCD's and stack them up.",
            "You can create apparel."
        ],
        [
            "Superior, and then I'll just show you this result before I conclude.",
            "This is just proving to you now.",
            "For those of you who are interested in this game of taking computation, photography, eyes ideas into the display world, you'll have the challenge of proving to the reviewers that you built a 3D display using a 2D video in a 2D paper, and so one solution you can use is to use a non physical light field.",
            "So here as you walk from left to right, up and down, you're seeing a different Roman numeral and this actually challenges the algorithm because not is compressible right?",
            "Normally if you have physical natural scene right then the parallax between these views means that they're all very closely related.",
            "But you can see that in both cases the timeshifted pinhole and the content adapted various successfully display the light field."
        ],
        [
            "In addition, you have this new trade space, so the 3rd and final contribution of this work is to realize that because we had a heuristic for 100 years of using pinhole arrays, we didn't have a trade space we could play with.",
            "If you wanted a light field ahead 5 views, you had to give up spatial resolution by a factor of five.",
            "We've now broken that for both light field display, at least by having a new trade space where you can actually adjust the spatio angular resolution tradeoff."
        ],
        [
            "Dynamically."
        ],
        [
            "Hands."
        ],
        [
            "So with that I will just conclude.",
            "So the main concepts of this paper are to find generalizations of masks for light field capture and display, and so hopefully I've convinced you that because we have high speed programmable devices, we can actually do much better than a conventional parallax barrier.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So today I guess I'm here sort of representing the more sort of hardware oriented side of computational photography.",
                    "label": 1
                },
                {
                    "sent": "A lot of the work we do with the chemical group at the Media Lab is really considering imaging as a system, and so you know the title of this course is based on computational tography.",
                    "label": 0
                },
                {
                    "sent": "Actually now we're looking at computational displays, and many of the concepts you're seeing in tomography and image reconstruction and optimization actually can be displayed.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applied equally well in the display space, so maybe you'll find this inspirational, so stepping aside rather than looking at traditional 2 dimensional imaging problems, what we're actually looking at is sort of, you know now there's all this buzz against 3D.",
                    "label": 0
                },
                {
                    "sent": "Let's actually look at the three dimensional imaging problem, whether you like it or not, this is what the industry has pushed their weight behind, and so if you try to make a 3 dimensional imaging system right all the way from a general scene to the viewer, just as with imaging, you just need to think about this as a perceptual problem at the end of the day, we don't care what we capture, we don't care what we display so long as the perceptual cues for depth.",
                    "label": 0
                },
                {
                    "sent": "Color another luminance effects are delivered correctly to an audience, right?",
                    "label": 0
                },
                {
                    "sent": "And so for three dimensional imaging, the key cues are binocular disparity and also motion parallax.",
                    "label": 0
                },
                {
                    "sent": "One might argue you can walk around the room wherever your eyes are located.",
                    "label": 0
                },
                {
                    "sent": "They see two disparate images.",
                    "label": 0
                },
                {
                    "sent": "If you can achieve that, at least the 1st order, you can have a very faithful death.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do this using current technology?",
                    "label": 0
                },
                {
                    "sent": "Well, if you look at what film studios are doing, you know they sort of look at the bag of tricks we have our last 100 years.",
                    "label": 0
                },
                {
                    "sent": "They say OK, if we want multiple view photography, let's throw a bunch of cameras at the problem.",
                    "label": 0
                },
                {
                    "sent": "We have to synchronize them.",
                    "label": 0
                },
                {
                    "sent": "We have to color calibrate them.",
                    "label": 0
                },
                {
                    "sent": "But the end of the day we can capture both binocular disparity as well as multiple multiview, parallax and then all of you have been to the theater recently.",
                    "label": 0
                },
                {
                    "sent": "You see that the solution they're using to display this content to you is not entirely clever.",
                    "label": 0
                },
                {
                    "sent": "It's hundreds of years old and that's using some sort of selection process.",
                    "label": 0
                },
                {
                    "sent": "You wear a pair of glasses.",
                    "label": 0
                },
                {
                    "sent": "The right and left.",
                    "label": 0
                },
                {
                    "sent": "I have two some two different filters, whether multiplexed in color, domain, time, domain, what have you they function to select the right eye image in the left eye image, right?",
                    "label": 0
                },
                {
                    "sent": "So the problem with all this is we're not using contact compact cameras that are easy to calibrate and operate or not using devices that are free of encumbrance to the user.",
                    "label": 0
                },
                {
                    "sent": "If you walk through an airport you look at yourself.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You're not going to wear special glasses, so before I go any further sort of coming from the graphics side of things, especially, we're looking at designing optical systems for displays and imaging and 1st order.",
                    "label": 0
                },
                {
                    "sent": "We can model those as Ray optics systems, right?",
                    "label": 1
                },
                {
                    "sent": "So we can ignore the facts of refraction and sorry of diffraction, and we can just trace Rays through systems and in graphics this is done using a parameterisation called the light field, which probably many of you are familiar with.",
                    "label": 1
                },
                {
                    "sent": "It's a very simple concept.",
                    "label": 0
                },
                {
                    "sent": "If I want to parameterise the radiance of a wavefront path passing through space.",
                    "label": 0
                },
                {
                    "sent": "The surface normal of that wavefront is array.",
                    "label": 0
                },
                {
                    "sent": "The radiance along that Ray is a four dimensional function which you can discretize and story in what is known as a light field, right?",
                    "label": 0
                },
                {
                    "sent": "So the radiance in Watts for story and that sort of thing is just this light field that's a four dimensional function, right?",
                    "label": 0
                },
                {
                    "sent": "So this is fundamentally the data structure we're using to represent multiview imagery.",
                    "label": 0
                },
                {
                    "sent": "This is what a camera is capturing.",
                    "label": 0
                },
                {
                    "sent": "1 camera captures a 2 dimensional slice of this 4 dimensional function and then also we're modifying displays to admit such a function.",
                    "label": 0
                },
                {
                    "sent": "So into the in the limits of geometrical optics.",
                    "label": 0
                },
                {
                    "sent": "Does in fact recreate multiple multiple views?",
                    "label": 0
                },
                {
                    "sent": "The other thing is in this work were primarily thinking about adding attenuators to cameras, right?",
                    "label": 0
                },
                {
                    "sent": "You could think about adding multiple refractive lens elements, but in this work we said the simplest optical element one could think of is an attenuating mask or a volumetric attenuator, and so we.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some way of representing attenuation in a volume on a light field, and so you can use a similar sort of shieldfield or attenuation function.",
                    "label": 0
                },
                {
                    "sent": "So this is a four dimensional data structure.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That acts on the light field, right?",
                    "label": 0
                },
                {
                    "sent": "So there is no similar concept.",
                    "label": 0
                },
                {
                    "sent": "You have a light field passing through some window.",
                    "label": 0
                },
                {
                    "sent": "It goes through an object and it transmits to another side.",
                    "label": 0
                },
                {
                    "sent": "This geometric propagation free space is a shear of this 4 dimensional function and in the plane of the occluder it's just multiplication.",
                    "label": 0
                },
                {
                    "sent": "It's very trivial now in the first half of this talk I'll be using sort of signal processing frameworks to understand how to capture light fields.",
                    "label": 0
                },
                {
                    "sent": "In the latter half will be using linear algebra, and so the main thing to look at courseware.",
                    "label": 0
                },
                {
                    "sent": "Ignoring reflection, reflection, refraction and scattering.",
                    "label": 0
                },
                {
                    "sent": "But also you can look at this all in the frequency domain and this sort of frequency domain analysis of light fields allows us to very easily design light field cameras using masks.",
                    "label": 0
                },
                {
                    "sent": "And so I just want to point out that the light field spectrum.",
                    "label": 0
                },
                {
                    "sent": "Again, this is a four dimensional function upon attenuation by a volume of volumetric attenuator is just given by the convolution of the incident light field and the convolution of this volumetric attenuation function and so this will become more clear once we start trying to build cameras.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These principles and so now I'm going to go back and probably be overly pedantic and describe why cameras are not 3 dimensional and so using a light field framework we see that if we have a sensor, some stack of optical elements in a scene, right?",
                    "label": 0
                },
                {
                    "sent": "Conventional photography projects this out.",
                    "label": 1
                },
                {
                    "sent": "We all know that we get a 2 dimensional projection of a 3D World.",
                    "label": 0
                },
                {
                    "sent": "But why exactly does that occur?",
                    "label": 0
                },
                {
                    "sent": "And so you can use light fields to analyze this.",
                    "label": 0
                },
                {
                    "sent": "Typically in computation photography we choose the first plane in this too plain parameterisation to be on the sensor.",
                    "label": 0
                },
                {
                    "sent": "The 2nd on the aperture, and now it's obvious what's happening here.",
                    "label": 0
                },
                {
                    "sent": "The four dimensional lightfield passing through the optical elements is.",
                    "label": 0
                },
                {
                    "sent": "Projected down to a 2 dimensional slice right?",
                    "label": 0
                },
                {
                    "sent": "So this is just like a tomographic principle.",
                    "label": 0
                },
                {
                    "sent": "We've taken a orthographic projection of the light field, so moving ahead, how exactly could we capture 3 dimensional image using a single large aperture camera when we need to prevent this projection operator from occurring, we need to record a four dimensional function onto a 2 dimensional sensor.",
                    "label": 0
                },
                {
                    "sent": "So fundamentally you need to do some type of multiplexing right?",
                    "label": 0
                },
                {
                    "sent": "So you can pursue temporal multiplexing like Sam was describing.",
                    "label": 0
                },
                {
                    "sent": "Or of course spatial multiplexing.",
                    "label": 0
                },
                {
                    "sent": "And these concepts are very old, right?",
                    "label": 0
                },
                {
                    "sent": "So if you talk about a 3 dimensional camera?",
                    "label": 0
                },
                {
                    "sent": "The first one was proposed actually in 1903, and this has been reinvented over the following century and actually in the SIGGRAPH community.",
                    "label": 0
                },
                {
                    "sent": "This has been reinvented more recently, about Frederick lives in 1903 published the first method for both recording 3 dimensional imagery and displaying it, and the idea is known as the Parallax barrier.",
                    "label": 0
                },
                {
                    "sent": "So for those you have young children, you may have seen the Gallup book.",
                    "label": 0
                },
                {
                    "sent": "This is based on a similar technology.",
                    "label": 0
                },
                {
                    "sent": "You have a sensor or a display device slightly in front of it.",
                    "label": 0
                },
                {
                    "sent": "You put in array of pin holes or slits, right?",
                    "label": 0
                },
                {
                    "sent": "And now you can see that by moving the sensor array back.",
                    "label": 0
                },
                {
                    "sent": "We've eliminated this projection operating.",
                    "label": 0
                },
                {
                    "sent": "Operation from occurring and individual pixel here no longer integrates over a full hemisphere.",
                    "label": 0
                },
                {
                    "sent": "It only integrates over a small angle, so each pixel now has an instantaneous field of view, which is very small, so you can take this 2 dimensional image and demultiplex it to be a four dimensional light field.",
                    "label": 0
                },
                {
                    "sent": "So we've now built a light field camera just using a mask in 1908.",
                    "label": 0
                },
                {
                    "sent": "Very similar concept was proposed by Nobel Laureate no less.",
                    "label": 0
                },
                {
                    "sent": "Just replace each of these pin holes with a lenslet, so placing a small lenslet array over a sensor you can now with a very short exposure capture this 4 dimensional light field.",
                    "label": 0
                },
                {
                    "sent": "Right now, remember this 4 dimensional light field can be decoded to give us a perspective projection from any point on the entrance aperture.",
                    "label": 0
                },
                {
                    "sent": "So if I choose two points, I can have a stereoscopic viewpoint of the scene at least over the entrance aperture my lens.",
                    "label": 0
                },
                {
                    "sent": "And so the main concept behind all of this is that spatial multiplexing of course gives up something.",
                    "label": 0
                },
                {
                    "sent": "So to capture light field we have to compromise spatial resolution to gain angular resolution, and that's the whole game we see in the cigarette communities.",
                    "label": 1
                },
                {
                    "sent": "How do you design light field cameras that using temporal and spatial multiplexing?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Give a high Fidelity representation.",
                    "label": 0
                },
                {
                    "sent": "Now the exact same analysis applies to displays, which is why I'm arguing that all the principles we're seeing competition photography can be ported over the display world in the display system.",
                    "label": 0
                },
                {
                    "sent": "The key component here is we need to think about the audience, and so again conventional displays throw up you're too plain parameterisation along the sensor axis.",
                    "label": 0
                },
                {
                    "sent": "We can parameterise a lightfield coordinate you slightly in front at some known distance.",
                    "label": 0
                },
                {
                    "sent": "We have a second plane and now you can see why.",
                    "label": 0
                },
                {
                    "sent": "In fact 2 dimensional displays cannot have projected general light field just because by design A pixel on a display device emits uniformly.",
                    "label": 0
                },
                {
                    "sent": "Approximately in all directions.",
                    "label": 0
                },
                {
                    "sent": "So once again we go back to that patent from Frederick lives in 1903 and this is in fact if you go to trade shows nowadays you say, OK, I'm wearing glasses in a theater.",
                    "label": 0
                },
                {
                    "sent": "How do I get rid of those glasses in the future?",
                    "label": 0
                },
                {
                    "sent": "You know, when we go to buy a 3 dimensional television, they're basically all at the moment based on two technologies, and so placing a parallax barrier again slightly in front of the sensor allows you to map a pixel which used to admit uniformly in all directions into a small angle, right?",
                    "label": 0
                },
                {
                    "sent": "So now you can take a 2 dimensional device and display of four dimensional function.",
                    "label": 0
                },
                {
                    "sent": "So if you're if you have two eyes located different positions, they see different sub elements of the display and therefore they can see different images.",
                    "label": 0
                },
                {
                    "sent": "Very simple concept, again all based on attenuation.",
                    "label": 0
                },
                {
                    "sent": "Again you can replace those pin holes or slits with lenses you can make you make a much brighter display.",
                    "label": 0
                },
                {
                    "sent": "But the key problem here is, again, we're trading spatial resolution for Angular resolution.",
                    "label": 1
                },
                {
                    "sent": "So if we want to have, say, 5 different viewpoints in front of the display, each of which provides stereoscopic views, then we need 10 images to be multiplexed behind each lens.",
                    "label": 0
                },
                {
                    "sent": "So we give up the spatial resolution by a factor of 10, right?",
                    "label": 0
                },
                {
                    "sent": "So even though we have HTTPS Now, we're back to something that's just 100 pixels in.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so we need to somehow solve this multiplexing problem, But if you go to manufacturers today and you say build me a 3D camera, building A3 to display that doesn't require glasses.",
                    "label": 0
                },
                {
                    "sent": "They will in fact propose these two solutions.",
                    "label": 0
                },
                {
                    "sent": "So Nintendo in the spring is selling a device based on parallax barriers and it's a simple concept.",
                    "label": 1
                },
                {
                    "sent": "You make a sensor display slightly in front of your place.",
                    "label": 0
                },
                {
                    "sent": "These array of slits that's 1903 nineteen 08.",
                    "label": 0
                },
                {
                    "sent": "We have the lenslet and if you look at this trade space, you know if you're an engineer and you say, OK, we're going to build and sell a 3 dimensional display device.",
                    "label": 0
                },
                {
                    "sent": "You might immediately think the lenses are the best solution because they don't attenuate light.",
                    "label": 0
                },
                {
                    "sent": "But you gain a lot with a pinhole array, right?",
                    "label": 1
                },
                {
                    "sent": "Even though the pinhole array attenuates light leading long exposures and Jim displays lens, let's lose resolution permanently, right?",
                    "label": 0
                },
                {
                    "sent": "So most of the content we have for displays and cameras is 2 dimensional in nature, so Nintendo is actually chosen not to use a lenslet array, and Phillips tried in the 90s and 2000 and failed because they tried using Lenslet San.",
                    "label": 0
                },
                {
                    "sent": "When you display a 2 dimensional image, your resolution is equal to the number of lens.",
                    "label": 0
                },
                {
                    "sent": "Let's no longer the number of pixels on the underlying display.",
                    "label": 0
                },
                {
                    "sent": "So what we're really seeing in the market is that we're using.",
                    "label": 0
                },
                {
                    "sent": "Two layer LCD devices and sharp was very clever and bet on this in the 90s and actually a lot of the cell phones were seeing and I think Fujifilm has a camera and also there's displays you can buy for laptops.",
                    "label": 0
                },
                {
                    "sent": "They're all based on dual layer LCD's and the reason is most of the time you don't want to see 3D content, you just disable this barrier.",
                    "label": 0
                },
                {
                    "sent": "You make it completely transparent, now you have a conventional high resolution to display.",
                    "label": 0
                },
                {
                    "sent": "You can do the same thing for light field capture and then you can turn the barrier on.",
                    "label": 1
                },
                {
                    "sent": "Now the problem is when you're actually multiplexing views say you have just two views.",
                    "label": 0
                },
                {
                    "sent": "It'll be half the brightness and half the resolution, right?",
                    "label": 0
                },
                {
                    "sent": "So the real game we want to play, and this is something we've been doing in our lab in MIT for several years now.",
                    "label": 0
                },
                {
                    "sent": "Is to find masks attenuation based functions that allow us to capture and display 4 dimensional light fields using some sort of pattern that transmits much more light, right?",
                    "label": 0
                },
                {
                    "sent": "So since 1903 when these concepts were invented, several things have changed.",
                    "label": 0
                },
                {
                    "sent": "First of all, we have high resolution programmable spatial light modulators that are also very high speed, right?",
                    "label": 0
                },
                {
                    "sent": "Whereas when photographs thought about this, he could print one mask.",
                    "label": 0
                },
                {
                    "sent": "Game over in addition, we also have ubiquitous computation, so we can change these masks depending on what we're trying to capture, and so this will label a lot of interesting applications, hopefully have time to go through them, but I'll just give you a brief.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results.",
                    "label": 0
                },
                {
                    "sent": "So remember the basic idea here is that if you want to use a single mask to Multiplex of four dimensional light filled onto a 2D sensor, you can use an array of pin holes, pays slightly in front of the sensor.",
                    "label": 0
                },
                {
                    "sent": "It turns out and we'll see why in a minute you can actually replace each pinhole with a generalized pattern that has some unique properties in the frequency domain.",
                    "label": 0
                },
                {
                    "sent": "So each pinhole is now replaced by a small tile and you'll see of course that this transmits much more light on average.",
                    "label": 0
                },
                {
                    "sent": "This mask transmits 50% of light, so it cost 1 exposure stop in the camera, but allows you to actually cover the exact same date as a pinhole array.",
                    "label": 0
                },
                {
                    "sent": "So you go from needing.",
                    "label": 0
                },
                {
                    "sent": "You know one minute long exposures to 1 second or less, right?",
                    "label": 0
                },
                {
                    "sent": "So this makes single shot light field capture possible using masks.",
                    "label": 1
                },
                {
                    "sent": "So this pattern solves that game of finding a replacement for pin holes.",
                    "label": 0
                },
                {
                    "sent": "Now it's interesting we have a recent work that's coming out at SIGGRAPH Asia in just next week.",
                    "label": 0
                },
                {
                    "sent": "Is that if you try to use this pattern to generalize parallax barriers for light field display, it actually doesn't work and it turns out that you're doing some sort of frequency domain heterodyning with this pattern, an because you can't have a negative value displayed on LCD.",
                    "label": 0
                },
                {
                    "sent": "This pattern no longer works, and so the recent work representing.",
                    "label": 0
                },
                {
                    "sent": "Is to actually find a different generalization of parallax barriers for light field display and so what's interesting is this sort of pattern.",
                    "label": 1
                },
                {
                    "sent": "Again, we have two LCD layers.",
                    "label": 0
                },
                {
                    "sent": "If you display this sort of pattern, something very similar to this on the two layers, you can actually emit this general multiview light field and what you'll notice is there very different in the case of light field display, we have a periodic pattern that's nonadaptive no matter what the image content is falling on the sensor.",
                    "label": 0
                },
                {
                    "sent": "This pattern is identical, right?",
                    "label": 0
                },
                {
                    "sent": "And it's also static overtime.",
                    "label": 1
                },
                {
                    "sent": "All those properties flip.",
                    "label": 0
                },
                {
                    "sent": "When we look at light field displays, this is of course a non periodic pattern.",
                    "label": 0
                },
                {
                    "sent": "It's content adaptive.",
                    "label": 0
                },
                {
                    "sent": "You can see that the image we're trying to display somehow gets involved into our mask and these also have to change overtime and so it's interesting that as we take concepts from computational photography into computational displays, certain concepts do not port and that has to do with the limitations of negative light and also the limitations of human perception when we design computational cameras, the encoder and decoder are completely under our control.",
                    "label": 0
                },
                {
                    "sent": "We can change the optics and the algorithm for displays we no longer have that freedom.",
                    "label": 0
                },
                {
                    "sent": "We can be as clever as we want in the optics in the encoding, but the decoder is always a human visual system, and so this discrepancy makes the computational imaging for displays.",
                    "label": 0
                },
                {
                    "sent": "I think somewhat more interesting.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so moving ahead hopefully have enough time to get through all this, but I want to explain the basic concept behind how these lightfield capture masks are does.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find.",
                    "label": 0
                },
                {
                    "sent": "And so, just to point this out, for those of you haven't seen this light field cameras basically reinvent the concept that was invented in 1903.",
                    "label": 0
                },
                {
                    "sent": "Sorry it's not up there by Frederic Ives, the basic ideas we're going to take a camera and we're going to put a mask behind it that functions like a parallax barrier.",
                    "label": 0
                },
                {
                    "sent": "So in the cigarette community, this was reinvented around 2005, and So what happened is they took a medium format camera and then placed a lenslet array, just like Lippmann proposed in 1908, that was micro machine, so this is simply a digital version.",
                    "label": 0
                },
                {
                    "sent": "Of something invented 100 years ago of what they did with that was entirely new though, and so you can build these things very inexpensively.",
                    "label": 0
                },
                {
                    "sent": "Also at Mitsubishi we also developed a very similar camera, but exploiting the masks.",
                    "label": 0
                },
                {
                    "sent": "Remember, masks have much more flexibility because they're cheap and also programmable if implemented with LCD's you can actually go back to a conventional camera, whereas a design like this you permanently compromised.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Resolution.",
                    "label": 0
                },
                {
                    "sent": "So now that we sort of go back to this trivial diagram of how a camera works, we can actually perform a light filled analysis.",
                    "label": 0
                },
                {
                    "sent": "So what I'm trying to answer here is how does image formation occur in the frequency domain?",
                    "label": 0
                },
                {
                    "sent": "So remember we have this two plane parameterisation of the light field.",
                    "label": 1
                },
                {
                    "sent": "EU plane parameterise is the intersection with the sensor, the S plane parameterized.",
                    "label": 0
                },
                {
                    "sent": "The intersection with the aperture plane of the lens, right?",
                    "label": 0
                },
                {
                    "sent": "So the image falling on the sensor before projection right before you average over the angles?",
                    "label": 0
                },
                {
                    "sent": "Is this 4 dimensional light field?",
                    "label": 1
                },
                {
                    "sent": "Now we all took signal processing or probably many of us.",
                    "label": 0
                },
                {
                    "sent": "You can always take avoid transform so you don't have to have an intuition for what this is, but because we have a four dimensional 2 dimensional light field in Flatland falling on the sensor, we have some light filled factor spectrum that falls on the sensor.",
                    "label": 0
                },
                {
                    "sent": "You can engineer the system to essentially provide a bandpass filter effect.",
                    "label": 0
                },
                {
                    "sent": "So what we're assuming in the following analysis is that the light field falling on the sensor is band limited, right, so?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next thing to realize is what happens when we don't have a mask present, right?",
                    "label": 0
                },
                {
                    "sent": "So this is a frequency domain interpretation of how image image Ng occurs, right?",
                    "label": 0
                },
                {
                    "sent": "What normally happens?",
                    "label": 0
                },
                {
                    "sent": "We have a pixel and it integrates overall angles.",
                    "label": 0
                },
                {
                    "sent": "It turns out this is a concept related to something known as the voice projection slice theorem.",
                    "label": 0
                },
                {
                    "sent": "In tomography you can think of a camera as being very equivalent to a CT scanner.",
                    "label": 0
                },
                {
                    "sent": "What happens is the sensor, because it measures the average value in angle.",
                    "label": 0
                },
                {
                    "sent": "What it's doing is extracting a slice in the frequency domain.",
                    "label": 1
                },
                {
                    "sent": "Along the spatial F sub U axis.",
                    "label": 0
                },
                {
                    "sent": "Right, and so if I have a very high resolution sensor, the light field falling on the sensor is actually oversampled, and So what if you want to think about how image formation occurs when you take a photograph.",
                    "label": 0
                },
                {
                    "sent": "This slice occurs and then you take an inverse Fourier transform.",
                    "label": 0
                },
                {
                    "sent": "That's the image you receive, right?",
                    "label": 0
                },
                {
                    "sent": "And so most cameras today.",
                    "label": 0
                },
                {
                    "sent": "I have very high resolution, and So what we're going to do is exploit this oversampling somehow.",
                    "label": 0
                },
                {
                    "sent": "We need to use lenses or masks to move the unsampled components, the unsampled spatio angular frequencies of light field.",
                    "label": 0
                },
                {
                    "sent": "Into this oversampled sensor bandwidth, right and so this was a work from Mitsubishi in 2007.",
                    "label": 0
                },
                {
                    "sent": "If you just look at the shieldfield I mentioned that very early in the talk this 4 dimensional volumetric attenuation function.",
                    "label": 0
                },
                {
                    "sent": "If you look at a shield filled of a single planar attenuator lying in front of a sensor, then what occurs in the frequency domain?",
                    "label": 0
                },
                {
                    "sent": "You have multiplication in the space in the Ray domain, which means you have convolution in the frequency domain, so a mask slightly in front of the sensor ends up being convolution along a slanted line and so what's interesting is if you go back and think about.",
                    "label": 0
                },
                {
                    "sent": "Frederic Ives invention.",
                    "label": 0
                },
                {
                    "sent": "Using this framework, he displayed a mass containing a uniform array of pin holes, right?",
                    "label": 0
                },
                {
                    "sent": "So if I have a Dirac comb, it's fully transform is also a Dirac comb, which means what's happens is the.",
                    "label": 1
                },
                {
                    "sent": "When I take a photograph with a pinhole array, I'm can.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evolving my baseband light filled with this slanted Dirac comb.",
                    "label": 0
                },
                {
                    "sent": "So this is the frequency domain interpretation of parallax barriers, and so what's interesting is if you get this distance just right and the pin hole spacing just right, you'll see that you take this baseband light filled and modulate it into the over simple oversampled sensor bandwidth, right?",
                    "label": 0
                },
                {
                    "sent": "So now the process I can do is I can take a photograph with my mask tickets for trans.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Form.",
                    "label": 0
                },
                {
                    "sent": "Then reshape.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I thought about this a couple years ago and I said, well, this is very nice.",
                    "label": 0
                },
                {
                    "sent": "It's a nice theoretical framework, but at the end of the day it doesn't give you any new pattern, right?",
                    "label": 0
                },
                {
                    "sent": "It's just explaining how panels work using a frequency domain interpretation.",
                    "label": 0
                },
                {
                    "sent": "So now what we want to do is play a game we know to capture a heterodyne lightfield using a single 2 dimensional sensor in one mask.",
                    "label": 0
                },
                {
                    "sent": "We need that mask to avoid transform, which is a 2 dimensional Dirac cone.",
                    "label": 1
                },
                {
                    "sent": "Right so Frederick, I've proposed pinhole arrays.",
                    "label": 0
                },
                {
                    "sent": "We know that these are self dual, so this works.",
                    "label": 0
                },
                {
                    "sent": "In 2007 Mitsubishi proposed this sum of sinusoids pattern right?",
                    "label": 0
                },
                {
                    "sent": "And so it turns out that if you just express each pair of impulses in the frequency domain as a spatial frequency at some orientation that allows you this pattern to also represent a uniform series of impulses in the frequency domain.",
                    "label": 1
                },
                {
                    "sent": "Now it turns out this pattern, while passing slightly more light, is actually just a truncated Fourier series of a pinhole, so it's actually only marginally better than a pinhole.",
                    "label": 0
                },
                {
                    "sent": "And So what we did is try to find pattern.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That transmit more light, and so if you just look at the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patterns can holes in the science of sinusoids.",
                    "label": 0
                },
                {
                    "sent": "Code are both periodic.",
                    "label": 0
                },
                {
                    "sent": "Right so they.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can ask well what is the family of periodic functions that also produce a 2 dimensional impulse train right?",
                    "label": 1
                },
                {
                    "sent": "And so thinking back to signal processing, I think it's chapter four of Oppenheim and Wilsky.",
                    "label": 0
                },
                {
                    "sent": "Actually, if you tile any random function, tile it so we make a periodic function, then we always get a uniform.",
                    "label": 0
                },
                {
                    "sent": "Sorry, an impulse train in the frequency domain, but the amplitude and phase of each impulse are given by the discrete for a series coefficients of an individual tile.",
                    "label": 0
                },
                {
                    "sent": "Right, So what this means is to capture light field.",
                    "label": 0
                },
                {
                    "sent": "We would like these impulses to be equal amplitude, right?",
                    "label": 0
                },
                {
                    "sent": "So what we want is a tiling pattern that is broadband, right?",
                    "label": 0
                },
                {
                    "sent": "So the the entire class of patterns which can capture light field are given by tiles which are have a broadband for a transform and so if.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go to the literature actually in radio astronomy they have a pattern which has a lot of properties that are beneficial.",
                    "label": 0
                },
                {
                    "sent": "It's called a modifying modified, uniformly redundant array.",
                    "label": 1
                },
                {
                    "sent": "Now this is just one solution you could use, but it has some nice properties.",
                    "label": 0
                },
                {
                    "sent": "For instance it's binary, so you can print it at very high contrast using commercial offset printers.",
                    "label": 0
                },
                {
                    "sent": "It also transmits 50% of light so long as the dimensions here are prime length, so it gives us a closed form solution to capture.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Light filled in a single stop and so, just to summarize, this originally had pin holes.",
                    "label": 0
                },
                {
                    "sent": "It turns out this sum of sinusoids passes slightly more light.",
                    "label": 0
                },
                {
                    "sent": "I mean significantly more in light, but it's just a truncated for a series, so the more angles you capture, the worst this performances.",
                    "label": 0
                },
                {
                    "sent": "Whereas with these tiled broadband codes you actually always have a 50% duty cycle, right?",
                    "label": 0
                },
                {
                    "sent": "So with very short exposures we can now capture light fields using mass.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we went ahead and built this using the Mitsubishi camera is very simple.",
                    "label": 0
                },
                {
                    "sent": "You just go to the print shop, ask them to print this pattern.",
                    "label": 0
                },
                {
                    "sent": "They ask you what is this?",
                    "label": 0
                },
                {
                    "sent": "Why are you printing it?",
                    "label": 0
                },
                {
                    "sent": "You say just.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Martin print it.",
                    "label": 0
                },
                {
                    "sent": "Here's what the photograph looks like.",
                    "label": 0
                },
                {
                    "sent": "So if you believe me what I've presented so far, this 2 dimensional photograph actually contains the parallax of views, right?",
                    "label": 0
                },
                {
                    "sent": "So by decoding this image, I can actually see slightly behind objects, and what Stanford showed in 2005 is not because I can do that.",
                    "label": 0
                },
                {
                    "sent": "I can also make a synthetic focal stack right?",
                    "label": 0
                },
                {
                    "sent": "So if you apply the foyer domain decoding I described first, we take avoid transform of this image.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You'll see a bunch of peaks and each peak here is coming from one of those impulses due to the foyer transform action of the mask, right?",
                    "label": 0
                },
                {
                    "sent": "So we just take all the regions within this way, transform, reshape them into a four dimensional data structure and then in.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I transform and that gives us an array of images.",
                    "label": 0
                },
                {
                    "sent": "So we took a single image from the camera and now one of these images corresponds to a small viewpoint somewhere different on the aperture.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, and so from that you can actually create a focal stack, and because you can create a focal stack, you can now estimate depth.",
                    "label": 0
                },
                {
                    "sent": "You can make an all focus image.",
                    "label": 0
                },
                {
                    "sent": "You can do all these things in computational photography that people have been doing in the last few years.",
                    "label": 0
                },
                {
                    "sent": "And so a nutshell.",
                    "label": 0
                },
                {
                    "sent": "That's mask based light field photography, right?",
                    "label": 0
                },
                {
                    "sent": "So because we're within one stop of lenses, we can now have all the flexibility and programmability of masks without the losses.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In curd by optics.",
                    "label": 0
                },
                {
                    "sent": "So at this point we had a couple of small follow on projects that just explored the space that's enabled by large format light field capture.",
                    "label": 1
                },
                {
                    "sent": "Because we can print these masks very large compared to lenses, we can do a lot of weird things.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, coming from sort of a computer vision background in my earlier sort of Masters Phase I thought a lot about 3D scanning, so he said, well, you know, in 3D scanning this sort of the brute force solution is just to buy a bunch of cameras, right?",
                    "label": 0
                },
                {
                    "sent": "And if I calibrate these very carefully, I can intersect the tangent cones to each surface and I'll get get an estimate of the object shape known as the visual hole.",
                    "label": 0
                },
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "Actually this is being proposed for three dimensional television systems, so there are several European efforts where they buy hundreds of cameras, they synchronize them.",
                    "label": 0
                },
                {
                    "sent": "They have these big rooms.",
                    "label": 0
                },
                {
                    "sent": "Full of blue cloth segment.",
                    "label": 0
                },
                {
                    "sent": "The actor right?",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is make this very cheap, and so the first thing to make it cheap is to not use cameras.",
                    "label": 0
                },
                {
                    "sent": "Let's use lights, because in many applications light sources and cameras are dual.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we can rearrange this light array and make a somewhat very strange camera.",
                    "label": 0
                },
                {
                    "sent": "So here we have an array of light sources.",
                    "label": 0
                },
                {
                    "sent": "We have a diffuser in a camera, so in some ways you can think of this as an enormous light field camera.",
                    "label": 0
                },
                {
                    "sent": "This is a sensor and this is the aperture of the lens.",
                    "label": 0
                },
                {
                    "sent": "If we wanted to reconstruct the shape of this object, we could turn a light on, it would cast a shadow.",
                    "label": 0
                },
                {
                    "sent": "We could repeat that process and once again we can recover the visual hole.",
                    "label": 0
                },
                {
                    "sent": "And this is basically exactly how CT scanner works, right?",
                    "label": 0
                },
                {
                    "sent": "This is just an optical version of that right now.",
                    "label": 0
                },
                {
                    "sent": "The problem with this is because we have an individual point of projection that's time multiplexed.",
                    "label": 0
                },
                {
                    "sent": "We can no longer scan.",
                    "label": 0
                },
                {
                    "sent": "Dynamic scenes, right?",
                    "label": 0
                },
                {
                    "sent": "Just like CT scanners, have trouble that scanning dynamic objects.",
                    "label": 0
                },
                {
                    "sent": "So what we'd like to do is be able to handle the case of simultaneous projections.",
                    "label": 1
                },
                {
                    "sent": "Right, and so to handle this.",
                    "label": 0
                },
                {
                    "sent": "You know this could you could you could make this a machine learning problem.",
                    "label": 0
                },
                {
                    "sent": "You could say, OK, I have all these shadows multiplexed.",
                    "label": 0
                },
                {
                    "sent": "Let's try to decompose that right?",
                    "label": 0
                },
                {
                    "sent": "And as you add more and more lights, that decomposition is going very difficult to do, especially if you have any realistic noise model for the camera.",
                    "label": 0
                },
                {
                    "sent": "So instead we use this large format light field camera.",
                    "label": 1
                },
                {
                    "sent": "So we say, let's just parameterized this as a light field.",
                    "label": 0
                },
                {
                    "sent": "If we could somehow capture the light field over a meter wide region.",
                    "label": 0
                },
                {
                    "sent": "Then we could just query that light field right in the light field tells us an individual Ray what the intensity is, right?",
                    "label": 0
                },
                {
                    "sent": "So if we take a four dimensional light field, 2 dimensional slices will be the shadows.",
                    "label": 0
                },
                {
                    "sent": "So in a single instant we can measure all of the shadows from all the light sources right?",
                    "label": 0
                },
                {
                    "sent": "So this would allow you to make a CT scanner with no moving parts.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do you capture this?",
                    "label": 0
                },
                {
                    "sent": "Well, you just use exactly the solution we already have, right?",
                    "label": 0
                },
                {
                    "sent": "We can just play some ask either with pinhole array or now one of these highly transmitting patterns slightly in front of the sensor plane.",
                    "label": 1
                },
                {
                    "sent": "Right, so when a CT scanner would have coded pattern slightly around the sensor and now in the single instant you can recover the visual hole.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, because you have the attenuation map directly, so you just take the received light field divided by a calibration light field that gives you the Shieldfield 2 dimensional slices of that will in fact be the shadows.",
                    "label": 0
                },
                {
                    "sent": "So this is single shot visual and now you can replace the.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the broadband pattern, so we'd like to build things by hand in our group at MIT, so we took this idea and just directly instantiate it.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's just the direct idea made real, so we take a camera large sheet of paper slightly in front of it.",
                    "label": 0
                },
                {
                    "sent": "We placed one of these enormous masks right, and so here you have all the benefits if you try to do this with lenses.",
                    "label": 0
                },
                {
                    "sent": "Do it right.",
                    "label": 0
                },
                {
                    "sent": "It cost you several $1000 to have custom made.",
                    "label": 0
                },
                {
                    "sent": "But if you really think about the see T application lenses don't work right because you can't have a refractive optical element for X Rays, so this is sort of prototyping aceti type scanner.",
                    "label": 0
                },
                {
                    "sent": "Here you can see if we have all the lights on we have multiplexed shadows, but now the inversion problem, right?",
                    "label": 0
                },
                {
                    "sent": "You could think in the inversion the condition matrix has been improved by having this high frequency modulation.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so here's just an example of what happens.",
                    "label": 0
                },
                {
                    "sent": "You put an object in.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The system you take a single exposure, so this is just a quarter of a second.",
                    "label": 0
                },
                {
                    "sent": "Now if you had pin holes, this would take a 62nd or longer exposure, right?",
                    "label": 0
                },
                {
                    "sent": "So this is allow fundamentally allowing single shot dynamic scenes.",
                    "label": 0
                },
                {
                    "sent": "If you zoom into this, you'll see that there's some strange modulation occurring here.",
                    "label": 0
                },
                {
                    "sent": "Again, this is all decoded in the frequency domain, just like the example I showed earlier for light field.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Camera here you can see again we get a set of images.",
                    "label": 0
                },
                {
                    "sent": "Now this what these images represent is the image seen from each light source.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can take that and again run the visual whole algorithm.",
                    "label": 0
                },
                {
                    "sent": "Whoops, it's playing already.",
                    "label": 0
                },
                {
                    "sent": "And you get a result, right?",
                    "label": 0
                },
                {
                    "sent": "And so this is a very coarse result because we have just one camera, right?",
                    "label": 0
                },
                {
                    "sent": "So we're using one camera as if it was 36 cameras and you have some artifacts due to the fact that we're using limited baseline tomography, right?",
                    "label": 0
                },
                {
                    "sent": "We're not getting a full 100 degrees set of projections.",
                    "label": 0
                },
                {
                    "sent": "We're only getting about 40 degrees.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now that we've found a generalization of parallax barriers, we can now efficiently reconstruct objects because we can make very large masks that have very short exposure times, and so we took this idea in a different direction.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another project, and again I'm just trying to show how concepts from computational tography can now move into completely different spaces, and so let's step back again at the Media Lab.",
                    "label": 0
                },
                {
                    "sent": "We sort of think a lot about human computer interaction, so we said well, are there any repercussions of this work in that domain?",
                    "label": 0
                },
                {
                    "sent": "And so if you think about the state of the art, we have Apple.",
                    "label": 0
                },
                {
                    "sent": "Here's a representative.",
                    "label": 0
                },
                {
                    "sent": "They were very successful in taking the idea presented at Ted just a few years ago by Jeff Hahn and commercializing that product and thereby pushing into the market.",
                    "label": 0
                },
                {
                    "sent": "So multi touch is now sort of a defacto thing that people assume will be in their devices.",
                    "label": 0
                },
                {
                    "sent": "Just in the last few years, we've also seen gesture based interfaces emerge right.",
                    "label": 0
                },
                {
                    "sent": "And most of these involve having some widget in your hand except for connect.",
                    "label": 0
                },
                {
                    "sent": "Right and then the other sort of display trend.",
                    "label": 0
                },
                {
                    "sent": "We're seeing our lighting sensitive displays right?",
                    "label": 1
                },
                {
                    "sent": "So most of your laptops, your cell phones.",
                    "label": 0
                },
                {
                    "sent": "If you have an iPhone, you'll notice that it changes its brightness depending on the ambient illumination, right?",
                    "label": 0
                },
                {
                    "sent": "And you can also imagine displays that take that to sort of an extreme, and use that ambient light sensor to actually make displays that respond to lighting.",
                    "label": 0
                },
                {
                    "sent": "So this is some SIGGRAPH work from several years ago, and So what we said is OK, we have all these things, and in a few minutes will see how it's related to this mask concept.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're going to make a single device that combines this because fundamentally all of these use optical sensors, right?",
                    "label": 0
                },
                {
                    "sent": "So one way of implementing multi touch is to use embedded photodetector arrays and a lot of the reason this is occurring is 'cause Apple has most of the patents on capacitive, multi touch and so now you're seeing optical multi touch where each pixel has a photo detector, right?",
                    "label": 1
                },
                {
                    "sent": "And then the photo textures you occlude determine the position of your finger.",
                    "label": 1
                },
                {
                    "sent": "Also you can do time of flight which is also an optical method and ambient light sensor is just a photodiode.",
                    "label": 1
                },
                {
                    "sent": "So basically combine all these devices into one thing.",
                    "label": 0
                },
                {
                    "sent": "And this one thing is a single LCD panel that at one instant in time measures the incident 4 dimensional light field.",
                    "label": 0
                },
                {
                    "sent": "So it's like a multi view camera array spanning the aperture right?",
                    "label": 0
                },
                {
                    "sent": "The display surface and at the other instant in time it simply displays a normal 2D image.",
                    "label": 0
                },
                {
                    "sent": "So let me describe how we built this.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fairly straightforward extension of what we did right.",
                    "label": 0
                },
                {
                    "sent": "The previous example I showed you with the idea of capturing the shape of an object and to do that we had a light source array, right?",
                    "label": 0
                },
                {
                    "sent": "Because when you turn on a light fundamentally it passes through the mask, gets modulated, falls on the sensor if array just passes through and include are it does not right.",
                    "label": 0
                },
                {
                    "sent": "So we can measure the shadows.",
                    "label": 0
                },
                {
                    "sent": "But really why did we need this light source array at all?",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Y&CT scanners.",
                    "label": 0
                },
                {
                    "sent": "Don't you just have some ambient illumination source, right?",
                    "label": 0
                },
                {
                    "sent": "So if we just turn on a light source, we also get some sort of reflected light field.",
                    "label": 0
                },
                {
                    "sent": "And the reflected light field could be used to reconstruct the shape as well.",
                    "label": 0
                },
                {
                    "sent": "So the question is, why can't we just build this system will look pretty much can if you zoom into this mask.",
                    "label": 0
                },
                {
                    "sent": "Here you'll see the problem is if we have a Ray of light approaching at normal incidence, it will fall in the sensor right?",
                    "label": 0
                },
                {
                    "sent": "So if we put a parallax barrier here, we'd be able to measure the incident 40 light field.",
                    "label": 0
                },
                {
                    "sent": "But then if we have an angle Ray of light coming in to speak steep angle, it will fall in the same sensor element which will violate the assumptions built into the demosaicing algorithm for the light fields.",
                    "label": 0
                },
                {
                    "sent": "And so all you have to do to make this work is at an angle limiting film.",
                    "label": 0
                },
                {
                    "sent": "Right, so if you put an angle limiting film, that problem solved.",
                    "label": 0
                },
                {
                    "sent": "Now the next step is to use one of these optical multi touch.",
                    "label": 0
                },
                {
                    "sent": "So get rid of the camera and diffuser and you just have a large large format sensor that also has a backlight embedded in it and there's actually patents from Apple.",
                    "label": 0
                },
                {
                    "sent": "Sharpen planer on this exact device which was the inspiration of the work on the backlight embedded backlight.",
                    "label": 0
                },
                {
                    "sent": "So now the last step here is we can replace the mask with an LCD right?",
                    "label": 0
                },
                {
                    "sent": "And so now this gives us a very thin display device, it's only slightly thicker than a normal display, but what we can do is we can display when the backlight is off the heterodyne code.",
                    "label": 0
                },
                {
                    "sent": "Right and then with the ambient illumination in the room, we can capture light field.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then we can turn the backlight on and use that LCD panel as a display device, right?",
                    "label": 0
                },
                {
                    "sent": "So we can have a single thin LCD panel that can see not just one image but an array of images spanning the display surface.",
                    "label": 0
                },
                {
                    "sent": "And we can also display a normal normal image content, and we can alternate between the two and.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time division Fashion Time Multiplex fashion.",
                    "label": 0
                },
                {
                    "sent": "So we built this at the time.",
                    "label": 0
                },
                {
                    "sent": "Sharp wasn't willing to share their LCD panel if since changed their opinion and so we actually cheated and we made one of these large format sensors using the same trick of a diffuser and cameras.",
                    "label": 0
                },
                {
                    "sent": "But really, there's no reason this can't be as thin as the gap between the sensor in the display.",
                    "label": 0
                },
                {
                    "sent": "So we hacked this apart 'cause we like building things.",
                    "label": 0
                },
                {
                    "sent": "We have an LCD panel stripped apart, the diffuser cameras and light.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Box, and here's the result.",
                    "label": 0
                },
                {
                    "sent": "Let me just play this.",
                    "label": 0
                },
                {
                    "sent": "So again, remember, this is like a sequence of projects where first we found a way to use masks to capture light fields, and once we could do that, we can make very large format devices because it's just a printed pattern.",
                    "label": 0
                },
                {
                    "sent": "But those masks, unlike parallax barriers, transmit much more light, so at each instant in time every single frame.",
                    "label": 0
                },
                {
                    "sent": "This backlight is oscillating, but it's actually 120 Hertz.",
                    "label": 0
                },
                {
                    "sent": "The human eye can't perceive it.",
                    "label": 0
                },
                {
                    "sent": "So at 60 Hertz we're decoding the light field.",
                    "label": 0
                },
                {
                    "sent": "We're taking a light field photograph.",
                    "label": 0
                },
                {
                    "sent": "And then we're using that array of cameras to synthesize a focal stack like I showed you earlier.",
                    "label": 0
                },
                {
                    "sent": "So at each instant in time we have a focal stack.",
                    "label": 0
                },
                {
                    "sent": "We can then run a depth from focus algorithm, so we now have a depth map at 60 Hertz.",
                    "label": 0
                },
                {
                    "sent": "We can do blob tracking on the depth Maps we can track every object in 3D in front of the display, and so now without any capacitive devices we can do multi touch interaction.",
                    "label": 0
                },
                {
                    "sent": "And we can have this blob tracker basically driving this very simple example.",
                    "label": 0
                },
                {
                    "sent": "So here the lateral translation of your hand controls the rotation matrix.",
                    "label": 0
                },
                {
                    "sent": "The scale of the object is controlled by the depth of the hand, right?",
                    "label": 0
                },
                {
                    "sent": "So this is fundamentally showing multi touch and gesture based interaction, right?",
                    "label": 0
                },
                {
                    "sent": "So if you try doing this with like a Microsoft Connect in a capacitive device, some sort of Frankenstein device you have problems near the display device where you can't handover between the two sensors because the field of view isn't available.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another thing you can do here is implement sort of what I think is beyond a 3 dimensional display, right?",
                    "label": 0
                },
                {
                    "sent": "Imagine 10 years down the road we all have 3D TV's that work without glasses.",
                    "label": 0
                },
                {
                    "sent": "If you go to a museum and you have a vase with Flowers in it next to the virtual representation of that, the real face will look much more faithful because it responds to ambient lighting, right?",
                    "label": 0
                },
                {
                    "sent": "And so this example.",
                    "label": 0
                },
                {
                    "sent": "Here is what we call light filled transfer.",
                    "label": 0
                },
                {
                    "sent": "We have a virtual scene and we're shining an actual flashlight at the display surface.",
                    "label": 0
                },
                {
                    "sent": "But remember, we're measuring the four dimensional light field.",
                    "label": 0
                },
                {
                    "sent": "At every at 60 Hertz so we can take this set of raise their intensities and colors and continue propagating those Rays into the virtual scene.",
                    "label": 0
                },
                {
                    "sent": "So real lighting sources can interact with virtual content.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the buy screen.",
                    "label": 0
                },
                {
                    "sent": "So we played around with cameras a lot, and at this point we said, well, you know, parallel experience.",
                    "label": 0
                },
                {
                    "sent": "Have two applications.",
                    "label": 0
                },
                {
                    "sent": "They're not really used a lot for light field capture.",
                    "label": 1
                },
                {
                    "sent": "Typically people use lenses and they just say we're interested in application.",
                    "label": 0
                },
                {
                    "sent": "We don't care that we lose spatial resolution or we don't care about having flexibility, but the real place you see parallax barriers in light field display, right?",
                    "label": 1
                },
                {
                    "sent": "If you go to trade shows and you look for glasses free 3D TV's, many of them actually use a parallax barrier, just like Nintendo is doing in a few months.",
                    "label": 0
                },
                {
                    "sent": "So that way you can revert back to the 2D mode, so we had all this theory and we said, well, Gee, can't we just put a heterodyne code in front of a normal display and get a 3 dimensional display?",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out you can't, so you can definitely put it there.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exterior.",
                    "label": 0
                },
                {
                    "sent": "And so I just want to show for the input side the problem reverses, right normally.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have is we have a sensor looking at the world through a barrier and we decode this 2D image to give us the light field.",
                    "label": 0
                },
                {
                    "sent": "But in display the problem is exactly the opposite.",
                    "label": 0
                },
                {
                    "sent": "We know the 40 light field we want to admit but we only have a 2 dimensional sensor in some known attenuation pattern.",
                    "label": 0
                },
                {
                    "sent": "So you have to find the encoding for the sensor and the mask pattern to omit the 40 light field.",
                    "label": 1
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the input to a 3D TV is actually not 3D at all, they're misnamed, they're actually 4 dimensional devices, and the way to think about that is if I have a true 3D TV and I close one eye and I look at this scene that has a green sphere in the plane of the display and a red one in front, and a blue one behind as I walked to the right, I perceive parallax, right?",
                    "label": 0
                },
                {
                    "sent": "This is not surprised I have horizontal parallax as I move my head up and down I have vertical parallax, right?",
                    "label": 0
                },
                {
                    "sent": "So the impact consortium the standard for Multiview 3D is in fact.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A light field and it's a 2D array of 2D images, right?",
                    "label": 0
                },
                {
                    "sent": "So if the light field concept wasn't clear earlier, hopefully this is what I actually give at each frame to a 3D display is a 2D array of images describing the horizontal and vertical view parallax, so it's a four dimensional light field using the parallax barrier solution I keep.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Opening all you have to do to display this content is make a set of pin holes and each panel is separated by three pixels horizontally and vertically, and then this would be displayed on the front or rear LCD panel.",
                    "label": 0
                },
                {
                    "sent": "It actually.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doesn't matter, and on the other LCD panel you display a set of interlaced images.",
                    "label": 0
                },
                {
                    "sent": "Right, and so this is just like that gallop book that your children might have when you stand at a distance.",
                    "label": 0
                },
                {
                    "sent": "You're seeing this pattern through a pinhole array and as you walk to the right, the pinhole array is affectively sliding and then it's appetizing and giving you the sub image right?",
                    "label": 0
                },
                {
                    "sent": "So the green sphere which is in the plane of this display has no disparity, whereas the red sphere right has this horizontal parallax at the edge, which is why you see this dappling pattern right?",
                    "label": 0
                },
                {
                    "sent": "So this is traditional parallel experience.",
                    "label": 0
                },
                {
                    "sent": "Now the problem.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is something intended, will have to confront is when you go to 3D mode.",
                    "label": 0
                },
                {
                    "sent": "This mask is incredibly dim, right?",
                    "label": 0
                },
                {
                    "sent": "It transmits very little light, just one 9th of the light.",
                    "label": 0
                },
                {
                    "sent": "Even if you had.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transparency for the open elements.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so for this project we actually tried using heterodyne and for reasons I won't explain now it failed and so we said, well, let's just step back for a minute.",
                    "label": 0
                },
                {
                    "sent": "Remember that since 1903 we have high speed programmable high resolution LCD panels and we also have computation.",
                    "label": 0
                },
                {
                    "sent": "So maybe there's something that can be done to make something equivalent to heterodyne codes for display, and so it actually turns out you can do that and you just start with first principles.",
                    "label": 0
                },
                {
                    "sent": "You say if I have two liquid crystal panels, what I have is a light box followed by two masks.",
                    "label": 0
                },
                {
                    "sent": "Have a couple minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, great.",
                    "label": 0
                },
                {
                    "sent": "So if I have a Ray of light leaving the light box.",
                    "label": 1
                },
                {
                    "sent": "Right, it just gets modulated twice.",
                    "label": 1
                },
                {
                    "sent": "So if I display a transparency pattern on each layer, they emitted light field.",
                    "label": 0
                },
                {
                    "sent": "You can think of as a matrix.",
                    "label": 0
                },
                {
                    "sent": "And this, amid light field, is given by the product of the two attenuations.",
                    "label": 0
                },
                {
                    "sent": "Now we have sort of an optimization problem we want to solve.",
                    "label": 0
                },
                {
                    "sent": "We have a target lightfield, we're trying to approximate.",
                    "label": 0
                },
                {
                    "sent": "We're free to control the transparency on these two layers.",
                    "label": 0
                },
                {
                    "sent": "Right, and so one result we show in this paper we're presenting.",
                    "label": 0
                },
                {
                    "sent": "First of all is that if you choose the correct coordinate system only in one coordinate system, you can express the emitted light field as the outer product of the two mask transparency functions, right?",
                    "label": 0
                },
                {
                    "sent": "So you can see here that the emitted light field in this coordinate parameterization is given by the outer product of the pinhole array and the interlaced images, and so now you can immediately see why pinhole arrays are low resolution and also dim.",
                    "label": 0
                },
                {
                    "sent": "Right, but this gives us a new insight into mass based light field display.",
                    "label": 0
                },
                {
                    "sent": "It turns out parallax barriers are not just light deficient.",
                    "label": 0
                },
                {
                    "sent": "The rank deficient, because I can express the target light field as an outer product.",
                    "label": 0
                },
                {
                    "sent": "That means the space of light fields that can create have to be rank one, right?",
                    "label": 0
                },
                {
                    "sent": "And if you actually measure a real light field, they're not rank one, right?",
                    "label": 0
                },
                {
                    "sent": "So we have this problem where for 100 years we've been using two layer devices, but fundamentally they cannot display light fields, at least not in the in the L2 norm sense very accurately so.",
                    "label": 0
                },
                {
                    "sent": "What we did is we said right?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One way to solve this is to use temporal multiplexing, and so in 2000 Ken Perlin from my you had a very interesting paper where you said let's just use high speed LCDS and let's shift the pin holes overtime, right?",
                    "label": 0
                },
                {
                    "sent": "And in this new framework we've proposed, you can see what happens is what we're doing is we're getting a second outer product that's coming because we have a high speed LCD panel.",
                    "label": 0
                },
                {
                    "sent": "The human eye integrates, say, at 60 Hertz, but if we have 240 Hertz LCD panel, we display 4 images that get averaged together, right?",
                    "label": 0
                },
                {
                    "sent": "So we can build a full resolution lightfield matrix.",
                    "label": 0
                },
                {
                    "sent": "Which means if we allow ourselves to display 4 images over the exposure time of the eye, we can do a rank four approximation of a light field, right?",
                    "label": 0
                },
                {
                    "sent": "So when you see all these bullet points when you go to Best Buy that say this is 120 Hertz.",
                    "label": 0
                },
                {
                    "sent": "LCD is sort of meaningless.",
                    "label": 0
                },
                {
                    "sent": "They try to market it for motion deblurring, but they should really market for is rank every frame rate you buy is buying you matrix rank.",
                    "label": 0
                },
                {
                    "sent": "And so we're actually calling this high rank displays, and so we hope manufacturers call these high rank displays because the general public will have to learn what rank is.",
                    "label": 0
                },
                {
                    "sent": "So we're going to form this outer product composition, but you still see the problem is an individual pixel here is very dim, because over the entire exposure time it's only open once, right?",
                    "label": 0
                },
                {
                    "sent": "So this is a heuristic construction of the lightfield matrix.",
                    "label": 0
                },
                {
                    "sent": "It's a heuristic decomposition.",
                    "label": 0
                },
                {
                    "sent": "The one key, the second key contribution.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper is to say, well, let's break all these heuristics we've had for 100 years, and let's just assume we can display anything on the two layers.",
                    "label": 0
                },
                {
                    "sent": "Overtime, right?",
                    "label": 0
                },
                {
                    "sent": "And so being in a machine learning community, you already know where we went with this, but some of this was new to me, so it took us a little while, but we said OK, well, this is easy.",
                    "label": 0
                },
                {
                    "sent": "We have a target light filled matrix.",
                    "label": 0
                },
                {
                    "sent": "We want to find a factorization in two other matrices.",
                    "label": 0
                },
                {
                    "sent": "The columns of this matrix represent the rear layer.",
                    "label": 0
                },
                {
                    "sent": "The rows represent the outer layer, right?",
                    "label": 0
                },
                {
                    "sent": "So the question is now or sorry.",
                    "label": 0
                },
                {
                    "sent": "The benefit here is that we can have pixels open for a longer time.",
                    "label": 0
                },
                {
                    "sent": "So the display can become much brighter.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, and so really, this is a very easy problem.",
                    "label": 0
                },
                {
                    "sent": "Many of the room would probably have many ways of solving this.",
                    "label": 0
                },
                {
                    "sent": "We sort of used a textbook solution.",
                    "label": 0
                },
                {
                    "sent": "We said, look, we're trying to decompose a matrix into a sum of outer.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Products.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It would just be singular value decomposition done, except you have to deal with the negative light issue.",
                    "label": 0
                },
                {
                    "sent": "If you ran a singular value composition you would have negative values in these matrices which you cannot display practically.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have to solve a non negative matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "We chose to minimize the L2 norm, which again is probably the wrong thing to do because in computational photography that might be OK for computational displays.",
                    "label": 0
                },
                {
                    "sent": "This should really be a perceptual error metric that we're optimizing, but we chose L2 norm because we have all the machinery for that and then we just run.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Non negative matrix factorization, but one thing.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The ad is a weight matrix, so in this formulation we've been very general.",
                    "label": 0
                },
                {
                    "sent": "So far we've we've accounted for the target lightfield by specifying this target matrix.",
                    "label": 0
                },
                {
                    "sent": "We've accounted for the display limitations by specifying the resolution both in time and space of each layer.",
                    "label": 0
                },
                {
                    "sent": "Well, we haven't accounted for his prior knowledge of the viewers.",
                    "label": 0
                },
                {
                    "sent": "For instance, if we only have someone standing to the right and left, there's no reason we need to reconstruct the central view with any accuracy whatsoever, right?",
                    "label": 0
                },
                {
                    "sent": "So, to make this call?",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In general, we actually allow a weight matrix.",
                    "label": 0
                },
                {
                    "sent": "Right, and so this weight matrix could be provided by an eye tracker, for instance.",
                    "label": 0
                },
                {
                    "sent": "Or you could just not define it and go ahead and try to admit the light filled correctly, but this buys you a lot of freedom to make the display brighter than conventional parallax berries, so at the end of the day we have L2 optimization over awaited factorization, so we just run weighted nonnegative matrix factorization.",
                    "label": 0
                },
                {
                    "sent": "It's pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "The benefit of the weights here is that we also need to.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or the whole matrix you out, otherwise you couldn't fit this into memory.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other benefit is we can find.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A low rank approximation, so if you for instance you can only afford to buy 120 Hertz LCD panel, we can give you a rank two decomposition of light field, but your neighbor who bought a 240 Hertz would rank 40 composition right?",
                    "label": 0
                },
                {
                    "sent": "When this decoder on the TV will do the best it can.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sense of rank.",
                    "label": 0
                },
                {
                    "sent": "So again, here's the target lightfield.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I coded up just a very simple solver here.",
                    "label": 0
                },
                {
                    "sent": "It's rather slow, but it's just a weighted update rule that takes into it.",
                    "label": 0
                },
                {
                    "sent": "This is the standard one you'll see from a Daniel in Sebastian Song from the 90s only as the weight matrix.",
                    "label": 0
                },
                {
                    "sent": "We start with random.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Toys for all the masks.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we descend.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so you can see.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bye.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A large number of iterations, so multiplicative update rule, we actually reconstruct the target light field.",
                    "label": 0
                },
                {
                    "sent": "So we found that generalization of heterodyne codes that emits more.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right and so then, in the interest of time, I'll just show you the results.",
                    "label": 0
                },
                {
                    "sent": "Here's what the front mask looks like, and so now you can see this is nothing like a heterodyne code, and it's nothing like a pinhole array, but it passes much more light, so we found a way to make displays brighter as well as to.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Populate fields using masks, and here's the real layer which also and so in the paper we actually describe this.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's clear structure.",
                    "label": 0
                },
                {
                    "sent": "You see it from the optimization result.",
                    "label": 0
                },
                {
                    "sent": "It turns out what's happening here is it's making a local.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parallax barrier I don't have.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can you explain how that works but has to do with the aperture ambiguity problem?",
                    "label": 0
                },
                {
                    "sent": "And so here's the emitted light field.",
                    "label": 0
                },
                {
                    "sent": "You notice it has some amount of noise because the NMF has converged to a local stationary point.",
                    "label": 0
                },
                {
                    "sent": "So you either have to reset it and find a better result, or you just accept the noise.",
                    "label": 0
                },
                {
                    "sent": "If it's perceptually insignificant.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so then, just to summarize, there are two benefits to this technique, right?",
                    "label": 0
                },
                {
                    "sent": "We can increase the brightness by trying to increase the target lightfield brightness or we can find a low rank decomposition increase the frame rate and so.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We actually built this.",
                    "label": 0
                },
                {
                    "sent": "It's fairly easy, just rip apart some LCD's and stack them up.",
                    "label": 0
                },
                {
                    "sent": "You can create apparel.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Superior, and then I'll just show you this result before I conclude.",
                    "label": 0
                },
                {
                    "sent": "This is just proving to you now.",
                    "label": 0
                },
                {
                    "sent": "For those of you who are interested in this game of taking computation, photography, eyes ideas into the display world, you'll have the challenge of proving to the reviewers that you built a 3D display using a 2D video in a 2D paper, and so one solution you can use is to use a non physical light field.",
                    "label": 0
                },
                {
                    "sent": "So here as you walk from left to right, up and down, you're seeing a different Roman numeral and this actually challenges the algorithm because not is compressible right?",
                    "label": 0
                },
                {
                    "sent": "Normally if you have physical natural scene right then the parallax between these views means that they're all very closely related.",
                    "label": 0
                },
                {
                    "sent": "But you can see that in both cases the timeshifted pinhole and the content adapted various successfully display the light field.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In addition, you have this new trade space, so the 3rd and final contribution of this work is to realize that because we had a heuristic for 100 years of using pinhole arrays, we didn't have a trade space we could play with.",
                    "label": 0
                },
                {
                    "sent": "If you wanted a light field ahead 5 views, you had to give up spatial resolution by a factor of five.",
                    "label": 0
                },
                {
                    "sent": "We've now broken that for both light field display, at least by having a new trade space where you can actually adjust the spatio angular resolution tradeoff.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dynamically.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hands.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that I will just conclude.",
                    "label": 0
                },
                {
                    "sent": "So the main concepts of this paper are to find generalizations of masks for light field capture and display, and so hopefully I've convinced you that because we have high speed programmable devices, we can actually do much better than a conventional parallax barrier.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}