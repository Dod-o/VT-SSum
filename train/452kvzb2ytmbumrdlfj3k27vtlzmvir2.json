{
    "id": "452kvzb2ytmbumrdlfj3k27vtlzmvir2",
    "title": "Troubleshooting and Optimizing Named Entity Resolution Systems in the Industry",
    "info": {
        "author": [
            "Panos Alexopoulos, Expert System Iberia"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_alexopoulos_resolution_systems/",
    "segmentation": [
        [
            "So good afternoon everybody.",
            "Thanks for being here.",
            "So I'm going to talk today about named Entity Resolution Systems and but I'm going to do it not from a systems point of view, but rather from the industry point of view.",
            "So the whole idea is how these are three.",
            "We can use these systems in an optimal way so as to practically satisfy the requirements of our clients."
        ],
        [
            "So.",
            "Name that is named Entity Resolution is practically the task where we detect mentions of named entities within texts when 10s can be people, organizations, locations, etc and we want to map.",
            "This mentions to the entities they refer to in an ambiguous way.",
            "So for example, if we have an article about Led Zeppelin, the music band we want to be able to know that Kashmir refers not to the region but rather to the song of Led Zeppelin and that page and plant are actually.",
            "Anne.",
            "Jimmy Page and Robert Plant the band players."
        ],
        [
            "Now, in the academia and in the industry, there have been several systems the last years developed this systems some.",
            "Some actually of them are quite known.",
            "They would be the spotlight by born I either by Max Planck and of course the Nerd platform.",
            "Now."
        ],
        [
            "Only systems to each other have different characteristics.",
            "They may differ in the background knowledge they used.",
            "Some use DB pedia, some used Jago, some others use Wikipedia.",
            "Also, to the algorithms that utilize and to the customization capabilities they provide to the end user."
        ],
        [
            "Furthermore, all these systems have been somehow evaluated right by applying them into data sets and performing experiments where you measure precision and recall."
        ],
        [
            "Now if someone goes in gathers all the evaluations that have been done and actually has a look at them.",
            "He or she may see that the systems this effectiveness may vary a lot depending on the data set where you apply it.",
            "So, for example, the the system performed at Steves and 62% effectiveness on the Reuters data set and 83% on the Ida Yagoto data sets.",
            "Similarly, the Pedia spotlight made save up to 81% on a set of 155 thousand wiki link samples.",
            "But on the other hand, it seems only 34% on the data set.",
            "Now the reason I'm showing these numbers is not to say that one system is better than the other.",
            "The reason I'm saying this number is that they illustrate in my."
        ],
        [
            "And the fact that.",
            "And our systems satisfactory performance in a given situation in a given scenario is not a guarantee that the same system will work in a different scenario where the data is different where the background knowledge is different.",
            "So what may happen and we want to avoid in practical situations natural situation with."
        ],
        [
            "Science is the following is the fact that you have a system you have applied it in 345 data sets.",
            "You have.",
            "Another adds effect is that you know that it achieves and yet when you go to a new client it still may fail, right?"
        ],
        [
            "So the question is, what can we do to avoid this or to prevent it?",
            "And how can we actually do something in order to improve things when are not when they're not very satisfactory?",
            "What we did in this work is that first we analyzed the typical way and their system works and we identified some high level potential causes of low effectiveness.",
            "2nd, we define the set of metrics which we may use in order to determine exactly what happens.",
            "In our scenario, becausw among the potential causes some.",
            "Maybe actually they actually the real reasons and some may not be.",
            "And 3rd we mapped this matrix.",
            "The values of these metrics to concrete actions that we may do in order to improve the effectiveness of the system."
        ],
        [
            "Starting with the generic, the high level picture of another system.",
            "And their systems are usually started and the application of another system usually starts with a set of input texts that we have and we want on them to apply entity resolution.",
            "We also have some target entities that we care about.",
            "We sometimes we care about all the entities that exist, and sometimes we only care for concrete entities.",
            "Like for example, we only want to do locations or we only want people or we only want actors or football players.",
            "Now we also need and usually have an entity shoulders.",
            "That is a disorders that Maps it's entity to a set of surface form of linguistic forms that it may take in a text.",
            "And also a necessary component is some evidence, some background knowledge that can be used as evidence.",
            "Now in the new system that we're using the same model web, this evidence is usually of two kinds.",
            "One is annotated texts like for example Wikipedia articles.",
            "And most importantly, knowledge graphs like DB pedia for example or freebase or something like that.",
            "Now the usual flow the user process by which name resolution happens in such systems is.",
            "As a first step, we use the energy source in order to months terms into the text that potentially match two entities, so its term is much too kind to a set of candidate entities.",
            "And then in the second step, by using.",
            "The evidential knowledge graph.",
            "And the system computes some confidence score on what which of the potential meanings is the correct one.",
            "Thus performing the disambiguation."
        ],
        [
            "Now you know this process, things may go may go wrong in two ways.",
            "Once in one case, you may have a low precision.",
            "That means that your text does not really contain the system assigned entities.",
            "The potential reason for this, the high level positions for this or two one is that you actually have high ambiguity in your domain in your text, so you have a difficult problem to solve.",
            "And the second reason is that you don't have enough evidence, so your knowledge graph or whatever evidence you use is not really.",
            "Adequate to solve your problem.",
            "In the case of Laurie call, you have the problem that the system fails to detect entities that are actually there.",
            "That can happen for two reasons.",
            "One is that you see Soros is incomplete.",
            "So for example for its entity you you don't really have all the potential server for surface forms that the entity may take in a text.",
            "Equal reason is that.",
            "Our system may be too strict.",
            "Only systems utilize some kind of threshold, right?",
            "Some confidence threshold not to decide whether some meaning is correct or not.",
            "If this threshold is too high right then the system will have greater precision, but potentially lower recall."
        ],
        [
            "So.",
            "Our task, our problem is how do we know what exactly what exactly is the problem in a particular situation?",
            "In order to do that, we calculate 2 set of metrics.",
            "The 1st of May discuss to do about ambiguity, so these metrics try to identity to measure how ambiguous is our domain, how big is our take our texts and how ambiguous is our knowledge graph.",
            "The second set of metrics have to do with the the adequacy of the evidence.",
            "In practice, is how how fit is the knowledge graph for the task of this application.",
            "For the test we have.",
            "If the fitness between the text and the Knowledge Graph is not good, then the system will probably have low effectiveness.",
            "In order to measure these metrics, we do some preparation.",
            "The preparation consists of considering a sample of the text that we have right, and this text can be for example supplied by our client.",
            "And we actually manually annotate them with entities from.",
            "We start getting this and other entities from the Knowledge Graph.",
            "So for example, we can take 102 hundred text depending on our problem size.",
            "And another thing we do is that we perform an automatic annotation of this text, but without performing an disambiguation.",
            "So we only do their matching.",
            "So we try to see what terms match to some entity from our Knowledge graph from officials in the text and how many entities."
        ],
        [
            "The first set of metrics has to do with ambiguity for the purpose of this work, we have considered four types of ambiguity.",
            "The first is what we call lexical.",
            "Ambiguity is the situation when you have an entity that has a very common name.",
            "Lexical name, for example page that we show can be a person, a name like like Larry Page or Jimmy Page and can be also the episode paper.",
            "Or it can be only for example, in another case we had a company called Collective but Collective is a very common adjective, but can not might not be an actual entity in many texts.",
            "The second thing would be good this between your target entities.",
            "So if we are actually targeting locations, for example, Tripoli can be the one in Greece that the city in Greece can be the city in Libya or elsewhere.",
            "Then we also may have knowledge graph ambiguity.",
            "That is, when you have a target entity with a non target entity being ambiguous.",
            "So for example, again with locations Barcelona in a text can refer to the city but can also refer to the team.",
            "The football team.",
            "And finally, we have global ambiguity.",
            "This is a bit different here.",
            "By global ambiguity we mean.",
            "The situation when a target entity is mixed with entities that totally out of our domain, but neither are the source, has these entities.",
            "Neither our knowledge graph.",
            "So we don't know nothing about this potential end.",
            "So for example we have audience.",
            "We have an ontology about companies, or it can be a company, but also others can be fruit."
        ],
        [
            "To measure how and what which of this ambiguity types prevails in our scenario and how, what's the extent to which they prevail?",
            "We use the already annotated texts that we have for lexical ambiguity.",
            "We measure the percentage of texts of text terms that are common terms that, for example, mixed with warning terms and have been actually wrongly mapped by the system to one or more target entities.",
            "For the target and ambiguity we measure represent of text terms that correspond to target entity and have been marked this entity by the system but also to other target entities like the triple example.",
            "For global ambiguity, we measure the percentage of terms that are not common lexical theirs, but rather actual entities in a text.",
            "But do not correspond to any of our and it is in the features.",
            "And of course have been wrongly mapped to the system by the system to one or more target.",
            "In this in our texts."
        ],
        [
            "For the knowledge from Big unity we have two sub metrics, the first metric.",
            "Measures how many terms correspond to a target entity in the text, but has actually been mapped to a non target entity.",
            "From the Knowledge Graph and the second one kids eat too.",
            "It measures the cases where we actually having in our text and non target entity and it has been wrongly mapped to a target entity by the system.",
            "Intuitively, the first summer the first metric shows how are how noisy our knowledge graph is with respect to the text to the text that we have because we may have very home again was very domain specific texts, but we may be using a very big knowledge graph that has a lot of noise.",
            "The second is the opposite we may have.",
            "An example we have very very noisy text to many domains so."
        ],
        [
            "Now moving on to everything's other question, we want to know our knowledge graph.",
            "How good is for the task that we wanted?",
            "One kind of metrics is richness.",
            "How rich is our graph?",
            "So for example, for the target is that we want to disambiguate.",
            "What do we know about them?",
            "How many other related entities we have?",
            "For example, if we want to disambiguate films, do we know all the actors of the films which can be used to actually understand what filming are we talking about?",
            "And most importantly, knowledge graph prevalence in texts.",
            "OK, we may have a very rich knowledge graph.",
            "Do the energies of the Knowledge Graph appear in our texts?",
            "'cause he might not be appearing.",
            "So there we actually measure the how many potential entities exist in the text along with the target end and most importantly which relations actually manifest in the text."
        ],
        [
            "The reason, as I said before, that we measure these metrics is to do a diagnosis and to move into some concrete action.",
            "So for example, if we see that we have high lexical ambiguity, then in that case the diagnosis is that our system does not really perform well enough.",
            "Word senses immigration, so it cannot really understand if or ants, for example, is a named entity, is a proper noun right rather than something else?",
            "Anne.",
            "So in that case, the action that we need to see somehow to improve our systems, basically linguistic processing capabilities.",
            "When we have high global ambiguity, then that means that many of most probably many of our input texts are not really related to the domain that we have.",
            "An in that case.",
            "The suggested action is to perform a pre filtering of the text to domain domain filtering and keep only the relevant text and perform on this name that resolution.",
            "Authentication is when we have a high K J1 and a low K J2.",
            "This intuitively means that the evidence knowledge Graph contains lots of noise contains contains several non target entities that hamper disambiguation process.",
            "Rather than helping it.",
            "In that case what we do what we propose to do is prove the graph.",
            "We don't need all the knowledge graph we need to keep only that part of it.",
            "That helps us most."
        ],
        [
            "Now, of course, if we have low knowledge graph business then the most I think it's obvious that we want to.",
            "Somehow we need to enrich the Knowledge graph starting from most prevalent relations.",
            "But we have high low high knowledge graph riznice but very low prevalence.",
            "So then again the promise in Knowledge Graph.",
            "It's not the correct graph that we need for the task that we have for the domain that we have.",
            "In that case we need to change our expanding on this graph with additional entities with additional relations that may happen, take place in the text.",
            "Finally, if we have low knowledge graph prevalence, no less but also known as ambiguity, so it's not a very difficult problem of low prevalence, then it may be that the system we're using a very strict threshold.",
            "So if we relax the threshold, then we may be able to achieve specially recall.",
            "We may be able to increase record."
        ],
        [
            "To show you how we actually applied these metrics, I'm going to describe two actual cases from real clients that we had.",
            "The first case was related to the football domain, so we had a set of short descriptions of video scenes where, for example, the text was saying that in this scene Messi gives a pass to Pedro and Pedro scores.",
            "In this, whereas in and we usually use the pedia as as a knowledge graph.",
            "And our own system in the second case and startups, we used news articles from News Feed and we wanted to locate startup companies, measure Starter combines.",
            "The important thing is that.",
            "In the first case, the net effect is that we achieved by using the PD as as a knowledge graph it was 60% precision, 55% recall and the second case only 35% precision and 50% recall."
        ],
        [
            "When we measured ambiguity, we realize that the additional totally different.",
            "So in the first case, the problem in football was that we had high high target ambiguity around 30% and high and very noisy graph 56%.",
            "It was KJ one in the second case we don't have such problem, but we have a very high global ambiguity and a considerable lexical ambiguity."
        ],
        [
            "Also, we realize that many of the relations of our of our ontology were present in the case of football, so we had called carries between placing their club or their Co players, but not so much about companies and business areas or other things from the knowledge driven from startups."
        ],
        [
            "Joe.",
            "Based on the values of the of the metrics, we perform the following actions.",
            "In the case of football, we proved the Knowledge Graph and kept only football related entities only.",
            "Actually, the first revelation that allows that allowed us to achieve to increase precision and recall to 82% and 80%.",
            "On the other hand.",
            "In the case of the startups we applied some heuristic rules in order to improve lexical disambiguation.",
            "We applied the classifier to filter out news articles because it proved that men of news articles were really relevant to technology, and we do so.",
            "The evidence threshold that allowed us to.",
            "Activision, about 70%, and their goal of 60%, which considering the fact that our Knowledge Graph was not really very good for the next, was a good result."
        ],
        [
            "So wrapping up.",
            "All this framework we know that it's not really formal, it's informal and rather crude.",
            "But we have found out from practical application that this can be actually very helpful in troubleshooting and optimizing near systems.",
            "And the main lesson we learned is that it's very hard to build one solution for all possible situations or possible data sets and all possible scenarios.",
            "Future agenda we want to provide some visualizations for this method.",
            "Of course, in order to make it more usable, we want to define metrics also for the case when.",
            "The evidence is in informal text, and finally we want to, if possible, to automate the deprivation of the metric value, which at the moment happens manually by some experts."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So good afternoon everybody.",
                    "label": 0
                },
                {
                    "sent": "Thanks for being here.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk today about named Entity Resolution Systems and but I'm going to do it not from a systems point of view, but rather from the industry point of view.",
                    "label": 1
                },
                {
                    "sent": "So the whole idea is how these are three.",
                    "label": 0
                },
                {
                    "sent": "We can use these systems in an optimal way so as to practically satisfy the requirements of our clients.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Name that is named Entity Resolution is practically the task where we detect mentions of named entities within texts when 10s can be people, organizations, locations, etc and we want to map.",
                    "label": 1
                },
                {
                    "sent": "This mentions to the entities they refer to in an ambiguous way.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have an article about Led Zeppelin, the music band we want to be able to know that Kashmir refers not to the region but rather to the song of Led Zeppelin and that page and plant are actually.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Jimmy Page and Robert Plant the band players.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, in the academia and in the industry, there have been several systems the last years developed this systems some.",
                    "label": 0
                },
                {
                    "sent": "Some actually of them are quite known.",
                    "label": 0
                },
                {
                    "sent": "They would be the spotlight by born I either by Max Planck and of course the Nerd platform.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only systems to each other have different characteristics.",
                    "label": 0
                },
                {
                    "sent": "They may differ in the background knowledge they used.",
                    "label": 0
                },
                {
                    "sent": "Some use DB pedia, some used Jago, some others use Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Also, to the algorithms that utilize and to the customization capabilities they provide to the end user.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Furthermore, all these systems have been somehow evaluated right by applying them into data sets and performing experiments where you measure precision and recall.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now if someone goes in gathers all the evaluations that have been done and actually has a look at them.",
                    "label": 0
                },
                {
                    "sent": "He or she may see that the systems this effectiveness may vary a lot depending on the data set where you apply it.",
                    "label": 0
                },
                {
                    "sent": "So, for example, the the system performed at Steves and 62% effectiveness on the Reuters data set and 83% on the Ida Yagoto data sets.",
                    "label": 1
                },
                {
                    "sent": "Similarly, the Pedia spotlight made save up to 81% on a set of 155 thousand wiki link samples.",
                    "label": 1
                },
                {
                    "sent": "But on the other hand, it seems only 34% on the data set.",
                    "label": 0
                },
                {
                    "sent": "Now the reason I'm showing these numbers is not to say that one system is better than the other.",
                    "label": 0
                },
                {
                    "sent": "The reason I'm saying this number is that they illustrate in my.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the fact that.",
                    "label": 0
                },
                {
                    "sent": "And our systems satisfactory performance in a given situation in a given scenario is not a guarantee that the same system will work in a different scenario where the data is different where the background knowledge is different.",
                    "label": 1
                },
                {
                    "sent": "So what may happen and we want to avoid in practical situations natural situation with.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Science is the following is the fact that you have a system you have applied it in 345 data sets.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "Another adds effect is that you know that it achieves and yet when you go to a new client it still may fail, right?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question is, what can we do to avoid this or to prevent it?",
                    "label": 0
                },
                {
                    "sent": "And how can we actually do something in order to improve things when are not when they're not very satisfactory?",
                    "label": 0
                },
                {
                    "sent": "What we did in this work is that first we analyzed the typical way and their system works and we identified some high level potential causes of low effectiveness.",
                    "label": 1
                },
                {
                    "sent": "2nd, we define the set of metrics which we may use in order to determine exactly what happens.",
                    "label": 0
                },
                {
                    "sent": "In our scenario, becausw among the potential causes some.",
                    "label": 0
                },
                {
                    "sent": "Maybe actually they actually the real reasons and some may not be.",
                    "label": 1
                },
                {
                    "sent": "And 3rd we mapped this matrix.",
                    "label": 1
                },
                {
                    "sent": "The values of these metrics to concrete actions that we may do in order to improve the effectiveness of the system.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Starting with the generic, the high level picture of another system.",
                    "label": 0
                },
                {
                    "sent": "And their systems are usually started and the application of another system usually starts with a set of input texts that we have and we want on them to apply entity resolution.",
                    "label": 0
                },
                {
                    "sent": "We also have some target entities that we care about.",
                    "label": 0
                },
                {
                    "sent": "We sometimes we care about all the entities that exist, and sometimes we only care for concrete entities.",
                    "label": 0
                },
                {
                    "sent": "Like for example, we only want to do locations or we only want people or we only want actors or football players.",
                    "label": 0
                },
                {
                    "sent": "Now we also need and usually have an entity shoulders.",
                    "label": 0
                },
                {
                    "sent": "That is a disorders that Maps it's entity to a set of surface form of linguistic forms that it may take in a text.",
                    "label": 0
                },
                {
                    "sent": "And also a necessary component is some evidence, some background knowledge that can be used as evidence.",
                    "label": 0
                },
                {
                    "sent": "Now in the new system that we're using the same model web, this evidence is usually of two kinds.",
                    "label": 0
                },
                {
                    "sent": "One is annotated texts like for example Wikipedia articles.",
                    "label": 0
                },
                {
                    "sent": "And most importantly, knowledge graphs like DB pedia for example or freebase or something like that.",
                    "label": 0
                },
                {
                    "sent": "Now the usual flow the user process by which name resolution happens in such systems is.",
                    "label": 0
                },
                {
                    "sent": "As a first step, we use the energy source in order to months terms into the text that potentially match two entities, so its term is much too kind to a set of candidate entities.",
                    "label": 0
                },
                {
                    "sent": "And then in the second step, by using.",
                    "label": 0
                },
                {
                    "sent": "The evidential knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "And the system computes some confidence score on what which of the potential meanings is the correct one.",
                    "label": 0
                },
                {
                    "sent": "Thus performing the disambiguation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now you know this process, things may go may go wrong in two ways.",
                    "label": 1
                },
                {
                    "sent": "Once in one case, you may have a low precision.",
                    "label": 0
                },
                {
                    "sent": "That means that your text does not really contain the system assigned entities.",
                    "label": 1
                },
                {
                    "sent": "The potential reason for this, the high level positions for this or two one is that you actually have high ambiguity in your domain in your text, so you have a difficult problem to solve.",
                    "label": 0
                },
                {
                    "sent": "And the second reason is that you don't have enough evidence, so your knowledge graph or whatever evidence you use is not really.",
                    "label": 0
                },
                {
                    "sent": "Adequate to solve your problem.",
                    "label": 0
                },
                {
                    "sent": "In the case of Laurie call, you have the problem that the system fails to detect entities that are actually there.",
                    "label": 1
                },
                {
                    "sent": "That can happen for two reasons.",
                    "label": 0
                },
                {
                    "sent": "One is that you see Soros is incomplete.",
                    "label": 0
                },
                {
                    "sent": "So for example for its entity you you don't really have all the potential server for surface forms that the entity may take in a text.",
                    "label": 0
                },
                {
                    "sent": "Equal reason is that.",
                    "label": 0
                },
                {
                    "sent": "Our system may be too strict.",
                    "label": 0
                },
                {
                    "sent": "Only systems utilize some kind of threshold, right?",
                    "label": 0
                },
                {
                    "sent": "Some confidence threshold not to decide whether some meaning is correct or not.",
                    "label": 0
                },
                {
                    "sent": "If this threshold is too high right then the system will have greater precision, but potentially lower recall.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Our task, our problem is how do we know what exactly what exactly is the problem in a particular situation?",
                    "label": 1
                },
                {
                    "sent": "In order to do that, we calculate 2 set of metrics.",
                    "label": 1
                },
                {
                    "sent": "The 1st of May discuss to do about ambiguity, so these metrics try to identity to measure how ambiguous is our domain, how big is our take our texts and how ambiguous is our knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "The second set of metrics have to do with the the adequacy of the evidence.",
                    "label": 0
                },
                {
                    "sent": "In practice, is how how fit is the knowledge graph for the task of this application.",
                    "label": 0
                },
                {
                    "sent": "For the test we have.",
                    "label": 0
                },
                {
                    "sent": "If the fitness between the text and the Knowledge Graph is not good, then the system will probably have low effectiveness.",
                    "label": 1
                },
                {
                    "sent": "In order to measure these metrics, we do some preparation.",
                    "label": 0
                },
                {
                    "sent": "The preparation consists of considering a sample of the text that we have right, and this text can be for example supplied by our client.",
                    "label": 0
                },
                {
                    "sent": "And we actually manually annotate them with entities from.",
                    "label": 1
                },
                {
                    "sent": "We start getting this and other entities from the Knowledge Graph.",
                    "label": 0
                },
                {
                    "sent": "So for example, we can take 102 hundred text depending on our problem size.",
                    "label": 0
                },
                {
                    "sent": "And another thing we do is that we perform an automatic annotation of this text, but without performing an disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So we only do their matching.",
                    "label": 0
                },
                {
                    "sent": "So we try to see what terms match to some entity from our Knowledge graph from officials in the text and how many entities.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first set of metrics has to do with ambiguity for the purpose of this work, we have considered four types of ambiguity.",
                    "label": 0
                },
                {
                    "sent": "The first is what we call lexical.",
                    "label": 0
                },
                {
                    "sent": "Ambiguity is the situation when you have an entity that has a very common name.",
                    "label": 0
                },
                {
                    "sent": "Lexical name, for example page that we show can be a person, a name like like Larry Page or Jimmy Page and can be also the episode paper.",
                    "label": 0
                },
                {
                    "sent": "Or it can be only for example, in another case we had a company called Collective but Collective is a very common adjective, but can not might not be an actual entity in many texts.",
                    "label": 0
                },
                {
                    "sent": "The second thing would be good this between your target entities.",
                    "label": 0
                },
                {
                    "sent": "So if we are actually targeting locations, for example, Tripoli can be the one in Greece that the city in Greece can be the city in Libya or elsewhere.",
                    "label": 1
                },
                {
                    "sent": "Then we also may have knowledge graph ambiguity.",
                    "label": 0
                },
                {
                    "sent": "That is, when you have a target entity with a non target entity being ambiguous.",
                    "label": 0
                },
                {
                    "sent": "So for example, again with locations Barcelona in a text can refer to the city but can also refer to the team.",
                    "label": 0
                },
                {
                    "sent": "The football team.",
                    "label": 0
                },
                {
                    "sent": "And finally, we have global ambiguity.",
                    "label": 0
                },
                {
                    "sent": "This is a bit different here.",
                    "label": 0
                },
                {
                    "sent": "By global ambiguity we mean.",
                    "label": 0
                },
                {
                    "sent": "The situation when a target entity is mixed with entities that totally out of our domain, but neither are the source, has these entities.",
                    "label": 0
                },
                {
                    "sent": "Neither our knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So we don't know nothing about this potential end.",
                    "label": 0
                },
                {
                    "sent": "So for example we have audience.",
                    "label": 0
                },
                {
                    "sent": "We have an ontology about companies, or it can be a company, but also others can be fruit.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To measure how and what which of this ambiguity types prevails in our scenario and how, what's the extent to which they prevail?",
                    "label": 0
                },
                {
                    "sent": "We use the already annotated texts that we have for lexical ambiguity.",
                    "label": 0
                },
                {
                    "sent": "We measure the percentage of texts of text terms that are common terms that, for example, mixed with warning terms and have been actually wrongly mapped by the system to one or more target entities.",
                    "label": 1
                },
                {
                    "sent": "For the target and ambiguity we measure represent of text terms that correspond to target entity and have been marked this entity by the system but also to other target entities like the triple example.",
                    "label": 0
                },
                {
                    "sent": "For global ambiguity, we measure the percentage of terms that are not common lexical theirs, but rather actual entities in a text.",
                    "label": 0
                },
                {
                    "sent": "But do not correspond to any of our and it is in the features.",
                    "label": 1
                },
                {
                    "sent": "And of course have been wrongly mapped to the system by the system to one or more target.",
                    "label": 0
                },
                {
                    "sent": "In this in our texts.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the knowledge from Big unity we have two sub metrics, the first metric.",
                    "label": 0
                },
                {
                    "sent": "Measures how many terms correspond to a target entity in the text, but has actually been mapped to a non target entity.",
                    "label": 1
                },
                {
                    "sent": "From the Knowledge Graph and the second one kids eat too.",
                    "label": 0
                },
                {
                    "sent": "It measures the cases where we actually having in our text and non target entity and it has been wrongly mapped to a target entity by the system.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, the first summer the first metric shows how are how noisy our knowledge graph is with respect to the text to the text that we have because we may have very home again was very domain specific texts, but we may be using a very big knowledge graph that has a lot of noise.",
                    "label": 1
                },
                {
                    "sent": "The second is the opposite we may have.",
                    "label": 0
                },
                {
                    "sent": "An example we have very very noisy text to many domains so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now moving on to everything's other question, we want to know our knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "How good is for the task that we wanted?",
                    "label": 0
                },
                {
                    "sent": "One kind of metrics is richness.",
                    "label": 0
                },
                {
                    "sent": "How rich is our graph?",
                    "label": 0
                },
                {
                    "sent": "So for example, for the target is that we want to disambiguate.",
                    "label": 0
                },
                {
                    "sent": "What do we know about them?",
                    "label": 0
                },
                {
                    "sent": "How many other related entities we have?",
                    "label": 1
                },
                {
                    "sent": "For example, if we want to disambiguate films, do we know all the actors of the films which can be used to actually understand what filming are we talking about?",
                    "label": 1
                },
                {
                    "sent": "And most importantly, knowledge graph prevalence in texts.",
                    "label": 1
                },
                {
                    "sent": "OK, we may have a very rich knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "Do the energies of the Knowledge Graph appear in our texts?",
                    "label": 0
                },
                {
                    "sent": "'cause he might not be appearing.",
                    "label": 0
                },
                {
                    "sent": "So there we actually measure the how many potential entities exist in the text along with the target end and most importantly which relations actually manifest in the text.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The reason, as I said before, that we measure these metrics is to do a diagnosis and to move into some concrete action.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we see that we have high lexical ambiguity, then in that case the diagnosis is that our system does not really perform well enough.",
                    "label": 0
                },
                {
                    "sent": "Word senses immigration, so it cannot really understand if or ants, for example, is a named entity, is a proper noun right rather than something else?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So in that case, the action that we need to see somehow to improve our systems, basically linguistic processing capabilities.",
                    "label": 0
                },
                {
                    "sent": "When we have high global ambiguity, then that means that many of most probably many of our input texts are not really related to the domain that we have.",
                    "label": 1
                },
                {
                    "sent": "An in that case.",
                    "label": 0
                },
                {
                    "sent": "The suggested action is to perform a pre filtering of the text to domain domain filtering and keep only the relevant text and perform on this name that resolution.",
                    "label": 0
                },
                {
                    "sent": "Authentication is when we have a high K J1 and a low K J2.",
                    "label": 1
                },
                {
                    "sent": "This intuitively means that the evidence knowledge Graph contains lots of noise contains contains several non target entities that hamper disambiguation process.",
                    "label": 0
                },
                {
                    "sent": "Rather than helping it.",
                    "label": 0
                },
                {
                    "sent": "In that case what we do what we propose to do is prove the graph.",
                    "label": 0
                },
                {
                    "sent": "We don't need all the knowledge graph we need to keep only that part of it.",
                    "label": 0
                },
                {
                    "sent": "That helps us most.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, of course, if we have low knowledge graph business then the most I think it's obvious that we want to.",
                    "label": 0
                },
                {
                    "sent": "Somehow we need to enrich the Knowledge graph starting from most prevalent relations.",
                    "label": 1
                },
                {
                    "sent": "But we have high low high knowledge graph riznice but very low prevalence.",
                    "label": 0
                },
                {
                    "sent": "So then again the promise in Knowledge Graph.",
                    "label": 0
                },
                {
                    "sent": "It's not the correct graph that we need for the task that we have for the domain that we have.",
                    "label": 0
                },
                {
                    "sent": "In that case we need to change our expanding on this graph with additional entities with additional relations that may happen, take place in the text.",
                    "label": 0
                },
                {
                    "sent": "Finally, if we have low knowledge graph prevalence, no less but also known as ambiguity, so it's not a very difficult problem of low prevalence, then it may be that the system we're using a very strict threshold.",
                    "label": 0
                },
                {
                    "sent": "So if we relax the threshold, then we may be able to achieve specially recall.",
                    "label": 0
                },
                {
                    "sent": "We may be able to increase record.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To show you how we actually applied these metrics, I'm going to describe two actual cases from real clients that we had.",
                    "label": 0
                },
                {
                    "sent": "The first case was related to the football domain, so we had a set of short descriptions of video scenes where, for example, the text was saying that in this scene Messi gives a pass to Pedro and Pedro scores.",
                    "label": 1
                },
                {
                    "sent": "In this, whereas in and we usually use the pedia as as a knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "And our own system in the second case and startups, we used news articles from News Feed and we wanted to locate startup companies, measure Starter combines.",
                    "label": 1
                },
                {
                    "sent": "The important thing is that.",
                    "label": 0
                },
                {
                    "sent": "In the first case, the net effect is that we achieved by using the PD as as a knowledge graph it was 60% precision, 55% recall and the second case only 35% precision and 50% recall.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When we measured ambiguity, we realize that the additional totally different.",
                    "label": 0
                },
                {
                    "sent": "So in the first case, the problem in football was that we had high high target ambiguity around 30% and high and very noisy graph 56%.",
                    "label": 0
                },
                {
                    "sent": "It was KJ one in the second case we don't have such problem, but we have a very high global ambiguity and a considerable lexical ambiguity.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, we realize that many of the relations of our of our ontology were present in the case of football, so we had called carries between placing their club or their Co players, but not so much about companies and business areas or other things from the knowledge driven from startups.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Joe.",
                    "label": 0
                },
                {
                    "sent": "Based on the values of the of the metrics, we perform the following actions.",
                    "label": 0
                },
                {
                    "sent": "In the case of football, we proved the Knowledge Graph and kept only football related entities only.",
                    "label": 1
                },
                {
                    "sent": "Actually, the first revelation that allows that allowed us to achieve to increase precision and recall to 82% and 80%.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "In the case of the startups we applied some heuristic rules in order to improve lexical disambiguation.",
                    "label": 1
                },
                {
                    "sent": "We applied the classifier to filter out news articles because it proved that men of news articles were really relevant to technology, and we do so.",
                    "label": 0
                },
                {
                    "sent": "The evidence threshold that allowed us to.",
                    "label": 0
                },
                {
                    "sent": "Activision, about 70%, and their goal of 60%, which considering the fact that our Knowledge Graph was not really very good for the next, was a good result.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So wrapping up.",
                    "label": 0
                },
                {
                    "sent": "All this framework we know that it's not really formal, it's informal and rather crude.",
                    "label": 0
                },
                {
                    "sent": "But we have found out from practical application that this can be actually very helpful in troubleshooting and optimizing near systems.",
                    "label": 0
                },
                {
                    "sent": "And the main lesson we learned is that it's very hard to build one solution for all possible situations or possible data sets and all possible scenarios.",
                    "label": 1
                },
                {
                    "sent": "Future agenda we want to provide some visualizations for this method.",
                    "label": 0
                },
                {
                    "sent": "Of course, in order to make it more usable, we want to define metrics also for the case when.",
                    "label": 0
                },
                {
                    "sent": "The evidence is in informal text, and finally we want to, if possible, to automate the deprivation of the metric value, which at the moment happens manually by some experts.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}