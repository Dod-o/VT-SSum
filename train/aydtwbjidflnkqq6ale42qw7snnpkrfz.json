{
    "id": "aydtwbjidflnkqq6ale42qw7snnpkrfz",
    "title": "A Probabilistic Approach for Integrating Heterogeneous Knowledge Sources",
    "info": {
        "author": [
            "Arnab Dutta, Research Group Data and Web Science, School of Business Informatics and Mathematics, University of Mannheim"
        ],
        "published": "July 30, 2014",
        "recorded": "May 2014",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2014_dutta_knowledge_sources/",
    "segmentation": [
        [
            "So yeah, this is a joint work with Christian Melikian Simona Ponsetto from the same University.",
            "So let's start off with a simple motivation like often in the."
        ],
        [
            "Yeah, we have like different kinds of facts lying around, so this is a sample fact.",
            "Like say, Brandon Routh was an actor in Superman.",
            "So what's wrong?",
            "Or what's so special about it?",
            "It's the problem with.",
            "The entities it's being referred to in this sentence.",
            "So like the Superman can be the our well known character, we know from a childhood.",
            "Maybe the film there's so many films we have already released, or it may be the comic book the We have from Marvel Marvel Comics.",
            "So the problem is like we're really lost at some point of time, like when you're working with these kind of people, we're really lost and for the time being we see like even this kind of ambiguity can also happen, like in the first case.",
            "Like if it's not Brandon Routh, it's like.",
            "Any Brandon or not?",
            "So even then we're kind of lossed.",
            "So."
        ],
        [
            "So that's that's the kind of broad outline or the broad problem in the web.",
            "Like it's uncertain like we really have under specified terms like, we really don't know which Superman are we talking about.",
            "And the bigger problem is like there is no exact semantics like we do not have a specific UI like you like Superman is some kind of a book or a film.",
            "So.",
            "For the moment, I just."
        ],
        [
            "Step back a bit and talk about the different knowledge sources we have like.",
            "The first one is more, which is I'd like to talk is the open one.",
            "So like as you know, like it's a nail or the River of datas datasets like they have, they call this open 'cause they're not kind of restricted to just few resources of the web, but they're more like like crawling across all the pages of in the web.",
            "The good thing about is like it's first of all, it's.",
            "Working on a large set of data.",
            "Secondly is like domain independent and it really like scales to a web web corpus.",
            "But the bigger problem is with this things that they're necessarily do not have a schema of their own, so.",
            "On the counterpart, let's see like what's the?",
            "What's the closed?"
        ],
        [
            "Once like DB pedia Jago this kind of things like they have a well defined schema and as you see like there every instances are like you are ified.",
            "But the problem is they're just restricted to Wikipedia or specific resources.",
            "Now you see like these two scenarios can easily plug in together like they have the best of both the words like it would be really nice if you can bring this to broad knowledge sources together.",
            "This can be illustrated by strike two friends talking like Nell.",
            "Andie.",
            "Because these are the two datasets I tried working on.",
            "Like Nail is kind of happy like he is like scrolling over all the way but he's bit sad because he had doesn't have a proper semantics.",
            "On the other hand, the Pedia says there well they have a proper ontology, but it's just restricted to Wikipedia.",
            "So here I proposed like."
        ],
        [
            "Broad approaches, like one is the baseline and then there is a probabilistic on the baseline.",
            "I will just go through it quickly because that's the very naive and the kind of adult approach, but still.",
            "Nevertheless, it's a very strong approach, as you will see and the 2nd is a probability one which is a more intelligent way of reasoning on this kind of datasets."
        ],
        [
            "The first is this baseline.",
            "What we do here is like we just look into the intra Wikipedia links.",
            "We just crawl Wikipedia using.",
            "We keep Reddit.",
            "We keep data data tool which is developed by Gavrilovich and what we're looking is like we're looking for any kind of anchor tags as we see here, like Superman here or Superman here.",
            "But the problem is like the same anchor can refer to different web pages actually like the same word like Superman is here, the character and here is a comic book.",
            "It's actually referring to just also of the similarity here.",
            "Like the nail terms or in any web extracted track, the terms are just like this.",
            "We just have a term like Superman, that's it and weak.",
            "Analogously, say that these are the counterparts of these analogous terms to the nail nail instances."
        ],
        [
            "So what we do is like we just crawl those data and collect some statistics over here.",
            "Look at how many times did Superman refer to Superman, the page Superman, the page title, Superman the film or the comic book and these are like the counts and if we have this kind of a frequency distribution you can usually define a kind of a probabilistic top K values level.",
            "So we said well it refers to Superman.",
            "The character with like 78% probability or something like that."
        ],
        [
            "But that's the problem.",
            "Here is like we're just talking or looking into the instances on a very like a.",
            "Just we're looking into the instance and not considering the context of it.",
            "We're not seeing like what's preceding or succeeding these entities.",
            "So."
        ],
        [
            "We talk about is the more advanced user problem, which is actually the main contribution where the broad idea is like we said, define a set of matching hypothesis why I called those hypothesis.",
            "I'll come to that shortly.",
            "The second is like we are exploiting the best or the good thing of DPD.",
            "As I said, like we are exploring the good thing of a structured knowledge base.",
            "And finally, we reason in such a way that we're kind of penalizing the wrong wrong hypothesis we had in our first step."
        ],
        [
            "So that's the kind of a broader picture like we have a triple.",
            "What we do is like we have different same as links here, so that's why I call those hypothesis because we're not sure what it really links to.",
            "It can be either of this tree and the next step is we just ask the sparkle in Twilight, give me its types so instantly we have like, OK, these are the types of these instances now by some intelligent way.",
            "If you come to know like the range of values actors star in movie.",
            "Takes is a kind of just films, then immediately these two or even more which are not compatible in this sense, are just eliminated out.",
            "It's a very simple approach, but the bigger question is if we knew like it's not possible for us to know like, well, this is a nail predicate and we have no clue like what should be its range or its domain.",
            "That"
        ],
        [
            "Point is, like OK, I just talk about more of this method now.",
            "So the problem as I said like we have to find a kind of a way to quantify or kind of attach some confidence is to every probable range values and similarly the domain values.",
            "I just give you some values of the range is just there is a counterpart of domains as well and the second task is bring or plug all this formulation together in a Markov network and try to solve it as an inference problem.",
            "And particularly, we're talking of the map inference here, where it's kind of talking of the the most likely state of the world.",
            "We're not talking of marginals like where we're trying to find like the probability of a particular node."
        ],
        [
            "So how do you do that?",
            "Like how do you generate this?",
            "The I'm talking about my first task where it's talking about attaching confidence to the probable domain or the range value.",
            "So the first type is.",
            "If you're talking of actor starred in movie, just came through all the nail triples.",
            "We have something like this and one of them is something the one we had in our example get the top one reference.",
            "Why top one?",
            "Because at this point of time we that's the only best information we have at our high hand.",
            "We'd really have no other clue.",
            "Just take the top one we trust.",
            "The most frequent sense we assume.",
            "OK, let that might be the best case that might be the best matching possible.",
            "Let's see go ahead, get the direct types and that's what we have like.",
            "We get like if the person is a fictional cat."
        ],
        [
            "After and what we do is next is like once we get this type we create a tree where we instantiate like we've put the creative tree like this, a hierarchy of classes and I put all the values where I call this like direct type counts because if you ask the type of instance from DVD sparkle endpoint, you actually get it materialized like if it's if it's actor.",
            "It's a person, it's a agent.",
            "It's a thing.",
            "So you go up the hierarchy all along.",
            "What we do is we mostly interested in the bottom most nodes so.",
            "If something is like just specific, it's a comic book or it's a play, we just add that value.",
            "We're not interested like we go up an add a value to its thing node or something like agent node.",
            "This is the kind of market, but.",
            "We want to the task at hand is we want to attach a kind of confidence to.",
            "The range from here we can easily say, well just you have 20 values here.",
            "Just do a problem Calculator, probability out of it and say like well, play is the range of active studies movie with probability .3.",
            "What's wrong in it?",
            "Like that, that's what I say.",
            "You leave the selection selection preference should be like.",
            "Sorry, that's a typo, it's like it should be now.",
            "Sorry, it's film like I go to the leaf node which is having the highest frequency, so it's.",
            "It's like 40 and then it's a book.",
            "Just go decreasing order of the values we have, so it's like play or cartoon.",
            "Equally probable and so on.",
            "But the problem is like.",
            "Here we have a high evidence for.",
            "Written work as well, but in this tree we are completely ignoring this subtree or the sub graph here because we're just looking into the leaf node and we see the highest magnitude of the value, and that's what we're considering, which is kind of wrong."
        ],
        [
            "Then, So what we do is like we propose a kind of scaling or.",
            "As I say, it's like a normalizing approach.",
            "What we do is like we define two scores.",
            "It's called up score on the down score.",
            "The UP score is starting from the leaf nodes and we go up the tree.",
            "Calculating this, I'll show it shortly in the next slide.",
            "Another is that down score, which like renormalizes all the values of the direct type."
        ],
        [
            "It's something we this is the same graph we had.",
            "This is the up score, so it starts from here.",
            "As you know, like the bottommost leave nodes, they will have the same up score.",
            "From this point, we just a moment like I go back here we have a parameter called Alpha and for the further we have experiments for like how we choose the Alpha for the timing.",
            "This example is concentrating with Alpha equals 2.5.",
            "So we start off with the ground like the leaf nodes and we go up the ladder like OK.",
            "So that's the up score because of this child nodes.",
            "Similarly we we collaborate all this together and go to the App Store here.",
            "Once you are the top of the note, we calculate the down scored then like from here the top node should have the same down score and we just propagate the values down back again to the leaf nodes.",
            "Now you see the beauty of this thing like now just because 80 was the highest.",
            "We did not in the full graph you had.",
            "Now we have a kind of a down score which is well reflected here with this high value.",
            "That's what we wanted to model.",
            "Or that's how we wanted to do it.",
            "And now you see, like it's more probable like this book is a better choice than a play than a comics.",
            "And so on.",
            "One important thing is like we here, we do not want to restrict on any 1 two or any top K preferences.",
            "We just want to put.",
            "Everything in even among can be a range of actor study movie or racing car.",
            "We're not restricting ourselves, but providing a wide range of probabilities.",
            "What we can find.",
            "The."
        ],
        [
            "Second, most important thing is that well, now we have the confidence is attached how to plug all this together.",
            "The first thing is like some of the.",
            "Like here I just want to give a more intuitive.",
            "Presentation and don't want to put in the Markov logic marginal formulas which a lot of people have seen lot many times.",
            "Just the broad idea is like you have a certain set of rules.",
            "I don't even see the 1st just set of rules and a set of evidence is what are the rules doing.",
            "The rules are basically.",
            "So this one is particularly just a transitive, same as like if A is BBC that so it's obviously is.",
            "As you can see.",
            "And this one is putting a cardinality constraint constraint on same as.",
            "That means like if.",
            "There is a mapping we should allow at most one mapping like Superman should be matched to.",
            "Either none or at least at most one not more than more than one.",
            "And that's the more important.",
            "The second rule, which says like.",
            "If you have a nail triple like a subject property object.",
            "And the object is mapped to the pedia instance with the confidence value this.",
            "And the DVD instance has got a particular class then.",
            "You say like the object is of type this with what confidence?",
            "With this W and note that this W is coming from the Alpha tree I just showed you like that's how we model this.",
            "This entire problem with this just one line like where we kind of.",
            "We see it shortly like how this single rule comes into play and plays a severe role in our solving solution.",
            "And the second instances like this in the market logic, this is the model and this is like the evidence here.",
            "We have two kinds of evidence is 1 is a soft truth.",
            "As you say, like here, we are not sure actually though, so this is the best way we can model our world like well, these are the probabilities or the confidence is we got from our Wikipedia top candidates like OK, just put in every every evidence we gathered from our world like so we keep it in our case and the 2nd is hard truths WHI hard because these are the ones extracted from DB pedia ontology.",
            "We know for sure like Superman is our comics character from DVD.",
            "If that is wrong then we're really out of.",
            "Out of scope.",
            "Now what we do is put this together like and solve it as a problem so the network looks like this and keep in mind like all."
        ],
        [
            "This predicates what I showed you like it's type an L triples.",
            "These are essentially a binary variable, so.",
            "Superman Brandon wrote actor starred in movie Superman.",
            "Is it true or false?",
            "So this note can have a true or false value.",
            "That's it.",
            "And that's how we instantiate or you ground start grounding your network like you put in, or fill in all the values.",
            "This variables can take like plug in all the values.",
            "So one kind of instantiation can be like this like.",
            "Just just like we have this film of type this, then that's what I marked like.",
            "The observed ones are like the bold ones and same as these are like the query ones like which eventually turns out to be true.",
            "Now see like here we have two different kinds of weight which are playing one from this approach where we assign like well if blah blah blah something like this.",
            "Then the Superman is a film with this amount of confidence again.",
            "On this level we also have a confidence with Superman's as well.",
            "That's actually the key part.",
            "Like here we allow these two weights to play each other and only that world where this combination is like a.",
            "It works like a positive feedback like the good type match with a good instantiation is yes, that's the winner.",
            "So and anything which is a bad type information but a good same as link won't succeed eventually, so it's like.",
            "Goes out of the equation, so that's why I say like we solve this and find out like what's the best world with the highest probability of of holding true."
        ],
        [
            "Now we take a break and say like OK, can we still do it better?",
            "Like is it the end of the story?",
            "Probably know becausw."
        ],
        [
            "Before you go through that directly, go to the because of the time I go to the, this next time we just like the bootstrapping, what we do is."
        ],
        [
            "We start off with all the hypothesis we have at our hand.",
            "Like all put everything in our system.",
            "Take the type the top one weights.",
            "And from that we create a Alpha tree with this kind of weights, the bold ones are the ones which are the ones which the values we observed in this first iteration.",
            "2nd is from this we let mark of logic do all the reasoning and find out the best world.",
            "What we get is no suitable mapping.",
            "Why Becausw the best one was one point 9 and the fictional character is minus 3.9.",
            "If it's like it's outside the scope of this presentation because it's just a kind of math or addition going on there which says like if these two are added, it's less than zero and anything less than zero is like it's a log linear model, so it's like less than probability half.",
            "So we just do not take any consideration, so that's only happening for this Superman mapping stuff.",
            "And keep in mind that there are also several other such mappings in the in our system.",
            "Let's feed it again.",
            "Now what we have is the same instantiation's like the same value.",
            "But now I mark the different one with a bold now not the top one, but it's the refined, which is what we get so far.",
            "Like from this loop with refined weights.",
            "Now what happens?",
            "Film gets a higher weight.",
            "It kinds of the other instances pushes film to be more likely.",
            "Now it's like a like a match made in heaven like film film like Wow, that's a great thing.",
            "Those two are working great tandem together and we have Superman.",
            "The film selected finally and go on with like several iterations till it terminates."
        ],
        [
            "And that's the whole story of it, and we just shortly go through our experiment so we have a gold standard manually created and we take like 100 triples from like 12 most frequently chosen nail properties and."
        ],
        [
            "This is the learning Alpha part where we just divide.",
            "We define our model, we model the problem in such ways, like from zero to 1 and we divide it into eight steps and we take like all the like .125 gap.",
            "The values and we divide into its like a two fold cross validation.",
            "If we train it on one side and we tested on other and we iterate or do the sampling for a lot many number of large number of samples and what we find is like this kind of output and this."
        ],
        [
            "Is more reflective something like this?",
            "Like you go on plotting Alpha with the respective fan scores, so that's like the good case we have, and finally."
        ],
        [
            "We have like the output.",
            "Like we we choose the 12 predicates and we start plotting.",
            "So this is like the baseline and we see like for some predicate we really couldn't do any better because this is a notorious property because sometimes it's the agent which can be organization or it can be a person and it's really hard to work with this way and for some others we really have a lot of.",
            "Improvement over baseline.",
            "On average we got like it's not.",
            "Also, it's a high value but but given that we have a most frequent baseline, which is really hard to beat, I think it's a pretty nice value of, like almost a four person gaining F1."
        ],
        [
            "And So what is the biggest limitation is like we cannot differentiate between types.",
            "Same type of person.",
            "We don't know like if it's like the Mel Gibson is the actor or the author William Gibson.",
            "So this type of thing and the other thing is if the DVD type information is missing, we're kind of lossed so we're working on that like incorporating data from other sources like Jago because they have Lago di darlings."
        ],
        [
            "And so, right now I'm kind of working on like bringing the properties together.",
            "We recently submitted something and then looking for more scope of knowledge generation and finally reverve, which is a wider data set like kind of 15,000,000 facts, much bigger than L. That would be an interesting test case for us."
        ],
        [
            "So with that, I'd like to thank you all for your kind attention.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So yeah, this is a joint work with Christian Melikian Simona Ponsetto from the same University.",
                    "label": 0
                },
                {
                    "sent": "So let's start off with a simple motivation like often in the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, we have like different kinds of facts lying around, so this is a sample fact.",
                    "label": 0
                },
                {
                    "sent": "Like say, Brandon Routh was an actor in Superman.",
                    "label": 1
                },
                {
                    "sent": "So what's wrong?",
                    "label": 0
                },
                {
                    "sent": "Or what's so special about it?",
                    "label": 0
                },
                {
                    "sent": "It's the problem with.",
                    "label": 0
                },
                {
                    "sent": "The entities it's being referred to in this sentence.",
                    "label": 0
                },
                {
                    "sent": "So like the Superman can be the our well known character, we know from a childhood.",
                    "label": 0
                },
                {
                    "sent": "Maybe the film there's so many films we have already released, or it may be the comic book the We have from Marvel Marvel Comics.",
                    "label": 0
                },
                {
                    "sent": "So the problem is like we're really lost at some point of time, like when you're working with these kind of people, we're really lost and for the time being we see like even this kind of ambiguity can also happen, like in the first case.",
                    "label": 0
                },
                {
                    "sent": "Like if it's not Brandon Routh, it's like.",
                    "label": 0
                },
                {
                    "sent": "Any Brandon or not?",
                    "label": 0
                },
                {
                    "sent": "So even then we're kind of lossed.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's that's the kind of broad outline or the broad problem in the web.",
                    "label": 1
                },
                {
                    "sent": "Like it's uncertain like we really have under specified terms like, we really don't know which Superman are we talking about.",
                    "label": 0
                },
                {
                    "sent": "And the bigger problem is like there is no exact semantics like we do not have a specific UI like you like Superman is some kind of a book or a film.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "For the moment, I just.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Step back a bit and talk about the different knowledge sources we have like.",
                    "label": 0
                },
                {
                    "sent": "The first one is more, which is I'd like to talk is the open one.",
                    "label": 0
                },
                {
                    "sent": "So like as you know, like it's a nail or the River of datas datasets like they have, they call this open 'cause they're not kind of restricted to just few resources of the web, but they're more like like crawling across all the pages of in the web.",
                    "label": 0
                },
                {
                    "sent": "The good thing about is like it's first of all, it's.",
                    "label": 0
                },
                {
                    "sent": "Working on a large set of data.",
                    "label": 0
                },
                {
                    "sent": "Secondly is like domain independent and it really like scales to a web web corpus.",
                    "label": 1
                },
                {
                    "sent": "But the bigger problem is with this things that they're necessarily do not have a schema of their own, so.",
                    "label": 1
                },
                {
                    "sent": "On the counterpart, let's see like what's the?",
                    "label": 0
                },
                {
                    "sent": "What's the closed?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once like DB pedia Jago this kind of things like they have a well defined schema and as you see like there every instances are like you are ified.",
                    "label": 0
                },
                {
                    "sent": "But the problem is they're just restricted to Wikipedia or specific resources.",
                    "label": 0
                },
                {
                    "sent": "Now you see like these two scenarios can easily plug in together like they have the best of both the words like it would be really nice if you can bring this to broad knowledge sources together.",
                    "label": 0
                },
                {
                    "sent": "This can be illustrated by strike two friends talking like Nell.",
                    "label": 0
                },
                {
                    "sent": "Andie.",
                    "label": 0
                },
                {
                    "sent": "Because these are the two datasets I tried working on.",
                    "label": 0
                },
                {
                    "sent": "Like Nail is kind of happy like he is like scrolling over all the way but he's bit sad because he had doesn't have a proper semantics.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, the Pedia says there well they have a proper ontology, but it's just restricted to Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "So here I proposed like.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Broad approaches, like one is the baseline and then there is a probabilistic on the baseline.",
                    "label": 0
                },
                {
                    "sent": "I will just go through it quickly because that's the very naive and the kind of adult approach, but still.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, it's a very strong approach, as you will see and the 2nd is a probability one which is a more intelligent way of reasoning on this kind of datasets.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first is this baseline.",
                    "label": 0
                },
                {
                    "sent": "What we do here is like we just look into the intra Wikipedia links.",
                    "label": 0
                },
                {
                    "sent": "We just crawl Wikipedia using.",
                    "label": 0
                },
                {
                    "sent": "We keep Reddit.",
                    "label": 0
                },
                {
                    "sent": "We keep data data tool which is developed by Gavrilovich and what we're looking is like we're looking for any kind of anchor tags as we see here, like Superman here or Superman here.",
                    "label": 0
                },
                {
                    "sent": "But the problem is like the same anchor can refer to different web pages actually like the same word like Superman is here, the character and here is a comic book.",
                    "label": 0
                },
                {
                    "sent": "It's actually referring to just also of the similarity here.",
                    "label": 0
                },
                {
                    "sent": "Like the nail terms or in any web extracted track, the terms are just like this.",
                    "label": 0
                },
                {
                    "sent": "We just have a term like Superman, that's it and weak.",
                    "label": 0
                },
                {
                    "sent": "Analogously, say that these are the counterparts of these analogous terms to the nail nail instances.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do is like we just crawl those data and collect some statistics over here.",
                    "label": 0
                },
                {
                    "sent": "Look at how many times did Superman refer to Superman, the page Superman, the page title, Superman the film or the comic book and these are like the counts and if we have this kind of a frequency distribution you can usually define a kind of a probabilistic top K values level.",
                    "label": 0
                },
                {
                    "sent": "So we said well it refers to Superman.",
                    "label": 0
                },
                {
                    "sent": "The character with like 78% probability or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But that's the problem.",
                    "label": 0
                },
                {
                    "sent": "Here is like we're just talking or looking into the instances on a very like a.",
                    "label": 0
                },
                {
                    "sent": "Just we're looking into the instance and not considering the context of it.",
                    "label": 1
                },
                {
                    "sent": "We're not seeing like what's preceding or succeeding these entities.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We talk about is the more advanced user problem, which is actually the main contribution where the broad idea is like we said, define a set of matching hypothesis why I called those hypothesis.",
                    "label": 1
                },
                {
                    "sent": "I'll come to that shortly.",
                    "label": 0
                },
                {
                    "sent": "The second is like we are exploiting the best or the good thing of DPD.",
                    "label": 0
                },
                {
                    "sent": "As I said, like we are exploring the good thing of a structured knowledge base.",
                    "label": 0
                },
                {
                    "sent": "And finally, we reason in such a way that we're kind of penalizing the wrong wrong hypothesis we had in our first step.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the kind of a broader picture like we have a triple.",
                    "label": 0
                },
                {
                    "sent": "What we do is like we have different same as links here, so that's why I call those hypothesis because we're not sure what it really links to.",
                    "label": 0
                },
                {
                    "sent": "It can be either of this tree and the next step is we just ask the sparkle in Twilight, give me its types so instantly we have like, OK, these are the types of these instances now by some intelligent way.",
                    "label": 0
                },
                {
                    "sent": "If you come to know like the range of values actors star in movie.",
                    "label": 0
                },
                {
                    "sent": "Takes is a kind of just films, then immediately these two or even more which are not compatible in this sense, are just eliminated out.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple approach, but the bigger question is if we knew like it's not possible for us to know like, well, this is a nail predicate and we have no clue like what should be its range or its domain.",
                    "label": 0
                },
                {
                    "sent": "That",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Point is, like OK, I just talk about more of this method now.",
                    "label": 0
                },
                {
                    "sent": "So the problem as I said like we have to find a kind of a way to quantify or kind of attach some confidence is to every probable range values and similarly the domain values.",
                    "label": 0
                },
                {
                    "sent": "I just give you some values of the range is just there is a counterpart of domains as well and the second task is bring or plug all this formulation together in a Markov network and try to solve it as an inference problem.",
                    "label": 1
                },
                {
                    "sent": "And particularly, we're talking of the map inference here, where it's kind of talking of the the most likely state of the world.",
                    "label": 0
                },
                {
                    "sent": "We're not talking of marginals like where we're trying to find like the probability of a particular node.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do you do that?",
                    "label": 0
                },
                {
                    "sent": "Like how do you generate this?",
                    "label": 0
                },
                {
                    "sent": "The I'm talking about my first task where it's talking about attaching confidence to the probable domain or the range value.",
                    "label": 0
                },
                {
                    "sent": "So the first type is.",
                    "label": 0
                },
                {
                    "sent": "If you're talking of actor starred in movie, just came through all the nail triples.",
                    "label": 1
                },
                {
                    "sent": "We have something like this and one of them is something the one we had in our example get the top one reference.",
                    "label": 0
                },
                {
                    "sent": "Why top one?",
                    "label": 0
                },
                {
                    "sent": "Because at this point of time we that's the only best information we have at our high hand.",
                    "label": 0
                },
                {
                    "sent": "We'd really have no other clue.",
                    "label": 0
                },
                {
                    "sent": "Just take the top one we trust.",
                    "label": 0
                },
                {
                    "sent": "The most frequent sense we assume.",
                    "label": 0
                },
                {
                    "sent": "OK, let that might be the best case that might be the best matching possible.",
                    "label": 0
                },
                {
                    "sent": "Let's see go ahead, get the direct types and that's what we have like.",
                    "label": 1
                },
                {
                    "sent": "We get like if the person is a fictional cat.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After and what we do is next is like once we get this type we create a tree where we instantiate like we've put the creative tree like this, a hierarchy of classes and I put all the values where I call this like direct type counts because if you ask the type of instance from DVD sparkle endpoint, you actually get it materialized like if it's if it's actor.",
                    "label": 1
                },
                {
                    "sent": "It's a person, it's a agent.",
                    "label": 0
                },
                {
                    "sent": "It's a thing.",
                    "label": 0
                },
                {
                    "sent": "So you go up the hierarchy all along.",
                    "label": 0
                },
                {
                    "sent": "What we do is we mostly interested in the bottom most nodes so.",
                    "label": 0
                },
                {
                    "sent": "If something is like just specific, it's a comic book or it's a play, we just add that value.",
                    "label": 0
                },
                {
                    "sent": "We're not interested like we go up an add a value to its thing node or something like agent node.",
                    "label": 0
                },
                {
                    "sent": "This is the kind of market, but.",
                    "label": 0
                },
                {
                    "sent": "We want to the task at hand is we want to attach a kind of confidence to.",
                    "label": 0
                },
                {
                    "sent": "The range from here we can easily say, well just you have 20 values here.",
                    "label": 0
                },
                {
                    "sent": "Just do a problem Calculator, probability out of it and say like well, play is the range of active studies movie with probability .3.",
                    "label": 0
                },
                {
                    "sent": "What's wrong in it?",
                    "label": 0
                },
                {
                    "sent": "Like that, that's what I say.",
                    "label": 0
                },
                {
                    "sent": "You leave the selection selection preference should be like.",
                    "label": 1
                },
                {
                    "sent": "Sorry, that's a typo, it's like it should be now.",
                    "label": 0
                },
                {
                    "sent": "Sorry, it's film like I go to the leaf node which is having the highest frequency, so it's.",
                    "label": 0
                },
                {
                    "sent": "It's like 40 and then it's a book.",
                    "label": 0
                },
                {
                    "sent": "Just go decreasing order of the values we have, so it's like play or cartoon.",
                    "label": 0
                },
                {
                    "sent": "Equally probable and so on.",
                    "label": 0
                },
                {
                    "sent": "But the problem is like.",
                    "label": 0
                },
                {
                    "sent": "Here we have a high evidence for.",
                    "label": 0
                },
                {
                    "sent": "Written work as well, but in this tree we are completely ignoring this subtree or the sub graph here because we're just looking into the leaf node and we see the highest magnitude of the value, and that's what we're considering, which is kind of wrong.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then, So what we do is like we propose a kind of scaling or.",
                    "label": 0
                },
                {
                    "sent": "As I say, it's like a normalizing approach.",
                    "label": 0
                },
                {
                    "sent": "What we do is like we define two scores.",
                    "label": 0
                },
                {
                    "sent": "It's called up score on the down score.",
                    "label": 0
                },
                {
                    "sent": "The UP score is starting from the leaf nodes and we go up the tree.",
                    "label": 0
                },
                {
                    "sent": "Calculating this, I'll show it shortly in the next slide.",
                    "label": 0
                },
                {
                    "sent": "Another is that down score, which like renormalizes all the values of the direct type.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's something we this is the same graph we had.",
                    "label": 0
                },
                {
                    "sent": "This is the up score, so it starts from here.",
                    "label": 0
                },
                {
                    "sent": "As you know, like the bottommost leave nodes, they will have the same up score.",
                    "label": 0
                },
                {
                    "sent": "From this point, we just a moment like I go back here we have a parameter called Alpha and for the further we have experiments for like how we choose the Alpha for the timing.",
                    "label": 0
                },
                {
                    "sent": "This example is concentrating with Alpha equals 2.5.",
                    "label": 0
                },
                {
                    "sent": "So we start off with the ground like the leaf nodes and we go up the ladder like OK.",
                    "label": 0
                },
                {
                    "sent": "So that's the up score because of this child nodes.",
                    "label": 0
                },
                {
                    "sent": "Similarly we we collaborate all this together and go to the App Store here.",
                    "label": 0
                },
                {
                    "sent": "Once you are the top of the note, we calculate the down scored then like from here the top node should have the same down score and we just propagate the values down back again to the leaf nodes.",
                    "label": 0
                },
                {
                    "sent": "Now you see the beauty of this thing like now just because 80 was the highest.",
                    "label": 0
                },
                {
                    "sent": "We did not in the full graph you had.",
                    "label": 0
                },
                {
                    "sent": "Now we have a kind of a down score which is well reflected here with this high value.",
                    "label": 0
                },
                {
                    "sent": "That's what we wanted to model.",
                    "label": 0
                },
                {
                    "sent": "Or that's how we wanted to do it.",
                    "label": 0
                },
                {
                    "sent": "And now you see, like it's more probable like this book is a better choice than a play than a comics.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "One important thing is like we here, we do not want to restrict on any 1 two or any top K preferences.",
                    "label": 0
                },
                {
                    "sent": "We just want to put.",
                    "label": 0
                },
                {
                    "sent": "Everything in even among can be a range of actor study movie or racing car.",
                    "label": 0
                },
                {
                    "sent": "We're not restricting ourselves, but providing a wide range of probabilities.",
                    "label": 0
                },
                {
                    "sent": "What we can find.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second, most important thing is that well, now we have the confidence is attached how to plug all this together.",
                    "label": 0
                },
                {
                    "sent": "The first thing is like some of the.",
                    "label": 1
                },
                {
                    "sent": "Like here I just want to give a more intuitive.",
                    "label": 1
                },
                {
                    "sent": "Presentation and don't want to put in the Markov logic marginal formulas which a lot of people have seen lot many times.",
                    "label": 0
                },
                {
                    "sent": "Just the broad idea is like you have a certain set of rules.",
                    "label": 0
                },
                {
                    "sent": "I don't even see the 1st just set of rules and a set of evidence is what are the rules doing.",
                    "label": 0
                },
                {
                    "sent": "The rules are basically.",
                    "label": 0
                },
                {
                    "sent": "So this one is particularly just a transitive, same as like if A is BBC that so it's obviously is.",
                    "label": 0
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                },
                {
                    "sent": "And this one is putting a cardinality constraint constraint on same as.",
                    "label": 0
                },
                {
                    "sent": "That means like if.",
                    "label": 0
                },
                {
                    "sent": "There is a mapping we should allow at most one mapping like Superman should be matched to.",
                    "label": 0
                },
                {
                    "sent": "Either none or at least at most one not more than more than one.",
                    "label": 0
                },
                {
                    "sent": "And that's the more important.",
                    "label": 0
                },
                {
                    "sent": "The second rule, which says like.",
                    "label": 0
                },
                {
                    "sent": "If you have a nail triple like a subject property object.",
                    "label": 0
                },
                {
                    "sent": "And the object is mapped to the pedia instance with the confidence value this.",
                    "label": 0
                },
                {
                    "sent": "And the DVD instance has got a particular class then.",
                    "label": 0
                },
                {
                    "sent": "You say like the object is of type this with what confidence?",
                    "label": 0
                },
                {
                    "sent": "With this W and note that this W is coming from the Alpha tree I just showed you like that's how we model this.",
                    "label": 0
                },
                {
                    "sent": "This entire problem with this just one line like where we kind of.",
                    "label": 0
                },
                {
                    "sent": "We see it shortly like how this single rule comes into play and plays a severe role in our solving solution.",
                    "label": 0
                },
                {
                    "sent": "And the second instances like this in the market logic, this is the model and this is like the evidence here.",
                    "label": 0
                },
                {
                    "sent": "We have two kinds of evidence is 1 is a soft truth.",
                    "label": 0
                },
                {
                    "sent": "As you say, like here, we are not sure actually though, so this is the best way we can model our world like well, these are the probabilities or the confidence is we got from our Wikipedia top candidates like OK, just put in every every evidence we gathered from our world like so we keep it in our case and the 2nd is hard truths WHI hard because these are the ones extracted from DB pedia ontology.",
                    "label": 0
                },
                {
                    "sent": "We know for sure like Superman is our comics character from DVD.",
                    "label": 0
                },
                {
                    "sent": "If that is wrong then we're really out of.",
                    "label": 0
                },
                {
                    "sent": "Out of scope.",
                    "label": 0
                },
                {
                    "sent": "Now what we do is put this together like and solve it as a problem so the network looks like this and keep in mind like all.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This predicates what I showed you like it's type an L triples.",
                    "label": 0
                },
                {
                    "sent": "These are essentially a binary variable, so.",
                    "label": 0
                },
                {
                    "sent": "Superman Brandon wrote actor starred in movie Superman.",
                    "label": 0
                },
                {
                    "sent": "Is it true or false?",
                    "label": 0
                },
                {
                    "sent": "So this note can have a true or false value.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "And that's how we instantiate or you ground start grounding your network like you put in, or fill in all the values.",
                    "label": 0
                },
                {
                    "sent": "This variables can take like plug in all the values.",
                    "label": 0
                },
                {
                    "sent": "So one kind of instantiation can be like this like.",
                    "label": 0
                },
                {
                    "sent": "Just just like we have this film of type this, then that's what I marked like.",
                    "label": 0
                },
                {
                    "sent": "The observed ones are like the bold ones and same as these are like the query ones like which eventually turns out to be true.",
                    "label": 0
                },
                {
                    "sent": "Now see like here we have two different kinds of weight which are playing one from this approach where we assign like well if blah blah blah something like this.",
                    "label": 0
                },
                {
                    "sent": "Then the Superman is a film with this amount of confidence again.",
                    "label": 0
                },
                {
                    "sent": "On this level we also have a confidence with Superman's as well.",
                    "label": 0
                },
                {
                    "sent": "That's actually the key part.",
                    "label": 0
                },
                {
                    "sent": "Like here we allow these two weights to play each other and only that world where this combination is like a.",
                    "label": 0
                },
                {
                    "sent": "It works like a positive feedback like the good type match with a good instantiation is yes, that's the winner.",
                    "label": 0
                },
                {
                    "sent": "So and anything which is a bad type information but a good same as link won't succeed eventually, so it's like.",
                    "label": 0
                },
                {
                    "sent": "Goes out of the equation, so that's why I say like we solve this and find out like what's the best world with the highest probability of of holding true.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we take a break and say like OK, can we still do it better?",
                    "label": 1
                },
                {
                    "sent": "Like is it the end of the story?",
                    "label": 0
                },
                {
                    "sent": "Probably know becausw.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before you go through that directly, go to the because of the time I go to the, this next time we just like the bootstrapping, what we do is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We start off with all the hypothesis we have at our hand.",
                    "label": 0
                },
                {
                    "sent": "Like all put everything in our system.",
                    "label": 0
                },
                {
                    "sent": "Take the type the top one weights.",
                    "label": 0
                },
                {
                    "sent": "And from that we create a Alpha tree with this kind of weights, the bold ones are the ones which are the ones which the values we observed in this first iteration.",
                    "label": 0
                },
                {
                    "sent": "2nd is from this we let mark of logic do all the reasoning and find out the best world.",
                    "label": 0
                },
                {
                    "sent": "What we get is no suitable mapping.",
                    "label": 0
                },
                {
                    "sent": "Why Becausw the best one was one point 9 and the fictional character is minus 3.9.",
                    "label": 0
                },
                {
                    "sent": "If it's like it's outside the scope of this presentation because it's just a kind of math or addition going on there which says like if these two are added, it's less than zero and anything less than zero is like it's a log linear model, so it's like less than probability half.",
                    "label": 0
                },
                {
                    "sent": "So we just do not take any consideration, so that's only happening for this Superman mapping stuff.",
                    "label": 0
                },
                {
                    "sent": "And keep in mind that there are also several other such mappings in the in our system.",
                    "label": 0
                },
                {
                    "sent": "Let's feed it again.",
                    "label": 0
                },
                {
                    "sent": "Now what we have is the same instantiation's like the same value.",
                    "label": 0
                },
                {
                    "sent": "But now I mark the different one with a bold now not the top one, but it's the refined, which is what we get so far.",
                    "label": 0
                },
                {
                    "sent": "Like from this loop with refined weights.",
                    "label": 0
                },
                {
                    "sent": "Now what happens?",
                    "label": 0
                },
                {
                    "sent": "Film gets a higher weight.",
                    "label": 0
                },
                {
                    "sent": "It kinds of the other instances pushes film to be more likely.",
                    "label": 0
                },
                {
                    "sent": "Now it's like a like a match made in heaven like film film like Wow, that's a great thing.",
                    "label": 0
                },
                {
                    "sent": "Those two are working great tandem together and we have Superman.",
                    "label": 0
                },
                {
                    "sent": "The film selected finally and go on with like several iterations till it terminates.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's the whole story of it, and we just shortly go through our experiment so we have a gold standard manually created and we take like 100 triples from like 12 most frequently chosen nail properties and.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the learning Alpha part where we just divide.",
                    "label": 0
                },
                {
                    "sent": "We define our model, we model the problem in such ways, like from zero to 1 and we divide it into eight steps and we take like all the like .125 gap.",
                    "label": 0
                },
                {
                    "sent": "The values and we divide into its like a two fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "If we train it on one side and we tested on other and we iterate or do the sampling for a lot many number of large number of samples and what we find is like this kind of output and this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is more reflective something like this?",
                    "label": 0
                },
                {
                    "sent": "Like you go on plotting Alpha with the respective fan scores, so that's like the good case we have, and finally.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have like the output.",
                    "label": 0
                },
                {
                    "sent": "Like we we choose the 12 predicates and we start plotting.",
                    "label": 0
                },
                {
                    "sent": "So this is like the baseline and we see like for some predicate we really couldn't do any better because this is a notorious property because sometimes it's the agent which can be organization or it can be a person and it's really hard to work with this way and for some others we really have a lot of.",
                    "label": 0
                },
                {
                    "sent": "Improvement over baseline.",
                    "label": 0
                },
                {
                    "sent": "On average we got like it's not.",
                    "label": 0
                },
                {
                    "sent": "Also, it's a high value but but given that we have a most frequent baseline, which is really hard to beat, I think it's a pretty nice value of, like almost a four person gaining F1.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And So what is the biggest limitation is like we cannot differentiate between types.",
                    "label": 0
                },
                {
                    "sent": "Same type of person.",
                    "label": 0
                },
                {
                    "sent": "We don't know like if it's like the Mel Gibson is the actor or the author William Gibson.",
                    "label": 1
                },
                {
                    "sent": "So this type of thing and the other thing is if the DVD type information is missing, we're kind of lossed so we're working on that like incorporating data from other sources like Jago because they have Lago di darlings.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so, right now I'm kind of working on like bringing the properties together.",
                    "label": 0
                },
                {
                    "sent": "We recently submitted something and then looking for more scope of knowledge generation and finally reverve, which is a wider data set like kind of 15,000,000 facts, much bigger than L. That would be an interesting test case for us.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that, I'd like to thank you all for your kind attention.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}