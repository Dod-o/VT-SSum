{
    "id": "cc6gc77u2zrcjny22fbb2alo6aoypktm",
    "title": "A Tale of Two Metrics: Simultaneous Bounds on Competitiveness and Regret",
    "info": {
        "author": [
            "Siddharth Barman, Department of Computing and Mathematical Sciences, California Institute of Technology (Caltech)"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_barman_bounds/",
    "segmentation": [
        [
            "Hi, Amsat, and this is joint work with Lachlin Andrew, Katrina Liggett, Bing Hongling, Adam Nelson, Allen Brockman, Adam Bierman.",
            "So a lot of us like the problem, so I guess."
        ],
        [
            "So in short, the key message of the result is that the two prominent metrics in measuring efficiency of online algorithms are competition regret and we studied a class of problems where both these metrics are relevant, and in fact we established that these metrics, though individually we can one at a time.",
            "We can find algorithms that perform well on these metrics.",
            "They are incompatible in the sense that there is no algorithm.",
            "That achieves that performs well on these metrics simultaneously."
        ],
        [
            "So the class of problems we are looking at is called smooth online convex optimization and the framework is quite general.",
            "The idea is at every point of time the decision maker picture, decision or an action which can be a scalar or vector XI and after that the environment reveals a convex cost function and algorithm."
        ],
        [
            "Cursor cost of C1X1.",
            "So with respect to the convex function that's revealed and the process goes on, the next time the Al Gore."
        ],
        [
            "Pick 6, two, and again.",
            "There's a convex cost function that's revealed."
        ],
        [
            "The environment and as before you get to see 2X2 cost, but the additional feature here is that the algorithm also incurs a switching cost, which is the difference between the norm of the difference between the two actions X2 and X1 South.",
            "Along with this cost, there's a switching cost involved.",
            "In the process."
        ],
        [
            "Goes on and on."
        ],
        [
            "So overall, the formulation the online problem can be stated as follows.",
            "You have this online sequence of decisions and cost functions, and you're trying to minimize the following problem where CTCT's are going to be the convex cost functions and at every step you pay this switching cost.",
            "Now, so this the added term here is can be thought of as a smoothing parameter, so we call it the smooth online convex optimization and obviously the goal here is to find algorithms that minimize this cost.",
            "So quite a general framework and it has many applique."
        ],
        [
            "Actions from like dynamic resizing data centers where you can think of these XTS as the active servers at any point of time and so the CTX T cost is the operating cost at time T and the switching costs here.",
            "The norm difference is the Baron tier costs that you incur when you change the number of active servers when you shut down or restart servers, you incur a cost and that's modeled as this.",
            "Switching cost here, and similarly there are plenty of other applications like geographical load balancing, video streaming and so on.",
            "So in the."
        ],
        [
            "This problem similar formulations have been studied in many many communities, though not identical.",
            "So in the two prominent communities that have looked at similar online problems or the online learning community and online algorithms community and noticeable differences here.",
            "The problem that's closest to this smooth online convex optimization in the Online's algorithms community is called a metrical task systems, where I'll kind of make these connections more clear.",
            "But the idea is in that setting your.",
            "Metric of choice is competitive ratio and there's no convexity assumption.",
            "On the other hand, I mean if you ignore the switching cost, then it's identical to online convex optimization, so there and there are metric of choice is regret.",
            "Thanks so."
        ],
        [
            "So let's start with connecting this problem to metrical task systems.",
            "So as I said, I mean there in metrical task systems we have a very similar optimization problem, but the cost functions are not convex and the key sort of technical.",
            "Point to note here is that in these problems here cost function is revealed 1st and then the algorithm has to pick an action.",
            "So if in some sense the algorithm has a look ahead of 1, so the cost function FT comes first and then you apply the action XD plus one.",
            "Because of that, in the that's the sort of cost that the metrical task system algorithm incurs.",
            "And more over here we don't really.",
            "It's Zuma convex set, it's a endpoint.",
            "You can think of it as the underlying metric.",
            "Here is some finite graph, and the switching costs are with respect to this graph.",
            "You kind of emphasize the fact that the cost function is the algorithm as I look ahead of 1.",
            "By denoting the cost by a subscript one.",
            "So this means that whenever you see a subscript one, it means that the algorithm first sees the cost function and then has to.",
            "Big it's action and as I said in the performance metric here of choice is competitive ratio, which is the worst case ratio of the.",
            "Of the cost incurred by the algorithm to their dynamic optimal.",
            "And I'm emphasizing the dynamic aspect here, because you say that the the in this you are allowed to change switch actions throughout.",
            "At all points of time in particular, you just look at this whole problem, solve it offline, and that's the optimal that you compare against."
        ],
        [
            "And so if you look at the so-called problem from a online algorithms perspective, we have.",
            "SIM card that actually achieves a constant competition ratio or competition of three for one dimensional problem.",
            "So everything here is 1 dimensional.",
            "This is convex set and so on and you get a computer issue of three.",
            "Now moving onto the online learning learning view of it as discussed in the last of this is sort of."
        ],
        [
            "Unnatural.",
            "Surrogate here and the idea is again the technical point.",
            "Note here is that when viewed as the online learning algorithm, you don't see the cost function.",
            "First, you first have to act, XT comes first and then the cost function is really so.",
            "The algorithm in some sense does not have a look ahead and we emphasize this fact by saying this subscript of putting a subscript of zero and the cost of the algorithm.",
            "And you define your regret as this.",
            "This is the cost of the algorithm incurs, subtracted or more than the static optimal.",
            "So here in this optimal we are not allowed to switch actions.",
            "We pick one single point and then look at this entire optimization problem.",
            "As mentioned earlier, there are plenty of algorithms that achieve good regret.",
            "Bounce, and I mean, as I said this he it's kind of intuitive that since you're only adding a norm to this term, that online gradient descent in fact achieves sublinear regret for socko as well.",
            "So it's kind of a."
        ],
        [
            "Follow up just a clean observation from that.",
            "So."
        ],
        [
            "Now the key point is that regret implies learning a static concept.",
            "It's good when your underlying concept is static, whereas competitive ratio is a good measure.",
            "When your underlying concept is dynamic, said in a more controlled perspective, the idea is low.",
            "Regret essentially corresponds to a more stable solution, whereas competitive ratio, since it's comparing against the dynamic optimal, corresponds to a more efficient solution.",
            "So the natural question is you would.",
            "Want to perform well on both of these metrics simultaneously?",
            "Since you don't know a priori what is the underlying concept that you're learning and so the so the question you asked.",
            "Is is there so they said there are a short their algorithms that perform well on these metrics one at a time and we would like to understand whether it's possible that there's an algorithm that does well on both these metrics simultaneously and we show that that's not really the case."
        ],
        [
            "And there is no such algorithm.",
            "No algorithm, either randomized or deterministic, can achieve this.",
            "Can achieve this property?",
            "Phone."
        ],
        [
            "Here's the sort of 1st crack at it, and if you look at the definitions in the right way.",
            "Kind of intuitive that this result should follow.",
            "As I said, I mean competitive ratio is defined with respect to cost one, and when I defined it, the action has 2X T is applied to cost C T -- 1, whereas regret is defined with respect to costs 0.",
            "So in this case XT is applied to cost function CT and it's kind of unlikely that if if you see T -- 1 and CTS some incense.",
            "Orthogonal you cannot expect XT to perform well on both these metrics simultaneously, so it's kind of intuitive result that follows from this observation.",
            "But overall this is not really fair, I'm just what I did was defined.",
            "These took these definitions in the standard setting and because of this discrepancy I got this incompatibility result.",
            "We can make this analysis more fair.",
            "We have to look at the same cost functions.",
            "At both both points, so one option is.",
            "I can make this cost 0, but that makes my task harder.",
            "I'm not even taking away power from the competitive ratio algorithm that earlier had a look at one and now does not have a look ahead.",
            "So I mean the more fair analysis would be to define another form of regret we called."
        ],
        [
            "Great time in which the algorithm again looks at cost 1 S. It's the same metric, but now we are allowing the cost function to be revealed 1st and then the regret algorithm has to act.",
            "So it's a more weaker target.",
            "And since we're looking for incompatibility, this would be a stronger result.",
            "And in fact, should add that even."
        ],
        [
            "When we look at this more relaxed version of regret, there is no algorithm that performs well on both these metrics simultaneously.",
            "So either the algorithm will have regret that asymptotically lower bounded by T or the competitive ratio has to be an increasing function of T."
        ],
        [
            "Phone let me just quickly give you a proof sketch.",
            "The idea is what we'll do is look at the entire.",
            "The entire input sequence and divide it into batches each of size.",
            "3M so I just consecutive batches.",
            "Each batch is of size 3M and now what I'll do is in each batch I'll use linear functions and guarantee one of two things.",
            "But I'll guarantee that either the regret in every batch is more than some chosen constant or the competitive ratio is proportional to the length of this batch.",
            "And my claim is that if I'm able to accomplish this for every batch, then that's it.",
            "That stab Lish is the result, and the reason is this.",
            "Let's say I want."
        ],
        [
            "The algorithm to achieve sublinear regret in that case for only some linear number of batches.",
            "Can I afford to have this blue inequality so the number of batches where this inequality holds has to be sub linear, otherwise the regret itself becomes linear.",
            "Now this forces that in the remaining batches the competitive ratio is in fact proportional to the length of the batch, so this red inequality occurs.",
            "Almost in.",
            "For a sub linear number of batches is red inequality occurs everywhere.",
            "Now this forces that the competitive ratio of the overall input has to be increasing in T and that's it.",
            "Stab Lish is the theorem, so all that's left for me now is to convince you.",
            "That I can use, I can pack function convex functions.",
            "In particular I use linear functions to achieve one of these two.",
            "Every batch.",
            "And the way I'm going to do it."
        ],
        [
            "Is to use two linear functions that that.",
            "Find between zero and one so my action space is just yeah.",
            "So here."
        ],
        [
            "When you say in everybody regretted at least constant, do you mean the regret with respect to the best?",
            "Yeah, yeah.",
            "I mean, so I'll construct the instances that the regret regret which is the district the optimal cost with respect to this.",
            "So I'm looking at the difference of the cost of the algorithm in this batch to the cost of the optimal in this batch.",
            "The optimal action being defined, overall overall it, but the way I'll construct it will stay the same.",
            "It will be the same star will be the same for single batch and the whole input, yeah.",
            "Yeah, I mean this might, but I mean, yeah, it's it's kind of.",
            "Yeah, so you can change things, but the way I do it, both of them will coincide.",
            "The extra for a batch will be the same, so the argument goes through.",
            "And."
        ],
        [
            "Just to emphasize this point, I guess that's a good question.",
            "The what I'll do is in each batch I'll have to have two linear functions, F0 and F. On my action spaces between two points, and the way I do it is just FOI look at if zero which has minimized zero F1 which has a minimum of one and I'll just.",
            "Stock up of zeros through the like the tail end of this path, so from M2 to M I'll only have zeros and I'll use efforts in the initial in the prefix part of my batch, they abundance of F0 is what forced me to have extras zero for the batch, and I'll repeat the same construction in every batch so X star continues to be at zero throughout the input sequence.",
            "Current now there are two possible cases.",
            "I look at the algorithm, so note that any here.",
            "This essentially means that if you if the algorithm at any point goes above some prescribed constant Delta, then I'll switch back to have zeros, making the algorithm pay for this sort of making the algorithm pay for trading off this from this neighborhood of 0, and that refers in it's a high level argument, but that forces the regret to go above.",
            "Constant, on the other hand, if the algorithm is restrained and stays within this Delta for the entire sequence from zero to M, then because it's facing a function which is has a high value close to 0, the competitive ratio goza.",
            "The, whereas I mean the dynamic optimal is to just be one here and then switch back to 0.",
            "But instead the algorithm because it's staying close to 0 incurs high costs and incurs a high competitive ratio.",
            "Find today."
        ],
        [
            "Stating that tells tells us that there is no algorithm that does well on both these metrics.",
            "The next natural question is what's the trader?",
            "What's the best I can do if I'm willing to have a competitive ratio that's, let's say, slowly increasing which T. So let's say I'm happy with the log log key, competitive issue.",
            "In that case, can I get sub linear record and the answer is yes, when we look at the 1 dimensional problem.",
            "So work based function."
        ],
        [
            "I got him an interest of time.",
            "I'll not go into the details, but the idea is we sort of parameterized the norm with a scaling factor and have this initial random seed, and every time we minimize this work function and the Kythira we have is that if we choose some particular Theta, let's say log log T in the competitive ratio is Theta and the regulators TV theater.",
            "So if you pick an increasing function of tne arbitrary small.",
            "So we get sublinear regret."
        ],
        [
            "So overall, I mean this is kind of giving us a framework where we, establishing compatibility and looked at.",
            "This tradeoff and in some sense for one dimensional.",
            "This is tight my counterexample, so the incompatibility proofs were also one dimensional.",
            "So next natural question is what if we look at other models?",
            "What's the?",
            "Incompatibility go through for weaker adversaries or what's the tradeoff in higher dimensions or in banded settings?",
            "And these are quite interesting problems that we're interested in, and I'll be happy to talk to you about it offline."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, Amsat, and this is joint work with Lachlin Andrew, Katrina Liggett, Bing Hongling, Adam Nelson, Allen Brockman, Adam Bierman.",
                    "label": 0
                },
                {
                    "sent": "So a lot of us like the problem, so I guess.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in short, the key message of the result is that the two prominent metrics in measuring efficiency of online algorithms are competition regret and we studied a class of problems where both these metrics are relevant, and in fact we established that these metrics, though individually we can one at a time.",
                    "label": 0
                },
                {
                    "sent": "We can find algorithms that perform well on these metrics.",
                    "label": 0
                },
                {
                    "sent": "They are incompatible in the sense that there is no algorithm.",
                    "label": 1
                },
                {
                    "sent": "That achieves that performs well on these metrics simultaneously.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the class of problems we are looking at is called smooth online convex optimization and the framework is quite general.",
                    "label": 0
                },
                {
                    "sent": "The idea is at every point of time the decision maker picture, decision or an action which can be a scalar or vector XI and after that the environment reveals a convex cost function and algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cursor cost of C1X1.",
                    "label": 0
                },
                {
                    "sent": "So with respect to the convex function that's revealed and the process goes on, the next time the Al Gore.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pick 6, two, and again.",
                    "label": 0
                },
                {
                    "sent": "There's a convex cost function that's revealed.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The environment and as before you get to see 2X2 cost, but the additional feature here is that the algorithm also incurs a switching cost, which is the difference between the norm of the difference between the two actions X2 and X1 South.",
                    "label": 0
                },
                {
                    "sent": "Along with this cost, there's a switching cost involved.",
                    "label": 0
                },
                {
                    "sent": "In the process.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Goes on and on.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So overall, the formulation the online problem can be stated as follows.",
                    "label": 0
                },
                {
                    "sent": "You have this online sequence of decisions and cost functions, and you're trying to minimize the following problem where CTCT's are going to be the convex cost functions and at every step you pay this switching cost.",
                    "label": 1
                },
                {
                    "sent": "Now, so this the added term here is can be thought of as a smoothing parameter, so we call it the smooth online convex optimization and obviously the goal here is to find algorithms that minimize this cost.",
                    "label": 0
                },
                {
                    "sent": "So quite a general framework and it has many applique.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actions from like dynamic resizing data centers where you can think of these XTS as the active servers at any point of time and so the CTX T cost is the operating cost at time T and the switching costs here.",
                    "label": 0
                },
                {
                    "sent": "The norm difference is the Baron tier costs that you incur when you change the number of active servers when you shut down or restart servers, you incur a cost and that's modeled as this.",
                    "label": 0
                },
                {
                    "sent": "Switching cost here, and similarly there are plenty of other applications like geographical load balancing, video streaming and so on.",
                    "label": 1
                },
                {
                    "sent": "So in the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This problem similar formulations have been studied in many many communities, though not identical.",
                    "label": 0
                },
                {
                    "sent": "So in the two prominent communities that have looked at similar online problems or the online learning community and online algorithms community and noticeable differences here.",
                    "label": 1
                },
                {
                    "sent": "The problem that's closest to this smooth online convex optimization in the Online's algorithms community is called a metrical task systems, where I'll kind of make these connections more clear.",
                    "label": 1
                },
                {
                    "sent": "But the idea is in that setting your.",
                    "label": 0
                },
                {
                    "sent": "Metric of choice is competitive ratio and there's no convexity assumption.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, I mean if you ignore the switching cost, then it's identical to online convex optimization, so there and there are metric of choice is regret.",
                    "label": 0
                },
                {
                    "sent": "Thanks so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's start with connecting this problem to metrical task systems.",
                    "label": 1
                },
                {
                    "sent": "So as I said, I mean there in metrical task systems we have a very similar optimization problem, but the cost functions are not convex and the key sort of technical.",
                    "label": 0
                },
                {
                    "sent": "Point to note here is that in these problems here cost function is revealed 1st and then the algorithm has to pick an action.",
                    "label": 0
                },
                {
                    "sent": "So if in some sense the algorithm has a look ahead of 1, so the cost function FT comes first and then you apply the action XD plus one.",
                    "label": 0
                },
                {
                    "sent": "Because of that, in the that's the sort of cost that the metrical task system algorithm incurs.",
                    "label": 0
                },
                {
                    "sent": "And more over here we don't really.",
                    "label": 0
                },
                {
                    "sent": "It's Zuma convex set, it's a endpoint.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as the underlying metric.",
                    "label": 0
                },
                {
                    "sent": "Here is some finite graph, and the switching costs are with respect to this graph.",
                    "label": 0
                },
                {
                    "sent": "You kind of emphasize the fact that the cost function is the algorithm as I look ahead of 1.",
                    "label": 0
                },
                {
                    "sent": "By denoting the cost by a subscript one.",
                    "label": 0
                },
                {
                    "sent": "So this means that whenever you see a subscript one, it means that the algorithm first sees the cost function and then has to.",
                    "label": 1
                },
                {
                    "sent": "Big it's action and as I said in the performance metric here of choice is competitive ratio, which is the worst case ratio of the.",
                    "label": 0
                },
                {
                    "sent": "Of the cost incurred by the algorithm to their dynamic optimal.",
                    "label": 0
                },
                {
                    "sent": "And I'm emphasizing the dynamic aspect here, because you say that the the in this you are allowed to change switch actions throughout.",
                    "label": 0
                },
                {
                    "sent": "At all points of time in particular, you just look at this whole problem, solve it offline, and that's the optimal that you compare against.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so if you look at the so-called problem from a online algorithms perspective, we have.",
                    "label": 1
                },
                {
                    "sent": "SIM card that actually achieves a constant competition ratio or competition of three for one dimensional problem.",
                    "label": 0
                },
                {
                    "sent": "So everything here is 1 dimensional.",
                    "label": 0
                },
                {
                    "sent": "This is convex set and so on and you get a computer issue of three.",
                    "label": 1
                },
                {
                    "sent": "Now moving onto the online learning learning view of it as discussed in the last of this is sort of.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unnatural.",
                    "label": 0
                },
                {
                    "sent": "Surrogate here and the idea is again the technical point.",
                    "label": 0
                },
                {
                    "sent": "Note here is that when viewed as the online learning algorithm, you don't see the cost function.",
                    "label": 0
                },
                {
                    "sent": "First, you first have to act, XT comes first and then the cost function is really so.",
                    "label": 0
                },
                {
                    "sent": "The algorithm in some sense does not have a look ahead and we emphasize this fact by saying this subscript of putting a subscript of zero and the cost of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And you define your regret as this.",
                    "label": 0
                },
                {
                    "sent": "This is the cost of the algorithm incurs, subtracted or more than the static optimal.",
                    "label": 0
                },
                {
                    "sent": "So here in this optimal we are not allowed to switch actions.",
                    "label": 0
                },
                {
                    "sent": "We pick one single point and then look at this entire optimization problem.",
                    "label": 0
                },
                {
                    "sent": "As mentioned earlier, there are plenty of algorithms that achieve good regret.",
                    "label": 0
                },
                {
                    "sent": "Bounce, and I mean, as I said this he it's kind of intuitive that since you're only adding a norm to this term, that online gradient descent in fact achieves sublinear regret for socko as well.",
                    "label": 1
                },
                {
                    "sent": "So it's kind of a.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Follow up just a clean observation from that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the key point is that regret implies learning a static concept.",
                    "label": 0
                },
                {
                    "sent": "It's good when your underlying concept is static, whereas competitive ratio is a good measure.",
                    "label": 1
                },
                {
                    "sent": "When your underlying concept is dynamic, said in a more controlled perspective, the idea is low.",
                    "label": 0
                },
                {
                    "sent": "Regret essentially corresponds to a more stable solution, whereas competitive ratio, since it's comparing against the dynamic optimal, corresponds to a more efficient solution.",
                    "label": 0
                },
                {
                    "sent": "So the natural question is you would.",
                    "label": 0
                },
                {
                    "sent": "Want to perform well on both of these metrics simultaneously?",
                    "label": 0
                },
                {
                    "sent": "Since you don't know a priori what is the underlying concept that you're learning and so the so the question you asked.",
                    "label": 0
                },
                {
                    "sent": "Is is there so they said there are a short their algorithms that perform well on these metrics one at a time and we would like to understand whether it's possible that there's an algorithm that does well on both these metrics simultaneously and we show that that's not really the case.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there is no such algorithm.",
                    "label": 0
                },
                {
                    "sent": "No algorithm, either randomized or deterministic, can achieve this.",
                    "label": 0
                },
                {
                    "sent": "Can achieve this property?",
                    "label": 0
                },
                {
                    "sent": "Phone.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's the sort of 1st crack at it, and if you look at the definitions in the right way.",
                    "label": 0
                },
                {
                    "sent": "Kind of intuitive that this result should follow.",
                    "label": 0
                },
                {
                    "sent": "As I said, I mean competitive ratio is defined with respect to cost one, and when I defined it, the action has 2X T is applied to cost C T -- 1, whereas regret is defined with respect to costs 0.",
                    "label": 1
                },
                {
                    "sent": "So in this case XT is applied to cost function CT and it's kind of unlikely that if if you see T -- 1 and CTS some incense.",
                    "label": 0
                },
                {
                    "sent": "Orthogonal you cannot expect XT to perform well on both these metrics simultaneously, so it's kind of intuitive result that follows from this observation.",
                    "label": 0
                },
                {
                    "sent": "But overall this is not really fair, I'm just what I did was defined.",
                    "label": 0
                },
                {
                    "sent": "These took these definitions in the standard setting and because of this discrepancy I got this incompatibility result.",
                    "label": 0
                },
                {
                    "sent": "We can make this analysis more fair.",
                    "label": 0
                },
                {
                    "sent": "We have to look at the same cost functions.",
                    "label": 0
                },
                {
                    "sent": "At both both points, so one option is.",
                    "label": 0
                },
                {
                    "sent": "I can make this cost 0, but that makes my task harder.",
                    "label": 0
                },
                {
                    "sent": "I'm not even taking away power from the competitive ratio algorithm that earlier had a look at one and now does not have a look ahead.",
                    "label": 0
                },
                {
                    "sent": "So I mean the more fair analysis would be to define another form of regret we called.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Great time in which the algorithm again looks at cost 1 S. It's the same metric, but now we are allowing the cost function to be revealed 1st and then the regret algorithm has to act.",
                    "label": 0
                },
                {
                    "sent": "So it's a more weaker target.",
                    "label": 0
                },
                {
                    "sent": "And since we're looking for incompatibility, this would be a stronger result.",
                    "label": 0
                },
                {
                    "sent": "And in fact, should add that even.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we look at this more relaxed version of regret, there is no algorithm that performs well on both these metrics simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So either the algorithm will have regret that asymptotically lower bounded by T or the competitive ratio has to be an increasing function of T.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Phone let me just quickly give you a proof sketch.",
                    "label": 1
                },
                {
                    "sent": "The idea is what we'll do is look at the entire.",
                    "label": 0
                },
                {
                    "sent": "The entire input sequence and divide it into batches each of size.",
                    "label": 0
                },
                {
                    "sent": "3M so I just consecutive batches.",
                    "label": 0
                },
                {
                    "sent": "Each batch is of size 3M and now what I'll do is in each batch I'll use linear functions and guarantee one of two things.",
                    "label": 0
                },
                {
                    "sent": "But I'll guarantee that either the regret in every batch is more than some chosen constant or the competitive ratio is proportional to the length of this batch.",
                    "label": 1
                },
                {
                    "sent": "And my claim is that if I'm able to accomplish this for every batch, then that's it.",
                    "label": 0
                },
                {
                    "sent": "That stab Lish is the result, and the reason is this.",
                    "label": 0
                },
                {
                    "sent": "Let's say I want.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The algorithm to achieve sublinear regret in that case for only some linear number of batches.",
                    "label": 0
                },
                {
                    "sent": "Can I afford to have this blue inequality so the number of batches where this inequality holds has to be sub linear, otherwise the regret itself becomes linear.",
                    "label": 0
                },
                {
                    "sent": "Now this forces that in the remaining batches the competitive ratio is in fact proportional to the length of the batch, so this red inequality occurs.",
                    "label": 0
                },
                {
                    "sent": "Almost in.",
                    "label": 0
                },
                {
                    "sent": "For a sub linear number of batches is red inequality occurs everywhere.",
                    "label": 0
                },
                {
                    "sent": "Now this forces that the competitive ratio of the overall input has to be increasing in T and that's it.",
                    "label": 1
                },
                {
                    "sent": "Stab Lish is the theorem, so all that's left for me now is to convince you.",
                    "label": 0
                },
                {
                    "sent": "That I can use, I can pack function convex functions.",
                    "label": 0
                },
                {
                    "sent": "In particular I use linear functions to achieve one of these two.",
                    "label": 0
                },
                {
                    "sent": "Every batch.",
                    "label": 0
                },
                {
                    "sent": "And the way I'm going to do it.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to use two linear functions that that.",
                    "label": 0
                },
                {
                    "sent": "Find between zero and one so my action space is just yeah.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you say in everybody regretted at least constant, do you mean the regret with respect to the best?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean, so I'll construct the instances that the regret regret which is the district the optimal cost with respect to this.",
                    "label": 0
                },
                {
                    "sent": "So I'm looking at the difference of the cost of the algorithm in this batch to the cost of the optimal in this batch.",
                    "label": 0
                },
                {
                    "sent": "The optimal action being defined, overall overall it, but the way I'll construct it will stay the same.",
                    "label": 0
                },
                {
                    "sent": "It will be the same star will be the same for single batch and the whole input, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean this might, but I mean, yeah, it's it's kind of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you can change things, but the way I do it, both of them will coincide.",
                    "label": 0
                },
                {
                    "sent": "The extra for a batch will be the same, so the argument goes through.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to emphasize this point, I guess that's a good question.",
                    "label": 0
                },
                {
                    "sent": "The what I'll do is in each batch I'll have to have two linear functions, F0 and F. On my action spaces between two points, and the way I do it is just FOI look at if zero which has minimized zero F1 which has a minimum of one and I'll just.",
                    "label": 0
                },
                {
                    "sent": "Stock up of zeros through the like the tail end of this path, so from M2 to M I'll only have zeros and I'll use efforts in the initial in the prefix part of my batch, they abundance of F0 is what forced me to have extras zero for the batch, and I'll repeat the same construction in every batch so X star continues to be at zero throughout the input sequence.",
                    "label": 1
                },
                {
                    "sent": "Current now there are two possible cases.",
                    "label": 0
                },
                {
                    "sent": "I look at the algorithm, so note that any here.",
                    "label": 0
                },
                {
                    "sent": "This essentially means that if you if the algorithm at any point goes above some prescribed constant Delta, then I'll switch back to have zeros, making the algorithm pay for this sort of making the algorithm pay for trading off this from this neighborhood of 0, and that refers in it's a high level argument, but that forces the regret to go above.",
                    "label": 0
                },
                {
                    "sent": "Constant, on the other hand, if the algorithm is restrained and stays within this Delta for the entire sequence from zero to M, then because it's facing a function which is has a high value close to 0, the competitive ratio goza.",
                    "label": 0
                },
                {
                    "sent": "The, whereas I mean the dynamic optimal is to just be one here and then switch back to 0.",
                    "label": 0
                },
                {
                    "sent": "But instead the algorithm because it's staying close to 0 incurs high costs and incurs a high competitive ratio.",
                    "label": 0
                },
                {
                    "sent": "Find today.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stating that tells tells us that there is no algorithm that does well on both these metrics.",
                    "label": 0
                },
                {
                    "sent": "The next natural question is what's the trader?",
                    "label": 0
                },
                {
                    "sent": "What's the best I can do if I'm willing to have a competitive ratio that's, let's say, slowly increasing which T. So let's say I'm happy with the log log key, competitive issue.",
                    "label": 0
                },
                {
                    "sent": "In that case, can I get sub linear record and the answer is yes, when we look at the 1 dimensional problem.",
                    "label": 0
                },
                {
                    "sent": "So work based function.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I got him an interest of time.",
                    "label": 0
                },
                {
                    "sent": "I'll not go into the details, but the idea is we sort of parameterized the norm with a scaling factor and have this initial random seed, and every time we minimize this work function and the Kythira we have is that if we choose some particular Theta, let's say log log T in the competitive ratio is Theta and the regulators TV theater.",
                    "label": 0
                },
                {
                    "sent": "So if you pick an increasing function of tne arbitrary small.",
                    "label": 0
                },
                {
                    "sent": "So we get sublinear regret.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So overall, I mean this is kind of giving us a framework where we, establishing compatibility and looked at.",
                    "label": 0
                },
                {
                    "sent": "This tradeoff and in some sense for one dimensional.",
                    "label": 0
                },
                {
                    "sent": "This is tight my counterexample, so the incompatibility proofs were also one dimensional.",
                    "label": 0
                },
                {
                    "sent": "So next natural question is what if we look at other models?",
                    "label": 0
                },
                {
                    "sent": "What's the?",
                    "label": 0
                },
                {
                    "sent": "Incompatibility go through for weaker adversaries or what's the tradeoff in higher dimensions or in banded settings?",
                    "label": 0
                },
                {
                    "sent": "And these are quite interesting problems that we're interested in, and I'll be happy to talk to you about it offline.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}