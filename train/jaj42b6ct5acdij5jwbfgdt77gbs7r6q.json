{
    "id": "jaj42b6ct5acdij5jwbfgdt77gbs7r6q",
    "title": "The Bayesian Group-Lasso for Analyzing Contingency Tables",
    "info": {
        "author": [
            "Sudhir Raman, Department of Computer Science, University of Basel"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_raman_bgl/",
    "segmentation": [
        [
            "So this is a rough path of the talk will start with."
        ],
        [
            "A little bit of motivation then some basic introduction, then talk about feature selection.",
            "And apply to contingency tables for count data.",
            "And finally, we'll look at the biological application that motivated us for this method, and the results that we got out of the data set.",
            "And finally, a summary and some future extensions that are possible.",
            "OK."
        ],
        [
            "So in terms of motivation, so we work primarily with biological data, and we frequently encounter problems with feature selection.",
            "So like finding novel biomarkers, it's generally there in cancer datasets.",
            "And then all these measurements are generally in terms of categories or some intensity levels.",
            "So these are categorical variables and will show that that leads to doing feature selection in groups of variables rather than just single single features.",
            "And then we also encounter a lot of count data in medical applications and then in terms of the method we try to provide meaningful variance estimates in terms of the regression coefficients.",
            "And we try to average over solutions rather than find just point estimates."
        ],
        [
            "We just entered introduction standard linear regression problem Y = 2 X speedup closets island.",
            "Then you can model it in different ways and generally we apply some kind of constraint on the regression coefficients.",
            "Basic version just have a likelihood you multiply it with a suitable prior on beta and you may have some more variables.",
            "You can define some more hyper priors data and finally you're interested to have a posterior and you want to analyze the posterior.",
            "Find either maximum estimate or average over solutions.",
            "OK, so now we look at this in."
        ],
        [
            "In the context of FICA."
        ],
        [
            "Selection.",
            "So I'll start with from the left side.",
            "So in terms of feature selection you have, you can start with the cost function subject to an L1 norm, which is a lazy constraint.",
            "And so last year there was some work done in a Bayesian context where the same thing was translated into a suitable prior which represents the lazoo constraint, which is basically a product of the Laplacian distributions over the regression coefficients.",
            "So now what we've done is we've extended this to feature selection in groups.",
            "So what we need is to apply a group luzu constraint which is smooth within the group and sparse between the groups.",
            "So that results in you're optimizing a function with a constraint of some of the L2 norms over the beat's.",
            "And then to define a suitable prior for this.",
            "What we do is we just extend that idea forward an have multivariate Laplacian over the groups a product of multiple oppressions over the groups.",
            "So we have this nice analytical form.",
            "But inference would be it would not be feasible with this with this alone.",
            "So what we what we do is now we break it."
        ],
        [
            "Up into a hierarchical model.",
            "So the same prior will now be represented in a hierarchical form.",
            "To make the posterior inference feasible.",
            "So in this case we use a normal gamma model where we represent the prior over beta in terms of a scale mixture of Gaussians, we use a gamma gamma distribution so.",
            "So it's it's yeah, it's a mixture of Gaussians with the mixture being in terms of a gamma distribution and we can solve that integral analytically and get back the multivariate Laplacian which was defined previously.",
            "So this is basically a representation of the same distribution but broken up in terms of a hierarchy.",
            "So if you look at this here, so we have these beetles which will be generated by the lambdas and lambdas.",
            "Again, our Lambda squares are parameterized by these rows.",
            "So we define another hyper prior on that conjugate hyper gamma, just parametrised by R&S.",
            "So we have this nice hierarchical model and the integration will be done based on the sampling process.",
            "OK."
        ],
        [
            "OK, so we had a simple regression problem and then we define a prior to enable grouped feature selection.",
            "So now we generalize the model.",
            "We go slightly beyond regression.",
            "We add another component in between to generalize it.",
            "So what that basically means is that your response was generated based on some distribution.",
            "Is on some distribution with mean Theta and your linear predictors.",
            "Here with.",
            "So they have random effect with normal 0 and then means you know Sigma squared variance.",
            "And the this particular predictor is now linked with the actual response through a link function.",
            "So in our case will use a person for this function.",
            "So then this will become exponential of ETA will be data.",
            "So in terms of the full model, we now we had earlier beta and we defined a prior based on hierarchical model which was this.",
            "So what we just added was Sigma Square.",
            "Because of this random effect and together with beta and X we generate the Zetas.",
            "And that based on a certain link function would finally generate the response.",
            "Which in our case would be count.",
            "OK.",
            "So now so we describe the model, so now we're going to apply."
        ],
        [
            "Two specifically to count data."
        ],
        [
            "OK, so contingency tables.",
            "So this is basically a table of counts where you have, let's say two variables.",
            "In this example X&Y.",
            "And these are categorical variables, so there are just categories or levels.",
            "So you have, let's say two categories high and low, high and low, and this these counts just represent how many times you observe this combination of values.",
            "And OK so you have this kind of table and so you can have it for a lot of variables.",
            "So the contingency table would basically be very huge.",
            "And for our case, the counts are random and our timing.",
            "Is fixed because you can model the count in different ways.",
            "You can model it mountain, multinomial etc.",
            "So but in our case the counts are random, but the time period is fixed in which the counts come, so we model it in, uh, we used person for modeling the accounts.",
            "So what that means in terms of the generalized linear model is that you generate the counts based on possible distribution and that is linked to the Zetas.",
            "Through T equal to eat exponential aveta.",
            "And these details are generated based on the covariates X.",
            "So that's how the response is finally generated.",
            "Based on these this input.",
            "So now in the context of categorical variables, the question is what is this X?",
            "That is, you have these counts, but these extras would basically be.",
            "A combination of.",
            "These values, that is you would say a certain combination of the categorical variable values gave rise to discount.",
            "So a design matrix X is constructed based on on this.",
            "So this is the construction of X, because here it's kind of little nonstandard.",
            "It's not that we observe some X, and we have those values to generate the counts.",
            "It's basically just a combination of values that these variables can take."
        ],
        [
            "And since they are categorical nature, we need to code them in a specific way.",
            "So let's say, OK, we have a variable which has four levels.",
            "So if you use a very simple dummy coding, you can code them in this way, which basically is some kind of selection on which value you're going to select, and hence this motivates the idea of group feature selection, because what we're doing here is we're splitting.",
            "One categorical variable into four columns.",
            "So now this whole this whole X matrix is now constructed based on these blocks of 4 four columns just for this example, and so these and these are just a single variables which would have these blocks.",
            "And if we choose to add."
        ],
        [
            "Higher order interaction terms.",
            "That is, we're not just interested in single features, we are interested in higher order interactions.",
            "So let's say first order interaction between, let's say feature one and feature 2.",
            "Then this would expand much more, because this can actually take 16 values.",
            "If this can take four values, then together these will take 16 values and.",
            "Hence you would need 16 more columns, so the columns would start blowing up.",
            "So therefore we will use more more efficient coding which will allow us to at least restrict the number of columns when we use higher order interactions.",
            "So take just taking that step forward.",
            "So what we had was we designed.",
            "We had a design matrix for the categorical variables where we had to split each variable into multiple columns.",
            "And we also add higher order interactions in our application.",
            "We just use interactions up to 2nd order.",
            "So we basically just analyze single features, pairwise interactions and triplets.",
            "And in terms of coding, we use polynomial contrast codes because they are suitable for our application in terms of.",
            "Since we measure intensity levels.",
            "So there is a certain order in the values.",
            "And Secondly, it avoids over parameterization, so it gives us minimum number of columns.",
            "You don't need all those columns to represent the categories.",
            "And most importantly, it is orthogonal in nature.",
            "So in the inference we requiere matrix inversion that can be avoided.",
            "The cause of this particular feature of the design matrix.",
            "And that is, basically, that's what makes the algorithm more efficient in this case, in the possible case.",
            "OK.",
            "So this this yeah, this is an example, like if there's a categorical variable file level, so it will be split in two K -- 1 columns.",
            "OK, so."
        ],
        [
            "In terms of inference, this is a standard Gibbs sampling, so we have.",
            "We have all these variables.",
            "So we sample from the joint based on the conditionals.",
            "Now, based on this definition, all the posterior conditions will be standard except this eater.",
            "Due to this, this term extra term here now for this again there are a lot of options for that.",
            "You can adapt rejection sampling, but we do a Laplace approximation which works out fine.",
            "So yeah, absolutely.",
            "So yeah, in this case, OK. OK."
        ],
        [
            "So in terms of experiments, so our whole motivate."
        ],
        [
            "And came from the biological side.",
            "So we are part of a computational pathology pipeline where we work in close Association with the medical partners so they they produce data based on the particular application, let's say cancer breast cancer data set.",
            "So they take tissue samples but use data.",
            "Then our colleague Thomas folks.",
            "He analyzes the images and together with the medical expertise we finally have the intensity levels protein intensity levels.",
            "And then we do our analysis and based on the result again, there are more biological experiments performed to to understand the results that are produced under this kind of inference.",
            "OK, so."
        ],
        [
            "Our application here is the breast cancer data set.",
            "It's the leading cause of tumor related death in women particularly invested countries.",
            "So the idea here is to find biomarkers which will help in prediction and personalized therapy as well.",
            "So and the technology used for generating data is immuno histo chemistry combined with tissue microarrays.",
            "So immunohistochemistry basically is a way to stain, stain the spots in order to measure the expression levels of proteins and it's very cost effective and done routinely.",
            "Tissue microarrays OK. You can analyze in parallel thousand tumors.",
            "And this, together with combining both these together.",
            "This is to accelerate studies because you can generate data very efficiently."
        ],
        [
            "OK, so this is just a rough overview of our tissue microarrays are you take primary samples from the cancerous tissue.",
            "Then you fill it into small cylinders and you slice off the top.",
            "So once you slice it off, you have this kind of slice, which is a lot of spots.",
            "And these are stained immunohistochemically an based on the protein that you want to study.",
            "And then these parts are analyzed based to judge the intensity level of the proteins.",
            "OK, so this was what we were studying.",
            "We were studying two patient groups.",
            "Uh, and."
        ],
        [
            "The idea was to find out the difference in the interaction terms between these two groups to see what proteins are more significant.",
            "Between these two groups.",
            "And the groups are divided based on risk, low risk at high risk.",
            "So there's a certain grading that pathologists do so.",
            "If we, if we look at the survival curves of these two groups so we can see this is the high risk group and this is the lowest group.",
            "So so I will drops very very quickly here.",
            "And OK, so the data the data set consists of lot of proteins but due to some prior knowledge from the doctors we could reduce that set to 7 particular proteins and they were more interested to focus on these seven proteins and with higher order interactions up to order 2.",
            "So so OK.",
            "So based on running this inference on this data set with these seven proteins and higher order interactions.",
            "So this is what we found in terms of the low risk and high risk group.",
            "So I'll explain the figure.",
            "So the circles indicate the main features.",
            "They're significant main features.",
            "The reddish triangles indicate the 2nd order interactions, that is triplets and the blue lines indicate the 1st order interactions.",
            "That is the pairwise interactions.",
            "So it was surprising for the doctors to see that.",
            "There are higher order interactions which becomes significant here because ideally they don't analyze the higher order interactions, they just looking at single features.",
            "So in this case they would have thought that OK CK56 KPN 2 and HE R2 would have been significant on their own, But here we have a strong second order interaction and.",
            "And there is in fact the HE R2 is not effective individually, so so that was very interesting and the same thing here where there's a strong pairwise interaction between these two.",
            "And you have a main effect here, but you don't really see a main effect here.",
            "So this this gives a kind of food for thought in terms of finding compound biomarkers rather than just single biomarkers.",
            "And we also compare it with a standard group lasso on personal likelihood.",
            "So this is the group norm and there's a relaxation constraint.",
            "So this is the solution path.",
            "So as you relax the constraint Moran you have more solutions that are popping up.",
            "So again, since we average over solutions, that's one advantage that we gain that OK in this we may find some more groups that may become active, but here since we average over solutions at least.",
            "At least we hope to.",
            "We hope that we're finding all these significant groups that we need to find.",
            "And OK, so this just shows a plot of these signals, posterior sampling, where this is this is for this particular interaction term that there are 90% of the samples were on positive side."
        ],
        [
            "And OK, just to summarize.",
            "So we have a Bayesian framework for group lasso to deal with count data specifically, and this is for feature selection for categorical variables because there we require a grouped feature selection.",
            "Then this has led to detection of novel compound biomarkers in the data set, so this is further being analyzed by the biologists to see the reason for this higher order interaction.",
            "And advantages are basically averages over solutions, gives us meaningful estimates and for the key thing is that we analyze higher order interactions which are which are interesting from a biological standpoint which may help us identify better compound biomarkers instead of just looking for a single biomarkers.",
            "And in terms of future work, this can be extended.",
            "The model can be extended to other kinds of data.",
            "Basically we just change the likelihood term so it can be extended to survival time using viable.",
            "Or you can use a beta distribution on the regional distribution.",
            "In terms of the in terms of feature selection, we can go beyond group who we can apply more sparse constraints.",
            "So on the lines of paper written by Karen Doucette.",
            "So this is where you can change the shape of the constraint rather than just the scale.",
            "And then, since so, since this has a, since the inference is done through Gibbs sampling, you can even add a clustering component to it where we can use the original processes to identify maybe clusters and do feature selection at the same time.",
            "Yeah."
        ],
        [
            "Thing is, that's about it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a rough path of the talk will start with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit of motivation then some basic introduction, then talk about feature selection.",
                    "label": 1
                },
                {
                    "sent": "And apply to contingency tables for count data.",
                    "label": 1
                },
                {
                    "sent": "And finally, we'll look at the biological application that motivated us for this method, and the results that we got out of the data set.",
                    "label": 0
                },
                {
                    "sent": "And finally, a summary and some future extensions that are possible.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in terms of motivation, so we work primarily with biological data, and we frequently encounter problems with feature selection.",
                    "label": 0
                },
                {
                    "sent": "So like finding novel biomarkers, it's generally there in cancer datasets.",
                    "label": 0
                },
                {
                    "sent": "And then all these measurements are generally in terms of categories or some intensity levels.",
                    "label": 0
                },
                {
                    "sent": "So these are categorical variables and will show that that leads to doing feature selection in groups of variables rather than just single single features.",
                    "label": 1
                },
                {
                    "sent": "And then we also encounter a lot of count data in medical applications and then in terms of the method we try to provide meaningful variance estimates in terms of the regression coefficients.",
                    "label": 1
                },
                {
                    "sent": "And we try to average over solutions rather than find just point estimates.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We just entered introduction standard linear regression problem Y = 2 X speedup closets island.",
                    "label": 1
                },
                {
                    "sent": "Then you can model it in different ways and generally we apply some kind of constraint on the regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "Basic version just have a likelihood you multiply it with a suitable prior on beta and you may have some more variables.",
                    "label": 0
                },
                {
                    "sent": "You can define some more hyper priors data and finally you're interested to have a posterior and you want to analyze the posterior.",
                    "label": 0
                },
                {
                    "sent": "Find either maximum estimate or average over solutions.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we look at this in.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the context of FICA.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Selection.",
                    "label": 0
                },
                {
                    "sent": "So I'll start with from the left side.",
                    "label": 0
                },
                {
                    "sent": "So in terms of feature selection you have, you can start with the cost function subject to an L1 norm, which is a lazy constraint.",
                    "label": 0
                },
                {
                    "sent": "And so last year there was some work done in a Bayesian context where the same thing was translated into a suitable prior which represents the lazoo constraint, which is basically a product of the Laplacian distributions over the regression coefficients.",
                    "label": 0
                },
                {
                    "sent": "So now what we've done is we've extended this to feature selection in groups.",
                    "label": 1
                },
                {
                    "sent": "So what we need is to apply a group luzu constraint which is smooth within the group and sparse between the groups.",
                    "label": 0
                },
                {
                    "sent": "So that results in you're optimizing a function with a constraint of some of the L2 norms over the beat's.",
                    "label": 0
                },
                {
                    "sent": "And then to define a suitable prior for this.",
                    "label": 0
                },
                {
                    "sent": "What we do is we just extend that idea forward an have multivariate Laplacian over the groups a product of multiple oppressions over the groups.",
                    "label": 0
                },
                {
                    "sent": "So we have this nice analytical form.",
                    "label": 0
                },
                {
                    "sent": "But inference would be it would not be feasible with this with this alone.",
                    "label": 0
                },
                {
                    "sent": "So what we what we do is now we break it.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Up into a hierarchical model.",
                    "label": 1
                },
                {
                    "sent": "So the same prior will now be represented in a hierarchical form.",
                    "label": 0
                },
                {
                    "sent": "To make the posterior inference feasible.",
                    "label": 0
                },
                {
                    "sent": "So in this case we use a normal gamma model where we represent the prior over beta in terms of a scale mixture of Gaussians, we use a gamma gamma distribution so.",
                    "label": 0
                },
                {
                    "sent": "So it's it's yeah, it's a mixture of Gaussians with the mixture being in terms of a gamma distribution and we can solve that integral analytically and get back the multivariate Laplacian which was defined previously.",
                    "label": 0
                },
                {
                    "sent": "So this is basically a representation of the same distribution but broken up in terms of a hierarchy.",
                    "label": 0
                },
                {
                    "sent": "So if you look at this here, so we have these beetles which will be generated by the lambdas and lambdas.",
                    "label": 0
                },
                {
                    "sent": "Again, our Lambda squares are parameterized by these rows.",
                    "label": 0
                },
                {
                    "sent": "So we define another hyper prior on that conjugate hyper gamma, just parametrised by R&S.",
                    "label": 0
                },
                {
                    "sent": "So we have this nice hierarchical model and the integration will be done based on the sampling process.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we had a simple regression problem and then we define a prior to enable grouped feature selection.",
                    "label": 0
                },
                {
                    "sent": "So now we generalize the model.",
                    "label": 0
                },
                {
                    "sent": "We go slightly beyond regression.",
                    "label": 0
                },
                {
                    "sent": "We add another component in between to generalize it.",
                    "label": 0
                },
                {
                    "sent": "So what that basically means is that your response was generated based on some distribution.",
                    "label": 0
                },
                {
                    "sent": "Is on some distribution with mean Theta and your linear predictors.",
                    "label": 0
                },
                {
                    "sent": "Here with.",
                    "label": 0
                },
                {
                    "sent": "So they have random effect with normal 0 and then means you know Sigma squared variance.",
                    "label": 0
                },
                {
                    "sent": "And the this particular predictor is now linked with the actual response through a link function.",
                    "label": 0
                },
                {
                    "sent": "So in our case will use a person for this function.",
                    "label": 0
                },
                {
                    "sent": "So then this will become exponential of ETA will be data.",
                    "label": 0
                },
                {
                    "sent": "So in terms of the full model, we now we had earlier beta and we defined a prior based on hierarchical model which was this.",
                    "label": 0
                },
                {
                    "sent": "So what we just added was Sigma Square.",
                    "label": 0
                },
                {
                    "sent": "Because of this random effect and together with beta and X we generate the Zetas.",
                    "label": 0
                },
                {
                    "sent": "And that based on a certain link function would finally generate the response.",
                    "label": 1
                },
                {
                    "sent": "Which in our case would be count.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now so we describe the model, so now we're going to apply.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two specifically to count data.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so contingency tables.",
                    "label": 0
                },
                {
                    "sent": "So this is basically a table of counts where you have, let's say two variables.",
                    "label": 0
                },
                {
                    "sent": "In this example X&Y.",
                    "label": 0
                },
                {
                    "sent": "And these are categorical variables, so there are just categories or levels.",
                    "label": 1
                },
                {
                    "sent": "So you have, let's say two categories high and low, high and low, and this these counts just represent how many times you observe this combination of values.",
                    "label": 0
                },
                {
                    "sent": "And OK so you have this kind of table and so you can have it for a lot of variables.",
                    "label": 0
                },
                {
                    "sent": "So the contingency table would basically be very huge.",
                    "label": 0
                },
                {
                    "sent": "And for our case, the counts are random and our timing.",
                    "label": 0
                },
                {
                    "sent": "Is fixed because you can model the count in different ways.",
                    "label": 0
                },
                {
                    "sent": "You can model it mountain, multinomial etc.",
                    "label": 0
                },
                {
                    "sent": "So but in our case the counts are random, but the time period is fixed in which the counts come, so we model it in, uh, we used person for modeling the accounts.",
                    "label": 1
                },
                {
                    "sent": "So what that means in terms of the generalized linear model is that you generate the counts based on possible distribution and that is linked to the Zetas.",
                    "label": 0
                },
                {
                    "sent": "Through T equal to eat exponential aveta.",
                    "label": 0
                },
                {
                    "sent": "And these details are generated based on the covariates X.",
                    "label": 0
                },
                {
                    "sent": "So that's how the response is finally generated.",
                    "label": 0
                },
                {
                    "sent": "Based on these this input.",
                    "label": 0
                },
                {
                    "sent": "So now in the context of categorical variables, the question is what is this X?",
                    "label": 0
                },
                {
                    "sent": "That is, you have these counts, but these extras would basically be.",
                    "label": 0
                },
                {
                    "sent": "A combination of.",
                    "label": 0
                },
                {
                    "sent": "These values, that is you would say a certain combination of the categorical variable values gave rise to discount.",
                    "label": 0
                },
                {
                    "sent": "So a design matrix X is constructed based on on this.",
                    "label": 0
                },
                {
                    "sent": "So this is the construction of X, because here it's kind of little nonstandard.",
                    "label": 0
                },
                {
                    "sent": "It's not that we observe some X, and we have those values to generate the counts.",
                    "label": 0
                },
                {
                    "sent": "It's basically just a combination of values that these variables can take.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And since they are categorical nature, we need to code them in a specific way.",
                    "label": 0
                },
                {
                    "sent": "So let's say, OK, we have a variable which has four levels.",
                    "label": 0
                },
                {
                    "sent": "So if you use a very simple dummy coding, you can code them in this way, which basically is some kind of selection on which value you're going to select, and hence this motivates the idea of group feature selection, because what we're doing here is we're splitting.",
                    "label": 0
                },
                {
                    "sent": "One categorical variable into four columns.",
                    "label": 0
                },
                {
                    "sent": "So now this whole this whole X matrix is now constructed based on these blocks of 4 four columns just for this example, and so these and these are just a single variables which would have these blocks.",
                    "label": 0
                },
                {
                    "sent": "And if we choose to add.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Higher order interaction terms.",
                    "label": 0
                },
                {
                    "sent": "That is, we're not just interested in single features, we are interested in higher order interactions.",
                    "label": 0
                },
                {
                    "sent": "So let's say first order interaction between, let's say feature one and feature 2.",
                    "label": 0
                },
                {
                    "sent": "Then this would expand much more, because this can actually take 16 values.",
                    "label": 0
                },
                {
                    "sent": "If this can take four values, then together these will take 16 values and.",
                    "label": 0
                },
                {
                    "sent": "Hence you would need 16 more columns, so the columns would start blowing up.",
                    "label": 0
                },
                {
                    "sent": "So therefore we will use more more efficient coding which will allow us to at least restrict the number of columns when we use higher order interactions.",
                    "label": 0
                },
                {
                    "sent": "So take just taking that step forward.",
                    "label": 0
                },
                {
                    "sent": "So what we had was we designed.",
                    "label": 0
                },
                {
                    "sent": "We had a design matrix for the categorical variables where we had to split each variable into multiple columns.",
                    "label": 0
                },
                {
                    "sent": "And we also add higher order interactions in our application.",
                    "label": 1
                },
                {
                    "sent": "We just use interactions up to 2nd order.",
                    "label": 0
                },
                {
                    "sent": "So we basically just analyze single features, pairwise interactions and triplets.",
                    "label": 0
                },
                {
                    "sent": "And in terms of coding, we use polynomial contrast codes because they are suitable for our application in terms of.",
                    "label": 1
                },
                {
                    "sent": "Since we measure intensity levels.",
                    "label": 0
                },
                {
                    "sent": "So there is a certain order in the values.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, it avoids over parameterization, so it gives us minimum number of columns.",
                    "label": 0
                },
                {
                    "sent": "You don't need all those columns to represent the categories.",
                    "label": 1
                },
                {
                    "sent": "And most importantly, it is orthogonal in nature.",
                    "label": 1
                },
                {
                    "sent": "So in the inference we requiere matrix inversion that can be avoided.",
                    "label": 0
                },
                {
                    "sent": "The cause of this particular feature of the design matrix.",
                    "label": 0
                },
                {
                    "sent": "And that is, basically, that's what makes the algorithm more efficient in this case, in the possible case.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this this yeah, this is an example, like if there's a categorical variable file level, so it will be split in two K -- 1 columns.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of inference, this is a standard Gibbs sampling, so we have.",
                    "label": 0
                },
                {
                    "sent": "We have all these variables.",
                    "label": 0
                },
                {
                    "sent": "So we sample from the joint based on the conditionals.",
                    "label": 0
                },
                {
                    "sent": "Now, based on this definition, all the posterior conditions will be standard except this eater.",
                    "label": 0
                },
                {
                    "sent": "Due to this, this term extra term here now for this again there are a lot of options for that.",
                    "label": 0
                },
                {
                    "sent": "You can adapt rejection sampling, but we do a Laplace approximation which works out fine.",
                    "label": 1
                },
                {
                    "sent": "So yeah, absolutely.",
                    "label": 0
                },
                {
                    "sent": "So yeah, in this case, OK. OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in terms of experiments, so our whole motivate.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And came from the biological side.",
                    "label": 0
                },
                {
                    "sent": "So we are part of a computational pathology pipeline where we work in close Association with the medical partners so they they produce data based on the particular application, let's say cancer breast cancer data set.",
                    "label": 0
                },
                {
                    "sent": "So they take tissue samples but use data.",
                    "label": 0
                },
                {
                    "sent": "Then our colleague Thomas folks.",
                    "label": 0
                },
                {
                    "sent": "He analyzes the images and together with the medical expertise we finally have the intensity levels protein intensity levels.",
                    "label": 0
                },
                {
                    "sent": "And then we do our analysis and based on the result again, there are more biological experiments performed to to understand the results that are produced under this kind of inference.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our application here is the breast cancer data set.",
                    "label": 1
                },
                {
                    "sent": "It's the leading cause of tumor related death in women particularly invested countries.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is to find biomarkers which will help in prediction and personalized therapy as well.",
                    "label": 0
                },
                {
                    "sent": "So and the technology used for generating data is immuno histo chemistry combined with tissue microarrays.",
                    "label": 0
                },
                {
                    "sent": "So immunohistochemistry basically is a way to stain, stain the spots in order to measure the expression levels of proteins and it's very cost effective and done routinely.",
                    "label": 0
                },
                {
                    "sent": "Tissue microarrays OK. You can analyze in parallel thousand tumors.",
                    "label": 1
                },
                {
                    "sent": "And this, together with combining both these together.",
                    "label": 0
                },
                {
                    "sent": "This is to accelerate studies because you can generate data very efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is just a rough overview of our tissue microarrays are you take primary samples from the cancerous tissue.",
                    "label": 1
                },
                {
                    "sent": "Then you fill it into small cylinders and you slice off the top.",
                    "label": 0
                },
                {
                    "sent": "So once you slice it off, you have this kind of slice, which is a lot of spots.",
                    "label": 1
                },
                {
                    "sent": "And these are stained immunohistochemically an based on the protein that you want to study.",
                    "label": 0
                },
                {
                    "sent": "And then these parts are analyzed based to judge the intensity level of the proteins.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was what we were studying.",
                    "label": 0
                },
                {
                    "sent": "We were studying two patient groups.",
                    "label": 0
                },
                {
                    "sent": "Uh, and.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea was to find out the difference in the interaction terms between these two groups to see what proteins are more significant.",
                    "label": 0
                },
                {
                    "sent": "Between these two groups.",
                    "label": 0
                },
                {
                    "sent": "And the groups are divided based on risk, low risk at high risk.",
                    "label": 0
                },
                {
                    "sent": "So there's a certain grading that pathologists do so.",
                    "label": 0
                },
                {
                    "sent": "If we, if we look at the survival curves of these two groups so we can see this is the high risk group and this is the lowest group.",
                    "label": 0
                },
                {
                    "sent": "So so I will drops very very quickly here.",
                    "label": 0
                },
                {
                    "sent": "And OK, so the data the data set consists of lot of proteins but due to some prior knowledge from the doctors we could reduce that set to 7 particular proteins and they were more interested to focus on these seven proteins and with higher order interactions up to order 2.",
                    "label": 1
                },
                {
                    "sent": "So so OK.",
                    "label": 0
                },
                {
                    "sent": "So based on running this inference on this data set with these seven proteins and higher order interactions.",
                    "label": 0
                },
                {
                    "sent": "So this is what we found in terms of the low risk and high risk group.",
                    "label": 1
                },
                {
                    "sent": "So I'll explain the figure.",
                    "label": 0
                },
                {
                    "sent": "So the circles indicate the main features.",
                    "label": 0
                },
                {
                    "sent": "They're significant main features.",
                    "label": 0
                },
                {
                    "sent": "The reddish triangles indicate the 2nd order interactions, that is triplets and the blue lines indicate the 1st order interactions.",
                    "label": 0
                },
                {
                    "sent": "That is the pairwise interactions.",
                    "label": 0
                },
                {
                    "sent": "So it was surprising for the doctors to see that.",
                    "label": 0
                },
                {
                    "sent": "There are higher order interactions which becomes significant here because ideally they don't analyze the higher order interactions, they just looking at single features.",
                    "label": 0
                },
                {
                    "sent": "So in this case they would have thought that OK CK56 KPN 2 and HE R2 would have been significant on their own, But here we have a strong second order interaction and.",
                    "label": 0
                },
                {
                    "sent": "And there is in fact the HE R2 is not effective individually, so so that was very interesting and the same thing here where there's a strong pairwise interaction between these two.",
                    "label": 0
                },
                {
                    "sent": "And you have a main effect here, but you don't really see a main effect here.",
                    "label": 0
                },
                {
                    "sent": "So this this gives a kind of food for thought in terms of finding compound biomarkers rather than just single biomarkers.",
                    "label": 0
                },
                {
                    "sent": "And we also compare it with a standard group lasso on personal likelihood.",
                    "label": 0
                },
                {
                    "sent": "So this is the group norm and there's a relaxation constraint.",
                    "label": 0
                },
                {
                    "sent": "So this is the solution path.",
                    "label": 0
                },
                {
                    "sent": "So as you relax the constraint Moran you have more solutions that are popping up.",
                    "label": 0
                },
                {
                    "sent": "So again, since we average over solutions, that's one advantage that we gain that OK in this we may find some more groups that may become active, but here since we average over solutions at least.",
                    "label": 0
                },
                {
                    "sent": "At least we hope to.",
                    "label": 0
                },
                {
                    "sent": "We hope that we're finding all these significant groups that we need to find.",
                    "label": 0
                },
                {
                    "sent": "And OK, so this just shows a plot of these signals, posterior sampling, where this is this is for this particular interaction term that there are 90% of the samples were on positive side.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And OK, just to summarize.",
                    "label": 0
                },
                {
                    "sent": "So we have a Bayesian framework for group lasso to deal with count data specifically, and this is for feature selection for categorical variables because there we require a grouped feature selection.",
                    "label": 1
                },
                {
                    "sent": "Then this has led to detection of novel compound biomarkers in the data set, so this is further being analyzed by the biologists to see the reason for this higher order interaction.",
                    "label": 0
                },
                {
                    "sent": "And advantages are basically averages over solutions, gives us meaningful estimates and for the key thing is that we analyze higher order interactions which are which are interesting from a biological standpoint which may help us identify better compound biomarkers instead of just looking for a single biomarkers.",
                    "label": 1
                },
                {
                    "sent": "And in terms of future work, this can be extended.",
                    "label": 0
                },
                {
                    "sent": "The model can be extended to other kinds of data.",
                    "label": 0
                },
                {
                    "sent": "Basically we just change the likelihood term so it can be extended to survival time using viable.",
                    "label": 0
                },
                {
                    "sent": "Or you can use a beta distribution on the regional distribution.",
                    "label": 0
                },
                {
                    "sent": "In terms of the in terms of feature selection, we can go beyond group who we can apply more sparse constraints.",
                    "label": 0
                },
                {
                    "sent": "So on the lines of paper written by Karen Doucette.",
                    "label": 0
                },
                {
                    "sent": "So this is where you can change the shape of the constraint rather than just the scale.",
                    "label": 0
                },
                {
                    "sent": "And then, since so, since this has a, since the inference is done through Gibbs sampling, you can even add a clustering component to it where we can use the original processes to identify maybe clusters and do feature selection at the same time.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing is, that's about it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}