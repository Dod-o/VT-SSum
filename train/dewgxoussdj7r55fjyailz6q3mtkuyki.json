{
    "id": "dewgxoussdj7r55fjyailz6q3mtkuyki",
    "title": "Poster Spotlights",
    "info": {
        "author": [
            "Vasu Parameswaran, Siemens Corporate Research",
            "Konstantinos Derpanis, Centre for Vision Research, York University",
            "Liangliang Cao, Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign",
            "Pradeep Natarajan, BBN technologies",
            "Fabian Nater, Department of Information Technology and Electrical Engineering, ETH Zurich",
            "Antoni Chan, Department of Computer Science, City University of Hong Kong",
            "Weilong Yang, School of Computing Science, Simon Fraser University",
            "Ruonan Li, Department of Electrical and Computer Engineering, University of Maryland",
            "Adriana Kovashka, Department of Computer Science, University of Texas at Austin",
            "Shandong Wu, School of Electrical Engineering and Computer Science, University of Central Florida",
            "Angela Yao, Department of Information Technology and Electrical Engineering, ETH Zurich",
            "Imran Saleemi, Department of Electrical Engineering and Computer Science, University of Central Florida",
            "Michalis Raptis, Computer Science Department, University of California, Los Angeles, UCLA"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Video Analysis"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_spotlights7a/",
    "segmentation": [
        [
            "Everybody, my name is 1 super permission from Siemens Corporate Research and I'm going to be talking a little bit about our work on illumination compensation based change detection using order consistency and this is joint work with Manish Singh and Vision or mission."
        ],
        [
            "So the main problem that we're trying to solve here is changed direction from static camera in the presence of a large number of illumination changes as well as a significant number of outliers in the scene.",
            "So this date of the art in this little area is to either data invariants, which unfortunately lose a lot of information or or to use a tech tech tech detection blocks, which unfortunately cannot really work for homogeneous blocks.",
            "So actually, if you really want to clean segmentation of the foreground background in the presence of illumination change, you may not be able to use.",
            "This method is very well, so actually what we do is that we generally generatively modeled illumination change between.",
            "The pair of images and we also show how we can make a low dimensional approximation termination change model.",
            "We also show how we can effectively use the method of rank order consistency in order to estimate the illumination change para meters and and once we have the elimination change, we apply the elevation change compensation to one of the images to make it look like the other one and after that we can compare the images in the original intensity space.",
            "So as an example here on the left side you can see CMT seen on the.",
            "Middle image you can see you can see that there are new people in the scene as well as a large elimination change.",
            "And after we do the elimination compensation based approach, we actually get to change map that you see on the right side.",
            "So if you're interested in this work, please do please do stop by the poster where we can explain a little bit more about the method and we can also show you our OC curves.",
            "Another image examples as well.",
            "Thank you."
        ],
        [
            "So good afternoon, my name is costed repanis from York University in Toronto, Canada.",
            "So the basic goal of our work is to detect and spatial temporal."
        ],
        [
            "Localized in action in a video sequence.",
            "We call this the action spotting problem to ground.",
            "This cool.",
            "Let's just take a look at the videos on the right.",
            "So at the top we have a video snippet that captures a particular action.",
            "So in this case a spin left action and at the bottom we have several actions.",
            "Spotting results the bounding boxes over here denote the spotted actions and also note that we are looking for several actions in this case.",
            "So not only in the spin left but also the swatting action.",
            "So there are several.",
            "Several main challenges in this approach, the first being that the same action yields wildly different image intensity patterns, so this can be caused for example by differences in clothing and also differences in spatial temporal scale.",
            "Another challenge in this work is the presence of distracting clutter and also with an eye towards real time application.",
            "Another challenge in this work is computational efficiency.",
            "So in the light of these various challenges, our approach consists of the following.",
            "First, we propose a novel compact feature set.",
            "This is based on 3D XYT orientation measurements, and in addition, in addition, we propose a similarity measure that admits fast search.",
            "And finally we successfully evaluated our approach on a wide range of challenging natural videos, and for those interested I'll be showing the video results at the poster session."
        ],
        [
            "Hi good afternoon.",
            "My name is my name is young Chow and I'm going to introduce our work on crossed set the video action detection."
        ],
        [
            "It's working, it's a collaborative, it's doctors only under Professor Thomas Long.",
            "The problem?",
            "The problem across data set action detection is important, especially in surveillance because in surveillance in traditional settings we need when I'm new to the settings given we need labeled retrained model and labeled new data set.",
            "Higher labeling process can be very expensive and can be very time consuming.",
            "We aim to alleviate this problem by training data training.",
            "Although in a South data set, but and then adopt model to a more complex data set without GNU label involved and we called a simple data set is Southeast set and called Target.",
            "The nudist at Target.",
            "Our solution is to build framework which combines the action detection and the model definition into a MLP estimation framework.",
            "Consider not only the spatial coherence but also the action detection.",
            "From the model prior in the South to set and we train our model on Cth data, set and pass our model on new two different challenging datasets.",
            "The first data set is coming is that come from from checking.",
            "Wait surveillance data, set the first the curve in the corner shows that I'm sorry."
        ],
        [
            "OK. Good afternoon everyone.",
            "I'm Pradeep from Raytheon.",
            "BBN technologies."
        ],
        [
            "I'm presenting our work on learning 3D action models from a few 2D videos.",
            "I did this work while I was at USC with my colleagues Vivek Singh and Professor Amnon Bhatia.",
            "In our work, we use Dynamic Bashan, Action Network, Switch, Mapper action models to a Debian.",
            "We model actions hierarchically at the primitive and composite event levels.",
            "The key motivation of our approach is to minimize training requirements by using formal action models, existing bag of words, style approaches required, large training sets for the models to generalize well, while recent methods that use mocap data record costly infrastructure to collect the training data.",
            "In contrast, our approach requires annotation of about five key poses in a few videos about two or three for each action.",
            "We recognize actions in our videos by sampling from our action models.",
            "We show results on data set collected in a real grocery store.",
            "Also for gesture recognition and in the standard basement data set on the Weisman data set, we get close to 99.5% accuracy, which is about state of the art.",
            "With just two to three training examples and 96% accuracy with just one training example.",
            "Please come to our poster number F8 for more details.",
            "Thank you."
        ],
        [
            "Hello, our papers about exploiting simple hierarchies for unsupervised behavior analysis.",
            "My name is Fabian Arthur.",
            "This is work together with Helmut Gardner and look one goal."
        ],
        [
            "The details are weak.",
            "So our target setting or one of our target setting is the monitoring of people in their living rooms.",
            "A camera is mounted somewhere and then we want to analyze what the people or the person is doing inside this room.",
            "Our model is successfully able to track the person throughout this scene.",
            "Normal events or else as you can see in green or are successfully recognized that such like walking, walking, behind, occluding objects or sitting.",
            "If something abnormal is happening like to jump over the sofa, the waving or the fall in the bottom.",
            "This is recognized as well.",
            "Since arguably not all events or not all actions that we can expect can be trained in the beginning, our model can be updated such that the lying, for example, which was not in the model first can be recognized then afterwards.",
            "So this is an unsupervised model which basically consists of two simple hierarchies.",
            "One hierarchy is analyzing appearance, the second hierarchy is analyzing the sequence of these appearances or the actions, so we're happy to be here and happy to show you more insights at poster session.",
            "Thanks."
        ],
        [
            "Hi, I'm Anthony Chan from City University of Hong Kong.",
            "This is joint work with a manually coviello and greatly increased from UC San Diego.",
            "So."
        ],
        [
            "The idea of this paper is we're interested in clustering dynamic textures.",
            "Into some groups, and then we also want to learn some novel representation of these dynamic texture centers.",
            "So the way we do this is we extend something called the hierarchical EM algorithm to probabilistic models with hidden state spaces.",
            "So you can use this fancy algorithm for a few things, and we present three applications in the paper.",
            "The first is we do hierarchical clustering of motion, basically by successively applying the ATM on the DTS.",
            "We also do semantic motion annotation or semantic texture annotation.",
            "This is similar to like image annotation with supervised multiclass labeling.",
            "We basically treat the annotation model as a DT mixture and then we aggregate over a large weakly labeled data set using ATM and the final application is on generating code books for a bag of systems representation which was introduced last CPR and in this.",
            "We basically represent each video volume as a DT and then we cluster DTS with HDM and use the novelty centers as the code words.",
            "So you can come to our poster and see our applications and in future work.",
            "We're thinking about using this same framework to cluster general graphical models, so you can think of maybe doing a bag of hmm representation or bag of X or your favorite latent variable model.",
            "So thanks."
        ],
        [
            "This is with only the title.",
            "Is the recognizing human actions from since their invention with latent post.",
            "This is joint work with young One and Greg Mori from some freezer."
        ],
        [
            "And our final goal is to infer the action of the person from single image.",
            "We treat human post as a latent variable, and when it comes to the action recognition, not all parts of the human body are equally important.",
            "For example, The Walking and play golf actions and the main differences between these actions.",
            "The Arms Play Golf is more like the V shape.",
            "Our man walking seems to have the arm hanging on the side of the body.",
            "The posting our system is learned in a way that is directly tide to the hour angle of action recognition.",
            "The whole system you learn under the framework of latent.",
            "Doctor SVM our experimental results demonstrate that by using the latent poses, the performance of action recognition can be improved.",
            "Since our final goal is actually recognition, we are not aiming to correctly localized body parts, but rather focus on localized body processes that are useful for the action recognition.",
            "So from the visualization of the latent poses, we can observe that for the sitting action our model almost always correctly localized legs which are extremely distinctive for this action.",
            "So another example is The Walking actions for this action.",
            "Is our model can correctly localized arms hanging on the two sides?",
            "Two sides of the torso?",
            "So if you're interested you can come stop by our poster, thanks."
        ],
        [
            "So I don't think anybody would think I'm wrong.",
            "Marshall, APA, and this type of my time I turn on my work.",
            "Here is group motion segmentation using spatial temporal driving force model and so in this picture you will see some."
        ],
        [
            "My players and you will see some directory's an on the left button to you will see some lines on some manifolds and on the right to your right and you will see some potential of the field and some vector fields.",
            "So the work is spread generally to show you how artists are related to each other.",
            "But this is not the key point.",
            "The key point is that we want to show you that something called group motion segmentation emerged from the multi object activity analysis and we propose the solution for that.",
            "So the problem is that we want to ask the question which objects correspond to the relevant motion of interests only using motion trajectory information.",
            "So in the context of football player, we want to answer who are the offensive players.",
            "So if you are tired of watching too many soccer games these days come this evening for something different.",
            "Thank you."
        ],
        [
            "Hi everyone, my name is Adriana Kubaska and I'm here to present my work on activity recognition using groupings of local spatial temporal features which is joined with my."
        ],
        [
            "Kaiser Christian ground at the University of Texas at Austin.",
            "So a common approach to action recognition involves the use of local spacetime interest points and features, but when used individually these can be 2 local.",
            "So the problem we're trying to solve is how to flexibly group these features for action recognition in order to capture relative spatial temporal relationships in a video.",
            "Or specifically, we want to capture weak spatial temporal information and learn a higher sorry.",
            "Using neighborhoods of features that can be a variable shapes that reflect the different sparsity of points.",
            "As you can see in this image at the top.",
            "Then we're going to learn a hierarchy of these discriminative neighborhoods in order to capture a spatial temporal information at different granularities.",
            "As you can see in the image in the bottom, we start with the raw features, then group these into neighborhood extent in both space and time, and group these further.",
            "We achieve state of their performance on the KTH human action data set in the UC F sports datasets.",
            "So if you're interested in action.",
            "Ignition and local spatial temporal features.",
            "Please come to our poster session.",
            "Thank you."
        ],
        [
            "Papa John's North buddy.",
            "My name is Shanda moot.",
            "Easy to join the work we provide more.",
            "Adam Black shar.",
            "Our worker is also about anomaly detection in crowd scenes."
        ],
        [
            "So the most exciting part of our approach can be seen from these two figures, which demonstrates our idea on how to use clustered particle trajectories to represent or to model crowd scenes.",
            "Actually arbitrarily crowded scenes.",
            "Also print out that while we're using motion trajectories, we are not using any kind of traditional tracking measure to acquire these transitory's.",
            "Instead, our method is based particle election followed by a clustering step.",
            "Also we're using Chronicle features to further identify the underlying dynamics of crowded scenes have based on that we will be able to using probabilistic model based method to 1st detect detect as in localized anomalies in crowd scenes.",
            "So in short this work is a unique utilization of lounging particle dynamics plus chronic invariants of choice and we propose this representative transitory zazen.",
            "You modeling element for.",
            "These cry being crowded scenes.",
            "So for more details and videos result please come to their poster.",
            "Thank you."
        ],
        [
            "Good afternoon, my name is Angela and I'm here to present some work on human action recognition and this is work that I did in collaboration with Juergen Gollan look fungal."
        ],
        [
            "TH Zurich.",
            "And so our objective here is to take a video.",
            "Maybe it's moving and there's several people in the video and we want to know well, what are these people doing and where and when are they doing this in the video?",
            "And we do this with the two stage approach.",
            "First by tracking tracking by detection.",
            "As you can see on the left and then to classify the peoples actions we use a half transform based voting framework and we extract 3D patches from the tracks represented by the color cubes on the left there.",
            "And then we train a random forest.",
            "To map the 3D patches to the spatial temporal, an action class center in the half space, and we apply our system to a variety of action recognition scenarios such as sports.",
            "As you see on the top right there, and also surveillance types of videos as well.",
            "So I look forward to meeting you at my poster and showing some of the results."
        ],
        [
            "Hello my name is Imran Salimi and this is a combined work with Lance Hartung of University of Wisconsin, Madison and my advisor Mubarak Shah.",
            "The problem."
        ],
        [
            "That we are trying to address as the estimation of motion patterns where the statistical description using low level features, for example optical flow and we want to avoid tracking an object level representation, another main contribution of our method is that we do not use similarity measures.",
            "For example Co occurrence, which are invariant which are inherent to El Dia type approaches and we define a new similarity measures which based on emotion model which allows us to do a hierarchical clustering of optical flow and special locations in 4 dimensional space.",
            "To get a mixture of Gaussians representation which can then be marginalized or we can find an expected flow of expected conditional expectation of optical flow for scene analysis.",
            "The applications of these are motion prior for tracking anomaly detection and persistent tracking through occlusions.",
            "So please come to our poster For more information.",
            "Thank you."
        ],
        [
            "Hello, I'm Alex raptis.",
            "In this work we decompose the variability of action pipe."
        ],
        [
            "In scene 2 components, the actor and the action, the actor is there being represented by a dynamic system and the action by the excitation signal of the system.",
            "For instance, if we have.",
            "The dynamic model of an older person.",
            "This will be different from the dynamic model of young person, however, the excitation signals for a common action will be similar since this is what defines the timing and the temporal order of the movement.",
            "So our intuition is by this decomposition we can reduce the variability that.",
            "It signals that represent actions have an.",
            "We improve the classification performance.",
            "However, this problem is imposed so we we tackle a blind system identification problem and we use sparse priors to.",
            "To determine the input signal.",
            "In this way, we have a distinct signature signature for each action an we allow ourselves to do supervised classification functions and unsupervised segmentation of axioms.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody, my name is 1 super permission from Siemens Corporate Research and I'm going to be talking a little bit about our work on illumination compensation based change detection using order consistency and this is joint work with Manish Singh and Vision or mission.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main problem that we're trying to solve here is changed direction from static camera in the presence of a large number of illumination changes as well as a significant number of outliers in the scene.",
                    "label": 0
                },
                {
                    "sent": "So this date of the art in this little area is to either data invariants, which unfortunately lose a lot of information or or to use a tech tech tech detection blocks, which unfortunately cannot really work for homogeneous blocks.",
                    "label": 0
                },
                {
                    "sent": "So actually, if you really want to clean segmentation of the foreground background in the presence of illumination change, you may not be able to use.",
                    "label": 0
                },
                {
                    "sent": "This method is very well, so actually what we do is that we generally generatively modeled illumination change between.",
                    "label": 1
                },
                {
                    "sent": "The pair of images and we also show how we can make a low dimensional approximation termination change model.",
                    "label": 1
                },
                {
                    "sent": "We also show how we can effectively use the method of rank order consistency in order to estimate the illumination change para meters and and once we have the elimination change, we apply the elevation change compensation to one of the images to make it look like the other one and after that we can compare the images in the original intensity space.",
                    "label": 0
                },
                {
                    "sent": "So as an example here on the left side you can see CMT seen on the.",
                    "label": 0
                },
                {
                    "sent": "Middle image you can see you can see that there are new people in the scene as well as a large elimination change.",
                    "label": 0
                },
                {
                    "sent": "And after we do the elimination compensation based approach, we actually get to change map that you see on the right side.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in this work, please do please do stop by the poster where we can explain a little bit more about the method and we can also show you our OC curves.",
                    "label": 0
                },
                {
                    "sent": "Another image examples as well.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So good afternoon, my name is costed repanis from York University in Toronto, Canada.",
                    "label": 0
                },
                {
                    "sent": "So the basic goal of our work is to detect and spatial temporal.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Localized in action in a video sequence.",
                    "label": 0
                },
                {
                    "sent": "We call this the action spotting problem to ground.",
                    "label": 0
                },
                {
                    "sent": "This cool.",
                    "label": 0
                },
                {
                    "sent": "Let's just take a look at the videos on the right.",
                    "label": 0
                },
                {
                    "sent": "So at the top we have a video snippet that captures a particular action.",
                    "label": 0
                },
                {
                    "sent": "So in this case a spin left action and at the bottom we have several actions.",
                    "label": 1
                },
                {
                    "sent": "Spotting results the bounding boxes over here denote the spotted actions and also note that we are looking for several actions in this case.",
                    "label": 0
                },
                {
                    "sent": "So not only in the spin left but also the swatting action.",
                    "label": 0
                },
                {
                    "sent": "So there are several.",
                    "label": 0
                },
                {
                    "sent": "Several main challenges in this approach, the first being that the same action yields wildly different image intensity patterns, so this can be caused for example by differences in clothing and also differences in spatial temporal scale.",
                    "label": 1
                },
                {
                    "sent": "Another challenge in this work is the presence of distracting clutter and also with an eye towards real time application.",
                    "label": 0
                },
                {
                    "sent": "Another challenge in this work is computational efficiency.",
                    "label": 1
                },
                {
                    "sent": "So in the light of these various challenges, our approach consists of the following.",
                    "label": 0
                },
                {
                    "sent": "First, we propose a novel compact feature set.",
                    "label": 1
                },
                {
                    "sent": "This is based on 3D XYT orientation measurements, and in addition, in addition, we propose a similarity measure that admits fast search.",
                    "label": 0
                },
                {
                    "sent": "And finally we successfully evaluated our approach on a wide range of challenging natural videos, and for those interested I'll be showing the video results at the poster session.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi good afternoon.",
                    "label": 0
                },
                {
                    "sent": "My name is my name is young Chow and I'm going to introduce our work on crossed set the video action detection.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's working, it's a collaborative, it's doctors only under Professor Thomas Long.",
                    "label": 0
                },
                {
                    "sent": "The problem?",
                    "label": 0
                },
                {
                    "sent": "The problem across data set action detection is important, especially in surveillance because in surveillance in traditional settings we need when I'm new to the settings given we need labeled retrained model and labeled new data set.",
                    "label": 0
                },
                {
                    "sent": "Higher labeling process can be very expensive and can be very time consuming.",
                    "label": 0
                },
                {
                    "sent": "We aim to alleviate this problem by training data training.",
                    "label": 0
                },
                {
                    "sent": "Although in a South data set, but and then adopt model to a more complex data set without GNU label involved and we called a simple data set is Southeast set and called Target.",
                    "label": 0
                },
                {
                    "sent": "The nudist at Target.",
                    "label": 0
                },
                {
                    "sent": "Our solution is to build framework which combines the action detection and the model definition into a MLP estimation framework.",
                    "label": 0
                },
                {
                    "sent": "Consider not only the spatial coherence but also the action detection.",
                    "label": 0
                },
                {
                    "sent": "From the model prior in the South to set and we train our model on Cth data, set and pass our model on new two different challenging datasets.",
                    "label": 0
                },
                {
                    "sent": "The first data set is coming is that come from from checking.",
                    "label": 0
                },
                {
                    "sent": "Wait surveillance data, set the first the curve in the corner shows that I'm sorry.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm Pradeep from Raytheon.",
                    "label": 0
                },
                {
                    "sent": "BBN technologies.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm presenting our work on learning 3D action models from a few 2D videos.",
                    "label": 1
                },
                {
                    "sent": "I did this work while I was at USC with my colleagues Vivek Singh and Professor Amnon Bhatia.",
                    "label": 0
                },
                {
                    "sent": "In our work, we use Dynamic Bashan, Action Network, Switch, Mapper action models to a Debian.",
                    "label": 0
                },
                {
                    "sent": "We model actions hierarchically at the primitive and composite event levels.",
                    "label": 0
                },
                {
                    "sent": "The key motivation of our approach is to minimize training requirements by using formal action models, existing bag of words, style approaches required, large training sets for the models to generalize well, while recent methods that use mocap data record costly infrastructure to collect the training data.",
                    "label": 0
                },
                {
                    "sent": "In contrast, our approach requires annotation of about five key poses in a few videos about two or three for each action.",
                    "label": 0
                },
                {
                    "sent": "We recognize actions in our videos by sampling from our action models.",
                    "label": 0
                },
                {
                    "sent": "We show results on data set collected in a real grocery store.",
                    "label": 0
                },
                {
                    "sent": "Also for gesture recognition and in the standard basement data set on the Weisman data set, we get close to 99.5% accuracy, which is about state of the art.",
                    "label": 0
                },
                {
                    "sent": "With just two to three training examples and 96% accuracy with just one training example.",
                    "label": 0
                },
                {
                    "sent": "Please come to our poster number F8 for more details.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello, our papers about exploiting simple hierarchies for unsupervised behavior analysis.",
                    "label": 1
                },
                {
                    "sent": "My name is Fabian Arthur.",
                    "label": 0
                },
                {
                    "sent": "This is work together with Helmut Gardner and look one goal.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The details are weak.",
                    "label": 0
                },
                {
                    "sent": "So our target setting or one of our target setting is the monitoring of people in their living rooms.",
                    "label": 0
                },
                {
                    "sent": "A camera is mounted somewhere and then we want to analyze what the people or the person is doing inside this room.",
                    "label": 0
                },
                {
                    "sent": "Our model is successfully able to track the person throughout this scene.",
                    "label": 0
                },
                {
                    "sent": "Normal events or else as you can see in green or are successfully recognized that such like walking, walking, behind, occluding objects or sitting.",
                    "label": 0
                },
                {
                    "sent": "If something abnormal is happening like to jump over the sofa, the waving or the fall in the bottom.",
                    "label": 0
                },
                {
                    "sent": "This is recognized as well.",
                    "label": 0
                },
                {
                    "sent": "Since arguably not all events or not all actions that we can expect can be trained in the beginning, our model can be updated such that the lying, for example, which was not in the model first can be recognized then afterwards.",
                    "label": 0
                },
                {
                    "sent": "So this is an unsupervised model which basically consists of two simple hierarchies.",
                    "label": 1
                },
                {
                    "sent": "One hierarchy is analyzing appearance, the second hierarchy is analyzing the sequence of these appearances or the actions, so we're happy to be here and happy to show you more insights at poster session.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Anthony Chan from City University of Hong Kong.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with a manually coviello and greatly increased from UC San Diego.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea of this paper is we're interested in clustering dynamic textures.",
                    "label": 0
                },
                {
                    "sent": "Into some groups, and then we also want to learn some novel representation of these dynamic texture centers.",
                    "label": 0
                },
                {
                    "sent": "So the way we do this is we extend something called the hierarchical EM algorithm to probabilistic models with hidden state spaces.",
                    "label": 0
                },
                {
                    "sent": "So you can use this fancy algorithm for a few things, and we present three applications in the paper.",
                    "label": 0
                },
                {
                    "sent": "The first is we do hierarchical clustering of motion, basically by successively applying the ATM on the DTS.",
                    "label": 0
                },
                {
                    "sent": "We also do semantic motion annotation or semantic texture annotation.",
                    "label": 0
                },
                {
                    "sent": "This is similar to like image annotation with supervised multiclass labeling.",
                    "label": 0
                },
                {
                    "sent": "We basically treat the annotation model as a DT mixture and then we aggregate over a large weakly labeled data set using ATM and the final application is on generating code books for a bag of systems representation which was introduced last CPR and in this.",
                    "label": 0
                },
                {
                    "sent": "We basically represent each video volume as a DT and then we cluster DTS with HDM and use the novelty centers as the code words.",
                    "label": 1
                },
                {
                    "sent": "So you can come to our poster and see our applications and in future work.",
                    "label": 0
                },
                {
                    "sent": "We're thinking about using this same framework to cluster general graphical models, so you can think of maybe doing a bag of hmm representation or bag of X or your favorite latent variable model.",
                    "label": 0
                },
                {
                    "sent": "So thanks.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is with only the title.",
                    "label": 0
                },
                {
                    "sent": "Is the recognizing human actions from since their invention with latent post.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with young One and Greg Mori from some freezer.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our final goal is to infer the action of the person from single image.",
                    "label": 0
                },
                {
                    "sent": "We treat human post as a latent variable, and when it comes to the action recognition, not all parts of the human body are equally important.",
                    "label": 0
                },
                {
                    "sent": "For example, The Walking and play golf actions and the main differences between these actions.",
                    "label": 0
                },
                {
                    "sent": "The Arms Play Golf is more like the V shape.",
                    "label": 0
                },
                {
                    "sent": "Our man walking seems to have the arm hanging on the side of the body.",
                    "label": 0
                },
                {
                    "sent": "The posting our system is learned in a way that is directly tide to the hour angle of action recognition.",
                    "label": 0
                },
                {
                    "sent": "The whole system you learn under the framework of latent.",
                    "label": 0
                },
                {
                    "sent": "Doctor SVM our experimental results demonstrate that by using the latent poses, the performance of action recognition can be improved.",
                    "label": 1
                },
                {
                    "sent": "Since our final goal is actually recognition, we are not aiming to correctly localized body parts, but rather focus on localized body processes that are useful for the action recognition.",
                    "label": 0
                },
                {
                    "sent": "So from the visualization of the latent poses, we can observe that for the sitting action our model almost always correctly localized legs which are extremely distinctive for this action.",
                    "label": 0
                },
                {
                    "sent": "So another example is The Walking actions for this action.",
                    "label": 0
                },
                {
                    "sent": "Is our model can correctly localized arms hanging on the two sides?",
                    "label": 0
                },
                {
                    "sent": "Two sides of the torso?",
                    "label": 0
                },
                {
                    "sent": "So if you're interested you can come stop by our poster, thanks.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I don't think anybody would think I'm wrong.",
                    "label": 0
                },
                {
                    "sent": "Marshall, APA, and this type of my time I turn on my work.",
                    "label": 0
                },
                {
                    "sent": "Here is group motion segmentation using spatial temporal driving force model and so in this picture you will see some.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My players and you will see some directory's an on the left button to you will see some lines on some manifolds and on the right to your right and you will see some potential of the field and some vector fields.",
                    "label": 0
                },
                {
                    "sent": "So the work is spread generally to show you how artists are related to each other.",
                    "label": 0
                },
                {
                    "sent": "But this is not the key point.",
                    "label": 0
                },
                {
                    "sent": "The key point is that we want to show you that something called group motion segmentation emerged from the multi object activity analysis and we propose the solution for that.",
                    "label": 0
                },
                {
                    "sent": "So the problem is that we want to ask the question which objects correspond to the relevant motion of interests only using motion trajectory information.",
                    "label": 1
                },
                {
                    "sent": "So in the context of football player, we want to answer who are the offensive players.",
                    "label": 0
                },
                {
                    "sent": "So if you are tired of watching too many soccer games these days come this evening for something different.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, my name is Adriana Kubaska and I'm here to present my work on activity recognition using groupings of local spatial temporal features which is joined with my.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kaiser Christian ground at the University of Texas at Austin.",
                    "label": 0
                },
                {
                    "sent": "So a common approach to action recognition involves the use of local spacetime interest points and features, but when used individually these can be 2 local.",
                    "label": 0
                },
                {
                    "sent": "So the problem we're trying to solve is how to flexibly group these features for action recognition in order to capture relative spatial temporal relationships in a video.",
                    "label": 1
                },
                {
                    "sent": "Or specifically, we want to capture weak spatial temporal information and learn a higher sorry.",
                    "label": 1
                },
                {
                    "sent": "Using neighborhoods of features that can be a variable shapes that reflect the different sparsity of points.",
                    "label": 0
                },
                {
                    "sent": "As you can see in this image at the top.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to learn a hierarchy of these discriminative neighborhoods in order to capture a spatial temporal information at different granularities.",
                    "label": 0
                },
                {
                    "sent": "As you can see in the image in the bottom, we start with the raw features, then group these into neighborhood extent in both space and time, and group these further.",
                    "label": 1
                },
                {
                    "sent": "We achieve state of their performance on the KTH human action data set in the UC F sports datasets.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in action.",
                    "label": 0
                },
                {
                    "sent": "Ignition and local spatial temporal features.",
                    "label": 0
                },
                {
                    "sent": "Please come to our poster session.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Papa John's North buddy.",
                    "label": 0
                },
                {
                    "sent": "My name is Shanda moot.",
                    "label": 0
                },
                {
                    "sent": "Easy to join the work we provide more.",
                    "label": 0
                },
                {
                    "sent": "Adam Black shar.",
                    "label": 0
                },
                {
                    "sent": "Our worker is also about anomaly detection in crowd scenes.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the most exciting part of our approach can be seen from these two figures, which demonstrates our idea on how to use clustered particle trajectories to represent or to model crowd scenes.",
                    "label": 0
                },
                {
                    "sent": "Actually arbitrarily crowded scenes.",
                    "label": 0
                },
                {
                    "sent": "Also print out that while we're using motion trajectories, we are not using any kind of traditional tracking measure to acquire these transitory's.",
                    "label": 0
                },
                {
                    "sent": "Instead, our method is based particle election followed by a clustering step.",
                    "label": 0
                },
                {
                    "sent": "Also we're using Chronicle features to further identify the underlying dynamics of crowded scenes have based on that we will be able to using probabilistic model based method to 1st detect detect as in localized anomalies in crowd scenes.",
                    "label": 0
                },
                {
                    "sent": "So in short this work is a unique utilization of lounging particle dynamics plus chronic invariants of choice and we propose this representative transitory zazen.",
                    "label": 1
                },
                {
                    "sent": "You modeling element for.",
                    "label": 0
                },
                {
                    "sent": "These cry being crowded scenes.",
                    "label": 1
                },
                {
                    "sent": "So for more details and videos result please come to their poster.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, my name is Angela and I'm here to present some work on human action recognition and this is work that I did in collaboration with Juergen Gollan look fungal.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "TH Zurich.",
                    "label": 0
                },
                {
                    "sent": "And so our objective here is to take a video.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's moving and there's several people in the video and we want to know well, what are these people doing and where and when are they doing this in the video?",
                    "label": 0
                },
                {
                    "sent": "And we do this with the two stage approach.",
                    "label": 0
                },
                {
                    "sent": "First by tracking tracking by detection.",
                    "label": 0
                },
                {
                    "sent": "As you can see on the left and then to classify the peoples actions we use a half transform based voting framework and we extract 3D patches from the tracks represented by the color cubes on the left there.",
                    "label": 0
                },
                {
                    "sent": "And then we train a random forest.",
                    "label": 0
                },
                {
                    "sent": "To map the 3D patches to the spatial temporal, an action class center in the half space, and we apply our system to a variety of action recognition scenarios such as sports.",
                    "label": 0
                },
                {
                    "sent": "As you see on the top right there, and also surveillance types of videos as well.",
                    "label": 0
                },
                {
                    "sent": "So I look forward to meeting you at my poster and showing some of the results.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello my name is Imran Salimi and this is a combined work with Lance Hartung of University of Wisconsin, Madison and my advisor Mubarak Shah.",
                    "label": 0
                },
                {
                    "sent": "The problem.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we are trying to address as the estimation of motion patterns where the statistical description using low level features, for example optical flow and we want to avoid tracking an object level representation, another main contribution of our method is that we do not use similarity measures.",
                    "label": 0
                },
                {
                    "sent": "For example Co occurrence, which are invariant which are inherent to El Dia type approaches and we define a new similarity measures which based on emotion model which allows us to do a hierarchical clustering of optical flow and special locations in 4 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "To get a mixture of Gaussians representation which can then be marginalized or we can find an expected flow of expected conditional expectation of optical flow for scene analysis.",
                    "label": 1
                },
                {
                    "sent": "The applications of these are motion prior for tracking anomaly detection and persistent tracking through occlusions.",
                    "label": 0
                },
                {
                    "sent": "So please come to our poster For more information.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, I'm Alex raptis.",
                    "label": 0
                },
                {
                    "sent": "In this work we decompose the variability of action pipe.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In scene 2 components, the actor and the action, the actor is there being represented by a dynamic system and the action by the excitation signal of the system.",
                    "label": 1
                },
                {
                    "sent": "For instance, if we have.",
                    "label": 0
                },
                {
                    "sent": "The dynamic model of an older person.",
                    "label": 0
                },
                {
                    "sent": "This will be different from the dynamic model of young person, however, the excitation signals for a common action will be similar since this is what defines the timing and the temporal order of the movement.",
                    "label": 0
                },
                {
                    "sent": "So our intuition is by this decomposition we can reduce the variability that.",
                    "label": 0
                },
                {
                    "sent": "It signals that represent actions have an.",
                    "label": 0
                },
                {
                    "sent": "We improve the classification performance.",
                    "label": 0
                },
                {
                    "sent": "However, this problem is imposed so we we tackle a blind system identification problem and we use sparse priors to.",
                    "label": 1
                },
                {
                    "sent": "To determine the input signal.",
                    "label": 1
                },
                {
                    "sent": "In this way, we have a distinct signature signature for each action an we allow ourselves to do supervised classification functions and unsupervised segmentation of axioms.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}