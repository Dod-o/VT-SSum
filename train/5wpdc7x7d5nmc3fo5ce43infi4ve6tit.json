{
    "id": "5wpdc7x7d5nmc3fo5ce43infi4ve6tit",
    "title": "Optimising Linked Data Queries in the Presence of Co-reference",
    "info": {
        "author": [
            "Xin Wang, School of Electronics and Computer Science, University of Southampton"
        ],
        "published": "July 30, 2014",
        "recorded": "May 2014",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2014_wang_linked_data/",
    "segmentation": [
        [
            "Hello everyone, I'm seeing one from the University of Southampton.",
            "I'm going to present our work about optimizing data query we taking coreference into account.",
            "So firstly."
        ],
        [
            "I want to explain what is coreference and we all know that the link data is.",
            "It's like a community effort and all this person are encouraged to publish their own data using whatever calibrated like although they are recommended to use some some well known vocabulary but still they have the freedom to create their own categories and very natural consequences that it's many instance can be referenced by multiple.",
            "Your eyes, rather than a unique one, and, for example here Timothy.",
            "I say we won't be surprised that has many different guys, but they all over point to the same person.",
            "And when we query the link data, usually it's linked data query that distributed sparkle query engine only recognize one of them, but not taking into account all this equipment, your eyes and so here we just want to address this problem in the efficient way."
        ],
        [
            "And those are the.",
            "There are many existing coreference are presented by the old semis vocabulary and so they are already.",
            "Many also mass segments in the link data, so that's the that's the data we can we can exploit.",
            "Anne.",
            "Firstly, the the coreference or the equivalent your eyes can be regarded as some implicit connection between different datasets, and before we consider on them, the other datasets are not connected, and if we take and take into account for reference, that's way too increase the connectivity of different data datasets, and naturally the by considering more your eyes, we can have more results.",
            "And also there have been a lot of work being done regarding how to identify how to identify different tries, but actually the equivalent so.",
            "As I just said in the last slide, many existing OSA my statements in the link clouds.",
            "And the.",
            "It's not very well supported by the existing distributed engines there, or just support the recognized whatever you provide to the engine, but not considering the equivalent your eyes."
        ],
        [
            "The challenges of taking correctly into account is that if you following a naive approach, you have to consider the Cartesian product of all the coreference of the concrete nodes in the query.",
            "For example, if you want to know.",
            "Orsino, someone working in the University of Southampton and we know that there's a, for example, the two different URLs refer to Timorously, and there are three different URLs.",
            "Refer to the University.",
            "Southampton probably will have to issue 6.",
            "A separate queries to get all the possible results, and that's very costly and also most of the optimization approach of distributed sparkle query relying on some statistics, mostly provided by by avoids, but certainly the coreference is not.",
            "It's not considered by void, so for most of the approach they can't just account user statistics.",
            "To take Coreference into account.",
            "And since there's more results coming back and that's just more optimization pressure, you need some better solutions to to increase the speed of the processing."
        ],
        [
            "And our contributions in this paper is to solve.",
            "The first challenge here we proposed approach called Virtual graph.",
            "What is basically now seems to merge all these different your eyes into OneNote so we can process them in one in one single query instead of issue multiple different queries.",
            "And since there's no existing statistics provided by void, we decide to explore exploit runtime statistics or just don't use any.",
            "Pre computed statistics since they are not accurate.",
            "And the.",
            "To increase the performance.",
            "We proposed this algorithm perceive that's accounting for parallel sub graph identification, which can break a graph into several sub sub graph sub queries that can be executed in parallel.",
            "We know that you only include increasing the parallelization may introduce some extra network traffic, but this algorithm that doesn't reduce introduce any extra traffic.",
            "That's the advantage of a day.",
            "And to evaluate our approach we have to extend the existing benchmark the blame benchmark because there is currently no no benchmarks voting preference over, we had to extend it."
        ],
        [
            "Firstly, I'm going to describe autograph.",
            "Actually the the idea behind this version graph is very simple that we can regard any nodes with some value as a variable with different values.",
            "So we can if there's concrete nodes and we know it has some Co reference and we can just take it size variable but have multiple values.",
            "An in in such a way we can combine all this coreference in one query and we can optimize them together to have the global optimal query execution plan.",
            "And here sayings."
        ],
        [
            "So if we assume that we have a triple pattern?",
            "X4 flows Tim Bursley and we know that team wrestling has at least 2 correct your eyes.",
            "Once team team invites PPL and after just Virtual Graph transformation we just transform transform the original triple pattern into the.",
            "The one at the bottom that we transform the node.",
            "Team into another note?",
            "P, whose value is TMNT, EPL?"
        ],
        [
            "And after the transformation we breakdown this query into subqueries.",
            "There's another, uh, the idea behind this algorithm is also very simple that if two triple patterns, so that the most simplest cases, two triple points connected by a concrete nodes, it doesn't matter following whatever you execute.",
            "This two triple patterns, because they are the result.",
            "Sites are separate, they won't affect each other.",
            "And we can simply, since their order is irrelevant because simply execute them in parallel and it won't increase any network traffic.",
            "Not like for example, if you have a arbitrary query, the certainly you can.",
            "You can execute each triple pattern in parallel no matter what it costs, but probably there's a huge amount of network traffic caused by this executions.",
            "It is naive execution approach and probably the result will be returned in a very long time.",
            "But following this one so this this this algorithm it won't have this side effects of increased network traffic."
        ],
        [
            "And the algorithm works very.",
            "It's a very simple algorithm as well, and we introduced this notion of fixed cardinality nodes that it's a generalization of the concrete nodes.",
            "You don't really have to have a concrete node to break the graph into into separate ones.",
            "The idea is the size of the result of the of the node doesn't change or doesn't change much during during the execution.",
            "So we call such.",
            "Notes, fixed cardinality nodes and.",
            "A query can be breakdown or disconnected at those fixed cardinality nodes.",
            "Here's"
        ],
        [
            "For example, we have this clear graph and three triple pattern connect by the concrete no team, although it doesn't have to be has to be a concrete.",
            "Now this can be any fixed cardinality nodes and we can simply break the original query into 3 sub queries and they can be executed in parallel without introducing extra network traffic."
        ],
        [
            "And the problem is that the algorithm is.",
            "Sorry.",
            "Firstly, for all the triple pattern or for all the triple patterns in the paragraph it's create, sorry.",
            "It creates a sub graph that each sub containing one single triple pattern and then it'll start scan through all the nodes.",
            "If the note is the fixed cardinality one it keeps all the subgraphs separated.",
            "I say they are but if the the node is not fixed cardinality one in the in the graph source and the whole or knows.",
            "Uh, algorithm just to connect.",
            "All the subgraphs connecting to this non fixed carnality nodes.",
            "So after 2 scan, once the first gun is to initial all this sub graph using each triple pen and the select scan it to scan through all this load and connecting older subgraph that's connected by a non fixed connecting node.",
            "So it's a very efficient algorithm."
        ],
        [
            "And here's overview of the apps or engine name HD have indeed the the last D stands for dynamic programming.",
            "Note then optimization, since that's exploits runtime statistics as opposed to those.",
            "Existing approach using some precomputed statistics and computers or this query plan before execution, but in our approach, the query execution and optimization actually interleaved during the query execution time.",
            "So given a query is first transformed by the virtual graph, then it says submit to the to the Posse algorithm to break to be broken into subgraphs.",
            "Then each subgraph is optimized using minimum spanning tree algorithm.",
            "That's basically a greedy algorithm.",
            "Pick the minimum age.",
            "Yeah, yeah, at each step and then this query query execution plan is submitted to the plan executor.",
            "And which is managed by.",
            "Communication Manager is basically what it does is to balancing the night traffic.",
            "No, the next traffic loads to each data set to make the maximum use of the bandwidth and for more detail of this query execution part please.",
            "I mean it's described in our previous work that LD one published in Link data Link over later Workshop in 2013."
        ],
        [
            "And talk about to evaluate our approach.",
            "We had to extend the existing building benchmark with some artificial generates coreference links and to do that.",
            "We firstly investigate billion Triple Challenge 2011 data sets to get the distribution of preference and simulates that its distribution in the Berlin benchmark.",
            "And you can see that the distribution is a parallel distribution."
        ],
        [
            "We evaluate approach the virtual graph and the algorithm proceeds separately firstly.",
            "We don't take preference into account.",
            "In this evaluation, we just evaluate the accuracy because it's it's not bound to reference.",
            "It can be a pilot in in any general query engine and we compare this one with our previous work there G1 but is referred to as HD Havanese to Tameka distinguish and the FedEx one.",
            "Which is also a very efficient distributed sparkle engine.",
            "And Please remember, Please remember we don't take corruption so into account at this evaluation.",
            "And foremost."
        ],
        [
            "Top of the query is this.",
            "The shows the query per second, the higher the better, the higher the faster and for most of the query the our approach LHD happened, D shows a certain improvement.",
            "On most of the queries.",
            "There are in our paper there's many other figures indicating the network traffic and and the average transmission rate, but I mean, if you're interested you can.",
            "You can see the find all these details in the paper."
        ],
        [
            "And Secondly, we evaluate the.",
            "The performance of virtual graph.",
            "And this time we we compare our approach.",
            "Refer to SHD.",
            "I haven't the star and it's complicated and this time is basically so HD with virtual graph and sports coreference.",
            "And we can compare it to the naive approach that we have to execute all this coreference queries separately, but each query is actually using energy, so it's also have the advantage of using the algorithm proceeds.",
            "And the third one is directly without preferences, just here serves as a baseline, shows the impact of introducing coreference."
        ],
        [
            "And here is the table of the query result after taking coreference into account and you can see for most of the queries there's a huge increase of the result account.",
            "An interesting thing is query 5.",
            "You can see that.",
            "That the last sizer actually happened.",
            "He doesn't have any corrections support, but it shows the same size of result size as as taking conference into account.",
            "That that's because in the inquiry, five in the original query, without taking to reference it already retrieved all this, all the nodes in the graph.",
            "So even you're taking current account, it won't give you anymore, because that's that's all of it."
        ],
        [
            "And here's the comparison for this tree approach.",
            "And still you can see that the naive approach just doesn't work, it's just slow or just stop working.",
            "Don't give you any result.",
            "And.",
            "Not surprisingly, taking Coreference account have a huge performance impact on the on the query per second on the on.",
            "The speed of query processing.",
            "And also even with our our approach, the virtual graph on it's improved performance.",
            "But still it's it's not very good.",
            "I have to say.",
            "OK, that's kind of it.",
            "And thanks for listening and any questions.",
            "One standard approach with dealing with core references is entity consolidation, so creating so.",
            "Sorry, do you understand me?",
            "Yeah, OK, so one standard approach with dealing with core references in RDF is entity consolidations or where you create Canonical and identifiers.",
            "In the RDF, resolving the old same as links.",
            "So I'm wondering how is that related to your work.",
            "Actually, here in our work we are focusing on the optimization how to improve the performance of query processing in distributively with correctly taking into account they don't really consider how to resolve this coreference, we don't consider how to.",
            "How to calculate?",
            "Wiser to your eyes are equal.",
            "But I answer your question.",
            "So it's I mean we take the correction resolution as another layer.",
            "I mean you can.",
            "You can do that separately and we just based on the existing.",
            "Or say my statements.",
            "Hello, my name is Mohammed Salim.",
            "From my KSW so thanks for your nice talk.",
            "I have a question regarding the evaluation.",
            "Since you are targeting distributed query processing but like the benchmark you use is not for the distributed query processing the Burden Sparkle benchmark is actually for a single data set.",
            "Yeah, residing in a single system so it's not a distributed environment.",
            "Yeah yeah.",
            "Another question is that it's it's like synthetic data.",
            "Even it's not the.",
            "Real benchmark as well, so it's not reflecting the real scenario, so sorry, can you say can you repeat the last time in the day to use in the Berlin Sparkle benchmark is actually a synthetic data, not real ones, so it's not reflecting the real scenario.",
            "Yeah, I mean, firstly, yes, the volume benchmarks for centralized one, but here what you're seeing in this evaluation is actually an extension of the brain.",
            "Benchmark has been describing our previous work in.",
            "2011 is a distributed version of the Bloomberg basically takes the blame benchmark this module and generates all this data based on the the billing benchmark data generated and distributed this data into several different removed state sites to create.",
            "To simulate this disability after net network and perform our evaluation in social network and in this work we just extend the benchmark again with the support of preference.",
            "Have you tried running the whole thing on Fed Bench or something similar?",
            "Sorry, have you tried running your approach on Fed bench no.",
            "Yes.",
            "OK, this is a follow up to the question before the last one with synthetic data, because if you're going into the real data.",
            "Entities will have different your eyes because they have different schema and how does your approach work in case when the schema actually differs between the coreference entities?",
            "For example, you have Tim Berners Lee on deep down.",
            "Do you have Tim Berners Lee in his profile?",
            "Then you will have different properties to query anyways.",
            "Yeah, we don't.",
            "I mean, include that so consideration in the current state of the work.",
            "Currently we don't really.",
            "I mean, take the difference of schema into account.",
            "We actually I don't really think they are there.",
            "I mean there would be a big impact on the performance because it just deals with this abstractive graph module rather than the detailed different schemas.",
            "And certainly we need some extra layer to combine or to consolidate this different different schemas in different datasets.",
            "But after that that step we can still apply or approach on the.",
            "Combined data graph."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everyone, I'm seeing one from the University of Southampton.",
                    "label": 1
                },
                {
                    "sent": "I'm going to present our work about optimizing data query we taking coreference into account.",
                    "label": 0
                },
                {
                    "sent": "So firstly.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to explain what is coreference and we all know that the link data is.",
                    "label": 0
                },
                {
                    "sent": "It's like a community effort and all this person are encouraged to publish their own data using whatever calibrated like although they are recommended to use some some well known vocabulary but still they have the freedom to create their own categories and very natural consequences that it's many instance can be referenced by multiple.",
                    "label": 0
                },
                {
                    "sent": "Your eyes, rather than a unique one, and, for example here Timothy.",
                    "label": 0
                },
                {
                    "sent": "I say we won't be surprised that has many different guys, but they all over point to the same person.",
                    "label": 1
                },
                {
                    "sent": "And when we query the link data, usually it's linked data query that distributed sparkle query engine only recognize one of them, but not taking into account all this equipment, your eyes and so here we just want to address this problem in the efficient way.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And those are the.",
                    "label": 0
                },
                {
                    "sent": "There are many existing coreference are presented by the old semis vocabulary and so they are already.",
                    "label": 0
                },
                {
                    "sent": "Many also mass segments in the link data, so that's the that's the data we can we can exploit.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Firstly, the the coreference or the equivalent your eyes can be regarded as some implicit connection between different datasets, and before we consider on them, the other datasets are not connected, and if we take and take into account for reference, that's way too increase the connectivity of different data datasets, and naturally the by considering more your eyes, we can have more results.",
                    "label": 0
                },
                {
                    "sent": "And also there have been a lot of work being done regarding how to identify how to identify different tries, but actually the equivalent so.",
                    "label": 0
                },
                {
                    "sent": "As I just said in the last slide, many existing OSA my statements in the link clouds.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "It's not very well supported by the existing distributed engines there, or just support the recognized whatever you provide to the engine, but not considering the equivalent your eyes.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The challenges of taking correctly into account is that if you following a naive approach, you have to consider the Cartesian product of all the coreference of the concrete nodes in the query.",
                    "label": 1
                },
                {
                    "sent": "For example, if you want to know.",
                    "label": 0
                },
                {
                    "sent": "Orsino, someone working in the University of Southampton and we know that there's a, for example, the two different URLs refer to Timorously, and there are three different URLs.",
                    "label": 0
                },
                {
                    "sent": "Refer to the University.",
                    "label": 0
                },
                {
                    "sent": "Southampton probably will have to issue 6.",
                    "label": 0
                },
                {
                    "sent": "A separate queries to get all the possible results, and that's very costly and also most of the optimization approach of distributed sparkle query relying on some statistics, mostly provided by by avoids, but certainly the coreference is not.",
                    "label": 0
                },
                {
                    "sent": "It's not considered by void, so for most of the approach they can't just account user statistics.",
                    "label": 0
                },
                {
                    "sent": "To take Coreference into account.",
                    "label": 0
                },
                {
                    "sent": "And since there's more results coming back and that's just more optimization pressure, you need some better solutions to to increase the speed of the processing.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our contributions in this paper is to solve.",
                    "label": 0
                },
                {
                    "sent": "The first challenge here we proposed approach called Virtual graph.",
                    "label": 0
                },
                {
                    "sent": "What is basically now seems to merge all these different your eyes into OneNote so we can process them in one in one single query instead of issue multiple different queries.",
                    "label": 0
                },
                {
                    "sent": "And since there's no existing statistics provided by void, we decide to explore exploit runtime statistics or just don't use any.",
                    "label": 0
                },
                {
                    "sent": "Pre computed statistics since they are not accurate.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "To increase the performance.",
                    "label": 0
                },
                {
                    "sent": "We proposed this algorithm perceive that's accounting for parallel sub graph identification, which can break a graph into several sub sub graph sub queries that can be executed in parallel.",
                    "label": 1
                },
                {
                    "sent": "We know that you only include increasing the parallelization may introduce some extra network traffic, but this algorithm that doesn't reduce introduce any extra traffic.",
                    "label": 0
                },
                {
                    "sent": "That's the advantage of a day.",
                    "label": 0
                },
                {
                    "sent": "And to evaluate our approach we have to extend the existing benchmark the blame benchmark because there is currently no no benchmarks voting preference over, we had to extend it.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Firstly, I'm going to describe autograph.",
                    "label": 0
                },
                {
                    "sent": "Actually the the idea behind this version graph is very simple that we can regard any nodes with some value as a variable with different values.",
                    "label": 1
                },
                {
                    "sent": "So we can if there's concrete nodes and we know it has some Co reference and we can just take it size variable but have multiple values.",
                    "label": 1
                },
                {
                    "sent": "An in in such a way we can combine all this coreference in one query and we can optimize them together to have the global optimal query execution plan.",
                    "label": 0
                },
                {
                    "sent": "And here sayings.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we assume that we have a triple pattern?",
                    "label": 0
                },
                {
                    "sent": "X4 flows Tim Bursley and we know that team wrestling has at least 2 correct your eyes.",
                    "label": 0
                },
                {
                    "sent": "Once team team invites PPL and after just Virtual Graph transformation we just transform transform the original triple pattern into the.",
                    "label": 1
                },
                {
                    "sent": "The one at the bottom that we transform the node.",
                    "label": 0
                },
                {
                    "sent": "Team into another note?",
                    "label": 0
                },
                {
                    "sent": "P, whose value is TMNT, EPL?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And after the transformation we breakdown this query into subqueries.",
                    "label": 0
                },
                {
                    "sent": "There's another, uh, the idea behind this algorithm is also very simple that if two triple patterns, so that the most simplest cases, two triple points connected by a concrete nodes, it doesn't matter following whatever you execute.",
                    "label": 0
                },
                {
                    "sent": "This two triple patterns, because they are the result.",
                    "label": 0
                },
                {
                    "sent": "Sites are separate, they won't affect each other.",
                    "label": 0
                },
                {
                    "sent": "And we can simply, since their order is irrelevant because simply execute them in parallel and it won't increase any network traffic.",
                    "label": 0
                },
                {
                    "sent": "Not like for example, if you have a arbitrary query, the certainly you can.",
                    "label": 0
                },
                {
                    "sent": "You can execute each triple pattern in parallel no matter what it costs, but probably there's a huge amount of network traffic caused by this executions.",
                    "label": 0
                },
                {
                    "sent": "It is naive execution approach and probably the result will be returned in a very long time.",
                    "label": 0
                },
                {
                    "sent": "But following this one so this this this algorithm it won't have this side effects of increased network traffic.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the algorithm works very.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple algorithm as well, and we introduced this notion of fixed cardinality nodes that it's a generalization of the concrete nodes.",
                    "label": 0
                },
                {
                    "sent": "You don't really have to have a concrete node to break the graph into into separate ones.",
                    "label": 0
                },
                {
                    "sent": "The idea is the size of the result of the of the node doesn't change or doesn't change much during during the execution.",
                    "label": 0
                },
                {
                    "sent": "So we call such.",
                    "label": 0
                },
                {
                    "sent": "Notes, fixed cardinality nodes and.",
                    "label": 0
                },
                {
                    "sent": "A query can be breakdown or disconnected at those fixed cardinality nodes.",
                    "label": 0
                },
                {
                    "sent": "Here's",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, we have this clear graph and three triple pattern connect by the concrete no team, although it doesn't have to be has to be a concrete.",
                    "label": 0
                },
                {
                    "sent": "Now this can be any fixed cardinality nodes and we can simply break the original query into 3 sub queries and they can be executed in parallel without introducing extra network traffic.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the problem is that the algorithm is.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Firstly, for all the triple pattern or for all the triple patterns in the paragraph it's create, sorry.",
                    "label": 1
                },
                {
                    "sent": "It creates a sub graph that each sub containing one single triple pattern and then it'll start scan through all the nodes.",
                    "label": 0
                },
                {
                    "sent": "If the note is the fixed cardinality one it keeps all the subgraphs separated.",
                    "label": 0
                },
                {
                    "sent": "I say they are but if the the node is not fixed cardinality one in the in the graph source and the whole or knows.",
                    "label": 0
                },
                {
                    "sent": "Uh, algorithm just to connect.",
                    "label": 0
                },
                {
                    "sent": "All the subgraphs connecting to this non fixed carnality nodes.",
                    "label": 0
                },
                {
                    "sent": "So after 2 scan, once the first gun is to initial all this sub graph using each triple pen and the select scan it to scan through all this load and connecting older subgraph that's connected by a non fixed connecting node.",
                    "label": 0
                },
                {
                    "sent": "So it's a very efficient algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's overview of the apps or engine name HD have indeed the the last D stands for dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "Note then optimization, since that's exploits runtime statistics as opposed to those.",
                    "label": 0
                },
                {
                    "sent": "Existing approach using some precomputed statistics and computers or this query plan before execution, but in our approach, the query execution and optimization actually interleaved during the query execution time.",
                    "label": 0
                },
                {
                    "sent": "So given a query is first transformed by the virtual graph, then it says submit to the to the Posse algorithm to break to be broken into subgraphs.",
                    "label": 0
                },
                {
                    "sent": "Then each subgraph is optimized using minimum spanning tree algorithm.",
                    "label": 0
                },
                {
                    "sent": "That's basically a greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "Pick the minimum age.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, at each step and then this query query execution plan is submitted to the plan executor.",
                    "label": 0
                },
                {
                    "sent": "And which is managed by.",
                    "label": 0
                },
                {
                    "sent": "Communication Manager is basically what it does is to balancing the night traffic.",
                    "label": 0
                },
                {
                    "sent": "No, the next traffic loads to each data set to make the maximum use of the bandwidth and for more detail of this query execution part please.",
                    "label": 0
                },
                {
                    "sent": "I mean it's described in our previous work that LD one published in Link data Link over later Workshop in 2013.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And talk about to evaluate our approach.",
                    "label": 0
                },
                {
                    "sent": "We had to extend the existing building benchmark with some artificial generates coreference links and to do that.",
                    "label": 0
                },
                {
                    "sent": "We firstly investigate billion Triple Challenge 2011 data sets to get the distribution of preference and simulates that its distribution in the Berlin benchmark.",
                    "label": 0
                },
                {
                    "sent": "And you can see that the distribution is a parallel distribution.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We evaluate approach the virtual graph and the algorithm proceeds separately firstly.",
                    "label": 0
                },
                {
                    "sent": "We don't take preference into account.",
                    "label": 0
                },
                {
                    "sent": "In this evaluation, we just evaluate the accuracy because it's it's not bound to reference.",
                    "label": 0
                },
                {
                    "sent": "It can be a pilot in in any general query engine and we compare this one with our previous work there G1 but is referred to as HD Havanese to Tameka distinguish and the FedEx one.",
                    "label": 0
                },
                {
                    "sent": "Which is also a very efficient distributed sparkle engine.",
                    "label": 0
                },
                {
                    "sent": "And Please remember, Please remember we don't take corruption so into account at this evaluation.",
                    "label": 0
                },
                {
                    "sent": "And foremost.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Top of the query is this.",
                    "label": 0
                },
                {
                    "sent": "The shows the query per second, the higher the better, the higher the faster and for most of the query the our approach LHD happened, D shows a certain improvement.",
                    "label": 0
                },
                {
                    "sent": "On most of the queries.",
                    "label": 0
                },
                {
                    "sent": "There are in our paper there's many other figures indicating the network traffic and and the average transmission rate, but I mean, if you're interested you can.",
                    "label": 0
                },
                {
                    "sent": "You can see the find all these details in the paper.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Secondly, we evaluate the.",
                    "label": 0
                },
                {
                    "sent": "The performance of virtual graph.",
                    "label": 0
                },
                {
                    "sent": "And this time we we compare our approach.",
                    "label": 0
                },
                {
                    "sent": "Refer to SHD.",
                    "label": 0
                },
                {
                    "sent": "I haven't the star and it's complicated and this time is basically so HD with virtual graph and sports coreference.",
                    "label": 0
                },
                {
                    "sent": "And we can compare it to the naive approach that we have to execute all this coreference queries separately, but each query is actually using energy, so it's also have the advantage of using the algorithm proceeds.",
                    "label": 0
                },
                {
                    "sent": "And the third one is directly without preferences, just here serves as a baseline, shows the impact of introducing coreference.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is the table of the query result after taking coreference into account and you can see for most of the queries there's a huge increase of the result account.",
                    "label": 0
                },
                {
                    "sent": "An interesting thing is query 5.",
                    "label": 0
                },
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "That the last sizer actually happened.",
                    "label": 0
                },
                {
                    "sent": "He doesn't have any corrections support, but it shows the same size of result size as as taking conference into account.",
                    "label": 0
                },
                {
                    "sent": "That that's because in the inquiry, five in the original query, without taking to reference it already retrieved all this, all the nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "So even you're taking current account, it won't give you anymore, because that's that's all of it.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's the comparison for this tree approach.",
                    "label": 0
                },
                {
                    "sent": "And still you can see that the naive approach just doesn't work, it's just slow or just stop working.",
                    "label": 0
                },
                {
                    "sent": "Don't give you any result.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Not surprisingly, taking Coreference account have a huge performance impact on the on the query per second on the on.",
                    "label": 0
                },
                {
                    "sent": "The speed of query processing.",
                    "label": 0
                },
                {
                    "sent": "And also even with our our approach, the virtual graph on it's improved performance.",
                    "label": 0
                },
                {
                    "sent": "But still it's it's not very good.",
                    "label": 0
                },
                {
                    "sent": "I have to say.",
                    "label": 0
                },
                {
                    "sent": "OK, that's kind of it.",
                    "label": 0
                },
                {
                    "sent": "And thanks for listening and any questions.",
                    "label": 0
                },
                {
                    "sent": "One standard approach with dealing with core references is entity consolidation, so creating so.",
                    "label": 0
                },
                {
                    "sent": "Sorry, do you understand me?",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, so one standard approach with dealing with core references in RDF is entity consolidations or where you create Canonical and identifiers.",
                    "label": 0
                },
                {
                    "sent": "In the RDF, resolving the old same as links.",
                    "label": 0
                },
                {
                    "sent": "So I'm wondering how is that related to your work.",
                    "label": 0
                },
                {
                    "sent": "Actually, here in our work we are focusing on the optimization how to improve the performance of query processing in distributively with correctly taking into account they don't really consider how to resolve this coreference, we don't consider how to.",
                    "label": 0
                },
                {
                    "sent": "How to calculate?",
                    "label": 0
                },
                {
                    "sent": "Wiser to your eyes are equal.",
                    "label": 0
                },
                {
                    "sent": "But I answer your question.",
                    "label": 0
                },
                {
                    "sent": "So it's I mean we take the correction resolution as another layer.",
                    "label": 0
                },
                {
                    "sent": "I mean you can.",
                    "label": 0
                },
                {
                    "sent": "You can do that separately and we just based on the existing.",
                    "label": 0
                },
                {
                    "sent": "Or say my statements.",
                    "label": 0
                },
                {
                    "sent": "Hello, my name is Mohammed Salim.",
                    "label": 0
                },
                {
                    "sent": "From my KSW so thanks for your nice talk.",
                    "label": 0
                },
                {
                    "sent": "I have a question regarding the evaluation.",
                    "label": 0
                },
                {
                    "sent": "Since you are targeting distributed query processing but like the benchmark you use is not for the distributed query processing the Burden Sparkle benchmark is actually for a single data set.",
                    "label": 0
                },
                {
                    "sent": "Yeah, residing in a single system so it's not a distributed environment.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "Another question is that it's it's like synthetic data.",
                    "label": 0
                },
                {
                    "sent": "Even it's not the.",
                    "label": 0
                },
                {
                    "sent": "Real benchmark as well, so it's not reflecting the real scenario, so sorry, can you say can you repeat the last time in the day to use in the Berlin Sparkle benchmark is actually a synthetic data, not real ones, so it's not reflecting the real scenario.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, firstly, yes, the volume benchmarks for centralized one, but here what you're seeing in this evaluation is actually an extension of the brain.",
                    "label": 0
                },
                {
                    "sent": "Benchmark has been describing our previous work in.",
                    "label": 0
                },
                {
                    "sent": "2011 is a distributed version of the Bloomberg basically takes the blame benchmark this module and generates all this data based on the the billing benchmark data generated and distributed this data into several different removed state sites to create.",
                    "label": 0
                },
                {
                    "sent": "To simulate this disability after net network and perform our evaluation in social network and in this work we just extend the benchmark again with the support of preference.",
                    "label": 0
                },
                {
                    "sent": "Have you tried running the whole thing on Fed Bench or something similar?",
                    "label": 0
                },
                {
                    "sent": "Sorry, have you tried running your approach on Fed bench no.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a follow up to the question before the last one with synthetic data, because if you're going into the real data.",
                    "label": 0
                },
                {
                    "sent": "Entities will have different your eyes because they have different schema and how does your approach work in case when the schema actually differs between the coreference entities?",
                    "label": 0
                },
                {
                    "sent": "For example, you have Tim Berners Lee on deep down.",
                    "label": 0
                },
                {
                    "sent": "Do you have Tim Berners Lee in his profile?",
                    "label": 0
                },
                {
                    "sent": "Then you will have different properties to query anyways.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we don't.",
                    "label": 0
                },
                {
                    "sent": "I mean, include that so consideration in the current state of the work.",
                    "label": 0
                },
                {
                    "sent": "Currently we don't really.",
                    "label": 0
                },
                {
                    "sent": "I mean, take the difference of schema into account.",
                    "label": 0
                },
                {
                    "sent": "We actually I don't really think they are there.",
                    "label": 0
                },
                {
                    "sent": "I mean there would be a big impact on the performance because it just deals with this abstractive graph module rather than the detailed different schemas.",
                    "label": 0
                },
                {
                    "sent": "And certainly we need some extra layer to combine or to consolidate this different different schemas in different datasets.",
                    "label": 0
                },
                {
                    "sent": "But after that that step we can still apply or approach on the.",
                    "label": 0
                },
                {
                    "sent": "Combined data graph.",
                    "label": 0
                }
            ]
        }
    }
}