{
    "id": "47xwxklmsblibyap6m3j6izjsbrepuna",
    "title": "A Completed Information Projection Interpretation of Expectation Propagation",
    "info": {
        "author": [
            "John MacLaren Walsh, Electrical and Computer Engineering Department, Drexel University"
        ],
        "published": "Dec. 31, 2007",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Mathematics"
        ]
    },
    "url": "http://videolectures.net/abi07_walsh_cip/",
    "segmentation": [
        [
            "You know there are a couple of very important pictures in this talk.",
            "Maybe will try to get to them very quickly.",
            "OK so."
        ],
        [
            "So here we go, alright, let's jump right into the thick of it.",
            "You guys have seen this six or seven different times today I think, but exponential family densities.",
            "Here we go are sufficient statistics.",
            "Functions are parameters that we're optimizing the log partition function for free energy that he was just working with in the previous talk.",
            "You get this nice thing that if you take the dual of that log partition function, you get the negative of the Shannon entropy.",
            "This is all standard.",
            "Exponential families you could call it information geometry, but not really doing anything with the Romanian metric, whereas my information geometry yeah, no remaining metric in this talk.",
            "So all right, and you know, of course, with that duality you get this nice one to one relationship between the log parameters and the expectation parameters, and you'll notice that these are the expected values of the sufficient statistics.",
            "OK, that's about all we need to."
        ],
        [
            "Here you want to go to the next slide.",
            "OK so EP for the 15th time today.",
            "What is it alright?",
            "Well we have a joint density.",
            "You know it factors into a product of smaller functions of the parameters.",
            "Theater a.",
            "This is an abuse of notation to say that Theta A is a subvector of Theta and the idea is to exploit this factorization.",
            "One of many that we could pick right with a factorization of the same form and I'm going to say although there's some people who say that you don't have to use exponential families to do EP.",
            "I'm going to say I'm the focus.",
            "I should say on the on the exponential family case today so my factors are going to be exponential families.",
            "And of course, the reason why is that when I'm in exponential families and I go to do the refinement step in EP well, the argument of the KL divergences that results to a moment matching criteria.",
            "In other words, when I say moment matching, the expected values of the sufficient statistics for the two distributions.",
            "OK, so here's our familiar.",
            "You keep around the one nasty factor, as he said in the previous talk and remove it from the approximating distribution.",
            "And then you met.",
            "You fit that to the.",
            "Product of all the approximating factors or the approximate."
        ],
        [
            "Distribution next slide please.",
            "OK, so one last bit of prerequisite here.",
            "Bregman divergences.",
            "We had one of those nice six invited talks at NIPS this year was by year sensor Champion of Bregman divergences.",
            "Well, what the heck are these and why are they relevant and why am I bringing them up?",
            "So let's let's go through that very quickly.",
            "You basically start with a fact that a differentiable convex function is lower bounded by its first order Taylor approximation and so in other words, if H is of lizandra type.",
            "Which you have a couple more requirements there, but let's just stick with that.",
            "It means here's our value at a particular set of parameters.",
            "And here's our linear approximation out to 1st order, an indeed it's it's greater than that, and there's that great picture that you can always draw that shows that, and it would be nice if I'd put this up on the slide, but I made this a little too hastily anyway.",
            "Let's keep moving Bregman divergences, it's alright, Bregman divergences.",
            "Yeah, yeah, we really do want to go fast.",
            "You know, we take this thing and we make a distance like metric out of it.",
            "You can see it's basically just like the difference between the actual value in the Taylor approximation, right?",
            "And that's what year sensors showed you in his talk with the nice picture.",
            "Alright, and in particular, these things have some properties of distance.",
            "In particular, we see from 66 being the linear approximation that is greater than or equal 0, and it's equal to 0 if and only if the parameters are equal.",
            "Alright, but on the other hand it's not symmetric.",
            "You need some special cases to have a triangle inequality that some of the cool stuff you can prove about this, and of course, as you guys could probably anticipate I'm just going to choose H to be the negentropy, and so I get the callback Leibler divergent's as my Bregman divergences.",
            "But there's a reason for going to this higher."
        ],
        [
            "For which we'll get to in a moment, so please move on.",
            "OK, so let's talk about projections.",
            "Algorithms that are built from Bregman divergences?",
            "Well, there's some very intuitive ones, since since of course the Bregman divergences is not symmetric, left projection is different from the right projection you will be familiar with this from the KL divergences.",
            "Most of you probably anyway, so you can build alternating projections algorithms between two different sets.",
            "Alright, so here's our alternating projections.",
            "Please move on these."
        ],
        [
            "I've been analyzed.",
            "There's some very old work by Chichar using the KL distance on that and Dijkstra's algorithm with cyclic Bregman projections.",
            "This is the one that we wanted.",
            "OK, this is the reason for going up to the higher layer OK, an namely what does this do?",
            "OK, so we'd like to find the point in the union of some SI believe capital S convex sets.",
            "Now intersection of some S convex sets.",
            "That's closest to our initial point, so this this algorithm will solve it.",
            "OK, what do we do closest in the sense of a left projection?",
            "OK, so how do we do this?",
            "Well, we start.",
            "We initialize these towels at zero and we project onto the set and we formed this difference between the gradient of the convex function we built the Bregman divergences with our previous.",
            "Tau and where we wound up after the projection.",
            "OK, so let's add some context.",
            "Choose H to be the negative entropy.",
            "Now remember what it does.",
            "The gradient then of H will map in between the.",
            "The expectation coordinates.",
            "So in other words, the expected values of sufficient statistics for this particular exponential distribution to the log parameters.",
            "So let's say we're doing a binary distribution.",
            "OK, this would be the map between the probability that the bid is 1 and the log likelihood ratio.",
            "And the reason why this is going to be useful?"
        ],
        [
            "See, in a second, please move on.",
            "Well, well, let's first introduce two sets that are related to the information projection formulation of EP.",
            "Well, first we make as many copies of the spaces that were factors.",
            "So we copy the space OK and one set is the set of densities which are supported on all copies being equal.",
            "Now if I might have some mathematicians in the room that feel like I've just run my fingers down a chalkboard by saying that because of course if things are continuous.",
            "The probability that condition continuously distributed random variables that are not identical or equal being constrained well.",
            "Of course, that's always defined to be 0, but you can consider an appropriate limiting process which which effectively makes this set in the parameter space is another set that's going to be of interest.",
            "Is a product of densities of the approximating family form.",
            "So in other words, this is just I take the approximating family and I copy it M times and I multiply it by itself, OK?",
            "And the starting point is where I take my original distribution now and I don't I no longer pay attention to the fact that the same variable was repeated in several factors.",
            "In other words, you can think of a factor graph.",
            "Again, this would be a good thing to draw.",
            "You can think of the factor graph which had each of the variables that I was trying to infer, and it was connected to each of the factors in that distribution, and an edge connects a variable in effect, or if that factor depends on that edge, what we're going to do is we're going to cut.",
            "That that graph in half OK and we're no longer to pay attention that we've replicated the same variables in the same place.",
            "And we're going to write the distribution.",
            "If that were the case, OK, that's going to be our initial."
        ],
        [
            "Starting point for our projection algorithm and just to give you some visual intuition here, here are two sets for the case of two."
        ],
        [
            "Let's let's move on.",
            "Alright, so let's now try to see how EP could be viewed as a projections algorithm.",
            "Well, what do we do?",
            "We start with that starting point.",
            "We projected onto Q OK, which product takes the product of all of the.",
            "The factors together.",
            "Then we project that onto P and we do Dijkstra's algorithm essentially and the only difference between this and Dijkstra's algorithm is that if we were to be proper when we're following a Dijkstra preprocessing with the projection, this is the type of dikes to preprocessing that you do.",
            "For a left projection.",
            "If you'll notice the method of cyclic Bregman projections, I was always doing left projections OK. Well, it turns out I can turn the left projection into a right projection by taking the convex the convex conjugate of the original function that I started with and using that instead.",
            "OK, so that would amount to replacing the star here and putting them here OK, but that's why this isn't exactly Dijkstra's algorithm.",
            "But the benefit here is."
        ],
        [
            "Clear, so if you want to move to the next slide, here's our pretty picture.",
            "Of course, this is an artistic illustration where we take the Bregman divergences an we turn it into orthogonal projections.",
            "OK, so when we do this, the distance, the difference between a right projection and a left projection is moot.",
            "OK, it's symmetric now, and of course we obtain the convergent algorithm Dijkstra's algorithm.",
            "OK, so."
        ],
        [
            "So if you want to move on, what does all this mean?",
            "What am I trying to bring to this well?",
            "You could say that EP replaces the left projection in Dijkstra's algorithm with the right projection, and it's as important a log convex set for a convex set.",
            "OK, and if you were to switch those two things, you yield a convergent algorithm.",
            "So the point here is to use this fact.",
            "The hope is to use this fact to analyze the convergence behavior of EP, which we all know is well not well understood in the least bit alright and.",
            "This could later perhaps be used to explain the root of occasionally good convergence behavior, and this happens to be one of my favorite toy open."
        ],
        [
            "Problems, so if you want to go to the next slide, alright, so this might seem crazy.",
            "You say EP you read, you read the description.",
            "Tom Inc is eat the description of EP and you get right to right at the beginning of the book and you're already seeing ardman of KL divergences and this is an information projection.",
            "So isn't the completed information projection interpretation already done?",
            "What has this extra Bregman divergences framework added for us?",
            "Well, it's just summarized in this.",
            "We've described the formation of this density.",
            "As a projection OK, and that actually lies in the difference between a lot of the other information.",
            "Projection analysis for cases of EP.",
            "Like the Turbo decoder, the LDC decoder, which happens to be the route in which I came into this field.",
            "This is where the novelty in this exposition lies that Dijkstra preprocessing is with the two sets that we picked is what allows us to form this density as the result of a projection in some preprocessing.",
            "OK. And of course previous information projections expositions, including this one, had this as this formation as an intervening step, as opposed to a projection.",
            "So you didn't really have a complete projections algorithm interpretation."
        ],
        [
            "Alright, so let's move on.",
            "Can you spend a little bit more what is projected onto what in this?"
        ],
        [
            "This left equation so my messages and my factor is project.",
            "So what's happened is I have this space where I have a product OK now of M copies.",
            "One for each factor.",
            "And these variables in these factors are now treated as different variables in this product space.",
            "That's the whole point of introducing the product space, OK?",
            "There are two projections.",
            "There are two things that go into the projection to make this make this density OK.",
            "The first thing is what takes this density and makes it into that.",
            "OK, that's the diekstra preprocessing.",
            "I'll just tell you and the next thing which makes this density into this.",
            "Is A is a left projection, which is of course intuitive when you do left projections, you always wind up with this sort of multiplication as the solution.",
            "You can show that.",
            "Exponential family yes, I an I should say this, we are not assuming we're assuming exponential family abrod exponential family, within which the true distribution lies.",
            "OK, but this does not mean that we ever work with this broad exponential family.",
            "OK, it's only I only need it for the sake of doing this analysis.",
            "Do you see what I'm saying?",
            "OK, so it could be an incredibly complex exponential family, but it needs to be an exponential family.",
            "And also we need that.",
            "Remember I said just from this notation.",
            "You can see these are exponential family factors, which is fairly common because of course we know that when that's the case, we can evaluate expectations of sufficient statistics to do the refinement rules.",
            "We don't have to do some minimization of the KL divergent's directly, OK?",
            "And yes, I need those to be exponential families too, and this needs to be a sub family of the larger fan."
        ],
        [
            "OK, so I don't want you to go home hungry.",
            "This was kind of like I wanted.",
            "It's nice to have everyone who's interested in these problems here.",
            "I wanted to advertise this as my favorite problem.",
            "It started.",
            "It's about maybe 3/4 done and I want to invite other people to try to use that connection.",
            "Use that interpretation to predict when their special instances of EP converge.",
            "Because of course this is such a wide, broad family of algorithms that you're going to have convergence conditions that are going to be.",
            "That should be dependent on your particular context.",
            "OK so but just so you don't go home hungry.",
            "You wanted a convergence proof.",
            "I want to give you a convergence proof.",
            "OK, so let's get to a convergence proof.",
            "Alright, so the idea here now is to shift gears, move away from Bregman projections, and to look at the system of equations.",
            "That EP is kind of iteratively solving an interpret the method in which we're solving these is something called the nonlinear block.",
            "Gauss Seidel iteration.",
            "OK, and so this amounts to writing down the entire system of equations.",
            "For an EP stationary point, namely that the expected value sufficient statistics under the approximating distribution and all those weighted distributions match for all of the different factors OK, and Now you view refinement as a solution for a subset of the variables, namely, the factor that you're refining.",
            "OK, the approximating factor that you're refining.",
            "For a subset of the equations at any given time?",
            "OK, so this is a very fairly."
        ],
        [
            "Correct point, and if you were to write out that instead of the in the expectation space you move back to the log space, there's a reason to do this, because of course I'm working with the log parameters.",
            "I probably want my equations to be in the log parameters as well.",
            "OK, and the way I do that is again, by this gradient of the negentropy that will move me in between.",
            "You know, here's a system of equations.",
            "It's it.",
            "Turns out that with a couple more manipulations, you can set it up like this.",
            "And if when regarded as a function of our parameters, are natural parameters or natural log parameters for the exponential family distribution.",
            "This this function is an M function, so this is straight I should say straight out of the theory for Gauss Seidel, iterative, nonlinear black, Gauss, Seidel iterative methods.",
            "OK, this is you take that convergence proof, you move it over here, you slap it down.",
            "That's all there is to this.",
            "If it's an M function.",
            "Continuous and surjective then it converges.",
            "E converges to a unique solution and thus the unique interior critical point of the constrained free energy minimization problem OK."
        ],
        [
            "So moving on, hope you didn't go home hungry."
        ],
        [
            "I'll take any questions.",
            "Oh OK, it has to do 1 weight.",
            "One way to explain it.",
            "One way to explain it is to look at the.",
            "The Jacobian matrix of this.",
            "OK, and M function amounts to a positive definite Jacobian matrix.",
            "Negative off diagonal elements and positive on diagonal elements.",
            "So there seems to be some sort of connection here to ideas like monotonicity, monotonicity, certainly, and as well as.",
            "Perhaps there's some connection with.",
            "This is this is a vague idea, but maybe super modularity ideas, but yeah, this is you.",
            "Basically.",
            "Take that theory and you plop it right down here.",
            "That's all there is to this.",
            "Whether or not you can get any insight in particular instances of EP lies in whether or not you can check whether or not these functions are M functions easily enough, an at least in the case of the Turbo decoder I tried to do that and it turns out that the conditions that you have to check or rather difficult to check because it amounts to moving over the almost the entire parameter space.",
            "If you use the method that I just described, where you look at the derivative matrix, the Jacobian matrix, and you evaluate whether or not it has this nice property, you now have to consider that for every single place where you could evaluate the Jacobian matrix right and that becomes a very computationally difficult problem.",
            "This domain is thought about well, yes they have.",
            "But I must say that this has lossed lossed kind of interest.",
            "As far as I can tell this is this is out of Rhinebolt van LJ Rhinebolt's work, and he was at the University of Maryland writing this stuff in the 1970s, so I don't know.",
            "In fact, that paper that this is out of is from a PDE conference.",
            "They were using these techniques to solve PDS numerically.",
            "I don't know if there are that many people who study this as this as a research method, because of course it's such a general set of problems.",
            "I think that's kind of what's at issue here.",
            "You know the theory that has to do has to handle so many special cases that it's hard to say something other than for some very very very special cases.",
            "Posters"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know there are a couple of very important pictures in this talk.",
                    "label": 0
                },
                {
                    "sent": "Maybe will try to get to them very quickly.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we go, alright, let's jump right into the thick of it.",
                    "label": 0
                },
                {
                    "sent": "You guys have seen this six or seven different times today I think, but exponential family densities.",
                    "label": 1
                },
                {
                    "sent": "Here we go are sufficient statistics.",
                    "label": 0
                },
                {
                    "sent": "Functions are parameters that we're optimizing the log partition function for free energy that he was just working with in the previous talk.",
                    "label": 1
                },
                {
                    "sent": "You get this nice thing that if you take the dual of that log partition function, you get the negative of the Shannon entropy.",
                    "label": 0
                },
                {
                    "sent": "This is all standard.",
                    "label": 0
                },
                {
                    "sent": "Exponential families you could call it information geometry, but not really doing anything with the Romanian metric, whereas my information geometry yeah, no remaining metric in this talk.",
                    "label": 0
                },
                {
                    "sent": "So all right, and you know, of course, with that duality you get this nice one to one relationship between the log parameters and the expectation parameters, and you'll notice that these are the expected values of the sufficient statistics.",
                    "label": 1
                },
                {
                    "sent": "OK, that's about all we need to.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you want to go to the next slide.",
                    "label": 0
                },
                {
                    "sent": "OK so EP for the 15th time today.",
                    "label": 0
                },
                {
                    "sent": "What is it alright?",
                    "label": 0
                },
                {
                    "sent": "Well we have a joint density.",
                    "label": 0
                },
                {
                    "sent": "You know it factors into a product of smaller functions of the parameters.",
                    "label": 0
                },
                {
                    "sent": "Theater a.",
                    "label": 0
                },
                {
                    "sent": "This is an abuse of notation to say that Theta A is a subvector of Theta and the idea is to exploit this factorization.",
                    "label": 0
                },
                {
                    "sent": "One of many that we could pick right with a factorization of the same form and I'm going to say although there's some people who say that you don't have to use exponential families to do EP.",
                    "label": 0
                },
                {
                    "sent": "I'm going to say I'm the focus.",
                    "label": 0
                },
                {
                    "sent": "I should say on the on the exponential family case today so my factors are going to be exponential families.",
                    "label": 0
                },
                {
                    "sent": "And of course, the reason why is that when I'm in exponential families and I go to do the refinement step in EP well, the argument of the KL divergences that results to a moment matching criteria.",
                    "label": 0
                },
                {
                    "sent": "In other words, when I say moment matching, the expected values of the sufficient statistics for the two distributions.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's our familiar.",
                    "label": 0
                },
                {
                    "sent": "You keep around the one nasty factor, as he said in the previous talk and remove it from the approximating distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you met.",
                    "label": 0
                },
                {
                    "sent": "You fit that to the.",
                    "label": 0
                },
                {
                    "sent": "Product of all the approximating factors or the approximate.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distribution next slide please.",
                    "label": 0
                },
                {
                    "sent": "OK, so one last bit of prerequisite here.",
                    "label": 0
                },
                {
                    "sent": "Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "We had one of those nice six invited talks at NIPS this year was by year sensor Champion of Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "Well, what the heck are these and why are they relevant and why am I bringing them up?",
                    "label": 0
                },
                {
                    "sent": "So let's let's go through that very quickly.",
                    "label": 0
                },
                {
                    "sent": "You basically start with a fact that a differentiable convex function is lower bounded by its first order Taylor approximation and so in other words, if H is of lizandra type.",
                    "label": 1
                },
                {
                    "sent": "Which you have a couple more requirements there, but let's just stick with that.",
                    "label": 0
                },
                {
                    "sent": "It means here's our value at a particular set of parameters.",
                    "label": 0
                },
                {
                    "sent": "And here's our linear approximation out to 1st order, an indeed it's it's greater than that, and there's that great picture that you can always draw that shows that, and it would be nice if I'd put this up on the slide, but I made this a little too hastily anyway.",
                    "label": 0
                },
                {
                    "sent": "Let's keep moving Bregman divergences, it's alright, Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, we really do want to go fast.",
                    "label": 0
                },
                {
                    "sent": "You know, we take this thing and we make a distance like metric out of it.",
                    "label": 0
                },
                {
                    "sent": "You can see it's basically just like the difference between the actual value in the Taylor approximation, right?",
                    "label": 0
                },
                {
                    "sent": "And that's what year sensors showed you in his talk with the nice picture.",
                    "label": 1
                },
                {
                    "sent": "Alright, and in particular, these things have some properties of distance.",
                    "label": 1
                },
                {
                    "sent": "In particular, we see from 66 being the linear approximation that is greater than or equal 0, and it's equal to 0 if and only if the parameters are equal.",
                    "label": 1
                },
                {
                    "sent": "Alright, but on the other hand it's not symmetric.",
                    "label": 0
                },
                {
                    "sent": "You need some special cases to have a triangle inequality that some of the cool stuff you can prove about this, and of course, as you guys could probably anticipate I'm just going to choose H to be the negentropy, and so I get the callback Leibler divergent's as my Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "But there's a reason for going to this higher.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For which we'll get to in a moment, so please move on.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's talk about projections.",
                    "label": 0
                },
                {
                    "sent": "Algorithms that are built from Bregman divergences?",
                    "label": 0
                },
                {
                    "sent": "Well, there's some very intuitive ones, since since of course the Bregman divergences is not symmetric, left projection is different from the right projection you will be familiar with this from the KL divergences.",
                    "label": 0
                },
                {
                    "sent": "Most of you probably anyway, so you can build alternating projections algorithms between two different sets.",
                    "label": 0
                },
                {
                    "sent": "Alright, so here's our alternating projections.",
                    "label": 0
                },
                {
                    "sent": "Please move on these.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've been analyzed.",
                    "label": 0
                },
                {
                    "sent": "There's some very old work by Chichar using the KL distance on that and Dijkstra's algorithm with cyclic Bregman projections.",
                    "label": 1
                },
                {
                    "sent": "This is the one that we wanted.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the reason for going up to the higher layer OK, an namely what does this do?",
                    "label": 1
                },
                {
                    "sent": "OK, so we'd like to find the point in the union of some SI believe capital S convex sets.",
                    "label": 0
                },
                {
                    "sent": "Now intersection of some S convex sets.",
                    "label": 0
                },
                {
                    "sent": "That's closest to our initial point, so this this algorithm will solve it.",
                    "label": 0
                },
                {
                    "sent": "OK, what do we do closest in the sense of a left projection?",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we do this?",
                    "label": 1
                },
                {
                    "sent": "Well, we start.",
                    "label": 0
                },
                {
                    "sent": "We initialize these towels at zero and we project onto the set and we formed this difference between the gradient of the convex function we built the Bregman divergences with our previous.",
                    "label": 0
                },
                {
                    "sent": "Tau and where we wound up after the projection.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's add some context.",
                    "label": 0
                },
                {
                    "sent": "Choose H to be the negative entropy.",
                    "label": 0
                },
                {
                    "sent": "Now remember what it does.",
                    "label": 0
                },
                {
                    "sent": "The gradient then of H will map in between the.",
                    "label": 0
                },
                {
                    "sent": "The expectation coordinates.",
                    "label": 0
                },
                {
                    "sent": "So in other words, the expected values of sufficient statistics for this particular exponential distribution to the log parameters.",
                    "label": 0
                },
                {
                    "sent": "So let's say we're doing a binary distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, this would be the map between the probability that the bid is 1 and the log likelihood ratio.",
                    "label": 0
                },
                {
                    "sent": "And the reason why this is going to be useful?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See, in a second, please move on.",
                    "label": 0
                },
                {
                    "sent": "Well, well, let's first introduce two sets that are related to the information projection formulation of EP.",
                    "label": 0
                },
                {
                    "sent": "Well, first we make as many copies of the spaces that were factors.",
                    "label": 1
                },
                {
                    "sent": "So we copy the space OK and one set is the set of densities which are supported on all copies being equal.",
                    "label": 1
                },
                {
                    "sent": "Now if I might have some mathematicians in the room that feel like I've just run my fingers down a chalkboard by saying that because of course if things are continuous.",
                    "label": 0
                },
                {
                    "sent": "The probability that condition continuously distributed random variables that are not identical or equal being constrained well.",
                    "label": 0
                },
                {
                    "sent": "Of course, that's always defined to be 0, but you can consider an appropriate limiting process which which effectively makes this set in the parameter space is another set that's going to be of interest.",
                    "label": 1
                },
                {
                    "sent": "Is a product of densities of the approximating family form.",
                    "label": 0
                },
                {
                    "sent": "So in other words, this is just I take the approximating family and I copy it M times and I multiply it by itself, OK?",
                    "label": 0
                },
                {
                    "sent": "And the starting point is where I take my original distribution now and I don't I no longer pay attention to the fact that the same variable was repeated in several factors.",
                    "label": 0
                },
                {
                    "sent": "In other words, you can think of a factor graph.",
                    "label": 0
                },
                {
                    "sent": "Again, this would be a good thing to draw.",
                    "label": 0
                },
                {
                    "sent": "You can think of the factor graph which had each of the variables that I was trying to infer, and it was connected to each of the factors in that distribution, and an edge connects a variable in effect, or if that factor depends on that edge, what we're going to do is we're going to cut.",
                    "label": 0
                },
                {
                    "sent": "That that graph in half OK and we're no longer to pay attention that we've replicated the same variables in the same place.",
                    "label": 0
                },
                {
                    "sent": "And we're going to write the distribution.",
                    "label": 0
                },
                {
                    "sent": "If that were the case, OK, that's going to be our initial.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Starting point for our projection algorithm and just to give you some visual intuition here, here are two sets for the case of two.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's let's move on.",
                    "label": 0
                },
                {
                    "sent": "Alright, so let's now try to see how EP could be viewed as a projections algorithm.",
                    "label": 1
                },
                {
                    "sent": "Well, what do we do?",
                    "label": 0
                },
                {
                    "sent": "We start with that starting point.",
                    "label": 0
                },
                {
                    "sent": "We projected onto Q OK, which product takes the product of all of the.",
                    "label": 0
                },
                {
                    "sent": "The factors together.",
                    "label": 0
                },
                {
                    "sent": "Then we project that onto P and we do Dijkstra's algorithm essentially and the only difference between this and Dijkstra's algorithm is that if we were to be proper when we're following a Dijkstra preprocessing with the projection, this is the type of dikes to preprocessing that you do.",
                    "label": 0
                },
                {
                    "sent": "For a left projection.",
                    "label": 1
                },
                {
                    "sent": "If you'll notice the method of cyclic Bregman projections, I was always doing left projections OK. Well, it turns out I can turn the left projection into a right projection by taking the convex the convex conjugate of the original function that I started with and using that instead.",
                    "label": 0
                },
                {
                    "sent": "OK, so that would amount to replacing the star here and putting them here OK, but that's why this isn't exactly Dijkstra's algorithm.",
                    "label": 0
                },
                {
                    "sent": "But the benefit here is.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clear, so if you want to move to the next slide, here's our pretty picture.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is an artistic illustration where we take the Bregman divergences an we turn it into orthogonal projections.",
                    "label": 0
                },
                {
                    "sent": "OK, so when we do this, the distance, the difference between a right projection and a left projection is moot.",
                    "label": 0
                },
                {
                    "sent": "OK, it's symmetric now, and of course we obtain the convergent algorithm Dijkstra's algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you want to move on, what does all this mean?",
                    "label": 1
                },
                {
                    "sent": "What am I trying to bring to this well?",
                    "label": 1
                },
                {
                    "sent": "You could say that EP replaces the left projection in Dijkstra's algorithm with the right projection, and it's as important a log convex set for a convex set.",
                    "label": 0
                },
                {
                    "sent": "OK, and if you were to switch those two things, you yield a convergent algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the point here is to use this fact.",
                    "label": 0
                },
                {
                    "sent": "The hope is to use this fact to analyze the convergence behavior of EP, which we all know is well not well understood in the least bit alright and.",
                    "label": 0
                },
                {
                    "sent": "This could later perhaps be used to explain the root of occasionally good convergence behavior, and this happens to be one of my favorite toy open.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problems, so if you want to go to the next slide, alright, so this might seem crazy.",
                    "label": 0
                },
                {
                    "sent": "You say EP you read, you read the description.",
                    "label": 0
                },
                {
                    "sent": "Tom Inc is eat the description of EP and you get right to right at the beginning of the book and you're already seeing ardman of KL divergences and this is an information projection.",
                    "label": 0
                },
                {
                    "sent": "So isn't the completed information projection interpretation already done?",
                    "label": 0
                },
                {
                    "sent": "What has this extra Bregman divergences framework added for us?",
                    "label": 0
                },
                {
                    "sent": "Well, it's just summarized in this.",
                    "label": 0
                },
                {
                    "sent": "We've described the formation of this density.",
                    "label": 0
                },
                {
                    "sent": "As a projection OK, and that actually lies in the difference between a lot of the other information.",
                    "label": 0
                },
                {
                    "sent": "Projection analysis for cases of EP.",
                    "label": 0
                },
                {
                    "sent": "Like the Turbo decoder, the LDC decoder, which happens to be the route in which I came into this field.",
                    "label": 0
                },
                {
                    "sent": "This is where the novelty in this exposition lies that Dijkstra preprocessing is with the two sets that we picked is what allows us to form this density as the result of a projection in some preprocessing.",
                    "label": 0
                },
                {
                    "sent": "OK. And of course previous information projections expositions, including this one, had this as this formation as an intervening step, as opposed to a projection.",
                    "label": 1
                },
                {
                    "sent": "So you didn't really have a complete projections algorithm interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so let's move on.",
                    "label": 0
                },
                {
                    "sent": "Can you spend a little bit more what is projected onto what in this?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This left equation so my messages and my factor is project.",
                    "label": 0
                },
                {
                    "sent": "So what's happened is I have this space where I have a product OK now of M copies.",
                    "label": 0
                },
                {
                    "sent": "One for each factor.",
                    "label": 0
                },
                {
                    "sent": "And these variables in these factors are now treated as different variables in this product space.",
                    "label": 0
                },
                {
                    "sent": "That's the whole point of introducing the product space, OK?",
                    "label": 0
                },
                {
                    "sent": "There are two projections.",
                    "label": 0
                },
                {
                    "sent": "There are two things that go into the projection to make this make this density OK.",
                    "label": 0
                },
                {
                    "sent": "The first thing is what takes this density and makes it into that.",
                    "label": 0
                },
                {
                    "sent": "OK, that's the diekstra preprocessing.",
                    "label": 0
                },
                {
                    "sent": "I'll just tell you and the next thing which makes this density into this.",
                    "label": 0
                },
                {
                    "sent": "Is A is a left projection, which is of course intuitive when you do left projections, you always wind up with this sort of multiplication as the solution.",
                    "label": 0
                },
                {
                    "sent": "You can show that.",
                    "label": 0
                },
                {
                    "sent": "Exponential family yes, I an I should say this, we are not assuming we're assuming exponential family abrod exponential family, within which the true distribution lies.",
                    "label": 0
                },
                {
                    "sent": "OK, but this does not mean that we ever work with this broad exponential family.",
                    "label": 0
                },
                {
                    "sent": "OK, it's only I only need it for the sake of doing this analysis.",
                    "label": 0
                },
                {
                    "sent": "Do you see what I'm saying?",
                    "label": 0
                },
                {
                    "sent": "OK, so it could be an incredibly complex exponential family, but it needs to be an exponential family.",
                    "label": 0
                },
                {
                    "sent": "And also we need that.",
                    "label": 0
                },
                {
                    "sent": "Remember I said just from this notation.",
                    "label": 0
                },
                {
                    "sent": "You can see these are exponential family factors, which is fairly common because of course we know that when that's the case, we can evaluate expectations of sufficient statistics to do the refinement rules.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do some minimization of the KL divergent's directly, OK?",
                    "label": 0
                },
                {
                    "sent": "And yes, I need those to be exponential families too, and this needs to be a sub family of the larger fan.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I don't want you to go home hungry.",
                    "label": 0
                },
                {
                    "sent": "This was kind of like I wanted.",
                    "label": 0
                },
                {
                    "sent": "It's nice to have everyone who's interested in these problems here.",
                    "label": 0
                },
                {
                    "sent": "I wanted to advertise this as my favorite problem.",
                    "label": 0
                },
                {
                    "sent": "It started.",
                    "label": 0
                },
                {
                    "sent": "It's about maybe 3/4 done and I want to invite other people to try to use that connection.",
                    "label": 0
                },
                {
                    "sent": "Use that interpretation to predict when their special instances of EP converge.",
                    "label": 0
                },
                {
                    "sent": "Because of course this is such a wide, broad family of algorithms that you're going to have convergence conditions that are going to be.",
                    "label": 0
                },
                {
                    "sent": "That should be dependent on your particular context.",
                    "label": 0
                },
                {
                    "sent": "OK so but just so you don't go home hungry.",
                    "label": 1
                },
                {
                    "sent": "You wanted a convergence proof.",
                    "label": 0
                },
                {
                    "sent": "I want to give you a convergence proof.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's get to a convergence proof.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the idea here now is to shift gears, move away from Bregman projections, and to look at the system of equations.",
                    "label": 0
                },
                {
                    "sent": "That EP is kind of iteratively solving an interpret the method in which we're solving these is something called the nonlinear block.",
                    "label": 0
                },
                {
                    "sent": "Gauss Seidel iteration.",
                    "label": 1
                },
                {
                    "sent": "OK, and so this amounts to writing down the entire system of equations.",
                    "label": 0
                },
                {
                    "sent": "For an EP stationary point, namely that the expected value sufficient statistics under the approximating distribution and all those weighted distributions match for all of the different factors OK, and Now you view refinement as a solution for a subset of the variables, namely, the factor that you're refining.",
                    "label": 0
                },
                {
                    "sent": "OK, the approximating factor that you're refining.",
                    "label": 0
                },
                {
                    "sent": "For a subset of the equations at any given time?",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very fairly.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Correct point, and if you were to write out that instead of the in the expectation space you move back to the log space, there's a reason to do this, because of course I'm working with the log parameters.",
                    "label": 0
                },
                {
                    "sent": "I probably want my equations to be in the log parameters as well.",
                    "label": 0
                },
                {
                    "sent": "OK, and the way I do that is again, by this gradient of the negentropy that will move me in between.",
                    "label": 0
                },
                {
                    "sent": "You know, here's a system of equations.",
                    "label": 1
                },
                {
                    "sent": "It's it.",
                    "label": 0
                },
                {
                    "sent": "Turns out that with a couple more manipulations, you can set it up like this.",
                    "label": 0
                },
                {
                    "sent": "And if when regarded as a function of our parameters, are natural parameters or natural log parameters for the exponential family distribution.",
                    "label": 1
                },
                {
                    "sent": "This this function is an M function, so this is straight I should say straight out of the theory for Gauss Seidel, iterative, nonlinear black, Gauss, Seidel iterative methods.",
                    "label": 0
                },
                {
                    "sent": "OK, this is you take that convergence proof, you move it over here, you slap it down.",
                    "label": 0
                },
                {
                    "sent": "That's all there is to this.",
                    "label": 0
                },
                {
                    "sent": "If it's an M function.",
                    "label": 1
                },
                {
                    "sent": "Continuous and surjective then it converges.",
                    "label": 0
                },
                {
                    "sent": "E converges to a unique solution and thus the unique interior critical point of the constrained free energy minimization problem OK.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So moving on, hope you didn't go home hungry.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll take any questions.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, it has to do 1 weight.",
                    "label": 0
                },
                {
                    "sent": "One way to explain it.",
                    "label": 0
                },
                {
                    "sent": "One way to explain it is to look at the.",
                    "label": 0
                },
                {
                    "sent": "The Jacobian matrix of this.",
                    "label": 0
                },
                {
                    "sent": "OK, and M function amounts to a positive definite Jacobian matrix.",
                    "label": 0
                },
                {
                    "sent": "Negative off diagonal elements and positive on diagonal elements.",
                    "label": 0
                },
                {
                    "sent": "So there seems to be some sort of connection here to ideas like monotonicity, monotonicity, certainly, and as well as.",
                    "label": 0
                },
                {
                    "sent": "Perhaps there's some connection with.",
                    "label": 0
                },
                {
                    "sent": "This is this is a vague idea, but maybe super modularity ideas, but yeah, this is you.",
                    "label": 0
                },
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "Take that theory and you plop it right down here.",
                    "label": 0
                },
                {
                    "sent": "That's all there is to this.",
                    "label": 0
                },
                {
                    "sent": "Whether or not you can get any insight in particular instances of EP lies in whether or not you can check whether or not these functions are M functions easily enough, an at least in the case of the Turbo decoder I tried to do that and it turns out that the conditions that you have to check or rather difficult to check because it amounts to moving over the almost the entire parameter space.",
                    "label": 0
                },
                {
                    "sent": "If you use the method that I just described, where you look at the derivative matrix, the Jacobian matrix, and you evaluate whether or not it has this nice property, you now have to consider that for every single place where you could evaluate the Jacobian matrix right and that becomes a very computationally difficult problem.",
                    "label": 0
                },
                {
                    "sent": "This domain is thought about well, yes they have.",
                    "label": 0
                },
                {
                    "sent": "But I must say that this has lossed lossed kind of interest.",
                    "label": 0
                },
                {
                    "sent": "As far as I can tell this is this is out of Rhinebolt van LJ Rhinebolt's work, and he was at the University of Maryland writing this stuff in the 1970s, so I don't know.",
                    "label": 0
                },
                {
                    "sent": "In fact, that paper that this is out of is from a PDE conference.",
                    "label": 0
                },
                {
                    "sent": "They were using these techniques to solve PDS numerically.",
                    "label": 0
                },
                {
                    "sent": "I don't know if there are that many people who study this as this as a research method, because of course it's such a general set of problems.",
                    "label": 0
                },
                {
                    "sent": "I think that's kind of what's at issue here.",
                    "label": 0
                },
                {
                    "sent": "You know the theory that has to do has to handle so many special cases that it's hard to say something other than for some very very very special cases.",
                    "label": 0
                },
                {
                    "sent": "Posters",
                    "label": 0
                }
            ]
        }
    }
}