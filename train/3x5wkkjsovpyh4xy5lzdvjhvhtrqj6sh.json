{
    "id": "3x5wkkjsovpyh4xy5lzdvjhvhtrqj6sh",
    "title": "Learning to Disambiguate Natural Language Using World Knowledge",
    "info": {
        "author": [
            "Antoine Bordes, Facebook"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Programming Languages"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_bordes_ldnluwk/",
    "segmentation": [
        [
            "Hello, it's a joint work with Nicole Engineer in Paris, Jason Western and Ronnoco Bear in NEC.",
            "And so we're going to talk about or pretty minier or work about disambiguation using London Edge."
        ],
        [
            "So basic idea was there is a strong prior knowledge that most work doesn't uses that we understand language becausw it has a deep connection to the world it is used for.",
            "So all go in.",
            "Our work is to learn to use both syntax but also the surrounding environment to try to understand or at least interpret natural language.",
            "So for example there are some examples here and he passed the exam or John went to the bank.",
            "You can basically have a better understanding of what that means if you know that Frank took an exam last week or if John is in the countryside and not in the city, and so that the the meaning can occur."
        ],
        [
            "So this is an old idea.",
            "This is a quote from Vinagre in 1971 and he said when the human reader sees a sentence, he used knowledge to understand it.",
            "This includes not only grammar but also is knowledge about words, the context of the sentence and most important is knowledge about the subject matter.",
            "A computer program supplied with only grammar for manipulating the syntax of language could not produce a translation of reasonable quality, so.",
            "That's what he said.",
            "And then after most work following his work didn't success because.",
            "Modeling the world knowledge and having a world model is really hard to get.",
            "But"
        ],
        [
            "Nowadays we could see a lot of modern application with set up like this, like for example in multiplayer online games.",
            "The World model is known because it's it's included in the database.",
            "So you have all the character that that are talking to each other with natural language and they're behaving in an environment that is totally known.",
            "So we say OK, why not trying something like this?",
            "So we are."
        ],
        [
            "Proposing the task of concept labeling the so the task is labeling task.",
            "So the goal is to map natural language sentence X to its labeling in terms of concept using what we call a universe which represents the current state of the world.",
            "So the universe would be a set of concept.",
            "For example, here it will be rated to house.",
            "So you got location like Kitchen or object like surprise people like Gina or Joan and they are related.",
            "They have relation between them.",
            "So Gina for example we are considering two types of relation in our work.",
            "So location and content by.",
            "So for example what what is written is that Gina is in the kitchen.",
            "John is in the kitchen, the Gina as the rise and so on.",
            "Entity tokens, not types.",
            "That's a particular kitchen.",
            "Yeah yeah, that's a particularly it's important, yeah?",
            "Yeah, it's kitchen a yeah.",
            "Yeah, it is a particular box of rice as well, so these are elements of the world.",
            "And so this universe is evolving because they relate the relation are moving.",
            "People are changing places and stuff and so you have word.",
            "You are verbs that can be seen as operator in this world.",
            "For example if you say move Gina Kitchen, she will move from one location to another one.",
            "So whole goal is given natural language sentences to predict which concept from the database are related to it.",
            "Because we think that it will be like a first step of understanding, or at least an interpretation of the meaning of the sentence.",
            "So."
        ],
        [
            "We will try that in the supervised fashion so we have to gather data and so together data like this is pretty hard because you have to align everything very precisely.",
            "You have to, so it's very complicated to label.",
            "So in our work we will consider some strong supervision, but it's kinda annoying and some weak supervision as well, which is much more realistic.",
            "So we just say that we have a sentence.",
            "We have the database and we also know that the concepts related to the sentence.",
            "As a bag, we don't need the alignment, so it's much more easy to gather some data."
        ],
        [
            "So the main difficulties in the in our work then, is the ambiguous words, because as soon as you have an ambiguity in the sentence, you can't.",
            "Really, you have to guess or to find out which concentrated too, so it can be like for pronouns.",
            "For example, as we can have several cartoons of milk in the universe.",
            "If we say give me the milk on the table, we need to know which milk it you're talking about, and so on.",
            "So this is the main difficulty of concept leveling in our setup is to try to use the unit the world knowledge to guess and to try to find out the to disambiguate these words."
        ],
        [
            "So here is Reese short example of what we'd like the system to be able to do.",
            "So we have a small universe with only one type of relation, which is location, and we have this sentence that we would like to.",
            "To label so."
        ],
        [
            "Like this, the first word is ambiguous is ambiguous because it's a pronoun.",
            "So we like the system to begin by label by versus suryn.",
            "So for example."
        ],
        [
            "There doesn't refer to any concept.",
            "The rise.",
            "It's discounted price is only one, so it's straightforward and."
        ],
        [
            "Refers to the web of cooking, so that's fine.",
            "And now we have to to find out who he refers to.",
            "And so now we like the system to be able."
        ],
        [
            "To do to use this kind of rules?",
            "First of all, the rice we know that the rise in the kitchen, so he refers to someone in the kitchen.",
            "Like here John or Gina second, he refers only to a subset of the concept.",
            "It's a linguistic information.",
            "It refers only to Mail, so it refers to John or Mark, and so with these two very simple rules you can."
        ],
        [
            "Everybody can guess that John Cook the rice because it's in the kitchen so, but."
        ],
        [
            "But for US it's challenging because this rule have just shown we want.",
            "We don't want to give them explicitly in training.",
            "We just go want algorithm to infer out of the universe and the language which which rule it needs to use to find out.",
            "So this was like the main motivation and amendment revision of the world and of the work.",
            "And we also don't want to give no engineering feature about or to describe the language and the concepts themselves.",
            "So we want basically the algorithm to try to discover as much as he could from raw data."
        ],
        [
            "So here's a learning algorithm to perform this."
        ],
        [
            "Ask so we want the matching score.",
            "This is that we have a triple like a sentence of candidate labeling and a universe, and we say that we want to predict the the the prediction is the one that maximizes score.",
            "Of course, using a non Max like this would be like very slow because we would like to take care of everything and it's not straightforward because as we've seen in the example, maybe you need to predict the last word to get the information about the location to disambiguate the first word."
        ],
        [
            "So we rather use a greedy order free inference, so we just go through the the sentence.",
            "So for example, we first try to label every words and then we pick out the one that has the higher score from all the position.",
            "So we select the pair.",
            "The position comes set.",
            "We are the most confident in.",
            "We hope that it will learn to label first non ambiguous words.",
            "That's what I've shown.",
            "Then we will remove this position and iterate.",
            "To label all the position in the sentence.",
            "And what's interesting is when we have added concept to, the labeling will collect all the universe based feature.",
            "That means that we will collect its location, will collect is contained by an we so that to predict the next step we will use this feature."
        ],
        [
            "So to do this inference, we need so a scoring function that will say that.",
            "That will score a particular triple, so we would like something that could potentially encode the similarities like that could potentially encode that.",
            "For example, he refers to male and that Gina that John and Mark were male, and this sort of thing.",
            "So we will use neural networks that will.",
            "Pushing potentially embed the concept in the words and London feature.",
            "So yeah, it's I will show you on the on the picture.",
            "It's it's easier.",
            "But why?"
        ],
        [
            "It's interesting is that how do we encode the well knowledge into the prediction?",
            "So for each concept of the universe, we will know the mapping, lack of dimension D. For us it was 10, so it's a in the beginning.",
            "This representation is random and then we are learning it.",
            "And during the process of the inference, if we want to use the particular relation in the universe, information in the process, we will say that the particular concept and its relation are included with the concatenation of the mappings.",
            "So for example, if we know that the milk is located in the kitchen is contained by John.",
            "What we are going to give to the learning algorithm is the concatenation of the vector representing milk, the one representing kitchen and the one representing John.",
            "If we know that Gina is located in the bedroom, it's representation would be Gina, bedroom and nothing, and for example for the web cook if we only cook and nothing, nothing, and so if we were not using the universe, the representation will be like this.",
            "So we will just say we would learn some feature about milk, but we have no information about the universe by this concatenation.",
            "We are giving this information to the algorithm."
        ],
        [
            "So if we get back to the previous example and try to to to label here."
        ],
        [
            "Here's how the the neural network is working, so we're first taking a window around the world of interest.",
            "Here's the sentence.",
            "Here's the labels we have already predicts, so we know everything but this, and we take a.",
            "Yes you can.",
            "So we take a window around it and then we will."
        ],
        [
            "First, use the embeddings for the word, so we have a dictionary.",
            "We learning the feature of the words, so these are the blue blue vectors."
        ],
        [
            "And we also, as I've just explained, embedding what we already know about the prediction that is the representation of the concept and also the representation of their relations.",
            "So for example, here the location.",
            "So we have all these vectors we can't."
        ],
        [
            "Tonight them and we have a long representation of the window that is the sentence and also all the conceptual project so far."
        ],
        [
            "We use a linear layer to conduct the end dimensional space.",
            "We keep this representation that is the representation of the window with all the knowledge we have so far.",
            "Yes, the whole database.",
            "In yes.",
            "So huge.",
            "Yeah, it's included, but what we give to the here, we're only selecting the one that we have already predicts or.",
            "So we have an embedding for each concept, but here we are selecting the one that we know so far.",
            "So here for example, we only have 1, two, six 6 * 2 vector inputs, OK.",
            "I mean, it's just like a binary layer here, so we're saying, OK, I will.",
            "I'm going to select the tags I've already predicted that the wrong before.",
            "OK. OK. OK, so anyway this is the in green.",
            "This is a representation of the the knowledge we have so far about the sliding window."
        ],
        [
            "Then what we do is for all the concept of the universe.",
            "Right now that could be candidate to be the the tag.",
            "The missing type will do the same.",
            "So here yes we are including every in this part where I'm cutting all the universe now recursively.",
            "So we're taking for example why he could be joined, for example, and Johnny's in the kitchen.",
            "So we have this information in the universe we take."
        ],
        [
            "Representation in the embeddings.",
            "We could get an idea so it's much smaller and then we put this in the same space there.",
            "And we do."
        ],
        [
            "It's a dot product, so basically here on the with the the network is in two is a parallel architecture.",
            "On this, we're just encouraging what we know about the sentence so far and hereafter for every candidate we have.",
            "Like every people or we are going to find out their their own representation and then we do the product for for all of them and we'll take the one with the IO score and it will be like the prediction for this particular.",
            "Window."
        ],
        [
            "So we did some experiment and so its original task, so we don't have some.",
            "The data is.",
            "It's hard to find.",
            "So what we did is just we've created around like small game multiplayer online game.",
            "So we create a universe with 82 concept like people small objects so they can do like 15 actions like giving object to one another, moving from room to room's and we have a simulation algorithms that play actually the game inside.",
            "So we are they are doing actions.",
            "For each sections we are generating a sentence, natural language sentence, and the sentence can be either ambiguous on ambiguous.",
            "For example, it sits on the chair and we have the labeling like Mark, sit on the chair.",
            "The father get some yogurt and so on.",
            "So we can with this simulation we can make as much data as we can.",
            "So we generated 50,000 but.",
            "We only use the 10,000 from, so it's very convenient to get the.",
            "The."
        ],
        [
            "So then we we compared some.",
            "Submitted to to try this labeling technique.",
            "So we compare different tagging method.",
            "We compare some supervision type and also what's more important is the future.",
            "So here for example says restricted using strong supervision is using all the universe information.",
            "So we're giving all we all we can know about the universe.",
            "And here's another.",
            "Let's work with left to right.",
            "So basically the difference between these two is that this one is learning their meetings and this one is not because it's just using a binary feature so.",
            "When?"
        ],
        [
            "Meaning.",
            "And then after we are using the neural networks have described that he's doing other free and not left to right and for several amount of the information about the universe.",
            "So here we are just giving as it puts the sentence.",
            "So no information about the universe.",
            "So he would be like just tagging task.",
            "So it's very it's very hard.",
            "I mean for all the ambiguities it just guessing randomly so it's 35% error and then we're just using the information about the contained by.",
            "So not all the information and so it's down to 17%.",
            "And then we are using only the location relationship, which is more important and is down to 5% error.",
            "So that means that you give this information is able to use it.",
            "And of course, when we give the."
        ],
        [
            "All the information we're down to 0% because as we created our data, we just wanted to make sure that all the ambiguities where do we are creating can be resolved.",
            "If you were able to use the word knowledge properly, and so that's what happened."
        ],
        [
            "The final results.",
            "It is when we do use weak supervision that since we don't give the alignment training, we're just giving some bags.",
            "So it's as much.",
            "This is order to train, but we're still succeeding because it doesn't change the fact that you can use the information about the universe.",
            "So we have done two very good rates."
        ],
        [
            "So finally I can just show.",
            "As we are learning the representation of each concept of the database, we can after to try to do a nearest neighbor in the space of this concept to see who are the closest one.",
            "So they were randomly initialized of course, and so we can see after the training that Gina, the closest wanna frozen Maggie which is the female Mark, Brian and John, the football.",
            "The closest is the toy car and the video game and so on for the food is here and then you got the room, living room and kitchen.",
            "So basically the embeddings are doing what we want them to do.",
            "Is that uncut some similarities and saying, for example, what I wanted in the beginning that Mark is ready to Brian John, so he will be related to this subset."
        ],
        [
            "So as a summary, we planted a very simple a general framework of concept labeling that that might be used to try to decode or try to use, well knowledge to understand output sentences.",
            "We presented our algorithm that is using both other free parents and also embeddings to try to use this information and some simulated data that knows that using this to use well knowledge is possible.",
            "And so next train is now.",
            "Next step would be to go inside the multiplayer online game, get the universe and try to train someone to speak inside."
        ],
        [
            "Thank you.",
            "Time for one question.",
            "So you're calling concepts I might actually think of his entities and entity.",
            "Yeah, and there's a person want to ask you if you thought about Co reference as a way of identifying entities in natural texts and trying to apply this to just natural Texas.",
            "Yeah, read the key question is the universe.",
            "I mean we need to have this relationship between between the entities, so we need a database that is saying that this sentence is related to this one.",
            "And this is will be used to.",
            "So yeah, we.",
            "We thought about applying to existing task.",
            "But The thing is that without the database algorithm is exactly the same as what could be done before.",
            "I say what's really new is just the way that we can encode something more, and if this is something we have to create it before you know it's hard to get.",
            "That would be very good.",
            "I mean, we're looking to apply it to real text, let's help.",
            "Do you think I'm in the database like the world's structure?",
            "So that he learns the database.",
            "Sorry.",
            "Uh, yeah auto three out of text and I I love to I have no I have no Q ought to do it, I mean.",
            "That would be like very cool, but.",
            "I mean, so far we have relying really under database and so that's why we're really heading towards like these games where the database exists.",
            "But then after yeah, if we can infer the database out of free text.",
            "Well done I think.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, it's a joint work with Nicole Engineer in Paris, Jason Western and Ronnoco Bear in NEC.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to talk about or pretty minier or work about disambiguation using London Edge.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basic idea was there is a strong prior knowledge that most work doesn't uses that we understand language becausw it has a deep connection to the world it is used for.",
                    "label": 1
                },
                {
                    "sent": "So all go in.",
                    "label": 1
                },
                {
                    "sent": "Our work is to learn to use both syntax but also the surrounding environment to try to understand or at least interpret natural language.",
                    "label": 0
                },
                {
                    "sent": "So for example there are some examples here and he passed the exam or John went to the bank.",
                    "label": 0
                },
                {
                    "sent": "You can basically have a better understanding of what that means if you know that Frank took an exam last week or if John is in the countryside and not in the city, and so that the the meaning can occur.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is an old idea.",
                    "label": 0
                },
                {
                    "sent": "This is a quote from Vinagre in 1971 and he said when the human reader sees a sentence, he used knowledge to understand it.",
                    "label": 0
                },
                {
                    "sent": "This includes not only grammar but also is knowledge about words, the context of the sentence and most important is knowledge about the subject matter.",
                    "label": 1
                },
                {
                    "sent": "A computer program supplied with only grammar for manipulating the syntax of language could not produce a translation of reasonable quality, so.",
                    "label": 1
                },
                {
                    "sent": "That's what he said.",
                    "label": 0
                },
                {
                    "sent": "And then after most work following his work didn't success because.",
                    "label": 0
                },
                {
                    "sent": "Modeling the world knowledge and having a world model is really hard to get.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nowadays we could see a lot of modern application with set up like this, like for example in multiplayer online games.",
                    "label": 1
                },
                {
                    "sent": "The World model is known because it's it's included in the database.",
                    "label": 0
                },
                {
                    "sent": "So you have all the character that that are talking to each other with natural language and they're behaving in an environment that is totally known.",
                    "label": 0
                },
                {
                    "sent": "So we say OK, why not trying something like this?",
                    "label": 0
                },
                {
                    "sent": "So we are.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proposing the task of concept labeling the so the task is labeling task.",
                    "label": 0
                },
                {
                    "sent": "So the goal is to map natural language sentence X to its labeling in terms of concept using what we call a universe which represents the current state of the world.",
                    "label": 1
                },
                {
                    "sent": "So the universe would be a set of concept.",
                    "label": 0
                },
                {
                    "sent": "For example, here it will be rated to house.",
                    "label": 0
                },
                {
                    "sent": "So you got location like Kitchen or object like surprise people like Gina or Joan and they are related.",
                    "label": 0
                },
                {
                    "sent": "They have relation between them.",
                    "label": 0
                },
                {
                    "sent": "So Gina for example we are considering two types of relation in our work.",
                    "label": 0
                },
                {
                    "sent": "So location and content by.",
                    "label": 0
                },
                {
                    "sent": "So for example what what is written is that Gina is in the kitchen.",
                    "label": 0
                },
                {
                    "sent": "John is in the kitchen, the Gina as the rise and so on.",
                    "label": 0
                },
                {
                    "sent": "Entity tokens, not types.",
                    "label": 0
                },
                {
                    "sent": "That's a particular kitchen.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, that's a particularly it's important, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's kitchen a yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it is a particular box of rice as well, so these are elements of the world.",
                    "label": 0
                },
                {
                    "sent": "And so this universe is evolving because they relate the relation are moving.",
                    "label": 0
                },
                {
                    "sent": "People are changing places and stuff and so you have word.",
                    "label": 0
                },
                {
                    "sent": "You are verbs that can be seen as operator in this world.",
                    "label": 0
                },
                {
                    "sent": "For example if you say move Gina Kitchen, she will move from one location to another one.",
                    "label": 0
                },
                {
                    "sent": "So whole goal is given natural language sentences to predict which concept from the database are related to it.",
                    "label": 0
                },
                {
                    "sent": "Because we think that it will be like a first step of understanding, or at least an interpretation of the meaning of the sentence.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will try that in the supervised fashion so we have to gather data and so together data like this is pretty hard because you have to align everything very precisely.",
                    "label": 0
                },
                {
                    "sent": "You have to, so it's very complicated to label.",
                    "label": 0
                },
                {
                    "sent": "So in our work we will consider some strong supervision, but it's kinda annoying and some weak supervision as well, which is much more realistic.",
                    "label": 0
                },
                {
                    "sent": "So we just say that we have a sentence.",
                    "label": 0
                },
                {
                    "sent": "We have the database and we also know that the concepts related to the sentence.",
                    "label": 0
                },
                {
                    "sent": "As a bag, we don't need the alignment, so it's much more easy to gather some data.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main difficulties in the in our work then, is the ambiguous words, because as soon as you have an ambiguity in the sentence, you can't.",
                    "label": 0
                },
                {
                    "sent": "Really, you have to guess or to find out which concentrated too, so it can be like for pronouns.",
                    "label": 0
                },
                {
                    "sent": "For example, as we can have several cartoons of milk in the universe.",
                    "label": 0
                },
                {
                    "sent": "If we say give me the milk on the table, we need to know which milk it you're talking about, and so on.",
                    "label": 1
                },
                {
                    "sent": "So this is the main difficulty of concept leveling in our setup is to try to use the unit the world knowledge to guess and to try to find out the to disambiguate these words.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is Reese short example of what we'd like the system to be able to do.",
                    "label": 0
                },
                {
                    "sent": "So we have a small universe with only one type of relation, which is location, and we have this sentence that we would like to.",
                    "label": 0
                },
                {
                    "sent": "To label so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like this, the first word is ambiguous is ambiguous because it's a pronoun.",
                    "label": 0
                },
                {
                    "sent": "So we like the system to begin by label by versus suryn.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There doesn't refer to any concept.",
                    "label": 0
                },
                {
                    "sent": "The rise.",
                    "label": 0
                },
                {
                    "sent": "It's discounted price is only one, so it's straightforward and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Refers to the web of cooking, so that's fine.",
                    "label": 0
                },
                {
                    "sent": "And now we have to to find out who he refers to.",
                    "label": 0
                },
                {
                    "sent": "And so now we like the system to be able.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do to use this kind of rules?",
                    "label": 0
                },
                {
                    "sent": "First of all, the rice we know that the rise in the kitchen, so he refers to someone in the kitchen.",
                    "label": 0
                },
                {
                    "sent": "Like here John or Gina second, he refers only to a subset of the concept.",
                    "label": 0
                },
                {
                    "sent": "It's a linguistic information.",
                    "label": 0
                },
                {
                    "sent": "It refers only to Mail, so it refers to John or Mark, and so with these two very simple rules you can.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody can guess that John Cook the rice because it's in the kitchen so, but.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But for US it's challenging because this rule have just shown we want.",
                    "label": 0
                },
                {
                    "sent": "We don't want to give them explicitly in training.",
                    "label": 1
                },
                {
                    "sent": "We just go want algorithm to infer out of the universe and the language which which rule it needs to use to find out.",
                    "label": 0
                },
                {
                    "sent": "So this was like the main motivation and amendment revision of the world and of the work.",
                    "label": 0
                },
                {
                    "sent": "And we also don't want to give no engineering feature about or to describe the language and the concepts themselves.",
                    "label": 0
                },
                {
                    "sent": "So we want basically the algorithm to try to discover as much as he could from raw data.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's a learning algorithm to perform this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ask so we want the matching score.",
                    "label": 0
                },
                {
                    "sent": "This is that we have a triple like a sentence of candidate labeling and a universe, and we say that we want to predict the the the prediction is the one that maximizes score.",
                    "label": 0
                },
                {
                    "sent": "Of course, using a non Max like this would be like very slow because we would like to take care of everything and it's not straightforward because as we've seen in the example, maybe you need to predict the last word to get the information about the location to disambiguate the first word.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we rather use a greedy order free inference, so we just go through the the sentence.",
                    "label": 0
                },
                {
                    "sent": "So for example, we first try to label every words and then we pick out the one that has the higher score from all the position.",
                    "label": 0
                },
                {
                    "sent": "So we select the pair.",
                    "label": 1
                },
                {
                    "sent": "The position comes set.",
                    "label": 0
                },
                {
                    "sent": "We are the most confident in.",
                    "label": 1
                },
                {
                    "sent": "We hope that it will learn to label first non ambiguous words.",
                    "label": 1
                },
                {
                    "sent": "That's what I've shown.",
                    "label": 0
                },
                {
                    "sent": "Then we will remove this position and iterate.",
                    "label": 1
                },
                {
                    "sent": "To label all the position in the sentence.",
                    "label": 0
                },
                {
                    "sent": "And what's interesting is when we have added concept to, the labeling will collect all the universe based feature.",
                    "label": 0
                },
                {
                    "sent": "That means that we will collect its location, will collect is contained by an we so that to predict the next step we will use this feature.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to do this inference, we need so a scoring function that will say that.",
                    "label": 1
                },
                {
                    "sent": "That will score a particular triple, so we would like something that could potentially encode the similarities like that could potentially encode that.",
                    "label": 1
                },
                {
                    "sent": "For example, he refers to male and that Gina that John and Mark were male, and this sort of thing.",
                    "label": 1
                },
                {
                    "sent": "So we will use neural networks that will.",
                    "label": 1
                },
                {
                    "sent": "Pushing potentially embed the concept in the words and London feature.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it's I will show you on the on the picture.",
                    "label": 0
                },
                {
                    "sent": "It's it's easier.",
                    "label": 0
                },
                {
                    "sent": "But why?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's interesting is that how do we encode the well knowledge into the prediction?",
                    "label": 0
                },
                {
                    "sent": "So for each concept of the universe, we will know the mapping, lack of dimension D. For us it was 10, so it's a in the beginning.",
                    "label": 1
                },
                {
                    "sent": "This representation is random and then we are learning it.",
                    "label": 0
                },
                {
                    "sent": "And during the process of the inference, if we want to use the particular relation in the universe, information in the process, we will say that the particular concept and its relation are included with the concatenation of the mappings.",
                    "label": 1
                },
                {
                    "sent": "So for example, if we know that the milk is located in the kitchen is contained by John.",
                    "label": 0
                },
                {
                    "sent": "What we are going to give to the learning algorithm is the concatenation of the vector representing milk, the one representing kitchen and the one representing John.",
                    "label": 0
                },
                {
                    "sent": "If we know that Gina is located in the bedroom, it's representation would be Gina, bedroom and nothing, and for example for the web cook if we only cook and nothing, nothing, and so if we were not using the universe, the representation will be like this.",
                    "label": 0
                },
                {
                    "sent": "So we will just say we would learn some feature about milk, but we have no information about the universe by this concatenation.",
                    "label": 0
                },
                {
                    "sent": "We are giving this information to the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we get back to the previous example and try to to to label here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's how the the neural network is working, so we're first taking a window around the world of interest.",
                    "label": 0
                },
                {
                    "sent": "Here's the sentence.",
                    "label": 0
                },
                {
                    "sent": "Here's the labels we have already predicts, so we know everything but this, and we take a.",
                    "label": 0
                },
                {
                    "sent": "Yes you can.",
                    "label": 0
                },
                {
                    "sent": "So we take a window around it and then we will.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, use the embeddings for the word, so we have a dictionary.",
                    "label": 0
                },
                {
                    "sent": "We learning the feature of the words, so these are the blue blue vectors.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also, as I've just explained, embedding what we already know about the prediction that is the representation of the concept and also the representation of their relations.",
                    "label": 0
                },
                {
                    "sent": "So for example, here the location.",
                    "label": 0
                },
                {
                    "sent": "So we have all these vectors we can't.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tonight them and we have a long representation of the window that is the sentence and also all the conceptual project so far.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We use a linear layer to conduct the end dimensional space.",
                    "label": 0
                },
                {
                    "sent": "We keep this representation that is the representation of the window with all the knowledge we have so far.",
                    "label": 0
                },
                {
                    "sent": "Yes, the whole database.",
                    "label": 0
                },
                {
                    "sent": "In yes.",
                    "label": 0
                },
                {
                    "sent": "So huge.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's included, but what we give to the here, we're only selecting the one that we have already predicts or.",
                    "label": 0
                },
                {
                    "sent": "So we have an embedding for each concept, but here we are selecting the one that we know so far.",
                    "label": 0
                },
                {
                    "sent": "So here for example, we only have 1, two, six 6 * 2 vector inputs, OK.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's just like a binary layer here, so we're saying, OK, I will.",
                    "label": 0
                },
                {
                    "sent": "I'm going to select the tags I've already predicted that the wrong before.",
                    "label": 0
                },
                {
                    "sent": "OK. OK. OK, so anyway this is the in green.",
                    "label": 0
                },
                {
                    "sent": "This is a representation of the the knowledge we have so far about the sliding window.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then what we do is for all the concept of the universe.",
                    "label": 0
                },
                {
                    "sent": "Right now that could be candidate to be the the tag.",
                    "label": 0
                },
                {
                    "sent": "The missing type will do the same.",
                    "label": 0
                },
                {
                    "sent": "So here yes we are including every in this part where I'm cutting all the universe now recursively.",
                    "label": 0
                },
                {
                    "sent": "So we're taking for example why he could be joined, for example, and Johnny's in the kitchen.",
                    "label": 0
                },
                {
                    "sent": "So we have this information in the universe we take.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Representation in the embeddings.",
                    "label": 0
                },
                {
                    "sent": "We could get an idea so it's much smaller and then we put this in the same space there.",
                    "label": 0
                },
                {
                    "sent": "And we do.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a dot product, so basically here on the with the the network is in two is a parallel architecture.",
                    "label": 0
                },
                {
                    "sent": "On this, we're just encouraging what we know about the sentence so far and hereafter for every candidate we have.",
                    "label": 0
                },
                {
                    "sent": "Like every people or we are going to find out their their own representation and then we do the product for for all of them and we'll take the one with the IO score and it will be like the prediction for this particular.",
                    "label": 0
                },
                {
                    "sent": "Window.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we did some experiment and so its original task, so we don't have some.",
                    "label": 0
                },
                {
                    "sent": "The data is.",
                    "label": 0
                },
                {
                    "sent": "It's hard to find.",
                    "label": 0
                },
                {
                    "sent": "So what we did is just we've created around like small game multiplayer online game.",
                    "label": 0
                },
                {
                    "sent": "So we create a universe with 82 concept like people small objects so they can do like 15 actions like giving object to one another, moving from room to room's and we have a simulation algorithms that play actually the game inside.",
                    "label": 1
                },
                {
                    "sent": "So we are they are doing actions.",
                    "label": 0
                },
                {
                    "sent": "For each sections we are generating a sentence, natural language sentence, and the sentence can be either ambiguous on ambiguous.",
                    "label": 1
                },
                {
                    "sent": "For example, it sits on the chair and we have the labeling like Mark, sit on the chair.",
                    "label": 0
                },
                {
                    "sent": "The father get some yogurt and so on.",
                    "label": 0
                },
                {
                    "sent": "So we can with this simulation we can make as much data as we can.",
                    "label": 0
                },
                {
                    "sent": "So we generated 50,000 but.",
                    "label": 0
                },
                {
                    "sent": "We only use the 10,000 from, so it's very convenient to get the.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we we compared some.",
                    "label": 0
                },
                {
                    "sent": "Submitted to to try this labeling technique.",
                    "label": 0
                },
                {
                    "sent": "So we compare different tagging method.",
                    "label": 0
                },
                {
                    "sent": "We compare some supervision type and also what's more important is the future.",
                    "label": 0
                },
                {
                    "sent": "So here for example says restricted using strong supervision is using all the universe information.",
                    "label": 0
                },
                {
                    "sent": "So we're giving all we all we can know about the universe.",
                    "label": 0
                },
                {
                    "sent": "And here's another.",
                    "label": 0
                },
                {
                    "sent": "Let's work with left to right.",
                    "label": 0
                },
                {
                    "sent": "So basically the difference between these two is that this one is learning their meetings and this one is not because it's just using a binary feature so.",
                    "label": 0
                },
                {
                    "sent": "When?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Meaning.",
                    "label": 0
                },
                {
                    "sent": "And then after we are using the neural networks have described that he's doing other free and not left to right and for several amount of the information about the universe.",
                    "label": 0
                },
                {
                    "sent": "So here we are just giving as it puts the sentence.",
                    "label": 0
                },
                {
                    "sent": "So no information about the universe.",
                    "label": 0
                },
                {
                    "sent": "So he would be like just tagging task.",
                    "label": 0
                },
                {
                    "sent": "So it's very it's very hard.",
                    "label": 0
                },
                {
                    "sent": "I mean for all the ambiguities it just guessing randomly so it's 35% error and then we're just using the information about the contained by.",
                    "label": 0
                },
                {
                    "sent": "So not all the information and so it's down to 17%.",
                    "label": 0
                },
                {
                    "sent": "And then we are using only the location relationship, which is more important and is down to 5% error.",
                    "label": 0
                },
                {
                    "sent": "So that means that you give this information is able to use it.",
                    "label": 0
                },
                {
                    "sent": "And of course, when we give the.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the information we're down to 0% because as we created our data, we just wanted to make sure that all the ambiguities where do we are creating can be resolved.",
                    "label": 0
                },
                {
                    "sent": "If you were able to use the word knowledge properly, and so that's what happened.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The final results.",
                    "label": 0
                },
                {
                    "sent": "It is when we do use weak supervision that since we don't give the alignment training, we're just giving some bags.",
                    "label": 0
                },
                {
                    "sent": "So it's as much.",
                    "label": 0
                },
                {
                    "sent": "This is order to train, but we're still succeeding because it doesn't change the fact that you can use the information about the universe.",
                    "label": 0
                },
                {
                    "sent": "So we have done two very good rates.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So finally I can just show.",
                    "label": 0
                },
                {
                    "sent": "As we are learning the representation of each concept of the database, we can after to try to do a nearest neighbor in the space of this concept to see who are the closest one.",
                    "label": 0
                },
                {
                    "sent": "So they were randomly initialized of course, and so we can see after the training that Gina, the closest wanna frozen Maggie which is the female Mark, Brian and John, the football.",
                    "label": 0
                },
                {
                    "sent": "The closest is the toy car and the video game and so on for the food is here and then you got the room, living room and kitchen.",
                    "label": 0
                },
                {
                    "sent": "So basically the embeddings are doing what we want them to do.",
                    "label": 0
                },
                {
                    "sent": "Is that uncut some similarities and saying, for example, what I wanted in the beginning that Mark is ready to Brian John, so he will be related to this subset.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as a summary, we planted a very simple a general framework of concept labeling that that might be used to try to decode or try to use, well knowledge to understand output sentences.",
                    "label": 1
                },
                {
                    "sent": "We presented our algorithm that is using both other free parents and also embeddings to try to use this information and some simulated data that knows that using this to use well knowledge is possible.",
                    "label": 1
                },
                {
                    "sent": "And so next train is now.",
                    "label": 0
                },
                {
                    "sent": "Next step would be to go inside the multiplayer online game, get the universe and try to train someone to speak inside.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Time for one question.",
                    "label": 0
                },
                {
                    "sent": "So you're calling concepts I might actually think of his entities and entity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and there's a person want to ask you if you thought about Co reference as a way of identifying entities in natural texts and trying to apply this to just natural Texas.",
                    "label": 0
                },
                {
                    "sent": "Yeah, read the key question is the universe.",
                    "label": 0
                },
                {
                    "sent": "I mean we need to have this relationship between between the entities, so we need a database that is saying that this sentence is related to this one.",
                    "label": 0
                },
                {
                    "sent": "And this is will be used to.",
                    "label": 0
                },
                {
                    "sent": "So yeah, we.",
                    "label": 0
                },
                {
                    "sent": "We thought about applying to existing task.",
                    "label": 0
                },
                {
                    "sent": "But The thing is that without the database algorithm is exactly the same as what could be done before.",
                    "label": 0
                },
                {
                    "sent": "I say what's really new is just the way that we can encode something more, and if this is something we have to create it before you know it's hard to get.",
                    "label": 0
                },
                {
                    "sent": "That would be very good.",
                    "label": 0
                },
                {
                    "sent": "I mean, we're looking to apply it to real text, let's help.",
                    "label": 0
                },
                {
                    "sent": "Do you think I'm in the database like the world's structure?",
                    "label": 0
                },
                {
                    "sent": "So that he learns the database.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Uh, yeah auto three out of text and I I love to I have no I have no Q ought to do it, I mean.",
                    "label": 0
                },
                {
                    "sent": "That would be like very cool, but.",
                    "label": 0
                },
                {
                    "sent": "I mean, so far we have relying really under database and so that's why we're really heading towards like these games where the database exists.",
                    "label": 0
                },
                {
                    "sent": "But then after yeah, if we can infer the database out of free text.",
                    "label": 0
                },
                {
                    "sent": "Well done I think.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}