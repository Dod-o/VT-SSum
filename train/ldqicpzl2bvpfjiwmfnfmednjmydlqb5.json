{
    "id": "ldqicpzl2bvpfjiwmfnfmednjmydlqb5",
    "title": "Designing Efficient Cascaded Classifiers: Tradeoff between Accuracy and Cost",
    "info": {
        "author": [
            "Balaji Krishnapuram, IBM"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/kdd2010_krishnapuram_decc/",
    "segmentation": [
        [
            "I'll be talking about designing cascaded classifiers and this is joint work with my coauthors because raker and shipping you this is work done in Siemens Healthcare."
        ],
        [
            "The fundamental question we are trying to address is minimizing different types of costs in the classification process.",
            "Traditional classifiers minimize misclassification costs.",
            "The cost of making a mistake in classification.",
            "There is a whole body of work over the last 1015 years talking about active label acquisition and semi supervised learning, predicated on the notion that features are cheap or essentially 0 cost, but labels are very expensive and if you want to minimize your costs in real life system, you want to reduce the cost of label acquisition for building a system.",
            "What is not being a bowl explode is the cost of acquiring features itself, either during the time of training the classifier or the time of deploying the classifier out in the real world and testing a new sample.",
            "Collecting features is an expensive book proposition.",
            "For many reasons.",
            "We will see that the next slide.",
            "So what has been done till now is first there is a little bit of work on Active feature acquisition.",
            "I will intelligently decide.",
            "Which features I want to collect on a test sample and for some this is really not very practical on some real life problems.",
            "For example Viola Jones face detection algorithm that allows them tries to extract 1,000,000 features from a bitmap image and tries to recognize.",
            "Is this a face or not and it tries to do this all over the large image and finds a little window.",
            "Very face is recognized.",
            "If you try to actively identify which features to collect next, you have to at least evaluate all the features once and then decide which features are the best ones.",
            "So it takes you order N time order N, where N is the number of features to even decide which is the best feature to pull it, and 11,000,000 features and you can only interest in pulling in the top 10 or 15, which causes will give you great accuracy.",
            "That's a waste of your time.",
            "You're not going to do this in practice.",
            "The second thing that people have been doing is something like a hidden Markov model reinforcement learning.",
            "The multi arm bandits and most of these work well in theory, but none of them is actually ever been implemented in practice and succeeded in any real life problem and the last which is actually very popular is a cascaded architecture.",
            "Originally the violent Jones face face detection work in the 90s with the Seminole Paper which completely changed the face detection publications around that time.",
            "So we will look at the cascaded architecture."
        ],
        [
            "Is a little bit more in the next in this work today and ask how do we optimize the design of a cascade so I'm always the cost of my data collection and maximize my accuracy at the same time.",
            "Now what do you mean by cost of feature acquisition costs?",
            "Can be computational.",
            "I might have to run an image processing algorithm on this image and acquire features, or it can be financial.",
            "I might have to conduct a.",
            "Test on a patient, either an emerging examination like an MRI or a CT scan, or a lab test or biopsy, or it could be human discomfort.",
            "In the case of a biopsy on the lung biopsy, there's actually a risk that the patient can die.",
            "There's a one person risk that of severe complications or death, so there are many different types of costs to getting information for my classifier to making a decision.",
            "So the questions are what we want to do in this stock, basically so to know you basically diploid another boosters aren't we done, I mean you already have a cascaded classifier.",
            "Well, several requirements are not satisfied by the existing systems.",
            "One knows that features need to be acquired on demand, which is satisfied by most cascaded systems.",
            "But the second is that a set of features can be acquired as a group.",
            "An image processing operation, an image processing kernel will give you a bunch of features.",
            "Together at the same cost, the third is that each feature group incurs a fixed cost, and the third 4th is that we need a tradeoff para meter to help you, or just the tradeoff between the accuracy of classification.",
            "Obviously if you give all the features that will be more accurate.",
            "Against the cost of feature acquisition, we need a way to tune in between this effectively."
        ],
        [
            "So here the example I'm trying to predict the outcomes of lung cancer patients undergoing chemo radiotherapy and I can use different set of features.",
            "A bunch of features, clinical demographics, age etc which are essentially zero, no costs.",
            "It's very easy to get or I can get the features before therapy, some lung function, creatinine clearance at the cost of examining the patient.",
            "Or I can start to image and the patient and start to collect some information.",
            "During the treatment which has more cost and after the trade treatment is over, there are some very expensive things that can be done as well.",
            "So there are varying levels of cost, but each one of these would give me a bunch of features simultaneously at each of these stages.",
            "Now the question is how do I design something in a cascaded architecture, optimal and."
        ],
        [
            "Why is this a casket actually solve this problem?",
            "I mean, it's been around since Wiler Jones in the 90s, but why it doesn't solve the problem?",
            "Essentially, the idea is you do not try to classify.",
            "We do not try to acquire all features for all samples.",
            "You acquire the cheapest feature at the very first stage and reject a bunch of samples saying this is not class one, based only on a first set of features.",
            "Then the remaining will be investigated by SEC classifier, which in turn computes extra features, more expensive features and rejects more of them along the way, and so on and so forth.",
            "So you really do not need to acquire the expensive features for the majority of your samples.",
            "And it's sort of like starting throughout needle for a haystack sorting through history.",
            "For a needle, you just one more it down.",
            "I need stage.",
            "You compute less and less, so the effective overall average runtime is or average cost is much lower.",
            "No, typically there are two issues to be addressed in designing this.",
            "One is how do you design each stage of the classifier and what is a threshold.",
            "Remember, each of these is a hard classifier.",
            "It only retains a small fraction of the samples in the next stage and eliminates most of them at each of the same stage itself.",
            "Usually an order of magnitude lesser data goes through to the next stage each time."
        ],
        [
            "So the traditional approaches mean that each state is designed only using examples through all the previous.",
            "That goes through all the previous stages.",
            "So you design the first stage, fix it, and then design the next stage, fix it, and then the third one, etc.",
            "And you also have to fix the thresholds for each classifier, because that's how you're going to actually decide which ones go through to the next stage, and we have to retrain it if it changed the choice of.",
            "The threshold and the classifier in the second stage can be quite different because the examples that are seen in the training set would be quite different as well.",
            "No.",
            "There are problems with this.",
            "Let's look at this for a moment.",
            "What one obvious problem is the errors in the first stage.",
            "Our mother recoverable and the second stage is sort of completely ignoring what is happening in the first stage, so the error sort of cascade through and get multiplied all over the place so it becomes very quickly.",
            "The accuracy starts to drop and one of the reasons is you sort of training each stage independently of the other stages.",
            "Not aware of the strengths and weaknesses of the other stages.",
            "Now if you're designing the stage three aware of where the mistakes could be in stage one and Stage 2.",
            "Or vice versa, the stage one itself could be aware of work could be mistakes in stage three.",
            "Potentially they can compensate for each other.",
            "That's basically the idea."
        ],
        [
            "Going on here, so we will actually talk about a system that jointly trains all these stages of the classifier at the same computational cost, not any larger computational costs.",
            "And we have a nob that controls explicitly the tradeoff between the accuracy of the classification and the cost of the feature acquisition.",
            "And we do this by modeling the expected feature cost for the average sample at Target deployment time, and we did couple the classifier training or the threshold selection.",
            "This is a nice little thing.",
            "As an addendum, is not the main reason for this paper, but it also reduces.",
            "Therefore my time of training substantially by orders of magnitude."
        ],
        [
            "No, just going through the notation very quickly, let each stage of the classifier be called ski onesie, twosie K. So these are the case stages in a cascade and each stage the features that come through at each stage.",
            "Let's, by the way, let me clarify that I'm assuming a fixed ordering a features in the increasing order of cost of the features for the moment will come to that in the very end when we talk about what else needs to be done.",
            "At the X is the features required at each stage, and if the classifier returns a value F of X which is greater than Theta, then it passes through to the next stage.",
            "If it is less than three to, then it rejects at that stage and you do not look at those samples any further.",
            "Why is the label and?",
            "I guess we're basically done with this notation, and yeah, the classifier we will use is a probabilistic classifier logistic regression.",
            "Nothing very fancy.",
            "Basically we throw take a linear classifier and pass it through a sigmoid to get out of probability at the other end."
        ],
        [
            "Now, here's the here's where the paper starts to make a contribution for the first time.",
            "We will turn this hard cascade and come up with a mathematical entity called a soft cascade which is used only at the time of training.",
            "It is not used at the time of testing.",
            "Remember if we want to accomplish the task of reducing the computation cost, you have to use a hard cascade at the testing time, but at the time of training you can always go back and create a mathematical object called a soft cascade.",
            "Which does the following.",
            "An instance is a sample is classed as a present if if every stage predicts it as a positive, but even if one stage calls it a negative, then it starts to lower the probabilities of it being a positive.",
            "So basically an instance is negative, at least one of the case the stages produces a negative.",
            "This is a probabilistic notion of what is the probability that if every classifier in between is a probabilistic classifier, water the probability.",
            "That the sample will be accepted at the end of the case stages."
        ],
        [
            "Now that is an interesting properties.",
            "First of all, sequential ordering of the different stages of a cascade is not important because it is probabilistic.",
            "You can switch the order and this off cascade would be exactly the same probability of something passing through.",
            "This is not true in a hard cascade which we have to use at the time of deployment, but this is primarily a mathematical idea which allows me to optimize these soft cascade.",
            "As a surrogate for the hard cascade and because of this mathematical idea, I can actually tremendously improve my effort to train cascades, reduce the cost of misclassification because I can model it, explain explicitly, and reduce the cost of collecting this data feature."
        ],
        [
            "Data.",
            "Now it's relatively straightforward.",
            "I have created a probabilistic model.",
            "I can impose a Laplacian prior, or, if you prefer, a Gaussian prior, that's that's fine.",
            "You can pick your favorite poison and we simply computer maximum or posteriori likelihood.",
            "There's a simple algorithm, coordinate doesn't."
        ],
        [
            "For them now comes the interesting part.",
            "OK, you can do this for just the soft cascade and that would maximize.",
            "That would optimize all the stages of a classifier in a cascaded architecture simultaneously, so you do not have Carol multiplicative effects of the errors at each stage.",
            "What about the costs?",
            "We would ideally like to find this classifier in a way that reduces the cost for a new instance at Test time and.",
            "Discussed is on an unknown test distribution, so we will approximate this based on an empirical."
        ],
        [
            "Customer training set.",
            "How do we get the cost?",
            "Turns out, you know, thinking of the soft cascade, we can actually write a probability that the feature will declare the sample will pass through stage one.",
            "So every sample will incur cost P1 at the stage one.",
            "Now, what fraction of the samples will cross through to the stage two to be examined there at all?",
            "That's only going to be the F of X, which is the classification probability for the XI being one.",
            "Times D and then the other times the cost of stage were two is basically the expected cost that I will incur to collect the features at stage two, and so on and so forth.",
            "And you can write an explicit mathematical function which is the cost of acquiring features.",
            "Are they average expected cost of acquiring features for a new sample X?",
            "Now I can compute the same thing as oppose summary over all the training samples and then I can maximize weighted combination of my lab function, But my log likelihood function and they cost so I can trade off there for an explicit cost versus the explicit accuracy of this joint soft cascade and we optimize it using a simple coordinate descent algorithm, cyclic coordinate descent algorithm.",
            "The details are in the paper.",
            "I'll be happy to talk about it at the poster."
        ],
        [
            "That's not what I'm experiments.",
            "The first couple of them were really small data sets.",
            "The third of them is a much larger computer aided diagnosis product, which is actually there in the market.",
            "Again, I cannot show the actual performance of the product and not be killed by the FDA because of literally labeling issues, so I'm just taking a subsample of the data to show how it actually works."
        ],
        [
            "The first event is basically talking about predicting the outcomes for lung cancer and the sharp summary is it's a very small data set.",
            "There are only three groups of the 2nd.",
            "It's already, there are only four groups of data features, and each is more expensive than the previous."
        ],
        [
            "The second data set I will describe is predicting pathological complete response.",
            "That is basically the rest primes to chemoradiotherapy for rectal cancer."
        ],
        [
            "And we will compare a single stage classifier which uses all of the features.",
            "Therefore it'll be the most accurate because it is all the data about every sample and our method would be to set to 0, which basically means I do not care about the cost, just optimize the accuracy and with very indeed as beta becomes larger and larger I care more and more about the cost, but I'm willing to sacrifice some of my accuracy in order to reduce the cost.",
            "Off obtaining the features and baseline methods will compare will be sequential training one step at a time.",
            "I will build a logistic regression or an LDA and also the Adaboost which is by definition a greedy sequential system which just builds one level at a time.",
            "But for one feature at a time.",
            "And notice that problem we actually cannot acquire one feature at a time will actually get one feature group at a time simultaneously, and you would be stupid not to use the rest of the features in the group, but that's just ignored in this evaluation procedure."
        ],
        [
            "Anyway, so the evaluation procedure as we will use 70% of the data for training and 30% for testing and then cycle through this many many ways so that you can basically get averages over tenfold repetitions and then try to produce some statistics for whether this is statically significant or not.",
            "And we will look at the area under the auto SQL bizarre evaluation metric.",
            "Now the reviewers did point out and I had should agree with him that this is turns out that randomly splitting 70% and 30% in doing this 10 times is not as good a statistical test.",
            "Yes, doing it directly without other statistical testing methods and I just don't have the time to fix it.",
            "I do agree that we need to improve the statistical hypothesis testing a little bit."
        ],
        [
            "Basic result is the proposed method is about as accurate as sequentially training logistic regression, but substantially cheaper that I get much reduced costs or.",
            "Substantially more accurate than the other methods in some other data sets, and the differences are static."
        ],
        [
            "Insignificant and the third data set is where we actually deployed it in the actual product.",
            "This is where I tried to look at a CT scan and identify suspicious regions which can be cancerous, and I did this on a sub sample data set with only 196 CT scans.",
            "With this correspondence, about 50,000 samples, 55,000 individual samples to be classified as a positive or a negative.",
            "The constraint is image processing.",
            "Applications take a lot of time for feature extraction.",
            "I cannot afford my desire to show that to the doctor immediately.",
            "So the cost of future acquisition has to be small."
        ],
        [
            "And the basic result is that you're about as accurate as an Adaboost classifier, but you take less than half the cost, which basically means that you're twice as fast as an Adaboost cascade architecture, but prices fast, which basically means the doctor does not have to wait as long, and it's easier to adopt in commercial."
        ],
        [
            "Practice conclusions.",
            "Frankie training all the stages so that the errors in the first stage can be sort of corrected in the other stages.",
            "They do not all propagate all over the place and kill you and we offer a nob to control the tradeoff between accuracy and cost and the open issues.",
            "Of course, we've sort of ducked the boat of what is the right order of features to acquire.",
            "What is the right order of the cascade through what we did?",
            "We just simply ordered the features by the cheapest coming 1st and most expensive coming last.",
            "We have subsequently after the paper was published.",
            "Done solve this problem, but we're not talking about that.",
            "Is here and the accuracy was discussed, nor does not always very sensitive.",
            "There is some sensitivity issues that we need to improve their.",
            "I'll take questions at this point.",
            "So any question.",
            "So our example you show us, there's only just a very small angle stages.",
            "For example three and only if there are many many more stage, such as in Viola Jones.",
            "Face detectors are generally over 10 stage.",
            "Whatever's difference is actually true.",
            "So then Viola Jones.",
            "Typically they'll be like millions of features, but you would probably end up using only the first 10 of them, and it essentially done with the classification after the first 10 or 20 features we have done that, but not in this particular paper where we reported.",
            "And that additional piece of work that is needed to be reported here is selecting the right order of the care of the features.",
            "If you can select the right order of the features and know which first 10 features you should be basically doing, you can ignore all the rest which we did not complete by the time the paper was submitted, but we have solved it later on so.",
            "General question.",
            "OK, this is it.",
            "Thanks a picture.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll be talking about designing cascaded classifiers and this is joint work with my coauthors because raker and shipping you this is work done in Siemens Healthcare.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The fundamental question we are trying to address is minimizing different types of costs in the classification process.",
                    "label": 1
                },
                {
                    "sent": "Traditional classifiers minimize misclassification costs.",
                    "label": 0
                },
                {
                    "sent": "The cost of making a mistake in classification.",
                    "label": 0
                },
                {
                    "sent": "There is a whole body of work over the last 1015 years talking about active label acquisition and semi supervised learning, predicated on the notion that features are cheap or essentially 0 cost, but labels are very expensive and if you want to minimize your costs in real life system, you want to reduce the cost of label acquisition for building a system.",
                    "label": 0
                },
                {
                    "sent": "What is not being a bowl explode is the cost of acquiring features itself, either during the time of training the classifier or the time of deploying the classifier out in the real world and testing a new sample.",
                    "label": 0
                },
                {
                    "sent": "Collecting features is an expensive book proposition.",
                    "label": 0
                },
                {
                    "sent": "For many reasons.",
                    "label": 0
                },
                {
                    "sent": "We will see that the next slide.",
                    "label": 0
                },
                {
                    "sent": "So what has been done till now is first there is a little bit of work on Active feature acquisition.",
                    "label": 1
                },
                {
                    "sent": "I will intelligently decide.",
                    "label": 0
                },
                {
                    "sent": "Which features I want to collect on a test sample and for some this is really not very practical on some real life problems.",
                    "label": 0
                },
                {
                    "sent": "For example Viola Jones face detection algorithm that allows them tries to extract 1,000,000 features from a bitmap image and tries to recognize.",
                    "label": 0
                },
                {
                    "sent": "Is this a face or not and it tries to do this all over the large image and finds a little window.",
                    "label": 0
                },
                {
                    "sent": "Very face is recognized.",
                    "label": 0
                },
                {
                    "sent": "If you try to actively identify which features to collect next, you have to at least evaluate all the features once and then decide which features are the best ones.",
                    "label": 1
                },
                {
                    "sent": "So it takes you order N time order N, where N is the number of features to even decide which is the best feature to pull it, and 11,000,000 features and you can only interest in pulling in the top 10 or 15, which causes will give you great accuracy.",
                    "label": 0
                },
                {
                    "sent": "That's a waste of your time.",
                    "label": 0
                },
                {
                    "sent": "You're not going to do this in practice.",
                    "label": 0
                },
                {
                    "sent": "The second thing that people have been doing is something like a hidden Markov model reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "The multi arm bandits and most of these work well in theory, but none of them is actually ever been implemented in practice and succeeded in any real life problem and the last which is actually very popular is a cascaded architecture.",
                    "label": 0
                },
                {
                    "sent": "Originally the violent Jones face face detection work in the 90s with the Seminole Paper which completely changed the face detection publications around that time.",
                    "label": 0
                },
                {
                    "sent": "So we will look at the cascaded architecture.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is a little bit more in the next in this work today and ask how do we optimize the design of a cascade so I'm always the cost of my data collection and maximize my accuracy at the same time.",
                    "label": 0
                },
                {
                    "sent": "Now what do you mean by cost of feature acquisition costs?",
                    "label": 0
                },
                {
                    "sent": "Can be computational.",
                    "label": 0
                },
                {
                    "sent": "I might have to run an image processing algorithm on this image and acquire features, or it can be financial.",
                    "label": 0
                },
                {
                    "sent": "I might have to conduct a.",
                    "label": 0
                },
                {
                    "sent": "Test on a patient, either an emerging examination like an MRI or a CT scan, or a lab test or biopsy, or it could be human discomfort.",
                    "label": 0
                },
                {
                    "sent": "In the case of a biopsy on the lung biopsy, there's actually a risk that the patient can die.",
                    "label": 0
                },
                {
                    "sent": "There's a one person risk that of severe complications or death, so there are many different types of costs to getting information for my classifier to making a decision.",
                    "label": 0
                },
                {
                    "sent": "So the questions are what we want to do in this stock, basically so to know you basically diploid another boosters aren't we done, I mean you already have a cascaded classifier.",
                    "label": 0
                },
                {
                    "sent": "Well, several requirements are not satisfied by the existing systems.",
                    "label": 0
                },
                {
                    "sent": "One knows that features need to be acquired on demand, which is satisfied by most cascaded systems.",
                    "label": 0
                },
                {
                    "sent": "But the second is that a set of features can be acquired as a group.",
                    "label": 1
                },
                {
                    "sent": "An image processing operation, an image processing kernel will give you a bunch of features.",
                    "label": 0
                },
                {
                    "sent": "Together at the same cost, the third is that each feature group incurs a fixed cost, and the third 4th is that we need a tradeoff para meter to help you, or just the tradeoff between the accuracy of classification.",
                    "label": 0
                },
                {
                    "sent": "Obviously if you give all the features that will be more accurate.",
                    "label": 0
                },
                {
                    "sent": "Against the cost of feature acquisition, we need a way to tune in between this effectively.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here the example I'm trying to predict the outcomes of lung cancer patients undergoing chemo radiotherapy and I can use different set of features.",
                    "label": 1
                },
                {
                    "sent": "A bunch of features, clinical demographics, age etc which are essentially zero, no costs.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to get or I can get the features before therapy, some lung function, creatinine clearance at the cost of examining the patient.",
                    "label": 1
                },
                {
                    "sent": "Or I can start to image and the patient and start to collect some information.",
                    "label": 0
                },
                {
                    "sent": "During the treatment which has more cost and after the trade treatment is over, there are some very expensive things that can be done as well.",
                    "label": 0
                },
                {
                    "sent": "So there are varying levels of cost, but each one of these would give me a bunch of features simultaneously at each of these stages.",
                    "label": 0
                },
                {
                    "sent": "Now the question is how do I design something in a cascaded architecture, optimal and.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why is this a casket actually solve this problem?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's been around since Wiler Jones in the 90s, but why it doesn't solve the problem?",
                    "label": 0
                },
                {
                    "sent": "Essentially, the idea is you do not try to classify.",
                    "label": 0
                },
                {
                    "sent": "We do not try to acquire all features for all samples.",
                    "label": 0
                },
                {
                    "sent": "You acquire the cheapest feature at the very first stage and reject a bunch of samples saying this is not class one, based only on a first set of features.",
                    "label": 0
                },
                {
                    "sent": "Then the remaining will be investigated by SEC classifier, which in turn computes extra features, more expensive features and rejects more of them along the way, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So you really do not need to acquire the expensive features for the majority of your samples.",
                    "label": 0
                },
                {
                    "sent": "And it's sort of like starting throughout needle for a haystack sorting through history.",
                    "label": 0
                },
                {
                    "sent": "For a needle, you just one more it down.",
                    "label": 0
                },
                {
                    "sent": "I need stage.",
                    "label": 0
                },
                {
                    "sent": "You compute less and less, so the effective overall average runtime is or average cost is much lower.",
                    "label": 0
                },
                {
                    "sent": "No, typically there are two issues to be addressed in designing this.",
                    "label": 0
                },
                {
                    "sent": "One is how do you design each stage of the classifier and what is a threshold.",
                    "label": 1
                },
                {
                    "sent": "Remember, each of these is a hard classifier.",
                    "label": 0
                },
                {
                    "sent": "It only retains a small fraction of the samples in the next stage and eliminates most of them at each of the same stage itself.",
                    "label": 0
                },
                {
                    "sent": "Usually an order of magnitude lesser data goes through to the next stage each time.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the traditional approaches mean that each state is designed only using examples through all the previous.",
                    "label": 0
                },
                {
                    "sent": "That goes through all the previous stages.",
                    "label": 1
                },
                {
                    "sent": "So you design the first stage, fix it, and then design the next stage, fix it, and then the third one, etc.",
                    "label": 0
                },
                {
                    "sent": "And you also have to fix the thresholds for each classifier, because that's how you're going to actually decide which ones go through to the next stage, and we have to retrain it if it changed the choice of.",
                    "label": 1
                },
                {
                    "sent": "The threshold and the classifier in the second stage can be quite different because the examples that are seen in the training set would be quite different as well.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "There are problems with this.",
                    "label": 0
                },
                {
                    "sent": "Let's look at this for a moment.",
                    "label": 0
                },
                {
                    "sent": "What one obvious problem is the errors in the first stage.",
                    "label": 0
                },
                {
                    "sent": "Our mother recoverable and the second stage is sort of completely ignoring what is happening in the first stage, so the error sort of cascade through and get multiplied all over the place so it becomes very quickly.",
                    "label": 0
                },
                {
                    "sent": "The accuracy starts to drop and one of the reasons is you sort of training each stage independently of the other stages.",
                    "label": 0
                },
                {
                    "sent": "Not aware of the strengths and weaknesses of the other stages.",
                    "label": 0
                },
                {
                    "sent": "Now if you're designing the stage three aware of where the mistakes could be in stage one and Stage 2.",
                    "label": 0
                },
                {
                    "sent": "Or vice versa, the stage one itself could be aware of work could be mistakes in stage three.",
                    "label": 0
                },
                {
                    "sent": "Potentially they can compensate for each other.",
                    "label": 0
                },
                {
                    "sent": "That's basically the idea.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going on here, so we will actually talk about a system that jointly trains all these stages of the classifier at the same computational cost, not any larger computational costs.",
                    "label": 0
                },
                {
                    "sent": "And we have a nob that controls explicitly the tradeoff between the accuracy of the classification and the cost of the feature acquisition.",
                    "label": 1
                },
                {
                    "sent": "And we do this by modeling the expected feature cost for the average sample at Target deployment time, and we did couple the classifier training or the threshold selection.",
                    "label": 1
                },
                {
                    "sent": "This is a nice little thing.",
                    "label": 0
                },
                {
                    "sent": "As an addendum, is not the main reason for this paper, but it also reduces.",
                    "label": 0
                },
                {
                    "sent": "Therefore my time of training substantially by orders of magnitude.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, just going through the notation very quickly, let each stage of the classifier be called ski onesie, twosie K. So these are the case stages in a cascade and each stage the features that come through at each stage.",
                    "label": 0
                },
                {
                    "sent": "Let's, by the way, let me clarify that I'm assuming a fixed ordering a features in the increasing order of cost of the features for the moment will come to that in the very end when we talk about what else needs to be done.",
                    "label": 0
                },
                {
                    "sent": "At the X is the features required at each stage, and if the classifier returns a value F of X which is greater than Theta, then it passes through to the next stage.",
                    "label": 0
                },
                {
                    "sent": "If it is less than three to, then it rejects at that stage and you do not look at those samples any further.",
                    "label": 0
                },
                {
                    "sent": "Why is the label and?",
                    "label": 0
                },
                {
                    "sent": "I guess we're basically done with this notation, and yeah, the classifier we will use is a probabilistic classifier logistic regression.",
                    "label": 0
                },
                {
                    "sent": "Nothing very fancy.",
                    "label": 0
                },
                {
                    "sent": "Basically we throw take a linear classifier and pass it through a sigmoid to get out of probability at the other end.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, here's the here's where the paper starts to make a contribution for the first time.",
                    "label": 0
                },
                {
                    "sent": "We will turn this hard cascade and come up with a mathematical entity called a soft cascade which is used only at the time of training.",
                    "label": 0
                },
                {
                    "sent": "It is not used at the time of testing.",
                    "label": 0
                },
                {
                    "sent": "Remember if we want to accomplish the task of reducing the computation cost, you have to use a hard cascade at the testing time, but at the time of training you can always go back and create a mathematical object called a soft cascade.",
                    "label": 0
                },
                {
                    "sent": "Which does the following.",
                    "label": 0
                },
                {
                    "sent": "An instance is a sample is classed as a present if if every stage predicts it as a positive, but even if one stage calls it a negative, then it starts to lower the probabilities of it being a positive.",
                    "label": 0
                },
                {
                    "sent": "So basically an instance is negative, at least one of the case the stages produces a negative.",
                    "label": 1
                },
                {
                    "sent": "This is a probabilistic notion of what is the probability that if every classifier in between is a probabilistic classifier, water the probability.",
                    "label": 0
                },
                {
                    "sent": "That the sample will be accepted at the end of the case stages.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now that is an interesting properties.",
                    "label": 0
                },
                {
                    "sent": "First of all, sequential ordering of the different stages of a cascade is not important because it is probabilistic.",
                    "label": 1
                },
                {
                    "sent": "You can switch the order and this off cascade would be exactly the same probability of something passing through.",
                    "label": 1
                },
                {
                    "sent": "This is not true in a hard cascade which we have to use at the time of deployment, but this is primarily a mathematical idea which allows me to optimize these soft cascade.",
                    "label": 0
                },
                {
                    "sent": "As a surrogate for the hard cascade and because of this mathematical idea, I can actually tremendously improve my effort to train cascades, reduce the cost of misclassification because I can model it, explain explicitly, and reduce the cost of collecting this data feature.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data.",
                    "label": 0
                },
                {
                    "sent": "Now it's relatively straightforward.",
                    "label": 0
                },
                {
                    "sent": "I have created a probabilistic model.",
                    "label": 0
                },
                {
                    "sent": "I can impose a Laplacian prior, or, if you prefer, a Gaussian prior, that's that's fine.",
                    "label": 1
                },
                {
                    "sent": "You can pick your favorite poison and we simply computer maximum or posteriori likelihood.",
                    "label": 0
                },
                {
                    "sent": "There's a simple algorithm, coordinate doesn't.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For them now comes the interesting part.",
                    "label": 0
                },
                {
                    "sent": "OK, you can do this for just the soft cascade and that would maximize.",
                    "label": 0
                },
                {
                    "sent": "That would optimize all the stages of a classifier in a cascaded architecture simultaneously, so you do not have Carol multiplicative effects of the errors at each stage.",
                    "label": 0
                },
                {
                    "sent": "What about the costs?",
                    "label": 0
                },
                {
                    "sent": "We would ideally like to find this classifier in a way that reduces the cost for a new instance at Test time and.",
                    "label": 1
                },
                {
                    "sent": "Discussed is on an unknown test distribution, so we will approximate this based on an empirical.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Customer training set.",
                    "label": 0
                },
                {
                    "sent": "How do we get the cost?",
                    "label": 0
                },
                {
                    "sent": "Turns out, you know, thinking of the soft cascade, we can actually write a probability that the feature will declare the sample will pass through stage one.",
                    "label": 0
                },
                {
                    "sent": "So every sample will incur cost P1 at the stage one.",
                    "label": 0
                },
                {
                    "sent": "Now, what fraction of the samples will cross through to the stage two to be examined there at all?",
                    "label": 0
                },
                {
                    "sent": "That's only going to be the F of X, which is the classification probability for the XI being one.",
                    "label": 0
                },
                {
                    "sent": "Times D and then the other times the cost of stage were two is basically the expected cost that I will incur to collect the features at stage two, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And you can write an explicit mathematical function which is the cost of acquiring features.",
                    "label": 0
                },
                {
                    "sent": "Are they average expected cost of acquiring features for a new sample X?",
                    "label": 1
                },
                {
                    "sent": "Now I can compute the same thing as oppose summary over all the training samples and then I can maximize weighted combination of my lab function, But my log likelihood function and they cost so I can trade off there for an explicit cost versus the explicit accuracy of this joint soft cascade and we optimize it using a simple coordinate descent algorithm, cyclic coordinate descent algorithm.",
                    "label": 0
                },
                {
                    "sent": "The details are in the paper.",
                    "label": 0
                },
                {
                    "sent": "I'll be happy to talk about it at the poster.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's not what I'm experiments.",
                    "label": 0
                },
                {
                    "sent": "The first couple of them were really small data sets.",
                    "label": 0
                },
                {
                    "sent": "The third of them is a much larger computer aided diagnosis product, which is actually there in the market.",
                    "label": 1
                },
                {
                    "sent": "Again, I cannot show the actual performance of the product and not be killed by the FDA because of literally labeling issues, so I'm just taking a subsample of the data to show how it actually works.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first event is basically talking about predicting the outcomes for lung cancer and the sharp summary is it's a very small data set.",
                    "label": 0
                },
                {
                    "sent": "There are only three groups of the 2nd.",
                    "label": 0
                },
                {
                    "sent": "It's already, there are only four groups of data features, and each is more expensive than the previous.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second data set I will describe is predicting pathological complete response.",
                    "label": 0
                },
                {
                    "sent": "That is basically the rest primes to chemoradiotherapy for rectal cancer.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we will compare a single stage classifier which uses all of the features.",
                    "label": 1
                },
                {
                    "sent": "Therefore it'll be the most accurate because it is all the data about every sample and our method would be to set to 0, which basically means I do not care about the cost, just optimize the accuracy and with very indeed as beta becomes larger and larger I care more and more about the cost, but I'm willing to sacrifice some of my accuracy in order to reduce the cost.",
                    "label": 0
                },
                {
                    "sent": "Off obtaining the features and baseline methods will compare will be sequential training one step at a time.",
                    "label": 0
                },
                {
                    "sent": "I will build a logistic regression or an LDA and also the Adaboost which is by definition a greedy sequential system which just builds one level at a time.",
                    "label": 0
                },
                {
                    "sent": "But for one feature at a time.",
                    "label": 0
                },
                {
                    "sent": "And notice that problem we actually cannot acquire one feature at a time will actually get one feature group at a time simultaneously, and you would be stupid not to use the rest of the features in the group, but that's just ignored in this evaluation procedure.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anyway, so the evaluation procedure as we will use 70% of the data for training and 30% for testing and then cycle through this many many ways so that you can basically get averages over tenfold repetitions and then try to produce some statistics for whether this is statically significant or not.",
                    "label": 1
                },
                {
                    "sent": "And we will look at the area under the auto SQL bizarre evaluation metric.",
                    "label": 0
                },
                {
                    "sent": "Now the reviewers did point out and I had should agree with him that this is turns out that randomly splitting 70% and 30% in doing this 10 times is not as good a statistical test.",
                    "label": 0
                },
                {
                    "sent": "Yes, doing it directly without other statistical testing methods and I just don't have the time to fix it.",
                    "label": 0
                },
                {
                    "sent": "I do agree that we need to improve the statistical hypothesis testing a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basic result is the proposed method is about as accurate as sequentially training logistic regression, but substantially cheaper that I get much reduced costs or.",
                    "label": 0
                },
                {
                    "sent": "Substantially more accurate than the other methods in some other data sets, and the differences are static.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Insignificant and the third data set is where we actually deployed it in the actual product.",
                    "label": 0
                },
                {
                    "sent": "This is where I tried to look at a CT scan and identify suspicious regions which can be cancerous, and I did this on a sub sample data set with only 196 CT scans.",
                    "label": 1
                },
                {
                    "sent": "With this correspondence, about 50,000 samples, 55,000 individual samples to be classified as a positive or a negative.",
                    "label": 0
                },
                {
                    "sent": "The constraint is image processing.",
                    "label": 0
                },
                {
                    "sent": "Applications take a lot of time for feature extraction.",
                    "label": 0
                },
                {
                    "sent": "I cannot afford my desire to show that to the doctor immediately.",
                    "label": 0
                },
                {
                    "sent": "So the cost of future acquisition has to be small.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the basic result is that you're about as accurate as an Adaboost classifier, but you take less than half the cost, which basically means that you're twice as fast as an Adaboost cascade architecture, but prices fast, which basically means the doctor does not have to wait as long, and it's easier to adopt in commercial.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Practice conclusions.",
                    "label": 0
                },
                {
                    "sent": "Frankie training all the stages so that the errors in the first stage can be sort of corrected in the other stages.",
                    "label": 0
                },
                {
                    "sent": "They do not all propagate all over the place and kill you and we offer a nob to control the tradeoff between accuracy and cost and the open issues.",
                    "label": 1
                },
                {
                    "sent": "Of course, we've sort of ducked the boat of what is the right order of features to acquire.",
                    "label": 1
                },
                {
                    "sent": "What is the right order of the cascade through what we did?",
                    "label": 0
                },
                {
                    "sent": "We just simply ordered the features by the cheapest coming 1st and most expensive coming last.",
                    "label": 0
                },
                {
                    "sent": "We have subsequently after the paper was published.",
                    "label": 0
                },
                {
                    "sent": "Done solve this problem, but we're not talking about that.",
                    "label": 0
                },
                {
                    "sent": "Is here and the accuracy was discussed, nor does not always very sensitive.",
                    "label": 0
                },
                {
                    "sent": "There is some sensitivity issues that we need to improve their.",
                    "label": 0
                },
                {
                    "sent": "I'll take questions at this point.",
                    "label": 0
                },
                {
                    "sent": "So any question.",
                    "label": 0
                },
                {
                    "sent": "So our example you show us, there's only just a very small angle stages.",
                    "label": 0
                },
                {
                    "sent": "For example three and only if there are many many more stage, such as in Viola Jones.",
                    "label": 0
                },
                {
                    "sent": "Face detectors are generally over 10 stage.",
                    "label": 0
                },
                {
                    "sent": "Whatever's difference is actually true.",
                    "label": 0
                },
                {
                    "sent": "So then Viola Jones.",
                    "label": 0
                },
                {
                    "sent": "Typically they'll be like millions of features, but you would probably end up using only the first 10 of them, and it essentially done with the classification after the first 10 or 20 features we have done that, but not in this particular paper where we reported.",
                    "label": 0
                },
                {
                    "sent": "And that additional piece of work that is needed to be reported here is selecting the right order of the care of the features.",
                    "label": 0
                },
                {
                    "sent": "If you can select the right order of the features and know which first 10 features you should be basically doing, you can ignore all the rest which we did not complete by the time the paper was submitted, but we have solved it later on so.",
                    "label": 0
                },
                {
                    "sent": "General question.",
                    "label": 0
                },
                {
                    "sent": "OK, this is it.",
                    "label": 0
                },
                {
                    "sent": "Thanks a picture.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}