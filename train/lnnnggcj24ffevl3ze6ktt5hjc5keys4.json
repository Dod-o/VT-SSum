{
    "id": "lnnnggcj24ffevl3ze6ktt5hjc5keys4",
    "title": "What/When Causal Expectation Modelling in Monophonic Pitched and Percussive Audio",
    "info": {
        "author": [
            "Amaury Hazan, Music Technology Group, Pompeu Fabra University"
        ],
        "published": "Feb. 1, 2008",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mbc07_hazan_wwc/",
    "segmentation": [
        [
            "So I present you well, work related to the work you have just seen before within them.",
            "Cap Project in computer by University.",
            "So this is let's say a bit more applied work which tries to model let's say the learning of sequences and expectation based on the listing of musical audio.",
            "So here for purpose of simplicity we won't use an incremental approach and we will try to work with a fixed number of cluster.",
            "So I'll show you."
        ],
        [
            "The let's say the outline of the presentation goals.",
            "I give you some background.",
            "I propose a system, show some evaluation.",
            "So we have been working evaluating on drum data and also we present some preliminary experiments using monophonic sang Melody and then while I show some future."
        ],
        [
            "Worked in conclusions, so we want to build a system for producing musical expectation based on the observation of audio.",
            "We have in this project quite the same constraints we would like the system to, let's say work in online fashion and unsupervised way.",
            "OK, but here again it will won't be incremental.",
            "So here the task is to let's say.",
            "Based on the observation of a musical sequence, let's say the sequence stop and you have to predict what and where will be the next musical event.",
            "OK, so yes, this."
        ],
        [
            "I've already said so.",
            "Some background on this, so this is, let's say a lot of ideas.",
            "We have been tried to borrow first, prediction, breathing, listening.",
            "So work from Ellis, Abdella interesting symbolic speech sequence learning system.",
            "So here we've been, yes, mainly focusing on what I've been doing.",
            "Pearson Wiggins on that then.",
            "Well, there are some ideas we would like to integrate in the future of valuations.",
            "Call following a component of the signal also for.",
            "Let's say generating synthesizing the expectation of the system we use some, let's say, works from concatenated synthesis and also well this work is related to improvisation system that could be could be used."
        ],
        [
            "OK.",
            "So the system design it's pretty similar to what regard as presented.",
            "We have a first layer which is doing the feature extraction.",
            "So here we want to extract, let's say timber descriptors, unset bits and we will say perform the reasoning at.",
            "Mid level OK using this mid level descriptors.",
            "Then we have a layer of dimensionality reduction.",
            "So basically it's doing online clustering and we let's say create symbols for the timber class and for the intern sets interval class.",
            "So it's written BRII.",
            "This is bit relative intern sets interval.",
            "We try to let's say the system that will process music in dependently of the extracted tempo an this is fed to, let's say symbolic music alert.",
            "A symbolic sequence learner that will predict the next timber and the next interval setting."
        ],
        [
            "Ever.",
            "OK, so first the feature extraction module.",
            "Well, we extract the bits using the Davis.",
            "The method proposed by Davis.",
            "We extract the unset using the high frequency content and then some simple descriptors.",
            "So rough spectral shape descriptors.",
            "Well, zero crossing rate.",
            "It's not spectral, but it described roughly the spectral shape spectral centroid.",
            "Mel frequency cepstrum coefficient and also we expect the pitch using the in FT, which is an adaptation of the in algorithm by 7 in the spectral domain.",
            "So we can compute this algorithms on the unset frame.",
            "That's very rough, but that can say a lot fast processing or average them over the Internet."
        ],
        [
            "Set region.",
            "So you have here well, an output for a simple example for the extraction of fun sets and bits.",
            "So based on the Davis be tracking method and high frequency content onset detection."
        ],
        [
            "OK, so we go now to this dimensionality reduction module.",
            "We'd like to produce an online unsupervised clustering to create the symbols for temporal and timber features.",
            "Prior to this, this is a bit cheating.",
            "We perform a bootstrap step at the beginning.",
            "The system doesn't know anything, so it will accumulate some, let's say information from the audio and will do a small batch on that.",
            "OK, so this helps us to normalize the Chamber.",
            "Distance and also to try to make an estimate of the number of clusters to work with.",
            "So we use a grid of Gaussian mixture model.",
            "Train with them to choose the best number of components so."
        ],
        [
            "So I'll go give some details about this.",
            "This Gaussian mixture model grid is made as following each row.",
            "It's an independent trend with initial random initialization, and for each row we have.",
            "Say for each column, or GMM with increasing number of Gaussians.",
            "So from one to the let's say maximum K we'll.",
            "Oh and well, that's it.",
            "We fit each of this.",
            "Let's say each of these cells using the expectation maximization algorithm.",
            "There is a very simple regularization procedure to let's say avoid excessively low variances and then well based on this we can choose for each row.",
            "Let's say the most.",
            "The optimal number of.",
            "Components using an information criterion as buys info by off Schwarz information criterion, Akaike information criterion or let's say a single order correction of the Akaike information criterion for small sample size.",
            "We get the median of the best cover each row and we obtain."
        ],
        [
            "Let's say a grid which looks a bit like this one.",
            "So here the light colors indicate, let's say a minimize information criterion.",
            "In this case, this is the big we are representing, and well, for this example we will choose free clusters for the timber.",
            "If three clusters for the iOS."
        ],
        [
            "So based on that, we can now perform K means and do the, let's say online processing.",
            "So for each incoming point we will assign the nearest cluster using Euclidean distance and make an update of this cluster well based on the distance and learning rate.",
            "OK, this learning rate as an important role because it will move the means at different.",
            "Let's say yes, right?",
            "So I will show you an example of this."
        ],
        [
            "OK, I give you an example of the let's say output.",
            "So here this is a dream sequence and we use the FCC here.",
            "You can visualize the projection of two components with PCA on the rights you have.",
            "OK, the intern sets intervals right bottom.",
            "These are, let's say the ruin to run set interval that are observed and on the top you get the instantaneous mean of the cluster assigned to this in turn set intervals.",
            "OK so here you can see that this is let's say pretty similar.",
            "The clustered into iOS are pretty similar to the."
        ],
        [
            "Throwaways you have here an example for the same melody, so here I have a representation.",
            "Well of just the pitch and I create clusters around this speech and you have also the internal set intervals so here.",
            "We use a learning rate for the online K means that is quite high like 0.9."
        ],
        [
            "That's why I show if we use a learning rate, which which is smaller.",
            "Let's say the means will move a bit less.",
            "Will we have more more?"
        ],
        [
            "Mentem to move, so you will get something which would like would look more like this."
        ],
        [
            "OK, so based on that we have the symbols or let's say audio sequence is converted into a sequence of symbols and we would like to predict the next symbol to come.",
            "So we use a technique derived from North Grams.",
            "So in which basically you try to predict the probability of the next possible symbols based on a subsequence of size N -- 1.",
            "And so this is a yes Markov chain modeling.",
            "Here we use, let's say, an extension of the simple engram technique.",
            "It's called prediction by partial match, and basically the idea is to when you cannot predict when you have not observed a symbol to predict given a context sequence.",
            "So the context sequence is this that guy.",
            "You have to perform a back off to make the prediction based on a lower order context.",
            "OK, so this is what you get here.",
            "Let's say when you have observed the symbol symbol, you make the prediction of the next symbol to come base of the count of the symbol.",
            "Given this sequence.",
            "And when you have not observed the symbol in that sequence, you use this gamma scaling factor and you recursively predict.",
            "Let's say the count based on the lower the context.",
            "So this is the."
        ],
        [
            "Simple lady.",
            "This is, let's say, an output of what the system would do based on a simple drum pattern.",
            "So you have the transcription on the top that represent let's say each incoming event.",
            "So you have for each vertical line in each color that represent a symbol that clustered, and so you have, let's say, the transcription on the top and the expectation on the bottom.",
            "You can see that.",
            "Well, the expectation after some time the expected patterns start to fit.",
            "To get closer to the transcription pattern, OK."
        ],
        [
            "So.",
            "We have been tried.",
            "We've tried to make an evaluation of the system in order to see whether it was learning through exposure of repeated patterns.",
            "So we have used, let's say drum loops or simple melodies that for loops and we have computed, let's say a weighted F measure to compare the expectation with."
        ],
        [
            "Transcription, so that's quite simple idea we've been using.",
            "We can consider, for example, that the red events, the red transcript event and the Red expected events can be compared using, let's say simple onset detection method OK, and we can make an average of the red F measure with the green F measure and so on.",
            "The thing is that infrequent events may have less weight, so we."
        ],
        [
            "Have waited this measure using that set the proportion of events that have occurred in this.",
            "In the during the listing process.",
            "So first this is from previous work.",
            "The system performs twice better than using random predictors.",
            "You given this weighted F measure, so that gave us, let's say, opportunity."
        ],
        [
            "To go on, so we've made more complex evaluation.",
            "Well, bigger evaluation when using the NST drum database, which is a corpus of drum loops and we have been, let's say, using a subset of this 5050 drum loops and you have on the left and histogram of the weighted F measure for all the database.",
            "So the baseline is what you have at the top.",
            "It's a 0 gram, so that's something that based on exposure, want, learn, merge and then you have a 5 gram.",
            "Model exposed to two loops, 5 gram model exposed to for loops and a 5 gram model exposed to 8 loops, yes.",
            "Good and bads which means I'm not understanding what those are like she thinks is it better with things.",
            "The distribution is tilted to the right or what?",
            "Yes, yes, maybe I OK OK. OK, let's redo that quickly.",
            "When you have first measure of 1 the let's say the sequence of events you're comparing at the same and when you have well the same within a tolerance window, which is a 50 millisecond that well, MI are setting let's say and when you have an F measure of zero as there is no event that match the order within the tolerance window.",
            "Yes.",
            "So here it is at the beginning you start with let's say distribution for the database that is.",
            "Much closer to 0 and through exposure.",
            "Let's say it's starting to learn the sequence which is repeated.",
            "So yes, that's not an extremely complex task task, but we can see that something is learned so well.",
            "Then we've been comparing the descriptors set that were measure.",
            "Given the descriptors that we were using, zero crossing rate, spectral centroid or MFC.",
            "And finally we have been applying the system to signify.",
            "This is so using the pitch and using a description based on the Internet region instead of the unset frame and that we got here.",
            "So we have made that with free folk melodies and we can see that, let's say the weighted F measure is increasing through exposure.",
            "But yes, there are, let's say.",
            "Measure that gives.",
            "Now there except that give best result.",
            "So the first one, for example what you have in parentheses, it's the average number of timber cluster and the average average number of internal set interval cluster.",
            "So in average there are more timber cluster for the monophonic melodies.",
            "So that makes the task rabbit."
        ],
        [
            "Are difficult.",
            "OK. From the prediction, we can derive an expectation anthropy.",
            "So this is let's say the that can be considered that has been presented through free yesterday by summer.",
            "As we can see that the certainty in the prediction for the next symbol and we can see here.",
            "Let's say the instantaneous expectation entropy in red for the timber and in green for the first time and the vertical boundaries are the, let's say the loops, where the loop starts and we can see, let's say, globally decreasing but locali repeating patterns of this entropy.",
            "So we would like to use this in some in some way to mark temporal cues."
        ],
        [
            "So this is another example for, let's say an expectation entropy of next step that let's say inside use to similar subpatterns and we have two 2."
        ],
        [
            "OK, so we can try to show you some example of concatenative synthesis use."
        ],
        [
            "This expectation OK, let's keep that.",
            "As a discussion, bootstrapping is cheating.",
            "We would like to have a fully online model and so we can do something.",
            "Either we want to be straightforward.",
            "We can shoot more and try to learn a chamber distance on a world drum collection or the musical collection so that, let's say, the yes, the events are well.",
            "Are best described and we can also try to have this bootstrap step continuously running in parallel, so that's more related to the work required.",
            "Machine has been presenting and then OK.",
            "This is straightforward discrete system.",
            "The onset at discrete and the symbols are fixed, so we would like to go from hard to soft clustering and work with transient region instead."
        ],
        [
            "Chris Pine set so well that's it summary I think yes.",
            "The ideas here and online and supervised system for computer.",
            "Expectation of senior and well I skip this.",
            "I prefer to show you one example applied to monophonic Melody, if it's possible.",
            "OK.",
            "So this is the original Austrian folk song.",
            "And then you get the synthesis.",
            "I'm sorry, I'm sorry.",
            "I can show you that one.",
            "It's very few time, so this is a jungle pattern answer.",
            "It's quite loud.",
            "OK, and then this is what you get when you expect it.",
            "Well."
        ],
        [
            "That's it, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I present you well, work related to the work you have just seen before within them.",
                    "label": 0
                },
                {
                    "sent": "Cap Project in computer by University.",
                    "label": 0
                },
                {
                    "sent": "So this is let's say a bit more applied work which tries to model let's say the learning of sequences and expectation based on the listing of musical audio.",
                    "label": 0
                },
                {
                    "sent": "So here for purpose of simplicity we won't use an incremental approach and we will try to work with a fixed number of cluster.",
                    "label": 0
                },
                {
                    "sent": "So I'll show you.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The let's say the outline of the presentation goals.",
                    "label": 0
                },
                {
                    "sent": "I give you some background.",
                    "label": 0
                },
                {
                    "sent": "I propose a system, show some evaluation.",
                    "label": 0
                },
                {
                    "sent": "So we have been working evaluating on drum data and also we present some preliminary experiments using monophonic sang Melody and then while I show some future.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Worked in conclusions, so we want to build a system for producing musical expectation based on the observation of audio.",
                    "label": 1
                },
                {
                    "sent": "We have in this project quite the same constraints we would like the system to, let's say work in online fashion and unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "OK, but here again it will won't be incremental.",
                    "label": 0
                },
                {
                    "sent": "So here the task is to let's say.",
                    "label": 0
                },
                {
                    "sent": "Based on the observation of a musical sequence, let's say the sequence stop and you have to predict what and where will be the next musical event.",
                    "label": 0
                },
                {
                    "sent": "OK, so yes, this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've already said so.",
                    "label": 0
                },
                {
                    "sent": "Some background on this, so this is, let's say a lot of ideas.",
                    "label": 0
                },
                {
                    "sent": "We have been tried to borrow first, prediction, breathing, listening.",
                    "label": 0
                },
                {
                    "sent": "So work from Ellis, Abdella interesting symbolic speech sequence learning system.",
                    "label": 0
                },
                {
                    "sent": "So here we've been, yes, mainly focusing on what I've been doing.",
                    "label": 0
                },
                {
                    "sent": "Pearson Wiggins on that then.",
                    "label": 0
                },
                {
                    "sent": "Well, there are some ideas we would like to integrate in the future of valuations.",
                    "label": 0
                },
                {
                    "sent": "Call following a component of the signal also for.",
                    "label": 0
                },
                {
                    "sent": "Let's say generating synthesizing the expectation of the system we use some, let's say, works from concatenated synthesis and also well this work is related to improvisation system that could be could be used.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the system design it's pretty similar to what regard as presented.",
                    "label": 1
                },
                {
                    "sent": "We have a first layer which is doing the feature extraction.",
                    "label": 0
                },
                {
                    "sent": "So here we want to extract, let's say timber descriptors, unset bits and we will say perform the reasoning at.",
                    "label": 0
                },
                {
                    "sent": "Mid level OK using this mid level descriptors.",
                    "label": 0
                },
                {
                    "sent": "Then we have a layer of dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "So basically it's doing online clustering and we let's say create symbols for the timber class and for the intern sets interval class.",
                    "label": 0
                },
                {
                    "sent": "So it's written BRII.",
                    "label": 0
                },
                {
                    "sent": "This is bit relative intern sets interval.",
                    "label": 0
                },
                {
                    "sent": "We try to let's say the system that will process music in dependently of the extracted tempo an this is fed to, let's say symbolic music alert.",
                    "label": 0
                },
                {
                    "sent": "A symbolic sequence learner that will predict the next timber and the next interval setting.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ever.",
                    "label": 0
                },
                {
                    "sent": "OK, so first the feature extraction module.",
                    "label": 1
                },
                {
                    "sent": "Well, we extract the bits using the Davis.",
                    "label": 0
                },
                {
                    "sent": "The method proposed by Davis.",
                    "label": 1
                },
                {
                    "sent": "We extract the unset using the high frequency content and then some simple descriptors.",
                    "label": 0
                },
                {
                    "sent": "So rough spectral shape descriptors.",
                    "label": 1
                },
                {
                    "sent": "Well, zero crossing rate.",
                    "label": 1
                },
                {
                    "sent": "It's not spectral, but it described roughly the spectral shape spectral centroid.",
                    "label": 0
                },
                {
                    "sent": "Mel frequency cepstrum coefficient and also we expect the pitch using the in FT, which is an adaptation of the in algorithm by 7 in the spectral domain.",
                    "label": 0
                },
                {
                    "sent": "So we can compute this algorithms on the unset frame.",
                    "label": 0
                },
                {
                    "sent": "That's very rough, but that can say a lot fast processing or average them over the Internet.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set region.",
                    "label": 0
                },
                {
                    "sent": "So you have here well, an output for a simple example for the extraction of fun sets and bits.",
                    "label": 0
                },
                {
                    "sent": "So based on the Davis be tracking method and high frequency content onset detection.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we go now to this dimensionality reduction module.",
                    "label": 1
                },
                {
                    "sent": "We'd like to produce an online unsupervised clustering to create the symbols for temporal and timber features.",
                    "label": 1
                },
                {
                    "sent": "Prior to this, this is a bit cheating.",
                    "label": 1
                },
                {
                    "sent": "We perform a bootstrap step at the beginning.",
                    "label": 0
                },
                {
                    "sent": "The system doesn't know anything, so it will accumulate some, let's say information from the audio and will do a small batch on that.",
                    "label": 0
                },
                {
                    "sent": "OK, so this helps us to normalize the Chamber.",
                    "label": 1
                },
                {
                    "sent": "Distance and also to try to make an estimate of the number of clusters to work with.",
                    "label": 0
                },
                {
                    "sent": "So we use a grid of Gaussian mixture model.",
                    "label": 0
                },
                {
                    "sent": "Train with them to choose the best number of components so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll go give some details about this.",
                    "label": 0
                },
                {
                    "sent": "This Gaussian mixture model grid is made as following each row.",
                    "label": 0
                },
                {
                    "sent": "It's an independent trend with initial random initialization, and for each row we have.",
                    "label": 0
                },
                {
                    "sent": "Say for each column, or GMM with increasing number of Gaussians.",
                    "label": 1
                },
                {
                    "sent": "So from one to the let's say maximum K we'll.",
                    "label": 0
                },
                {
                    "sent": "Oh and well, that's it.",
                    "label": 0
                },
                {
                    "sent": "We fit each of this.",
                    "label": 0
                },
                {
                    "sent": "Let's say each of these cells using the expectation maximization algorithm.",
                    "label": 0
                },
                {
                    "sent": "There is a very simple regularization procedure to let's say avoid excessively low variances and then well based on this we can choose for each row.",
                    "label": 1
                },
                {
                    "sent": "Let's say the most.",
                    "label": 0
                },
                {
                    "sent": "The optimal number of.",
                    "label": 0
                },
                {
                    "sent": "Components using an information criterion as buys info by off Schwarz information criterion, Akaike information criterion or let's say a single order correction of the Akaike information criterion for small sample size.",
                    "label": 0
                },
                {
                    "sent": "We get the median of the best cover each row and we obtain.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say a grid which looks a bit like this one.",
                    "label": 0
                },
                {
                    "sent": "So here the light colors indicate, let's say a minimize information criterion.",
                    "label": 0
                },
                {
                    "sent": "In this case, this is the big we are representing, and well, for this example we will choose free clusters for the timber.",
                    "label": 0
                },
                {
                    "sent": "If three clusters for the iOS.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So based on that, we can now perform K means and do the, let's say online processing.",
                    "label": 0
                },
                {
                    "sent": "So for each incoming point we will assign the nearest cluster using Euclidean distance and make an update of this cluster well based on the distance and learning rate.",
                    "label": 1
                },
                {
                    "sent": "OK, this learning rate as an important role because it will move the means at different.",
                    "label": 0
                },
                {
                    "sent": "Let's say yes, right?",
                    "label": 0
                },
                {
                    "sent": "So I will show you an example of this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I give you an example of the let's say output.",
                    "label": 0
                },
                {
                    "sent": "So here this is a dream sequence and we use the FCC here.",
                    "label": 0
                },
                {
                    "sent": "You can visualize the projection of two components with PCA on the rights you have.",
                    "label": 0
                },
                {
                    "sent": "OK, the intern sets intervals right bottom.",
                    "label": 0
                },
                {
                    "sent": "These are, let's say the ruin to run set interval that are observed and on the top you get the instantaneous mean of the cluster assigned to this in turn set intervals.",
                    "label": 0
                },
                {
                    "sent": "OK so here you can see that this is let's say pretty similar.",
                    "label": 0
                },
                {
                    "sent": "The clustered into iOS are pretty similar to the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Throwaways you have here an example for the same melody, so here I have a representation.",
                    "label": 0
                },
                {
                    "sent": "Well of just the pitch and I create clusters around this speech and you have also the internal set intervals so here.",
                    "label": 0
                },
                {
                    "sent": "We use a learning rate for the online K means that is quite high like 0.9.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's why I show if we use a learning rate, which which is smaller.",
                    "label": 0
                },
                {
                    "sent": "Let's say the means will move a bit less.",
                    "label": 0
                },
                {
                    "sent": "Will we have more more?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mentem to move, so you will get something which would like would look more like this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so based on that we have the symbols or let's say audio sequence is converted into a sequence of symbols and we would like to predict the next symbol to come.",
                    "label": 0
                },
                {
                    "sent": "So we use a technique derived from North Grams.",
                    "label": 0
                },
                {
                    "sent": "So in which basically you try to predict the probability of the next possible symbols based on a subsequence of size N -- 1.",
                    "label": 0
                },
                {
                    "sent": "And so this is a yes Markov chain modeling.",
                    "label": 0
                },
                {
                    "sent": "Here we use, let's say, an extension of the simple engram technique.",
                    "label": 0
                },
                {
                    "sent": "It's called prediction by partial match, and basically the idea is to when you cannot predict when you have not observed a symbol to predict given a context sequence.",
                    "label": 1
                },
                {
                    "sent": "So the context sequence is this that guy.",
                    "label": 1
                },
                {
                    "sent": "You have to perform a back off to make the prediction based on a lower order context.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what you get here.",
                    "label": 0
                },
                {
                    "sent": "Let's say when you have observed the symbol symbol, you make the prediction of the next symbol to come base of the count of the symbol.",
                    "label": 0
                },
                {
                    "sent": "Given this sequence.",
                    "label": 0
                },
                {
                    "sent": "And when you have not observed the symbol in that sequence, you use this gamma scaling factor and you recursively predict.",
                    "label": 1
                },
                {
                    "sent": "Let's say the count based on the lower the context.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple lady.",
                    "label": 0
                },
                {
                    "sent": "This is, let's say, an output of what the system would do based on a simple drum pattern.",
                    "label": 0
                },
                {
                    "sent": "So you have the transcription on the top that represent let's say each incoming event.",
                    "label": 0
                },
                {
                    "sent": "So you have for each vertical line in each color that represent a symbol that clustered, and so you have, let's say, the transcription on the top and the expectation on the bottom.",
                    "label": 0
                },
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "Well, the expectation after some time the expected patterns start to fit.",
                    "label": 0
                },
                {
                    "sent": "To get closer to the transcription pattern, OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have been tried.",
                    "label": 0
                },
                {
                    "sent": "We've tried to make an evaluation of the system in order to see whether it was learning through exposure of repeated patterns.",
                    "label": 0
                },
                {
                    "sent": "So we have used, let's say drum loops or simple melodies that for loops and we have computed, let's say a weighted F measure to compare the expectation with.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Transcription, so that's quite simple idea we've been using.",
                    "label": 0
                },
                {
                    "sent": "We can consider, for example, that the red events, the red transcript event and the Red expected events can be compared using, let's say simple onset detection method OK, and we can make an average of the red F measure with the green F measure and so on.",
                    "label": 0
                },
                {
                    "sent": "The thing is that infrequent events may have less weight, so we.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have waited this measure using that set the proportion of events that have occurred in this.",
                    "label": 0
                },
                {
                    "sent": "In the during the listing process.",
                    "label": 0
                },
                {
                    "sent": "So first this is from previous work.",
                    "label": 0
                },
                {
                    "sent": "The system performs twice better than using random predictors.",
                    "label": 1
                },
                {
                    "sent": "You given this weighted F measure, so that gave us, let's say, opportunity.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To go on, so we've made more complex evaluation.",
                    "label": 0
                },
                {
                    "sent": "Well, bigger evaluation when using the NST drum database, which is a corpus of drum loops and we have been, let's say, using a subset of this 5050 drum loops and you have on the left and histogram of the weighted F measure for all the database.",
                    "label": 0
                },
                {
                    "sent": "So the baseline is what you have at the top.",
                    "label": 0
                },
                {
                    "sent": "It's a 0 gram, so that's something that based on exposure, want, learn, merge and then you have a 5 gram.",
                    "label": 0
                },
                {
                    "sent": "Model exposed to two loops, 5 gram model exposed to for loops and a 5 gram model exposed to 8 loops, yes.",
                    "label": 0
                },
                {
                    "sent": "Good and bads which means I'm not understanding what those are like she thinks is it better with things.",
                    "label": 0
                },
                {
                    "sent": "The distribution is tilted to the right or what?",
                    "label": 0
                },
                {
                    "sent": "Yes, yes, maybe I OK OK. OK, let's redo that quickly.",
                    "label": 0
                },
                {
                    "sent": "When you have first measure of 1 the let's say the sequence of events you're comparing at the same and when you have well the same within a tolerance window, which is a 50 millisecond that well, MI are setting let's say and when you have an F measure of zero as there is no event that match the order within the tolerance window.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So here it is at the beginning you start with let's say distribution for the database that is.",
                    "label": 0
                },
                {
                    "sent": "Much closer to 0 and through exposure.",
                    "label": 0
                },
                {
                    "sent": "Let's say it's starting to learn the sequence which is repeated.",
                    "label": 0
                },
                {
                    "sent": "So yes, that's not an extremely complex task task, but we can see that something is learned so well.",
                    "label": 0
                },
                {
                    "sent": "Then we've been comparing the descriptors set that were measure.",
                    "label": 0
                },
                {
                    "sent": "Given the descriptors that we were using, zero crossing rate, spectral centroid or MFC.",
                    "label": 0
                },
                {
                    "sent": "And finally we have been applying the system to signify.",
                    "label": 0
                },
                {
                    "sent": "This is so using the pitch and using a description based on the Internet region instead of the unset frame and that we got here.",
                    "label": 0
                },
                {
                    "sent": "So we have made that with free folk melodies and we can see that, let's say the weighted F measure is increasing through exposure.",
                    "label": 0
                },
                {
                    "sent": "But yes, there are, let's say.",
                    "label": 0
                },
                {
                    "sent": "Measure that gives.",
                    "label": 0
                },
                {
                    "sent": "Now there except that give best result.",
                    "label": 0
                },
                {
                    "sent": "So the first one, for example what you have in parentheses, it's the average number of timber cluster and the average average number of internal set interval cluster.",
                    "label": 0
                },
                {
                    "sent": "So in average there are more timber cluster for the monophonic melodies.",
                    "label": 0
                },
                {
                    "sent": "So that makes the task rabbit.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are difficult.",
                    "label": 0
                },
                {
                    "sent": "OK. From the prediction, we can derive an expectation anthropy.",
                    "label": 0
                },
                {
                    "sent": "So this is let's say the that can be considered that has been presented through free yesterday by summer.",
                    "label": 0
                },
                {
                    "sent": "As we can see that the certainty in the prediction for the next symbol and we can see here.",
                    "label": 1
                },
                {
                    "sent": "Let's say the instantaneous expectation entropy in red for the timber and in green for the first time and the vertical boundaries are the, let's say the loops, where the loop starts and we can see, let's say, globally decreasing but locali repeating patterns of this entropy.",
                    "label": 0
                },
                {
                    "sent": "So we would like to use this in some in some way to mark temporal cues.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is another example for, let's say an expectation entropy of next step that let's say inside use to similar subpatterns and we have two 2.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we can try to show you some example of concatenative synthesis use.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This expectation OK, let's keep that.",
                    "label": 0
                },
                {
                    "sent": "As a discussion, bootstrapping is cheating.",
                    "label": 1
                },
                {
                    "sent": "We would like to have a fully online model and so we can do something.",
                    "label": 0
                },
                {
                    "sent": "Either we want to be straightforward.",
                    "label": 0
                },
                {
                    "sent": "We can shoot more and try to learn a chamber distance on a world drum collection or the musical collection so that, let's say, the yes, the events are well.",
                    "label": 0
                },
                {
                    "sent": "Are best described and we can also try to have this bootstrap step continuously running in parallel, so that's more related to the work required.",
                    "label": 0
                },
                {
                    "sent": "Machine has been presenting and then OK.",
                    "label": 1
                },
                {
                    "sent": "This is straightforward discrete system.",
                    "label": 0
                },
                {
                    "sent": "The onset at discrete and the symbols are fixed, so we would like to go from hard to soft clustering and work with transient region instead.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chris Pine set so well that's it summary I think yes.",
                    "label": 0
                },
                {
                    "sent": "The ideas here and online and supervised system for computer.",
                    "label": 1
                },
                {
                    "sent": "Expectation of senior and well I skip this.",
                    "label": 1
                },
                {
                    "sent": "I prefer to show you one example applied to monophonic Melody, if it's possible.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is the original Austrian folk song.",
                    "label": 0
                },
                {
                    "sent": "And then you get the synthesis.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "I can show you that one.",
                    "label": 0
                },
                {
                    "sent": "It's very few time, so this is a jungle pattern answer.",
                    "label": 0
                },
                {
                    "sent": "It's quite loud.",
                    "label": 0
                },
                {
                    "sent": "OK, and then this is what you get when you expect it.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, thanks.",
                    "label": 0
                }
            ]
        }
    }
}