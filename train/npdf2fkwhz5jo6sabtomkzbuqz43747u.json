{
    "id": "npdf2fkwhz5jo6sabtomkzbuqz43747u",
    "title": "Preference Learning",
    "info": {
        "author": [
            "Johannes F\u00fcrnkranz, Department of Computer Science, Darmstadt University of Technology",
            "Eyke Hullermeier, Mathematik und Informatik, Philipps-Universit\u00e4t Marburg"
        ],
        "published": "Nov. 16, 2010",
        "recorded": "September 2010",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2010_hullermeier_furnkranz_pl/",
    "segmentation": [
        [
            "Welcome everybody to our workshop on preference learning.",
            "This workshop has been prepared by myself.",
            "I am I cool Amaya from Marburg University in Germany, and you're his friend counts from Domscheit University in also in Germany.",
            "This workshop constitutes the first part of our.",
            "This tutorial constitutes the first part of our workshop on preference learning, and it will be followed by a number of talks.",
            "That will be given in the afternoon.",
            "Actually we were planning to.",
            "Have a somewhat more comprehensive and longer tutorial, but eventually it turned out that we received quite a couple of good submissions to our workshop and then we decided to have more presentations and therefore to shorten the tutorial a little bit.",
            "So after all, we will have a 90 minutes tutorial, which clearly means that we can only give the more or less a superficial introduction to the field, so you should understand it more to an introduction.",
            "Preference learning, then tutorial that really goes into technical details."
        ],
        [
            "So first let me give a very brief introduction to what we are actually talking about.",
            "So what is preference learning?",
            "Roughly speaking, our view of preference learning is as an emerging subfield of machine learning that deals with the learning of preference models from observed preference information, or from information that has been extracted specifically for that purpose.",
            "For example, from sources like the Internet, typically like in machine learning in general, these models are used for predictive purposes, that is to predict the preferences of.",
            "Knew individuals that you have not seen before or references in you situations in which you have not been before, and so on.",
            "So you see that preference learning is connecting two things, namely learning on the one side and preferences on the other side, and therefore it is a kind of interdisciplinary research field that connects machine learning with other areas in which preferences have played a key role for a couple of years.",
            "Like for example, operations research, the social science and economy, and so on.",
            "So these are all fields in which preferences have been studied for quite a."
        ],
        [
            "Long time.",
            "The growing interest in this field is also witnessed by a number of dedicated events and workshops that have been organized on this topic.",
            "Here we have a small list which is not exhaustive, but nevertheless shows that really a number of people have started to to work in this field.",
            "This list also, of course, includes our.",
            "Say one can maybe even say workshop serious.",
            "It's already the third time that we organize this workshop on the occasion of the of the CML conference.",
            "And what is perhaps also notable?",
            "I would like to point out is that also now mathematicians have become interested in this topic of preferences, and in particular in ranking.",
            "So this year, for instance, there is the first international workshop on the mathematics of ranking.",
            "So this is really something that attracts attention also outside our."
        ],
        [
            "Community.",
            "More generally, we can see currently that preferences play a key role also in AI in general, so not only in machine learning, but in AI in general.",
            "And this of course has a number of reasons in particular.",
            "One reason is that preferences have a number of applications of important applications, so they are used in recommender systems.",
            "In adaptive systems in information retrieval, autonomous agents games, and so on, these are all fields in which preferences really play a very important role.",
            "Of course, AI is not only focusing on the learning or the acquisition of Preferences, but in the 1st place.",
            "These people are also studying.",
            "Aspects related to preference, representation and reasoning with preferences.",
            "Yeah, so seen from the point of AI.",
            "Preference learning is again only a subfield within these broader field of."
        ],
        [
            "Answers.",
            "So here you see the agenda of our introductory tutorial today.",
            "I will start right now with a brief overview of what kind of problems have been studied till now in the field of preference learning then Johannes will take over and speak about loss functions.",
            "As you will see this these types of preference learning call for the development of novel loss functions and Johannes will explain you more about this then in the third part I will speak.",
            "A little bit about what kind of learning methods, what kind of learning techniques have been proposed so far to tackle these preference learning problems.",
            "And finally Johannes will speak a little bit about complexity issues.",
            "Sometimes these techniques are quite complex from a computational point of view, and that's why it is also worth discussing this issue.",
            "OK, so let me start right away."
        ],
        [
            "The first with the first part of this tutorial, which is about preference learning problems.",
            "So preference learning problems are quite diverse and they can be distinguished along a number of different dimensions, including, for example, the representation of the preferences or the type of preference model.",
            "So how are preferences actually represented?",
            "Other represented in terms of utility functions which can be ordinal or Cardinal or in a relational form using preference relations?",
            "Or maybe a type of logical description representation?",
            "You will hear more about these terms in the following then the second question is how are the individuals?",
            "About which we want to reason, I represent it, or the alternatives or items whose preferences we want to describe.",
            "Is it only in terms of an identifier, or maybe in terms of the feature vector or even more complex in terms of a type of structured representation?",
            "And then there is the type of training input?",
            "Is it direct or indirect?",
            "We have complete or only incomplete preference relations?",
            "Is it in the form of utility's and so on?",
            "So you will see in the following that there is a great variant.",
            "Parietti and in modeling these type of."
        ],
        [
            "Friends learning problems.",
            "Very generally, one can distinguish 2.",
            "Ways of representing preferences that have been studied quite intensively in the literature.",
            "For example, on choice and decision theory, and this is in terms of what we call here absolute and relative preferences.",
            "The one possibility to describe preferences is to evaluate to assess single alternatives.",
            "So I give you a single alternative and I say to what extent are like or dislike this alternative, and the second very natural way to express preferences in terms of.",
            "Comparing competing alternatives.",
            "So I give you 2 alternatives for example and you say me which one you prefer and maybe to what extent.",
            "So this is the difference between assessing and comparing.",
            "And again, within these two categories, of course, you can make a finer distinction.",
            "For example, you can express absolute preferences in a binary way, saying only, for example, I like an alternative, or I dislike it.",
            "For instance, I like A&B.",
            "They get preference degrees one or utility quiz one, and I dislike CMP.",
            "Or you can do it in a gradual way, for instance expressing preferences on a numerical scale.",
            "Using utility degrees between zero and one, or perhaps on an ordinal scale in which you just have a finite number of graded, ordered utility degrees which are not numerical, then on the right hand side here you can use different types of order relations in order to describe preferences in a relative way.",
            "For example, total orders or partial order relations in which you are also allowed to say.",
            "Certain objects simply cannot be compared, right?",
            "I cannot compare them.",
            "We will see examples of this type later on.",
            "Roughly, we can.",
            "Say that from a machine learning POV, this left hand side here leads to a kind of regression problem.",
            "Maybe in ordinal regression problem, because here the problem is to predict utility decrease.",
            "This is something very close to regression learning on the right hand side.",
            "Here we will see that.",
            "That tasks in which preferences are represented in a relative way more lead to classification and ranking problems.",
            "Yeah, because here you have to compare things which is a type of classification.",
            "If I compare two things, I have two alternatives and I can express."
        ],
        [
            "This in form of A's vacation problem.",
            "The rest of my overview will follow the following distinction between 2, say types of different preference preference learning tasks.",
            "The one is a type of problem which is very close to conventional supervised learning, and here the problem is to learn a kind of function that Maps from an instance SpaceX to a space of, say, preference models here denoted by P and this function Maps.",
            "Instances too, yeah, preference models and this type of problem is very close to structured or complex output prediction becausw these preference models here on the right hand side are typically quite complex.",
            "Definitely what we're doing here is going beyond simple prediction of scalar outputs like in classification and regression.",
            "So this is the one type where you have like, typically in supervised machine learning the distinction between an input speed space and an output space.",
            "Then in the second part I will speak about problems for which you do not have this distinction between input and output space.",
            "At least not so clearly, and this will include problems like object ranking, instance ranking, collaborative filtering and so on."
        ],
        [
            "So let me first say a bit more about this first type of problem.",
            "So here instances are typically, but not necessarily characterized in terms of a feature vector, but this is the more uninteresting part.",
            "What is more interesting is the right hand side here, namely the way in which outputs are represented.",
            "And here normally the output space consists of preference models over a fixed set of alternatives.",
            "So we fixed the set of alternatives about.",
            "We make preference statements, we call these aternatives, typically classes or labels.",
            "Just leaning on the standard notation that is also used in machine learning.",
            "Supervised machine learning, and these are represented in terms of an identifier, so we are speaking here mainly of extensions of multiclass classification.",
            "As you will see."
        ],
        [
            "In a minute.",
            "The first type of problem that I have here is multi label classification.",
            "Actually Multi Label classification is not say preference learning task in the narrow sense, but we can subsume it here under the notion of preference learning.",
            "If we interpret the labels just as preference statements.",
            "So the situation here is that you have as trading information instances on the left hand side, whatever that means.",
            "It's just feature vectors.",
            "For example, a person described by number of features.",
            "And then you have a set of labels which correspond to our alternatives and we just say for every instance whether this instance likes the alternative or not.",
            "Likes here is encoded as one, and dislike is encoded as zero.",
            "So this is the information we get for training.",
            "Then for prediction we get a new instance and we have to make a prediction of his or her preferences again.",
            "In terms of such a 01 vector.",
            "The ground truth, we assume in this setting is also this 01 vector of like this like values and what we need here in order to say how good our prediction actually is is a loss function that compares these types of 01 vectors or the subsets two subsets of liked our preferred items?",
            "And this is something that Johannes will talk about in more."
        ],
        [
            "Detail later on.",
            "Then the second type of problem is a slight.",
            "Only a slight modification of the previous one in which the only difference is that the prediction is now given in terms of a ranking of all items that can also be expressed as a permutation.",
            "Here for example, the alternative A is put on rank 4.",
            "The alternative B on rank one and so on.",
            "You see this permutation encodes this ranking.",
            "And.",
            "Still, we assume that the ground truth is a subset of liked or preferred items, and then what we have to do is to come up with the last function that compares ranking in which we.",
            "We intend to predict to put the preferred at the preferred alternatives.",
            "Ahead of the disliked alternatives and what we have to do is to compare this type of ranking with the subset."
        ],
        [
            "Of preferred items.",
            "Then recently there has been proposed greater extension of this multi label setting in which we go beyond the simple distinction between preferred and non preferred and can express preferences on an ordinal degree like a -- 0 plus and plus plus.",
            "In this example.",
            "Here the prediction again is of the same form and also the ground truth.",
            "So what we have to do here is to compare two subsets too.",
            "One can say fuzzy subsets of preferred items."
        ],
        [
            "You can also put this into the ranking context in which the prediction is given in form of a ranking again and then what we need is a loss function that compares such a ranking with a fuzzy subset of preferred item."
        ],
        [
            "So.",
            "The second type of so these were all variants say of this multi label classification setting.",
            "The second type of problem is label ranking and label ranking.",
            "We are given preference information of the of the relative type.",
            "So here we assume that with every instance we associate a subset of pairwise preferences between the items given as training information.",
            "So for example for the first instance here we know that.",
            "A is preferred to be.",
            "Bees prefer to see and seize.",
            "Prefer to D for the second instance.",
            "We only know that bees prefer to see and so on.",
            "So this is our training information.",
            "So on the basis of this training information, we tried to train a model that is able to predict for a new query instance a total order, a ranking in the form of a total order of alternatives.",
            "So here for example, B better than D, better than C, better than A and we assume also that the ground truth is of the same type.",
            "So the ground truth is also a ranking.",
            "And what we have to do then is to compare.",
            "Predicted ranking with the true."
        ],
        [
            "What we have seen here are two examples.",
            "In which the preferences are modeled either in the absolute way or in the relative way, and just as a side remark, I would like to mention that.",
            "That a combination of these two ways of representing preferences has been proposed, namely what we call something that we call a calibrated label, ranking a calibrated ranking is just a ranking of the normal type in which we introduce Additionally a kind of, say zero point that distinguishes between a positive side and the negative side.",
            "So the information this type of prediction captures.",
            "Is a total order of alternatives plus a distinction between what is liked and what is not liked or what is relevant or what is irrelevant depending on the context in which we use this type of prediction."
        ],
        [
            "OK, now let me say a few words about the second type of problems in which we do not have this clear distinction between input space and output space, as we typically have in supervised machine learning.",
            "So I will mention as examples here the problems of so-called object and instance ranking, in which we actually do not have a kind of output space.",
            "And the problem of collaborative collaborative filtering in which we do not have a clear input space."
        ],
        [
            "Clearly defined input space.",
            "So the problem of object ranking has already been proposed number of years ago and in this setting we are given as training information.",
            "Pairwise comparisons between objects.",
            "Here again it might be persons or whatever, but it can also be more complex objects like websites or so on presented in a more complex way.",
            "So we are given these pairwise preferences be between.",
            "Objects or instances as training information and the goal is to train a function are ranking function that is able to rank every new subset of of items that we maybe have not seen before.",
            "So if I give a query such as subset of items X 12X13, MY function is supposed to rank them to put them in a total order like this one here.",
            "Sometimes, depending on the context, we are not interested in the full ranking but only for example in in the top ranks in the first K top ranks or we are maybe interested in a distinction between positive and negative or relevant or irrelevant items.",
            "So this ranking is typically compared with the ground truth truth that is also ranking a total order of.",
            "All the alternatives or only a top K ranking?",
            "Or maybe a subset of positive and negative items?",
            "Like an information retrieval, how you typically have relevant, you distinguish between relevant and non relevant documents."
        ],
        [
            "In instance ranking the situation is almost the same except for the type of training information that we are given, because here we are given training information of the absolute types, so not relative comparisons between pairs of objects, but objects rated on an absolute scale.",
            "Typically it's an ordinal scale like here.",
            "So for example, the first item has a minus rating, the second item has a 0 rating and so on.",
            "Yeah, ratings on an ordinal scale.",
            "And again we want to train a ranking function that is able to rank every new subset of items like in the example before and as a ground truth.",
            "We suppose that we are again given these ordinary ratings of the objects and of course the intention is to rank the items having a positive rating before the items having a negative rating.",
            "And if this is not the case, then you have made a ranking error.",
            "So for example, here we put minus item an item with a rating minus before an item with the ranking plus and this is of course a ranking mistake ranking error.",
            "Actually, this looks like an ordinal classification or an ordinal regression problem, but if you look closer at what we are using here as a prediction and as a ground truth, you see that we actually do not want to maximize classification accuracy.",
            "But what we actually want to maximize."
        ],
        [
            "Ranking accuracy, so here we have a distinction between classification and.",
            "And ranking you can also see this as an extension of AUC maximization, which we only have two classes, positive and negative.",
            "Here we have the multiclass case in which the ordinal ratings can also assume values, something in between the worst and the best.",
            "And as I said, what we're trying to do here is ranked from the most likely good instances to the most likely bad instances."
        ],
        [
            "Um?",
            "Yeah, the.",
            "The last problem here I want to discuss very briefly is collaborative filtering.",
            "As one of the methods that have been studied quite intensively in the recommender systems community.",
            "Here we do not have a kind of clearly defined input space becausw both the users and the items.",
            "The products are only described in terms of an identifier.",
            "The preferences are of the absolute type, so we are given absolute ratings of products given by the users and.",
            "Typically this is again done in terms of ordinal degrees.",
            "So we have ordinal utility degrees, for example here, ranging from very bad to excellent.",
            "And the typical setting in collaborative filtering looks like this.",
            "You have given such a table which is partly filled with ratings.",
            "Typically this table is very sparse because most of the fields are empty here.",
            "For example, this second user has rated the third product as as bad, and so on.",
            "And what you what you essentially try to do is fill the table, or at least fill one row of the table, which corresponds to predicting.",
            "The preference is the absolute preferences of 1 specific user for all the products here, and this is done by exploiting correlations between these ratings given as training information."
        ],
        [
            "OK so here you see an overview I am not going to discuss this in detail.",
            "Maybe you can have a closer look at this.",
            "At home you can download the slides from the Internet in which I have summarized the problems.",
            "I have briefly touched on here in the first part of this tutorial and distinguish between the type of representation that is used for the inputs and the outputs and the type of reference information that is given as training.",
            "Information for prediction and as a ground truth, distinguishing distinguishing between absolute and relative preferences or dinner, numerical, binary, and so on.",
            "But what you can also grasp here from this table is that we roughly have two main directions in preference learning.",
            "The one is to generalize the multiclass classification problem.",
            "So this year, or tasks that.",
            "Can be seen as generalizations on of conventional multiclass classification and the second direction is to study different types of ranking problems.",
            "So ranking at variance these are.",
            "The problems here of label ranking, object ranking and instance ranking essentially.",
            "So this is the second main direction."
        ],
        [
            "Within preference learning.",
            "So.",
            "I just mentioned.",
            "I would just like to mention that of course one can also go beyond predicting simple rankings in the form of total orders and.",
            "Essentially, rankings can be generalized in two different ways.",
            "First, we can say that we do not want to.",
            "We do not insist on having a strict order in the sense that we assume that all alternatives are compareable.",
            "So we can generalize.",
            "Bye.",
            "Allowing to express in comparability between two items, or also for allowing to express the in difference between 2 two items.",
            "For example, if I would like to to predict the preferences of a person with regard to these four cities here, for example for making Holidays or for organizing a conference or whatever, I, for example, would like to allow to say that Barcelona is maximally preferred.",
            "Rome is least preferred, but between Paris and London in between, I cannot distinguish, so I cannot compare them.",
            "This is not a ranking.",
            "This is not a total order, but only a partial order.",
            "Yeah.",
            "This idea of.",
            "Of representing preferences in terms of partial orders has been studied, especially in the context of what is called conditional preference networks.",
            "I will say a little bit about this later on.",
            "Yes, of course.",
            "Those were just getting bored with lunch later.",
            "Because then.",
            "Objects with Jessica Stlouise later movie.",
            "None of this would be.",
            "No, it's not equivalent for several reasons.",
            "First, we would not express in comparability, but indifference objects put in the same class, assigned the same class label would be indistinguishable.",
            "So it would correspond to expressing indifference and the the second what you essentially get then, is what people often call a bucket order.",
            "Some elements are put in the same bucket, but there is yet another distinction.",
            "If you assign these absolute degrees, then you have essentially more information, because if you have only a bucket order then you do not know necessarily the absolute ratings.",
            "If you know the absolute ratings, you have a bucket order.",
            "That's so you can go from the absolute ratings to the order, but not the other way around.",
            "So you have essentially more information, yeah?",
            "So.",
            "A prediction in terms of a partial order can be interpreted in two different ways, depending on what we assume as a ground truth.",
            "If we assume that the ground truth is a total order, it corresponds to the interpretation of, say, partial abstention or uncertainty.",
            "That way, I was talking about yesterday in his talk and say OK, actually, Paris and London can be ranked, but simply I don't know.",
            "I don't know how to rank them or the second interpretation is that.",
            "The ground truth is really a partial order for what reason ever London and Paris cannot be compared, so these are two different interpretations that have to be distinguished."
        ],
        [
            "In that context here.",
            "So now eventually I make the.",
            "The transfer to Johannes.",
            "This is my last slide.",
            "And we have seen on the previous slides that within the context of these different types of of preference learning problems, we have to compare different types of predictions and with the ground truth if we want to, we want to evaluate a classifier predictor.",
            "And.",
            "We have seen that sometimes it's just the comparison of utility degrees, so of scalar outputs and predictions.",
            "This is easy this we already know how to do, but in the more complex for the more complex problems we have to compare more, say complex things given as a prediction on the one side and as a ground truth on the other side.",
            "And this is an interesting question by itself.",
            "How to do it?",
            "How to how to how to make these comparison."
        ],
        [
            "And this is something that Johannes will now speak about in the second part of our tutorial."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome everybody to our workshop on preference learning.",
                    "label": 1
                },
                {
                    "sent": "This workshop has been prepared by myself.",
                    "label": 1
                },
                {
                    "sent": "I am I cool Amaya from Marburg University in Germany, and you're his friend counts from Domscheit University in also in Germany.",
                    "label": 0
                },
                {
                    "sent": "This workshop constitutes the first part of our.",
                    "label": 0
                },
                {
                    "sent": "This tutorial constitutes the first part of our workshop on preference learning, and it will be followed by a number of talks.",
                    "label": 0
                },
                {
                    "sent": "That will be given in the afternoon.",
                    "label": 0
                },
                {
                    "sent": "Actually we were planning to.",
                    "label": 0
                },
                {
                    "sent": "Have a somewhat more comprehensive and longer tutorial, but eventually it turned out that we received quite a couple of good submissions to our workshop and then we decided to have more presentations and therefore to shorten the tutorial a little bit.",
                    "label": 0
                },
                {
                    "sent": "So after all, we will have a 90 minutes tutorial, which clearly means that we can only give the more or less a superficial introduction to the field, so you should understand it more to an introduction.",
                    "label": 0
                },
                {
                    "sent": "Preference learning, then tutorial that really goes into technical details.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first let me give a very brief introduction to what we are actually talking about.",
                    "label": 0
                },
                {
                    "sent": "So what is preference learning?",
                    "label": 1
                },
                {
                    "sent": "Roughly speaking, our view of preference learning is as an emerging subfield of machine learning that deals with the learning of preference models from observed preference information, or from information that has been extracted specifically for that purpose.",
                    "label": 1
                },
                {
                    "sent": "For example, from sources like the Internet, typically like in machine learning in general, these models are used for predictive purposes, that is to predict the preferences of.",
                    "label": 0
                },
                {
                    "sent": "Knew individuals that you have not seen before or references in you situations in which you have not been before, and so on.",
                    "label": 0
                },
                {
                    "sent": "So you see that preference learning is connecting two things, namely learning on the one side and preferences on the other side, and therefore it is a kind of interdisciplinary research field that connects machine learning with other areas in which preferences have played a key role for a couple of years.",
                    "label": 0
                },
                {
                    "sent": "Like for example, operations research, the social science and economy, and so on.",
                    "label": 0
                },
                {
                    "sent": "So these are all fields in which preferences have been studied for quite a.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Long time.",
                    "label": 0
                },
                {
                    "sent": "The growing interest in this field is also witnessed by a number of dedicated events and workshops that have been organized on this topic.",
                    "label": 0
                },
                {
                    "sent": "Here we have a small list which is not exhaustive, but nevertheless shows that really a number of people have started to to work in this field.",
                    "label": 0
                },
                {
                    "sent": "This list also, of course, includes our.",
                    "label": 0
                },
                {
                    "sent": "Say one can maybe even say workshop serious.",
                    "label": 0
                },
                {
                    "sent": "It's already the third time that we organize this workshop on the occasion of the of the CML conference.",
                    "label": 1
                },
                {
                    "sent": "And what is perhaps also notable?",
                    "label": 1
                },
                {
                    "sent": "I would like to point out is that also now mathematicians have become interested in this topic of preferences, and in particular in ranking.",
                    "label": 0
                },
                {
                    "sent": "So this year, for instance, there is the first international workshop on the mathematics of ranking.",
                    "label": 1
                },
                {
                    "sent": "So this is really something that attracts attention also outside our.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Community.",
                    "label": 0
                },
                {
                    "sent": "More generally, we can see currently that preferences play a key role also in AI in general, so not only in machine learning, but in AI in general.",
                    "label": 1
                },
                {
                    "sent": "And this of course has a number of reasons in particular.",
                    "label": 0
                },
                {
                    "sent": "One reason is that preferences have a number of applications of important applications, so they are used in recommender systems.",
                    "label": 1
                },
                {
                    "sent": "In adaptive systems in information retrieval, autonomous agents games, and so on, these are all fields in which preferences really play a very important role.",
                    "label": 0
                },
                {
                    "sent": "Of course, AI is not only focusing on the learning or the acquisition of Preferences, but in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "These people are also studying.",
                    "label": 1
                },
                {
                    "sent": "Aspects related to preference, representation and reasoning with preferences.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so seen from the point of AI.",
                    "label": 0
                },
                {
                    "sent": "Preference learning is again only a subfield within these broader field of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Answers.",
                    "label": 0
                },
                {
                    "sent": "So here you see the agenda of our introductory tutorial today.",
                    "label": 0
                },
                {
                    "sent": "I will start right now with a brief overview of what kind of problems have been studied till now in the field of preference learning then Johannes will take over and speak about loss functions.",
                    "label": 0
                },
                {
                    "sent": "As you will see this these types of preference learning call for the development of novel loss functions and Johannes will explain you more about this then in the third part I will speak.",
                    "label": 1
                },
                {
                    "sent": "A little bit about what kind of learning methods, what kind of learning techniques have been proposed so far to tackle these preference learning problems.",
                    "label": 0
                },
                {
                    "sent": "And finally Johannes will speak a little bit about complexity issues.",
                    "label": 0
                },
                {
                    "sent": "Sometimes these techniques are quite complex from a computational point of view, and that's why it is also worth discussing this issue.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me start right away.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first with the first part of this tutorial, which is about preference learning problems.",
                    "label": 0
                },
                {
                    "sent": "So preference learning problems are quite diverse and they can be distinguished along a number of different dimensions, including, for example, the representation of the preferences or the type of preference model.",
                    "label": 1
                },
                {
                    "sent": "So how are preferences actually represented?",
                    "label": 0
                },
                {
                    "sent": "Other represented in terms of utility functions which can be ordinal or Cardinal or in a relational form using preference relations?",
                    "label": 0
                },
                {
                    "sent": "Or maybe a type of logical description representation?",
                    "label": 0
                },
                {
                    "sent": "You will hear more about these terms in the following then the second question is how are the individuals?",
                    "label": 0
                },
                {
                    "sent": "About which we want to reason, I represent it, or the alternatives or items whose preferences we want to describe.",
                    "label": 0
                },
                {
                    "sent": "Is it only in terms of an identifier, or maybe in terms of the feature vector or even more complex in terms of a type of structured representation?",
                    "label": 1
                },
                {
                    "sent": "And then there is the type of training input?",
                    "label": 0
                },
                {
                    "sent": "Is it direct or indirect?",
                    "label": 0
                },
                {
                    "sent": "We have complete or only incomplete preference relations?",
                    "label": 0
                },
                {
                    "sent": "Is it in the form of utility's and so on?",
                    "label": 0
                },
                {
                    "sent": "So you will see in the following that there is a great variant.",
                    "label": 0
                },
                {
                    "sent": "Parietti and in modeling these type of.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Friends learning problems.",
                    "label": 0
                },
                {
                    "sent": "Very generally, one can distinguish 2.",
                    "label": 0
                },
                {
                    "sent": "Ways of representing preferences that have been studied quite intensively in the literature.",
                    "label": 0
                },
                {
                    "sent": "For example, on choice and decision theory, and this is in terms of what we call here absolute and relative preferences.",
                    "label": 0
                },
                {
                    "sent": "The one possibility to describe preferences is to evaluate to assess single alternatives.",
                    "label": 0
                },
                {
                    "sent": "So I give you a single alternative and I say to what extent are like or dislike this alternative, and the second very natural way to express preferences in terms of.",
                    "label": 0
                },
                {
                    "sent": "Comparing competing alternatives.",
                    "label": 0
                },
                {
                    "sent": "So I give you 2 alternatives for example and you say me which one you prefer and maybe to what extent.",
                    "label": 0
                },
                {
                    "sent": "So this is the difference between assessing and comparing.",
                    "label": 0
                },
                {
                    "sent": "And again, within these two categories, of course, you can make a finer distinction.",
                    "label": 0
                },
                {
                    "sent": "For example, you can express absolute preferences in a binary way, saying only, for example, I like an alternative, or I dislike it.",
                    "label": 0
                },
                {
                    "sent": "For instance, I like A&B.",
                    "label": 0
                },
                {
                    "sent": "They get preference degrees one or utility quiz one, and I dislike CMP.",
                    "label": 0
                },
                {
                    "sent": "Or you can do it in a gradual way, for instance expressing preferences on a numerical scale.",
                    "label": 0
                },
                {
                    "sent": "Using utility degrees between zero and one, or perhaps on an ordinal scale in which you just have a finite number of graded, ordered utility degrees which are not numerical, then on the right hand side here you can use different types of order relations in order to describe preferences in a relative way.",
                    "label": 0
                },
                {
                    "sent": "For example, total orders or partial order relations in which you are also allowed to say.",
                    "label": 0
                },
                {
                    "sent": "Certain objects simply cannot be compared, right?",
                    "label": 0
                },
                {
                    "sent": "I cannot compare them.",
                    "label": 0
                },
                {
                    "sent": "We will see examples of this type later on.",
                    "label": 0
                },
                {
                    "sent": "Roughly, we can.",
                    "label": 0
                },
                {
                    "sent": "Say that from a machine learning POV, this left hand side here leads to a kind of regression problem.",
                    "label": 0
                },
                {
                    "sent": "Maybe in ordinal regression problem, because here the problem is to predict utility decrease.",
                    "label": 0
                },
                {
                    "sent": "This is something very close to regression learning on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "Here we will see that.",
                    "label": 0
                },
                {
                    "sent": "That tasks in which preferences are represented in a relative way more lead to classification and ranking problems.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because here you have to compare things which is a type of classification.",
                    "label": 0
                },
                {
                    "sent": "If I compare two things, I have two alternatives and I can express.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This in form of A's vacation problem.",
                    "label": 0
                },
                {
                    "sent": "The rest of my overview will follow the following distinction between 2, say types of different preference preference learning tasks.",
                    "label": 1
                },
                {
                    "sent": "The one is a type of problem which is very close to conventional supervised learning, and here the problem is to learn a kind of function that Maps from an instance SpaceX to a space of, say, preference models here denoted by P and this function Maps.",
                    "label": 1
                },
                {
                    "sent": "Instances too, yeah, preference models and this type of problem is very close to structured or complex output prediction becausw these preference models here on the right hand side are typically quite complex.",
                    "label": 0
                },
                {
                    "sent": "Definitely what we're doing here is going beyond simple prediction of scalar outputs like in classification and regression.",
                    "label": 0
                },
                {
                    "sent": "So this is the one type where you have like, typically in supervised machine learning the distinction between an input speed space and an output space.",
                    "label": 0
                },
                {
                    "sent": "Then in the second part I will speak about problems for which you do not have this distinction between input and output space.",
                    "label": 0
                },
                {
                    "sent": "At least not so clearly, and this will include problems like object ranking, instance ranking, collaborative filtering and so on.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me first say a bit more about this first type of problem.",
                    "label": 0
                },
                {
                    "sent": "So here instances are typically, but not necessarily characterized in terms of a feature vector, but this is the more uninteresting part.",
                    "label": 1
                },
                {
                    "sent": "What is more interesting is the right hand side here, namely the way in which outputs are represented.",
                    "label": 0
                },
                {
                    "sent": "And here normally the output space consists of preference models over a fixed set of alternatives.",
                    "label": 1
                },
                {
                    "sent": "So we fixed the set of alternatives about.",
                    "label": 0
                },
                {
                    "sent": "We make preference statements, we call these aternatives, typically classes or labels.",
                    "label": 1
                },
                {
                    "sent": "Just leaning on the standard notation that is also used in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Supervised machine learning, and these are represented in terms of an identifier, so we are speaking here mainly of extensions of multiclass classification.",
                    "label": 0
                },
                {
                    "sent": "As you will see.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a minute.",
                    "label": 0
                },
                {
                    "sent": "The first type of problem that I have here is multi label classification.",
                    "label": 0
                },
                {
                    "sent": "Actually Multi Label classification is not say preference learning task in the narrow sense, but we can subsume it here under the notion of preference learning.",
                    "label": 0
                },
                {
                    "sent": "If we interpret the labels just as preference statements.",
                    "label": 0
                },
                {
                    "sent": "So the situation here is that you have as trading information instances on the left hand side, whatever that means.",
                    "label": 0
                },
                {
                    "sent": "It's just feature vectors.",
                    "label": 0
                },
                {
                    "sent": "For example, a person described by number of features.",
                    "label": 0
                },
                {
                    "sent": "And then you have a set of labels which correspond to our alternatives and we just say for every instance whether this instance likes the alternative or not.",
                    "label": 0
                },
                {
                    "sent": "Likes here is encoded as one, and dislike is encoded as zero.",
                    "label": 0
                },
                {
                    "sent": "So this is the information we get for training.",
                    "label": 0
                },
                {
                    "sent": "Then for prediction we get a new instance and we have to make a prediction of his or her preferences again.",
                    "label": 0
                },
                {
                    "sent": "In terms of such a 01 vector.",
                    "label": 0
                },
                {
                    "sent": "The ground truth, we assume in this setting is also this 01 vector of like this like values and what we need here in order to say how good our prediction actually is is a loss function that compares these types of 01 vectors or the subsets two subsets of liked our preferred items?",
                    "label": 0
                },
                {
                    "sent": "And this is something that Johannes will talk about in more.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detail later on.",
                    "label": 0
                },
                {
                    "sent": "Then the second type of problem is a slight.",
                    "label": 0
                },
                {
                    "sent": "Only a slight modification of the previous one in which the only difference is that the prediction is now given in terms of a ranking of all items that can also be expressed as a permutation.",
                    "label": 1
                },
                {
                    "sent": "Here for example, the alternative A is put on rank 4.",
                    "label": 0
                },
                {
                    "sent": "The alternative B on rank one and so on.",
                    "label": 0
                },
                {
                    "sent": "You see this permutation encodes this ranking.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "Still, we assume that the ground truth is a subset of liked or preferred items, and then what we have to do is to come up with the last function that compares ranking in which we.",
                    "label": 0
                },
                {
                    "sent": "We intend to predict to put the preferred at the preferred alternatives.",
                    "label": 0
                },
                {
                    "sent": "Ahead of the disliked alternatives and what we have to do is to compare this type of ranking with the subset.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of preferred items.",
                    "label": 0
                },
                {
                    "sent": "Then recently there has been proposed greater extension of this multi label setting in which we go beyond the simple distinction between preferred and non preferred and can express preferences on an ordinal degree like a -- 0 plus and plus plus.",
                    "label": 0
                },
                {
                    "sent": "In this example.",
                    "label": 0
                },
                {
                    "sent": "Here the prediction again is of the same form and also the ground truth.",
                    "label": 0
                },
                {
                    "sent": "So what we have to do here is to compare two subsets too.",
                    "label": 0
                },
                {
                    "sent": "One can say fuzzy subsets of preferred items.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also put this into the ranking context in which the prediction is given in form of a ranking again and then what we need is a loss function that compares such a ranking with a fuzzy subset of preferred item.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The second type of so these were all variants say of this multi label classification setting.",
                    "label": 0
                },
                {
                    "sent": "The second type of problem is label ranking and label ranking.",
                    "label": 1
                },
                {
                    "sent": "We are given preference information of the of the relative type.",
                    "label": 0
                },
                {
                    "sent": "So here we assume that with every instance we associate a subset of pairwise preferences between the items given as training information.",
                    "label": 1
                },
                {
                    "sent": "So for example for the first instance here we know that.",
                    "label": 0
                },
                {
                    "sent": "A is preferred to be.",
                    "label": 0
                },
                {
                    "sent": "Bees prefer to see and seize.",
                    "label": 0
                },
                {
                    "sent": "Prefer to D for the second instance.",
                    "label": 0
                },
                {
                    "sent": "We only know that bees prefer to see and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is our training information.",
                    "label": 0
                },
                {
                    "sent": "So on the basis of this training information, we tried to train a model that is able to predict for a new query instance a total order, a ranking in the form of a total order of alternatives.",
                    "label": 0
                },
                {
                    "sent": "So here for example, B better than D, better than C, better than A and we assume also that the ground truth is of the same type.",
                    "label": 0
                },
                {
                    "sent": "So the ground truth is also a ranking.",
                    "label": 1
                },
                {
                    "sent": "And what we have to do then is to compare.",
                    "label": 0
                },
                {
                    "sent": "Predicted ranking with the true.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we have seen here are two examples.",
                    "label": 0
                },
                {
                    "sent": "In which the preferences are modeled either in the absolute way or in the relative way, and just as a side remark, I would like to mention that.",
                    "label": 0
                },
                {
                    "sent": "That a combination of these two ways of representing preferences has been proposed, namely what we call something that we call a calibrated label, ranking a calibrated ranking is just a ranking of the normal type in which we introduce Additionally a kind of, say zero point that distinguishes between a positive side and the negative side.",
                    "label": 0
                },
                {
                    "sent": "So the information this type of prediction captures.",
                    "label": 0
                },
                {
                    "sent": "Is a total order of alternatives plus a distinction between what is liked and what is not liked or what is relevant or what is irrelevant depending on the context in which we use this type of prediction.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now let me say a few words about the second type of problems in which we do not have this clear distinction between input space and output space, as we typically have in supervised machine learning.",
                    "label": 0
                },
                {
                    "sent": "So I will mention as examples here the problems of so-called object and instance ranking, in which we actually do not have a kind of output space.",
                    "label": 1
                },
                {
                    "sent": "And the problem of collaborative collaborative filtering in which we do not have a clear input space.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Clearly defined input space.",
                    "label": 0
                },
                {
                    "sent": "So the problem of object ranking has already been proposed number of years ago and in this setting we are given as training information.",
                    "label": 0
                },
                {
                    "sent": "Pairwise comparisons between objects.",
                    "label": 0
                },
                {
                    "sent": "Here again it might be persons or whatever, but it can also be more complex objects like websites or so on presented in a more complex way.",
                    "label": 0
                },
                {
                    "sent": "So we are given these pairwise preferences be between.",
                    "label": 1
                },
                {
                    "sent": "Objects or instances as training information and the goal is to train a function are ranking function that is able to rank every new subset of of items that we maybe have not seen before.",
                    "label": 0
                },
                {
                    "sent": "So if I give a query such as subset of items X 12X13, MY function is supposed to rank them to put them in a total order like this one here.",
                    "label": 0
                },
                {
                    "sent": "Sometimes, depending on the context, we are not interested in the full ranking but only for example in in the top ranks in the first K top ranks or we are maybe interested in a distinction between positive and negative or relevant or irrelevant items.",
                    "label": 0
                },
                {
                    "sent": "So this ranking is typically compared with the ground truth truth that is also ranking a total order of.",
                    "label": 1
                },
                {
                    "sent": "All the alternatives or only a top K ranking?",
                    "label": 0
                },
                {
                    "sent": "Or maybe a subset of positive and negative items?",
                    "label": 0
                },
                {
                    "sent": "Like an information retrieval, how you typically have relevant, you distinguish between relevant and non relevant documents.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In instance ranking the situation is almost the same except for the type of training information that we are given, because here we are given training information of the absolute types, so not relative comparisons between pairs of objects, but objects rated on an absolute scale.",
                    "label": 0
                },
                {
                    "sent": "Typically it's an ordinal scale like here.",
                    "label": 0
                },
                {
                    "sent": "So for example, the first item has a minus rating, the second item has a 0 rating and so on.",
                    "label": 0
                },
                {
                    "sent": "Yeah, ratings on an ordinal scale.",
                    "label": 0
                },
                {
                    "sent": "And again we want to train a ranking function that is able to rank every new subset of items like in the example before and as a ground truth.",
                    "label": 0
                },
                {
                    "sent": "We suppose that we are again given these ordinary ratings of the objects and of course the intention is to rank the items having a positive rating before the items having a negative rating.",
                    "label": 0
                },
                {
                    "sent": "And if this is not the case, then you have made a ranking error.",
                    "label": 0
                },
                {
                    "sent": "So for example, here we put minus item an item with a rating minus before an item with the ranking plus and this is of course a ranking mistake ranking error.",
                    "label": 0
                },
                {
                    "sent": "Actually, this looks like an ordinal classification or an ordinal regression problem, but if you look closer at what we are using here as a prediction and as a ground truth, you see that we actually do not want to maximize classification accuracy.",
                    "label": 0
                },
                {
                    "sent": "But what we actually want to maximize.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ranking accuracy, so here we have a distinction between classification and.",
                    "label": 0
                },
                {
                    "sent": "And ranking you can also see this as an extension of AUC maximization, which we only have two classes, positive and negative.",
                    "label": 1
                },
                {
                    "sent": "Here we have the multiclass case in which the ordinal ratings can also assume values, something in between the worst and the best.",
                    "label": 0
                },
                {
                    "sent": "And as I said, what we're trying to do here is ranked from the most likely good instances to the most likely bad instances.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, the.",
                    "label": 0
                },
                {
                    "sent": "The last problem here I want to discuss very briefly is collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "As one of the methods that have been studied quite intensively in the recommender systems community.",
                    "label": 0
                },
                {
                    "sent": "Here we do not have a kind of clearly defined input space becausw both the users and the items.",
                    "label": 0
                },
                {
                    "sent": "The products are only described in terms of an identifier.",
                    "label": 0
                },
                {
                    "sent": "The preferences are of the absolute type, so we are given absolute ratings of products given by the users and.",
                    "label": 0
                },
                {
                    "sent": "Typically this is again done in terms of ordinal degrees.",
                    "label": 1
                },
                {
                    "sent": "So we have ordinal utility degrees, for example here, ranging from very bad to excellent.",
                    "label": 1
                },
                {
                    "sent": "And the typical setting in collaborative filtering looks like this.",
                    "label": 0
                },
                {
                    "sent": "You have given such a table which is partly filled with ratings.",
                    "label": 0
                },
                {
                    "sent": "Typically this table is very sparse because most of the fields are empty here.",
                    "label": 0
                },
                {
                    "sent": "For example, this second user has rated the third product as as bad, and so on.",
                    "label": 0
                },
                {
                    "sent": "And what you what you essentially try to do is fill the table, or at least fill one row of the table, which corresponds to predicting.",
                    "label": 0
                },
                {
                    "sent": "The preference is the absolute preferences of 1 specific user for all the products here, and this is done by exploiting correlations between these ratings given as training information.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here you see an overview I am not going to discuss this in detail.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can have a closer look at this.",
                    "label": 0
                },
                {
                    "sent": "At home you can download the slides from the Internet in which I have summarized the problems.",
                    "label": 0
                },
                {
                    "sent": "I have briefly touched on here in the first part of this tutorial and distinguish between the type of representation that is used for the inputs and the outputs and the type of reference information that is given as training.",
                    "label": 0
                },
                {
                    "sent": "Information for prediction and as a ground truth, distinguishing distinguishing between absolute and relative preferences or dinner, numerical, binary, and so on.",
                    "label": 0
                },
                {
                    "sent": "But what you can also grasp here from this table is that we roughly have two main directions in preference learning.",
                    "label": 1
                },
                {
                    "sent": "The one is to generalize the multiclass classification problem.",
                    "label": 0
                },
                {
                    "sent": "So this year, or tasks that.",
                    "label": 0
                },
                {
                    "sent": "Can be seen as generalizations on of conventional multiclass classification and the second direction is to study different types of ranking problems.",
                    "label": 0
                },
                {
                    "sent": "So ranking at variance these are.",
                    "label": 0
                },
                {
                    "sent": "The problems here of label ranking, object ranking and instance ranking essentially.",
                    "label": 1
                },
                {
                    "sent": "So this is the second main direction.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Within preference learning.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I just mentioned.",
                    "label": 0
                },
                {
                    "sent": "I would just like to mention that of course one can also go beyond predicting simple rankings in the form of total orders and.",
                    "label": 0
                },
                {
                    "sent": "Essentially, rankings can be generalized in two different ways.",
                    "label": 1
                },
                {
                    "sent": "First, we can say that we do not want to.",
                    "label": 0
                },
                {
                    "sent": "We do not insist on having a strict order in the sense that we assume that all alternatives are compareable.",
                    "label": 0
                },
                {
                    "sent": "So we can generalize.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "Allowing to express in comparability between two items, or also for allowing to express the in difference between 2 two items.",
                    "label": 0
                },
                {
                    "sent": "For example, if I would like to to predict the preferences of a person with regard to these four cities here, for example for making Holidays or for organizing a conference or whatever, I, for example, would like to allow to say that Barcelona is maximally preferred.",
                    "label": 0
                },
                {
                    "sent": "Rome is least preferred, but between Paris and London in between, I cannot distinguish, so I cannot compare them.",
                    "label": 0
                },
                {
                    "sent": "This is not a ranking.",
                    "label": 1
                },
                {
                    "sent": "This is not a total order, but only a partial order.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "This idea of.",
                    "label": 1
                },
                {
                    "sent": "Of representing preferences in terms of partial orders has been studied, especially in the context of what is called conditional preference networks.",
                    "label": 0
                },
                {
                    "sent": "I will say a little bit about this later on.",
                    "label": 0
                },
                {
                    "sent": "Yes, of course.",
                    "label": 0
                },
                {
                    "sent": "Those were just getting bored with lunch later.",
                    "label": 0
                },
                {
                    "sent": "Because then.",
                    "label": 0
                },
                {
                    "sent": "Objects with Jessica Stlouise later movie.",
                    "label": 0
                },
                {
                    "sent": "None of this would be.",
                    "label": 0
                },
                {
                    "sent": "No, it's not equivalent for several reasons.",
                    "label": 0
                },
                {
                    "sent": "First, we would not express in comparability, but indifference objects put in the same class, assigned the same class label would be indistinguishable.",
                    "label": 0
                },
                {
                    "sent": "So it would correspond to expressing indifference and the the second what you essentially get then, is what people often call a bucket order.",
                    "label": 0
                },
                {
                    "sent": "Some elements are put in the same bucket, but there is yet another distinction.",
                    "label": 0
                },
                {
                    "sent": "If you assign these absolute degrees, then you have essentially more information, because if you have only a bucket order then you do not know necessarily the absolute ratings.",
                    "label": 0
                },
                {
                    "sent": "If you know the absolute ratings, you have a bucket order.",
                    "label": 0
                },
                {
                    "sent": "That's so you can go from the absolute ratings to the order, but not the other way around.",
                    "label": 0
                },
                {
                    "sent": "So you have essentially more information, yeah?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "A prediction in terms of a partial order can be interpreted in two different ways, depending on what we assume as a ground truth.",
                    "label": 1
                },
                {
                    "sent": "If we assume that the ground truth is a total order, it corresponds to the interpretation of, say, partial abstention or uncertainty.",
                    "label": 0
                },
                {
                    "sent": "That way, I was talking about yesterday in his talk and say OK, actually, Paris and London can be ranked, but simply I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't know how to rank them or the second interpretation is that.",
                    "label": 0
                },
                {
                    "sent": "The ground truth is really a partial order for what reason ever London and Paris cannot be compared, so these are two different interpretations that have to be distinguished.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In that context here.",
                    "label": 0
                },
                {
                    "sent": "So now eventually I make the.",
                    "label": 0
                },
                {
                    "sent": "The transfer to Johannes.",
                    "label": 0
                },
                {
                    "sent": "This is my last slide.",
                    "label": 0
                },
                {
                    "sent": "And we have seen on the previous slides that within the context of these different types of of preference learning problems, we have to compare different types of predictions and with the ground truth if we want to, we want to evaluate a classifier predictor.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We have seen that sometimes it's just the comparison of utility degrees, so of scalar outputs and predictions.",
                    "label": 0
                },
                {
                    "sent": "This is easy this we already know how to do, but in the more complex for the more complex problems we have to compare more, say complex things given as a prediction on the one side and as a ground truth on the other side.",
                    "label": 0
                },
                {
                    "sent": "And this is an interesting question by itself.",
                    "label": 0
                },
                {
                    "sent": "How to do it?",
                    "label": 0
                },
                {
                    "sent": "How to how to how to make these comparison.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is something that Johannes will now speak about in the second part of our tutorial.",
                    "label": 0
                }
            ]
        }
    }
}