{
    "id": "45m46hsio4zezpxm6jooyckjqnog65gf",
    "title": "Multiple View Object Cosegmentation using Appearance and Stereo Cues",
    "info": {
        "author": [
            "Adarsh Kowdle, Cornell University"
        ],
        "chairman": [
            "Aude Oliva, Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, MIT",
            "Silvio Savarese, Department of Electrical Engineering and Computer Science, University of Michigan"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition"
        ]
    },
    "url": "http://videolectures.net/eccv2012_kowdle_stereo/",
    "segmentation": [
        [
            "My name is Arthur Scott Lee in this joint work with that person and Rick Szeliski"
        ],
        [
            "So the task we're looking at here is we're given a set of images of an object capture from multiple viewpoints, and our goal is to automatically infer what the object of interest is and to perform and to obtain a per pixel and accurate foreground segment."
        ],
        [
            "Nation from each view and there is some of the results which will get so."
        ],
        [
            "Uh, the task of obtaining accurate foreground segmentation is something which has been looked at in the past, and there have been a lot of interactive techniques were given.",
            "The user input.",
            "You build a global color Model 1, which describes the foreground 11 which describes the background, and you propagate that across images.",
            "Now there have been some works which tried to do this more recently with as an unsupervised algorithm where they used a similar appearance models, but they tried to use the intuition that the foreground model tends to appear similar while the background changes more drastically.",
            "However, this is a constraint which is not easily satisfied for multiview images.",
            "So."
        ],
        [
            "In Multiview data, the other thing you can do is obtain geometric globally consistent 3D model of this object of interest and then project this into each view and thus obtaining the segmentation.",
            "However, we know that obtaining an accurate 3D model of objects is a hard task.",
            "So what we do in this work is bypass this particular stage and we instead go to an approximate representation of a scene visa piece, piecewise planar stereo framework, whereas prior work have shown we can obtain a low level segmentation where pixels are grouped, planar surface is or.",
            "However, prior work has not reasoned about the foreground object, and that's something we do in this work, so our contribution is an unsupervised."
        ],
        [
            "Echo segmentation algorithm which exploits stereo and an appearance cues, and will show that we extend prior work on piecewise planar stereo such that it's robust scenarios where stereo matching is unreliable and by doing so we show that we can get better."
        ],
        [
            "So this is.",
            "So here's an overview of our algorithm.",
            "We use a multi stage framework where you start off with your input images.",
            "We first obtain a perform piecewise planar stereo to obtain a."
        ],
        [
            "Inner labeling of the scene and and piecewise planar depth depth map.",
            "And then we perform a reason level foreground background labeling which is which gives us a code segmentation of the foreground for each image.",
            "And once we have this for each image, we finally perform a multiview pixel level foreground background labeling.",
            "So let's start."
        ],
        [
            "For the piecewise planar studio.",
            "Given the set of input images, we first run a structure from motion to calibrate the cameras and."
        ],
        [
            "Once we have that done, for every view, we use two neighboring used to perform dense stereo.",
            "We do this using Semi global stereo matching and in addition to an estimate of the depth we also get an estimate of the confidence of the algorithm with this step estimate."
        ],
        [
            "Now that we have this, we now hypothesize planes by using a seed and grow approach and by doing so we obtain our initial labeling of pixels to plane plane hypothesis.",
            "Now our goal given these plane hypothesis."
        ],
        [
            "Is to obtain a planar labeling where per pixel planar learning and then we can use this planar labeling tomorrow to obtain our piecewise planar depth map."
        ],
        [
            "It's worth noting that when you when you're looking at hard or complicated objects which have occlusions and pin structures such as the bicycle here are initial stereo matching."
        ],
        [
            "Can be erroneous, so as you can see in the yellow ellipse, the estimates of the depth are wrong here.",
            "And this is something we should propagate through.",
            "When you use a peaceful explains the big separate planar framework which uses only stereo cues.",
            "So what we do in our in this approach is is trying to incorporate appearance and stereo cues to try and recover the finer details of the object, and will see that this is something which will help us do better with the task of."
        ],
        [
            "Segmentation.",
            "So a framework for piecewise planar Studio is similar to prior work, so you have a pixel level MRF formulated over your whole image, and you need to assign a discrete planar label for each pixel.",
            "Now each plane is parameterized by a 3D plane equation and an appearance model which describes that particular region.",
            "And now we have an energy function."
        ],
        [
            "Find over all the pixels.",
            "So let's take a look at the terms."
        ],
        [
            "This started with the geometric unity term.",
            "Now this is a per pixel score, which tells you how compatible a plane is to particular pixel.",
            "So given our initial estimate of the of the depth of a pixel from our stereo matching, we're trying to measure how compatible is it.",
            "When I say that this Pixel has to line up, particularly in pie.",
            "We modulate this."
        ],
        [
            "Item using a per pixel confidence value and this is where we use our confidence map.",
            "We initially obtain now as you can see in this example, while while while there was errors in the estimated depth map, we see that that's actually seen in the algorithms.",
            "Confidence in this depth map and so that helps us modulate this geometric term."
        ],
        [
            "The other unity term is an appearance unary term.",
            "Now, given our planar labeling, we can actually use for every reason.",
            "We can actually obtain upper reason compact appearance model which describes our particular region, and in contrast to a global color, models these parties in color models will help us better distinguish the contours of the object."
        ],
        [
            "Are pairwise term is is the popular contrast sensitive parts model?"
        ],
        [
            "And once we have this, we perform inference using iterative graph cut with every iteration we relearn the the appearance model for each of these regions and then obtain an updated labeling and typically in 2 three iterations we obtain our planar labeling and are piecewise planar."
        ],
        [
            "Map.",
            "With this in place, now let's look at how we obtain a reasonable."
        ],
        [
            "Diagram labeling our goal.",
            "Our task here is given our initial reason labeling treat each region as a node."
        ],
        [
            "A graph that is giving us an irregular small graph and given this obtain reason level labeling where each region is either a foreground or background."
        ],
        [
            "Reason.",
            "We do so by formulating two energy function, one which describes one which which helps model the appearance and another which helps model the geometry.",
            "The unity term for both of these energy functions is what we call the objectness term.",
            "This encodes how likely a region belongs to the foreground object, and to do this we go back and look at our recent labeling and piecewise planar death map and using the depth map we can now project each of these regions into each of our camera viewpoints.",
            "And so now we can see that the red region lies in the field of view of a lot more cameras and the blue region, thus giving it a higher objectness score than the blue region."
        ],
        [
            "The first of our pairwise terms is an appearance based compatibility term.",
            "Now this tries to encode how similar to neighboring."
        ],
        [
            "So when you look at two regions on the couch here, they are fairly similar in appearance, so this has a high compatibility score.",
            "However, when you."
        ],
        [
            "The two regions, such as the couch and the ground surface.",
            "This is not as compatible, and so this will have a lower score that's trying to allow for a label change at this point."
        ],
        [
            "The second energy function has the pairwise term, which which is modeled by the depth based compatibility score.",
            "So here we want to try and encourage a label change when you have a depth discontinuity."
        ],
        [
            "So when you're considering two regions on the couch again, these are fairly compatible with depth, so they have a high score."
        ],
        [
            "Over 2 regions which straddle the depth discontinuity should have would end up having a lower lower compatibility score that's trying to allow for a depth for a label change."
        ],
        [
            "At this point.",
            "So with this in place, we can we now perform inference on both these energy functions and we do it independently to obtain our map labels.",
            "And finally we label a region as foreground.",
            "If either of these two energy functions labels the region's program."
        ],
        [
            "When you look at the results at this at this stage, we see that for a simple object such as the couch, we already have pretty good segmentation of the couch in place."
        ],
        [
            "However, when you look at more complicated objects such as this carriage sequence, here we see that some portion of the carriage might be missing in one of the viewpoints, but that might be captured in another viewpoint, so this brings."
        ],
        [
            "To our final stage of multiview foreground background labeling.",
            "So this is where we want to pull all the information from the reason level labeling."
        ],
        [
            "So now we construct a pixel level MRF over all the pixels of an image, and now we want to give each pixel the foreground or background label."
        ],
        [
            "We have an energy function defined over this pixel MRF and now we have an object Ness term, again as one of our unity terms.",
            "Now similar to the region level Objectness term.",
            "This is again trying to measure how likely your pixel belongs to the foreground object.",
            "And similar to earlier, now we can look at every pixel and using the depth of piecewise planar bitmap project these pixels into each camera.",
            "But now we have this additional information from our previous stage we now."
        ],
        [
            "A sense of where the foreground is.",
            "So we use this to say that the red pixel is more, is more likely to be object than the blue pixel."
        ],
        [
            "The second term here is the appearance unity term.",
            "Now that we have a course reason level labeling, we can use the foreground and background to open up to obtain our foreground and background appearance models and this will help modulate this term."
        ],
        [
            "The pairwise sum again is a contrast sensitive Potts model."
        ],
        [
            "So once we have this, we perform graph cuts to obtain our labeling, and as you can see here, what started off as as errors in our region level labeling are fixed as shown in the sign ellipse in our multi view labeling."
        ],
        [
            "So this is our complete algorithm to obtain Multiview Object Co segmentation.",
            "Let's take a look at this."
        ],
        [
            "This.",
            "Of we collected 7 datasets with as few as six images captured from different viewpoints to as many as 60 images.",
            "Looking at the object, the SFM reconstructions of these sequences are shown below the thumbnail."
        ],
        [
            "For ground truth we manually labeled the ground truth using graph cut.",
            "So for for image such as this."
        ],
        [
            "Obtaining a good segmentation as seen here involved about four minutes of effort to obtain the segmentation again using a purely appearance based."
        ],
        [
            "George.",
            "So evaluation metric."
        ],
        [
            "Given our segmentation is the standard intersection over union metric, however, to actually get a better sense of the accuracy, we evaluated this metric only over X pixel ban."
        ],
        [
            "Around the boundary.",
            "Now with this is."
        ],
        [
            "The metric we now can go to the comparisons with prior work.",
            "So for two of the images shown here, if you use a purely appearance based approach, while it can get the, you can actually do a good job at recognizing the foreground object.",
            "Getting a pixel level pixel accurate.",
            "Segmentation is a hard problem here.",
            "The second or third comparison we did was try to use pass based multiview stereo to obtain a reconstruction of the whole scene, then manually crop out the 3D model corresponding to the object of interest and projected into each view.",
            "Now that gives us slightly better results qualitatively.",
            "In comparison."
        ],
        [
            "We see that we perform much better, both quantitatively and qualitatively and closely matches were the ground truth we have.",
            "So in more comparison, we saw that our approach outperforms the prior work both in the metric of a 10 pixel wide band around the boundary, and the more traditional full image segmentation accuracy."
        ],
        [
            "Qualitatively, we see that we do a pretty good job at recovering quality, depth map San.",
            "Good segmentations in particular, piecewise planar proxies, was able to model even non planar objects such as the chair here."
        ],
        [
            "And we were able to handle irregularities in the scene such as specular surface is on the car and overlapping foreground background appearance models such as the bike and the road below."
        ],
        [
            "Lastly, we saw that we were able to obtain quality depth Maps, an good segmentation even in case of thin structures and complex occlusions, as we see here.",
            "The more results qualitative and quantitative in the paper, and I'll refer you to that for more."
        ],
        [
            "So in conclusion, what we have proposed is an unsupervised Co segmentation algorithm where we've used a multi staged approach to put together appearance and stereo cues to infer the object of interest to recover pixel accurate foreground segmentation in each view and to recover good quality depth Maps.",
            "With that I thank you and."
        ],
        [
            "Remote assist validate questions."
        ],
        [
            "Very interesting work.",
            "So my question is, from my understanding for regional level program background segmentation you solve graph cuts for geometry, another grass cut for appearance independently for the reason yes for multiple you mix both.",
            "So why didn't you mix both with?",
            "So we thought about that.",
            "So we saw that the two things, the appearance and the geometry is trying to tease apart.",
            "It's a little different.",
            "You can think of trying to put them together and then tune para meters, but we just chose not to have an additional free variable and just do that separately.",
            "We tend to over segment at the region level, but I think when we come to the stage of the multi level those are fixed.",
            "Do you actually have a sense of the number of the kind of the quality of your segmentation as a function of the number of views you take?",
            "Assuming you don't have major occlusion events that would affect your right layout.",
            "Yeah, so we don't have a quantitative measure for this, but can you repeat the question?",
            "Sorry, so the question was, do we have a sense of how the how much?",
            "How much effect the number of views has on the segmentation accuracy?",
            "Is that right?",
            "So so in our datasets we had as few as.",
            "Six or seven images to as many as 60 images, but we don't have a quantitative measure.",
            "But one thing is that for harder objects such as the bicycle or the motorbike, I think we do need in a fuse around the object to be able to tease it apart, and so that's a constraint which we do have for this work.",
            "I have a question regarding limitations.",
            "When is the planar assumption break?",
            "Does the planar assumption break you segment humans for example?",
            "So I think a lot of the scenes, even even some of these objects we see here are not necessarily planar objects such as the doll and even the couch to a certain extent is not.",
            "The chair is Inter planar object, so I think the piecewise planar does do a good job and I think the reason why we went with that is that the contours of the object of well are well defined in that representation.",
            "So I think even humans can be segmented out this way.",
            "Hi, thank you very nice results when you're observing a rigid body from a fixed viewpoint from several viewpoints and you've gotta fix scene there, the object has to satisfy silhouette coherency or sort of.",
            "The visual Hull should be consistent.",
            "Do you have a way of enforcing that or do you have an idea how you might enforce that?",
            "If you don't so right now we do have a constraint that the object is within the field of view of all the images, and so once that goes once that breaks, we do need to use some other sort of visual approach to sort of say that.",
            "The object still exists within this image.",
            "Right now we do have a constraint that it should be within the field of view.",
            "I think moving forward we can sort of try to see if you can use this segmentation to try and fix the 3D model we have and try to see if that can be put in a loop to sort of fix that.",
            "Thank you.",
            "OK, actually about the last question, so it so I was wondering how self occlusions, in particular for concave objects like the sofa affects the foreground background segmentation because I guess you would have some visibility issue there, right right?",
            "So I think within a fuse the depth estimate for the foreground object, even in presence of self occlusions is pretty good.",
            "And when you do have a self occlusion foreground labeling problem is easy because it's still the foreground object.",
            "And so that does not cause any problems because we seem to have visibility constraints that help us grow together parts.",
            "Thank you, so let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Arthur Scott Lee in this joint work with that person and Rick Szeliski",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the task we're looking at here is we're given a set of images of an object capture from multiple viewpoints, and our goal is to automatically infer what the object of interest is and to perform and to obtain a per pixel and accurate foreground segment.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation from each view and there is some of the results which will get so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Uh, the task of obtaining accurate foreground segmentation is something which has been looked at in the past, and there have been a lot of interactive techniques were given.",
                    "label": 0
                },
                {
                    "sent": "The user input.",
                    "label": 0
                },
                {
                    "sent": "You build a global color Model 1, which describes the foreground 11 which describes the background, and you propagate that across images.",
                    "label": 0
                },
                {
                    "sent": "Now there have been some works which tried to do this more recently with as an unsupervised algorithm where they used a similar appearance models, but they tried to use the intuition that the foreground model tends to appear similar while the background changes more drastically.",
                    "label": 0
                },
                {
                    "sent": "However, this is a constraint which is not easily satisfied for multiview images.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In Multiview data, the other thing you can do is obtain geometric globally consistent 3D model of this object of interest and then project this into each view and thus obtaining the segmentation.",
                    "label": 0
                },
                {
                    "sent": "However, we know that obtaining an accurate 3D model of objects is a hard task.",
                    "label": 0
                },
                {
                    "sent": "So what we do in this work is bypass this particular stage and we instead go to an approximate representation of a scene visa piece, piecewise planar stereo framework, whereas prior work have shown we can obtain a low level segmentation where pixels are grouped, planar surface is or.",
                    "label": 0
                },
                {
                    "sent": "However, prior work has not reasoned about the foreground object, and that's something we do in this work, so our contribution is an unsupervised.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Echo segmentation algorithm which exploits stereo and an appearance cues, and will show that we extend prior work on piecewise planar stereo such that it's robust scenarios where stereo matching is unreliable and by doing so we show that we can get better.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "So here's an overview of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "We use a multi stage framework where you start off with your input images.",
                    "label": 1
                },
                {
                    "sent": "We first obtain a perform piecewise planar stereo to obtain a.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inner labeling of the scene and and piecewise planar depth depth map.",
                    "label": 0
                },
                {
                    "sent": "And then we perform a reason level foreground background labeling which is which gives us a code segmentation of the foreground for each image.",
                    "label": 0
                },
                {
                    "sent": "And once we have this for each image, we finally perform a multiview pixel level foreground background labeling.",
                    "label": 0
                },
                {
                    "sent": "So let's start.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the piecewise planar studio.",
                    "label": 0
                },
                {
                    "sent": "Given the set of input images, we first run a structure from motion to calibrate the cameras and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once we have that done, for every view, we use two neighboring used to perform dense stereo.",
                    "label": 0
                },
                {
                    "sent": "We do this using Semi global stereo matching and in addition to an estimate of the depth we also get an estimate of the confidence of the algorithm with this step estimate.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now that we have this, we now hypothesize planes by using a seed and grow approach and by doing so we obtain our initial labeling of pixels to plane plane hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Now our goal given these plane hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to obtain a planar labeling where per pixel planar learning and then we can use this planar labeling tomorrow to obtain our piecewise planar depth map.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's worth noting that when you when you're looking at hard or complicated objects which have occlusions and pin structures such as the bicycle here are initial stereo matching.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can be erroneous, so as you can see in the yellow ellipse, the estimates of the depth are wrong here.",
                    "label": 1
                },
                {
                    "sent": "And this is something we should propagate through.",
                    "label": 0
                },
                {
                    "sent": "When you use a peaceful explains the big separate planar framework which uses only stereo cues.",
                    "label": 1
                },
                {
                    "sent": "So what we do in our in this approach is is trying to incorporate appearance and stereo cues to try and recover the finer details of the object, and will see that this is something which will help us do better with the task of.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Segmentation.",
                    "label": 0
                },
                {
                    "sent": "So a framework for piecewise planar Studio is similar to prior work, so you have a pixel level MRF formulated over your whole image, and you need to assign a discrete planar label for each pixel.",
                    "label": 0
                },
                {
                    "sent": "Now each plane is parameterized by a 3D plane equation and an appearance model which describes that particular region.",
                    "label": 1
                },
                {
                    "sent": "And now we have an energy function.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find over all the pixels.",
                    "label": 0
                },
                {
                    "sent": "So let's take a look at the terms.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This started with the geometric unity term.",
                    "label": 0
                },
                {
                    "sent": "Now this is a per pixel score, which tells you how compatible a plane is to particular pixel.",
                    "label": 0
                },
                {
                    "sent": "So given our initial estimate of the of the depth of a pixel from our stereo matching, we're trying to measure how compatible is it.",
                    "label": 0
                },
                {
                    "sent": "When I say that this Pixel has to line up, particularly in pie.",
                    "label": 0
                },
                {
                    "sent": "We modulate this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Item using a per pixel confidence value and this is where we use our confidence map.",
                    "label": 1
                },
                {
                    "sent": "We initially obtain now as you can see in this example, while while while there was errors in the estimated depth map, we see that that's actually seen in the algorithms.",
                    "label": 0
                },
                {
                    "sent": "Confidence in this depth map and so that helps us modulate this geometric term.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other unity term is an appearance unary term.",
                    "label": 1
                },
                {
                    "sent": "Now, given our planar labeling, we can actually use for every reason.",
                    "label": 0
                },
                {
                    "sent": "We can actually obtain upper reason compact appearance model which describes our particular region, and in contrast to a global color, models these parties in color models will help us better distinguish the contours of the object.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are pairwise term is is the popular contrast sensitive parts model?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once we have this, we perform inference using iterative graph cut with every iteration we relearn the the appearance model for each of these regions and then obtain an updated labeling and typically in 2 three iterations we obtain our planar labeling and are piecewise planar.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Map.",
                    "label": 0
                },
                {
                    "sent": "With this in place, now let's look at how we obtain a reasonable.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Diagram labeling our goal.",
                    "label": 0
                },
                {
                    "sent": "Our task here is given our initial reason labeling treat each region as a node.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A graph that is giving us an irregular small graph and given this obtain reason level labeling where each region is either a foreground or background.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reason.",
                    "label": 0
                },
                {
                    "sent": "We do so by formulating two energy function, one which describes one which which helps model the appearance and another which helps model the geometry.",
                    "label": 0
                },
                {
                    "sent": "The unity term for both of these energy functions is what we call the objectness term.",
                    "label": 1
                },
                {
                    "sent": "This encodes how likely a region belongs to the foreground object, and to do this we go back and look at our recent labeling and piecewise planar death map and using the depth map we can now project each of these regions into each of our camera viewpoints.",
                    "label": 0
                },
                {
                    "sent": "And so now we can see that the red region lies in the field of view of a lot more cameras and the blue region, thus giving it a higher objectness score than the blue region.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first of our pairwise terms is an appearance based compatibility term.",
                    "label": 0
                },
                {
                    "sent": "Now this tries to encode how similar to neighboring.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you look at two regions on the couch here, they are fairly similar in appearance, so this has a high compatibility score.",
                    "label": 0
                },
                {
                    "sent": "However, when you.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two regions, such as the couch and the ground surface.",
                    "label": 0
                },
                {
                    "sent": "This is not as compatible, and so this will have a lower score that's trying to allow for a label change at this point.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second energy function has the pairwise term, which which is modeled by the depth based compatibility score.",
                    "label": 0
                },
                {
                    "sent": "So here we want to try and encourage a label change when you have a depth discontinuity.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when you're considering two regions on the couch again, these are fairly compatible with depth, so they have a high score.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over 2 regions which straddle the depth discontinuity should have would end up having a lower lower compatibility score that's trying to allow for a depth for a label change.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At this point.",
                    "label": 0
                },
                {
                    "sent": "So with this in place, we can we now perform inference on both these energy functions and we do it independently to obtain our map labels.",
                    "label": 1
                },
                {
                    "sent": "And finally we label a region as foreground.",
                    "label": 1
                },
                {
                    "sent": "If either of these two energy functions labels the region's program.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you look at the results at this at this stage, we see that for a simple object such as the couch, we already have pretty good segmentation of the couch in place.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "However, when you look at more complicated objects such as this carriage sequence, here we see that some portion of the carriage might be missing in one of the viewpoints, but that might be captured in another viewpoint, so this brings.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To our final stage of multiview foreground background labeling.",
                    "label": 0
                },
                {
                    "sent": "So this is where we want to pull all the information from the reason level labeling.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we construct a pixel level MRF over all the pixels of an image, and now we want to give each pixel the foreground or background label.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have an energy function defined over this pixel MRF and now we have an object Ness term, again as one of our unity terms.",
                    "label": 0
                },
                {
                    "sent": "Now similar to the region level Objectness term.",
                    "label": 0
                },
                {
                    "sent": "This is again trying to measure how likely your pixel belongs to the foreground object.",
                    "label": 0
                },
                {
                    "sent": "And similar to earlier, now we can look at every pixel and using the depth of piecewise planar bitmap project these pixels into each camera.",
                    "label": 0
                },
                {
                    "sent": "But now we have this additional information from our previous stage we now.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A sense of where the foreground is.",
                    "label": 0
                },
                {
                    "sent": "So we use this to say that the red pixel is more, is more likely to be object than the blue pixel.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second term here is the appearance unity term.",
                    "label": 0
                },
                {
                    "sent": "Now that we have a course reason level labeling, we can use the foreground and background to open up to obtain our foreground and background appearance models and this will help modulate this term.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The pairwise sum again is a contrast sensitive Potts model.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once we have this, we perform graph cuts to obtain our labeling, and as you can see here, what started off as as errors in our region level labeling are fixed as shown in the sign ellipse in our multi view labeling.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is our complete algorithm to obtain Multiview Object Co segmentation.",
                    "label": 0
                },
                {
                    "sent": "Let's take a look at this.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Of we collected 7 datasets with as few as six images captured from different viewpoints to as many as 60 images.",
                    "label": 0
                },
                {
                    "sent": "Looking at the object, the SFM reconstructions of these sequences are shown below the thumbnail.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For ground truth we manually labeled the ground truth using graph cut.",
                    "label": 0
                },
                {
                    "sent": "So for for image such as this.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obtaining a good segmentation as seen here involved about four minutes of effort to obtain the segmentation again using a purely appearance based.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "George.",
                    "label": 0
                },
                {
                    "sent": "So evaluation metric.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given our segmentation is the standard intersection over union metric, however, to actually get a better sense of the accuracy, we evaluated this metric only over X pixel ban.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Around the boundary.",
                    "label": 0
                },
                {
                    "sent": "Now with this is.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The metric we now can go to the comparisons with prior work.",
                    "label": 0
                },
                {
                    "sent": "So for two of the images shown here, if you use a purely appearance based approach, while it can get the, you can actually do a good job at recognizing the foreground object.",
                    "label": 0
                },
                {
                    "sent": "Getting a pixel level pixel accurate.",
                    "label": 0
                },
                {
                    "sent": "Segmentation is a hard problem here.",
                    "label": 0
                },
                {
                    "sent": "The second or third comparison we did was try to use pass based multiview stereo to obtain a reconstruction of the whole scene, then manually crop out the 3D model corresponding to the object of interest and projected into each view.",
                    "label": 0
                },
                {
                    "sent": "Now that gives us slightly better results qualitatively.",
                    "label": 0
                },
                {
                    "sent": "In comparison.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We see that we perform much better, both quantitatively and qualitatively and closely matches were the ground truth we have.",
                    "label": 0
                },
                {
                    "sent": "So in more comparison, we saw that our approach outperforms the prior work both in the metric of a 10 pixel wide band around the boundary, and the more traditional full image segmentation accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Qualitatively, we see that we do a pretty good job at recovering quality, depth map San.",
                    "label": 0
                },
                {
                    "sent": "Good segmentations in particular, piecewise planar proxies, was able to model even non planar objects such as the chair here.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we were able to handle irregularities in the scene such as specular surface is on the car and overlapping foreground background appearance models such as the bike and the road below.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lastly, we saw that we were able to obtain quality depth Maps, an good segmentation even in case of thin structures and complex occlusions, as we see here.",
                    "label": 0
                },
                {
                    "sent": "The more results qualitative and quantitative in the paper, and I'll refer you to that for more.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, what we have proposed is an unsupervised Co segmentation algorithm where we've used a multi staged approach to put together appearance and stereo cues to infer the object of interest to recover pixel accurate foreground segmentation in each view and to recover good quality depth Maps.",
                    "label": 0
                },
                {
                    "sent": "With that I thank you and.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remote assist validate questions.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very interesting work.",
                    "label": 0
                },
                {
                    "sent": "So my question is, from my understanding for regional level program background segmentation you solve graph cuts for geometry, another grass cut for appearance independently for the reason yes for multiple you mix both.",
                    "label": 0
                },
                {
                    "sent": "So why didn't you mix both with?",
                    "label": 0
                },
                {
                    "sent": "So we thought about that.",
                    "label": 0
                },
                {
                    "sent": "So we saw that the two things, the appearance and the geometry is trying to tease apart.",
                    "label": 0
                },
                {
                    "sent": "It's a little different.",
                    "label": 0
                },
                {
                    "sent": "You can think of trying to put them together and then tune para meters, but we just chose not to have an additional free variable and just do that separately.",
                    "label": 0
                },
                {
                    "sent": "We tend to over segment at the region level, but I think when we come to the stage of the multi level those are fixed.",
                    "label": 0
                },
                {
                    "sent": "Do you actually have a sense of the number of the kind of the quality of your segmentation as a function of the number of views you take?",
                    "label": 0
                },
                {
                    "sent": "Assuming you don't have major occlusion events that would affect your right layout.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we don't have a quantitative measure for this, but can you repeat the question?",
                    "label": 0
                },
                {
                    "sent": "Sorry, so the question was, do we have a sense of how the how much?",
                    "label": 0
                },
                {
                    "sent": "How much effect the number of views has on the segmentation accuracy?",
                    "label": 1
                },
                {
                    "sent": "Is that right?",
                    "label": 0
                },
                {
                    "sent": "So so in our datasets we had as few as.",
                    "label": 0
                },
                {
                    "sent": "Six or seven images to as many as 60 images, but we don't have a quantitative measure.",
                    "label": 0
                },
                {
                    "sent": "But one thing is that for harder objects such as the bicycle or the motorbike, I think we do need in a fuse around the object to be able to tease it apart, and so that's a constraint which we do have for this work.",
                    "label": 0
                },
                {
                    "sent": "I have a question regarding limitations.",
                    "label": 0
                },
                {
                    "sent": "When is the planar assumption break?",
                    "label": 1
                },
                {
                    "sent": "Does the planar assumption break you segment humans for example?",
                    "label": 0
                },
                {
                    "sent": "So I think a lot of the scenes, even even some of these objects we see here are not necessarily planar objects such as the doll and even the couch to a certain extent is not.",
                    "label": 0
                },
                {
                    "sent": "The chair is Inter planar object, so I think the piecewise planar does do a good job and I think the reason why we went with that is that the contours of the object of well are well defined in that representation.",
                    "label": 0
                },
                {
                    "sent": "So I think even humans can be segmented out this way.",
                    "label": 0
                },
                {
                    "sent": "Hi, thank you very nice results when you're observing a rigid body from a fixed viewpoint from several viewpoints and you've gotta fix scene there, the object has to satisfy silhouette coherency or sort of.",
                    "label": 0
                },
                {
                    "sent": "The visual Hull should be consistent.",
                    "label": 0
                },
                {
                    "sent": "Do you have a way of enforcing that or do you have an idea how you might enforce that?",
                    "label": 0
                },
                {
                    "sent": "If you don't so right now we do have a constraint that the object is within the field of view of all the images, and so once that goes once that breaks, we do need to use some other sort of visual approach to sort of say that.",
                    "label": 0
                },
                {
                    "sent": "The object still exists within this image.",
                    "label": 0
                },
                {
                    "sent": "Right now we do have a constraint that it should be within the field of view.",
                    "label": 0
                },
                {
                    "sent": "I think moving forward we can sort of try to see if you can use this segmentation to try and fix the 3D model we have and try to see if that can be put in a loop to sort of fix that.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, actually about the last question, so it so I was wondering how self occlusions, in particular for concave objects like the sofa affects the foreground background segmentation because I guess you would have some visibility issue there, right right?",
                    "label": 0
                },
                {
                    "sent": "So I think within a fuse the depth estimate for the foreground object, even in presence of self occlusions is pretty good.",
                    "label": 0
                },
                {
                    "sent": "And when you do have a self occlusion foreground labeling problem is easy because it's still the foreground object.",
                    "label": 0
                },
                {
                    "sent": "And so that does not cause any problems because we seem to have visibility constraints that help us grow together parts.",
                    "label": 0
                },
                {
                    "sent": "Thank you, so let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}