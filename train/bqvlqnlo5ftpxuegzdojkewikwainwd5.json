{
    "id": "bqvlqnlo5ftpxuegzdojkewikwainwd5",
    "title": "Content based Fake News Detection Using Knowledge Graphs",
    "info": {
        "author": [
            "Jeff Z. Pan, University of Southampton"
        ],
        "published": "Nov. 22, 2018",
        "recorded": "October 2018",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2018_pan_content_fake_news/",
    "segmentation": [
        [
            "Hi thanks, I'm just pulling from University property in and this is John work with colleagues from the update Wuhan Joan Lab on Knowledge Engineering, an information security.",
            "So basically what we're looking at here is to see how we could apply approximate reasoning for fake news detection, so obviously we."
        ],
        [
            "Papa Oh no, that fake news detection becomes quite.",
            "Popular topics since the US election in 2016.",
            "But in terms of the research, I think people have been looking into fake news for a long time.",
            "Well, what is famous is some news articles that are intentionally and verifiably false and could mislead.",
            "Readers, and there are different reasons for that.",
            "Sometimes you do that because of money.",
            "In some other situation, you do that because you want to manipulate manipulate other people.",
            "And there are various different techniques to do fake news.",
            "You could provide information with sliding scale.",
            "You could take information completely out of context, or you could also offer alternative facts or lies.",
            "So in terms of detecting fake news, obviously there are at least two stage on first stage is to check whether something is fake news or not, and then you know in the later stage you want.",
            "You might want to check what types of fake news it is.",
            "So."
        ],
        [
            "If you think about.",
            "Things in a bit more detail way through task of fake news detection, is to consider a news Article D and a set of background articles.",
            "Be for example, for the purpose of training.",
            "To check whether the is true or fake and there are quite some work already.",
            "So fake news detection and many of them are based on machine learning based approaches or feature extraction based approach.",
            "Accuracy is not bad at all, just that.",
            "With this approach is you could just detect the fake news because of certain features.",
            "For example, the sign of the writing or certain keywords will use in the tags, but it's not really helpful for you to answer why it is a fake news.",
            "So the path.",
            "So the motivation of our work is to."
        ],
        [
            "See what can we have with knowledge graph with the vision that you know with the graph in place?",
            "With all these relevant entities and relations, you could start to hopefully explain why some.",
            "Piece of news is fake news or not?",
            "So for example, if you have some.",
            "Tags.",
            "Here you know you could translate that into into tuples.",
            "And then you start to consider fairness detection based on knowledge graph.",
            "In an ideal world, obviously we need to come back to reality in the next line, but for the moment just consider that we have a set of new chip Osgi form from the input news article.",
            "So it might be one, or it might be more than one and you have a background knowledge graph G. Anne.",
            "So the news is too if the G SM G and and big trees Union is consistent.",
            "Otherwise it could be fake, but as I said, this is in an ideal work in reality there."
        ],
        [
            "A few challenges.",
            "The first challenge is that there might not be any knowledge graph for you to use, because news are always coming up sometimes.",
            "And such, surprisingly, you might not actually have the time to prepare those knowledge graph up front.",
            "Anne.",
            "And even there are some existing relevant ones.",
            "They might not be complete, or they might not be have good enough precision or quality.",
            "So for example, if you have to translate, you know.",
            "Extract your post from tags.",
            "Usually it won't be perfect for sure.",
            "I mean, at least with the NLP techniques that we have at the moment."
        ],
        [
            "So we think this is a good application for approximate reasoning, because actually you don't.",
            "You don't really stick so tightly to sign complete, so obviously one idea is to see whether we could apply existing approximate techniques that we could use the required field without, you know, from DL 2 ELDLQ&E L2 RL.",
            "Various reasons supporting that, including the trial reason that we developed in Aberdeen.",
            "Now, if you really think carefully about that, you realize that this is not working, because this approach requires the presence of the schema or the box.",
            "If you don't have the box, then you have don't have much to do with this logic based approximation."
        ],
        [
            "And there is actually some existing work when you don't have schema.",
            "One way of doing things is to do path based reasoning.",
            "There's some work.",
            "It's not really about reasoning, but it's actually using path.",
            "So for example, if you want to check whether a bug has notable is notable work of some person, you could try to check if there's any any other shortest paths connecting these two entities and make a judgment based on that.",
            "But in our evaluation, we found out that you know good quality parts are not always there.",
            "You know there might be 2 nodes, but they might not be connected in some situation that maybe some of the nodes are not actually there in the knowledge graph.",
            "So what do you do with it?",
            "So then."
        ],
        [
            "This next idea is to to relax the notion of reason a little bit and consider some kind of similarity reasoning as approximate reasoning.",
            "If you think about that in the machine learning community when they talk about knowledge graph reasoning, they actually think about this kind of similarity reasoning.",
            "So northcraft completion.",
            "If you're not familiar with it, is.",
            "Defined as follows.",
            "Given a knowledge graph G containing a tee box and a box that asks of completion is to compute an extension, a box, a prime such that all the new triples in a primes use only name classes and then properties from from the tee box T. An there are different approaches to do North Graph completion, but one very popular approach is to do embedding knowledge graph embedding."
        ],
        [
            "So.",
            "Given two entities in a head and tail.",
            "Knowledge graph embedding approaches tried to represent had Intel as some K dimensional vectors and then define some scoring function FT to measure the possibility of such triple in the embedding space.",
            "So we could actually constructs this kind of model by.",
            "Trying to minimize saying the global loss function involving all the entities and relations in the given background knowledge graph G. And then we could use such model to do approximate reasoning.",
            "So how do we actually use?"
        ],
        [
            "For for reasoning, obviously we need to do something before we apply the model, we need to extract suppose TS from the input news article.",
            "I'm not going to go into details there, but you can find more details in the paper.",
            "But once you have all those triples, you can start to calculate the bias values with respect to the model that we have.",
            "And then there are various different approaches for you to make use of this bias value to decide whether the the input news article is true or fake.",
            "So one approach is to just use one model.",
            "It could be a. A2 Knowledge graph or it could be a fake knowledge graph.",
            "Afraid new knowledge graph.",
            "And obviously, if it is a 2 new knowledge graph that the by Friday would be should be smaller.",
            "If it is a true news.",
            "But if it is a fake news knowledge graph, basically if it is close to the graph then it would be a fake news.",
            "You could also have binary model.",
            "You have two and fake North grew up and see which side.",
            "The new chips are closer to.",
            "And you can also have this combined hybrid approach by you know, connecting or combining the features from the above.",
            "Models.",
            "Now this is the approach, but the question is how does it does it work and how do we evaluate that?"
        ],
        [
            "So we use a benchmark partially coming from cargo, so there are bound some news articles about the 2016 US election.",
            "They're all fake.",
            "And we also collected some 2 news articles about the same topic from BBC Independence and Sky.",
            "And so we have altogether 1400.",
            "Article, you know in each case and we use 1000 articles for training and we use the other 400 for testing.",
            "So we need to create the Knowledge graph that we have the failed knowledge graph based on the fake news article base and we have the two knowledge.",
            "We have two types of two knowledge graph.",
            "One is based on the pedia for hops starting from the 2016 election.",
            "An entity as well as the entity that we have in the 1st.",
            "In the first North graph.",
            "And the second 2 two news knowledge graph is based on the two news articles.",
            "And then we could construct the three models.",
            "Using trancey, so there are various different approaches to do knowledge graph embedding.",
            "We just start to use something simple an.",
            "The plan is that once we understand how it work, we could do more complicated stuff later on.",
            "But it turns out that trans.",
            "It's not too bad at all for our purpose.",
            "So."
        ],
        [
            "So we have this is a table telling you different model.",
            "The three models that we talk about with various way of doing the values function, we either do calculate the Max or the average.",
            "The first observation is that the models actually from the news articles are not too bad.",
            "Escoces over viewpoint 7.",
            "Anne.",
            "An if you look at the flag or the two.",
            "Knowledge graph from the other codes.",
            "They are kind of come.",
            "Parable is both is about 0.77.",
            "That means the same for the SF score.",
            "And Interestingly, actually the DB."
        ],
        [
            "Pedia for Hobbits actually getting the highest.",
            "F score for this.",
            "So maybe 'cause the other two knowledge base are basically too messy.",
            "Anne.",
            "And to compare with our baseline for the past based approach, actually every every single model in our approach actually outperform the baseline approach.",
            "In terms of F1 score.",
            "So those are the single model about binary model.",
            "In general we could see that binary models better than all the single models.",
            "Anne.",
            "An we could also see that combining.",
            "Combining the fake news knowledge graph with the pedia North Graph actually produce the best among among the binary models here.",
            "We could have also had the hybrid approach by combining features an here we could actually use SVN and we could have different kernel functions and you can see that you know.",
            "The hybrid approach it actually could further improve the performance depending on what kind of kernel functions that you use.",
            "Sometimes you have better precision, sometimes you have better recall."
        ],
        [
            "So to conclude, the work the basic given that the text datasets that we have in looks like the embedding base approximate reasoning approach can be useful to help detect fake news even in the presence of incomplete and imprecise knowledge graph.",
            "Since we submitted, we actually have some more work on what happens if we do have the schema right?",
            "And what is the quality of embedding when when you want to consider the scheme as well.",
            "So we have a paper published in this later on this year's about schema where to pull classification.",
            "So that we could actually use approximate consistency checking based on logic.",
            "An embedding based approximate reasoning together.",
            "Surprisingly, we see that some of the embedding based approaches are not really very good getting correct.",
            "Suppose, for example, if you apply trancy over now 9951 of 1 version of the Never Ending Language learning data set, you only get less than 1% of correct riposte.",
            "But if you applied schema where triple classification, we could improve the correctness by over 40%.",
            "And you could use this kind of approach to create more correct.",
            "Suppose, for example using the DB pedia subset of the political datasets.",
            "We could increase more than 50 times of the correct data set triples that we could we could use compared to plain usage of embedding based approach.",
            "So in the future we would like to look into more about how do we use the schema and how to explain the results of the fake news detection.",
            "OK."
        ],
        [
            "Thank you.",
            "Thanks for your talk, Jeff.",
            "Very nice, very nice work.",
            "Do we have a bit of insight in which parts you can very well spot the fake news and in which places you fail?",
            "Does this have to do with this systematic this failure due to lack of knowledge or anything?",
            "Or if you have some time, I think this is a good question.",
            "Very good question.",
            "I'm.",
            "It is not very easily done.",
            "Without the support of explanations because you know, news articles are not very short, an with thousands more than 1000 news articles, it's really difficult asking for anecdotal insight before really difficult to really.",
            "No exactly where exactly it goes wrong and but, but that's one of the motivation of actually looking into explanations.",
            "Good question.",
            "So if you wanted to detect fake news related to the election, that means you will need a very good quality knowledge graph.",
            "An If I understood correctly, use four hop approach to get to create this knowledge graph and that's I think anytime you traverse anything more than two hops, you very much diverge from virtue started with.",
            "So that would be pretty challenging to know.",
            "What are the election specific issues or politics position to know?",
            "What are the divergent new concepts that come in and to also ensure that a lot of things during election that are about election without talking about politics?",
            "It could be about, you know, racial thing it could be, or at least not known to be relevant to election or primary and hence.",
            "You know you would need a dynamic knowledge graph to really continually updated noise graph to be able to get anywhere.",
            "At this very challenging, obviously as a set without good quality knowledge graph you contact, you can't be sure, sometimes right?",
            "And you're you're mentioning of the two hubs is exactly the case, and that's why we believe that.",
            "Maybe that's why the path based approach is not really working because you don't really have good quality graph to actually cover to cover the paths connecting various important entities.",
            "Now.",
            "Embedding based approach is working in a different way, so it's kind of computing a model.",
            "Right and respecting all the entities, existing entities and relations, and then use it to track the new so.",
            "Yes.",
            "Yeah, if you if you want to monitor incremental stuff.",
            "I mean obviously that would be beyond the scope of this work.",
            "There's one of the future things.",
            "There's a lot of interesting things that we could look into.",
            "This is just one starting point to see whether actually you could make use of approximate reasoning to.",
            "Do, you know, some meaningful detection?",
            "Hi.",
            "Question is, how do you differentiate between fake sorry?",
            "I'm here hi hi.",
            "How do you differentiate between fake and perspective or opinion and also things that rely on of highly complex or long history?",
            "Yeah, so that's the kind of more details I mentioned in the second stage, right?",
            "So in this stage you don't?",
            "Yeah, and as I mentioned to Steven, without having a useful explanation, services is really difficult to.",
            "Two to three and debug such services.",
            "Now what you what you could do is to see the precision and recall at this stage with small number of news articles we could we could do some.",
            "Detailed study, but but explaining everything for the whole data set would be a lot of work.",
            "Thanks for the talk.",
            "So one of the example I came across recently.",
            "I was actually testing one of these fake detection services and it's very good in detecting things that are kind of commonly takes the pattern over fake article.",
            "Like you know sharks swimming in the codes of yeah, but then it fails when something similar to that is actually true, like there was some waste resolved.",
            "You know, got flooded into the water, you know something a bit extreme.",
            "Yes, now I wonder what?",
            "How do you think such an approach would work with cases like that?",
            "Or what can we do to make it work with cases like yeah, so so when you do feature extraction, so typically you capture some keywords or sometimes if you really want to do it in a semantic way, some entities but but you know that you could turn a true news into failures by changing some of the relations, right?",
            "Right, you have two right entities.",
            "You change that the label of the relation.",
            "Then you get around triple, so not considering the relation.",
            "Would be a big mistake I think and and and somehow to some extent this embedding based approach actually consider both entities and relations together.",
            "So that's why we think it might be a promising approach to start with, but you know there are a lot of other things that we could do.",
            "On top of this.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi thanks, I'm just pulling from University property in and this is John work with colleagues from the update Wuhan Joan Lab on Knowledge Engineering, an information security.",
                    "label": 0
                },
                {
                    "sent": "So basically what we're looking at here is to see how we could apply approximate reasoning for fake news detection, so obviously we.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Papa Oh no, that fake news detection becomes quite.",
                    "label": 0
                },
                {
                    "sent": "Popular topics since the US election in 2016.",
                    "label": 1
                },
                {
                    "sent": "But in terms of the research, I think people have been looking into fake news for a long time.",
                    "label": 0
                },
                {
                    "sent": "Well, what is famous is some news articles that are intentionally and verifiably false and could mislead.",
                    "label": 1
                },
                {
                    "sent": "Readers, and there are different reasons for that.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you do that because of money.",
                    "label": 0
                },
                {
                    "sent": "In some other situation, you do that because you want to manipulate manipulate other people.",
                    "label": 0
                },
                {
                    "sent": "And there are various different techniques to do fake news.",
                    "label": 1
                },
                {
                    "sent": "You could provide information with sliding scale.",
                    "label": 0
                },
                {
                    "sent": "You could take information completely out of context, or you could also offer alternative facts or lies.",
                    "label": 0
                },
                {
                    "sent": "So in terms of detecting fake news, obviously there are at least two stage on first stage is to check whether something is fake news or not, and then you know in the later stage you want.",
                    "label": 1
                },
                {
                    "sent": "You might want to check what types of fake news it is.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you think about.",
                    "label": 0
                },
                {
                    "sent": "Things in a bit more detail way through task of fake news detection, is to consider a news Article D and a set of background articles.",
                    "label": 1
                },
                {
                    "sent": "Be for example, for the purpose of training.",
                    "label": 0
                },
                {
                    "sent": "To check whether the is true or fake and there are quite some work already.",
                    "label": 0
                },
                {
                    "sent": "So fake news detection and many of them are based on machine learning based approaches or feature extraction based approach.",
                    "label": 0
                },
                {
                    "sent": "Accuracy is not bad at all, just that.",
                    "label": 0
                },
                {
                    "sent": "With this approach is you could just detect the fake news because of certain features.",
                    "label": 0
                },
                {
                    "sent": "For example, the sign of the writing or certain keywords will use in the tags, but it's not really helpful for you to answer why it is a fake news.",
                    "label": 0
                },
                {
                    "sent": "So the path.",
                    "label": 0
                },
                {
                    "sent": "So the motivation of our work is to.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See what can we have with knowledge graph with the vision that you know with the graph in place?",
                    "label": 0
                },
                {
                    "sent": "With all these relevant entities and relations, you could start to hopefully explain why some.",
                    "label": 0
                },
                {
                    "sent": "Piece of news is fake news or not?",
                    "label": 1
                },
                {
                    "sent": "So for example, if you have some.",
                    "label": 0
                },
                {
                    "sent": "Tags.",
                    "label": 0
                },
                {
                    "sent": "Here you know you could translate that into into tuples.",
                    "label": 0
                },
                {
                    "sent": "And then you start to consider fairness detection based on knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "In an ideal world, obviously we need to come back to reality in the next line, but for the moment just consider that we have a set of new chip Osgi form from the input news article.",
                    "label": 0
                },
                {
                    "sent": "So it might be one, or it might be more than one and you have a background knowledge graph G. Anne.",
                    "label": 1
                },
                {
                    "sent": "So the news is too if the G SM G and and big trees Union is consistent.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it could be fake, but as I said, this is in an ideal work in reality there.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A few challenges.",
                    "label": 0
                },
                {
                    "sent": "The first challenge is that there might not be any knowledge graph for you to use, because news are always coming up sometimes.",
                    "label": 1
                },
                {
                    "sent": "And such, surprisingly, you might not actually have the time to prepare those knowledge graph up front.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And even there are some existing relevant ones.",
                    "label": 0
                },
                {
                    "sent": "They might not be complete, or they might not be have good enough precision or quality.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you have to translate, you know.",
                    "label": 0
                },
                {
                    "sent": "Extract your post from tags.",
                    "label": 0
                },
                {
                    "sent": "Usually it won't be perfect for sure.",
                    "label": 0
                },
                {
                    "sent": "I mean, at least with the NLP techniques that we have at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we think this is a good application for approximate reasoning, because actually you don't.",
                    "label": 0
                },
                {
                    "sent": "You don't really stick so tightly to sign complete, so obviously one idea is to see whether we could apply existing approximate techniques that we could use the required field without, you know, from DL 2 ELDLQ&E L2 RL.",
                    "label": 0
                },
                {
                    "sent": "Various reasons supporting that, including the trial reason that we developed in Aberdeen.",
                    "label": 0
                },
                {
                    "sent": "Now, if you really think carefully about that, you realize that this is not working, because this approach requires the presence of the schema or the box.",
                    "label": 1
                },
                {
                    "sent": "If you don't have the box, then you have don't have much to do with this logic based approximation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there is actually some existing work when you don't have schema.",
                    "label": 0
                },
                {
                    "sent": "One way of doing things is to do path based reasoning.",
                    "label": 0
                },
                {
                    "sent": "There's some work.",
                    "label": 0
                },
                {
                    "sent": "It's not really about reasoning, but it's actually using path.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to check whether a bug has notable is notable work of some person, you could try to check if there's any any other shortest paths connecting these two entities and make a judgment based on that.",
                    "label": 0
                },
                {
                    "sent": "But in our evaluation, we found out that you know good quality parts are not always there.",
                    "label": 1
                },
                {
                    "sent": "You know there might be 2 nodes, but they might not be connected in some situation that maybe some of the nodes are not actually there in the knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "So what do you do with it?",
                    "label": 0
                },
                {
                    "sent": "So then.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This next idea is to to relax the notion of reason a little bit and consider some kind of similarity reasoning as approximate reasoning.",
                    "label": 0
                },
                {
                    "sent": "If you think about that in the machine learning community when they talk about knowledge graph reasoning, they actually think about this kind of similarity reasoning.",
                    "label": 0
                },
                {
                    "sent": "So northcraft completion.",
                    "label": 0
                },
                {
                    "sent": "If you're not familiar with it, is.",
                    "label": 0
                },
                {
                    "sent": "Defined as follows.",
                    "label": 0
                },
                {
                    "sent": "Given a knowledge graph G containing a tee box and a box that asks of completion is to compute an extension, a box, a prime such that all the new triples in a primes use only name classes and then properties from from the tee box T. An there are different approaches to do North Graph completion, but one very popular approach is to do embedding knowledge graph embedding.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Given two entities in a head and tail.",
                    "label": 0
                },
                {
                    "sent": "Knowledge graph embedding approaches tried to represent had Intel as some K dimensional vectors and then define some scoring function FT to measure the possibility of such triple in the embedding space.",
                    "label": 1
                },
                {
                    "sent": "So we could actually constructs this kind of model by.",
                    "label": 0
                },
                {
                    "sent": "Trying to minimize saying the global loss function involving all the entities and relations in the given background knowledge graph G. And then we could use such model to do approximate reasoning.",
                    "label": 1
                },
                {
                    "sent": "So how do we actually use?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For for reasoning, obviously we need to do something before we apply the model, we need to extract suppose TS from the input news article.",
                    "label": 1
                },
                {
                    "sent": "I'm not going to go into details there, but you can find more details in the paper.",
                    "label": 0
                },
                {
                    "sent": "But once you have all those triples, you can start to calculate the bias values with respect to the model that we have.",
                    "label": 0
                },
                {
                    "sent": "And then there are various different approaches for you to make use of this bias value to decide whether the the input news article is true or fake.",
                    "label": 0
                },
                {
                    "sent": "So one approach is to just use one model.",
                    "label": 0
                },
                {
                    "sent": "It could be a. A2 Knowledge graph or it could be a fake knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "Afraid new knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "And obviously, if it is a 2 new knowledge graph that the by Friday would be should be smaller.",
                    "label": 0
                },
                {
                    "sent": "If it is a true news.",
                    "label": 0
                },
                {
                    "sent": "But if it is a fake news knowledge graph, basically if it is close to the graph then it would be a fake news.",
                    "label": 0
                },
                {
                    "sent": "You could also have binary model.",
                    "label": 0
                },
                {
                    "sent": "You have two and fake North grew up and see which side.",
                    "label": 0
                },
                {
                    "sent": "The new chips are closer to.",
                    "label": 0
                },
                {
                    "sent": "And you can also have this combined hybrid approach by you know, connecting or combining the features from the above.",
                    "label": 0
                },
                {
                    "sent": "Models.",
                    "label": 0
                },
                {
                    "sent": "Now this is the approach, but the question is how does it does it work and how do we evaluate that?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we use a benchmark partially coming from cargo, so there are bound some news articles about the 2016 US election.",
                    "label": 0
                },
                {
                    "sent": "They're all fake.",
                    "label": 0
                },
                {
                    "sent": "And we also collected some 2 news articles about the same topic from BBC Independence and Sky.",
                    "label": 0
                },
                {
                    "sent": "And so we have altogether 1400.",
                    "label": 0
                },
                {
                    "sent": "Article, you know in each case and we use 1000 articles for training and we use the other 400 for testing.",
                    "label": 1
                },
                {
                    "sent": "So we need to create the Knowledge graph that we have the failed knowledge graph based on the fake news article base and we have the two knowledge.",
                    "label": 0
                },
                {
                    "sent": "We have two types of two knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "One is based on the pedia for hops starting from the 2016 election.",
                    "label": 1
                },
                {
                    "sent": "An entity as well as the entity that we have in the 1st.",
                    "label": 0
                },
                {
                    "sent": "In the first North graph.",
                    "label": 1
                },
                {
                    "sent": "And the second 2 two news knowledge graph is based on the two news articles.",
                    "label": 0
                },
                {
                    "sent": "And then we could construct the three models.",
                    "label": 0
                },
                {
                    "sent": "Using trancey, so there are various different approaches to do knowledge graph embedding.",
                    "label": 0
                },
                {
                    "sent": "We just start to use something simple an.",
                    "label": 0
                },
                {
                    "sent": "The plan is that once we understand how it work, we could do more complicated stuff later on.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that trans.",
                    "label": 0
                },
                {
                    "sent": "It's not too bad at all for our purpose.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have this is a table telling you different model.",
                    "label": 0
                },
                {
                    "sent": "The three models that we talk about with various way of doing the values function, we either do calculate the Max or the average.",
                    "label": 0
                },
                {
                    "sent": "The first observation is that the models actually from the news articles are not too bad.",
                    "label": 0
                },
                {
                    "sent": "Escoces over viewpoint 7.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "An if you look at the flag or the two.",
                    "label": 0
                },
                {
                    "sent": "Knowledge graph from the other codes.",
                    "label": 0
                },
                {
                    "sent": "They are kind of come.",
                    "label": 0
                },
                {
                    "sent": "Parable is both is about 0.77.",
                    "label": 0
                },
                {
                    "sent": "That means the same for the SF score.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, actually the DB.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pedia for Hobbits actually getting the highest.",
                    "label": 0
                },
                {
                    "sent": "F score for this.",
                    "label": 0
                },
                {
                    "sent": "So maybe 'cause the other two knowledge base are basically too messy.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And to compare with our baseline for the past based approach, actually every every single model in our approach actually outperform the baseline approach.",
                    "label": 0
                },
                {
                    "sent": "In terms of F1 score.",
                    "label": 0
                },
                {
                    "sent": "So those are the single model about binary model.",
                    "label": 0
                },
                {
                    "sent": "In general we could see that binary models better than all the single models.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "An we could also see that combining.",
                    "label": 0
                },
                {
                    "sent": "Combining the fake news knowledge graph with the pedia North Graph actually produce the best among among the binary models here.",
                    "label": 0
                },
                {
                    "sent": "We could have also had the hybrid approach by combining features an here we could actually use SVN and we could have different kernel functions and you can see that you know.",
                    "label": 0
                },
                {
                    "sent": "The hybrid approach it actually could further improve the performance depending on what kind of kernel functions that you use.",
                    "label": 1
                },
                {
                    "sent": "Sometimes you have better precision, sometimes you have better recall.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, the work the basic given that the text datasets that we have in looks like the embedding base approximate reasoning approach can be useful to help detect fake news even in the presence of incomplete and imprecise knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "Since we submitted, we actually have some more work on what happens if we do have the schema right?",
                    "label": 0
                },
                {
                    "sent": "And what is the quality of embedding when when you want to consider the scheme as well.",
                    "label": 1
                },
                {
                    "sent": "So we have a paper published in this later on this year's about schema where to pull classification.",
                    "label": 1
                },
                {
                    "sent": "So that we could actually use approximate consistency checking based on logic.",
                    "label": 0
                },
                {
                    "sent": "An embedding based approximate reasoning together.",
                    "label": 0
                },
                {
                    "sent": "Surprisingly, we see that some of the embedding based approaches are not really very good getting correct.",
                    "label": 0
                },
                {
                    "sent": "Suppose, for example, if you apply trancy over now 9951 of 1 version of the Never Ending Language learning data set, you only get less than 1% of correct riposte.",
                    "label": 0
                },
                {
                    "sent": "But if you applied schema where triple classification, we could improve the correctness by over 40%.",
                    "label": 0
                },
                {
                    "sent": "And you could use this kind of approach to create more correct.",
                    "label": 1
                },
                {
                    "sent": "Suppose, for example using the DB pedia subset of the political datasets.",
                    "label": 0
                },
                {
                    "sent": "We could increase more than 50 times of the correct data set triples that we could we could use compared to plain usage of embedding based approach.",
                    "label": 0
                },
                {
                    "sent": "So in the future we would like to look into more about how do we use the schema and how to explain the results of the fake news detection.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your talk, Jeff.",
                    "label": 0
                },
                {
                    "sent": "Very nice, very nice work.",
                    "label": 0
                },
                {
                    "sent": "Do we have a bit of insight in which parts you can very well spot the fake news and in which places you fail?",
                    "label": 0
                },
                {
                    "sent": "Does this have to do with this systematic this failure due to lack of knowledge or anything?",
                    "label": 0
                },
                {
                    "sent": "Or if you have some time, I think this is a good question.",
                    "label": 0
                },
                {
                    "sent": "Very good question.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "It is not very easily done.",
                    "label": 0
                },
                {
                    "sent": "Without the support of explanations because you know, news articles are not very short, an with thousands more than 1000 news articles, it's really difficult asking for anecdotal insight before really difficult to really.",
                    "label": 0
                },
                {
                    "sent": "No exactly where exactly it goes wrong and but, but that's one of the motivation of actually looking into explanations.",
                    "label": 0
                },
                {
                    "sent": "Good question.",
                    "label": 0
                },
                {
                    "sent": "So if you wanted to detect fake news related to the election, that means you will need a very good quality knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "An If I understood correctly, use four hop approach to get to create this knowledge graph and that's I think anytime you traverse anything more than two hops, you very much diverge from virtue started with.",
                    "label": 0
                },
                {
                    "sent": "So that would be pretty challenging to know.",
                    "label": 0
                },
                {
                    "sent": "What are the election specific issues or politics position to know?",
                    "label": 0
                },
                {
                    "sent": "What are the divergent new concepts that come in and to also ensure that a lot of things during election that are about election without talking about politics?",
                    "label": 0
                },
                {
                    "sent": "It could be about, you know, racial thing it could be, or at least not known to be relevant to election or primary and hence.",
                    "label": 0
                },
                {
                    "sent": "You know you would need a dynamic knowledge graph to really continually updated noise graph to be able to get anywhere.",
                    "label": 0
                },
                {
                    "sent": "At this very challenging, obviously as a set without good quality knowledge graph you contact, you can't be sure, sometimes right?",
                    "label": 0
                },
                {
                    "sent": "And you're you're mentioning of the two hubs is exactly the case, and that's why we believe that.",
                    "label": 0
                },
                {
                    "sent": "Maybe that's why the path based approach is not really working because you don't really have good quality graph to actually cover to cover the paths connecting various important entities.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Embedding based approach is working in a different way, so it's kind of computing a model.",
                    "label": 0
                },
                {
                    "sent": "Right and respecting all the entities, existing entities and relations, and then use it to track the new so.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you if you want to monitor incremental stuff.",
                    "label": 0
                },
                {
                    "sent": "I mean obviously that would be beyond the scope of this work.",
                    "label": 0
                },
                {
                    "sent": "There's one of the future things.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of interesting things that we could look into.",
                    "label": 0
                },
                {
                    "sent": "This is just one starting point to see whether actually you could make use of approximate reasoning to.",
                    "label": 0
                },
                {
                    "sent": "Do, you know, some meaningful detection?",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "Question is, how do you differentiate between fake sorry?",
                    "label": 0
                },
                {
                    "sent": "I'm here hi hi.",
                    "label": 0
                },
                {
                    "sent": "How do you differentiate between fake and perspective or opinion and also things that rely on of highly complex or long history?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's the kind of more details I mentioned in the second stage, right?",
                    "label": 0
                },
                {
                    "sent": "So in this stage you don't?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and as I mentioned to Steven, without having a useful explanation, services is really difficult to.",
                    "label": 0
                },
                {
                    "sent": "Two to three and debug such services.",
                    "label": 0
                },
                {
                    "sent": "Now what you what you could do is to see the precision and recall at this stage with small number of news articles we could we could do some.",
                    "label": 0
                },
                {
                    "sent": "Detailed study, but but explaining everything for the whole data set would be a lot of work.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the talk.",
                    "label": 0
                },
                {
                    "sent": "So one of the example I came across recently.",
                    "label": 0
                },
                {
                    "sent": "I was actually testing one of these fake detection services and it's very good in detecting things that are kind of commonly takes the pattern over fake article.",
                    "label": 0
                },
                {
                    "sent": "Like you know sharks swimming in the codes of yeah, but then it fails when something similar to that is actually true, like there was some waste resolved.",
                    "label": 0
                },
                {
                    "sent": "You know, got flooded into the water, you know something a bit extreme.",
                    "label": 0
                },
                {
                    "sent": "Yes, now I wonder what?",
                    "label": 0
                },
                {
                    "sent": "How do you think such an approach would work with cases like that?",
                    "label": 0
                },
                {
                    "sent": "Or what can we do to make it work with cases like yeah, so so when you do feature extraction, so typically you capture some keywords or sometimes if you really want to do it in a semantic way, some entities but but you know that you could turn a true news into failures by changing some of the relations, right?",
                    "label": 0
                },
                {
                    "sent": "Right, you have two right entities.",
                    "label": 0
                },
                {
                    "sent": "You change that the label of the relation.",
                    "label": 0
                },
                {
                    "sent": "Then you get around triple, so not considering the relation.",
                    "label": 0
                },
                {
                    "sent": "Would be a big mistake I think and and and somehow to some extent this embedding based approach actually consider both entities and relations together.",
                    "label": 0
                },
                {
                    "sent": "So that's why we think it might be a promising approach to start with, but you know there are a lot of other things that we could do.",
                    "label": 0
                },
                {
                    "sent": "On top of this.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}