{
    "id": "3cqs6zsh3zrvsh3q2ze5rxz2n5jowtfw",
    "title": "Dynamic \u21131 Reconstruction",
    "info": {
        "author": [
            "Justin Romberg, School of Electrical and Computer Engineering, Georgia Institute of Technology"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization"
        ]
    },
    "url": "http://videolectures.net/roks2013_romberg_reconstruction/",
    "segmentation": [
        [
            "So I'm going to talk.",
            "As the name suggests, I'm going to talk about solving L1 minimization programs to do sparse recovery, but kind of the twist here about we're going to look at is we're going to look at when things are dynamic, so things are changing, so we'll use the word dynamic in two different ways.",
            "So one is, like, you know, we have.",
            "We're sort of sitting at the solution to an optimization program, and something changes.",
            "Either we make a new measurement, or maybe the signal moves a little bit, or we want to change the functional slightly.",
            "So, like how do we quickly update the solution without having to re solve everything?",
            "So is there sort of a principled way for move to the solutions from one optimization program to another, like very closely related one, especially in this context of L1 OK, the other sort of way will use the word dynamical is to actually solve the ZL1 system, so I will get into this a little later in the talk, But basically will study sort of simple dynamical systems that settle to the solution of these L1 optimization programs of interest, and will do things like, say, like, OK, like how long does it take for them to settle, and if I know my solution is sparse.",
            "Will that help me increase my speed?",
            "OK, so two different ways to think about dynamics, but I guess you can use the word for both."
        ],
        [
            "Alright, so first let's just let me just give you a little bit of background because it really helps motivate.",
            "Like why I think this line of research is important and interesting.",
            "So I mean, this is the sort of standard Now standard kind of sparse solutions to underdetermined system equation problem.",
            "You know, I've looked at this problem a lot over the last 10 years.",
            "A lot of people have looked at this problem a lot over the last 10 years, probably thousands of papers on on on conditions under which this these systems can be meaningfully solved, even when they're under determined.",
            "And kind of the you know, the high level moral from this whole body of research is if I have underdetermined system equations it's still might be possible to solve it if my solution is structured, and so there's many different types of structure you might use.",
            "Will talk today about sparse.",
            "I'm sorry, does this sound?",
            "It's OK?",
            "OK, so I'll talk specifically about when XX the the vectors are interested sensing or sparse, but you know, there's there's other types of things you might be interested in to.",
            "OK, So what you could say is like if this matrix obeys certain properties, right?",
            "Then you sort of can meaningfully recover and stable recovered sparse vectors from underdetermined systems, so a lot of the people that worked on this problem myself, including they have the kind of their background in mathematical signal processing.",
            "So a lot of the language we use to describe what's going.",
            "John has this like a signal processing engineering twisted so you know we really think of this Fayaz modeling like some type of acquisition system, right?",
            "So we're really trying to sample this X, not.",
            "You can make all the entries of these wise the measurements right.",
            "Each one is like an inner product.",
            "It gets a different row of Phi and then you know we talk about sampling theorem.",
            "So how many rows of five do I need to make sure I recover Isaiah structure decks not from these measurements?",
            "Why right?",
            "If I go backwards I say OK, I can sample it at this rate.",
            "And be OK. OK so but you know in the end it's just."
        ],
        [
            "Now, underdetermined systems of linear equations alright, so.",
            "Would mean just what can we say about when we can solve them so you know if I have just the basic question of y = 5 X not plus noise, when can I stabili recover?",
            "That's not, so there's maybe a lot of ways you can start to answer this question.",
            "I'll show you just one.",
            "Interesting framework in which they answered, and it's nice because it really ties back into like you know, just standard linear algebra for least squares, right?",
            "So this this idea of what's called a restricted isometry.",
            "And So what this means is you know, assuming the columns of my matrix fire are normalized appropriately and it says OK. Now if I have any 2 S. Parsecs, what it says it does that applying Fi doesn't change the length of these two S sparse vectors to.",
            "So if this is true of my matrix 5, then I can do meaningfully do this inversion.",
            "And that's kind of nice.",
            "We can tie that back almost immediately.",
            "To OK, say I have, you know, a critically or overdetermined fi and I want to recover X not plus noise using least squares like when can I do that?",
            "Well, kind of fundamentally what you need is you need kind of all the singular values.",
            "If I'd be about the same and these would be well conditioned, right?",
            "That's exactly, you know what this says without this sparsity constraint.",
            "So you would be able to solve underdetermined systems.",
            "Of course we need something weaker since it can't possibly be true for all X.",
            "And So what we just need is this property to hold overall, say 2 S. Sparse vectors.",
            "Another way to think about it is.",
            "You know, if I think about a 2 S sparse vector as being the difference between 2S sparse things that essentially saying I'm sort of preserving all the distances between S sparse vectors and somehow if it's identifiable in the original space is identifiable.",
            "Once I look at it through fun.",
            "OK, so that's the sort of the condition under which this works.",
            "Or one of the conditions under which this works.",
            "I just put this one up 'cause we're going to get in touch on this, or revisit this later in the talk.",
            "OK, so how can you do it?",
            "There's actually alright.",
            "So first like OK, that's a condition on file like what kind of matrices had this restricted isometry property?"
        ],
        [
            "So a fact which was surprising to some and not surprising to others is that you can sort of get achieve this property somewhat efficiently just using a random matrix right?",
            "And so people from theoretical computer science will tell you.",
            "OK, that's not surprising because you know if you're interested in keeping things identifiable, we know that random projections preserve distances.",
            "If you're coming from the kind of land of signal processing we think about sampling signals, like taking inner products against random codes, it seems kind of bizarre at first.",
            "OK, but the point is is like if say you just have this matrix and you fill the entries full of random numbers, you can recover S for sex, not from when the number of rows looks something like the sparsity.",
            "So rather than needing like North System and equations here to find an unknown's you can get away with having S times log in right, so right?",
            "So the basically the complexity here scales something like the complexity of the signal.",
            "Rather than kind of this, the intrinsic dimensionality.",
            "OK, so there's that one thing that now domain.",
            "How do you do it?",
            "It's not like you do this inversion by applying a pseudo inverse to the other side.",
            "There's many different approaches, will focus on ones using convex programming.",
            "These convex programming, different types of greedy algorithms.",
            "Iterative thresholding algorithms are actually almost the same at this point.",
            "We are methods, a complex program, etc.",
            "OK, so the way you know we'll look at it in the way we might understand the best out of all."
        ],
        [
            "Loose is spy.",
            "You solving.",
            "You know when everything is real linear program basically right?",
            "So what we say is OK look, I have these measurements why I want to get back to this original vector XI know what this matrix is so I know that basically just need to consider all say the vectors X which obey this set of linear constraints and all of those you know, since my model is things being Sparks, let me choose the sparse right and So what we use instead of this parses this proxy for sparsest L1 norm.",
            "It's, you know, even though it's a proxy and kind of a convex relaxation, it's actually probably effective in the sense that you know for exactly kind of the same range of M in relation to SNN.",
            "Say, if you observe a perfectly sparse signal that's noiseless, you can prove that this thing will recover the signal exactly like you really do have a sampling theorem.",
            "The sense that if I observe a perfectly sparse signal through this matrix, I can recover it by solving this program and the you know, as everyone knows once.",
            "Actually, Steve Boy was saying for once you sort of set something up and and the framework where people have worked for, you know 20 years very hard how to solve these problems then you know you've done something.",
            "OK, so that's that's what we say.",
            "So another thing we might say is, OK, look this works are sparse vectors.",
            "It takes no imagination at all to say, OK, you know sparsity.",
            "I can change what I mean by that.",
            "I can be sparse and I only have a few nonzero entries, can be sparse, and that there's some other ortho basis I can't transfer."
        ],
        [
            "On my my signal into, which is sparse, that's all that does.",
            "I mean, all that affects is sort of composing your measurement matrix with some ortho transform over here, and only that like this can all be kind of made robust to noise, right?",
            "So if we"
        ],
        [
            "We have some noise added into it.",
            "You know?",
            "We can basically turn this, you know, go from these sort of equality constraints into this sort of more relaxed version.",
            "I guess when people call this either basis, pursuit, denoising or L1L2 or the OR the last.",
            "So even though it's more like kind of LaGrange form of the law, so anyway, so if we solve a program like this, we actually have guarantees about.",
            "OK, if we have so much noise I can actually recover a sparse signal or signal which is almost sparse to some error bound which.",
            "Makes sense, it scales like the noise level and to the degree I can approximate my original signal with a sparse signal.",
            "OK, so this is, you know.",
            "Again, the type of program are interested in something, so let me just one second one minute just because there's such a varied audience, say why.",
            "Like sparsity.",
            "OK, that's one thing the Nobel Prize vectors, but is really important from the context implies the model we use."
        ],
        [
            "All the time.",
            "So it was just a quick example like here's a four megapixel image.",
            "Here's a say, a one to one ortho transformation.",
            "It's called a wavelet transform, right?",
            "And basically what you could see it this way, which answers most of it's blue.",
            "That means most of the coefficients are small, right?",
            "And so another thing you see is like where we get these big wavelet coefficients.",
            "Those are along the edges of the image, right?",
            "So actually what kind of The upshot of this means like, OK, like most of these can be very well approximated by zero, so 11."
        ],
        [
            "Consequences that is like if I just throw away 99% of the smallest coefficients, I get almost the exact image back from the second thing.",
            "It's like we know that.",
            "So in some sense we can say like things that are piecewise smooth.",
            "They're going to have sparse wavelet transforms, but kind of interesting thing.",
            "Really makes it like appropriate for this comp."
        ],
        [
            "Sensing model is the sparse coefficients even though will only be a few, they'll be in different places every time because again, it depends on what the edge structure is in the image.",
            "So we have this model of wanting to sort of model something is sparse, but not like a low dimensional subspace.",
            "For sparse, like there's a small number of active coefficients.",
            "I don't know which ones.",
            "OK, so that's why we value sparsity, 'cause it allows us to sort of take very dramatic first steps towards doing things like image compression or estimation in the presence of noise or.",
            "Feature extraction and things like this OK.",
            "So."
        ],
        [
            "So once you kind of combine this idea of sensing and sparsity, right?",
            "So what kind of The upshot of this this line of research is, or like what a lot of the motivation was.",
            "OK, and now if I have an acquisition system, I can sort of get away with taking a small number of samples.",
            "If you somehow inject some kind of randomness or diversity into the acquisition process.",
            "So like, here's a good example of where this one.",
            "So this is what's called a hyperspectral image, so it has a lot of pixels, right?",
            "But each sort of end.",
            "It's a series of images, each with a lot of pixels, so each image.",
            "Is basically the response of some field to like a very narrow set of wavelengths of light, so very narrow band of light.",
            "So I collect this over several bins, right?",
            "And so you know what this is saying is like instead of having to take a measurement or sense something at every single pixel at every one of these different wavelengths could be hundreds of wavelengths and millions of pixels.",
            "But if I can instead, like somehow combine different pixels in wavelengths together, again using some kind of global and diverse code, but perhaps get away with many, many fewer of those.",
            "I said no, so it's like you're integrating the compression into this sensor, right?",
            "And so the similar thing is true with.",
            "Another scenario, so here is like a typical RF signal is really just the time frequency representation of a signal taken off mantenna, so you know you know if you're just going to plug this thing into analog to digital converter.",
            "You might have to sort of classically have to sample a twice whatever this maximum frequency is, right?",
            "But if you can do something before that ADC, like, say, take the signal, branch it off into different branches multiplied by random codes, integrate over those results, and then sample right?",
            "You could probably get away with a smaller total sampling.",
            "Right and then other systems like MRI.",
            "It's actually the savings are much clearer.",
            "It's like OK, I just have to take fewer samples in the MRI machine, work my way out in frequency and just correspond to regulated spending less time.",
            "OK, so that's you know that those have been the games alright.",
            "So now what?",
            "You know?",
            "What's been kind of interesting how long researches?"
        ],
        [
            "You know, in some way it's OK.",
            "I have now I have this data and if I want to reconstruct the image I can sort of say OK.",
            "Here comes the data into my optimization program.",
            "It's input.",
            "I run this optimization program.",
            "I get my output image or signal out that's a bigger vector and then I sort of move all right and then when that works and that the motivation for that and the model for that is all perfectly clear.",
            "Kind of in the context of linear algebra like y = 5 X right.",
            "But there's a big sort of slice of signal processing that's kind of thinks in a completely different framework.",
            "Are you don't really think of in terms of y = X you think in terms of filters, kind of.",
            "The first thing you learn when you're in signal processing you think of like just reams of data coming into a filter which you multiply and add together, and you get a different data stream out right?",
            "And all that's done very much in mind from the beginning of I'm going to just have constant data streaming in an constant data streaming out.",
            "OK and so So what we're trying to do with this dynamic stuff, and you know, taking poking at it from a few different directions is trying to put it more this Ellen Research more into this filtering framework, right?",
            "So instead of just having Y in solving optimization program and getting something else out and not being the end, it's like we want to solve it.",
            "It's a whole series, so these optimization programs, and maybe the data is changing in such a way that we can model.",
            "And maybe we can link together those optimization programs in such a way that maybe.",
            "Either they are easier to solve or we get some gain from doing that, right?",
            "So we have almost in mind that sense of like an L1 filter like things are streaming in things are streaming out and then sort of the relationship between these two sides is something like, you know, plugging in why here and having that map to the output.",
            "OK, so you know in another way this kind of another way to look at big Data.",
            "We might not know.",
            "I mean, I happen to also be interested in solving problems, but I might also not be interested in solving big ones, but solving say many many many small problems.",
            "Many times a second.",
            "Oh, OK, so that's that's kind of, you know, kind of what we have in mind.",
            "So again, we'll look at like kind of two ways to think about this.",
            "One is really this idea of.",
            "OK, I'm going to solve a series of optimization programs.",
            "How can I quickly go from the solution of 1 to the solution of the other?",
            "And they all sort of all rely critically on the fact that they have this form, and the 2nd way is actually I have a dynamical system which Maps continuous time inputs to continuous time outputs, right?",
            "And so how do I sort of if the input stay steady?",
            "It's a it's solve this program like how do I characterize how long that takes a set of first step and understanding?",
            "That type of continuous time system.",
            "Or like L1 filter if you will.",
            "OK so first right?",
            "So that's essentially here, so this fast."
        ],
        [
            "Getting a solutions.",
            "This is work.",
            "You know my student, so I want to see if we just got his PhD.",
            "You know, we worked together over a sort of a series of years about this and this systems of nonlinear differential equations that solve L1.",
            "This is with the student that another professor at Rice, who's actually idea about this dynamical system was Chris Roselle.",
            "We share a student or elevon who's who.",
            "See the results here.",
            "OK, so first for the, for the.",
            "Fast updating of solutions of owner question.",
            "So let me just."
        ],
        [
            "You know, plug back into sort of an area you know signal processing or just applied mathematics.",
            "Where were the kind of characterize is what we want, right?",
            "And so let's just sort of look at this classical like least squares problem.",
            "OK, so I've overdetermined system equations I solve least squares so close form through that I just apply the pseudoinverse on the left, right and so if the matrix is small enough you know.",
            "Maybe if I can compute this once I could just store it in memory, then if I get new data it's not really a big deal, I just apply it to the new data to get my new estimate.",
            "But you can also do things like if you add a measurement gets added right.",
            "So say I have a least squares."
        ],
        [
            "Solution for y = 5 X and then I learn something new about X, right?",
            "So in this case I'm just adding a single row to five and get a single new measurement right?",
            "And so then OK, what's the new least square solution?",
            "Well, this is now the system I want to solve right, but we know we're saying is like.",
            "Here's a matrix have already inverted, right?",
            "And they want to add a rank one matrix to that, so that's sort of well known how to how to do these type of updates.",
            "And in the in numerical numerical linear algebra, right?",
            "And so sort of a convenient way you can write.",
            "The solution which kind of brings out what's going on here is, you know, by by playing around with.",
            "Again, identities from linear algebra sort of rewrite this as my new estimate is my old estimate times you know what's called some some gain matrix and the difference between, say, the residual of what I measured and like what I predicted.",
            "I would measure given my old estimate, right?",
            "So like this new measurement, W matches the measurement.",
            "You know I would have had with my old estimate exactly this should be X hat X, not had X not here.",
            "Then I do nothing.",
            "I just keep that same estimate right?",
            "If it's consistent, it's consistent.",
            "Now and I move on, but if it's not, you know what I do is I take that residual.",
            "I pass it through a linear system, right?",
            "And so the with the neat thing is here is like.",
            "Basically we can write this as sort of my old inverse, just applied to a vector, in this case a single vector, in this case and so here we hear what it's saying is like instead of having to solve a new system of equations, all I need is a couple matrix vector multiplies and I can move on and then there's.",
            "You know there's also formula for updating the inverse here and so I can repeat this as needed.",
            "And also if I instead of seeing 1 mission I see many.",
            "You know you can sort of incorporate them all at the same time as well.",
            "OK, so that's that's one example from kind of again, classic sort of sequential estimation, yeah?",
            "Hey there, so this so in this case the file is over determined.",
            "The bigger the big fire, and then this the last one is just wondering which is the single measurement.",
            "Well, OK, well we'll get we want it to be there when I'm just talking about this is like in the classical overdetermined set, right?",
            "So yeah, so we'll talk about.",
            "So we're going to one of our goals is to extend this idea to underdetermined systems, but with L1 regularizer attached to it.",
            "So yes, so I'm trying to undo trying to set the tone saying you can do this for least squares.",
            "So another thing you can do with least squares, something another that thing that's very classical was."
        ],
        [
            "Kalman filter, right?",
            "So that's the idea where is not only do I have measurements streaming in all the time?",
            "The signal I'm trying to estimate is also moving around all the time, but it's not moving around arbitrarily.",
            "I have a model, a linear model from how it's moving from time to time instance.",
            "So what that allows me to do is a sort of allows me to connect together.",
            "Different optimization programs to get some gain basically right, and so if I just write down OK, like look at each time is since TI see some observations of X.",
            "These say could be either underdetermined or overdetermined in this case, and then between T and T + 1.",
            "My ex moves, but it moves according to some linear way or some up release approximately that I that I know.",
            "OK.",
            "So then if I sort of want to get an estimate for X at all these different times.",
            "I just again, it's just sort of a big linear system, so I can just again think of it as a big least squares problem.",
            "And because of the structure of this linear system, basically it's you know there's only only see terms on the diagonal here and one things up right directly, but to the to the left of the diagonal there is again a fast way to do this, so it's a little more complicated, right?",
            "But basically what you say is OK, look, you know, given my current estimate, I can guess what the next estimate should be just by applying my linear model.",
            "Right and then I do the same kind of blow up low rank, updating chicken then basically say is like OK, my new best guess from what's going on at time K plus one is again you know I take this this prediction that I made apply this measurement matrix and then I just have some gain matrix operating on that residual right?",
            "So again this is one of the sort of fundamental tools in applied mathematics and it's really again really just about updating here.",
            "At least squares solutions as as measurements rolling.",
            "OK so is these two types of things that?",
            "We're kind of after in.",
            "Ah, but it you know we want to do this again in the context of L1 instead of L2.",
            "OK, so."
        ],
        [
            "Here is the kind of the the."
        ],
        [
            "The main framework we want to look at for, so I have this optimization problem is a little different than the one I just showed.",
            "You have minda WX here, W is just.",
            "It's a diagonal matrix that has positive entries along this diagonal.",
            "So if those were all just equal to Lambda, so they'll be like Lambda times the identity.",
            "This is exactly this loss over talking about, but maybe you want to favor some components more than other components.",
            "I'll just sort of allow that flexibility.",
            "And then you know what we want to do is say, OK, let's say we're sitting at the solution to a program like this.",
            "And then something happened.",
            "So where do we buy something?",
            "So say maybe we add or remove a measurement from file.",
            "So I observe a new entry just like in recursively squares.",
            "How do I update this solution to this so the underlying signal changes a little bit, right?",
            "So if it changes a little bit, how do I again sort of quickly update the solution?",
            "Again, trying to use these ideas of efficient low rank updates or say like the weights change so I have no reason to believe.",
            "That maybe I want to favor some of my entries more than others, so I changed the weights how to again avoid solving things from scratch.",
            "Or again, more of this kind of linear dynamical systems model where I have sort of streaming measurements from a signal which is evolving right.",
            "So now I have a kind of like a series of optimization programs, but there's they're all linked together right there, linked together because you know they're getting an estimate for something later really tells me about something which happened earlier on.",
            "OK, so as these types of things we want to alright, so the sort of we can sort of attack all four of these using the same type of trick that Rick starts just by writing down what the optimality conditions are for solving this program.",
            "OK, so here is unconstrained optimization program.",
            "We can kind of find optimality condition."
        ],
        [
            "So here is the sort of set of optimality conditions, basically like a recasting of the KKT conditions.",
            "I mean essentially how you compute what these optimality conditions are.",
            "As you say, OK, look for to be at optimal point.",
            "I need zero to be in the subgradient of this thing.",
            "I mean subgradient mean, since since this WXL one it's not a smooth like a piecewise linear thing, so it's not differentiable.",
            "So you can think of a sort of a gradient as being a supporting hyperplane out of point.",
            "So when you have like a kink, maybe there will be a lot of supporting hyperplanes.",
            "So we're all we ask is that like sort of the 0 being the subgradient of this thing?",
            "And So what?",
            "That means this fact that you have multiple supporting hyperplanes, I get sort of a system of equations, linear equations.",
            "In this case my solution has to obey on the support and then sort of a system of linear inequality.",
            "So it has to be off the support.",
            "OK, so well, let's just look at what this depends on this, right?",
            "So I know that if X star obeys these conditions right then it's then it's a solution to a solution to this optimization program.",
            "So what's interesting about this several things.",
            "One is, you know if I collect kind of these linear constraints over all elements of my support, right?",
            "So first, like what are these depend on?",
            "They did?",
            "You know they depend on the support, right?",
            "So this gamma star is the locations of the active coefficients of the solution.",
            "And these these are like the signs of the location of the active coefficients of the solutions.",
            "OK, so then what?",
            "But once those are determined essentially what I have is I have a system of linear inequality's for X star on the support, and again a system of linear polys office support.",
            "This is the fact that you know the I have these linear equation was going to allow me to say OK you know as things change a little bit how does this solution perturb into its new one and the fact that this is sort of a linear system equations on the support it kind of means that this solution?",
            "Well it doesn't move linearly from one solution to the next.",
            "It takes a piecewise linear path and only takes a piecewise linear path that we can trace.",
            "Uh, relatively quickly.",
            "So let's just look at one simple example of this."
        ],
        [
            "Yeah yeah, it's diagonal and positive.",
            "It's basically like just some WK absolute values of X.",
            "It just for compactness, right?",
            "Like that?",
            "OK, so let's let's just look at 111.",
            "Example of that will illustrate tricks.",
            "OK, so we observed Y 1 = 5 X one plus some error.",
            "Alright so we say OK, fine, I'm going to estimate X solving the lasso.",
            "So I solve it and I'm sitting at my solution X1 hand.",
            "Right now new set of measurements arrive.",
            "Why two now?",
            "I want to solve this new.",
            "Now one optimization problem.",
            "OK so I have the solution to this.",
            "And I suspect that X1 and X2 are close to each other.",
            "That's just my model for what's going on.",
            "So the idea is like how, instead of like sort of resolving this, how can I just sort of map the solution of this under the solution of this?",
            "And you do it using this kind of standard trick called homotopy, where it's like what I do is I slowly transform this optimization program into this optimization problems by introducing a parameter, right?",
            "So what I say is OK, look what I'm going to do is.",
            "I'm going to put both sets of measurements in here, but I'm going to multiply Y 2 by epsilon Y 1 by 1 minus epsilon.",
            "Then move epsilon from zero to 1, so that's going to fade out.",
            "These and bring in these.",
            "OK, so that's I mean, it should be clear that epsilon equals zero.",
            "You know we're sitting the solution here, and if we solve this for epsilon equals one here at the solution here.",
            "But the point is is like as we change epsilon, this trace is out of."
        ],
        [
            "Path of solutions and it's a path that you know we can actually move along and predict.",
            "So why can you do that in half?",
            "So it's actually pretty easy once you just write down the what these optimality conditions are.",
            "So here's you know, for any fixed epsilon you know, here's what my optimality conditions look like.",
            "They're exactly the same, just with these two different wise.",
            "But you can see OK Now if I just perturb epsilon a little bit, right?",
            "I know that you know this.",
            "Again, there's this linear system equations on the support, so if I change epsilon just a little that support or the science of this on the support doesn't change.",
            "So if I change epsilon just a little, what can I say?",
            "OK, look the direction I must have to move.",
            "As epsilon say increases, is this.",
            "It's basically I just looked this.",
            "I increment exit and look at the difference between those two, right?",
            "So I move along this direction so it's basically the difference of the measurements, but then suck through this matrix.",
            "So this matrix is over determined.",
            "So what Phi Gamma is?",
            "It's fine, but I pull out the columns that correspond to the set gamma, so it's going to be over determined.",
            "So this.",
            "Inverse exists, So what then?",
            "So then essentially is OK. That's the direction I want to move, and then the idea is I move along that direction until something changes right?",
            "And so I know that the only time like something meaningful happen is if, like I'm moving and say one of the things that was active in my support leaves, it gets set to 0 right?",
            "Or the other thing that could happen is I'm moving and one of my constraints off the support one of those constraints becomes active, right?",
            "So basically one of these bump up against land, right?",
            "That means something new wants to enter the support.",
            "Right, so once I wanted to do is I move until one of those things happens, right?",
            "And then what do I do?",
            "I have to adjust this this game.",
            "So what is adjusting?",
            "Gamma reason was either it means either like adding or subtracting, removing a row from gamma.",
            "So again I know how to do that very efficiently using low rank updates and then only that.",
            "Just because these are linear."
        ],
        [
            "Linear inequality's I can actually if I'm sitting at this point here, I can very quickly calculate units ordered or whatever N operation.",
            "What the size of the next epsilon needs to be to get me to the next kink, right?",
            "So it's basically just just yeah against 'cause because it's this varies linearly with epsilon.",
            "OK, So what I do is I say OK, I said at this point I figure out what direction I need to move, figure out how far I move there to get to the next King Point.",
            "The cost of this is a low rank update, so a couple.",
            "Vector matrix multiplies and then I just repeat that process right?",
            "And so hopefully if X2 is close to X1, it won't take too many links in this chain.",
            "OK, so that's that's one thing we do.",
            "So here is just couple of expr."
        ],
        [
            "Elements to show that you know, sort of semi realistic situations.",
            "At least this number of paths is very manageable.",
            "In fact so manageable that that you beat state of the art solvers easilly, that even have a warm stuff.",
            "OK so here are just a couple examples we use.",
            "So here is like versus synthetics poor signal.",
            "And then at every time say we change like maybe I think it's some percentage.",
            "Maybe it's 5% of the entries so we take out 5% and that in.",
            "Another 5% just chosen at random.",
            "Here's another example of what we do is we have a 1 dimensional signal, so a series of 1 dimensional signals which we measure through a matrix Phi, but with those one dimensional signals are there just slices from this image, right?",
            "So you'll have sort of periods were not much in the signal changing, but then you hit a discontinuity, right?",
            "And so if you would like to again, say, look in the wavelet domain, maybe a lot of wavelet coefficients become active and then they move around slowly as you move down the image etc.",
            "OK, then you do stuff where you have.",
            "Say splines and you move the knots around, or maybe oscillate the polynomial parts between the splines.",
            "So again, you know if you look at wavelet transforms of these things, essentially what you're doing is the wavelet coefficients are moving around and they're moving from side to side a little bit, either as the singularity's movers, things become sharper around the singular OK, so if you do experiments like this, I mean what you can kind of say."
        ],
        [
            "Is.",
            "You know you can measure performance in two ways.",
            "Maybe this blue way is more indicative, so this is basically the average number of vector matrix multiplies we needed to do.",
            "Do it, do an update and then you compare it to like L1 solvers which are say starting using as a warm start.",
            "The previous solution and you can beat them by a factor of three or four.",
            "We also have the CPU times listed here, though again I think like you know, just because of the implementation issues.",
            "I mean, this is this vector multiplies really are what dominate the implementation calls.",
            "So I think if this was done very carefully you know this is really how you would expect the performance of the scale.",
            "OK, so that's that's one set of examples.",
            "So that's the single moving it is.",
            "Again, it was very simple, and so we did."
        ],
        [
            "Write down the optimality conditions and move from one set of measurements to the next.",
            "OK, so there's.",
            "You can play a similar trick, but you know in a slightly different way, so now say instead of the thing moving, let's say I add a measurement to my system, right?",
            "So I'm sitting at the solution to this program.",
            "And let's say I get one new measurement to this matrix.",
            "This matrix Phi solution should change.",
            "How do I update it?",
            "And you do sort of exactly the same thing, so I said OK here I have this.",
            "I want to add this term in.",
            "So basically I just put an epsilon in front of it and I just meant that from zero to 1.",
            "You can again write down what the optimality conditions are.",
            "Again they just depend on just as before.",
            "It depends on what the support of the."
        ],
        [
            "Signal is what the science sequences on the support.",
            "So again, as I change this epsilon again, moving in this piecewise linear manner as things enter and leave the support and I'm doing low rank updates to compute what the directions are.",
            "OK, so given that you know we can again run an A."
        ],
        [
            "Set up experiments an if we sort of measure the average number of matrix vector product for update.",
            "Yeah, it's not too important what these things are, but it's like in the real scenario.",
            "Again, what we see the same type of thing where you know if we look at the number of major Spectre multiplies, we need it.",
            "In this case, maybe beats it between a factor of like two to five or something like this, OK?",
            "So then finally, there's just one other thing I want to mention before we go."
        ],
        [
            "So like the real good generalization.",
            "So we have these two tricks, one for the the sort of signal, the signal moving around an one is for adding a new measurement in, and there's another thing we might like to fact is done in practice, and that's maybe just change the weights of the sink so you know there's there's a practice.",
            "At least you can get a lot out of, say you know if I solve L1 once.",
            "Once a uniform set of weights, I put Lambda everywhere.",
            "So if L1 and then I kind of see which ones are big.",
            "Right and so then I say, OK, you know, maybe my I didn't estimate my small coefficients very nicely, but if I can now solve this again, but increasing the weights on, you know the things that I'm sure are there, maybe I can start to pull out some of this.",
            "You know, less important stuff.",
            "So in practice I mean this is pulled directly from from this paper.",
            "You know if you have problems.",
            "So this is basically three modulated pulses sitting on top of each other.",
            "So problems were like L1 just doesn't work very well at recovering the signal, but if you run this reweighting scheme.",
            "You can, yeah yeah yeah, get a much improved estimate.",
            "OK so, but the point is, is the point is you want to solve this program.",
            "You're getting a series of solutions and with how you want to change things, you want to update the weights from one program instance to the next so you know I want we can skip the details here.",
            "So again, you do exactly the same thing you do."
        ],
        [
            "Work from 1 system of weights to the next.",
            "You know, look at the optimality conditions.",
            "Compute what the update direction must be, and then again moving that move move.",
            "And yeah, moving that direction till something changes, either something leaves us support or or comes in OK. And so again you know if we look at results."
        ],
        [
            "You know, again, we sort of compare how many matrix vector multiplies we need as compared again taking like a sort of state of the art L1 solver and giving it a warm start of what the previous solution was.",
            "And when you map these things out for just a series of different experiments.",
            "So these are sort of related standard recovery problems.",
            "Where to say the number of measurements versus the M versus and so the number of rows?",
            "There's a number of costs.",
            "Columns in the matrix is taking different proportions.",
            "Again, it's it's the same sort of thing where the number of matrix vector multiplies we need.",
            "In this case, maybe even a factor of 5 to 10 less than using other soldiers.",
            "OK, so.",
            "Ah.",
            "That's good, although it doesn't quite give us get us all the way there.",
            "Right and so."
        ],
        [
            "All of these these kind of ideas that we talked about, they relied sort of very critically on being at the, you know, X where I'm starting from being the solution to one optimization program and then translating that into the solution of another optimization problem.",
            "So what's actually really difficult to do, and it took us awhile to figure out, is to get it like basically this idea of a Kalman filter inside this framework, and here's why.",
            "So when you're again when you have this kind of dynamical systems update, so again, the idea is you're trying to estimate vector, but the vectors changing at every different instance, right?",
            "And you again you have some idea about how The thing is changing, But the problem here is like what you're doing is you're kind of adding and removing columns instead of rows from the matrix.",
            "OK, so really you know what we like is we sort of know how to do things like this where we have say a guess and we want to update from the guests in the least square setting.",
            "So the idea is like how can we just get take that general idea and like map it to a homotopy problem.",
            "So basically here I have a guess given again I take my old estimate, apply F to it and then I sort of work with the difference of my guess.",
            "You know from what I consider consistent measurements work with that to to get my new Western.",
            "So it's more like you know what we want is rather from moving from one solution to another one.",
            "Can we get a sort of a general warm start and it's a warm start that might come from a prediction and then trace the path from that, and that will kind of give us the last sort of ingredients in getting to know what a true streaming system is."
        ],
        [
            "And so the idea is actually pretty simple and you can actually take it and it can encompass all these other things that you know that we talked about earlier and actually does so even a little more efficiently.",
            "And once you see what you just say is this, it's like OK look, I have.",
            "I want to solve say this system so I have, you know, some optimization problems.",
            "So this is like the new program that I want to solve and I just have an initial guess or prediction will call V. So what you can do is say OK, look what I can do is I can choose this.",
            "You according to V and the way I choose this year according to these when I said epsilon equal to 0 here like I have this sort of new optimization program which V is the solution to and then I just again change epsilon.",
            "Up to one.",
            "OK so EU of course is chosen in relationship to be very carefully right.",
            "So it has a couple of nice properties right?",
            "So it's not there."
        ],
        [
            "Something we made up, so the first property it has is again, you know at epsilon equals to zero.",
            "With this choice of UV really is the solution to this program, so we are still just kind of changing solutions of optimization programs.",
            "But then also it has this property.",
            "OK look, you know if I have a prediction V and my measurements are consistent with VI, don't have to do much.",
            "Actually it's you just sort of used to sort of updating on the support when you do that.",
            "Oh OK, so it has a nice consistent.",
            "So basically like you know, if you you can get away with just correcting the support like this program will do that.",
            "And also if this residual is small.",
            "Basically it's sort of.",
            "It just looks like kind of adjusting the solution by thresholding almost OK.",
            "So I mean we don't have to go through it anymore.",
            "It's like you know, you sort of again, write down optimal conditions, conditions, figure out the direction you have to move, and then do it.",
            "OK.",
            "So then what we?"
        ],
        [
            "What this allows us to do now, is there like really do streaming systems right?",
            "So here's just one example of the Leica compressed sensing streaming system, or interested in doing this type of recovery so.",
            "We had this DARPA analog that information project, So what the details of this project aren't that important?",
            "But essentially what it boils down to is you had like a radar signal coming into a receiver right in the radar signal.",
            "I did pretty high bandwidth, so something on the order of a couple of giga Hertz so broken into several channels, and then you did this kind of idea where you sort of randomly modulate the signal in each of these channels, and then you sort of integrate, and then subsample the result.",
            "So the idea here is I have kind of a signal which I might have a model for.",
            "And you know what I'm spitting, as I've receiver that spitting out samples of this signal at a high rate, right?",
            "So it's not like there's sort of a start time and a stop time to what's going on here again, it's just sort of like these measurements are streaming by, and in this case they're shooting by a fairly high rate.",
            "OK, so then."
        ],
        [
            "You know what do we want to say?",
            "If we have a signal which looks like this?",
            "So this is maybe a collection of chirps.",
            "There's lots of ways you can sort of build a good representation for these types of signals by sort of windowing them time and taking Fourier transform.",
            "So lots of sort of local Fourier transforms this particular one I'm showing you is a lap orthogonal transform, sort of very carefully designed, so like projections inside each of these windows are actually orthogonal to one another.",
            "But basically you know what this means.",
            "If I have something which looks like this, it becomes very sparse for each moment in time.",
            "When I look at it through this transform.",
            "So the idea is like one sparse reconstruction for measurements like this, and you know in this basis."
        ],
        [
            "OK, so when you sort of set this up, I mean what you might have in this system you might have like slightly overlapping or even this even can't even block diagonal types of measurements, so there's sort of whole window of time I want to do the reconstruction over and then I have sort of overlapping bases right?",
            "And So what the point of this is I have kind of a series of optimization programs in substance, but they're sort of all linked together because they overlap.",
            "OK, so the goal here is like I'd sort of knock something off the edge of the window, brings something new in.",
            "How do I update the solution and so you can do this by taking care of the edge effects in the appropriate way and then bike again.",
            "Just setting up this this homotopy algorithm and so you know again, and in doing this what you're doing is just kind of making a prediction about what comes next.",
            "If you don't have a model, you might just predict you know whatever the last sort of."
        ],
        [
            "Or set of coefficients you are and then you're correcting your just correcting by bringing epsilon up from zero to 1 and we know them.",
            "By doing that, you're just doing a series of lowering updates, and if your prediction is close to signal, it will be a small number.",
            "So for like signals which look like this again, you see tremendous gains.",
            "So if you look at like the you know the NUM."
        ],
        [
            "Or of a matrix vector multiplies you need, you know, actually this is over the course.",
            "The entire simulation here.",
            "Maybe we needed like 10,000?",
            "Or is if you looked at again, L1 solvers with a warm start, it might have been like five or six or even 10 times that.",
            "OK, so then another thing you could do, almost by by not doing much.",
            "Once you have this framework in places you know.",
            "Again, this signals are moving, but now you have a model for how it's moving, so you have this kind of Kalman filtering set up again over a sort of an entire sequence of Windows.",
            "What you'd like to do is solve what looks like a series of independent problems, but."
        ],
        [
            "Kind of linked together through the dynamics of X, so sort of since X is moving away around their predictable way, like learning about access to later time tells you about, you know what it should have been at an earlier time too.",
            "So again, we drop measurements off, add them on, and then correct using this homotopy and you know this just this plot we always did was sort of take a sparse signal and shifted around unpredictably and then."
        ],
        [
            "Monica looked at like what was the difference between using the like, the sparse regularization and just the standard?",
            "I'll call my filter and you get, you know some again there like just as you would expect you would.",
            "But then more importantly, I mean when you."
        ],
        [
            "Sort of use this this low rank updating framework.",
            "You tend to be just warm starting a regular solver by again less significant factor, like maybe five or six here.",
            "OK, so that's the.",
            "What all will say about moving from one optimization program to the next?",
            "So to end here, I just want to mention a little bit about the other kind of way of thinking about dynamics right now, just."
        ],
        [
            "To motivate this very quickly so there's kind of a movement."
        ],
        [
            "In a.",
            "And signal processing kind of getting going back to the future.",
            "So back in time, 30 years where people are starting to revisit analog signal processing systems right?",
            "And so the way the computational model these things is completely different than what you would use to build a register or arithmetic unit on a computer, right?",
            "So they use transistors, but they use them like not as being on or off switches.",
            "They use them in this called this like subthreshold regime, right?",
            "And So what this does is it kind of.",
            "Using this kind of nonlinear map from.",
            "So let's just say between like the expectation current and what comes out.",
            "You kind of allows you to do operations in this log rhythmic turn, so we kind of what The upshot here is like.",
            "You know, you can do big computations using fewer transistors, and only that, since you're sort of operating them in this sub threshold regime, they burn much less power.",
            "And So what?",
            "You can kind of think about this is at the end of the day is, you know I have a noisy computer, kind of has all the problems that analog circuits always have.",
            "But it's very fast and it's very little power, so maybe I can do computations with the precision of 10 to the minus two, and maybe I can build a much smaller circuit that runs at much smaller power.",
            "Doing that, and there's some actually tremendous small scale successes.",
            "Doing things like this, so there have been booked both companies and research projects that have you had have used circuits like this to do so, like beamforming in hearing it, right?",
            "So basically you're doing you're doing LMS, so finding weights the null out noise sources.",
            "I was also a company that used technology like this to do error correcting codes for flash drives, right?",
            "We're actually we have a lot of the lot of the same structure you have for these.",
            "Ah, convex optimization programs.",
            "OK so, and there's even people that I can claim they can do image processing.",
            "Well, that's a lot of what's frustrating about this work is sort of exists in the context of a bunch of startups, so there's like this published realm of material and there's stuff that different startup companies claim they can do OK.",
            "But anyway, if like we are to.",
            "I believe you know that a lot of this stuff can be scaled.",
            "You know what the account would kind of allow us to do is is like we could you in theory implement kind of a very simple system, which is basically just involves vector matrix multiplies and like small nonlinearities that you know if you think about taking analog input, I would have an analog output where if I kept the input still it would settle to the solution of different optimization programs.",
            "In fact, that idea is kind of not not new, I mean a lot of people.",
            "Say I don't know in the 80s built small circuits which could solve, say linear programs or or quadratic programs.",
            "I guess Hopfield was kind of the director of this research, so I mean at the end that idea."
        ],
        [
            "You know, at the end of the day, kind of where you're getting the gain is just like a digital multiplying Accumulo vector matrix multiplication, right?",
            "So you can build an analogue vector matrix multiplier.",
            "That's 100 inputs, or 100 outputs, or even a couple 100 inputs.",
            "A couple of 100 outputs, but it works with the bandwidth of like 100 megahertz, right?",
            "So maybe doing 50 million of these operations per second effectively and you're doing it?",
            "You know using very, very little power in milliwatts of power, OK, so.",
            "Ha."
        ],
        [
            "What can we?",
            "What does that mean in terms of solving L1?",
            "Actually you can sort of write down, you know, either for the lasso or even a more general type of optimization program.",
            "You can write down a set of of nonlinear differential equations that.",
            "That that's settled to these things.",
            "OK, so since I'm running out of time, let me just talk kind of.",
            "More generally, you know about what we have for.",
            "Analysis, and so like what we've done here.",
            "Say OK, look.",
            "There's actually a simple kind of normal now."
        ],
        [
            "Work architecture right?",
            "And it really just consists of.",
            "Here comes the input right then what I do is I have a state, it gets fed through activation functions.",
            "These are in the context of the one.",
            "These are basically soft thresholding and then I feedback.",
            "The feedback, so this is basically 5 transpose 5, So what this looks like is essentially like a continuous time version of iterative soft thresholding, except everything is running continuously.",
            "OK, so system like this, you know, really falls under the realm of these these these analog circuits people think they can build something like this to scale.",
            "So the question is like we just want to get a feel for how this thing behaves.",
            "So in other words, if I'm trying to recover something sparse, how long does it take me?",
            "So let me just talk about a few things we can set.",
            "OK, so first thing you know, you can very quickly figure out what the relationship between this."
        ],
        [
            "Function you want operating on each thing and what this activation function.",
            "So if like you want this to be L1, you know this each of the sea of UN.",
            "It looks like absolute value, and so you're essentially taking the derivative of what's going on here.",
            "So let me just point out here that like you know, there's sort of a lot of work in dynamical systems about how solutions to these systems of equations behave, but like a lot of like what makes what we did complicate it was the same thing that makes it gives you complications and standardizes things back to.",
            "Things are not continuous, not differentiable, and even unbounded.",
            "In this case, right?",
            "So we had all these different ingredients that didn't quite exist yet in the literature.",
            "OK, So what can we say so?"
        ],
        [
            "Alright, we can talk about you know.",
            "So again, if I sort of fixed the input, Yi can think of the output here is evolving along some continuous path will eventually converge is, you know, we can say very cleanly it's going to converge to this solution.",
            "It's optimization program, so we'd like to know uniform like does it converge?",
            "And if so, how fast?",
            "And then can I improve them?",
            "So let me just take two minutes and I'll be really quick about this so."
        ],
        [
            "There's a bunch of mild conditions on this activation function, which let's just say we're bent, does they?",
            "Don't even."
        ],
        [
            "We're discussing too much.",
            "So the first thing you could say is like, OK, look if the we can even skip that sofa."
        ],
        [
            "So we could say is like look, you know if we have these mild conditions like no matter where we start.",
            "This this thing converges to the solution of LCA and not only that you like this sort of state variables converge to right.",
            "And this is true whether or not like you have a unique solution.",
            "So here is even a case where we had two columns which were just linear multiples of each other, right?",
            "And so you could imagine because it's dynamical system kind of getting into a loop where you're oscillating between these two columns.",
            "Kind of no guarantee our priority.",
            "That doesn't happen, so sort of showed that you can protect against them OK?",
            "Then"
        ],
        [
            "Other thing that we did that we said the skip on is like OK."
        ],
        [
            "Score to tie back more to sparse recovery.",
            "We say OK, look if this path of solutions you know.",
            "If it does not too many things ever become active right then we can sign a guarantee an exponential convergence, but you have that big caveat where you know you have no guarantee that not too many things become active, right?",
            "That's that's one thing.",
            "But then you can actually say look in the context of.",
            "Of L1 we can actually have tours."
        ],
        [
            "All to say OK, look if our matrix is this random compressed sensing matrix.",
            "We actually bound the number of nodes just ever become active at one time, right?",
            "And actually we've been doing this.",
            "We the mathematics looks similar, but not exactly the same.",
            "The results that we have for, like orthogonal matching pursuit and homotopy algorithms where you sort of guaranteeing that every time something becomes active.",
            "It's really part of your true solution, right?",
            "And so we have this week result that says, like look, I can guarantee that nothing becomes active.",
            "That's not supposed to be active.",
            "If I'm, say, have a lot of measurements compared to my sparsity, so M goes like S squared right?",
            "But I can say if I'm."
        ],
        [
            "I'm willing to settle for something weaker, right?",
            "I can say like, OK, look, I can promise you that say if my final solution has 30 active elements, I can promise you that no more than 60 elements ever get active, right?",
            "If from, like again, a number of measurements which is just linear in S, right?",
            "So this we know is kind of a condition to satisfy the RP notices condition for like when L1 recovery works.",
            "And it also you know if the solution to this this lasso is sparse is also now conditioned for.",
            "Basically this circuit converging exponentially.",
            "Right now only converging exponentially, but you can sort of bound the number of things that ever become active and that just helps you characterize the path of the next.",
            "OK so."
        ],
        [
            "Sorry for going over a little bit.",
            "There are more references we can use and open up for questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk.",
                    "label": 0
                },
                {
                    "sent": "As the name suggests, I'm going to talk about solving L1 minimization programs to do sparse recovery, but kind of the twist here about we're going to look at is we're going to look at when things are dynamic, so things are changing, so we'll use the word dynamic in two different ways.",
                    "label": 0
                },
                {
                    "sent": "So one is, like, you know, we have.",
                    "label": 0
                },
                {
                    "sent": "We're sort of sitting at the solution to an optimization program, and something changes.",
                    "label": 0
                },
                {
                    "sent": "Either we make a new measurement, or maybe the signal moves a little bit, or we want to change the functional slightly.",
                    "label": 0
                },
                {
                    "sent": "So, like how do we quickly update the solution without having to re solve everything?",
                    "label": 0
                },
                {
                    "sent": "So is there sort of a principled way for move to the solutions from one optimization program to another, like very closely related one, especially in this context of L1 OK, the other sort of way will use the word dynamical is to actually solve the ZL1 system, so I will get into this a little later in the talk, But basically will study sort of simple dynamical systems that settle to the solution of these L1 optimization programs of interest, and will do things like, say, like, OK, like how long does it take for them to settle, and if I know my solution is sparse.",
                    "label": 0
                },
                {
                    "sent": "Will that help me increase my speed?",
                    "label": 0
                },
                {
                    "sent": "OK, so two different ways to think about dynamics, but I guess you can use the word for both.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so first let's just let me just give you a little bit of background because it really helps motivate.",
                    "label": 0
                },
                {
                    "sent": "Like why I think this line of research is important and interesting.",
                    "label": 0
                },
                {
                    "sent": "So I mean, this is the sort of standard Now standard kind of sparse solutions to underdetermined system equation problem.",
                    "label": 0
                },
                {
                    "sent": "You know, I've looked at this problem a lot over the last 10 years.",
                    "label": 0
                },
                {
                    "sent": "A lot of people have looked at this problem a lot over the last 10 years, probably thousands of papers on on on conditions under which this these systems can be meaningfully solved, even when they're under determined.",
                    "label": 0
                },
                {
                    "sent": "And kind of the you know, the high level moral from this whole body of research is if I have underdetermined system equations it's still might be possible to solve it if my solution is structured, and so there's many different types of structure you might use.",
                    "label": 0
                },
                {
                    "sent": "Will talk today about sparse.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, does this sound?",
                    "label": 0
                },
                {
                    "sent": "It's OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll talk specifically about when XX the the vectors are interested sensing or sparse, but you know, there's there's other types of things you might be interested in to.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you could say is like if this matrix obeys certain properties, right?",
                    "label": 0
                },
                {
                    "sent": "Then you sort of can meaningfully recover and stable recovered sparse vectors from underdetermined systems, so a lot of the people that worked on this problem myself, including they have the kind of their background in mathematical signal processing.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the language we use to describe what's going.",
                    "label": 0
                },
                {
                    "sent": "John has this like a signal processing engineering twisted so you know we really think of this Fayaz modeling like some type of acquisition system, right?",
                    "label": 0
                },
                {
                    "sent": "So we're really trying to sample this X, not.",
                    "label": 0
                },
                {
                    "sent": "You can make all the entries of these wise the measurements right.",
                    "label": 0
                },
                {
                    "sent": "Each one is like an inner product.",
                    "label": 0
                },
                {
                    "sent": "It gets a different row of Phi and then you know we talk about sampling theorem.",
                    "label": 0
                },
                {
                    "sent": "So how many rows of five do I need to make sure I recover Isaiah structure decks not from these measurements?",
                    "label": 0
                },
                {
                    "sent": "Why right?",
                    "label": 0
                },
                {
                    "sent": "If I go backwards I say OK, I can sample it at this rate.",
                    "label": 0
                },
                {
                    "sent": "And be OK. OK so but you know in the end it's just.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, underdetermined systems of linear equations alright, so.",
                    "label": 0
                },
                {
                    "sent": "Would mean just what can we say about when we can solve them so you know if I have just the basic question of y = 5 X not plus noise, when can I stabili recover?",
                    "label": 1
                },
                {
                    "sent": "That's not, so there's maybe a lot of ways you can start to answer this question.",
                    "label": 0
                },
                {
                    "sent": "I'll show you just one.",
                    "label": 0
                },
                {
                    "sent": "Interesting framework in which they answered, and it's nice because it really ties back into like you know, just standard linear algebra for least squares, right?",
                    "label": 0
                },
                {
                    "sent": "So this this idea of what's called a restricted isometry.",
                    "label": 1
                },
                {
                    "sent": "And So what this means is you know, assuming the columns of my matrix fire are normalized appropriately and it says OK. Now if I have any 2 S. Parsecs, what it says it does that applying Fi doesn't change the length of these two S sparse vectors to.",
                    "label": 0
                },
                {
                    "sent": "So if this is true of my matrix 5, then I can do meaningfully do this inversion.",
                    "label": 0
                },
                {
                    "sent": "And that's kind of nice.",
                    "label": 0
                },
                {
                    "sent": "We can tie that back almost immediately.",
                    "label": 0
                },
                {
                    "sent": "To OK, say I have, you know, a critically or overdetermined fi and I want to recover X not plus noise using least squares like when can I do that?",
                    "label": 0
                },
                {
                    "sent": "Well, kind of fundamentally what you need is you need kind of all the singular values.",
                    "label": 0
                },
                {
                    "sent": "If I'd be about the same and these would be well conditioned, right?",
                    "label": 0
                },
                {
                    "sent": "That's exactly, you know what this says without this sparsity constraint.",
                    "label": 1
                },
                {
                    "sent": "So you would be able to solve underdetermined systems.",
                    "label": 0
                },
                {
                    "sent": "Of course we need something weaker since it can't possibly be true for all X.",
                    "label": 0
                },
                {
                    "sent": "And So what we just need is this property to hold overall, say 2 S. Sparse vectors.",
                    "label": 0
                },
                {
                    "sent": "Another way to think about it is.",
                    "label": 0
                },
                {
                    "sent": "You know, if I think about a 2 S sparse vector as being the difference between 2S sparse things that essentially saying I'm sort of preserving all the distances between S sparse vectors and somehow if it's identifiable in the original space is identifiable.",
                    "label": 0
                },
                {
                    "sent": "Once I look at it through fun.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the sort of the condition under which this works.",
                    "label": 0
                },
                {
                    "sent": "Or one of the conditions under which this works.",
                    "label": 0
                },
                {
                    "sent": "I just put this one up 'cause we're going to get in touch on this, or revisit this later in the talk.",
                    "label": 0
                },
                {
                    "sent": "OK, so how can you do it?",
                    "label": 0
                },
                {
                    "sent": "There's actually alright.",
                    "label": 0
                },
                {
                    "sent": "So first like OK, that's a condition on file like what kind of matrices had this restricted isometry property?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a fact which was surprising to some and not surprising to others is that you can sort of get achieve this property somewhat efficiently just using a random matrix right?",
                    "label": 0
                },
                {
                    "sent": "And so people from theoretical computer science will tell you.",
                    "label": 0
                },
                {
                    "sent": "OK, that's not surprising because you know if you're interested in keeping things identifiable, we know that random projections preserve distances.",
                    "label": 0
                },
                {
                    "sent": "If you're coming from the kind of land of signal processing we think about sampling signals, like taking inner products against random codes, it seems kind of bizarre at first.",
                    "label": 0
                },
                {
                    "sent": "OK, but the point is is like if say you just have this matrix and you fill the entries full of random numbers, you can recover S for sex, not from when the number of rows looks something like the sparsity.",
                    "label": 0
                },
                {
                    "sent": "So rather than needing like North System and equations here to find an unknown's you can get away with having S times log in right, so right?",
                    "label": 0
                },
                {
                    "sent": "So the basically the complexity here scales something like the complexity of the signal.",
                    "label": 0
                },
                {
                    "sent": "Rather than kind of this, the intrinsic dimensionality.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's that one thing that now domain.",
                    "label": 0
                },
                {
                    "sent": "How do you do it?",
                    "label": 0
                },
                {
                    "sent": "It's not like you do this inversion by applying a pseudo inverse to the other side.",
                    "label": 0
                },
                {
                    "sent": "There's many different approaches, will focus on ones using convex programming.",
                    "label": 1
                },
                {
                    "sent": "These convex programming, different types of greedy algorithms.",
                    "label": 1
                },
                {
                    "sent": "Iterative thresholding algorithms are actually almost the same at this point.",
                    "label": 0
                },
                {
                    "sent": "We are methods, a complex program, etc.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way you know we'll look at it in the way we might understand the best out of all.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Loose is spy.",
                    "label": 0
                },
                {
                    "sent": "You solving.",
                    "label": 0
                },
                {
                    "sent": "You know when everything is real linear program basically right?",
                    "label": 0
                },
                {
                    "sent": "So what we say is OK look, I have these measurements why I want to get back to this original vector XI know what this matrix is so I know that basically just need to consider all say the vectors X which obey this set of linear constraints and all of those you know, since my model is things being Sparks, let me choose the sparse right and So what we use instead of this parses this proxy for sparsest L1 norm.",
                    "label": 0
                },
                {
                    "sent": "It's, you know, even though it's a proxy and kind of a convex relaxation, it's actually probably effective in the sense that you know for exactly kind of the same range of M in relation to SNN.",
                    "label": 0
                },
                {
                    "sent": "Say, if you observe a perfectly sparse signal that's noiseless, you can prove that this thing will recover the signal exactly like you really do have a sampling theorem.",
                    "label": 0
                },
                {
                    "sent": "The sense that if I observe a perfectly sparse signal through this matrix, I can recover it by solving this program and the you know, as everyone knows once.",
                    "label": 0
                },
                {
                    "sent": "Actually, Steve Boy was saying for once you sort of set something up and and the framework where people have worked for, you know 20 years very hard how to solve these problems then you know you've done something.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's what we say.",
                    "label": 0
                },
                {
                    "sent": "So another thing we might say is, OK, look this works are sparse vectors.",
                    "label": 0
                },
                {
                    "sent": "It takes no imagination at all to say, OK, you know sparsity.",
                    "label": 0
                },
                {
                    "sent": "I can change what I mean by that.",
                    "label": 0
                },
                {
                    "sent": "I can be sparse and I only have a few nonzero entries, can be sparse, and that there's some other ortho basis I can't transfer.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On my my signal into, which is sparse, that's all that does.",
                    "label": 0
                },
                {
                    "sent": "I mean, all that affects is sort of composing your measurement matrix with some ortho transform over here, and only that like this can all be kind of made robust to noise, right?",
                    "label": 0
                },
                {
                    "sent": "So if we",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have some noise added into it.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "We can basically turn this, you know, go from these sort of equality constraints into this sort of more relaxed version.",
                    "label": 0
                },
                {
                    "sent": "I guess when people call this either basis, pursuit, denoising or L1L2 or the OR the last.",
                    "label": 0
                },
                {
                    "sent": "So even though it's more like kind of LaGrange form of the law, so anyway, so if we solve a program like this, we actually have guarantees about.",
                    "label": 0
                },
                {
                    "sent": "OK, if we have so much noise I can actually recover a sparse signal or signal which is almost sparse to some error bound which.",
                    "label": 0
                },
                {
                    "sent": "Makes sense, it scales like the noise level and to the degree I can approximate my original signal with a sparse signal.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is, you know.",
                    "label": 0
                },
                {
                    "sent": "Again, the type of program are interested in something, so let me just one second one minute just because there's such a varied audience, say why.",
                    "label": 0
                },
                {
                    "sent": "Like sparsity.",
                    "label": 0
                },
                {
                    "sent": "OK, that's one thing the Nobel Prize vectors, but is really important from the context implies the model we use.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All the time.",
                    "label": 0
                },
                {
                    "sent": "So it was just a quick example like here's a four megapixel image.",
                    "label": 0
                },
                {
                    "sent": "Here's a say, a one to one ortho transformation.",
                    "label": 0
                },
                {
                    "sent": "It's called a wavelet transform, right?",
                    "label": 1
                },
                {
                    "sent": "And basically what you could see it this way, which answers most of it's blue.",
                    "label": 0
                },
                {
                    "sent": "That means most of the coefficients are small, right?",
                    "label": 0
                },
                {
                    "sent": "And so another thing you see is like where we get these big wavelet coefficients.",
                    "label": 0
                },
                {
                    "sent": "Those are along the edges of the image, right?",
                    "label": 0
                },
                {
                    "sent": "So actually what kind of The upshot of this means like, OK, like most of these can be very well approximated by zero, so 11.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consequences that is like if I just throw away 99% of the smallest coefficients, I get almost the exact image back from the second thing.",
                    "label": 0
                },
                {
                    "sent": "It's like we know that.",
                    "label": 0
                },
                {
                    "sent": "So in some sense we can say like things that are piecewise smooth.",
                    "label": 0
                },
                {
                    "sent": "They're going to have sparse wavelet transforms, but kind of interesting thing.",
                    "label": 0
                },
                {
                    "sent": "Really makes it like appropriate for this comp.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sensing model is the sparse coefficients even though will only be a few, they'll be in different places every time because again, it depends on what the edge structure is in the image.",
                    "label": 0
                },
                {
                    "sent": "So we have this model of wanting to sort of model something is sparse, but not like a low dimensional subspace.",
                    "label": 0
                },
                {
                    "sent": "For sparse, like there's a small number of active coefficients.",
                    "label": 0
                },
                {
                    "sent": "I don't know which ones.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's why we value sparsity, 'cause it allows us to sort of take very dramatic first steps towards doing things like image compression or estimation in the presence of noise or.",
                    "label": 0
                },
                {
                    "sent": "Feature extraction and things like this OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once you kind of combine this idea of sensing and sparsity, right?",
                    "label": 0
                },
                {
                    "sent": "So what kind of The upshot of this this line of research is, or like what a lot of the motivation was.",
                    "label": 0
                },
                {
                    "sent": "OK, and now if I have an acquisition system, I can sort of get away with taking a small number of samples.",
                    "label": 0
                },
                {
                    "sent": "If you somehow inject some kind of randomness or diversity into the acquisition process.",
                    "label": 0
                },
                {
                    "sent": "So like, here's a good example of where this one.",
                    "label": 0
                },
                {
                    "sent": "So this is what's called a hyperspectral image, so it has a lot of pixels, right?",
                    "label": 0
                },
                {
                    "sent": "But each sort of end.",
                    "label": 0
                },
                {
                    "sent": "It's a series of images, each with a lot of pixels, so each image.",
                    "label": 0
                },
                {
                    "sent": "Is basically the response of some field to like a very narrow set of wavelengths of light, so very narrow band of light.",
                    "label": 0
                },
                {
                    "sent": "So I collect this over several bins, right?",
                    "label": 0
                },
                {
                    "sent": "And so you know what this is saying is like instead of having to take a measurement or sense something at every single pixel at every one of these different wavelengths could be hundreds of wavelengths and millions of pixels.",
                    "label": 0
                },
                {
                    "sent": "But if I can instead, like somehow combine different pixels in wavelengths together, again using some kind of global and diverse code, but perhaps get away with many, many fewer of those.",
                    "label": 0
                },
                {
                    "sent": "I said no, so it's like you're integrating the compression into this sensor, right?",
                    "label": 0
                },
                {
                    "sent": "And so the similar thing is true with.",
                    "label": 0
                },
                {
                    "sent": "Another scenario, so here is like a typical RF signal is really just the time frequency representation of a signal taken off mantenna, so you know you know if you're just going to plug this thing into analog to digital converter.",
                    "label": 0
                },
                {
                    "sent": "You might have to sort of classically have to sample a twice whatever this maximum frequency is, right?",
                    "label": 0
                },
                {
                    "sent": "But if you can do something before that ADC, like, say, take the signal, branch it off into different branches multiplied by random codes, integrate over those results, and then sample right?",
                    "label": 0
                },
                {
                    "sent": "You could probably get away with a smaller total sampling.",
                    "label": 0
                },
                {
                    "sent": "Right and then other systems like MRI.",
                    "label": 0
                },
                {
                    "sent": "It's actually the savings are much clearer.",
                    "label": 0
                },
                {
                    "sent": "It's like OK, I just have to take fewer samples in the MRI machine, work my way out in frequency and just correspond to regulated spending less time.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's you know that those have been the games alright.",
                    "label": 0
                },
                {
                    "sent": "So now what?",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "What's been kind of interesting how long researches?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You know, in some way it's OK.",
                    "label": 0
                },
                {
                    "sent": "I have now I have this data and if I want to reconstruct the image I can sort of say OK.",
                    "label": 0
                },
                {
                    "sent": "Here comes the data into my optimization program.",
                    "label": 0
                },
                {
                    "sent": "It's input.",
                    "label": 0
                },
                {
                    "sent": "I run this optimization program.",
                    "label": 0
                },
                {
                    "sent": "I get my output image or signal out that's a bigger vector and then I sort of move all right and then when that works and that the motivation for that and the model for that is all perfectly clear.",
                    "label": 0
                },
                {
                    "sent": "Kind of in the context of linear algebra like y = 5 X right.",
                    "label": 0
                },
                {
                    "sent": "But there's a big sort of slice of signal processing that's kind of thinks in a completely different framework.",
                    "label": 0
                },
                {
                    "sent": "Are you don't really think of in terms of y = X you think in terms of filters, kind of.",
                    "label": 0
                },
                {
                    "sent": "The first thing you learn when you're in signal processing you think of like just reams of data coming into a filter which you multiply and add together, and you get a different data stream out right?",
                    "label": 0
                },
                {
                    "sent": "And all that's done very much in mind from the beginning of I'm going to just have constant data streaming in an constant data streaming out.",
                    "label": 0
                },
                {
                    "sent": "OK and so So what we're trying to do with this dynamic stuff, and you know, taking poking at it from a few different directions is trying to put it more this Ellen Research more into this filtering framework, right?",
                    "label": 0
                },
                {
                    "sent": "So instead of just having Y in solving optimization program and getting something else out and not being the end, it's like we want to solve it.",
                    "label": 1
                },
                {
                    "sent": "It's a whole series, so these optimization programs, and maybe the data is changing in such a way that we can model.",
                    "label": 0
                },
                {
                    "sent": "And maybe we can link together those optimization programs in such a way that maybe.",
                    "label": 0
                },
                {
                    "sent": "Either they are easier to solve or we get some gain from doing that, right?",
                    "label": 0
                },
                {
                    "sent": "So we have almost in mind that sense of like an L1 filter like things are streaming in things are streaming out and then sort of the relationship between these two sides is something like, you know, plugging in why here and having that map to the output.",
                    "label": 0
                },
                {
                    "sent": "OK, so you know in another way this kind of another way to look at big Data.",
                    "label": 0
                },
                {
                    "sent": "We might not know.",
                    "label": 0
                },
                {
                    "sent": "I mean, I happen to also be interested in solving problems, but I might also not be interested in solving big ones, but solving say many many many small problems.",
                    "label": 0
                },
                {
                    "sent": "Many times a second.",
                    "label": 0
                },
                {
                    "sent": "Oh, OK, so that's that's kind of, you know, kind of what we have in mind.",
                    "label": 0
                },
                {
                    "sent": "So again, we'll look at like kind of two ways to think about this.",
                    "label": 0
                },
                {
                    "sent": "One is really this idea of.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm going to solve a series of optimization programs.",
                    "label": 0
                },
                {
                    "sent": "How can I quickly go from the solution of 1 to the solution of the other?",
                    "label": 0
                },
                {
                    "sent": "And they all sort of all rely critically on the fact that they have this form, and the 2nd way is actually I have a dynamical system which Maps continuous time inputs to continuous time outputs, right?",
                    "label": 0
                },
                {
                    "sent": "And so how do I sort of if the input stay steady?",
                    "label": 0
                },
                {
                    "sent": "It's a it's solve this program like how do I characterize how long that takes a set of first step and understanding?",
                    "label": 0
                },
                {
                    "sent": "That type of continuous time system.",
                    "label": 0
                },
                {
                    "sent": "Or like L1 filter if you will.",
                    "label": 0
                },
                {
                    "sent": "OK so first right?",
                    "label": 0
                },
                {
                    "sent": "So that's essentially here, so this fast.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Getting a solutions.",
                    "label": 0
                },
                {
                    "sent": "This is work.",
                    "label": 0
                },
                {
                    "sent": "You know my student, so I want to see if we just got his PhD.",
                    "label": 0
                },
                {
                    "sent": "You know, we worked together over a sort of a series of years about this and this systems of nonlinear differential equations that solve L1.",
                    "label": 1
                },
                {
                    "sent": "This is with the student that another professor at Rice, who's actually idea about this dynamical system was Chris Roselle.",
                    "label": 0
                },
                {
                    "sent": "We share a student or elevon who's who.",
                    "label": 0
                },
                {
                    "sent": "See the results here.",
                    "label": 0
                },
                {
                    "sent": "OK, so first for the, for the.",
                    "label": 1
                },
                {
                    "sent": "Fast updating of solutions of owner question.",
                    "label": 0
                },
                {
                    "sent": "So let me just.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, plug back into sort of an area you know signal processing or just applied mathematics.",
                    "label": 0
                },
                {
                    "sent": "Where were the kind of characterize is what we want, right?",
                    "label": 0
                },
                {
                    "sent": "And so let's just sort of look at this classical like least squares problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so I've overdetermined system equations I solve least squares so close form through that I just apply the pseudoinverse on the left, right and so if the matrix is small enough you know.",
                    "label": 0
                },
                {
                    "sent": "Maybe if I can compute this once I could just store it in memory, then if I get new data it's not really a big deal, I just apply it to the new data to get my new estimate.",
                    "label": 0
                },
                {
                    "sent": "But you can also do things like if you add a measurement gets added right.",
                    "label": 0
                },
                {
                    "sent": "So say I have a least squares.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solution for y = 5 X and then I learn something new about X, right?",
                    "label": 0
                },
                {
                    "sent": "So in this case I'm just adding a single row to five and get a single new measurement right?",
                    "label": 0
                },
                {
                    "sent": "And so then OK, what's the new least square solution?",
                    "label": 0
                },
                {
                    "sent": "Well, this is now the system I want to solve right, but we know we're saying is like.",
                    "label": 0
                },
                {
                    "sent": "Here's a matrix have already inverted, right?",
                    "label": 0
                },
                {
                    "sent": "And they want to add a rank one matrix to that, so that's sort of well known how to how to do these type of updates.",
                    "label": 0
                },
                {
                    "sent": "And in the in numerical numerical linear algebra, right?",
                    "label": 0
                },
                {
                    "sent": "And so sort of a convenient way you can write.",
                    "label": 0
                },
                {
                    "sent": "The solution which kind of brings out what's going on here is, you know, by by playing around with.",
                    "label": 0
                },
                {
                    "sent": "Again, identities from linear algebra sort of rewrite this as my new estimate is my old estimate times you know what's called some some gain matrix and the difference between, say, the residual of what I measured and like what I predicted.",
                    "label": 0
                },
                {
                    "sent": "I would measure given my old estimate, right?",
                    "label": 0
                },
                {
                    "sent": "So like this new measurement, W matches the measurement.",
                    "label": 0
                },
                {
                    "sent": "You know I would have had with my old estimate exactly this should be X hat X, not had X not here.",
                    "label": 0
                },
                {
                    "sent": "Then I do nothing.",
                    "label": 0
                },
                {
                    "sent": "I just keep that same estimate right?",
                    "label": 0
                },
                {
                    "sent": "If it's consistent, it's consistent.",
                    "label": 0
                },
                {
                    "sent": "Now and I move on, but if it's not, you know what I do is I take that residual.",
                    "label": 0
                },
                {
                    "sent": "I pass it through a linear system, right?",
                    "label": 0
                },
                {
                    "sent": "And so the with the neat thing is here is like.",
                    "label": 0
                },
                {
                    "sent": "Basically we can write this as sort of my old inverse, just applied to a vector, in this case a single vector, in this case and so here we hear what it's saying is like instead of having to solve a new system of equations, all I need is a couple matrix vector multiplies and I can move on and then there's.",
                    "label": 0
                },
                {
                    "sent": "You know there's also formula for updating the inverse here and so I can repeat this as needed.",
                    "label": 0
                },
                {
                    "sent": "And also if I instead of seeing 1 mission I see many.",
                    "label": 0
                },
                {
                    "sent": "You know you can sort of incorporate them all at the same time as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's one example from kind of again, classic sort of sequential estimation, yeah?",
                    "label": 0
                },
                {
                    "sent": "Hey there, so this so in this case the file is over determined.",
                    "label": 0
                },
                {
                    "sent": "The bigger the big fire, and then this the last one is just wondering which is the single measurement.",
                    "label": 0
                },
                {
                    "sent": "Well, OK, well we'll get we want it to be there when I'm just talking about this is like in the classical overdetermined set, right?",
                    "label": 0
                },
                {
                    "sent": "So yeah, so we'll talk about.",
                    "label": 0
                },
                {
                    "sent": "So we're going to one of our goals is to extend this idea to underdetermined systems, but with L1 regularizer attached to it.",
                    "label": 0
                },
                {
                    "sent": "So yes, so I'm trying to undo trying to set the tone saying you can do this for least squares.",
                    "label": 0
                },
                {
                    "sent": "So another thing you can do with least squares, something another that thing that's very classical was.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kalman filter, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the idea where is not only do I have measurements streaming in all the time?",
                    "label": 0
                },
                {
                    "sent": "The signal I'm trying to estimate is also moving around all the time, but it's not moving around arbitrarily.",
                    "label": 0
                },
                {
                    "sent": "I have a model, a linear model from how it's moving from time to time instance.",
                    "label": 0
                },
                {
                    "sent": "So what that allows me to do is a sort of allows me to connect together.",
                    "label": 0
                },
                {
                    "sent": "Different optimization programs to get some gain basically right, and so if I just write down OK, like look at each time is since TI see some observations of X.",
                    "label": 0
                },
                {
                    "sent": "These say could be either underdetermined or overdetermined in this case, and then between T and T + 1.",
                    "label": 0
                },
                {
                    "sent": "My ex moves, but it moves according to some linear way or some up release approximately that I that I know.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So then if I sort of want to get an estimate for X at all these different times.",
                    "label": 0
                },
                {
                    "sent": "I just again, it's just sort of a big linear system, so I can just again think of it as a big least squares problem.",
                    "label": 0
                },
                {
                    "sent": "And because of the structure of this linear system, basically it's you know there's only only see terms on the diagonal here and one things up right directly, but to the to the left of the diagonal there is again a fast way to do this, so it's a little more complicated, right?",
                    "label": 0
                },
                {
                    "sent": "But basically what you say is OK, look, you know, given my current estimate, I can guess what the next estimate should be just by applying my linear model.",
                    "label": 0
                },
                {
                    "sent": "Right and then I do the same kind of blow up low rank, updating chicken then basically say is like OK, my new best guess from what's going on at time K plus one is again you know I take this this prediction that I made apply this measurement matrix and then I just have some gain matrix operating on that residual right?",
                    "label": 0
                },
                {
                    "sent": "So again this is one of the sort of fundamental tools in applied mathematics and it's really again really just about updating here.",
                    "label": 0
                },
                {
                    "sent": "At least squares solutions as as measurements rolling.",
                    "label": 0
                },
                {
                    "sent": "OK so is these two types of things that?",
                    "label": 0
                },
                {
                    "sent": "We're kind of after in.",
                    "label": 0
                },
                {
                    "sent": "Ah, but it you know we want to do this again in the context of L1 instead of L2.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the kind of the the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The main framework we want to look at for, so I have this optimization problem is a little different than the one I just showed.",
                    "label": 0
                },
                {
                    "sent": "You have minda WX here, W is just.",
                    "label": 0
                },
                {
                    "sent": "It's a diagonal matrix that has positive entries along this diagonal.",
                    "label": 0
                },
                {
                    "sent": "So if those were all just equal to Lambda, so they'll be like Lambda times the identity.",
                    "label": 0
                },
                {
                    "sent": "This is exactly this loss over talking about, but maybe you want to favor some components more than other components.",
                    "label": 0
                },
                {
                    "sent": "I'll just sort of allow that flexibility.",
                    "label": 0
                },
                {
                    "sent": "And then you know what we want to do is say, OK, let's say we're sitting at the solution to a program like this.",
                    "label": 1
                },
                {
                    "sent": "And then something happened.",
                    "label": 0
                },
                {
                    "sent": "So where do we buy something?",
                    "label": 0
                },
                {
                    "sent": "So say maybe we add or remove a measurement from file.",
                    "label": 0
                },
                {
                    "sent": "So I observe a new entry just like in recursively squares.",
                    "label": 0
                },
                {
                    "sent": "How do I update this solution to this so the underlying signal changes a little bit, right?",
                    "label": 1
                },
                {
                    "sent": "So if it changes a little bit, how do I again sort of quickly update the solution?",
                    "label": 0
                },
                {
                    "sent": "Again, trying to use these ideas of efficient low rank updates or say like the weights change so I have no reason to believe.",
                    "label": 0
                },
                {
                    "sent": "That maybe I want to favor some of my entries more than others, so I changed the weights how to again avoid solving things from scratch.",
                    "label": 0
                },
                {
                    "sent": "Or again, more of this kind of linear dynamical systems model where I have sort of streaming measurements from a signal which is evolving right.",
                    "label": 0
                },
                {
                    "sent": "So now I have a kind of like a series of optimization programs, but there's they're all linked together right there, linked together because you know they're getting an estimate for something later really tells me about something which happened earlier on.",
                    "label": 0
                },
                {
                    "sent": "OK, so as these types of things we want to alright, so the sort of we can sort of attack all four of these using the same type of trick that Rick starts just by writing down what the optimality conditions are for solving this program.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is unconstrained optimization program.",
                    "label": 0
                },
                {
                    "sent": "We can kind of find optimality condition.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the sort of set of optimality conditions, basically like a recasting of the KKT conditions.",
                    "label": 1
                },
                {
                    "sent": "I mean essentially how you compute what these optimality conditions are.",
                    "label": 0
                },
                {
                    "sent": "As you say, OK, look for to be at optimal point.",
                    "label": 0
                },
                {
                    "sent": "I need zero to be in the subgradient of this thing.",
                    "label": 1
                },
                {
                    "sent": "I mean subgradient mean, since since this WXL one it's not a smooth like a piecewise linear thing, so it's not differentiable.",
                    "label": 0
                },
                {
                    "sent": "So you can think of a sort of a gradient as being a supporting hyperplane out of point.",
                    "label": 0
                },
                {
                    "sent": "So when you have like a kink, maybe there will be a lot of supporting hyperplanes.",
                    "label": 0
                },
                {
                    "sent": "So we're all we ask is that like sort of the 0 being the subgradient of this thing?",
                    "label": 0
                },
                {
                    "sent": "And So what?",
                    "label": 0
                },
                {
                    "sent": "That means this fact that you have multiple supporting hyperplanes, I get sort of a system of equations, linear equations.",
                    "label": 0
                },
                {
                    "sent": "In this case my solution has to obey on the support and then sort of a system of linear inequality.",
                    "label": 0
                },
                {
                    "sent": "So it has to be off the support.",
                    "label": 0
                },
                {
                    "sent": "OK, so well, let's just look at what this depends on this, right?",
                    "label": 0
                },
                {
                    "sent": "So I know that if X star obeys these conditions right then it's then it's a solution to a solution to this optimization program.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting about this several things.",
                    "label": 0
                },
                {
                    "sent": "One is, you know if I collect kind of these linear constraints over all elements of my support, right?",
                    "label": 0
                },
                {
                    "sent": "So first, like what are these depend on?",
                    "label": 0
                },
                {
                    "sent": "They did?",
                    "label": 0
                },
                {
                    "sent": "You know they depend on the support, right?",
                    "label": 0
                },
                {
                    "sent": "So this gamma star is the locations of the active coefficients of the solution.",
                    "label": 0
                },
                {
                    "sent": "And these these are like the signs of the location of the active coefficients of the solutions.",
                    "label": 0
                },
                {
                    "sent": "OK, so then what?",
                    "label": 0
                },
                {
                    "sent": "But once those are determined essentially what I have is I have a system of linear inequality's for X star on the support, and again a system of linear polys office support.",
                    "label": 0
                },
                {
                    "sent": "This is the fact that you know the I have these linear equation was going to allow me to say OK you know as things change a little bit how does this solution perturb into its new one and the fact that this is sort of a linear system equations on the support it kind of means that this solution?",
                    "label": 0
                },
                {
                    "sent": "Well it doesn't move linearly from one solution to the next.",
                    "label": 0
                },
                {
                    "sent": "It takes a piecewise linear path and only takes a piecewise linear path that we can trace.",
                    "label": 0
                },
                {
                    "sent": "Uh, relatively quickly.",
                    "label": 0
                },
                {
                    "sent": "So let's just look at one simple example of this.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah yeah, it's diagonal and positive.",
                    "label": 0
                },
                {
                    "sent": "It's basically like just some WK absolute values of X.",
                    "label": 0
                },
                {
                    "sent": "It just for compactness, right?",
                    "label": 0
                },
                {
                    "sent": "Like that?",
                    "label": 0
                },
                {
                    "sent": "OK, so let's let's just look at 111.",
                    "label": 0
                },
                {
                    "sent": "Example of that will illustrate tricks.",
                    "label": 0
                },
                {
                    "sent": "OK, so we observed Y 1 = 5 X one plus some error.",
                    "label": 0
                },
                {
                    "sent": "Alright so we say OK, fine, I'm going to estimate X solving the lasso.",
                    "label": 0
                },
                {
                    "sent": "So I solve it and I'm sitting at my solution X1 hand.",
                    "label": 0
                },
                {
                    "sent": "Right now new set of measurements arrive.",
                    "label": 1
                },
                {
                    "sent": "Why two now?",
                    "label": 0
                },
                {
                    "sent": "I want to solve this new.",
                    "label": 0
                },
                {
                    "sent": "Now one optimization problem.",
                    "label": 1
                },
                {
                    "sent": "OK so I have the solution to this.",
                    "label": 0
                },
                {
                    "sent": "And I suspect that X1 and X2 are close to each other.",
                    "label": 0
                },
                {
                    "sent": "That's just my model for what's going on.",
                    "label": 0
                },
                {
                    "sent": "So the idea is like how, instead of like sort of resolving this, how can I just sort of map the solution of this under the solution of this?",
                    "label": 0
                },
                {
                    "sent": "And you do it using this kind of standard trick called homotopy, where it's like what I do is I slowly transform this optimization program into this optimization problems by introducing a parameter, right?",
                    "label": 0
                },
                {
                    "sent": "So what I say is OK, look what I'm going to do is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to put both sets of measurements in here, but I'm going to multiply Y 2 by epsilon Y 1 by 1 minus epsilon.",
                    "label": 0
                },
                {
                    "sent": "Then move epsilon from zero to 1, so that's going to fade out.",
                    "label": 0
                },
                {
                    "sent": "These and bring in these.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's I mean, it should be clear that epsilon equals zero.",
                    "label": 0
                },
                {
                    "sent": "You know we're sitting the solution here, and if we solve this for epsilon equals one here at the solution here.",
                    "label": 0
                },
                {
                    "sent": "But the point is is like as we change epsilon, this trace is out of.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Path of solutions and it's a path that you know we can actually move along and predict.",
                    "label": 0
                },
                {
                    "sent": "So why can you do that in half?",
                    "label": 0
                },
                {
                    "sent": "So it's actually pretty easy once you just write down the what these optimality conditions are.",
                    "label": 0
                },
                {
                    "sent": "So here's you know, for any fixed epsilon you know, here's what my optimality conditions look like.",
                    "label": 0
                },
                {
                    "sent": "They're exactly the same, just with these two different wise.",
                    "label": 0
                },
                {
                    "sent": "But you can see OK Now if I just perturb epsilon a little bit, right?",
                    "label": 0
                },
                {
                    "sent": "I know that you know this.",
                    "label": 0
                },
                {
                    "sent": "Again, there's this linear system equations on the support, so if I change epsilon just a little that support or the science of this on the support doesn't change.",
                    "label": 0
                },
                {
                    "sent": "So if I change epsilon just a little, what can I say?",
                    "label": 0
                },
                {
                    "sent": "OK, look the direction I must have to move.",
                    "label": 0
                },
                {
                    "sent": "As epsilon say increases, is this.",
                    "label": 0
                },
                {
                    "sent": "It's basically I just looked this.",
                    "label": 0
                },
                {
                    "sent": "I increment exit and look at the difference between those two, right?",
                    "label": 0
                },
                {
                    "sent": "So I move along this direction so it's basically the difference of the measurements, but then suck through this matrix.",
                    "label": 0
                },
                {
                    "sent": "So this matrix is over determined.",
                    "label": 0
                },
                {
                    "sent": "So what Phi Gamma is?",
                    "label": 0
                },
                {
                    "sent": "It's fine, but I pull out the columns that correspond to the set gamma, so it's going to be over determined.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Inverse exists, So what then?",
                    "label": 0
                },
                {
                    "sent": "So then essentially is OK. That's the direction I want to move, and then the idea is I move along that direction until something changes right?",
                    "label": 0
                },
                {
                    "sent": "And so I know that the only time like something meaningful happen is if, like I'm moving and say one of the things that was active in my support leaves, it gets set to 0 right?",
                    "label": 0
                },
                {
                    "sent": "Or the other thing that could happen is I'm moving and one of my constraints off the support one of those constraints becomes active, right?",
                    "label": 0
                },
                {
                    "sent": "So basically one of these bump up against land, right?",
                    "label": 0
                },
                {
                    "sent": "That means something new wants to enter the support.",
                    "label": 0
                },
                {
                    "sent": "Right, so once I wanted to do is I move until one of those things happens, right?",
                    "label": 0
                },
                {
                    "sent": "And then what do I do?",
                    "label": 0
                },
                {
                    "sent": "I have to adjust this this game.",
                    "label": 0
                },
                {
                    "sent": "So what is adjusting?",
                    "label": 0
                },
                {
                    "sent": "Gamma reason was either it means either like adding or subtracting, removing a row from gamma.",
                    "label": 0
                },
                {
                    "sent": "So again I know how to do that very efficiently using low rank updates and then only that.",
                    "label": 0
                },
                {
                    "sent": "Just because these are linear.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Linear inequality's I can actually if I'm sitting at this point here, I can very quickly calculate units ordered or whatever N operation.",
                    "label": 0
                },
                {
                    "sent": "What the size of the next epsilon needs to be to get me to the next kink, right?",
                    "label": 0
                },
                {
                    "sent": "So it's basically just just yeah against 'cause because it's this varies linearly with epsilon.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I do is I say OK, I said at this point I figure out what direction I need to move, figure out how far I move there to get to the next King Point.",
                    "label": 0
                },
                {
                    "sent": "The cost of this is a low rank update, so a couple.",
                    "label": 0
                },
                {
                    "sent": "Vector matrix multiplies and then I just repeat that process right?",
                    "label": 0
                },
                {
                    "sent": "And so hopefully if X2 is close to X1, it won't take too many links in this chain.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's one thing we do.",
                    "label": 0
                },
                {
                    "sent": "So here is just couple of expr.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elements to show that you know, sort of semi realistic situations.",
                    "label": 0
                },
                {
                    "sent": "At least this number of paths is very manageable.",
                    "label": 0
                },
                {
                    "sent": "In fact so manageable that that you beat state of the art solvers easilly, that even have a warm stuff.",
                    "label": 0
                },
                {
                    "sent": "OK so here are just a couple examples we use.",
                    "label": 0
                },
                {
                    "sent": "So here is like versus synthetics poor signal.",
                    "label": 0
                },
                {
                    "sent": "And then at every time say we change like maybe I think it's some percentage.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's 5% of the entries so we take out 5% and that in.",
                    "label": 0
                },
                {
                    "sent": "Another 5% just chosen at random.",
                    "label": 0
                },
                {
                    "sent": "Here's another example of what we do is we have a 1 dimensional signal, so a series of 1 dimensional signals which we measure through a matrix Phi, but with those one dimensional signals are there just slices from this image, right?",
                    "label": 0
                },
                {
                    "sent": "So you'll have sort of periods were not much in the signal changing, but then you hit a discontinuity, right?",
                    "label": 0
                },
                {
                    "sent": "And so if you would like to again, say, look in the wavelet domain, maybe a lot of wavelet coefficients become active and then they move around slowly as you move down the image etc.",
                    "label": 0
                },
                {
                    "sent": "OK, then you do stuff where you have.",
                    "label": 0
                },
                {
                    "sent": "Say splines and you move the knots around, or maybe oscillate the polynomial parts between the splines.",
                    "label": 0
                },
                {
                    "sent": "So again, you know if you look at wavelet transforms of these things, essentially what you're doing is the wavelet coefficients are moving around and they're moving from side to side a little bit, either as the singularity's movers, things become sharper around the singular OK, so if you do experiments like this, I mean what you can kind of say.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "You know you can measure performance in two ways.",
                    "label": 0
                },
                {
                    "sent": "Maybe this blue way is more indicative, so this is basically the average number of vector matrix multiplies we needed to do.",
                    "label": 0
                },
                {
                    "sent": "Do it, do an update and then you compare it to like L1 solvers which are say starting using as a warm start.",
                    "label": 0
                },
                {
                    "sent": "The previous solution and you can beat them by a factor of three or four.",
                    "label": 0
                },
                {
                    "sent": "We also have the CPU times listed here, though again I think like you know, just because of the implementation issues.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is this vector multiplies really are what dominate the implementation calls.",
                    "label": 0
                },
                {
                    "sent": "So I think if this was done very carefully you know this is really how you would expect the performance of the scale.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's one set of examples.",
                    "label": 0
                },
                {
                    "sent": "So that's the single moving it is.",
                    "label": 0
                },
                {
                    "sent": "Again, it was very simple, and so we did.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Write down the optimality conditions and move from one set of measurements to the next.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's.",
                    "label": 0
                },
                {
                    "sent": "You can play a similar trick, but you know in a slightly different way, so now say instead of the thing moving, let's say I add a measurement to my system, right?",
                    "label": 1
                },
                {
                    "sent": "So I'm sitting at the solution to this program.",
                    "label": 1
                },
                {
                    "sent": "And let's say I get one new measurement to this matrix.",
                    "label": 0
                },
                {
                    "sent": "This matrix Phi solution should change.",
                    "label": 0
                },
                {
                    "sent": "How do I update it?",
                    "label": 0
                },
                {
                    "sent": "And you do sort of exactly the same thing, so I said OK here I have this.",
                    "label": 0
                },
                {
                    "sent": "I want to add this term in.",
                    "label": 0
                },
                {
                    "sent": "So basically I just put an epsilon in front of it and I just meant that from zero to 1.",
                    "label": 0
                },
                {
                    "sent": "You can again write down what the optimality conditions are.",
                    "label": 0
                },
                {
                    "sent": "Again they just depend on just as before.",
                    "label": 0
                },
                {
                    "sent": "It depends on what the support of the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Signal is what the science sequences on the support.",
                    "label": 0
                },
                {
                    "sent": "So again, as I change this epsilon again, moving in this piecewise linear manner as things enter and leave the support and I'm doing low rank updates to compute what the directions are.",
                    "label": 0
                },
                {
                    "sent": "OK, so given that you know we can again run an A.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set up experiments an if we sort of measure the average number of matrix vector product for update.",
                    "label": 1
                },
                {
                    "sent": "Yeah, it's not too important what these things are, but it's like in the real scenario.",
                    "label": 0
                },
                {
                    "sent": "Again, what we see the same type of thing where you know if we look at the number of major Spectre multiplies, we need it.",
                    "label": 0
                },
                {
                    "sent": "In this case, maybe beats it between a factor of like two to five or something like this, OK?",
                    "label": 0
                },
                {
                    "sent": "So then finally, there's just one other thing I want to mention before we go.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So like the real good generalization.",
                    "label": 0
                },
                {
                    "sent": "So we have these two tricks, one for the the sort of signal, the signal moving around an one is for adding a new measurement in, and there's another thing we might like to fact is done in practice, and that's maybe just change the weights of the sink so you know there's there's a practice.",
                    "label": 0
                },
                {
                    "sent": "At least you can get a lot out of, say you know if I solve L1 once.",
                    "label": 0
                },
                {
                    "sent": "Once a uniform set of weights, I put Lambda everywhere.",
                    "label": 0
                },
                {
                    "sent": "So if L1 and then I kind of see which ones are big.",
                    "label": 0
                },
                {
                    "sent": "Right and so then I say, OK, you know, maybe my I didn't estimate my small coefficients very nicely, but if I can now solve this again, but increasing the weights on, you know the things that I'm sure are there, maybe I can start to pull out some of this.",
                    "label": 0
                },
                {
                    "sent": "You know, less important stuff.",
                    "label": 0
                },
                {
                    "sent": "So in practice I mean this is pulled directly from from this paper.",
                    "label": 0
                },
                {
                    "sent": "You know if you have problems.",
                    "label": 0
                },
                {
                    "sent": "So this is basically three modulated pulses sitting on top of each other.",
                    "label": 0
                },
                {
                    "sent": "So problems were like L1 just doesn't work very well at recovering the signal, but if you run this reweighting scheme.",
                    "label": 0
                },
                {
                    "sent": "You can, yeah yeah yeah, get a much improved estimate.",
                    "label": 0
                },
                {
                    "sent": "OK so, but the point is, is the point is you want to solve this program.",
                    "label": 0
                },
                {
                    "sent": "You're getting a series of solutions and with how you want to change things, you want to update the weights from one program instance to the next so you know I want we can skip the details here.",
                    "label": 0
                },
                {
                    "sent": "So again, you do exactly the same thing you do.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work from 1 system of weights to the next.",
                    "label": 0
                },
                {
                    "sent": "You know, look at the optimality conditions.",
                    "label": 1
                },
                {
                    "sent": "Compute what the update direction must be, and then again moving that move move.",
                    "label": 0
                },
                {
                    "sent": "And yeah, moving that direction till something changes, either something leaves us support or or comes in OK. And so again you know if we look at results.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, again, we sort of compare how many matrix vector multiplies we need as compared again taking like a sort of state of the art L1 solver and giving it a warm start of what the previous solution was.",
                    "label": 0
                },
                {
                    "sent": "And when you map these things out for just a series of different experiments.",
                    "label": 0
                },
                {
                    "sent": "So these are sort of related standard recovery problems.",
                    "label": 0
                },
                {
                    "sent": "Where to say the number of measurements versus the M versus and so the number of rows?",
                    "label": 0
                },
                {
                    "sent": "There's a number of costs.",
                    "label": 0
                },
                {
                    "sent": "Columns in the matrix is taking different proportions.",
                    "label": 0
                },
                {
                    "sent": "Again, it's it's the same sort of thing where the number of matrix vector multiplies we need.",
                    "label": 0
                },
                {
                    "sent": "In this case, maybe even a factor of 5 to 10 less than using other soldiers.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Ah.",
                    "label": 0
                },
                {
                    "sent": "That's good, although it doesn't quite give us get us all the way there.",
                    "label": 0
                },
                {
                    "sent": "Right and so.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All of these these kind of ideas that we talked about, they relied sort of very critically on being at the, you know, X where I'm starting from being the solution to one optimization program and then translating that into the solution of another optimization problem.",
                    "label": 0
                },
                {
                    "sent": "So what's actually really difficult to do, and it took us awhile to figure out, is to get it like basically this idea of a Kalman filter inside this framework, and here's why.",
                    "label": 0
                },
                {
                    "sent": "So when you're again when you have this kind of dynamical systems update, so again, the idea is you're trying to estimate vector, but the vectors changing at every different instance, right?",
                    "label": 0
                },
                {
                    "sent": "And you again you have some idea about how The thing is changing, But the problem here is like what you're doing is you're kind of adding and removing columns instead of rows from the matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so really you know what we like is we sort of know how to do things like this where we have say a guess and we want to update from the guests in the least square setting.",
                    "label": 0
                },
                {
                    "sent": "So the idea is like how can we just get take that general idea and like map it to a homotopy problem.",
                    "label": 0
                },
                {
                    "sent": "So basically here I have a guess given again I take my old estimate, apply F to it and then I sort of work with the difference of my guess.",
                    "label": 0
                },
                {
                    "sent": "You know from what I consider consistent measurements work with that to to get my new Western.",
                    "label": 0
                },
                {
                    "sent": "So it's more like you know what we want is rather from moving from one solution to another one.",
                    "label": 0
                },
                {
                    "sent": "Can we get a sort of a general warm start and it's a warm start that might come from a prediction and then trace the path from that, and that will kind of give us the last sort of ingredients in getting to know what a true streaming system is.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the idea is actually pretty simple and you can actually take it and it can encompass all these other things that you know that we talked about earlier and actually does so even a little more efficiently.",
                    "label": 0
                },
                {
                    "sent": "And once you see what you just say is this, it's like OK look, I have.",
                    "label": 0
                },
                {
                    "sent": "I want to solve say this system so I have, you know, some optimization problems.",
                    "label": 1
                },
                {
                    "sent": "So this is like the new program that I want to solve and I just have an initial guess or prediction will call V. So what you can do is say OK, look what I can do is I can choose this.",
                    "label": 0
                },
                {
                    "sent": "You according to V and the way I choose this year according to these when I said epsilon equal to 0 here like I have this sort of new optimization program which V is the solution to and then I just again change epsilon.",
                    "label": 0
                },
                {
                    "sent": "Up to one.",
                    "label": 0
                },
                {
                    "sent": "OK so EU of course is chosen in relationship to be very carefully right.",
                    "label": 0
                },
                {
                    "sent": "So it has a couple of nice properties right?",
                    "label": 0
                },
                {
                    "sent": "So it's not there.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something we made up, so the first property it has is again, you know at epsilon equals to zero.",
                    "label": 0
                },
                {
                    "sent": "With this choice of UV really is the solution to this program, so we are still just kind of changing solutions of optimization programs.",
                    "label": 0
                },
                {
                    "sent": "But then also it has this property.",
                    "label": 0
                },
                {
                    "sent": "OK look, you know if I have a prediction V and my measurements are consistent with VI, don't have to do much.",
                    "label": 0
                },
                {
                    "sent": "Actually it's you just sort of used to sort of updating on the support when you do that.",
                    "label": 0
                },
                {
                    "sent": "Oh OK, so it has a nice consistent.",
                    "label": 0
                },
                {
                    "sent": "So basically like you know, if you you can get away with just correcting the support like this program will do that.",
                    "label": 0
                },
                {
                    "sent": "And also if this residual is small.",
                    "label": 0
                },
                {
                    "sent": "Basically it's sort of.",
                    "label": 0
                },
                {
                    "sent": "It just looks like kind of adjusting the solution by thresholding almost OK.",
                    "label": 0
                },
                {
                    "sent": "So I mean we don't have to go through it anymore.",
                    "label": 0
                },
                {
                    "sent": "It's like you know, you sort of again, write down optimal conditions, conditions, figure out the direction you have to move, and then do it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So then what we?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What this allows us to do now, is there like really do streaming systems right?",
                    "label": 0
                },
                {
                    "sent": "So here's just one example of the Leica compressed sensing streaming system, or interested in doing this type of recovery so.",
                    "label": 0
                },
                {
                    "sent": "We had this DARPA analog that information project, So what the details of this project aren't that important?",
                    "label": 0
                },
                {
                    "sent": "But essentially what it boils down to is you had like a radar signal coming into a receiver right in the radar signal.",
                    "label": 0
                },
                {
                    "sent": "I did pretty high bandwidth, so something on the order of a couple of giga Hertz so broken into several channels, and then you did this kind of idea where you sort of randomly modulate the signal in each of these channels, and then you sort of integrate, and then subsample the result.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is I have kind of a signal which I might have a model for.",
                    "label": 0
                },
                {
                    "sent": "And you know what I'm spitting, as I've receiver that spitting out samples of this signal at a high rate, right?",
                    "label": 0
                },
                {
                    "sent": "So it's not like there's sort of a start time and a stop time to what's going on here again, it's just sort of like these measurements are streaming by, and in this case they're shooting by a fairly high rate.",
                    "label": 0
                },
                {
                    "sent": "OK, so then.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know what do we want to say?",
                    "label": 0
                },
                {
                    "sent": "If we have a signal which looks like this?",
                    "label": 0
                },
                {
                    "sent": "So this is maybe a collection of chirps.",
                    "label": 0
                },
                {
                    "sent": "There's lots of ways you can sort of build a good representation for these types of signals by sort of windowing them time and taking Fourier transform.",
                    "label": 0
                },
                {
                    "sent": "So lots of sort of local Fourier transforms this particular one I'm showing you is a lap orthogonal transform, sort of very carefully designed, so like projections inside each of these windows are actually orthogonal to one another.",
                    "label": 0
                },
                {
                    "sent": "But basically you know what this means.",
                    "label": 0
                },
                {
                    "sent": "If I have something which looks like this, it becomes very sparse for each moment in time.",
                    "label": 0
                },
                {
                    "sent": "When I look at it through this transform.",
                    "label": 0
                },
                {
                    "sent": "So the idea is like one sparse reconstruction for measurements like this, and you know in this basis.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so when you sort of set this up, I mean what you might have in this system you might have like slightly overlapping or even this even can't even block diagonal types of measurements, so there's sort of whole window of time I want to do the reconstruction over and then I have sort of overlapping bases right?",
                    "label": 0
                },
                {
                    "sent": "And So what the point of this is I have kind of a series of optimization programs in substance, but they're sort of all linked together because they overlap.",
                    "label": 0
                },
                {
                    "sent": "OK, so the goal here is like I'd sort of knock something off the edge of the window, brings something new in.",
                    "label": 0
                },
                {
                    "sent": "How do I update the solution and so you can do this by taking care of the edge effects in the appropriate way and then bike again.",
                    "label": 0
                },
                {
                    "sent": "Just setting up this this homotopy algorithm and so you know again, and in doing this what you're doing is just kind of making a prediction about what comes next.",
                    "label": 0
                },
                {
                    "sent": "If you don't have a model, you might just predict you know whatever the last sort of.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or set of coefficients you are and then you're correcting your just correcting by bringing epsilon up from zero to 1 and we know them.",
                    "label": 0
                },
                {
                    "sent": "By doing that, you're just doing a series of lowering updates, and if your prediction is close to signal, it will be a small number.",
                    "label": 0
                },
                {
                    "sent": "So for like signals which look like this again, you see tremendous gains.",
                    "label": 0
                },
                {
                    "sent": "So if you look at like the you know the NUM.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or of a matrix vector multiplies you need, you know, actually this is over the course.",
                    "label": 0
                },
                {
                    "sent": "The entire simulation here.",
                    "label": 0
                },
                {
                    "sent": "Maybe we needed like 10,000?",
                    "label": 0
                },
                {
                    "sent": "Or is if you looked at again, L1 solvers with a warm start, it might have been like five or six or even 10 times that.",
                    "label": 0
                },
                {
                    "sent": "OK, so then another thing you could do, almost by by not doing much.",
                    "label": 0
                },
                {
                    "sent": "Once you have this framework in places you know.",
                    "label": 0
                },
                {
                    "sent": "Again, this signals are moving, but now you have a model for how it's moving, so you have this kind of Kalman filtering set up again over a sort of an entire sequence of Windows.",
                    "label": 0
                },
                {
                    "sent": "What you'd like to do is solve what looks like a series of independent problems, but.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kind of linked together through the dynamics of X, so sort of since X is moving away around their predictable way, like learning about access to later time tells you about, you know what it should have been at an earlier time too.",
                    "label": 0
                },
                {
                    "sent": "So again, we drop measurements off, add them on, and then correct using this homotopy and you know this just this plot we always did was sort of take a sparse signal and shifted around unpredictably and then.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Monica looked at like what was the difference between using the like, the sparse regularization and just the standard?",
                    "label": 0
                },
                {
                    "sent": "I'll call my filter and you get, you know some again there like just as you would expect you would.",
                    "label": 0
                },
                {
                    "sent": "But then more importantly, I mean when you.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of use this this low rank updating framework.",
                    "label": 0
                },
                {
                    "sent": "You tend to be just warm starting a regular solver by again less significant factor, like maybe five or six here.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the.",
                    "label": 0
                },
                {
                    "sent": "What all will say about moving from one optimization program to the next?",
                    "label": 0
                },
                {
                    "sent": "So to end here, I just want to mention a little bit about the other kind of way of thinking about dynamics right now, just.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To motivate this very quickly so there's kind of a movement.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In a.",
                    "label": 0
                },
                {
                    "sent": "And signal processing kind of getting going back to the future.",
                    "label": 0
                },
                {
                    "sent": "So back in time, 30 years where people are starting to revisit analog signal processing systems right?",
                    "label": 0
                },
                {
                    "sent": "And so the way the computational model these things is completely different than what you would use to build a register or arithmetic unit on a computer, right?",
                    "label": 0
                },
                {
                    "sent": "So they use transistors, but they use them like not as being on or off switches.",
                    "label": 0
                },
                {
                    "sent": "They use them in this called this like subthreshold regime, right?",
                    "label": 0
                },
                {
                    "sent": "And So what this does is it kind of.",
                    "label": 0
                },
                {
                    "sent": "Using this kind of nonlinear map from.",
                    "label": 0
                },
                {
                    "sent": "So let's just say between like the expectation current and what comes out.",
                    "label": 0
                },
                {
                    "sent": "You kind of allows you to do operations in this log rhythmic turn, so we kind of what The upshot here is like.",
                    "label": 0
                },
                {
                    "sent": "You know, you can do big computations using fewer transistors, and only that, since you're sort of operating them in this sub threshold regime, they burn much less power.",
                    "label": 0
                },
                {
                    "sent": "And So what?",
                    "label": 0
                },
                {
                    "sent": "You can kind of think about this is at the end of the day is, you know I have a noisy computer, kind of has all the problems that analog circuits always have.",
                    "label": 0
                },
                {
                    "sent": "But it's very fast and it's very little power, so maybe I can do computations with the precision of 10 to the minus two, and maybe I can build a much smaller circuit that runs at much smaller power.",
                    "label": 0
                },
                {
                    "sent": "Doing that, and there's some actually tremendous small scale successes.",
                    "label": 1
                },
                {
                    "sent": "Doing things like this, so there have been booked both companies and research projects that have you had have used circuits like this to do so, like beamforming in hearing it, right?",
                    "label": 0
                },
                {
                    "sent": "So basically you're doing you're doing LMS, so finding weights the null out noise sources.",
                    "label": 0
                },
                {
                    "sent": "I was also a company that used technology like this to do error correcting codes for flash drives, right?",
                    "label": 1
                },
                {
                    "sent": "We're actually we have a lot of the lot of the same structure you have for these.",
                    "label": 0
                },
                {
                    "sent": "Ah, convex optimization programs.",
                    "label": 1
                },
                {
                    "sent": "OK so, and there's even people that I can claim they can do image processing.",
                    "label": 0
                },
                {
                    "sent": "Well, that's a lot of what's frustrating about this work is sort of exists in the context of a bunch of startups, so there's like this published realm of material and there's stuff that different startup companies claim they can do OK.",
                    "label": 0
                },
                {
                    "sent": "But anyway, if like we are to.",
                    "label": 0
                },
                {
                    "sent": "I believe you know that a lot of this stuff can be scaled.",
                    "label": 0
                },
                {
                    "sent": "You know what the account would kind of allow us to do is is like we could you in theory implement kind of a very simple system, which is basically just involves vector matrix multiplies and like small nonlinearities that you know if you think about taking analog input, I would have an analog output where if I kept the input still it would settle to the solution of different optimization programs.",
                    "label": 0
                },
                {
                    "sent": "In fact, that idea is kind of not not new, I mean a lot of people.",
                    "label": 1
                },
                {
                    "sent": "Say I don't know in the 80s built small circuits which could solve, say linear programs or or quadratic programs.",
                    "label": 0
                },
                {
                    "sent": "I guess Hopfield was kind of the director of this research, so I mean at the end that idea.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You know, at the end of the day, kind of where you're getting the gain is just like a digital multiplying Accumulo vector matrix multiplication, right?",
                    "label": 0
                },
                {
                    "sent": "So you can build an analogue vector matrix multiplier.",
                    "label": 0
                },
                {
                    "sent": "That's 100 inputs, or 100 outputs, or even a couple 100 inputs.",
                    "label": 0
                },
                {
                    "sent": "A couple of 100 outputs, but it works with the bandwidth of like 100 megahertz, right?",
                    "label": 0
                },
                {
                    "sent": "So maybe doing 50 million of these operations per second effectively and you're doing it?",
                    "label": 0
                },
                {
                    "sent": "You know using very, very little power in milliwatts of power, OK, so.",
                    "label": 0
                },
                {
                    "sent": "Ha.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What can we?",
                    "label": 0
                },
                {
                    "sent": "What does that mean in terms of solving L1?",
                    "label": 0
                },
                {
                    "sent": "Actually you can sort of write down, you know, either for the lasso or even a more general type of optimization program.",
                    "label": 0
                },
                {
                    "sent": "You can write down a set of of nonlinear differential equations that.",
                    "label": 1
                },
                {
                    "sent": "That that's settled to these things.",
                    "label": 0
                },
                {
                    "sent": "OK, so since I'm running out of time, let me just talk kind of.",
                    "label": 1
                },
                {
                    "sent": "More generally, you know about what we have for.",
                    "label": 0
                },
                {
                    "sent": "Analysis, and so like what we've done here.",
                    "label": 0
                },
                {
                    "sent": "Say OK, look.",
                    "label": 0
                },
                {
                    "sent": "There's actually a simple kind of normal now.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work architecture right?",
                    "label": 0
                },
                {
                    "sent": "And it really just consists of.",
                    "label": 0
                },
                {
                    "sent": "Here comes the input right then what I do is I have a state, it gets fed through activation functions.",
                    "label": 0
                },
                {
                    "sent": "These are in the context of the one.",
                    "label": 0
                },
                {
                    "sent": "These are basically soft thresholding and then I feedback.",
                    "label": 0
                },
                {
                    "sent": "The feedback, so this is basically 5 transpose 5, So what this looks like is essentially like a continuous time version of iterative soft thresholding, except everything is running continuously.",
                    "label": 0
                },
                {
                    "sent": "OK, so system like this, you know, really falls under the realm of these these these analog circuits people think they can build something like this to scale.",
                    "label": 0
                },
                {
                    "sent": "So the question is like we just want to get a feel for how this thing behaves.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if I'm trying to recover something sparse, how long does it take me?",
                    "label": 0
                },
                {
                    "sent": "So let me just talk about a few things we can set.",
                    "label": 0
                },
                {
                    "sent": "OK, so first thing you know, you can very quickly figure out what the relationship between this.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function you want operating on each thing and what this activation function.",
                    "label": 0
                },
                {
                    "sent": "So if like you want this to be L1, you know this each of the sea of UN.",
                    "label": 0
                },
                {
                    "sent": "It looks like absolute value, and so you're essentially taking the derivative of what's going on here.",
                    "label": 0
                },
                {
                    "sent": "So let me just point out here that like you know, there's sort of a lot of work in dynamical systems about how solutions to these systems of equations behave, but like a lot of like what makes what we did complicate it was the same thing that makes it gives you complications and standardizes things back to.",
                    "label": 0
                },
                {
                    "sent": "Things are not continuous, not differentiable, and even unbounded.",
                    "label": 0
                },
                {
                    "sent": "In this case, right?",
                    "label": 0
                },
                {
                    "sent": "So we had all these different ingredients that didn't quite exist yet in the literature.",
                    "label": 0
                },
                {
                    "sent": "OK, So what can we say so?",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, we can talk about you know.",
                    "label": 0
                },
                {
                    "sent": "So again, if I sort of fixed the input, Yi can think of the output here is evolving along some continuous path will eventually converge is, you know, we can say very cleanly it's going to converge to this solution.",
                    "label": 0
                },
                {
                    "sent": "It's optimization program, so we'd like to know uniform like does it converge?",
                    "label": 0
                },
                {
                    "sent": "And if so, how fast?",
                    "label": 0
                },
                {
                    "sent": "And then can I improve them?",
                    "label": 0
                },
                {
                    "sent": "So let me just take two minutes and I'll be really quick about this so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's a bunch of mild conditions on this activation function, which let's just say we're bent, does they?",
                    "label": 0
                },
                {
                    "sent": "Don't even.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're discussing too much.",
                    "label": 0
                },
                {
                    "sent": "So the first thing you could say is like, OK, look if the we can even skip that sofa.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we could say is like look, you know if we have these mild conditions like no matter where we start.",
                    "label": 0
                },
                {
                    "sent": "This this thing converges to the solution of LCA and not only that you like this sort of state variables converge to right.",
                    "label": 0
                },
                {
                    "sent": "And this is true whether or not like you have a unique solution.",
                    "label": 0
                },
                {
                    "sent": "So here is even a case where we had two columns which were just linear multiples of each other, right?",
                    "label": 0
                },
                {
                    "sent": "And so you could imagine because it's dynamical system kind of getting into a loop where you're oscillating between these two columns.",
                    "label": 0
                },
                {
                    "sent": "Kind of no guarantee our priority.",
                    "label": 0
                },
                {
                    "sent": "That doesn't happen, so sort of showed that you can protect against them OK?",
                    "label": 0
                },
                {
                    "sent": "Then",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other thing that we did that we said the skip on is like OK.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Score to tie back more to sparse recovery.",
                    "label": 0
                },
                {
                    "sent": "We say OK, look if this path of solutions you know.",
                    "label": 0
                },
                {
                    "sent": "If it does not too many things ever become active right then we can sign a guarantee an exponential convergence, but you have that big caveat where you know you have no guarantee that not too many things become active, right?",
                    "label": 0
                },
                {
                    "sent": "That's that's one thing.",
                    "label": 0
                },
                {
                    "sent": "But then you can actually say look in the context of.",
                    "label": 0
                },
                {
                    "sent": "Of L1 we can actually have tours.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All to say OK, look if our matrix is this random compressed sensing matrix.",
                    "label": 0
                },
                {
                    "sent": "We actually bound the number of nodes just ever become active at one time, right?",
                    "label": 0
                },
                {
                    "sent": "And actually we've been doing this.",
                    "label": 0
                },
                {
                    "sent": "We the mathematics looks similar, but not exactly the same.",
                    "label": 0
                },
                {
                    "sent": "The results that we have for, like orthogonal matching pursuit and homotopy algorithms where you sort of guaranteeing that every time something becomes active.",
                    "label": 0
                },
                {
                    "sent": "It's really part of your true solution, right?",
                    "label": 0
                },
                {
                    "sent": "And so we have this week result that says, like look, I can guarantee that nothing becomes active.",
                    "label": 0
                },
                {
                    "sent": "That's not supposed to be active.",
                    "label": 0
                },
                {
                    "sent": "If I'm, say, have a lot of measurements compared to my sparsity, so M goes like S squared right?",
                    "label": 0
                },
                {
                    "sent": "But I can say if I'm.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm willing to settle for something weaker, right?",
                    "label": 0
                },
                {
                    "sent": "I can say like, OK, look, I can promise you that say if my final solution has 30 active elements, I can promise you that no more than 60 elements ever get active, right?",
                    "label": 0
                },
                {
                    "sent": "If from, like again, a number of measurements which is just linear in S, right?",
                    "label": 0
                },
                {
                    "sent": "So this we know is kind of a condition to satisfy the RP notices condition for like when L1 recovery works.",
                    "label": 0
                },
                {
                    "sent": "And it also you know if the solution to this this lasso is sparse is also now conditioned for.",
                    "label": 0
                },
                {
                    "sent": "Basically this circuit converging exponentially.",
                    "label": 0
                },
                {
                    "sent": "Right now only converging exponentially, but you can sort of bound the number of things that ever become active and that just helps you characterize the path of the next.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry for going over a little bit.",
                    "label": 0
                },
                {
                    "sent": "There are more references we can use and open up for questions.",
                    "label": 0
                }
            ]
        }
    }
}