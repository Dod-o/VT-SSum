{
    "id": "5p7nl6k7htawp7wup5mlzet37zutkwq3",
    "title": "From linearly-solvable optimal control to trajectory optimization, and (hopefully) back",
    "info": {
        "author": [
            "Emanuel Todorov, Department of Computer Science and Engineering, University of Washington"
        ],
        "published": "Oct. 16, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Mathematics->Control Theory",
            "Top->Computer Science->Robotics",
            "Top->Physics->Statistical Physics"
        ]
    },
    "url": "http://videolectures.net/cyberstat2012_todorov_optimal_control/",
    "segmentation": [
        [
            "This talk is going to have two parts.",
            "The first one will summarize the number of results with obtained over the past few years that are closely related to things that people have been talking about here and then.",
            "The second part is going to be about the next thing we're doing, so linearly suboptimal.",
            "Control it."
        ],
        [
            "The class of stochastic optimal control problems that can be reduced to solving linear equations.",
            "The way I got into this was very interested in some old papers by Fleming and meter that were, you know, playing with PDS and turning linear into nonlinear.",
            "Once an identifying diffusions that can be reduced to linear equations.",
            "And I thought, you know, can this be somehow generalize?",
            "Then use the computationally?",
            "So here's the here's the problem setting that.",
            "You can make linear, so in the stands for a Markov decision process.",
            "Or that is so traditionally what people do is you have a control that chooses an action you which in turn specifies the transition probabilities.",
            "So if X is the current state, use the action you choose.",
            "You have some control stochastic dynamics that tells you what's the probability of every possible next 8X prime.",
            "Now we're going to modify this as follows.",
            "So instead of asking the controller to pick symbols that are symbolic actions, and then having some function that Maps those probabilities, we're going to allow the controller to pick those probabilities directly.",
            "OK, so the controller is actually now conditional probability function calling from X to X prime.",
            "Addition, we're going to define passive dynamics, which is basically what the system would like to do.",
            "If you don't control it.",
            "NDPS usually don't have that, so if you look at the reinforcement learning literature in gridworld, since there is no such thing as passive dynamics, usually designed.",
            "But if you look at any physical system, there is a notion of passive dynamics, or when you set the control to zero, that's what the passive dynamics is OK, and we need to restrict this so that if the passive dynamics if some transition is impossible under the passive dynamics, it has to remain impossible under the control.",
            "For some things to become finite."
        ],
        [
            "And so we're going to restrict the running cost or the cost rate to be in this form.",
            "So little L is going to be running costs function of state in the control, so it can depend on the state in any way it wants and the control is going to penalize be penalized as the care divergent between the transition probabilities you pick and the transition transition probabilities that the system would like to do.",
            "If you didn't control it.",
            "So basically the control can impose any dynamic situations.",
            "However it pays the price for pushing the system too far from what it wants to do.",
            "This input, in practice this is important not only because it makes the cardioversions finite, but also it prevents silly things like teleporting yourself to the goal state in one step, right?",
            "Ideally, we wouldn't want to do that.",
            "So."
        ],
        [
            "It's very easy to see that this reduces to linear equation, so this is the two line derivation.",
            "So this thing on the top is the standard Bellman equation.",
            "This is your optimal cost to go or value function is the minimum overall actions of the immediate cost which we defined to be this.",
            "This formula for Kelly Burgess plus the expectation over the value of the next state will take expectations over the same thing.",
            "We can buy the logs and so now we're minimizing over something that's basically a Cal diversions, but it is a normalized.",
            "So divide and multiply by a normalization constant.",
            "This thing becomes zero and you get."
        ],
        [
            "A closed form solution for the control law, which is that it's your passive dynamics waited by the exponent of your optimal cost to go function, which we're going to cozy.",
            "And then normalized so this normalization operator is just the sum of that of the numerator while we calling this thing a desirability function is going to become clear in a moment."
        ],
        [
            "I solved to summarize what we got is.",
            "Basically we're looking for a function Z that satisfies this equation, so Z is equal to exponentiate state cost times.",
            "This linear operator.",
            "So in a picture, what does that do?",
            "Well, here's why."
        ],
        [
            "That's so suppose X is the current state.",
            "Passive dynamics tells you what the next days like today it's the black.",
            "So density an supposed to computer ZNZ happens to be this blue thing.",
            "So what you do is you multiply the black thing by the blue thing and what the blue thing does is basically shifts this passive dynamic stores the parts of the state space where you like to be, so that's why we're calling the desirability function.",
            "Sort of pushes it towards your desires, and then you sample and directing, and that's your next day.",
            "So the rating is the optimal control dynamics.",
            "Um?",
            "Now you vote yes.",
            "We're going to look at a bunch of examples where we use this thing to approximate systems that we're already working with.",
            "Um?"
        ],
        [
            "Actually, the next two slides we will give you another very specific answer to that question, so we also know that from birth working also from central mirrors work and.",
            "Others turns out that there is a class of controlled diffusion that also reduced to linear Hamilton, Chicago.",
            "Many questions, and they look like that.",
            "So this is stochastic dynamics.",
            "You have some passive dynamics that can be nonlinear.",
            "The key condition is that the States and the controls have to live in the same subspace, so anything that the control could do could have happened by accident and vice versa.",
            "For example, if you are sitting in that chair, you fall asleep, you could accidentally get up and walk out of the door.",
            "That must be possible in order for you to actually be able to walk out.",
            "Perfect, but you know, that's how the math works.",
            "Um?",
            "The control cost.",
            "Sorry the cost rate can be any function of the state and then the penalty for the control has to be related to the noise amplitude.",
            "So basically the more noise in the system is, the cheaper is to control advisors.",
            "So actually this shows that these things don't have a meaningful deterministic limit, right?",
            "So if you try to send the noise going to 0, control will become infinitely expensive and you can define the problem, but you never move.",
            "Alright, so for these problems you can show we know what the optimal control of this is like.",
            "Control affine system and then people have shown that you do a standard logarithmic transformation.",
            "You get this linear equation where L is your second order linear differential operator.",
            "That's the generator of the passive dynamics where you set to 0.",
            "So what do this problem classes have to do with each other?",
            "And we obviously they're both stochastic optimal control problems that somehow reduced to solving a linear problem.",
            "They started out being very different.",
            "So here's how."
        ],
        [
            "Can relate them.",
            "So basically the thing I defined first is sometimes much more general.",
            "You can reduce it to the control diffusion in the following way.",
            "So obviously what I did find those discrete time.",
            "This is continuous time, so we'll have to take in continuous time limit.",
            "So let's define the passive dynamics for our linear MDP, so it's going to be done in the obvious way, right?",
            "So remember we need to define this passive dynamics going from X to X prime.",
            "We're now going to index it by the time step and take the limit of age cost to 0, so it's going to be a Gaussian.",
            "It's going to be centered at the next state where the diffusion is likely to find itself.",
            "You don't control it X + H A and then it's variance.",
            "It's going to be basically how much violence variance diffusion is going to accumulate in time step H, which is, which is this."
        ],
        [
            "OK, so now.",
            "The discrete time step costs is going to be Q of H times.",
            "Usual cost times age because that's how long you accumulated cost OK and now.",
            "How do we get?",
            "What do we do with the scale divisions cost?",
            "So now the densities are Gaussian, so we have a formula for evaluating the care divergent, so the care divergent between two Gaussians with the same covariance is just the square difference between their means, weighted by the inverse covariance.",
            "If the queries are different, this becomes slightly more messy, but here they are not.",
            "So here's the picture, right?",
            "So you hear the passive dynamics wants to take you here with sorry with some Gaussian you are pushing it here.",
            "KL divergent between those two things happens to be the usual quadratic energy costs that we all know and love.",
            "So basically we can start with this LM GPS, specialized the densities to be Gaussians and take this continuous time limit, and you can recover those diffusions."
        ],
        [
            "I.",
            "But of course you can do also many other things that you can.",
            "You can do things in discrete time that don't correspond to any sensible continuous time.",
            "Process like for example the way that contact dynamics are simulated these days.",
            "Turns out you cannot define continuous time.",
            "Equations of motion becausw columb friction is not defined in continuous time.",
            "There's a paradox that's about 120 years old.",
            "Explains to you why that's not possible.",
            "And then many other situations where you can play."
        ],
        [
            "This so here's a summary of mostly linear Bellman questions.",
            "This is the LDP cases diffusion case.",
            "Remember had this to operators L. Is that generator P. Is this normalization operator I defined, which is basically an integral operator and these are all the different ways you can define optimal control problems.",
            "So first exit means you run until you hit some boundary and then you pay final cost in this in some way.",
            "The simplest, so you have to augment these equations with boundary condition.",
            "Of course finite horizon issue ran until.",
            "Some final time and then you pay the final cost.",
            "Average cost reduces to eigenvalue to principal eigenvalue eigenfunction problem where this C is the average cost per step and the discounted cost is the only one that ends up being nonlinear.",
            "So basically here you have to raise this Anansi to the power of Alpha, where Alpha is the discount factor.",
            "Um?",
            "This you can ask how this is normal.",
            "Normalizing operator P relates to your generator and it's basically the generator.",
            "Continuous time diffusion is just the first or the term in the expansion of our discrete time operator with respect to the time step.",
            "And of course it has high order terms that have been ignored.",
            "So you can do a lot of things with this."
        ],
        [
            "For example, you can.",
            "Try to like discretize continuous problems and solve them with things like policy, traditional value iteration.",
            "So here's a standard example from the literature.",
            "This is a so called Corona Hill.",
            "The goal is to.",
            "So basically this is a point mass moving on a curved route and there's gravity so dynamically nonlinear.",
            "The goal is to park here, and this is the parking lot.",
            "It's a parking lot on a steep Hill very well.",
            "This is the optimal control as a function of position and velocity.",
            "This is some stochastic trajectory, so the optimal control system this is the parking lot.",
            "This is what you compute by putting this on the dense grid and using standard policy iteration as an empty.",
            "So here you're discretizing both the state and control.",
            "Here we're discretizing only the state, and the control is sort of given to us analytically by the formula that we saw on the second slide, and as you would expect this, they give you the same things, except this you can compute a lot faster.",
            "Why can you compute a lot faster?",
            "Because these are MVP's where we don't have to do anything explicit with the controls, so we generic an MVP is there is always a loop over.",
            "The control should basically maximizing or minimizing over them, and that some kind of inner loop.",
            "Here.",
            "We've gotten rid of that once and for all, and we've explained we replaced it with an analytical formula.",
            "Install.",
            "These algorithms get much faster.",
            "This is like number of updates on the log scale.",
            "This is policy value iteration.",
            "This is sometimes callings iteration, which is like the obvious way iterative way to solve those linear equations.",
            "Actually\\ in Matlab would be even faster, but like for purposes of comparison I decided to do this simple minded iteration.",
            "This is CPU time."
        ],
        [
            "Can also sampling, which is related to close related to Captain's work, so again, this is the equation we want to solve.",
            "Suppose you didn't have a model of anything but somebody gave you samples.",
            "Current states accent the next states experiments that were obtained and the costs that were paid in these samples were done under the passive dynamics.",
            "OK, and."
        ],
        [
            "So what you can do is you can actually approximate this by just summing up the exponent of the trajectory costs and dividing over the number of trajectories.",
            "That's a Monte Carlo estimates.",
            "That's basically the path integral approach.",
            "It's unbiased, but it's very slow as every other Montecarlo thing."
        ],
        [
            "One way to speed it up is to use trick that's in the enforcement.",
            "Learning is known as.",
            "Temporal difference is sorry, it's temporal difference learning.",
            "So what you do is, as you get the updates, you keep sort of.",
            "It's almost like running a filter on your estimate of Z.",
            "So so you observe some XNSMX prime event, so some next state and some cost.",
            "And then you're going to use this update rule to update your estimate about Z.",
            "At this step, Berry seems learning right, so obviously that has to go to zero if you want this thing to converge at some point.",
            "So these things tend to be a lot faster and."
        ],
        [
            "Nothing you can do actually is important sampling, which is by far the best thing you can do.",
            "So we said that I mean the math says that you have to sample from the passive dynamics, and as I mentioned earlier, if you imagine what it takes to get from a chair that, well, you know what is the chance of you getting up from a chair by accident.",
            "You know that's never going to happen, so.",
            "It's not such a good idea to sample from the passive dynamics.",
            "Instead, you want to sample from your best guess about the optimal control dynamics.",
            "What is your best guess?",
            "Well, you have your estimate of this Z desirability function.",
            "If this were the actual Z then we know what the optimal control is because we have a formula for you.",
            "Given this or you sample from that.",
            "And then you have to do the standards of important sampling correction.",
            "So you scale by the probability ratio.",
            "The thing you should have done over the thing that you actually did an.",
            "This converges alot faster.",
            "One drawback here is that to do important sampling you actually need a model of this P. Like this you define yourself.",
            "So you obviously have a model of it, but this you will have to learn."
        ],
        [
            "And so these things have an analog in the different living called Q learning, which is basically Model 3 way to learn optimal control.",
            "An again, as you would expect, this works faster.",
            "Becausw Q Learning learns a function over the product space of states, an controls.",
            "Here we just need to learn a function over the state space, so it's a much smaller function and we can do it both by sampling from the passive dynamics or in this greedy way.",
            "And basically this is the learning with greedy issues basically outperforms or the other things on some simple problem."
        ],
        [
            "Um, their estimation control duality is this is closely related to central Middle East Auckland.",
            "Just cover it in this context, so the probability of a trajectory.",
            "X12X2 that started at zero under the passive dynamics, which is the product of the transition probabilities.",
            "And the optimal control dynamics, the same trajectory has probability which you can easily show that it's the prior, the one on the passive dynamics times the exponent of this sound state costs.",
            "So it's simple logical to show that.",
            "So if you look at that clearly, this is equivalent to Bayes rule, where this is your prior QS.",
            "You're negative log likelihood and this is your posterior.",
            "So this is sort of a trajectory view of base rule.",
            "You can also turn it into a recursive.",
            "Filtering."
        ],
        [
            "Kind of thing where let's say you define MUK to be the marginal serve at one time step.",
            "The margin of this density and you define some constant R which is just this marginal over yours function your disability function.",
            "This satisfies this equation that we had before.",
            "It basically goes from the next day to the current state, so it goes backwards in time.",
            "This new quantity are that we defined.",
            "It just turns out to be the forward filtering danced itself, so it's a very simple equation and of course is the product of the two.",
            "So this is exactly based on recursive Bayesian inference where.",
            "Z is our backward filtering density of course and normalized as far as filtering density and Mr. Martino."
        ],
        [
            "So here's here's the actual problems that are dual to each other, so there's continuous and discrete time and continuous time.",
            "We have our control diffusion with our quadratic costs.",
            "I skipped the Sigma for reasons that are beyond me at the moment.",
            "Problem this control problem is due to this estimation problem.",
            "You skip the control, so just becomes the passive dynamics instead of a state cost, you put some measurement function which can now be a vector and these things are dual.",
            "When your state cost in, the control problem is the square the L2 norm of your measurement function.",
            "So if these conditions are satisfied then the Z and immune functions that I showed you on the previous slide correspond to the Bayesian estimation here.",
            "In the discrete case, the picture is in some sense simpler, so here the control dynamics are like whatever you specify.",
            "This was the cost for already show that this is Jewel 2, the system evolving under the passive dynamics instead of the control dynamics, you're making some binary measurements, which are basically coin flips with rate given by some whatever function you want R and then to make this dual you have to relate this Q&R and the way you relate the miscue has to be the negative log R. You can specialize this for the linear case."
        ],
        [
            "I don't think I have time for."
        ],
        [
            "Let me just say that when you specialize for the linear case, you get the duality not between the linear quadratic regulator and the common filter, which is what you see in textbooks, but between the linear quadratic regulator and information filter, which is the thing that propagates the inverse covariance rather than the covariance.",
            "I'll just skip that."
        ],
        [
            "There is a thing called a maximum principle for the most likely trajectory, so you know what maximum principle is basically a way to characterize the optimal trajectory for a deterministic system.",
            "People have tried to derive such things for stochastic control, but everything that exists is some PD like thing that actually characterized the global solution and not the individual trajectory.",
            "Here we can say something about an individual trajectory for optimal control.",
            "Stochastic system.",
            "In particular, we can ask what is the most likely trajectory you know?",
            "What's the maximum?"
        ],
        [
            "Of.",
            "Of this new here and we can show that this is the solution to a well defined deterministic optimal control problem where the pontryagin's maximum principle applies, so we can basically extend it to stochastic control."
        ],
        [
            "I'm just going to summarize the results so.",
            "The maximum this meal is the optimal trajectory for deterministic control problem with any dynamics that you want.",
            "So you write any deterministic dynamics that Maps state and action to ex prime, and you define the cost to be the state calls that you had before, and now you add this term which is the log of minus log passive dynamics at the current state and next state where the next state is given by your function and you have to be careful to make sure that 0 Sir respected right.",
            "So if something was impossible.",
            "It better not shop here.",
            "In the continuous case, the station get slightly more complicated, so I had to use the Onsager match lab function, which is a way to compute relative density.",
            "So basically, given two trajectories, you can ask what's the ratio of probability?",
            "Some small tubes around those trajectories, and then you take the limit of those tubes going to zero, and that that's your ratio.",
            "So when you define it that way, if you ask for the maximum interesting things happen so.",
            "The most likely trajectory for optimal control diffusion can be shown to be the optimal trajectory for deterministic problem, where the dynamics.",
            "R. But obviously there not there.",
            "Basically, I have X plus BU I forgot the bill.",
            "So you drop the noise and what you did is you corrected the cost function and the way you corrected the cost function is you added that the emergence of the passive dynamics.",
            "Here's a new medical exam."
        ],
        [
            "To show you that, so here's a little system scaler system.",
            "I pick some nonlinear passive dynamics which shown here the black curve, so I picked this out.",
            "It has like 2 stable points in one unstable point.",
            "The version such as the derivative shown here in red.",
            "So to find the most likely trajectory for the optimally controlled stochastic system given here, we drop this.",
            "We make a deterministic problem.",
            "We add the derivative of A to the cost of the running cost was actually 0.",
            "Just began to achieve A and then we solve the thing with some trajectory optimizer.",
            "And.",
            "So here's a comparison of the stochastic and deterministic versions.",
            "So this is the.",
            "This is the Z and this is the R that I told you about.",
            "So these are these are ability function as a function of time and space are is this?",
            "Forward filtering density to defend and use the thing we want to maximize.",
            "So what you see here is I saw the problem twice on a dense grid for different values of Sigma.",
            "I picked this problem, so we're changing the noise actually has a dramatic effect on the optimal solution, even though everything else remains the same and you can kind of look at how it had crashed in, see why, but so the red is.",
            "So what you think is the marginal density.",
            "Of course I cannot plot the actual meal which is against our trajectory because projectors high dimensional right?",
            "So the system like wants to be here so.",
            "When noise is small and it kind of wants to.",
            "So basically what happens here is the control gives out.",
            "It allows the noise to send the system to one of the stable points and then the last minute makes a big effort engulfed or zero, which is where the goal is and you can see this black curve which is the optimal trajectory for deterministic problem and it kind of matches pretty nicely the marginal of course is guaranteed to match the.",
            "Speaking of the marginal, so that's fine.",
            "This dotted thing is actually the second best local minimum, and it kind of corresponds to the thing that that's no longer optimal in it.",
            "Becomes optimum signal changes."
        ],
        [
            "And another nice property this has is compositionality of optimal control laws, and this is actually quite trivial.",
            "It comes from the fact that, so remember in the first exit case we're solving linear boundary value problems.",
            "An linear boundary value problems have the property that the solution on the interior is a linear function of whatever you put on the boundary, so in this case we're putting final costs on the boundary, and we're getting the optimal value function control on the interior.",
            "So if I put two different final costs and solve it, then I can take any linear combination of those final costs and the solutions are going to combine linearly in the same way, so I'll be more precise.",
            "Suppose if you pick a bunch of final cost GK.",
            "And you combine them in.",
            "This way you exponentiate you.",
            "Mix them somehow, take the log.",
            "And this is the final cost for the problem you want to solve.",
            "And suppose that that you've solved individual problems.",
            "So we have a bunch of problems that have the same dynamic, same running cost, different final costs.",
            "In this case, in this ability functions and the optimal controls for each of those are already known.",
            "Then the disability function for the problem you want to solve is simply the linear combination and the optimal control offer.",
            "The thing you want to solve is just a similar sort of linear combination of the control laws that you started with.",
            "Incidentally, the formula is the same both for the diffusions and for the.",
            "These discrete time process, even though we actually define derived somewhat differently.",
            "It's kind of cool.",
            "So this you can apply to LQG to do something quite surprising.",
            "So we can solve a bunch of LPG problems that have the same dynamics and running costs, but different final costs.",
            "And now we can combine them and now we can get analytical solutions to a very general class of problems that have linear dynamics.",
            "Running costs quadratic, but final cause that's pretty much arbitrary.",
            "Basically, the final cost has to be the log of a Gaussian mixture, but Gaussian mixtures are universal function approximators, so you can actually approximate anything."
        ],
        [
            "So here's a numerical example.",
            "Consider a bunch of systems that are.",
            "Basically we're integrating the controls and adding some noise.",
            "We're paying some costs for the control rate and will have some final costs, which are quadratics, data center, different things given by these constant CK.",
            "So position, time value, optimal cost to go for a single problem.",
            "The picture looks like this, so we have some quadratic at the final time and then quadratic somehow changes in time.",
            "The optimal control law is linear in its gain changes over time.",
            "An if you actually simulate this thing and look at the distribution of final states going to be very nice Gaussian centered, various trying to do now I can compose two of those analytically and I can get sort of multimodal things that do crazy things and you can compose a lot more of those if you want."
        ],
        [
            "Um?",
            "And finally, what we can do is we can actually try to develop a more powerful method for solving things based on function approximation.",
            "So here's the general idea.",
            "Again, this is the question we want to solve.",
            "This is for the infinite Horizon average cost case, where we have an unknown eigenvalue and it's the principle eigenvalue problem.",
            "So it's linear, but you know you're searching for functions defined over some very high dimensional space.",
            "And, well, we don't really have a way to find such things, So what you can do is you can."
        ],
        [
            "Define.",
            "Z to have some parametric form and we're going to pick this form.",
            "We're going to choose a bunch of so-called features, so features are just scalar functions over the state, and we're going to take linear combinations of those features, and Furthermore, we're going to parameterise the features themselves with some parameters stated that can somehow change their shape.",
            "So basically splitting the unknown parameters into parameters that have linear effect and parameters that have nonlinear effect, and then this is that OK, so take that zip, plug it in here and.",
            "Pick a bunch of collocation states, extend where you're going to enforce this conditions, and then you do least squares fit and you find optimal parameters.",
            "More precisely, how you do that, you end up solving this linear algebra problem, so Lambda F some matrix WS, your vector of unknown linear weights, G, some other metrics, and WS.",
            "Again, the unknown, and these matrices F&G how to evaluate them.",
            "If it's simple, you just evaluate all the features that all the colocation state.",
            "So that's trivial.",
            "Geez, complicates Oforji actually have to compute this integral, so this is the passive dynamics convolved with your features, and once you compute those then you just do some linear algebra and you're done.",
            "If you also want to adapt status, what you do is perfect Theta.",
            "You find the optimal W by solving a linear problem.",
            "You plug this in here.",
            "You compute the bellman residual now manages the function of data and you take the gradient with respect to data and do gradient descent.",
            "I don't know of any interesting problem that's convex, but certainly not this way.",
            "Uh, no.",
            "I don't believe any anything useful is going to be convex here."
        ],
        [
            "Here is an example.",
            "No, no gradient centers.",
            "What means useless convex?",
            "OK, so I mean whether something is comics or not is pretty much irrelevant.",
            "The only thing that's relevant is how quickly your Newton method is going to converge and how good that local minimum is going to be.",
            "Now there lots of convex problems for Newton's method actually takes a very long time.",
            "And Conversely, there lots of non convex problems where you are thinking computer application so that in practice.",
            "Now it's hard to prove theorems, but doesn't mean it's useless.",
            "Here a couple of examples.",
            "These are just scalar system.",
            "This is a metric like an inverted pendulum.",
            "The cost is to move either this way or this way at constant speed.",
            "Here this is this car on the Hilton.",
            "The cost is to be here with this velocity or here with this post.",
            "So basically setting up this cost to create limit cycles here.",
            "This thing can actually hit the wall and it was dropped to 0.",
            "So this is state cost.",
            "This is optimal control laws computed exactly basically on very dense grids.",
            "This is the empirical 'cause this is all trajectories of the system look like.",
            "OK, here's our function approximation with 40 Gaussian basis that were thrown somewhere and then we adapt adapted their means.",
            "Paris, so the adaptation of the missing components is crucial.",
            "If you don't do that, this looks really bad.",
            "If you don't want you to look bad, and if you want to keep the means of covariance is fixed, you have to increase the number of Gaussians alot.",
            "So basically what I'm saying is that.",
            "You know, if you try to put a grid over the state space, the curse of dimensionality is going to kill you.",
            "Obviously if you try to put a bunch of features that are localized.",
            "The curse of dimensionality is still going to kill you because effectively you still need the grid over the state space, right?",
            "Because they're localized, I mean.",
            "Yeah you can.",
            "You need the number of grid points per dimension is now smaller, but the exponent is still something very large.",
            "The only way to get around from that is to not try to cover the whole state space, but you try to allow your method to figure out where it should put the basis and just cover that part of state space and all the rest.",
            "So having this thing adaptive is actually essential.",
            "Unfortunately, that's where the IT becomes an art more than science.",
            "I've converted."
        ],
        [
            "So, so let me just make a couple of remarks on that.",
            "So we've played with these things for awhile.",
            "I just said that location States and basis need to cover the unknown regional state space or the optimal control dynamics tend to live for trying various adaptive methods.",
            "Not know principle way to that."
        ],
        [
            "11 trick would be to use the trajectory optimization to figure out where the system should kind of go and then put your bases there and use that to initialize.",
            "Or if you're doing something like imitation learning.",
            "Basically collect data from a human doing something.",
            "Put your basis functions there and then solve an optimal control problem for a robot that supposed to do the same thing."
        ],
        [
            "The computational bottleneck in all this is evaluating these integrals that elements of that matrix G. So basically involving these things.",
            "There are cases where you can do this analytically.",
            "So if you represent P as mixtures of Gaussians, or just single Gaussians, and these guys are Gaussians, multiply that by polynomials.",
            "Then you can do this analytically, which is very nice.",
            "So this is our favorite function approximator right now.",
            "You know Gaussians multiplied by polynomials are actually quite nice, because you know the kind of local, but you can give them a lot of freedom and polynomial and.",
            "Coefficients of the polynomial actually show up linearly, so all that extra freedom is actually handled by a single\\ in Matlab, and you don't pay for it.",
            "No, not quite a sorry quadrotor.",
            "I just there's a formula maybe called culture.",
            "OK, there is also.",
            "There's also something or curvature, which is unfortunate that basically is a numerical approximation which tends to become very inaccurate very quickly in high dimensions, as we discovered recently.",
            "So I mean, we've made progress in various aspects of this, but I can summarize.",
            "Many more hours of talking."
        ],
        [
            "By saying that the numerical methods derived from this framework are much more efficient than what we had before, but they are not enough to beat the curse of dimensionality.",
            "So are we back to where we started and hopefully not so do we have our methods that are likely to work really well once we have something else to help them?",
            "So basically by themselves, I don't think they're going to work.",
            "But I believe that even more strongly about every other method that's out there.",
            "But if we have something else that kind of gets the right idea, these things can help and build sort of regions of attraction and feedback controls that make sense.",
            "Anne.",
            "So now I'm going to switch to something else that I'm very hopeful about right now.",
            "Before I switched that, let me say that so this this summarizes world I was done up until maybe two years ago.",
            "It's in a paper that appeared on the 1st slide, which you can read if you want some PNS since then couple of."
        ],
        [
            "Especially my postdoc if angles in my student DJ who is have been doing a lot of interesting extensions and they're going to be talking about them on Saturday and sending in particular, there is now, so we always see this scale divisions thing all over and over and over again, so they figured that you can use a renewed dye vergence and you can set up a game theoretic.",
            "You know scenario where you gain get these linear solvable things, and they're actually a generalization of everything we've seen so far, and you can reduce.",
            "You can obtain all the other cases from it, but you'll see that on Sunday.",
            "So, um.",
            "That's that, now what are we going to do next?"
        ],
        [
            "We're back to good old trajectory optimization.",
            "Why becausw?",
            "Having done this for years and having looked at all the beautiful scalar examples that we put in our papers, I convinced myself that it's not really going to allow me to do things I want to do, at least not by itself.",
            "It's really good for writing papers, and we managed to write like 1015 papers on this in a couple of years.",
            "But if you want to actually control something rather than write papers about control.",
            "It's um, it's a different story, so we pick trajectory optimization because that's what works.",
            "Actually, let me tell you a funny story to kind of make this transition.",
            "So about two years ago I gave a talk at a conference code dynamic walking, so that's a that's a meeting.",
            "Nice robotic say some people from mechanics, somebody mechanics.",
            "Basically there are smart people.",
            "Their goal is to create walking robots and complicated machines.",
            "Also understand human movement.",
            "Most of these people at some point in their life have tried some mathematically glorious idea.",
            "That's going to tell them how to do control.",
            "And they failed.",
            "So now they're doing more intuitive things that actually work.",
            "But if but if you show up with some great mathematical idea, there are very supportive.",
            "Like, yeah, go for it, come back and let us know how it works out.",
            "Fine, so I gave a talk.",
            "Basically this and they are very supportive after me.",
            "There's a I don't know how many of you know arrested Rick at MIT is sort of.",
            "Does robotics control?",
            "He used to collaborate with with Pablo?",
            "And so he got up and gave a talk about another glorious mathematical idea which is building 3 self linear quadratic regulators and using sum of squares optimization to improve stability.",
            "Bounce and then make sure they overlap so the whole thing becomes stable so.",
            "Same response, great golfer, it shows this year at the same conference my group presented our latest work.",
            "We shall lots of things that work really well as a show.",
            "In a moment, the phrase linear solver optimal control is not even mentioned because we're not using raster tricks.",
            "Group got up and gave a talk.",
            "They showed lots of things that work.",
            "Sum of squares optimization was not even mentioned, like they're doing trajectory optimization the same way as we are, because that's how it works."
        ],
        [
            "Before you do.",
            "Oh yeah, much more positive.",
            "We even got a DARPA grant as a side effect.",
            "If you're going to do that, can somebody tell me how much time I have?",
            "OK.",
            "So if you're going to trajectory optimization, this is heavily model based.",
            "I mean you're doing everything in the model.",
            "If you're going to do a model.",
            "If you look at so.",
            "Actually this is one of the problems with control.",
            "In general, so you start with an equation that X dot equals FX yuan.",
            "You derive a lot of stuff.",
            "And then the time comes to Kaplan example an you have to scratch your head and say what is F?",
            "Well, you know, I just did all this math I have.",
            "You know two weeks before the conference paper.",
            "I'm not going to come up with some elaborate F. I'm going to do an inverted pendulum or something.",
            "Now the F for a really interesting system is something incredibly complicated that you couldn't write down by hand, even if you spend several years writing.",
            "Instead, you have to use.",
            "Design simulation software to actually simulate F for you, and then you have to connect it to whatever controllers dot you're using.",
            "And that's actually not so simple.",
            "So very few people do, so having realized that, and also having realized that the simulation software that's out there is really designed for simulation and gaming and not for control, I've spent the last.",
            "Three years almost developing a new physics engine which is specifically tailored for control.",
            "So now it's almost finished.",
            "I will be using it very soon.",
            "Fact I'll show you examples of using it already, so it combines the best recursive algorithms for smooth dynamics in robotics.",
            "We developed a bunch of new algorithms for simulating contact dynamics.",
            "Turns out, contact dynamics is really the key to getting robots to do interesting things.",
            "It's a lot higher than the smooth dynamics.",
            "People have always sort of swept it under the rug and then it manually, but that doesn't scale.",
            "And this is an open research problem.",
            "Like I alluded to earlier, we don't have a principled way to do it, so everything out there is some kind of approximation.",
            "It also models things like tendence mathematics.",
            "Currently trans 100 times faster than real time on a single core on a desktop.",
            "For something like 23 degrees and humanoid.",
            "And most importantly, it uses parallel processing to compute finite difference approximations to derivatives and derivatives.",
            "Of course, what you need to do optimal control.",
            "So basically, without this we wouldn't be doing any of the stuff I'm about to show you, so this has really been an enabling technology."
        ],
        [
            "Let me just quickly give you an overview of trajectory optimization methods.",
            "That's not at all standard, but when you start doing it in practice, you realize that you have a lot of choices.",
            "So here's the general procedure.",
            "There are bunch of relevant variables that we need to compute, so we are talking specifically about problems, so there are positions.",
            "There's velocities, secondary systems, there are talks or forces that you're playing, and there are contact forces between the robot in the environment.",
            "OK, So what you do is you split them into a set of independent and dependent variables independent variables, meaning that you can compute them as functions of the independent ones.",
            "OK.",
            "If the independent variables are actually couple.",
            "So if you pick them over complete representation, for example, you chose to optimize both positions and we lost it for whatever reason.",
            "Then you have to impose constraints.",
            "And then this is very critical.",
            "If there's contact dynamics, you have to find some way to smooth it that's physically realistic, and yet it's smooth enough to allow gradient descent things to work.",
            "And this is really key.",
            "Without that, you basically get stack instantly and you optimize.",
            "It will never make any progress.",
            "And then after you've done all that you want to apply some 2nd order sort of classes, 2nd order method, and usually you do it with continuation continuation means that you first define the problem that somewhat easier to solve.",
            "For example, you allow your about to kind of grab itself by the head and move itself to the room, and then, which is very easy way to work to do locomotion, just flow through there and then gradually you penalize that kind of thing so it's forced to discover walking and such.",
            "So there are lots of ways to partition this.",
            "For example if the talks or the control signals are the independent variables, then everything else is dependant.",
            "You can get it to forward integration.",
            "And then you solve it with things like differential dynamic programming.",
            "Try to define both talks and the contact forces to be independent instead of getting the contact force through simulation.",
            "And then you have to enforce some constraints that are now solved.",
            "That actually tends to work better because contact force is really important and you don't want to treat them as a side effect of the dynamics you actually want to let the optimizer reason about them directly so that works better.",
            "You can define only the positions, so this is another way to do it is called space time optimization.",
            "So you define the sequence of positions through the entire trajectory and you treat the entire project is 1 big vector, which is the number of.",
            "Degrees of Freedom times, number of time steps.",
            "You you are finite difference.",
            "To compute the velocities you apply inverse dynamics to compute the torques, either contact them if you have to invent some contact simulation algorithm that's actually invertible, and we've done that and then you have the positions, velocities, controls and everything you define.",
            "The cost changes apply Newton's method to it.",
            "You don't actually need to know anything about control theory whatsoever to do that, just need to know calculus in Newton's method basically.",
            "Sadly, that's one of the things that works best, and there's some other variations."
        ],
        [
            "So specifically here, the class of matters that we use.",
            "The first one is actually model creative control.",
            "So what is model pretty control?",
            "So here's the idea.",
            "In some state blue you're going to compute an optimal trajectory after some time horizon, which is as long as your computer allows.",
            "And then you're going to execute the first portion of that trajectory.",
            "And what happens is probably not what you plan.",
            "'cause there may be model errors, noise, God knows what you're going to transition here.",
            "That's OK, because when you find yourself here, you're going to compute another optimal trajectory going to execute the first step come here, etc.",
            "So it's a wonderful idea.",
            "The only catch is that you have to be doing optimal control in real time, so you have to be fast enough, in fact.",
            "Sorry, I can tell if you're if you have an optimizer that is fast enough to do this.",
            "And shorter analytical formula actually gives the optimal control.",
            "I don't know why you would do anything else.",
            "I mean maybe to save electricity because some computer cluster is going to be working really hard to do this, but but this thing works amazingly well if you look at things like chemical process control is basically what everyone does becausw the dynamics are slow and smooth enough to throw out random with your optimizer.",
            "In robotics it's almost never used except for like really simple to problems because people didn't have optimizes the graph.",
            "Projector with respect to what I have said?",
            "OK, so you have your running costs and then you're going to put some final cost on the horizon.",
            "That final cost is going to be some heuristic approximation to the optimal value function is the same thing as the heuristic evaluation functions in chest.",
            "In fact, you can think of chess as model creative control like you know you unfold the three after few moves.",
            "In the past you evaluate your heuristic, you propagate back, you decide how to move, you move, you see what your problem then do it again.",
            "Except the Game 2 rating setting, so of course it has complications.",
            "Right, so you need some some heuristic for that."
        ],
        [
            "The other actually, so I should prob."
        ],
        [
            "We interleave OK, so let me show you some results using this approach.",
            "So here's the simple one.",
            "So here's this is a three degree of freedom robot.",
            "The goal is to bounce this ping pong ball.",
            "It bounced at various Heights because the cost function on every bounce kind of changes.",
            "It's perfectly interactive, so you can push it, grab the ball, whatever.",
            "It's just doing MPC.",
            "We're computing an optimal trajectory once every 10 milliseconds.",
            "And we're computing it from now until the next contact with either ball.",
            "Why is my MPEG decoder doing this exam?",
            "Sensor says Vicon system that basically sees the balls as markers.",
            "It's the infrared motion capture system and then there are in colors in the in the joints of the robot.",
            "OK, so here is the.",
            "Most complicated thing with that in MPC, so this is the task of getting up full humanoid full dynamics when it's green.",
            "That means the brain is switched off so it falls down.",
            "Red Arrow is external force that we have a way of injecting into a simulation with the six degree of freedom mouse, which is the most beautiful gadget ever and orange means the brain is on so it gets up this on a single desktop with two 6 core processors runs about five times slower than real time right now.",
            "Which means that on a cluster with like five or six computers, we can already run in real time.",
            "So again, I should point out that this thing scales beautifully in parallel because almost all the time is spent finite difference in the dynamics and getting the derivatives and that can be just branched a whole cluster.",
            "And this is indestructible.",
            "This is like you can do anything you want to it and what is wrong with the goal?",
            "OK, so good question.",
            "The goal is to put the center of mass 1 meter over the feet so and save energy along the way if you can.",
            "So you can see that the arms don't.",
            "Here the goal is to is to keep the center of mass moving forward.",
            "Add stuff.",
            "OK, so so MPC.",
            "That works rather well."
        ],
        [
            "Remember, this kind of space time optimization, so alternative approaches just parameterized the sequence of positions and optimize that how object.",
            "He"
        ],
        [
            "An example of that.",
            "OK, so the cost again make the center of mass move forward with.",
            "So here we actually we have proper and so here we are, minimizing power in Watts.",
            "It ends up walking with something like 20 ones.",
            "This is 84 kilogram humanoid.",
            "It's actually pretty amazing.",
            "Amazing because I mean if you think about it, there's no friction in it, so there shouldn't be that much energy dissipation.",
            "There is only friction with the ground, yes, but you're not really sliding on the ground.",
            "You basically stop and then you left.",
            "So yeah, you lose some energy when you hit the ground, but you don't hit that hard.",
            "Um?",
            "Right, so when you do running, you hit the ground much harder so it costs a lot more.",
            "Yes.",
            "This thing has 18 or no.",
            "I think this one has 23 join so it has 23 degrees of freedom and there are about 30 to 50 timesteps.",
            "I'm not sure how many are in the trajectory, so let's say 20 times, so somewhere between 500,000.",
            "Yes.",
            "I don't have hands moving because when you walk the passive dynamics will cause your hands to swing and it will be expensive to stop them.",
            "And once they start slinging turns out you can swing them a bit more to somehow transfer meant.",
            "I'm going also.",
            "I mean I don't know why.",
            "That's you know that's the beauty of optimal control is that you don't need to know why.",
            "You just say what you want to happen an your fast computer does it for you.",
            "I like a model.",
            "This is more sexy.",
            "Yeah we should if you know the cost function for sexiness, let me know."
        ],
        [
            "So the last thing I'll show you is actually the most interesting thing with them, so here we really develop this idea that Contacts are the key to interesting behaviors.",
            "Anan we really have to come up with clever ways to handle them.",
            "So what we did is we defined.",
            "A very unusual formulation of the cost function, which sort of forces the optimizer to think hierarchically about Contacts and trajectories.",
            "So here's the idea.",
            "We're going to be optimizing the trajectories for characters that look like that, and the optimizing the sequence of positions plus a bunch of additional decision variables.",
            "Column CIT.",
            "What Si says is that it basically indicates potential contact.",
            "I should be active in movement Phase 50 SE.",
            "I'm 50, just splits time into a few discrete phases and these guys say is given contact.",
            "Let's say between my hand and table.",
            "Should it be active in this space?",
            "White faces?",
            "Because if you look at Contacts, what usually happens is that you know you touch something, then you do something for awhile, but you're in contact for awhile.",
            "You know the contact forces themselves may change.",
            "You may even have things like like rolling contact, but you are in contact then if you break contact for awhile you.",
            "Broken for awhile, so that's the way to compress the problem.",
            "So basically we're forcing the optimizer to declare if it wants to make Contacts or not, and then these variables affect the cost.",
            "So here's what we do.",
            "We add this extra custom which basically says in this a lot of jargon what it simply means that if you said you're going to be in contact, and if you're not in contact, I'm going to penalize why would you ever say that you want to be in contact?",
            "'cause if you don't say that then it's very expensive to generate contact forces.",
            "OK, so if you want contact forces, you have to declare them.",
            "If you don't declare them, it's going to be costly to generate.",
            "This.",
            "Some.",
            "No, because we said so.",
            "We changed the problem formulation, so here's what we're.",
            "Again, we're trying to force the optimizer to think about Contacts explicitly, not as side effects of the kinematics and dynamics, but explicitly, and so the question is, how do you do that when it's optimizing both projector and the Contacts?",
            "How do we force it to actually think about the context when they're fully determined given the trajectory?",
            "So we kind of have to allow some kind of mismatch between the two, right?",
            "And then and then?",
            "If there is a mismatch, we need to have some custom that forces the thing to become consistent, but because it was thinking about these abstract contact events.",
            "The hope is that they're going to once you force them to become consistent, they're going to drag the whole trajectory to almost more sensible movement.",
            "It's all heuristic, but that's how it works, you know?",
            "Let me show you how well it works."
        ],
        [
            "So this happens later in this movie.",
            "This is actually something else I don't have time to talk about.",
            "OK, so this is a trajectory optimization in progress, so here it thought of some trajectory and now it's thinking how to refine it.",
            "And then it starts executing it and see all this sequence of steps.",
            "Came from a simple cost function which said please make sure that your tour is over that cross over there.",
            "At the end of the movement.",
            "I don't care what you do, just put the torso over there so this entire thing with all these steps.",
            "Obviously adjustments everything came from optimal control trajectory optimization.",
            "Simplest possible cost you can imagine, plus against some joint torques.",
            "Yeah, sure, the dynamics.",
            "Independent variables the, so this is the way this is encoded actually is we called the end effector positions and then we use inverse kinematics to find the joint angles.",
            "But it's just a convenience to help the optimizer a bit more.",
            "If you put a target high app.",
            "So here we have the big friction coefficients to feed there about 2:00, so that kind of sticky, so it can invent climbing.",
            "Here we ask you to put that also upside down so it can do hand stands.",
            "So basically, just by changing the initial configuration where the target is, you can get all kinds of diverse movements.",
            "Now this is nowhere close to the other.",
            "Let me comment on this.",
            "So here's the task is to get the ball down.",
            "The cost function doesn't say anything about these.",
            "Humans will optimize as well.",
            "This ball thing doesn't have an actuator, but these humans do.",
            "So let me figure out how to use them.",
            "And here's how I use them.",
            "They have a shared brain, so this is coordinated control and they're not independent.",
            "Here the little guy has to put his head up there and optimizer figures out that you know the big guy has to help him somehow.",
            "So again the cost function here is at the end of the movement.",
            "The head has to be up there.",
            "That's it.",
            "Everything else comes out of dynamics, an optimization.",
            "Between 2 and 10 minutes, but this is not optimized for real parallelism yet, so this has a lot of room for improvement.",
            "I don't think this will run in MPC model, but the other things do OK here.",
            "The cost is to spin the pen in the vertical plane.",
            "Cost function doesn't even mention a hand, but obviously you have to use a hand to make that happen.",
            "So we use the hand.",
            "Here the cost the cost function says spin the pen in the horizontal plane apparently and some other movement emerges.",
            "Here what's going on?",
            "His supposed to somehow toss it and catch it?",
            "I forget how this was encoded, but something really simple.",
            "Again.",
            "I mean, in general we found that exactly how you encode the task doesn't make much difference like this.",
            "How you formulate these Contacts, that's where the magic is really.",
            "The optimizer itself is just off the shelf, but we're not doing anything on the optimization front.",
            "Can do the same thing with the robot hand.",
            "It has to pull this thing up.",
            "He has to spin the pen so same, actually same cost as before, but now it doesn't have enough fingers to lift it up in there, so it ends up using the table to support it during the spinning phase.",
            "It's fully emergent thing.",
            "He has to put the object in the air.",
            "Here it has two.",
            "Embodiment, I mean the the actual mechanics of well I mean all is very natural.",
            "Yeah, it seems very natural.",
            "I mean, this is a fairly realistic simulations.",
            "They're not like real robot yet, so we'll see.",
            "So that's that.",
            "So obviously we want to."
        ],
        [
            "To play with real robots, so that's where we're heading next.",
            "We have two of them, so this actually sounds the most advanced robots that anyone has right now.",
            "This.",
            "Is made by Coco in Japan.",
            "It has about 40 degrees of freedom, pneumatically actuated, so it has 80 valves.",
            "So the state is in each the pressure inside each cylinder is a state variable because they have time constants like 5060 milliseconds.",
            "So this thing has 160 dimensional state space.",
            "Here we're just asking it to go to random poses for system ID purposes.",
            "We haven't really figured out how to control the whole thing.",
            "This is called Shadowhand, except we bought one and realized it's the actuation is a joke, so we returned it and we built our own actuation.",
            "This is the thing that's so disappointing pointing to wrong places of pneumatic cylinders.",
            "They put on this tendence.",
            "This is actually moving through one joint at a time.",
            "This is real time, so this is several times faster than a human hand with the new actuation.",
            "So we'll be trying to control these things.",
            "The other thing we're doing, we're very excited about is this thing called that robotics challenge, so I don't know if you've heard of it, but you will be hearing about over the next couple of years 'cause the whole robotics community worldwide is gearing up to do this.",
            "So remember the Fukushima disaster that somebody had to turn off the nuclear power plant, but it was dangerous for humans so dark, but decided to build robots that actually do that.",
            "And apparently they're quite serious, so the idea is to build these robots that build by Boston Dynamics.",
            "Same people who build the big dogs, little dogs, and such.",
            "They actually already have them.",
            "And it looked like that.",
            "So this thing has to walk across rubble.",
            "Get a car, open the car, get into the car, drive the car, get out of the car.",
            "Pick up a power tool.",
            "Climb a ladder.",
            "Open the door, demolisher concrete panel going to a dark room located valve that's leaking and go and turn it off and maybe come back if possible.",
            "Perfect man hey yeah.",
            "You wanna get some?",
            "Speaking of radio, of course there is a human operator involved, right?",
            "So you are allowed to have an operator you have Wi-Fi type bandwidth, but you cannot joystick something that has 30 degrees of freedom, like you cannot tell operate such things so clearly the thing has to have a lot of control intelligence built in.",
            "Then the operator is basically going to be sending commands on a fairly high level is because human cannot still.",
            "No, there's about and how detailed no, no, I mean Wi-Fi is says that they're going to degrade the channel capacity because they want you to use this little bandwidth.",
            "Possible, they're giving a Wi-Fi.",
            "The problems that humans cannot joystick.",
            "30 degree freedom robots.",
            "I mean, you cannot tell operate that thing.",
            "You can probably tell you now call, but there maybe like move this arm here or whatever.",
            "But you know, this has real time dynamics, for example, when it starts following, it takes.",
            "I don't know 100 milliseconds before we're going to do any cost $1,000,000.",
            "And there's a nuclear power plant to be turned on.",
            "So we'll see how that goes, but basically the goal is to use this planning trajectory planning algorithms to quickly come up with.",
            "Sensible and physically plausible plans in some seconds.",
            "Once we have that do MPC random words, the linear sub optimal control fillingane?",
            "Do we get back to it after optimization?",
            "I think we do because.",
            "I mean, just 'cause you can do MPC multiplicative control.",
            "It's kind of silly.",
            "I mean basically what you're doing is you're rediscovering walking once every 10 milliseconds.",
            "Really, do you have to do it so once you discover it, maybe you can somehow cache all these solutions and fit this model global basis function approximators and and solve linear systems and build bigger?",
            "Bigger feedback controllers with bigger region of attraction but but it's a good thing that we have this trajectory optimizers, because without that we can't even get started.",
            "So thank you for listening.",
            "Quite discouraging to the theory.",
            "Yeah, having done it for a few years and discouraging to me, no.",
            "I mean look, I don't think it's discouraging, it's just that.",
            "The theoretical challenges.",
            "Well, one of them is impossible, which is to understand nonconvex optimization.",
            "We can.",
            "Maybe there are special classes of non convex functions where you can say things but is a humanoid robot going to fit in that special class.",
            "The dynamics and interesting content analysis, yeah.",
            "Yeah, so so.",
            "It's pretty clear that my Contacts are keyboard in terms of sensing and in terms of planning.",
            "So yeah, so that's one inside that.",
            "I mean, I actually quite a few people in robotics nowadays have because more and more people are moving in that direction.",
            "We probably have the best planners, but a lot of people working in that direction already.",
            "Directly, I don't know.",
            "I mean usually when you do, I think the best way to do things is like you know, start working really hard.",
            "Empirical problem, get stuck, realized why you're stuck, and define the theoretical problem that you need to solve.",
            "If if your motivation is OK, how do I write the next CDC paper?",
            "I know there's lots of theories you can develop that way, but are they useful to anyone?",
            "We don't know if your motivation is not developed theory that actually makes that happen.",
            "You know it'll probably end up being a different kind of theory, hopefully is going to be there someday, but I. Pepper"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This talk is going to have two parts.",
                    "label": 0
                },
                {
                    "sent": "The first one will summarize the number of results with obtained over the past few years that are closely related to things that people have been talking about here and then.",
                    "label": 0
                },
                {
                    "sent": "The second part is going to be about the next thing we're doing, so linearly suboptimal.",
                    "label": 0
                },
                {
                    "sent": "Control it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The class of stochastic optimal control problems that can be reduced to solving linear equations.",
                    "label": 0
                },
                {
                    "sent": "The way I got into this was very interested in some old papers by Fleming and meter that were, you know, playing with PDS and turning linear into nonlinear.",
                    "label": 0
                },
                {
                    "sent": "Once an identifying diffusions that can be reduced to linear equations.",
                    "label": 0
                },
                {
                    "sent": "And I thought, you know, can this be somehow generalize?",
                    "label": 0
                },
                {
                    "sent": "Then use the computationally?",
                    "label": 0
                },
                {
                    "sent": "So here's the here's the problem setting that.",
                    "label": 0
                },
                {
                    "sent": "You can make linear, so in the stands for a Markov decision process.",
                    "label": 0
                },
                {
                    "sent": "Or that is so traditionally what people do is you have a control that chooses an action you which in turn specifies the transition probabilities.",
                    "label": 1
                },
                {
                    "sent": "So if X is the current state, use the action you choose.",
                    "label": 0
                },
                {
                    "sent": "You have some control stochastic dynamics that tells you what's the probability of every possible next 8X prime.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to modify this as follows.",
                    "label": 1
                },
                {
                    "sent": "So instead of asking the controller to pick symbols that are symbolic actions, and then having some function that Maps those probabilities, we're going to allow the controller to pick those probabilities directly.",
                    "label": 0
                },
                {
                    "sent": "OK, so the controller is actually now conditional probability function calling from X to X prime.",
                    "label": 0
                },
                {
                    "sent": "Addition, we're going to define passive dynamics, which is basically what the system would like to do.",
                    "label": 0
                },
                {
                    "sent": "If you don't control it.",
                    "label": 0
                },
                {
                    "sent": "NDPS usually don't have that, so if you look at the reinforcement learning literature in gridworld, since there is no such thing as passive dynamics, usually designed.",
                    "label": 0
                },
                {
                    "sent": "But if you look at any physical system, there is a notion of passive dynamics, or when you set the control to zero, that's what the passive dynamics is OK, and we need to restrict this so that if the passive dynamics if some transition is impossible under the passive dynamics, it has to remain impossible under the control.",
                    "label": 0
                },
                {
                    "sent": "For some things to become finite.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so we're going to restrict the running cost or the cost rate to be in this form.",
                    "label": 1
                },
                {
                    "sent": "So little L is going to be running costs function of state in the control, so it can depend on the state in any way it wants and the control is going to penalize be penalized as the care divergent between the transition probabilities you pick and the transition transition probabilities that the system would like to do.",
                    "label": 0
                },
                {
                    "sent": "If you didn't control it.",
                    "label": 0
                },
                {
                    "sent": "So basically the control can impose any dynamic situations.",
                    "label": 1
                },
                {
                    "sent": "However it pays the price for pushing the system too far from what it wants to do.",
                    "label": 1
                },
                {
                    "sent": "This input, in practice this is important not only because it makes the cardioversions finite, but also it prevents silly things like teleporting yourself to the goal state in one step, right?",
                    "label": 0
                },
                {
                    "sent": "Ideally, we wouldn't want to do that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's very easy to see that this reduces to linear equation, so this is the two line derivation.",
                    "label": 0
                },
                {
                    "sent": "So this thing on the top is the standard Bellman equation.",
                    "label": 0
                },
                {
                    "sent": "This is your optimal cost to go or value function is the minimum overall actions of the immediate cost which we defined to be this.",
                    "label": 0
                },
                {
                    "sent": "This formula for Kelly Burgess plus the expectation over the value of the next state will take expectations over the same thing.",
                    "label": 0
                },
                {
                    "sent": "We can buy the logs and so now we're minimizing over something that's basically a Cal diversions, but it is a normalized.",
                    "label": 0
                },
                {
                    "sent": "So divide and multiply by a normalization constant.",
                    "label": 0
                },
                {
                    "sent": "This thing becomes zero and you get.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A closed form solution for the control law, which is that it's your passive dynamics waited by the exponent of your optimal cost to go function, which we're going to cozy.",
                    "label": 0
                },
                {
                    "sent": "And then normalized so this normalization operator is just the sum of that of the numerator while we calling this thing a desirability function is going to become clear in a moment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I solved to summarize what we got is.",
                    "label": 0
                },
                {
                    "sent": "Basically we're looking for a function Z that satisfies this equation, so Z is equal to exponentiate state cost times.",
                    "label": 0
                },
                {
                    "sent": "This linear operator.",
                    "label": 0
                },
                {
                    "sent": "So in a picture, what does that do?",
                    "label": 0
                },
                {
                    "sent": "Well, here's why.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's so suppose X is the current state.",
                    "label": 0
                },
                {
                    "sent": "Passive dynamics tells you what the next days like today it's the black.",
                    "label": 0
                },
                {
                    "sent": "So density an supposed to computer ZNZ happens to be this blue thing.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you multiply the black thing by the blue thing and what the blue thing does is basically shifts this passive dynamic stores the parts of the state space where you like to be, so that's why we're calling the desirability function.",
                    "label": 0
                },
                {
                    "sent": "Sort of pushes it towards your desires, and then you sample and directing, and that's your next day.",
                    "label": 0
                },
                {
                    "sent": "So the rating is the optimal control dynamics.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now you vote yes.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at a bunch of examples where we use this thing to approximate systems that we're already working with.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, the next two slides we will give you another very specific answer to that question, so we also know that from birth working also from central mirrors work and.",
                    "label": 0
                },
                {
                    "sent": "Others turns out that there is a class of controlled diffusion that also reduced to linear Hamilton, Chicago.",
                    "label": 0
                },
                {
                    "sent": "Many questions, and they look like that.",
                    "label": 0
                },
                {
                    "sent": "So this is stochastic dynamics.",
                    "label": 0
                },
                {
                    "sent": "You have some passive dynamics that can be nonlinear.",
                    "label": 0
                },
                {
                    "sent": "The key condition is that the States and the controls have to live in the same subspace, so anything that the control could do could have happened by accident and vice versa.",
                    "label": 0
                },
                {
                    "sent": "For example, if you are sitting in that chair, you fall asleep, you could accidentally get up and walk out of the door.",
                    "label": 0
                },
                {
                    "sent": "That must be possible in order for you to actually be able to walk out.",
                    "label": 0
                },
                {
                    "sent": "Perfect, but you know, that's how the math works.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The control cost.",
                    "label": 0
                },
                {
                    "sent": "Sorry the cost rate can be any function of the state and then the penalty for the control has to be related to the noise amplitude.",
                    "label": 0
                },
                {
                    "sent": "So basically the more noise in the system is, the cheaper is to control advisors.",
                    "label": 0
                },
                {
                    "sent": "So actually this shows that these things don't have a meaningful deterministic limit, right?",
                    "label": 0
                },
                {
                    "sent": "So if you try to send the noise going to 0, control will become infinitely expensive and you can define the problem, but you never move.",
                    "label": 0
                },
                {
                    "sent": "Alright, so for these problems you can show we know what the optimal control of this is like.",
                    "label": 0
                },
                {
                    "sent": "Control affine system and then people have shown that you do a standard logarithmic transformation.",
                    "label": 0
                },
                {
                    "sent": "You get this linear equation where L is your second order linear differential operator.",
                    "label": 1
                },
                {
                    "sent": "That's the generator of the passive dynamics where you set to 0.",
                    "label": 1
                },
                {
                    "sent": "So what do this problem classes have to do with each other?",
                    "label": 0
                },
                {
                    "sent": "And we obviously they're both stochastic optimal control problems that somehow reduced to solving a linear problem.",
                    "label": 0
                },
                {
                    "sent": "They started out being very different.",
                    "label": 0
                },
                {
                    "sent": "So here's how.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can relate them.",
                    "label": 0
                },
                {
                    "sent": "So basically the thing I defined first is sometimes much more general.",
                    "label": 0
                },
                {
                    "sent": "You can reduce it to the control diffusion in the following way.",
                    "label": 0
                },
                {
                    "sent": "So obviously what I did find those discrete time.",
                    "label": 0
                },
                {
                    "sent": "This is continuous time, so we'll have to take in continuous time limit.",
                    "label": 0
                },
                {
                    "sent": "So let's define the passive dynamics for our linear MDP, so it's going to be done in the obvious way, right?",
                    "label": 0
                },
                {
                    "sent": "So remember we need to define this passive dynamics going from X to X prime.",
                    "label": 1
                },
                {
                    "sent": "We're now going to index it by the time step and take the limit of age cost to 0, so it's going to be a Gaussian.",
                    "label": 1
                },
                {
                    "sent": "It's going to be centered at the next state where the diffusion is likely to find itself.",
                    "label": 0
                },
                {
                    "sent": "You don't control it X + H A and then it's variance.",
                    "label": 0
                },
                {
                    "sent": "It's going to be basically how much violence variance diffusion is going to accumulate in time step H, which is, which is this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now.",
                    "label": 0
                },
                {
                    "sent": "The discrete time step costs is going to be Q of H times.",
                    "label": 0
                },
                {
                    "sent": "Usual cost times age because that's how long you accumulated cost OK and now.",
                    "label": 0
                },
                {
                    "sent": "How do we get?",
                    "label": 0
                },
                {
                    "sent": "What do we do with the scale divisions cost?",
                    "label": 0
                },
                {
                    "sent": "So now the densities are Gaussian, so we have a formula for evaluating the care divergent, so the care divergent between two Gaussians with the same covariance is just the square difference between their means, weighted by the inverse covariance.",
                    "label": 0
                },
                {
                    "sent": "If the queries are different, this becomes slightly more messy, but here they are not.",
                    "label": 0
                },
                {
                    "sent": "So here's the picture, right?",
                    "label": 0
                },
                {
                    "sent": "So you hear the passive dynamics wants to take you here with sorry with some Gaussian you are pushing it here.",
                    "label": 0
                },
                {
                    "sent": "KL divergent between those two things happens to be the usual quadratic energy costs that we all know and love.",
                    "label": 0
                },
                {
                    "sent": "So basically we can start with this LM GPS, specialized the densities to be Gaussians and take this continuous time limit, and you can recover those diffusions.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "But of course you can do also many other things that you can.",
                    "label": 0
                },
                {
                    "sent": "You can do things in discrete time that don't correspond to any sensible continuous time.",
                    "label": 0
                },
                {
                    "sent": "Process like for example the way that contact dynamics are simulated these days.",
                    "label": 0
                },
                {
                    "sent": "Turns out you cannot define continuous time.",
                    "label": 0
                },
                {
                    "sent": "Equations of motion becausw columb friction is not defined in continuous time.",
                    "label": 0
                },
                {
                    "sent": "There's a paradox that's about 120 years old.",
                    "label": 0
                },
                {
                    "sent": "Explains to you why that's not possible.",
                    "label": 0
                },
                {
                    "sent": "And then many other situations where you can play.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This so here's a summary of mostly linear Bellman questions.",
                    "label": 1
                },
                {
                    "sent": "This is the LDP cases diffusion case.",
                    "label": 0
                },
                {
                    "sent": "Remember had this to operators L. Is that generator P. Is this normalization operator I defined, which is basically an integral operator and these are all the different ways you can define optimal control problems.",
                    "label": 0
                },
                {
                    "sent": "So first exit means you run until you hit some boundary and then you pay final cost in this in some way.",
                    "label": 0
                },
                {
                    "sent": "The simplest, so you have to augment these equations with boundary condition.",
                    "label": 0
                },
                {
                    "sent": "Of course finite horizon issue ran until.",
                    "label": 0
                },
                {
                    "sent": "Some final time and then you pay the final cost.",
                    "label": 0
                },
                {
                    "sent": "Average cost reduces to eigenvalue to principal eigenvalue eigenfunction problem where this C is the average cost per step and the discounted cost is the only one that ends up being nonlinear.",
                    "label": 0
                },
                {
                    "sent": "So basically here you have to raise this Anansi to the power of Alpha, where Alpha is the discount factor.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This you can ask how this is normal.",
                    "label": 0
                },
                {
                    "sent": "Normalizing operator P relates to your generator and it's basically the generator.",
                    "label": 0
                },
                {
                    "sent": "Continuous time diffusion is just the first or the term in the expansion of our discrete time operator with respect to the time step.",
                    "label": 0
                },
                {
                    "sent": "And of course it has high order terms that have been ignored.",
                    "label": 0
                },
                {
                    "sent": "So you can do a lot of things with this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, you can.",
                    "label": 0
                },
                {
                    "sent": "Try to like discretize continuous problems and solve them with things like policy, traditional value iteration.",
                    "label": 0
                },
                {
                    "sent": "So here's a standard example from the literature.",
                    "label": 0
                },
                {
                    "sent": "This is a so called Corona Hill.",
                    "label": 0
                },
                {
                    "sent": "The goal is to.",
                    "label": 0
                },
                {
                    "sent": "So basically this is a point mass moving on a curved route and there's gravity so dynamically nonlinear.",
                    "label": 0
                },
                {
                    "sent": "The goal is to park here, and this is the parking lot.",
                    "label": 0
                },
                {
                    "sent": "It's a parking lot on a steep Hill very well.",
                    "label": 0
                },
                {
                    "sent": "This is the optimal control as a function of position and velocity.",
                    "label": 1
                },
                {
                    "sent": "This is some stochastic trajectory, so the optimal control system this is the parking lot.",
                    "label": 0
                },
                {
                    "sent": "This is what you compute by putting this on the dense grid and using standard policy iteration as an empty.",
                    "label": 0
                },
                {
                    "sent": "So here you're discretizing both the state and control.",
                    "label": 0
                },
                {
                    "sent": "Here we're discretizing only the state, and the control is sort of given to us analytically by the formula that we saw on the second slide, and as you would expect this, they give you the same things, except this you can compute a lot faster.",
                    "label": 0
                },
                {
                    "sent": "Why can you compute a lot faster?",
                    "label": 0
                },
                {
                    "sent": "Because these are MVP's where we don't have to do anything explicit with the controls, so we generic an MVP is there is always a loop over.",
                    "label": 0
                },
                {
                    "sent": "The control should basically maximizing or minimizing over them, and that some kind of inner loop.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "We've gotten rid of that once and for all, and we've explained we replaced it with an analytical formula.",
                    "label": 0
                },
                {
                    "sent": "Install.",
                    "label": 0
                },
                {
                    "sent": "These algorithms get much faster.",
                    "label": 0
                },
                {
                    "sent": "This is like number of updates on the log scale.",
                    "label": 1
                },
                {
                    "sent": "This is policy value iteration.",
                    "label": 0
                },
                {
                    "sent": "This is sometimes callings iteration, which is like the obvious way iterative way to solve those linear equations.",
                    "label": 0
                },
                {
                    "sent": "Actually\\ in Matlab would be even faster, but like for purposes of comparison I decided to do this simple minded iteration.",
                    "label": 0
                },
                {
                    "sent": "This is CPU time.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can also sampling, which is related to close related to Captain's work, so again, this is the equation we want to solve.",
                    "label": 0
                },
                {
                    "sent": "Suppose you didn't have a model of anything but somebody gave you samples.",
                    "label": 0
                },
                {
                    "sent": "Current states accent the next states experiments that were obtained and the costs that were paid in these samples were done under the passive dynamics.",
                    "label": 1
                },
                {
                    "sent": "OK, and.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what you can do is you can actually approximate this by just summing up the exponent of the trajectory costs and dividing over the number of trajectories.",
                    "label": 0
                },
                {
                    "sent": "That's a Monte Carlo estimates.",
                    "label": 1
                },
                {
                    "sent": "That's basically the path integral approach.",
                    "label": 0
                },
                {
                    "sent": "It's unbiased, but it's very slow as every other Montecarlo thing.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One way to speed it up is to use trick that's in the enforcement.",
                    "label": 0
                },
                {
                    "sent": "Learning is known as.",
                    "label": 0
                },
                {
                    "sent": "Temporal difference is sorry, it's temporal difference learning.",
                    "label": 0
                },
                {
                    "sent": "So what you do is, as you get the updates, you keep sort of.",
                    "label": 0
                },
                {
                    "sent": "It's almost like running a filter on your estimate of Z.",
                    "label": 0
                },
                {
                    "sent": "So so you observe some XNSMX prime event, so some next state and some cost.",
                    "label": 0
                },
                {
                    "sent": "And then you're going to use this update rule to update your estimate about Z.",
                    "label": 0
                },
                {
                    "sent": "At this step, Berry seems learning right, so obviously that has to go to zero if you want this thing to converge at some point.",
                    "label": 0
                },
                {
                    "sent": "So these things tend to be a lot faster and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nothing you can do actually is important sampling, which is by far the best thing you can do.",
                    "label": 0
                },
                {
                    "sent": "So we said that I mean the math says that you have to sample from the passive dynamics, and as I mentioned earlier, if you imagine what it takes to get from a chair that, well, you know what is the chance of you getting up from a chair by accident.",
                    "label": 0
                },
                {
                    "sent": "You know that's never going to happen, so.",
                    "label": 0
                },
                {
                    "sent": "It's not such a good idea to sample from the passive dynamics.",
                    "label": 1
                },
                {
                    "sent": "Instead, you want to sample from your best guess about the optimal control dynamics.",
                    "label": 0
                },
                {
                    "sent": "What is your best guess?",
                    "label": 1
                },
                {
                    "sent": "Well, you have your estimate of this Z desirability function.",
                    "label": 1
                },
                {
                    "sent": "If this were the actual Z then we know what the optimal control is because we have a formula for you.",
                    "label": 0
                },
                {
                    "sent": "Given this or you sample from that.",
                    "label": 0
                },
                {
                    "sent": "And then you have to do the standards of important sampling correction.",
                    "label": 0
                },
                {
                    "sent": "So you scale by the probability ratio.",
                    "label": 0
                },
                {
                    "sent": "The thing you should have done over the thing that you actually did an.",
                    "label": 0
                },
                {
                    "sent": "This converges alot faster.",
                    "label": 0
                },
                {
                    "sent": "One drawback here is that to do important sampling you actually need a model of this P. Like this you define yourself.",
                    "label": 0
                },
                {
                    "sent": "So you obviously have a model of it, but this you will have to learn.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so these things have an analog in the different living called Q learning, which is basically Model 3 way to learn optimal control.",
                    "label": 1
                },
                {
                    "sent": "An again, as you would expect, this works faster.",
                    "label": 0
                },
                {
                    "sent": "Becausw Q Learning learns a function over the product space of states, an controls.",
                    "label": 0
                },
                {
                    "sent": "Here we just need to learn a function over the state space, so it's a much smaller function and we can do it both by sampling from the passive dynamics or in this greedy way.",
                    "label": 1
                },
                {
                    "sent": "And basically this is the learning with greedy issues basically outperforms or the other things on some simple problem.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, their estimation control duality is this is closely related to central Middle East Auckland.",
                    "label": 0
                },
                {
                    "sent": "Just cover it in this context, so the probability of a trajectory.",
                    "label": 1
                },
                {
                    "sent": "X12X2 that started at zero under the passive dynamics, which is the product of the transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "And the optimal control dynamics, the same trajectory has probability which you can easily show that it's the prior, the one on the passive dynamics times the exponent of this sound state costs.",
                    "label": 1
                },
                {
                    "sent": "So it's simple logical to show that.",
                    "label": 0
                },
                {
                    "sent": "So if you look at that clearly, this is equivalent to Bayes rule, where this is your prior QS.",
                    "label": 1
                },
                {
                    "sent": "You're negative log likelihood and this is your posterior.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of a trajectory view of base rule.",
                    "label": 0
                },
                {
                    "sent": "You can also turn it into a recursive.",
                    "label": 0
                },
                {
                    "sent": "Filtering.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kind of thing where let's say you define MUK to be the marginal serve at one time step.",
                    "label": 1
                },
                {
                    "sent": "The margin of this density and you define some constant R which is just this marginal over yours function your disability function.",
                    "label": 0
                },
                {
                    "sent": "This satisfies this equation that we had before.",
                    "label": 0
                },
                {
                    "sent": "It basically goes from the next day to the current state, so it goes backwards in time.",
                    "label": 0
                },
                {
                    "sent": "This new quantity are that we defined.",
                    "label": 1
                },
                {
                    "sent": "It just turns out to be the forward filtering danced itself, so it's a very simple equation and of course is the product of the two.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly based on recursive Bayesian inference where.",
                    "label": 1
                },
                {
                    "sent": "Z is our backward filtering density of course and normalized as far as filtering density and Mr. Martino.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's here's the actual problems that are dual to each other, so there's continuous and discrete time and continuous time.",
                    "label": 0
                },
                {
                    "sent": "We have our control diffusion with our quadratic costs.",
                    "label": 0
                },
                {
                    "sent": "I skipped the Sigma for reasons that are beyond me at the moment.",
                    "label": 0
                },
                {
                    "sent": "Problem this control problem is due to this estimation problem.",
                    "label": 0
                },
                {
                    "sent": "You skip the control, so just becomes the passive dynamics instead of a state cost, you put some measurement function which can now be a vector and these things are dual.",
                    "label": 0
                },
                {
                    "sent": "When your state cost in, the control problem is the square the L2 norm of your measurement function.",
                    "label": 0
                },
                {
                    "sent": "So if these conditions are satisfied then the Z and immune functions that I showed you on the previous slide correspond to the Bayesian estimation here.",
                    "label": 0
                },
                {
                    "sent": "In the discrete case, the picture is in some sense simpler, so here the control dynamics are like whatever you specify.",
                    "label": 0
                },
                {
                    "sent": "This was the cost for already show that this is Jewel 2, the system evolving under the passive dynamics instead of the control dynamics, you're making some binary measurements, which are basically coin flips with rate given by some whatever function you want R and then to make this dual you have to relate this Q&R and the way you relate the miscue has to be the negative log R. You can specialize this for the linear case.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't think I have time for.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just say that when you specialize for the linear case, you get the duality not between the linear quadratic regulator and the common filter, which is what you see in textbooks, but between the linear quadratic regulator and information filter, which is the thing that propagates the inverse covariance rather than the covariance.",
                    "label": 0
                },
                {
                    "sent": "I'll just skip that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is a thing called a maximum principle for the most likely trajectory, so you know what maximum principle is basically a way to characterize the optimal trajectory for a deterministic system.",
                    "label": 1
                },
                {
                    "sent": "People have tried to derive such things for stochastic control, but everything that exists is some PD like thing that actually characterized the global solution and not the individual trajectory.",
                    "label": 0
                },
                {
                    "sent": "Here we can say something about an individual trajectory for optimal control.",
                    "label": 0
                },
                {
                    "sent": "Stochastic system.",
                    "label": 0
                },
                {
                    "sent": "In particular, we can ask what is the most likely trajectory you know?",
                    "label": 0
                },
                {
                    "sent": "What's the maximum?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Of this new here and we can show that this is the solution to a well defined deterministic optimal control problem where the pontryagin's maximum principle applies, so we can basically extend it to stochastic control.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm just going to summarize the results so.",
                    "label": 0
                },
                {
                    "sent": "The maximum this meal is the optimal trajectory for deterministic control problem with any dynamics that you want.",
                    "label": 1
                },
                {
                    "sent": "So you write any deterministic dynamics that Maps state and action to ex prime, and you define the cost to be the state calls that you had before, and now you add this term which is the log of minus log passive dynamics at the current state and next state where the next state is given by your function and you have to be careful to make sure that 0 Sir respected right.",
                    "label": 0
                },
                {
                    "sent": "So if something was impossible.",
                    "label": 0
                },
                {
                    "sent": "It better not shop here.",
                    "label": 0
                },
                {
                    "sent": "In the continuous case, the station get slightly more complicated, so I had to use the Onsager match lab function, which is a way to compute relative density.",
                    "label": 0
                },
                {
                    "sent": "So basically, given two trajectories, you can ask what's the ratio of probability?",
                    "label": 0
                },
                {
                    "sent": "Some small tubes around those trajectories, and then you take the limit of those tubes going to zero, and that that's your ratio.",
                    "label": 0
                },
                {
                    "sent": "So when you define it that way, if you ask for the maximum interesting things happen so.",
                    "label": 1
                },
                {
                    "sent": "The most likely trajectory for optimal control diffusion can be shown to be the optimal trajectory for deterministic problem, where the dynamics.",
                    "label": 0
                },
                {
                    "sent": "R. But obviously there not there.",
                    "label": 0
                },
                {
                    "sent": "Basically, I have X plus BU I forgot the bill.",
                    "label": 0
                },
                {
                    "sent": "So you drop the noise and what you did is you corrected the cost function and the way you corrected the cost function is you added that the emergence of the passive dynamics.",
                    "label": 0
                },
                {
                    "sent": "Here's a new medical exam.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To show you that, so here's a little system scaler system.",
                    "label": 0
                },
                {
                    "sent": "I pick some nonlinear passive dynamics which shown here the black curve, so I picked this out.",
                    "label": 0
                },
                {
                    "sent": "It has like 2 stable points in one unstable point.",
                    "label": 0
                },
                {
                    "sent": "The version such as the derivative shown here in red.",
                    "label": 0
                },
                {
                    "sent": "So to find the most likely trajectory for the optimally controlled stochastic system given here, we drop this.",
                    "label": 1
                },
                {
                    "sent": "We make a deterministic problem.",
                    "label": 0
                },
                {
                    "sent": "We add the derivative of A to the cost of the running cost was actually 0.",
                    "label": 0
                },
                {
                    "sent": "Just began to achieve A and then we solve the thing with some trajectory optimizer.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So here's a comparison of the stochastic and deterministic versions.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "This is the Z and this is the R that I told you about.",
                    "label": 0
                },
                {
                    "sent": "So these are these are ability function as a function of time and space are is this?",
                    "label": 0
                },
                {
                    "sent": "Forward filtering density to defend and use the thing we want to maximize.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is I saw the problem twice on a dense grid for different values of Sigma.",
                    "label": 1
                },
                {
                    "sent": "I picked this problem, so we're changing the noise actually has a dramatic effect on the optimal solution, even though everything else remains the same and you can kind of look at how it had crashed in, see why, but so the red is.",
                    "label": 0
                },
                {
                    "sent": "So what you think is the marginal density.",
                    "label": 0
                },
                {
                    "sent": "Of course I cannot plot the actual meal which is against our trajectory because projectors high dimensional right?",
                    "label": 0
                },
                {
                    "sent": "So the system like wants to be here so.",
                    "label": 0
                },
                {
                    "sent": "When noise is small and it kind of wants to.",
                    "label": 0
                },
                {
                    "sent": "So basically what happens here is the control gives out.",
                    "label": 0
                },
                {
                    "sent": "It allows the noise to send the system to one of the stable points and then the last minute makes a big effort engulfed or zero, which is where the goal is and you can see this black curve which is the optimal trajectory for deterministic problem and it kind of matches pretty nicely the marginal of course is guaranteed to match the.",
                    "label": 0
                },
                {
                    "sent": "Speaking of the marginal, so that's fine.",
                    "label": 0
                },
                {
                    "sent": "This dotted thing is actually the second best local minimum, and it kind of corresponds to the thing that that's no longer optimal in it.",
                    "label": 0
                },
                {
                    "sent": "Becomes optimum signal changes.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And another nice property this has is compositionality of optimal control laws, and this is actually quite trivial.",
                    "label": 0
                },
                {
                    "sent": "It comes from the fact that, so remember in the first exit case we're solving linear boundary value problems.",
                    "label": 0
                },
                {
                    "sent": "An linear boundary value problems have the property that the solution on the interior is a linear function of whatever you put on the boundary, so in this case we're putting final costs on the boundary, and we're getting the optimal value function control on the interior.",
                    "label": 0
                },
                {
                    "sent": "So if I put two different final costs and solve it, then I can take any linear combination of those final costs and the solutions are going to combine linearly in the same way, so I'll be more precise.",
                    "label": 0
                },
                {
                    "sent": "Suppose if you pick a bunch of final cost GK.",
                    "label": 0
                },
                {
                    "sent": "And you combine them in.",
                    "label": 0
                },
                {
                    "sent": "This way you exponentiate you.",
                    "label": 0
                },
                {
                    "sent": "Mix them somehow, take the log.",
                    "label": 0
                },
                {
                    "sent": "And this is the final cost for the problem you want to solve.",
                    "label": 0
                },
                {
                    "sent": "And suppose that that you've solved individual problems.",
                    "label": 0
                },
                {
                    "sent": "So we have a bunch of problems that have the same dynamic, same running cost, different final costs.",
                    "label": 0
                },
                {
                    "sent": "In this case, in this ability functions and the optimal controls for each of those are already known.",
                    "label": 0
                },
                {
                    "sent": "Then the disability function for the problem you want to solve is simply the linear combination and the optimal control offer.",
                    "label": 1
                },
                {
                    "sent": "The thing you want to solve is just a similar sort of linear combination of the control laws that you started with.",
                    "label": 0
                },
                {
                    "sent": "Incidentally, the formula is the same both for the diffusions and for the.",
                    "label": 0
                },
                {
                    "sent": "These discrete time process, even though we actually define derived somewhat differently.",
                    "label": 0
                },
                {
                    "sent": "It's kind of cool.",
                    "label": 0
                },
                {
                    "sent": "So this you can apply to LQG to do something quite surprising.",
                    "label": 0
                },
                {
                    "sent": "So we can solve a bunch of LPG problems that have the same dynamics and running costs, but different final costs.",
                    "label": 0
                },
                {
                    "sent": "And now we can combine them and now we can get analytical solutions to a very general class of problems that have linear dynamics.",
                    "label": 0
                },
                {
                    "sent": "Running costs quadratic, but final cause that's pretty much arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Basically, the final cost has to be the log of a Gaussian mixture, but Gaussian mixtures are universal function approximators, so you can actually approximate anything.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a numerical example.",
                    "label": 0
                },
                {
                    "sent": "Consider a bunch of systems that are.",
                    "label": 0
                },
                {
                    "sent": "Basically we're integrating the controls and adding some noise.",
                    "label": 0
                },
                {
                    "sent": "We're paying some costs for the control rate and will have some final costs, which are quadratics, data center, different things given by these constant CK.",
                    "label": 0
                },
                {
                    "sent": "So position, time value, optimal cost to go for a single problem.",
                    "label": 0
                },
                {
                    "sent": "The picture looks like this, so we have some quadratic at the final time and then quadratic somehow changes in time.",
                    "label": 0
                },
                {
                    "sent": "The optimal control law is linear in its gain changes over time.",
                    "label": 1
                },
                {
                    "sent": "An if you actually simulate this thing and look at the distribution of final states going to be very nice Gaussian centered, various trying to do now I can compose two of those analytically and I can get sort of multimodal things that do crazy things and you can compose a lot more of those if you want.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And finally, what we can do is we can actually try to develop a more powerful method for solving things based on function approximation.",
                    "label": 0
                },
                {
                    "sent": "So here's the general idea.",
                    "label": 0
                },
                {
                    "sent": "Again, this is the question we want to solve.",
                    "label": 0
                },
                {
                    "sent": "This is for the infinite Horizon average cost case, where we have an unknown eigenvalue and it's the principle eigenvalue problem.",
                    "label": 0
                },
                {
                    "sent": "So it's linear, but you know you're searching for functions defined over some very high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "And, well, we don't really have a way to find such things, So what you can do is you can.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Define.",
                    "label": 0
                },
                {
                    "sent": "Z to have some parametric form and we're going to pick this form.",
                    "label": 0
                },
                {
                    "sent": "We're going to choose a bunch of so-called features, so features are just scalar functions over the state, and we're going to take linear combinations of those features, and Furthermore, we're going to parameterise the features themselves with some parameters stated that can somehow change their shape.",
                    "label": 0
                },
                {
                    "sent": "So basically splitting the unknown parameters into parameters that have linear effect and parameters that have nonlinear effect, and then this is that OK, so take that zip, plug it in here and.",
                    "label": 0
                },
                {
                    "sent": "Pick a bunch of collocation states, extend where you're going to enforce this conditions, and then you do least squares fit and you find optimal parameters.",
                    "label": 0
                },
                {
                    "sent": "More precisely, how you do that, you end up solving this linear algebra problem, so Lambda F some matrix WS, your vector of unknown linear weights, G, some other metrics, and WS.",
                    "label": 0
                },
                {
                    "sent": "Again, the unknown, and these matrices F&G how to evaluate them.",
                    "label": 0
                },
                {
                    "sent": "If it's simple, you just evaluate all the features that all the colocation state.",
                    "label": 0
                },
                {
                    "sent": "So that's trivial.",
                    "label": 0
                },
                {
                    "sent": "Geez, complicates Oforji actually have to compute this integral, so this is the passive dynamics convolved with your features, and once you compute those then you just do some linear algebra and you're done.",
                    "label": 0
                },
                {
                    "sent": "If you also want to adapt status, what you do is perfect Theta.",
                    "label": 0
                },
                {
                    "sent": "You find the optimal W by solving a linear problem.",
                    "label": 0
                },
                {
                    "sent": "You plug this in here.",
                    "label": 0
                },
                {
                    "sent": "You compute the bellman residual now manages the function of data and you take the gradient with respect to data and do gradient descent.",
                    "label": 0
                },
                {
                    "sent": "I don't know of any interesting problem that's convex, but certainly not this way.",
                    "label": 0
                },
                {
                    "sent": "Uh, no.",
                    "label": 0
                },
                {
                    "sent": "I don't believe any anything useful is going to be convex here.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is an example.",
                    "label": 0
                },
                {
                    "sent": "No, no gradient centers.",
                    "label": 0
                },
                {
                    "sent": "What means useless convex?",
                    "label": 0
                },
                {
                    "sent": "OK, so I mean whether something is comics or not is pretty much irrelevant.",
                    "label": 0
                },
                {
                    "sent": "The only thing that's relevant is how quickly your Newton method is going to converge and how good that local minimum is going to be.",
                    "label": 0
                },
                {
                    "sent": "Now there lots of convex problems for Newton's method actually takes a very long time.",
                    "label": 0
                },
                {
                    "sent": "And Conversely, there lots of non convex problems where you are thinking computer application so that in practice.",
                    "label": 0
                },
                {
                    "sent": "Now it's hard to prove theorems, but doesn't mean it's useless.",
                    "label": 0
                },
                {
                    "sent": "Here a couple of examples.",
                    "label": 0
                },
                {
                    "sent": "These are just scalar system.",
                    "label": 0
                },
                {
                    "sent": "This is a metric like an inverted pendulum.",
                    "label": 0
                },
                {
                    "sent": "The cost is to move either this way or this way at constant speed.",
                    "label": 0
                },
                {
                    "sent": "Here this is this car on the Hilton.",
                    "label": 0
                },
                {
                    "sent": "The cost is to be here with this velocity or here with this post.",
                    "label": 0
                },
                {
                    "sent": "So basically setting up this cost to create limit cycles here.",
                    "label": 0
                },
                {
                    "sent": "This thing can actually hit the wall and it was dropped to 0.",
                    "label": 0
                },
                {
                    "sent": "So this is state cost.",
                    "label": 1
                },
                {
                    "sent": "This is optimal control laws computed exactly basically on very dense grids.",
                    "label": 0
                },
                {
                    "sent": "This is the empirical 'cause this is all trajectories of the system look like.",
                    "label": 0
                },
                {
                    "sent": "OK, here's our function approximation with 40 Gaussian basis that were thrown somewhere and then we adapt adapted their means.",
                    "label": 0
                },
                {
                    "sent": "Paris, so the adaptation of the missing components is crucial.",
                    "label": 0
                },
                {
                    "sent": "If you don't do that, this looks really bad.",
                    "label": 0
                },
                {
                    "sent": "If you don't want you to look bad, and if you want to keep the means of covariance is fixed, you have to increase the number of Gaussians alot.",
                    "label": 0
                },
                {
                    "sent": "So basically what I'm saying is that.",
                    "label": 0
                },
                {
                    "sent": "You know, if you try to put a grid over the state space, the curse of dimensionality is going to kill you.",
                    "label": 0
                },
                {
                    "sent": "Obviously if you try to put a bunch of features that are localized.",
                    "label": 0
                },
                {
                    "sent": "The curse of dimensionality is still going to kill you because effectively you still need the grid over the state space, right?",
                    "label": 0
                },
                {
                    "sent": "Because they're localized, I mean.",
                    "label": 0
                },
                {
                    "sent": "Yeah you can.",
                    "label": 0
                },
                {
                    "sent": "You need the number of grid points per dimension is now smaller, but the exponent is still something very large.",
                    "label": 0
                },
                {
                    "sent": "The only way to get around from that is to not try to cover the whole state space, but you try to allow your method to figure out where it should put the basis and just cover that part of state space and all the rest.",
                    "label": 0
                },
                {
                    "sent": "So having this thing adaptive is actually essential.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, that's where the IT becomes an art more than science.",
                    "label": 0
                },
                {
                    "sent": "I've converted.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so let me just make a couple of remarks on that.",
                    "label": 0
                },
                {
                    "sent": "So we've played with these things for awhile.",
                    "label": 0
                },
                {
                    "sent": "I just said that location States and basis need to cover the unknown regional state space or the optimal control dynamics tend to live for trying various adaptive methods.",
                    "label": 1
                },
                {
                    "sent": "Not know principle way to that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "11 trick would be to use the trajectory optimization to figure out where the system should kind of go and then put your bases there and use that to initialize.",
                    "label": 1
                },
                {
                    "sent": "Or if you're doing something like imitation learning.",
                    "label": 0
                },
                {
                    "sent": "Basically collect data from a human doing something.",
                    "label": 1
                },
                {
                    "sent": "Put your basis functions there and then solve an optimal control problem for a robot that supposed to do the same thing.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The computational bottleneck in all this is evaluating these integrals that elements of that matrix G. So basically involving these things.",
                    "label": 0
                },
                {
                    "sent": "There are cases where you can do this analytically.",
                    "label": 0
                },
                {
                    "sent": "So if you represent P as mixtures of Gaussians, or just single Gaussians, and these guys are Gaussians, multiply that by polynomials.",
                    "label": 0
                },
                {
                    "sent": "Then you can do this analytically, which is very nice.",
                    "label": 0
                },
                {
                    "sent": "So this is our favorite function approximator right now.",
                    "label": 0
                },
                {
                    "sent": "You know Gaussians multiplied by polynomials are actually quite nice, because you know the kind of local, but you can give them a lot of freedom and polynomial and.",
                    "label": 0
                },
                {
                    "sent": "Coefficients of the polynomial actually show up linearly, so all that extra freedom is actually handled by a single\\ in Matlab, and you don't pay for it.",
                    "label": 0
                },
                {
                    "sent": "No, not quite a sorry quadrotor.",
                    "label": 0
                },
                {
                    "sent": "I just there's a formula maybe called culture.",
                    "label": 0
                },
                {
                    "sent": "OK, there is also.",
                    "label": 0
                },
                {
                    "sent": "There's also something or curvature, which is unfortunate that basically is a numerical approximation which tends to become very inaccurate very quickly in high dimensions, as we discovered recently.",
                    "label": 0
                },
                {
                    "sent": "So I mean, we've made progress in various aspects of this, but I can summarize.",
                    "label": 0
                },
                {
                    "sent": "Many more hours of talking.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By saying that the numerical methods derived from this framework are much more efficient than what we had before, but they are not enough to beat the curse of dimensionality.",
                    "label": 1
                },
                {
                    "sent": "So are we back to where we started and hopefully not so do we have our methods that are likely to work really well once we have something else to help them?",
                    "label": 0
                },
                {
                    "sent": "So basically by themselves, I don't think they're going to work.",
                    "label": 0
                },
                {
                    "sent": "But I believe that even more strongly about every other method that's out there.",
                    "label": 0
                },
                {
                    "sent": "But if we have something else that kind of gets the right idea, these things can help and build sort of regions of attraction and feedback controls that make sense.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So now I'm going to switch to something else that I'm very hopeful about right now.",
                    "label": 0
                },
                {
                    "sent": "Before I switched that, let me say that so this this summarizes world I was done up until maybe two years ago.",
                    "label": 0
                },
                {
                    "sent": "It's in a paper that appeared on the 1st slide, which you can read if you want some PNS since then couple of.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Especially my postdoc if angles in my student DJ who is have been doing a lot of interesting extensions and they're going to be talking about them on Saturday and sending in particular, there is now, so we always see this scale divisions thing all over and over and over again, so they figured that you can use a renewed dye vergence and you can set up a game theoretic.",
                    "label": 0
                },
                {
                    "sent": "You know scenario where you gain get these linear solvable things, and they're actually a generalization of everything we've seen so far, and you can reduce.",
                    "label": 0
                },
                {
                    "sent": "You can obtain all the other cases from it, but you'll see that on Sunday.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "That's that, now what are we going to do next?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're back to good old trajectory optimization.",
                    "label": 1
                },
                {
                    "sent": "Why becausw?",
                    "label": 0
                },
                {
                    "sent": "Having done this for years and having looked at all the beautiful scalar examples that we put in our papers, I convinced myself that it's not really going to allow me to do things I want to do, at least not by itself.",
                    "label": 0
                },
                {
                    "sent": "It's really good for writing papers, and we managed to write like 1015 papers on this in a couple of years.",
                    "label": 0
                },
                {
                    "sent": "But if you want to actually control something rather than write papers about control.",
                    "label": 0
                },
                {
                    "sent": "It's um, it's a different story, so we pick trajectory optimization because that's what works.",
                    "label": 0
                },
                {
                    "sent": "Actually, let me tell you a funny story to kind of make this transition.",
                    "label": 0
                },
                {
                    "sent": "So about two years ago I gave a talk at a conference code dynamic walking, so that's a that's a meeting.",
                    "label": 0
                },
                {
                    "sent": "Nice robotic say some people from mechanics, somebody mechanics.",
                    "label": 0
                },
                {
                    "sent": "Basically there are smart people.",
                    "label": 0
                },
                {
                    "sent": "Their goal is to create walking robots and complicated machines.",
                    "label": 0
                },
                {
                    "sent": "Also understand human movement.",
                    "label": 0
                },
                {
                    "sent": "Most of these people at some point in their life have tried some mathematically glorious idea.",
                    "label": 0
                },
                {
                    "sent": "That's going to tell them how to do control.",
                    "label": 0
                },
                {
                    "sent": "And they failed.",
                    "label": 0
                },
                {
                    "sent": "So now they're doing more intuitive things that actually work.",
                    "label": 0
                },
                {
                    "sent": "But if but if you show up with some great mathematical idea, there are very supportive.",
                    "label": 0
                },
                {
                    "sent": "Like, yeah, go for it, come back and let us know how it works out.",
                    "label": 0
                },
                {
                    "sent": "Fine, so I gave a talk.",
                    "label": 0
                },
                {
                    "sent": "Basically this and they are very supportive after me.",
                    "label": 0
                },
                {
                    "sent": "There's a I don't know how many of you know arrested Rick at MIT is sort of.",
                    "label": 0
                },
                {
                    "sent": "Does robotics control?",
                    "label": 0
                },
                {
                    "sent": "He used to collaborate with with Pablo?",
                    "label": 0
                },
                {
                    "sent": "And so he got up and gave a talk about another glorious mathematical idea which is building 3 self linear quadratic regulators and using sum of squares optimization to improve stability.",
                    "label": 0
                },
                {
                    "sent": "Bounce and then make sure they overlap so the whole thing becomes stable so.",
                    "label": 0
                },
                {
                    "sent": "Same response, great golfer, it shows this year at the same conference my group presented our latest work.",
                    "label": 0
                },
                {
                    "sent": "We shall lots of things that work really well as a show.",
                    "label": 0
                },
                {
                    "sent": "In a moment, the phrase linear solver optimal control is not even mentioned because we're not using raster tricks.",
                    "label": 0
                },
                {
                    "sent": "Group got up and gave a talk.",
                    "label": 0
                },
                {
                    "sent": "They showed lots of things that work.",
                    "label": 0
                },
                {
                    "sent": "Sum of squares optimization was not even mentioned, like they're doing trajectory optimization the same way as we are, because that's how it works.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before you do.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, much more positive.",
                    "label": 0
                },
                {
                    "sent": "We even got a DARPA grant as a side effect.",
                    "label": 0
                },
                {
                    "sent": "If you're going to do that, can somebody tell me how much time I have?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So if you're going to trajectory optimization, this is heavily model based.",
                    "label": 0
                },
                {
                    "sent": "I mean you're doing everything in the model.",
                    "label": 0
                },
                {
                    "sent": "If you're going to do a model.",
                    "label": 0
                },
                {
                    "sent": "If you look at so.",
                    "label": 0
                },
                {
                    "sent": "Actually this is one of the problems with control.",
                    "label": 0
                },
                {
                    "sent": "In general, so you start with an equation that X dot equals FX yuan.",
                    "label": 0
                },
                {
                    "sent": "You derive a lot of stuff.",
                    "label": 0
                },
                {
                    "sent": "And then the time comes to Kaplan example an you have to scratch your head and say what is F?",
                    "label": 0
                },
                {
                    "sent": "Well, you know, I just did all this math I have.",
                    "label": 0
                },
                {
                    "sent": "You know two weeks before the conference paper.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to come up with some elaborate F. I'm going to do an inverted pendulum or something.",
                    "label": 0
                },
                {
                    "sent": "Now the F for a really interesting system is something incredibly complicated that you couldn't write down by hand, even if you spend several years writing.",
                    "label": 0
                },
                {
                    "sent": "Instead, you have to use.",
                    "label": 0
                },
                {
                    "sent": "Design simulation software to actually simulate F for you, and then you have to connect it to whatever controllers dot you're using.",
                    "label": 0
                },
                {
                    "sent": "And that's actually not so simple.",
                    "label": 0
                },
                {
                    "sent": "So very few people do, so having realized that, and also having realized that the simulation software that's out there is really designed for simulation and gaming and not for control, I've spent the last.",
                    "label": 0
                },
                {
                    "sent": "Three years almost developing a new physics engine which is specifically tailored for control.",
                    "label": 1
                },
                {
                    "sent": "So now it's almost finished.",
                    "label": 0
                },
                {
                    "sent": "I will be using it very soon.",
                    "label": 0
                },
                {
                    "sent": "Fact I'll show you examples of using it already, so it combines the best recursive algorithms for smooth dynamics in robotics.",
                    "label": 1
                },
                {
                    "sent": "We developed a bunch of new algorithms for simulating contact dynamics.",
                    "label": 1
                },
                {
                    "sent": "Turns out, contact dynamics is really the key to getting robots to do interesting things.",
                    "label": 0
                },
                {
                    "sent": "It's a lot higher than the smooth dynamics.",
                    "label": 0
                },
                {
                    "sent": "People have always sort of swept it under the rug and then it manually, but that doesn't scale.",
                    "label": 0
                },
                {
                    "sent": "And this is an open research problem.",
                    "label": 0
                },
                {
                    "sent": "Like I alluded to earlier, we don't have a principled way to do it, so everything out there is some kind of approximation.",
                    "label": 0
                },
                {
                    "sent": "It also models things like tendence mathematics.",
                    "label": 0
                },
                {
                    "sent": "Currently trans 100 times faster than real time on a single core on a desktop.",
                    "label": 1
                },
                {
                    "sent": "For something like 23 degrees and humanoid.",
                    "label": 0
                },
                {
                    "sent": "And most importantly, it uses parallel processing to compute finite difference approximations to derivatives and derivatives.",
                    "label": 0
                },
                {
                    "sent": "Of course, what you need to do optimal control.",
                    "label": 0
                },
                {
                    "sent": "So basically, without this we wouldn't be doing any of the stuff I'm about to show you, so this has really been an enabling technology.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me just quickly give you an overview of trajectory optimization methods.",
                    "label": 1
                },
                {
                    "sent": "That's not at all standard, but when you start doing it in practice, you realize that you have a lot of choices.",
                    "label": 1
                },
                {
                    "sent": "So here's the general procedure.",
                    "label": 0
                },
                {
                    "sent": "There are bunch of relevant variables that we need to compute, so we are talking specifically about problems, so there are positions.",
                    "label": 0
                },
                {
                    "sent": "There's velocities, secondary systems, there are talks or forces that you're playing, and there are contact forces between the robot in the environment.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you do is you split them into a set of independent and dependent variables independent variables, meaning that you can compute them as functions of the independent ones.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "If the independent variables are actually couple.",
                    "label": 1
                },
                {
                    "sent": "So if you pick them over complete representation, for example, you chose to optimize both positions and we lost it for whatever reason.",
                    "label": 0
                },
                {
                    "sent": "Then you have to impose constraints.",
                    "label": 0
                },
                {
                    "sent": "And then this is very critical.",
                    "label": 0
                },
                {
                    "sent": "If there's contact dynamics, you have to find some way to smooth it that's physically realistic, and yet it's smooth enough to allow gradient descent things to work.",
                    "label": 0
                },
                {
                    "sent": "And this is really key.",
                    "label": 0
                },
                {
                    "sent": "Without that, you basically get stack instantly and you optimize.",
                    "label": 0
                },
                {
                    "sent": "It will never make any progress.",
                    "label": 0
                },
                {
                    "sent": "And then after you've done all that you want to apply some 2nd order sort of classes, 2nd order method, and usually you do it with continuation continuation means that you first define the problem that somewhat easier to solve.",
                    "label": 0
                },
                {
                    "sent": "For example, you allow your about to kind of grab itself by the head and move itself to the room, and then, which is very easy way to work to do locomotion, just flow through there and then gradually you penalize that kind of thing so it's forced to discover walking and such.",
                    "label": 0
                },
                {
                    "sent": "So there are lots of ways to partition this.",
                    "label": 0
                },
                {
                    "sent": "For example if the talks or the control signals are the independent variables, then everything else is dependant.",
                    "label": 0
                },
                {
                    "sent": "You can get it to forward integration.",
                    "label": 0
                },
                {
                    "sent": "And then you solve it with things like differential dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "Try to define both talks and the contact forces to be independent instead of getting the contact force through simulation.",
                    "label": 0
                },
                {
                    "sent": "And then you have to enforce some constraints that are now solved.",
                    "label": 0
                },
                {
                    "sent": "That actually tends to work better because contact force is really important and you don't want to treat them as a side effect of the dynamics you actually want to let the optimizer reason about them directly so that works better.",
                    "label": 0
                },
                {
                    "sent": "You can define only the positions, so this is another way to do it is called space time optimization.",
                    "label": 1
                },
                {
                    "sent": "So you define the sequence of positions through the entire trajectory and you treat the entire project is 1 big vector, which is the number of.",
                    "label": 0
                },
                {
                    "sent": "Degrees of Freedom times, number of time steps.",
                    "label": 1
                },
                {
                    "sent": "You you are finite difference.",
                    "label": 0
                },
                {
                    "sent": "To compute the velocities you apply inverse dynamics to compute the torques, either contact them if you have to invent some contact simulation algorithm that's actually invertible, and we've done that and then you have the positions, velocities, controls and everything you define.",
                    "label": 0
                },
                {
                    "sent": "The cost changes apply Newton's method to it.",
                    "label": 0
                },
                {
                    "sent": "You don't actually need to know anything about control theory whatsoever to do that, just need to know calculus in Newton's method basically.",
                    "label": 0
                },
                {
                    "sent": "Sadly, that's one of the things that works best, and there's some other variations.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So specifically here, the class of matters that we use.",
                    "label": 0
                },
                {
                    "sent": "The first one is actually model creative control.",
                    "label": 0
                },
                {
                    "sent": "So what is model pretty control?",
                    "label": 0
                },
                {
                    "sent": "So here's the idea.",
                    "label": 0
                },
                {
                    "sent": "In some state blue you're going to compute an optimal trajectory after some time horizon, which is as long as your computer allows.",
                    "label": 0
                },
                {
                    "sent": "And then you're going to execute the first portion of that trajectory.",
                    "label": 0
                },
                {
                    "sent": "And what happens is probably not what you plan.",
                    "label": 0
                },
                {
                    "sent": "'cause there may be model errors, noise, God knows what you're going to transition here.",
                    "label": 0
                },
                {
                    "sent": "That's OK, because when you find yourself here, you're going to compute another optimal trajectory going to execute the first step come here, etc.",
                    "label": 0
                },
                {
                    "sent": "So it's a wonderful idea.",
                    "label": 0
                },
                {
                    "sent": "The only catch is that you have to be doing optimal control in real time, so you have to be fast enough, in fact.",
                    "label": 0
                },
                {
                    "sent": "Sorry, I can tell if you're if you have an optimizer that is fast enough to do this.",
                    "label": 0
                },
                {
                    "sent": "And shorter analytical formula actually gives the optimal control.",
                    "label": 0
                },
                {
                    "sent": "I don't know why you would do anything else.",
                    "label": 0
                },
                {
                    "sent": "I mean maybe to save electricity because some computer cluster is going to be working really hard to do this, but but this thing works amazingly well if you look at things like chemical process control is basically what everyone does becausw the dynamics are slow and smooth enough to throw out random with your optimizer.",
                    "label": 0
                },
                {
                    "sent": "In robotics it's almost never used except for like really simple to problems because people didn't have optimizes the graph.",
                    "label": 0
                },
                {
                    "sent": "Projector with respect to what I have said?",
                    "label": 0
                },
                {
                    "sent": "OK, so you have your running costs and then you're going to put some final cost on the horizon.",
                    "label": 0
                },
                {
                    "sent": "That final cost is going to be some heuristic approximation to the optimal value function is the same thing as the heuristic evaluation functions in chest.",
                    "label": 0
                },
                {
                    "sent": "In fact, you can think of chess as model creative control like you know you unfold the three after few moves.",
                    "label": 0
                },
                {
                    "sent": "In the past you evaluate your heuristic, you propagate back, you decide how to move, you move, you see what your problem then do it again.",
                    "label": 0
                },
                {
                    "sent": "Except the Game 2 rating setting, so of course it has complications.",
                    "label": 0
                },
                {
                    "sent": "Right, so you need some some heuristic for that.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other actually, so I should prob.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We interleave OK, so let me show you some results using this approach.",
                    "label": 0
                },
                {
                    "sent": "So here's the simple one.",
                    "label": 0
                },
                {
                    "sent": "So here's this is a three degree of freedom robot.",
                    "label": 0
                },
                {
                    "sent": "The goal is to bounce this ping pong ball.",
                    "label": 0
                },
                {
                    "sent": "It bounced at various Heights because the cost function on every bounce kind of changes.",
                    "label": 0
                },
                {
                    "sent": "It's perfectly interactive, so you can push it, grab the ball, whatever.",
                    "label": 0
                },
                {
                    "sent": "It's just doing MPC.",
                    "label": 0
                },
                {
                    "sent": "We're computing an optimal trajectory once every 10 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "And we're computing it from now until the next contact with either ball.",
                    "label": 0
                },
                {
                    "sent": "Why is my MPEG decoder doing this exam?",
                    "label": 0
                },
                {
                    "sent": "Sensor says Vicon system that basically sees the balls as markers.",
                    "label": 0
                },
                {
                    "sent": "It's the infrared motion capture system and then there are in colors in the in the joints of the robot.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is the.",
                    "label": 0
                },
                {
                    "sent": "Most complicated thing with that in MPC, so this is the task of getting up full humanoid full dynamics when it's green.",
                    "label": 0
                },
                {
                    "sent": "That means the brain is switched off so it falls down.",
                    "label": 0
                },
                {
                    "sent": "Red Arrow is external force that we have a way of injecting into a simulation with the six degree of freedom mouse, which is the most beautiful gadget ever and orange means the brain is on so it gets up this on a single desktop with two 6 core processors runs about five times slower than real time right now.",
                    "label": 0
                },
                {
                    "sent": "Which means that on a cluster with like five or six computers, we can already run in real time.",
                    "label": 0
                },
                {
                    "sent": "So again, I should point out that this thing scales beautifully in parallel because almost all the time is spent finite difference in the dynamics and getting the derivatives and that can be just branched a whole cluster.",
                    "label": 0
                },
                {
                    "sent": "And this is indestructible.",
                    "label": 0
                },
                {
                    "sent": "This is like you can do anything you want to it and what is wrong with the goal?",
                    "label": 0
                },
                {
                    "sent": "OK, so good question.",
                    "label": 0
                },
                {
                    "sent": "The goal is to put the center of mass 1 meter over the feet so and save energy along the way if you can.",
                    "label": 0
                },
                {
                    "sent": "So you can see that the arms don't.",
                    "label": 0
                },
                {
                    "sent": "Here the goal is to is to keep the center of mass moving forward.",
                    "label": 0
                },
                {
                    "sent": "Add stuff.",
                    "label": 0
                },
                {
                    "sent": "OK, so so MPC.",
                    "label": 0
                },
                {
                    "sent": "That works rather well.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remember, this kind of space time optimization, so alternative approaches just parameterized the sequence of positions and optimize that how object.",
                    "label": 0
                },
                {
                    "sent": "He",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An example of that.",
                    "label": 0
                },
                {
                    "sent": "OK, so the cost again make the center of mass move forward with.",
                    "label": 0
                },
                {
                    "sent": "So here we actually we have proper and so here we are, minimizing power in Watts.",
                    "label": 0
                },
                {
                    "sent": "It ends up walking with something like 20 ones.",
                    "label": 0
                },
                {
                    "sent": "This is 84 kilogram humanoid.",
                    "label": 0
                },
                {
                    "sent": "It's actually pretty amazing.",
                    "label": 0
                },
                {
                    "sent": "Amazing because I mean if you think about it, there's no friction in it, so there shouldn't be that much energy dissipation.",
                    "label": 0
                },
                {
                    "sent": "There is only friction with the ground, yes, but you're not really sliding on the ground.",
                    "label": 0
                },
                {
                    "sent": "You basically stop and then you left.",
                    "label": 0
                },
                {
                    "sent": "So yeah, you lose some energy when you hit the ground, but you don't hit that hard.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right, so when you do running, you hit the ground much harder so it costs a lot more.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "This thing has 18 or no.",
                    "label": 0
                },
                {
                    "sent": "I think this one has 23 join so it has 23 degrees of freedom and there are about 30 to 50 timesteps.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure how many are in the trajectory, so let's say 20 times, so somewhere between 500,000.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I don't have hands moving because when you walk the passive dynamics will cause your hands to swing and it will be expensive to stop them.",
                    "label": 0
                },
                {
                    "sent": "And once they start slinging turns out you can swing them a bit more to somehow transfer meant.",
                    "label": 0
                },
                {
                    "sent": "I'm going also.",
                    "label": 0
                },
                {
                    "sent": "I mean I don't know why.",
                    "label": 0
                },
                {
                    "sent": "That's you know that's the beauty of optimal control is that you don't need to know why.",
                    "label": 0
                },
                {
                    "sent": "You just say what you want to happen an your fast computer does it for you.",
                    "label": 0
                },
                {
                    "sent": "I like a model.",
                    "label": 0
                },
                {
                    "sent": "This is more sexy.",
                    "label": 0
                },
                {
                    "sent": "Yeah we should if you know the cost function for sexiness, let me know.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the last thing I'll show you is actually the most interesting thing with them, so here we really develop this idea that Contacts are the key to interesting behaviors.",
                    "label": 0
                },
                {
                    "sent": "Anan we really have to come up with clever ways to handle them.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we defined.",
                    "label": 0
                },
                {
                    "sent": "A very unusual formulation of the cost function, which sort of forces the optimizer to think hierarchically about Contacts and trajectories.",
                    "label": 0
                },
                {
                    "sent": "So here's the idea.",
                    "label": 0
                },
                {
                    "sent": "We're going to be optimizing the trajectories for characters that look like that, and the optimizing the sequence of positions plus a bunch of additional decision variables.",
                    "label": 0
                },
                {
                    "sent": "Column CIT.",
                    "label": 0
                },
                {
                    "sent": "What Si says is that it basically indicates potential contact.",
                    "label": 1
                },
                {
                    "sent": "I should be active in movement Phase 50 SE.",
                    "label": 1
                },
                {
                    "sent": "I'm 50, just splits time into a few discrete phases and these guys say is given contact.",
                    "label": 0
                },
                {
                    "sent": "Let's say between my hand and table.",
                    "label": 0
                },
                {
                    "sent": "Should it be active in this space?",
                    "label": 0
                },
                {
                    "sent": "White faces?",
                    "label": 0
                },
                {
                    "sent": "Because if you look at Contacts, what usually happens is that you know you touch something, then you do something for awhile, but you're in contact for awhile.",
                    "label": 0
                },
                {
                    "sent": "You know the contact forces themselves may change.",
                    "label": 0
                },
                {
                    "sent": "You may even have things like like rolling contact, but you are in contact then if you break contact for awhile you.",
                    "label": 0
                },
                {
                    "sent": "Broken for awhile, so that's the way to compress the problem.",
                    "label": 1
                },
                {
                    "sent": "So basically we're forcing the optimizer to declare if it wants to make Contacts or not, and then these variables affect the cost.",
                    "label": 0
                },
                {
                    "sent": "So here's what we do.",
                    "label": 0
                },
                {
                    "sent": "We add this extra custom which basically says in this a lot of jargon what it simply means that if you said you're going to be in contact, and if you're not in contact, I'm going to penalize why would you ever say that you want to be in contact?",
                    "label": 0
                },
                {
                    "sent": "'cause if you don't say that then it's very expensive to generate contact forces.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you want contact forces, you have to declare them.",
                    "label": 0
                },
                {
                    "sent": "If you don't declare them, it's going to be costly to generate.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "No, because we said so.",
                    "label": 0
                },
                {
                    "sent": "We changed the problem formulation, so here's what we're.",
                    "label": 0
                },
                {
                    "sent": "Again, we're trying to force the optimizer to think about Contacts explicitly, not as side effects of the kinematics and dynamics, but explicitly, and so the question is, how do you do that when it's optimizing both projector and the Contacts?",
                    "label": 0
                },
                {
                    "sent": "How do we force it to actually think about the context when they're fully determined given the trajectory?",
                    "label": 0
                },
                {
                    "sent": "So we kind of have to allow some kind of mismatch between the two, right?",
                    "label": 0
                },
                {
                    "sent": "And then and then?",
                    "label": 0
                },
                {
                    "sent": "If there is a mismatch, we need to have some custom that forces the thing to become consistent, but because it was thinking about these abstract contact events.",
                    "label": 0
                },
                {
                    "sent": "The hope is that they're going to once you force them to become consistent, they're going to drag the whole trajectory to almost more sensible movement.",
                    "label": 0
                },
                {
                    "sent": "It's all heuristic, but that's how it works, you know?",
                    "label": 0
                },
                {
                    "sent": "Let me show you how well it works.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this happens later in this movie.",
                    "label": 0
                },
                {
                    "sent": "This is actually something else I don't have time to talk about.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a trajectory optimization in progress, so here it thought of some trajectory and now it's thinking how to refine it.",
                    "label": 0
                },
                {
                    "sent": "And then it starts executing it and see all this sequence of steps.",
                    "label": 0
                },
                {
                    "sent": "Came from a simple cost function which said please make sure that your tour is over that cross over there.",
                    "label": 0
                },
                {
                    "sent": "At the end of the movement.",
                    "label": 0
                },
                {
                    "sent": "I don't care what you do, just put the torso over there so this entire thing with all these steps.",
                    "label": 0
                },
                {
                    "sent": "Obviously adjustments everything came from optimal control trajectory optimization.",
                    "label": 0
                },
                {
                    "sent": "Simplest possible cost you can imagine, plus against some joint torques.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure, the dynamics.",
                    "label": 0
                },
                {
                    "sent": "Independent variables the, so this is the way this is encoded actually is we called the end effector positions and then we use inverse kinematics to find the joint angles.",
                    "label": 0
                },
                {
                    "sent": "But it's just a convenience to help the optimizer a bit more.",
                    "label": 0
                },
                {
                    "sent": "If you put a target high app.",
                    "label": 0
                },
                {
                    "sent": "So here we have the big friction coefficients to feed there about 2:00, so that kind of sticky, so it can invent climbing.",
                    "label": 0
                },
                {
                    "sent": "Here we ask you to put that also upside down so it can do hand stands.",
                    "label": 0
                },
                {
                    "sent": "So basically, just by changing the initial configuration where the target is, you can get all kinds of diverse movements.",
                    "label": 0
                },
                {
                    "sent": "Now this is nowhere close to the other.",
                    "label": 0
                },
                {
                    "sent": "Let me comment on this.",
                    "label": 0
                },
                {
                    "sent": "So here's the task is to get the ball down.",
                    "label": 0
                },
                {
                    "sent": "The cost function doesn't say anything about these.",
                    "label": 0
                },
                {
                    "sent": "Humans will optimize as well.",
                    "label": 0
                },
                {
                    "sent": "This ball thing doesn't have an actuator, but these humans do.",
                    "label": 0
                },
                {
                    "sent": "So let me figure out how to use them.",
                    "label": 0
                },
                {
                    "sent": "And here's how I use them.",
                    "label": 0
                },
                {
                    "sent": "They have a shared brain, so this is coordinated control and they're not independent.",
                    "label": 0
                },
                {
                    "sent": "Here the little guy has to put his head up there and optimizer figures out that you know the big guy has to help him somehow.",
                    "label": 0
                },
                {
                    "sent": "So again the cost function here is at the end of the movement.",
                    "label": 0
                },
                {
                    "sent": "The head has to be up there.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "Everything else comes out of dynamics, an optimization.",
                    "label": 0
                },
                {
                    "sent": "Between 2 and 10 minutes, but this is not optimized for real parallelism yet, so this has a lot of room for improvement.",
                    "label": 0
                },
                {
                    "sent": "I don't think this will run in MPC model, but the other things do OK here.",
                    "label": 0
                },
                {
                    "sent": "The cost is to spin the pen in the vertical plane.",
                    "label": 0
                },
                {
                    "sent": "Cost function doesn't even mention a hand, but obviously you have to use a hand to make that happen.",
                    "label": 0
                },
                {
                    "sent": "So we use the hand.",
                    "label": 0
                },
                {
                    "sent": "Here the cost the cost function says spin the pen in the horizontal plane apparently and some other movement emerges.",
                    "label": 0
                },
                {
                    "sent": "Here what's going on?",
                    "label": 0
                },
                {
                    "sent": "His supposed to somehow toss it and catch it?",
                    "label": 0
                },
                {
                    "sent": "I forget how this was encoded, but something really simple.",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "I mean, in general we found that exactly how you encode the task doesn't make much difference like this.",
                    "label": 0
                },
                {
                    "sent": "How you formulate these Contacts, that's where the magic is really.",
                    "label": 0
                },
                {
                    "sent": "The optimizer itself is just off the shelf, but we're not doing anything on the optimization front.",
                    "label": 0
                },
                {
                    "sent": "Can do the same thing with the robot hand.",
                    "label": 0
                },
                {
                    "sent": "It has to pull this thing up.",
                    "label": 0
                },
                {
                    "sent": "He has to spin the pen so same, actually same cost as before, but now it doesn't have enough fingers to lift it up in there, so it ends up using the table to support it during the spinning phase.",
                    "label": 0
                },
                {
                    "sent": "It's fully emergent thing.",
                    "label": 0
                },
                {
                    "sent": "He has to put the object in the air.",
                    "label": 0
                },
                {
                    "sent": "Here it has two.",
                    "label": 0
                },
                {
                    "sent": "Embodiment, I mean the the actual mechanics of well I mean all is very natural.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it seems very natural.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is a fairly realistic simulations.",
                    "label": 0
                },
                {
                    "sent": "They're not like real robot yet, so we'll see.",
                    "label": 0
                },
                {
                    "sent": "So that's that.",
                    "label": 0
                },
                {
                    "sent": "So obviously we want to.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To play with real robots, so that's where we're heading next.",
                    "label": 0
                },
                {
                    "sent": "We have two of them, so this actually sounds the most advanced robots that anyone has right now.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Is made by Coco in Japan.",
                    "label": 0
                },
                {
                    "sent": "It has about 40 degrees of freedom, pneumatically actuated, so it has 80 valves.",
                    "label": 0
                },
                {
                    "sent": "So the state is in each the pressure inside each cylinder is a state variable because they have time constants like 5060 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "So this thing has 160 dimensional state space.",
                    "label": 0
                },
                {
                    "sent": "Here we're just asking it to go to random poses for system ID purposes.",
                    "label": 0
                },
                {
                    "sent": "We haven't really figured out how to control the whole thing.",
                    "label": 0
                },
                {
                    "sent": "This is called Shadowhand, except we bought one and realized it's the actuation is a joke, so we returned it and we built our own actuation.",
                    "label": 0
                },
                {
                    "sent": "This is the thing that's so disappointing pointing to wrong places of pneumatic cylinders.",
                    "label": 0
                },
                {
                    "sent": "They put on this tendence.",
                    "label": 0
                },
                {
                    "sent": "This is actually moving through one joint at a time.",
                    "label": 0
                },
                {
                    "sent": "This is real time, so this is several times faster than a human hand with the new actuation.",
                    "label": 0
                },
                {
                    "sent": "So we'll be trying to control these things.",
                    "label": 0
                },
                {
                    "sent": "The other thing we're doing, we're very excited about is this thing called that robotics challenge, so I don't know if you've heard of it, but you will be hearing about over the next couple of years 'cause the whole robotics community worldwide is gearing up to do this.",
                    "label": 0
                },
                {
                    "sent": "So remember the Fukushima disaster that somebody had to turn off the nuclear power plant, but it was dangerous for humans so dark, but decided to build robots that actually do that.",
                    "label": 0
                },
                {
                    "sent": "And apparently they're quite serious, so the idea is to build these robots that build by Boston Dynamics.",
                    "label": 0
                },
                {
                    "sent": "Same people who build the big dogs, little dogs, and such.",
                    "label": 0
                },
                {
                    "sent": "They actually already have them.",
                    "label": 0
                },
                {
                    "sent": "And it looked like that.",
                    "label": 0
                },
                {
                    "sent": "So this thing has to walk across rubble.",
                    "label": 1
                },
                {
                    "sent": "Get a car, open the car, get into the car, drive the car, get out of the car.",
                    "label": 0
                },
                {
                    "sent": "Pick up a power tool.",
                    "label": 0
                },
                {
                    "sent": "Climb a ladder.",
                    "label": 0
                },
                {
                    "sent": "Open the door, demolisher concrete panel going to a dark room located valve that's leaking and go and turn it off and maybe come back if possible.",
                    "label": 0
                },
                {
                    "sent": "Perfect man hey yeah.",
                    "label": 0
                },
                {
                    "sent": "You wanna get some?",
                    "label": 0
                },
                {
                    "sent": "Speaking of radio, of course there is a human operator involved, right?",
                    "label": 0
                },
                {
                    "sent": "So you are allowed to have an operator you have Wi-Fi type bandwidth, but you cannot joystick something that has 30 degrees of freedom, like you cannot tell operate such things so clearly the thing has to have a lot of control intelligence built in.",
                    "label": 0
                },
                {
                    "sent": "Then the operator is basically going to be sending commands on a fairly high level is because human cannot still.",
                    "label": 0
                },
                {
                    "sent": "No, there's about and how detailed no, no, I mean Wi-Fi is says that they're going to degrade the channel capacity because they want you to use this little bandwidth.",
                    "label": 0
                },
                {
                    "sent": "Possible, they're giving a Wi-Fi.",
                    "label": 0
                },
                {
                    "sent": "The problems that humans cannot joystick.",
                    "label": 0
                },
                {
                    "sent": "30 degree freedom robots.",
                    "label": 0
                },
                {
                    "sent": "I mean, you cannot tell operate that thing.",
                    "label": 0
                },
                {
                    "sent": "You can probably tell you now call, but there maybe like move this arm here or whatever.",
                    "label": 0
                },
                {
                    "sent": "But you know, this has real time dynamics, for example, when it starts following, it takes.",
                    "label": 0
                },
                {
                    "sent": "I don't know 100 milliseconds before we're going to do any cost $1,000,000.",
                    "label": 0
                },
                {
                    "sent": "And there's a nuclear power plant to be turned on.",
                    "label": 0
                },
                {
                    "sent": "So we'll see how that goes, but basically the goal is to use this planning trajectory planning algorithms to quickly come up with.",
                    "label": 0
                },
                {
                    "sent": "Sensible and physically plausible plans in some seconds.",
                    "label": 0
                },
                {
                    "sent": "Once we have that do MPC random words, the linear sub optimal control fillingane?",
                    "label": 0
                },
                {
                    "sent": "Do we get back to it after optimization?",
                    "label": 0
                },
                {
                    "sent": "I think we do because.",
                    "label": 0
                },
                {
                    "sent": "I mean, just 'cause you can do MPC multiplicative control.",
                    "label": 0
                },
                {
                    "sent": "It's kind of silly.",
                    "label": 0
                },
                {
                    "sent": "I mean basically what you're doing is you're rediscovering walking once every 10 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "Really, do you have to do it so once you discover it, maybe you can somehow cache all these solutions and fit this model global basis function approximators and and solve linear systems and build bigger?",
                    "label": 0
                },
                {
                    "sent": "Bigger feedback controllers with bigger region of attraction but but it's a good thing that we have this trajectory optimizers, because without that we can't even get started.",
                    "label": 0
                },
                {
                    "sent": "So thank you for listening.",
                    "label": 0
                },
                {
                    "sent": "Quite discouraging to the theory.",
                    "label": 0
                },
                {
                    "sent": "Yeah, having done it for a few years and discouraging to me, no.",
                    "label": 0
                },
                {
                    "sent": "I mean look, I don't think it's discouraging, it's just that.",
                    "label": 0
                },
                {
                    "sent": "The theoretical challenges.",
                    "label": 0
                },
                {
                    "sent": "Well, one of them is impossible, which is to understand nonconvex optimization.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "Maybe there are special classes of non convex functions where you can say things but is a humanoid robot going to fit in that special class.",
                    "label": 0
                },
                {
                    "sent": "The dynamics and interesting content analysis, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so.",
                    "label": 0
                },
                {
                    "sent": "It's pretty clear that my Contacts are keyboard in terms of sensing and in terms of planning.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so that's one inside that.",
                    "label": 0
                },
                {
                    "sent": "I mean, I actually quite a few people in robotics nowadays have because more and more people are moving in that direction.",
                    "label": 0
                },
                {
                    "sent": "We probably have the best planners, but a lot of people working in that direction already.",
                    "label": 0
                },
                {
                    "sent": "Directly, I don't know.",
                    "label": 0
                },
                {
                    "sent": "I mean usually when you do, I think the best way to do things is like you know, start working really hard.",
                    "label": 0
                },
                {
                    "sent": "Empirical problem, get stuck, realized why you're stuck, and define the theoretical problem that you need to solve.",
                    "label": 0
                },
                {
                    "sent": "If if your motivation is OK, how do I write the next CDC paper?",
                    "label": 0
                },
                {
                    "sent": "I know there's lots of theories you can develop that way, but are they useful to anyone?",
                    "label": 0
                },
                {
                    "sent": "We don't know if your motivation is not developed theory that actually makes that happen.",
                    "label": 0
                },
                {
                    "sent": "You know it'll probably end up being a different kind of theory, hopefully is going to be there someday, but I. Pepper",
                    "label": 0
                }
            ]
        }
    }
}