{
    "id": "ya4mxn5vtzo2etzoukshj26l6iijvub4",
    "title": "Transferring Semantic Categories with Vertex Kernels: Recommendations with Semantic SVD++",
    "info": {
        "author": [
            "Matthew Rowe, School of Computing and Communications, Lancaster University"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_rowe_transferring_semantic_categories/",
    "segmentation": [
        [
            "So yeah, my name is Matthew Rowe.",
            "I'm a lecturer at Lancaster University and I'm going to talk to you today about an approach to combine link data with matrix factorization for recommender systems, right?",
            "So to give you an example, the task which."
        ],
        [
            "To accomplish is something called predicting ratings right?",
            "So we've got a user and issues as Darth Vader, right?",
            "And as we all know, Darth Vader was Chewbacca, but he knows Han Solo as well, right?",
            "And the task basically is we're providing a bunch of items, so in this context a movie.",
            "So we got 2 movies that are quite similar here.",
            "Star Trek and aliens.",
            "We've got one that's a bit of an outlier maid in Manhattan, so if you ever seen this film, it's very different from the first 2, right?",
            "Yeah OK people have seen it.",
            "It's probably forced viewing as well, right?",
            "So in essence, in matrix factorization or entrance predict ratings, we have a user's buy items matrix, right?",
            "And what we want to do is we're trying to predict Darth Vader's rating for his aliens film.",
            "I've got this?",
            "Here right and often what happens is R2D2 would take this matrix, will induce some model, and output the predicted rating right, and our quality of a prediction is how far we are away from the absolute true value.",
            "Now there's different ways of doing this.",
            "This neighborhood based models and also something called matrix factorization, which I'm going to talk about.",
            "In the context, this talk, but it's original work.",
            "When I was looking at this, I was really interested in trying to study how users tastes evolved overtime.",
            "How do they change as users go along and there's?"
        ],
        [
            "The problem if you're trying to do this using latent factors within matrix factorization, and this is something called the factor consistency problem.",
            "So what you often find is that the actual approach takes this users by items matrix and tries to decompose it into two different matrices.",
            "So you have a users by factors matrix and items by factors matrix, and factors are basically like some aspects Infinity, so it could be that Darth Vader has a preference for romantic comedies.",
            "He has a preference for sci-fi movies and same for items as well.",
            "An item can be more aligned with romantic comedy.",
            "Or more lines were sci-fi film, so often will happen is if you take your data set and you say wrong to split my data set up into equal frequency chunks, and I'm going to mine you latent factor vector for Darth Vader over one chunk and then over the next chunk you have a problem when we trying to line the latent factors.",
            "You can't do it.",
            "This is this factor consistency problem.",
            "You have no idea.",
            "But the first factor Maps to the second one or the first one.",
            "And the problem is, you can't really examine to see how Darth Vader states have evolved overtime.",
            "OK, so my salute."
        ],
        [
            "This was to use semantic categories.",
            "OK, so link data categories and you're all sold on this so I'll just give you a brief overview.",
            "You have an item, aliens in this context.",
            "This hasn't urri this has skulls.",
            "Categories are mapped to this so we know that alien aliens is an action horror film.",
            "We know that it's published in 1986.",
            "That sort of thing and what we can do instead is we can look to see what the preferences are for a given category given a user.",
            "So it could be that Darth Vader user 2 here has a preference for one category over another.",
            "And this is basically informed somehow he's rated items which have been mapped to these categories beforehand, and the nice thing about this is that we can capture preference for a category at a given time among color lifecycle stage S. And every time we can look to see how this changes, right, we can see how the distribution of preferences but Darth Vader has for these categories is changed, so we get this nice mapping overtime."
        ],
        [
            "Now, publishers work before the Web Intelligence conference, but when I actually start to look into the data after I've done these experiments, I discovered a problem.",
            "And this problem is called cold start categories, right?",
            "So you've probably heard about cold start users called start items in the context of recommender systems.",
            "Course, that categories are something else slightly different, but I'm kind of related.",
            "So if you flip the problem around a little bit, imagine if we've got the rate."
        ],
        [
            "Things for Star Trek and raelians.",
            "We want to predict it for this movie here you probably wear, but obviously these will map to certain categories and made a Manhattan world map to other categories, but there's no overlap between this right?",
            "So probably therefore have is that our previous approach, which relied on knowing how Darth Vader was going to rate category C4 and C5 breaks down, right?",
            "This is what we call unrated categories or cold start categories.",
            "OK, so that's the context.",
            "What we look at and basically talk about ways to actually bring in existing ratings from these categories on the left hand side.",
            "So C1C2 and C3 to cover these ones, which help you have to have ratings for."
        ],
        [
            "So the outline of the talk and talk about the dates that we have and how we align it with your eyes.",
            "But I'm going to quantify the extent which is called star categories problem actually exists, and I'm going to talk about how we transfer in these rated categories before hand to cover these unrated ones.",
            "Then talk about user profiling.",
            "Then how we incorporate this into this SVD plus plus approach and then evaluate it in the conclusions as well.",
            "So in the context of."
        ],
        [
            "This paper I use watercolor movie tweetings datasets.",
            "This is a relatively new date set that came out last year and this was mined from tweets that people have published.",
            "So what happened is they going rate a movie on IMDb and this would then be pushed into their Twitter account and Simon dooms and his team went and actually crawl Twitter for all IMDb links, extracted the actual URL so they get some metadata about this and were provided with basically is a numeric item ID.",
            "The title of the movie and also the year as well.",
            "So the task graph will becomes we need to get this yr I that."
        ],
        [
            "Site some idea lines too, so going back to our example of aliens, we say right given this title, look up on the semantic Web or in the link data Cloud.",
            "All the counterfeit ur eyes.",
            "But this movie item could be related to.",
            "For each candidate, we then look at the actual skills categories and what you find is that often it will say the year that this movie was released in.",
            "So in this context, in aliens it's 1986.",
            "We have that in our own existing data set, so we can use this as a disambiguate are, and we say afterwards that, yeah, we've got a match between item ID in your eye, so this is an existing approach to some research from Barry.",
            "Have you switch replicating this here?",
            "But what happens is we get a reduction right?",
            "If you look in the table here we have the absolute numbers of items, users and ratings in parentheses.",
            "We have a reduction as a percentage.",
            "What we find is that actually the coverage of this data is we're using DB pedia.",
            "I think 3.9 here.",
            "Actual coverage is such that people are actually revealing really obscure films often.",
            "So we don't.",
            "We are actually able to get a Uri for those films.",
            "So we get this reduction.",
            "So in the context of this talk, in the experiments are going to discuss.",
            "Basically, I want to look to see how users takes a changing overtime in the training data set, sewing time, time order, everything.",
            "I'll use the next 10% for validation, so for tuning a model and then finally they held out final 10% for testing."
        ],
        [
            "So to quantify the extent switch called start categories actually occur while did was a took each user, all the categories they rated, the training set and then look at the items of rates in the training set in the categories of those items.",
            "And when I looked in the validation set and the test set to see what was actually missing.",
            "So if you look at the distribution of this, what we find is that actually on average was a hundred categories are missed in validation set 138 in the test.",
            "So it's quite a lot of information we're missing, so it's quite a lot of calls that categories we need to account for."
        ],
        [
            "So in order to account for them, we use something called vertex kernels.",
            "So let's go back to this example again.",
            "We obviously have these categories that these three items have been mapped to.",
            "When we actually look in the linked data graph, we found it is arbitrary concepts of these are going to be sort of dark, Brown ready, sort of colored boxes.",
            "We found essentially arbitrary concepts that these are the categories have been mapped to.",
            "Just buy some random predicates, don't really matter what.",
            "What we can quickly see when we look through it.",
            "OK, this is just conjecture, an example, but in your data it kind of shows the same thing is actually alignment.",
            "Over there we can see how.",
            "Previously we cannot get a mapping, but now we can see how, for instance, like C4's map to_free consistency, freeze mapped_free as well.",
            "So we get kind of overlap we can exploit."
        ],
        [
            "We do this by basically trying to transfer in existing similar categories by exploiting that graph and the neighborhood of it.",
            "So we have this function here and it's basically takes as input rated categories and some categories of the item that we want to then try and align.",
            "Basically we're not covering and the trick here is that we want to choose categories from this set.",
            "See which maximize this function here, so it's a vertex kernel function and basically what this is doing is saying OK giving these two categories.",
            "What's the actual sort node similarity, but also the neighborhood similarity, but we can then compute.",
            "And so you."
        ],
        [
            "Hope you're doing this.",
            "Basically to go back to this example, you take the first category.",
            "This is aliens have been mapped to, so C2 and we can see how it's been mapped to or aligned all related to_2_free and for C4 we have_free_M and what we can do is basically we can compute vectors which to know natural sort of links that are going on.",
            "So by computing these vectors we can then just measures measure of similarity between.",
            "And this is what we do.",
            "So we vary the actual vertex kernel function that we use, so we can actually get different sort of ways of computing the similarity.",
            "So I'm not going to go into the actual mathematics of how what these functions are there in the paper, but suffice to say you're able to watch the values overtime."
        ],
        [
            "So.",
            "What does this actually enable?",
            "So by using semantic categories, we can do something pretty complex and more advance of user profiling.",
            "We can actually say that if we take all the users and ratings in the training split and we split up into 5 equal stages, we can actually drive the average rating preference per category in each stage and this will give us a probability distribution.",
            "This will tell us what's the affinity at user has to a given semantic category at a given time.",
            "So this thing here.",
            "So this is what it looks like if we just have these five stages, we can see how they.",
            "Evolution of the users tastes are changing overtime and this is pretty powerful thing to do because it allows us then to use measures from information theory to see how these distributions are actually changing."
        ],
        [
            "Let's give you a couple of examples.",
            "We can actually see by looking at the one stage versus the previous stage.",
            "One structural difference in what the users actually rating their preferences for the semantic after categories.",
            "So for this we use conditional entropy and what this is showing that the users actually diverge away from the price.",
            "We can also compute transfer entropy.",
            "This allows us to see what's the extent which global taste properties actually affect the users preferences as well.",
            "So here in this context, because the users takes a diverging away, it basically shows that the global takes that have an effect and explain why these two things are important in seconds.",
            "We can encode this in the actual recommender system."
        ],
        [
            "So when we put all these things together all these little nuts and bolts basically we came up with modification of an existing SVD plus plus model, and there's two important changes we implemented.",
            "First of all, we can actually capture this taste evolution overtime.",
            "We can also include the semantic personalization component, so I'm going to show you horrible function now and basically this is composed of three parts, so we have static biases components.",
            "This is just like on average what's going on.",
            "Then we have a category biases component in the personalization component.",
            "The trick really here is in the second bit, and this is where."
        ],
        [
            "Actually bring in and transferring this information using vertex kernels so.",
            "So basically we have two parts to this.",
            "The first parts for general category biases.",
            "So given categories of an item, what's generally devices that they have that all users have?",
            "And then we also have the use specific biases.",
            "So given categories of the item and given a user, what's their preferences for these for these categories?"
        ],
        [
            "So the second part, the second component, is composed of decomposed even further so prior rated categories and transfer categories and basically what we do here is we then implement these vertex kernels.",
            "In this second part is basically says for all the categories that user hasn't rated.",
            "Finally similar categories using this arbitrary vertex kernel and we can actually change this depending on which one we want to look at.",
            "And then we can actually wait using beta to see what's the effect of actually transferring in this information versus not doing so.",
            "Basically what happens here is that for each one of these computations were basically saying OK, what's the?",
            "What's the likely rating given the fact that it's a category in this user.",
            "So we compose this by the final rating of final preference for user has for this category.",
            "What's the change in that preference?",
            "Overtime?",
            "So we saw that conditional entropy, and what's the global influence that transfer entropy?",
            "How does this actually affect users?",
            "So you're pulling out of that and then changing the transfer entropy?",
            "So."
        ],
        [
            "The experiment we conducted, the aim we want to predict the actual ratings that users have.",
            "For items.",
            "There's two things we want to look at.",
            "First of all, OK, we've done a lot of computation here.",
            "Does actually have an effect to actually improve over existing models?",
            "And the second thing is, do we actually get a reduction in error if we transfer in these previous or to cover?",
            "These calls are categories."
        ],
        [
            "So we tested for models.",
            "First one was just our baseline, so we have SVD in SVD plus plus and then we have two modified ones.",
            "So one just including the category biases and wonderful personalization component, and for these latter two models, we actually very the kernels.",
            "We have five different models in their sort of four kernels member.",
            "That one see what effect is when we do the standard thing of training of hyperparameters over validation, split and applying it on held out set.",
            "We're trying to minimize this OK.",
            "So the results from."
        ],
        [
            "This what we find is that OK, these are our baselines.",
            "We find, unsurprisingly, SVD plus plus app forms of existing SVD model.",
            "What you find is it won't be just include this semantic biases stuff.",
            "So the first row in this subsection we see a reduction in error.",
            "OK, pretty marginal.",
            "However, when we start to include these vertex kernels and transfer an existing information, we get more significant reduction."
        ],
        [
            "I'm in the same for the full model as well.",
            "Interesting thing is that there's not much difference between the full personalization model and just this one that includes category vices, and this is really the power of being able to test for user evolution and taste and actually bring this stuff in OK. Yeah, and then also what we found is that by choosing beta, you'll find it's quite got quite high value, so it's basically indicating that generally only transferring a little bit of this information is beneficial versus a lot."
        ],
        [
            "OK, so to conclude, I've shown that users tastes evolve overtime.",
            "We can track this using semantic categories.",
            "Vertex kernels allow us to overcome this cold start categories problem.",
            "So basically saying OK, what's the most similar category to actually transfer in?",
            "And we found a significant reduction in air.",
            "OK, particularly these existing baselines.",
            "And also when we transfer in semantic category information in the future work basically is.",
            "I think there's a lot of areas you could go with this, but generally the 1st two things we're looking at is how can we exploit the graph space more 'cause we just use these rudimentary sort of.",
            "Vector computations at the moment."
        ],
        [
            "OK, yeah, that's it.",
            "So we've got any questions.",
            "Will be happy to answer them."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yeah, my name is Matthew Rowe.",
                    "label": 1
                },
                {
                    "sent": "I'm a lecturer at Lancaster University and I'm going to talk to you today about an approach to combine link data with matrix factorization for recommender systems, right?",
                    "label": 0
                },
                {
                    "sent": "So to give you an example, the task which.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To accomplish is something called predicting ratings right?",
                    "label": 1
                },
                {
                    "sent": "So we've got a user and issues as Darth Vader, right?",
                    "label": 0
                },
                {
                    "sent": "And as we all know, Darth Vader was Chewbacca, but he knows Han Solo as well, right?",
                    "label": 0
                },
                {
                    "sent": "And the task basically is we're providing a bunch of items, so in this context a movie.",
                    "label": 0
                },
                {
                    "sent": "So we got 2 movies that are quite similar here.",
                    "label": 0
                },
                {
                    "sent": "Star Trek and aliens.",
                    "label": 0
                },
                {
                    "sent": "We've got one that's a bit of an outlier maid in Manhattan, so if you ever seen this film, it's very different from the first 2, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah OK people have seen it.",
                    "label": 0
                },
                {
                    "sent": "It's probably forced viewing as well, right?",
                    "label": 1
                },
                {
                    "sent": "So in essence, in matrix factorization or entrance predict ratings, we have a user's buy items matrix, right?",
                    "label": 0
                },
                {
                    "sent": "And what we want to do is we're trying to predict Darth Vader's rating for his aliens film.",
                    "label": 0
                },
                {
                    "sent": "I've got this?",
                    "label": 0
                },
                {
                    "sent": "Here right and often what happens is R2D2 would take this matrix, will induce some model, and output the predicted rating right, and our quality of a prediction is how far we are away from the absolute true value.",
                    "label": 0
                },
                {
                    "sent": "Now there's different ways of doing this.",
                    "label": 0
                },
                {
                    "sent": "This neighborhood based models and also something called matrix factorization, which I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "In the context, this talk, but it's original work.",
                    "label": 0
                },
                {
                    "sent": "When I was looking at this, I was really interested in trying to study how users tastes evolved overtime.",
                    "label": 0
                },
                {
                    "sent": "How do they change as users go along and there's?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem if you're trying to do this using latent factors within matrix factorization, and this is something called the factor consistency problem.",
                    "label": 1
                },
                {
                    "sent": "So what you often find is that the actual approach takes this users by items matrix and tries to decompose it into two different matrices.",
                    "label": 0
                },
                {
                    "sent": "So you have a users by factors matrix and items by factors matrix, and factors are basically like some aspects Infinity, so it could be that Darth Vader has a preference for romantic comedies.",
                    "label": 0
                },
                {
                    "sent": "He has a preference for sci-fi movies and same for items as well.",
                    "label": 0
                },
                {
                    "sent": "An item can be more aligned with romantic comedy.",
                    "label": 0
                },
                {
                    "sent": "Or more lines were sci-fi film, so often will happen is if you take your data set and you say wrong to split my data set up into equal frequency chunks, and I'm going to mine you latent factor vector for Darth Vader over one chunk and then over the next chunk you have a problem when we trying to line the latent factors.",
                    "label": 0
                },
                {
                    "sent": "You can't do it.",
                    "label": 0
                },
                {
                    "sent": "This is this factor consistency problem.",
                    "label": 0
                },
                {
                    "sent": "You have no idea.",
                    "label": 0
                },
                {
                    "sent": "But the first factor Maps to the second one or the first one.",
                    "label": 1
                },
                {
                    "sent": "And the problem is, you can't really examine to see how Darth Vader states have evolved overtime.",
                    "label": 0
                },
                {
                    "sent": "OK, so my salute.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was to use semantic categories.",
                    "label": 0
                },
                {
                    "sent": "OK, so link data categories and you're all sold on this so I'll just give you a brief overview.",
                    "label": 0
                },
                {
                    "sent": "You have an item, aliens in this context.",
                    "label": 0
                },
                {
                    "sent": "This hasn't urri this has skulls.",
                    "label": 0
                },
                {
                    "sent": "Categories are mapped to this so we know that alien aliens is an action horror film.",
                    "label": 0
                },
                {
                    "sent": "We know that it's published in 1986.",
                    "label": 0
                },
                {
                    "sent": "That sort of thing and what we can do instead is we can look to see what the preferences are for a given category given a user.",
                    "label": 0
                },
                {
                    "sent": "So it could be that Darth Vader user 2 here has a preference for one category over another.",
                    "label": 0
                },
                {
                    "sent": "And this is basically informed somehow he's rated items which have been mapped to these categories beforehand, and the nice thing about this is that we can capture preference for a category at a given time among color lifecycle stage S. And every time we can look to see how this changes, right, we can see how the distribution of preferences but Darth Vader has for these categories is changed, so we get this nice mapping overtime.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, publishers work before the Web Intelligence conference, but when I actually start to look into the data after I've done these experiments, I discovered a problem.",
                    "label": 0
                },
                {
                    "sent": "And this problem is called cold start categories, right?",
                    "label": 0
                },
                {
                    "sent": "So you've probably heard about cold start users called start items in the context of recommender systems.",
                    "label": 0
                },
                {
                    "sent": "Course, that categories are something else slightly different, but I'm kind of related.",
                    "label": 0
                },
                {
                    "sent": "So if you flip the problem around a little bit, imagine if we've got the rate.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things for Star Trek and raelians.",
                    "label": 0
                },
                {
                    "sent": "We want to predict it for this movie here you probably wear, but obviously these will map to certain categories and made a Manhattan world map to other categories, but there's no overlap between this right?",
                    "label": 0
                },
                {
                    "sent": "So probably therefore have is that our previous approach, which relied on knowing how Darth Vader was going to rate category C4 and C5 breaks down, right?",
                    "label": 0
                },
                {
                    "sent": "This is what we call unrated categories or cold start categories.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's the context.",
                    "label": 0
                },
                {
                    "sent": "What we look at and basically talk about ways to actually bring in existing ratings from these categories on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "So C1C2 and C3 to cover these ones, which help you have to have ratings for.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the outline of the talk and talk about the dates that we have and how we align it with your eyes.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to quantify the extent which is called star categories problem actually exists, and I'm going to talk about how we transfer in these rated categories before hand to cover these unrated ones.",
                    "label": 0
                },
                {
                    "sent": "Then talk about user profiling.",
                    "label": 1
                },
                {
                    "sent": "Then how we incorporate this into this SVD plus plus approach and then evaluate it in the conclusions as well.",
                    "label": 0
                },
                {
                    "sent": "So in the context of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This paper I use watercolor movie tweetings datasets.",
                    "label": 0
                },
                {
                    "sent": "This is a relatively new date set that came out last year and this was mined from tweets that people have published.",
                    "label": 0
                },
                {
                    "sent": "So what happened is they going rate a movie on IMDb and this would then be pushed into their Twitter account and Simon dooms and his team went and actually crawl Twitter for all IMDb links, extracted the actual URL so they get some metadata about this and were provided with basically is a numeric item ID.",
                    "label": 0
                },
                {
                    "sent": "The title of the movie and also the year as well.",
                    "label": 0
                },
                {
                    "sent": "So the task graph will becomes we need to get this yr I that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Site some idea lines too, so going back to our example of aliens, we say right given this title, look up on the semantic Web or in the link data Cloud.",
                    "label": 0
                },
                {
                    "sent": "All the counterfeit ur eyes.",
                    "label": 0
                },
                {
                    "sent": "But this movie item could be related to.",
                    "label": 0
                },
                {
                    "sent": "For each candidate, we then look at the actual skills categories and what you find is that often it will say the year that this movie was released in.",
                    "label": 0
                },
                {
                    "sent": "So in this context, in aliens it's 1986.",
                    "label": 0
                },
                {
                    "sent": "We have that in our own existing data set, so we can use this as a disambiguate are, and we say afterwards that, yeah, we've got a match between item ID in your eye, so this is an existing approach to some research from Barry.",
                    "label": 0
                },
                {
                    "sent": "Have you switch replicating this here?",
                    "label": 0
                },
                {
                    "sent": "But what happens is we get a reduction right?",
                    "label": 0
                },
                {
                    "sent": "If you look in the table here we have the absolute numbers of items, users and ratings in parentheses.",
                    "label": 0
                },
                {
                    "sent": "We have a reduction as a percentage.",
                    "label": 0
                },
                {
                    "sent": "What we find is that actually the coverage of this data is we're using DB pedia.",
                    "label": 0
                },
                {
                    "sent": "I think 3.9 here.",
                    "label": 0
                },
                {
                    "sent": "Actual coverage is such that people are actually revealing really obscure films often.",
                    "label": 0
                },
                {
                    "sent": "So we don't.",
                    "label": 0
                },
                {
                    "sent": "We are actually able to get a Uri for those films.",
                    "label": 0
                },
                {
                    "sent": "So we get this reduction.",
                    "label": 0
                },
                {
                    "sent": "So in the context of this talk, in the experiments are going to discuss.",
                    "label": 0
                },
                {
                    "sent": "Basically, I want to look to see how users takes a changing overtime in the training data set, sewing time, time order, everything.",
                    "label": 0
                },
                {
                    "sent": "I'll use the next 10% for validation, so for tuning a model and then finally they held out final 10% for testing.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to quantify the extent switch called start categories actually occur while did was a took each user, all the categories they rated, the training set and then look at the items of rates in the training set in the categories of those items.",
                    "label": 0
                },
                {
                    "sent": "And when I looked in the validation set and the test set to see what was actually missing.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the distribution of this, what we find is that actually on average was a hundred categories are missed in validation set 138 in the test.",
                    "label": 0
                },
                {
                    "sent": "So it's quite a lot of information we're missing, so it's quite a lot of calls that categories we need to account for.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to account for them, we use something called vertex kernels.",
                    "label": 1
                },
                {
                    "sent": "So let's go back to this example again.",
                    "label": 0
                },
                {
                    "sent": "We obviously have these categories that these three items have been mapped to.",
                    "label": 0
                },
                {
                    "sent": "When we actually look in the linked data graph, we found it is arbitrary concepts of these are going to be sort of dark, Brown ready, sort of colored boxes.",
                    "label": 0
                },
                {
                    "sent": "We found essentially arbitrary concepts that these are the categories have been mapped to.",
                    "label": 0
                },
                {
                    "sent": "Just buy some random predicates, don't really matter what.",
                    "label": 0
                },
                {
                    "sent": "What we can quickly see when we look through it.",
                    "label": 0
                },
                {
                    "sent": "OK, this is just conjecture, an example, but in your data it kind of shows the same thing is actually alignment.",
                    "label": 0
                },
                {
                    "sent": "Over there we can see how.",
                    "label": 0
                },
                {
                    "sent": "Previously we cannot get a mapping, but now we can see how, for instance, like C4's map to_free consistency, freeze mapped_free as well.",
                    "label": 0
                },
                {
                    "sent": "So we get kind of overlap we can exploit.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do this by basically trying to transfer in existing similar categories by exploiting that graph and the neighborhood of it.",
                    "label": 0
                },
                {
                    "sent": "So we have this function here and it's basically takes as input rated categories and some categories of the item that we want to then try and align.",
                    "label": 0
                },
                {
                    "sent": "Basically we're not covering and the trick here is that we want to choose categories from this set.",
                    "label": 0
                },
                {
                    "sent": "See which maximize this function here, so it's a vertex kernel function and basically what this is doing is saying OK giving these two categories.",
                    "label": 0
                },
                {
                    "sent": "What's the actual sort node similarity, but also the neighborhood similarity, but we can then compute.",
                    "label": 0
                },
                {
                    "sent": "And so you.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hope you're doing this.",
                    "label": 0
                },
                {
                    "sent": "Basically to go back to this example, you take the first category.",
                    "label": 0
                },
                {
                    "sent": "This is aliens have been mapped to, so C2 and we can see how it's been mapped to or aligned all related to_2_free and for C4 we have_free_M and what we can do is basically we can compute vectors which to know natural sort of links that are going on.",
                    "label": 0
                },
                {
                    "sent": "So by computing these vectors we can then just measures measure of similarity between.",
                    "label": 0
                },
                {
                    "sent": "And this is what we do.",
                    "label": 0
                },
                {
                    "sent": "So we vary the actual vertex kernel function that we use, so we can actually get different sort of ways of computing the similarity.",
                    "label": 0
                },
                {
                    "sent": "So I'm not going to go into the actual mathematics of how what these functions are there in the paper, but suffice to say you're able to watch the values overtime.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What does this actually enable?",
                    "label": 0
                },
                {
                    "sent": "So by using semantic categories, we can do something pretty complex and more advance of user profiling.",
                    "label": 0
                },
                {
                    "sent": "We can actually say that if we take all the users and ratings in the training split and we split up into 5 equal stages, we can actually drive the average rating preference per category in each stage and this will give us a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "This will tell us what's the affinity at user has to a given semantic category at a given time.",
                    "label": 0
                },
                {
                    "sent": "So this thing here.",
                    "label": 0
                },
                {
                    "sent": "So this is what it looks like if we just have these five stages, we can see how they.",
                    "label": 0
                },
                {
                    "sent": "Evolution of the users tastes are changing overtime and this is pretty powerful thing to do because it allows us then to use measures from information theory to see how these distributions are actually changing.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's give you a couple of examples.",
                    "label": 0
                },
                {
                    "sent": "We can actually see by looking at the one stage versus the previous stage.",
                    "label": 0
                },
                {
                    "sent": "One structural difference in what the users actually rating their preferences for the semantic after categories.",
                    "label": 0
                },
                {
                    "sent": "So for this we use conditional entropy and what this is showing that the users actually diverge away from the price.",
                    "label": 1
                },
                {
                    "sent": "We can also compute transfer entropy.",
                    "label": 1
                },
                {
                    "sent": "This allows us to see what's the extent which global taste properties actually affect the users preferences as well.",
                    "label": 0
                },
                {
                    "sent": "So here in this context, because the users takes a diverging away, it basically shows that the global takes that have an effect and explain why these two things are important in seconds.",
                    "label": 0
                },
                {
                    "sent": "We can encode this in the actual recommender system.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we put all these things together all these little nuts and bolts basically we came up with modification of an existing SVD plus plus model, and there's two important changes we implemented.",
                    "label": 0
                },
                {
                    "sent": "First of all, we can actually capture this taste evolution overtime.",
                    "label": 0
                },
                {
                    "sent": "We can also include the semantic personalization component, so I'm going to show you horrible function now and basically this is composed of three parts, so we have static biases components.",
                    "label": 0
                },
                {
                    "sent": "This is just like on average what's going on.",
                    "label": 0
                },
                {
                    "sent": "Then we have a category biases component in the personalization component.",
                    "label": 0
                },
                {
                    "sent": "The trick really here is in the second bit, and this is where.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually bring in and transferring this information using vertex kernels so.",
                    "label": 0
                },
                {
                    "sent": "So basically we have two parts to this.",
                    "label": 0
                },
                {
                    "sent": "The first parts for general category biases.",
                    "label": 0
                },
                {
                    "sent": "So given categories of an item, what's generally devices that they have that all users have?",
                    "label": 0
                },
                {
                    "sent": "And then we also have the use specific biases.",
                    "label": 0
                },
                {
                    "sent": "So given categories of the item and given a user, what's their preferences for these for these categories?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second part, the second component, is composed of decomposed even further so prior rated categories and transfer categories and basically what we do here is we then implement these vertex kernels.",
                    "label": 0
                },
                {
                    "sent": "In this second part is basically says for all the categories that user hasn't rated.",
                    "label": 0
                },
                {
                    "sent": "Finally similar categories using this arbitrary vertex kernel and we can actually change this depending on which one we want to look at.",
                    "label": 0
                },
                {
                    "sent": "And then we can actually wait using beta to see what's the effect of actually transferring in this information versus not doing so.",
                    "label": 0
                },
                {
                    "sent": "Basically what happens here is that for each one of these computations were basically saying OK, what's the?",
                    "label": 0
                },
                {
                    "sent": "What's the likely rating given the fact that it's a category in this user.",
                    "label": 0
                },
                {
                    "sent": "So we compose this by the final rating of final preference for user has for this category.",
                    "label": 0
                },
                {
                    "sent": "What's the change in that preference?",
                    "label": 0
                },
                {
                    "sent": "Overtime?",
                    "label": 0
                },
                {
                    "sent": "So we saw that conditional entropy, and what's the global influence that transfer entropy?",
                    "label": 0
                },
                {
                    "sent": "How does this actually affect users?",
                    "label": 0
                },
                {
                    "sent": "So you're pulling out of that and then changing the transfer entropy?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The experiment we conducted, the aim we want to predict the actual ratings that users have.",
                    "label": 0
                },
                {
                    "sent": "For items.",
                    "label": 0
                },
                {
                    "sent": "There's two things we want to look at.",
                    "label": 0
                },
                {
                    "sent": "First of all, OK, we've done a lot of computation here.",
                    "label": 0
                },
                {
                    "sent": "Does actually have an effect to actually improve over existing models?",
                    "label": 0
                },
                {
                    "sent": "And the second thing is, do we actually get a reduction in error if we transfer in these previous or to cover?",
                    "label": 0
                },
                {
                    "sent": "These calls are categories.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we tested for models.",
                    "label": 0
                },
                {
                    "sent": "First one was just our baseline, so we have SVD in SVD plus plus and then we have two modified ones.",
                    "label": 0
                },
                {
                    "sent": "So one just including the category biases and wonderful personalization component, and for these latter two models, we actually very the kernels.",
                    "label": 0
                },
                {
                    "sent": "We have five different models in their sort of four kernels member.",
                    "label": 0
                },
                {
                    "sent": "That one see what effect is when we do the standard thing of training of hyperparameters over validation, split and applying it on held out set.",
                    "label": 0
                },
                {
                    "sent": "We're trying to minimize this OK.",
                    "label": 0
                },
                {
                    "sent": "So the results from.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This what we find is that OK, these are our baselines.",
                    "label": 0
                },
                {
                    "sent": "We find, unsurprisingly, SVD plus plus app forms of existing SVD model.",
                    "label": 0
                },
                {
                    "sent": "What you find is it won't be just include this semantic biases stuff.",
                    "label": 0
                },
                {
                    "sent": "So the first row in this subsection we see a reduction in error.",
                    "label": 0
                },
                {
                    "sent": "OK, pretty marginal.",
                    "label": 0
                },
                {
                    "sent": "However, when we start to include these vertex kernels and transfer an existing information, we get more significant reduction.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm in the same for the full model as well.",
                    "label": 0
                },
                {
                    "sent": "Interesting thing is that there's not much difference between the full personalization model and just this one that includes category vices, and this is really the power of being able to test for user evolution and taste and actually bring this stuff in OK. Yeah, and then also what we found is that by choosing beta, you'll find it's quite got quite high value, so it's basically indicating that generally only transferring a little bit of this information is beneficial versus a lot.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to conclude, I've shown that users tastes evolve overtime.",
                    "label": 0
                },
                {
                    "sent": "We can track this using semantic categories.",
                    "label": 0
                },
                {
                    "sent": "Vertex kernels allow us to overcome this cold start categories problem.",
                    "label": 1
                },
                {
                    "sent": "So basically saying OK, what's the most similar category to actually transfer in?",
                    "label": 0
                },
                {
                    "sent": "And we found a significant reduction in air.",
                    "label": 1
                },
                {
                    "sent": "OK, particularly these existing baselines.",
                    "label": 0
                },
                {
                    "sent": "And also when we transfer in semantic category information in the future work basically is.",
                    "label": 0
                },
                {
                    "sent": "I think there's a lot of areas you could go with this, but generally the 1st two things we're looking at is how can we exploit the graph space more 'cause we just use these rudimentary sort of.",
                    "label": 0
                },
                {
                    "sent": "Vector computations at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, yeah, that's it.",
                    "label": 0
                },
                {
                    "sent": "So we've got any questions.",
                    "label": 0
                },
                {
                    "sent": "Will be happy to answer them.",
                    "label": 0
                }
            ]
        }
    }
}