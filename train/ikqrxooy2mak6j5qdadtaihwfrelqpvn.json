{
    "id": "ikqrxooy2mak6j5qdadtaihwfrelqpvn",
    "title": "Fast Influence-based Coarsening for Large Networks",
    "info": {
        "author": [
            "B. Aditya Prakash, Department of Computer Science, Virginia Polytechnic Institute and State University"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_prakash_large_networks/",
    "segmentation": [
        [
            "So I'm other than today.",
            "I'll be talking about fast influence based course links for large networks this is joint work with Manish John who's sitting here, ya and BS.",
            "So."
        ],
        [
            "So.",
            "We all know networks are getting huge and I mean for example the freak friendship network at least was like 87 million users and almost 8 billion photos.",
            "Amazon has like 237 million accounts.",
            "Facebook is growing on a tremendous rate every day and so on and so forth."
        ],
        [
            "So there is a clear need for faster analysis for network algorithms, and there's an ever growing list of applications which utilized network effects, right?",
            "For example, viral marketing information, diffusion, Epidemiology and so on.",
            "So however, scaling up traditional algorithms up to millions of nodes is hard, right?",
            "I mean, that's why we have so many papers having really cool algorithms for a new techniques for these problems so."
        ],
        [
            "I mean, of course the best way to do this is having faster, simpler algorithms or perform analysis locally.",
            "So what the approach we use in our paper is to zoom out of the network to obtain a smaller representation of the network which preserves some properties which you want and then run our traditional algorithms on that smaller representation.",
            "So that's the hope that would be faster."
        ],
        [
            "So that is what we do in this paper, and we call this coursing.",
            "So if you want to think about what we do, you can think of in one sentence we give a Birds Eye view of the network, preserving some structural properties.",
            "So we want to see this huge hairy ball and try to give you a smaller representation."
        ],
        [
            "You can also think of this as zooming out of the network, so if you have a big graph, you can see that this graph seems to have like major structures like ABCD, so probably you can zoom out at a certain level.",
            "You might think something like this, right?",
            "So this is a smaller representation of the network and the type of graphs which we motivated our work was cascade graphs.",
            "Were suppose you have memes flowing on a big network like Twitter or disease propagating on a population network and we want to summarize what really happened, right?",
            "We want to see structurally how the cascade happened, how the mean spread, and that's what we're trying to do here.",
            "And we call this action coarsening."
        ],
        [
            "So what are the challenges when we won?"
        ],
        [
            "To solve this problem right, I mean what are the product of the research questions involved in trying to understand what we want to preserve.",
            "How do we preserve it, and how do we do this fast right?",
            "So the first challenge is how do you maintain diffusive characteristics while coarsening networks right?",
            "So if I give you a cascade networks, what would you preserve?",
            "I mean, what does it even mean to say that I want to preserve diffusive characteristics, right?",
            "So this needs to be defined a little more precisely and the second challenge is how do you merge nodes to get that course networks right?",
            "How do you combine nodes to get a smaller network?",
            "So you need to even define the merging operation?",
            "And of course, the algorithm task there is.",
            "How do you find these things in a fast, scalable manner?"
        ],
        [
            "So I mean, so I mean, you can look at the diffusion graph, right?",
            "So diffusion graph is a well understood concept.",
            "This is essentially like this can be blogs connected to each other.",
            "Depending on who cites whom, or even blogs or pages right?",
            "Which site link each other.",
            "So diffusion is a graph induced by time ordered propagation of information, right?",
            "So we have given this graph.",
            "This is the motivation for the paper.",
            "But you can use this on any graph and we want to summarize this right."
        ],
        [
            "Just to give you a background about modeling information diffusion, or I mean any spreading process.",
            "I mean the very famous model which in fact one the test of Time award in the CS Katie was the independent Cascade model right?",
            "Compared to an here.",
            "Effectively you have a graph and you have weights on the edges, right?",
            "An weights on the edges denote the probability of spreading given the neighbors infected.",
            "For example this guy is infected and the problem.",
            "Suppose there's a meme or any disease spreading the probability that it will spread to its neighbors is denoted by some weight on the edge.",
            "Right, and this succeeds by some probability and it's so on and so forth.",
            "So information is spreading over the network in such a way, and we want to preserve information, preserve the content of information in the graph, and we course in it.",
            "So that's the problem we're trying to solve.",
            "So how would you do this?",
            "Water, the diffuser characteristics you want to curse in.",
            "So it turns out."
        ],
        [
            "Had a paper couple of years back and I CDM, which kind of showed up.",
            "I think an interesting result which says that the first eigenvalue of adjacency matrices is enough for most diffusion models and it kind of related to the epidemic threshold.",
            "So what is the epidemic threshold?",
            "Epidemic threshold is the is the condition under which there will be a large epidemic on a graph, so that's what we're trying to do there.",
            "So that is related to the largest eigenvalue of the edges in the matrix, right?",
            "So given this result, it seems intuitive that the diffuser.",
            "Critics of a graph can be captured to a large extent by the 1st eigenvalue, and that's what we're trying to aim, so that's how we define our goal.",
            "So to give you an intuition of what I mean by the 1st eigenvalue and what does it even mean for a diffusion, right?",
            "So suppose you have these three graphs.",
            "If you look at this all around 5 nodes, and these two in fact have the same average degree, right?",
            "Whereas click doesn't and you can see that the chain intuitively is very safe, right?",
            "You wouldn't expect the epidemic or widest spread too much, right?",
            "Because everybody is connected to just.",
            "Two people, so Anna large smaller chain is equal into a larger chain, right?",
            "In fact, the eigenvalue for this is more or less constant as as N grows, whereas the star has an average degree as the same as the chain.",
            "But clearly star is much more flamable, right?",
            "Because if the center of the star is infected, it can quickly spread over to the rest of the graph, and this is shown by the as as grows the eigenvalue of star grows roughly rise order root.",
            "And of course, a click is deadly, right?",
            "I mean any guy can impact any other guy in the network.",
            "This is also called homogeneous models, right?",
            "So here the eigenvalue grows as root N sorry order and so clearly increasing Lambda is including the one billeti an.",
            "You would expect graphs having same Lambda to have same diffusive characteristics given this result.",
            "So OK good.",
            "So what?"
        ],
        [
            "We do is that we we say that, OK, let's maintain the eigenvalue as week or so.",
            "We have still not defined what do we even mean by coarsening, but whatever that may mean, we want to preserve the eigenvalue.",
            "That's the goal.",
            "So you take the large graph you course in it and you get a smaller network, right?",
            "And make this course in network have the least change in the first eigenvalue.",
            "That's what we want to do, and that's what we're aiming for.",
            "OK."
        ],
        [
            "Good, so now let's go onto the second challenge, which is how do you even merge nodes right?",
            "And this is actually is not that straightforward, and this needs some little intuition, so I'll just try to give you the intuition and for details you can look up the paper.",
            "So suppose you have this chain, right?",
            "In fact, let's backtrack what we want to do when we want to merge is that we want to get a course in graph that approximates the original with respect to the diffusion, right?",
            "With respect to the actual diffusion model.",
            "So remember the weights on the edges are roughly kind of conditional probabilities of spreading the infection right.",
            "Whatever model that may be.",
            "So if this guy is infected, what is the probability he spreads it to his neighbors?",
            "That's what these probabilities don't.",
            "So suppose you have a chain and you have these weights and you have these two nodes in which we want to merge, right?",
            "So we want to merge these two nodes into another node called C. The question we're asking is that should be changed.",
            "The weights of the graph.",
            "So intuitively, if you don't change the weights of the graph of the eigenvalue, should degrees right?",
            "Because you're decreasing the size of the graph, so then I mean it seems like the problem is not well posed, right?",
            "So what we say is that we need to re wait the graph intelligently?",
            "And how do we do that?",
            "So here's the intuition, right?",
            "So if we keep the same weight, then the probability that see infects D is still .5, right?",
            "That seems excessive.",
            "'cause if I choose C2 effects and choose C, you're clearly infecting physically either B or a right, not both.",
            "I mean, in reality you cannot choose both of them right?",
            "When you're choosing, see effectively choosing either one of them and the way we think about this is that the choosing them yet uniformly at random, because all those nodes are similar with respect to their diffusion characteristics, right?",
            "So if I in fact either of those two nodes, you would expect the final footprint to be roughly the same.",
            "So that's the intuition.",
            "So that's why you if in fact B, the probability that he gets infected is .5, right?",
            "Just one edge effect, a the probability that gets infected is .25, right?",
            "So if I choose?",
            "Only at random you would expect the average infection probability to be .375, right?",
            "And that's why you need to re weight it.",
            "So without going into too many details about the general case where you need to consider all."
        ],
        [
            "So parts going from the course and node which is C to the other sets of edges going across from A to B.",
            "You can write down the equations for how the average probability of infection for each set of nodes which are neighbors for NB.",
            "So yeah, you can look up the paper."
        ],
        [
            "So that's the way we define merging, right?",
            "That's the way we define coarsening, so we have defined what we want to maintain.",
            "We have defined how are we doing the unit action.",
            "Right now we need to pick out the best edges which we should choose to merge so that the goal is attained, right?",
            "So the goal is to find the best nodes to merge according to the Merge definition given in the previous slide in a fast and scalable way to a large network, right so?"
        ],
        [
            "Let's just define the graph coarsening problem abit more formally, so it's a combinatorial problem which is given a large graph, Gianna introduction Factor Alpha.",
            "It just says how many nodes do we want in the course and graph, right?",
            "That's a tunable parameter.",
            "Find the best set of actually edges or I should say node pairs because this is directed.",
            "So you might have multiple edges between I mean to and fro between our node pair, best set of node pairs to merge so that the eigenvalue change right?",
            "This is the original graph and this is the course and graph should be minimized and so you can think of edge being the courses graph with the least change of the first Dragon value.",
            "That's the goal."
        ],
        [
            "So, and I've greedy heuristic would be just test each edge test each node pair, calculate the change in value and choose the guy with the lowest change, right?",
            "I mean that's doable, but it's too slow because order M squared to score all the edges if it sound directed graph.",
            "And in fact if you have to, if the reduction factor is Alpha then it's NP horizon right?",
            "Because you need two sets of nodes, so you basically lose time benefits of analyzing the smaller graph, right?",
            "You want to make this course next step as fast as possible so that you can run your algorithms on this smaller graph.",
            "So if this itself is too expensive then there's no point doing this.",
            "So."
        ],
        [
            "So our proposed method, which I won't go into too much."
        ],
        [
            "Detail is based on the idea that yes, you can approximate the change fast enough an A bit of algebra shows that you can up to 1st order terms.",
            "You can estimate the score of an edge or node pair in constant time, and then I puristic remember is a quadratic time right?",
            "So this is pretty fast."
        ],
        [
            "And so that essentially means that given the first eigenvalue Lambda and the corresponding eigenvectors, the score of a node pair can be approximate in constant time.",
            "So this this suppose you're merging A&B and you see you merge it into C and you want to estimate what's the change.",
            "So if you think about like this that if I can estimate this change I can choose the node pair with the least change.",
            "Simple as that."
        ],
        [
            "Again, these are details.",
            "I mean, please see the paper for the exact derivation, but it's yeah, it looks a bit heavy, but it's very nice.",
            "I mean in terms of algebra, so it's based on left and right eigenvectors and there is a slight trick involved in self loops there."
        ],
        [
            "So the complete algorithm, for course.",
            "Net is this right?",
            "Compute the scores for all edge pairs or all node pairs, merge nodes with the smallest score and then just keep repeating so it's a greedy approach.",
            "So if I have the original network like this and then I tried assign scores for each node pair which comes to be like this which is green and red right?",
            "Green means that these are good edges to merge and red means these are bad edges to merge.",
            "And then you merge these edges and you get this course in graph.",
            "I'm not showing the rebated.",
            "Right, so just intuitively just looking at this very simple toy example, you can see that.",
            "I mean it is merging the node pairs which are have similar characteristics where it's preserving the structure of how the graph looks like at least even here.",
            "I mean, this node is clearly important because it's like the hub.",
            "So I mean you can see that it's kind of preserving that."
        ],
        [
            "But so this is sub quadratic.",
            "As I said, based on number of nodes and edges and yeah."
        ],
        [
            "So this is I mean, intuitively it looks fine.",
            "So now we want to measure how?",
            "How does it perform it, at least with respect to the graph coarsening problem, right?"
        ],
        [
            "Sorry, so our algorithms course net, so we compare against random for example.",
            "So this is Amazon and eBay LP, so this is the first eigenvalue when none of the nodes have been Corson, right?",
            "And just one look at this resulting you see that even after merging 70% of the node pairs in the graph you have, we have maintained the first eigenvalue effectively at constant right?",
            "I mean, there is almost no perceptible change in the first eigenvalue, so this is, this was something very nice, and because we didn't really expect this to happen right, that really is showing that most which might agree with intuition that most of the edges of the nodes in the.",
            "Real graph are probably not that important in terms of the structure of the graph and this and we have many more results in the paper.",
            "So the first eigenvalue gap is well up to even.",
            "I mean there were some graphs where you could prune over 90% of the graph."
        ],
        [
            "Cool and scalability.",
            "Even though theoretically it's like sub quadratic, but I mean at least on the graph which we tried, which are pretty large.",
            "I mean it's almost near linear, so which is also good.",
            "So that shows that you can do it fast enough and because it is based on a spectral methods, I mean if there is a faster algorithm for calculating the eigenvalue or you can parallelize it.",
            "I mean, these are very straightforward for doing that with this algorithm."
        ],
        [
            "And."
        ],
        [
            "This was scalability with respect to the reduction factor Alpha, right?",
            "Which is so?",
            "That means the more you want to course in the proportionately more you pay cost, and it is also scaleable with respect to the graph size."
        ],
        [
            "OK, good, so this is like OK, we have defined a graph coarsening problem.",
            "We have solved it efficiently and we have seen that it solves reasonably well, right?",
            "So?",
            "But the natural question is what is it useful for, right?",
            "Can you show an objective way of evaluating where you can use this in fast makeup algorithm faster or do some other data mining tasks faster, right?",
            "So we."
        ],
        [
            "A couple of applications in the paper there.",
            "I think they're working on more.",
            "One application is like influence maximization, so again, this is from the campaign paper at all paper, and I'm sure many people know it.",
            "But let me give you a brief overview of it, right?",
            "So it's like you have you want to convince us subset of individuals in the social network to adopt your product so that they spread the by word of mouth process and make other people adopt your whatever you would want them to adopt, right?",
            "It can be more product or whatever.",
            "So you want to trigger large cascade of productive options.",
            "And the influence maximization problem asks that, can you help me choose these best people in a social network given awaited IC model?"
        ],
        [
            "So who is the most influential person, right?",
            "So we said that OK, if this.",
            "If we are really preserving the diffuser characteristics of the graph, then if you run the influence maximization, any algorithm on the smaller graph, the course in graph, you should get similar results, right?",
            "Or at least this is close to the quality of the original graph.",
            "So here's what we call.",
            "So we have a we call our framework as C spin for at least the influence maximization problem.",
            "So what we do is that we course in the large social network using course net, right?",
            "So you get a much smaller graph.",
            "For really large alphas I mean these are alphas ranging from 70 to 80% right?",
            "Then you solve the influence maximization problem on the course and graph.",
            "So now I mean you can use any algorithm to solve it.",
            "We use fast enough algorithm called PMII which is a pretty popular heuristic and we didn't want to use the original greedy algorithm because pretty slow.",
            "So of course we will get time gains based on it, but PM is performs very well and it's very popular so we use that and we solve it on the smaller graph and then we randomly select one note to zoom out.",
            "So this is important.",
            "So you don't want to spend too much effort in actually trying to map the solutions from the course in graph to the original graph, right?",
            "Because if you want to do that then might as well solve the problem on the original graph right?",
            "And the way we do the coursing right.",
            "The way we carefully perform the coarsening attributes.",
            "All the nodes which have similar diffusive characteristics are in one group.",
            "You can think of it like that.",
            "So if you choose one supernode or one group, you can randomly allocate any one of the nodes in that group and the hope is that because the way we have done coarsening, these nodes have similar footprints.",
            "So that's why this can be performed, right?",
            "So you can do randomly select any node which is uniformly at random, which is very fast from each selected supernode, so this."
        ],
        [
            "This shows a bit of schematics like take the Big Graph course and it solved influence maximization problem.",
            "Suppose you see you can just zoom out an choose any any any guy in that group.",
            "OK, we call the C Smith.",
            "Let's see how it performs right?",
            "So if you run PMII on the.",
            "If you run PMI on the original graph and you run PMI and then you see spin the our framework and this shows the ratio of footprints right?",
            "This shows the how much footprint or how much spread do you get from the original algorithm and from what we get from our course in method and you can see they are all very close to 1.",
            "Right, it's versus spread ratio for different networks, and this is spread ratio versus Alpha on a particular network, so it shows that even you can score some 95% of the graph, at least in some graphs and still get maintained the spread, which was pretty nice.",
            "I mean, that means that it intuitively means that the real structure for network important for this problem is probably not that complicated."
        ],
        [
            "And also with respect to Alpha so you can merge up to 95% of the vertices, right?"
        ],
        [
            "And scalability is pretty important, so this is a 1.5 million node graph you can.",
            "This is log scale right?",
            "So this is time and this is the number of seeds.",
            "This is, Kay, the budget of the problem.",
            "You can see that running on the original graphics or like order of ours right?",
            "Whereas running on the smaller graph takes 8%.",
            "This includes the time for coarsening, right?",
            "So this is where we are comparing against the time total time taken by C-SPAN, not just running PMI on the small graph.",
            "So this can find good solutions in minutes instead of hours.",
            "The other."
        ],
        [
            "So that's good.",
            "That's one.",
            "Objectivity is to measure what good GC problem is for.",
            "But we also show a case study in the paper which is on diffusion characterization, which is like, can you characterize diffusion?",
            "Can it help us understand how the diffusion happens, right?",
            "So the goal is to use the graph coursing problem to understand information cascades.",
            "So what we did very quickly, as I only two minutes, we use the data set of Flixster, which is a popular meme data set where the meme is actually a movie.",
            "And there is a social network, and when movie friends rate movies, you assume that the cascade has happened.",
            "So of course, so you learn the IC model.",
            "What we did was we learned an IC model using.",
            "There are many papers which tried to do that, learn the weights of the graph and once we have learned that we try to course in it to understand what kind of cascades have happened and we course in there."
        ],
        [
            "At work using an Alpha .5 and we studied the form groups right.",
            "So one quick thing I'll just talk about a couple of observations is like.",
            "So suppose if you plot the number of movies and the number of groups these movies touch, right?",
            "So that's like saying that Harmony Cascades.",
            "Such harmony groups.",
            "The first observation is that a very large fraction of movies, probably in a very small number of groups which might be expected as most movies are junk, right?",
            "So the second observation is that the movie spread in a multi modal scale, which is like there are many scales of these spread.",
            "So movie so you can see these peaks right?",
            "So that means if a movie is popular.",
            "If there is multiple peaks of popularity an in fact you can even use this idea to get non network surrogates for super nodes right?",
            "That means you can get non network surrogates of people having similar diffusive characteristics.",
            "So the nice thing about the fixture data set is that there are other features as well like age, demographics.",
            "So you can find what kind of demographics or what kind of properties does each supernode share right?",
            "And you can figure out that these nodes have similar diffusive characteristics.",
            "So one thing which we found was correlated with age.",
            "So you can I mean so.",
            "If you want to find people with similar diffusion characteristics, you can probably use age as a good surrogate, and you can do this for each data set you have OK."
        ],
        [
            "To conclude, we propose the graph coarsening problem, which says that given large graphene reduction factor Alpha, how to find the best nodes to coarsen?",
            "And we also defined what we're coarsening, how we're doing that we gave fast algorithm course net which estimates edge scores in constant time and sub quadratic, but in practice it's almost linear.",
            "We showed two applications, particularly the paper influence maximization.",
            "Different characterization showed that even for GCP give a good algorithm."
        ],
        [
            "So the code is at my website.",
            "Thanks for the funding.",
            "Any questions?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm other than today.",
                    "label": 0
                },
                {
                    "sent": "I'll be talking about fast influence based course links for large networks this is joint work with Manish John who's sitting here, ya and BS.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We all know networks are getting huge and I mean for example the freak friendship network at least was like 87 million users and almost 8 billion photos.",
                    "label": 1
                },
                {
                    "sent": "Amazon has like 237 million accounts.",
                    "label": 0
                },
                {
                    "sent": "Facebook is growing on a tremendous rate every day and so on and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there is a clear need for faster analysis for network algorithms, and there's an ever growing list of applications which utilized network effects, right?",
                    "label": 1
                },
                {
                    "sent": "For example, viral marketing information, diffusion, Epidemiology and so on.",
                    "label": 0
                },
                {
                    "sent": "So however, scaling up traditional algorithms up to millions of nodes is hard, right?",
                    "label": 1
                },
                {
                    "sent": "I mean, that's why we have so many papers having really cool algorithms for a new techniques for these problems so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean, of course the best way to do this is having faster, simpler algorithms or perform analysis locally.",
                    "label": 1
                },
                {
                    "sent": "So what the approach we use in our paper is to zoom out of the network to obtain a smaller representation of the network which preserves some properties which you want and then run our traditional algorithms on that smaller representation.",
                    "label": 1
                },
                {
                    "sent": "So that's the hope that would be faster.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that is what we do in this paper, and we call this coursing.",
                    "label": 0
                },
                {
                    "sent": "So if you want to think about what we do, you can think of in one sentence we give a Birds Eye view of the network, preserving some structural properties.",
                    "label": 1
                },
                {
                    "sent": "So we want to see this huge hairy ball and try to give you a smaller representation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can also think of this as zooming out of the network, so if you have a big graph, you can see that this graph seems to have like major structures like ABCD, so probably you can zoom out at a certain level.",
                    "label": 1
                },
                {
                    "sent": "You might think something like this, right?",
                    "label": 0
                },
                {
                    "sent": "So this is a smaller representation of the network and the type of graphs which we motivated our work was cascade graphs.",
                    "label": 1
                },
                {
                    "sent": "Were suppose you have memes flowing on a big network like Twitter or disease propagating on a population network and we want to summarize what really happened, right?",
                    "label": 0
                },
                {
                    "sent": "We want to see structurally how the cascade happened, how the mean spread, and that's what we're trying to do here.",
                    "label": 0
                },
                {
                    "sent": "And we call this action coarsening.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what are the challenges when we won?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To solve this problem right, I mean what are the product of the research questions involved in trying to understand what we want to preserve.",
                    "label": 0
                },
                {
                    "sent": "How do we preserve it, and how do we do this fast right?",
                    "label": 1
                },
                {
                    "sent": "So the first challenge is how do you maintain diffusive characteristics while coarsening networks right?",
                    "label": 0
                },
                {
                    "sent": "So if I give you a cascade networks, what would you preserve?",
                    "label": 0
                },
                {
                    "sent": "I mean, what does it even mean to say that I want to preserve diffusive characteristics, right?",
                    "label": 1
                },
                {
                    "sent": "So this needs to be defined a little more precisely and the second challenge is how do you merge nodes to get that course networks right?",
                    "label": 0
                },
                {
                    "sent": "How do you combine nodes to get a smaller network?",
                    "label": 0
                },
                {
                    "sent": "So you need to even define the merging operation?",
                    "label": 0
                },
                {
                    "sent": "And of course, the algorithm task there is.",
                    "label": 0
                },
                {
                    "sent": "How do you find these things in a fast, scalable manner?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I mean, so I mean, you can look at the diffusion graph, right?",
                    "label": 0
                },
                {
                    "sent": "So diffusion graph is a well understood concept.",
                    "label": 0
                },
                {
                    "sent": "This is essentially like this can be blogs connected to each other.",
                    "label": 0
                },
                {
                    "sent": "Depending on who cites whom, or even blogs or pages right?",
                    "label": 0
                },
                {
                    "sent": "Which site link each other.",
                    "label": 0
                },
                {
                    "sent": "So diffusion is a graph induced by time ordered propagation of information, right?",
                    "label": 1
                },
                {
                    "sent": "So we have given this graph.",
                    "label": 0
                },
                {
                    "sent": "This is the motivation for the paper.",
                    "label": 0
                },
                {
                    "sent": "But you can use this on any graph and we want to summarize this right.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to give you a background about modeling information diffusion, or I mean any spreading process.",
                    "label": 0
                },
                {
                    "sent": "I mean the very famous model which in fact one the test of Time award in the CS Katie was the independent Cascade model right?",
                    "label": 1
                },
                {
                    "sent": "Compared to an here.",
                    "label": 0
                },
                {
                    "sent": "Effectively you have a graph and you have weights on the edges, right?",
                    "label": 0
                },
                {
                    "sent": "An weights on the edges denote the probability of spreading given the neighbors infected.",
                    "label": 0
                },
                {
                    "sent": "For example this guy is infected and the problem.",
                    "label": 0
                },
                {
                    "sent": "Suppose there's a meme or any disease spreading the probability that it will spread to its neighbors is denoted by some weight on the edge.",
                    "label": 0
                },
                {
                    "sent": "Right, and this succeeds by some probability and it's so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "So information is spreading over the network in such a way, and we want to preserve information, preserve the content of information in the graph, and we course in it.",
                    "label": 0
                },
                {
                    "sent": "So that's the problem we're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "So how would you do this?",
                    "label": 0
                },
                {
                    "sent": "Water, the diffuser characteristics you want to curse in.",
                    "label": 0
                },
                {
                    "sent": "So it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Had a paper couple of years back and I CDM, which kind of showed up.",
                    "label": 0
                },
                {
                    "sent": "I think an interesting result which says that the first eigenvalue of adjacency matrices is enough for most diffusion models and it kind of related to the epidemic threshold.",
                    "label": 1
                },
                {
                    "sent": "So what is the epidemic threshold?",
                    "label": 0
                },
                {
                    "sent": "Epidemic threshold is the is the condition under which there will be a large epidemic on a graph, so that's what we're trying to do there.",
                    "label": 0
                },
                {
                    "sent": "So that is related to the largest eigenvalue of the edges in the matrix, right?",
                    "label": 0
                },
                {
                    "sent": "So given this result, it seems intuitive that the diffuser.",
                    "label": 0
                },
                {
                    "sent": "Critics of a graph can be captured to a large extent by the 1st eigenvalue, and that's what we're trying to aim, so that's how we define our goal.",
                    "label": 0
                },
                {
                    "sent": "So to give you an intuition of what I mean by the 1st eigenvalue and what does it even mean for a diffusion, right?",
                    "label": 0
                },
                {
                    "sent": "So suppose you have these three graphs.",
                    "label": 0
                },
                {
                    "sent": "If you look at this all around 5 nodes, and these two in fact have the same average degree, right?",
                    "label": 0
                },
                {
                    "sent": "Whereas click doesn't and you can see that the chain intuitively is very safe, right?",
                    "label": 0
                },
                {
                    "sent": "You wouldn't expect the epidemic or widest spread too much, right?",
                    "label": 0
                },
                {
                    "sent": "Because everybody is connected to just.",
                    "label": 0
                },
                {
                    "sent": "Two people, so Anna large smaller chain is equal into a larger chain, right?",
                    "label": 0
                },
                {
                    "sent": "In fact, the eigenvalue for this is more or less constant as as N grows, whereas the star has an average degree as the same as the chain.",
                    "label": 0
                },
                {
                    "sent": "But clearly star is much more flamable, right?",
                    "label": 0
                },
                {
                    "sent": "Because if the center of the star is infected, it can quickly spread over to the rest of the graph, and this is shown by the as as grows the eigenvalue of star grows roughly rise order root.",
                    "label": 0
                },
                {
                    "sent": "And of course, a click is deadly, right?",
                    "label": 0
                },
                {
                    "sent": "I mean any guy can impact any other guy in the network.",
                    "label": 0
                },
                {
                    "sent": "This is also called homogeneous models, right?",
                    "label": 0
                },
                {
                    "sent": "So here the eigenvalue grows as root N sorry order and so clearly increasing Lambda is including the one billeti an.",
                    "label": 0
                },
                {
                    "sent": "You would expect graphs having same Lambda to have same diffusive characteristics given this result.",
                    "label": 0
                },
                {
                    "sent": "So OK good.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do is that we we say that, OK, let's maintain the eigenvalue as week or so.",
                    "label": 0
                },
                {
                    "sent": "We have still not defined what do we even mean by coarsening, but whatever that may mean, we want to preserve the eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "That's the goal.",
                    "label": 0
                },
                {
                    "sent": "So you take the large graph you course in it and you get a smaller network, right?",
                    "label": 0
                },
                {
                    "sent": "And make this course in network have the least change in the first eigenvalue.",
                    "label": 1
                },
                {
                    "sent": "That's what we want to do, and that's what we're aiming for.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good, so now let's go onto the second challenge, which is how do you even merge nodes right?",
                    "label": 0
                },
                {
                    "sent": "And this is actually is not that straightforward, and this needs some little intuition, so I'll just try to give you the intuition and for details you can look up the paper.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have this chain, right?",
                    "label": 0
                },
                {
                    "sent": "In fact, let's backtrack what we want to do when we want to merge is that we want to get a course in graph that approximates the original with respect to the diffusion, right?",
                    "label": 1
                },
                {
                    "sent": "With respect to the actual diffusion model.",
                    "label": 0
                },
                {
                    "sent": "So remember the weights on the edges are roughly kind of conditional probabilities of spreading the infection right.",
                    "label": 0
                },
                {
                    "sent": "Whatever model that may be.",
                    "label": 0
                },
                {
                    "sent": "So if this guy is infected, what is the probability he spreads it to his neighbors?",
                    "label": 0
                },
                {
                    "sent": "That's what these probabilities don't.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have a chain and you have these weights and you have these two nodes in which we want to merge, right?",
                    "label": 0
                },
                {
                    "sent": "So we want to merge these two nodes into another node called C. The question we're asking is that should be changed.",
                    "label": 0
                },
                {
                    "sent": "The weights of the graph.",
                    "label": 0
                },
                {
                    "sent": "So intuitively, if you don't change the weights of the graph of the eigenvalue, should degrees right?",
                    "label": 0
                },
                {
                    "sent": "Because you're decreasing the size of the graph, so then I mean it seems like the problem is not well posed, right?",
                    "label": 0
                },
                {
                    "sent": "So what we say is that we need to re wait the graph intelligently?",
                    "label": 0
                },
                {
                    "sent": "And how do we do that?",
                    "label": 0
                },
                {
                    "sent": "So here's the intuition, right?",
                    "label": 0
                },
                {
                    "sent": "So if we keep the same weight, then the probability that see infects D is still .5, right?",
                    "label": 0
                },
                {
                    "sent": "That seems excessive.",
                    "label": 0
                },
                {
                    "sent": "'cause if I choose C2 effects and choose C, you're clearly infecting physically either B or a right, not both.",
                    "label": 0
                },
                {
                    "sent": "I mean, in reality you cannot choose both of them right?",
                    "label": 0
                },
                {
                    "sent": "When you're choosing, see effectively choosing either one of them and the way we think about this is that the choosing them yet uniformly at random, because all those nodes are similar with respect to their diffusion characteristics, right?",
                    "label": 0
                },
                {
                    "sent": "So if I in fact either of those two nodes, you would expect the final footprint to be roughly the same.",
                    "label": 0
                },
                {
                    "sent": "So that's the intuition.",
                    "label": 0
                },
                {
                    "sent": "So that's why you if in fact B, the probability that he gets infected is .5, right?",
                    "label": 0
                },
                {
                    "sent": "Just one edge effect, a the probability that gets infected is .25, right?",
                    "label": 0
                },
                {
                    "sent": "So if I choose?",
                    "label": 0
                },
                {
                    "sent": "Only at random you would expect the average infection probability to be .375, right?",
                    "label": 0
                },
                {
                    "sent": "And that's why you need to re weight it.",
                    "label": 0
                },
                {
                    "sent": "So without going into too many details about the general case where you need to consider all.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So parts going from the course and node which is C to the other sets of edges going across from A to B.",
                    "label": 0
                },
                {
                    "sent": "You can write down the equations for how the average probability of infection for each set of nodes which are neighbors for NB.",
                    "label": 0
                },
                {
                    "sent": "So yeah, you can look up the paper.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the way we define merging, right?",
                    "label": 0
                },
                {
                    "sent": "That's the way we define coarsening, so we have defined what we want to maintain.",
                    "label": 0
                },
                {
                    "sent": "We have defined how are we doing the unit action.",
                    "label": 0
                },
                {
                    "sent": "Right now we need to pick out the best edges which we should choose to merge so that the goal is attained, right?",
                    "label": 0
                },
                {
                    "sent": "So the goal is to find the best nodes to merge according to the Merge definition given in the previous slide in a fast and scalable way to a large network, right so?",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's just define the graph coarsening problem abit more formally, so it's a combinatorial problem which is given a large graph, Gianna introduction Factor Alpha.",
                    "label": 0
                },
                {
                    "sent": "It just says how many nodes do we want in the course and graph, right?",
                    "label": 0
                },
                {
                    "sent": "That's a tunable parameter.",
                    "label": 0
                },
                {
                    "sent": "Find the best set of actually edges or I should say node pairs because this is directed.",
                    "label": 1
                },
                {
                    "sent": "So you might have multiple edges between I mean to and fro between our node pair, best set of node pairs to merge so that the eigenvalue change right?",
                    "label": 0
                },
                {
                    "sent": "This is the original graph and this is the course and graph should be minimized and so you can think of edge being the courses graph with the least change of the first Dragon value.",
                    "label": 1
                },
                {
                    "sent": "That's the goal.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, and I've greedy heuristic would be just test each edge test each node pair, calculate the change in value and choose the guy with the lowest change, right?",
                    "label": 1
                },
                {
                    "sent": "I mean that's doable, but it's too slow because order M squared to score all the edges if it sound directed graph.",
                    "label": 0
                },
                {
                    "sent": "And in fact if you have to, if the reduction factor is Alpha then it's NP horizon right?",
                    "label": 0
                },
                {
                    "sent": "Because you need two sets of nodes, so you basically lose time benefits of analyzing the smaller graph, right?",
                    "label": 1
                },
                {
                    "sent": "You want to make this course next step as fast as possible so that you can run your algorithms on this smaller graph.",
                    "label": 0
                },
                {
                    "sent": "So if this itself is too expensive then there's no point doing this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our proposed method, which I won't go into too much.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detail is based on the idea that yes, you can approximate the change fast enough an A bit of algebra shows that you can up to 1st order terms.",
                    "label": 1
                },
                {
                    "sent": "You can estimate the score of an edge or node pair in constant time, and then I puristic remember is a quadratic time right?",
                    "label": 1
                },
                {
                    "sent": "So this is pretty fast.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so that essentially means that given the first eigenvalue Lambda and the corresponding eigenvectors, the score of a node pair can be approximate in constant time.",
                    "label": 1
                },
                {
                    "sent": "So this this suppose you're merging A&B and you see you merge it into C and you want to estimate what's the change.",
                    "label": 0
                },
                {
                    "sent": "So if you think about like this that if I can estimate this change I can choose the node pair with the least change.",
                    "label": 0
                },
                {
                    "sent": "Simple as that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, these are details.",
                    "label": 0
                },
                {
                    "sent": "I mean, please see the paper for the exact derivation, but it's yeah, it looks a bit heavy, but it's very nice.",
                    "label": 0
                },
                {
                    "sent": "I mean in terms of algebra, so it's based on left and right eigenvectors and there is a slight trick involved in self loops there.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the complete algorithm, for course.",
                    "label": 1
                },
                {
                    "sent": "Net is this right?",
                    "label": 0
                },
                {
                    "sent": "Compute the scores for all edge pairs or all node pairs, merge nodes with the smallest score and then just keep repeating so it's a greedy approach.",
                    "label": 1
                },
                {
                    "sent": "So if I have the original network like this and then I tried assign scores for each node pair which comes to be like this which is green and red right?",
                    "label": 0
                },
                {
                    "sent": "Green means that these are good edges to merge and red means these are bad edges to merge.",
                    "label": 0
                },
                {
                    "sent": "And then you merge these edges and you get this course in graph.",
                    "label": 0
                },
                {
                    "sent": "I'm not showing the rebated.",
                    "label": 0
                },
                {
                    "sent": "Right, so just intuitively just looking at this very simple toy example, you can see that.",
                    "label": 0
                },
                {
                    "sent": "I mean it is merging the node pairs which are have similar characteristics where it's preserving the structure of how the graph looks like at least even here.",
                    "label": 0
                },
                {
                    "sent": "I mean, this node is clearly important because it's like the hub.",
                    "label": 0
                },
                {
                    "sent": "So I mean you can see that it's kind of preserving that.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But so this is sub quadratic.",
                    "label": 0
                },
                {
                    "sent": "As I said, based on number of nodes and edges and yeah.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is I mean, intuitively it looks fine.",
                    "label": 0
                },
                {
                    "sent": "So now we want to measure how?",
                    "label": 0
                },
                {
                    "sent": "How does it perform it, at least with respect to the graph coarsening problem, right?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry, so our algorithms course net, so we compare against random for example.",
                    "label": 0
                },
                {
                    "sent": "So this is Amazon and eBay LP, so this is the first eigenvalue when none of the nodes have been Corson, right?",
                    "label": 0
                },
                {
                    "sent": "And just one look at this resulting you see that even after merging 70% of the node pairs in the graph you have, we have maintained the first eigenvalue effectively at constant right?",
                    "label": 0
                },
                {
                    "sent": "I mean, there is almost no perceptible change in the first eigenvalue, so this is, this was something very nice, and because we didn't really expect this to happen right, that really is showing that most which might agree with intuition that most of the edges of the nodes in the.",
                    "label": 0
                },
                {
                    "sent": "Real graph are probably not that important in terms of the structure of the graph and this and we have many more results in the paper.",
                    "label": 1
                },
                {
                    "sent": "So the first eigenvalue gap is well up to even.",
                    "label": 1
                },
                {
                    "sent": "I mean there were some graphs where you could prune over 90% of the graph.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cool and scalability.",
                    "label": 0
                },
                {
                    "sent": "Even though theoretically it's like sub quadratic, but I mean at least on the graph which we tried, which are pretty large.",
                    "label": 0
                },
                {
                    "sent": "I mean it's almost near linear, so which is also good.",
                    "label": 0
                },
                {
                    "sent": "So that shows that you can do it fast enough and because it is based on a spectral methods, I mean if there is a faster algorithm for calculating the eigenvalue or you can parallelize it.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are very straightforward for doing that with this algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was scalability with respect to the reduction factor Alpha, right?",
                    "label": 0
                },
                {
                    "sent": "Which is so?",
                    "label": 0
                },
                {
                    "sent": "That means the more you want to course in the proportionately more you pay cost, and it is also scaleable with respect to the graph size.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, good, so this is like OK, we have defined a graph coarsening problem.",
                    "label": 0
                },
                {
                    "sent": "We have solved it efficiently and we have seen that it solves reasonably well, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "But the natural question is what is it useful for, right?",
                    "label": 0
                },
                {
                    "sent": "Can you show an objective way of evaluating where you can use this in fast makeup algorithm faster or do some other data mining tasks faster, right?",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A couple of applications in the paper there.",
                    "label": 0
                },
                {
                    "sent": "I think they're working on more.",
                    "label": 0
                },
                {
                    "sent": "One application is like influence maximization, so again, this is from the campaign paper at all paper, and I'm sure many people know it.",
                    "label": 0
                },
                {
                    "sent": "But let me give you a brief overview of it, right?",
                    "label": 0
                },
                {
                    "sent": "So it's like you have you want to convince us subset of individuals in the social network to adopt your product so that they spread the by word of mouth process and make other people adopt your whatever you would want them to adopt, right?",
                    "label": 1
                },
                {
                    "sent": "It can be more product or whatever.",
                    "label": 1
                },
                {
                    "sent": "So you want to trigger large cascade of productive options.",
                    "label": 1
                },
                {
                    "sent": "And the influence maximization problem asks that, can you help me choose these best people in a social network given awaited IC model?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So who is the most influential person, right?",
                    "label": 0
                },
                {
                    "sent": "So we said that OK, if this.",
                    "label": 0
                },
                {
                    "sent": "If we are really preserving the diffuser characteristics of the graph, then if you run the influence maximization, any algorithm on the smaller graph, the course in graph, you should get similar results, right?",
                    "label": 0
                },
                {
                    "sent": "Or at least this is close to the quality of the original graph.",
                    "label": 0
                },
                {
                    "sent": "So here's what we call.",
                    "label": 1
                },
                {
                    "sent": "So we have a we call our framework as C spin for at least the influence maximization problem.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that we course in the large social network using course net, right?",
                    "label": 1
                },
                {
                    "sent": "So you get a much smaller graph.",
                    "label": 0
                },
                {
                    "sent": "For really large alphas I mean these are alphas ranging from 70 to 80% right?",
                    "label": 1
                },
                {
                    "sent": "Then you solve the influence maximization problem on the course and graph.",
                    "label": 0
                },
                {
                    "sent": "So now I mean you can use any algorithm to solve it.",
                    "label": 0
                },
                {
                    "sent": "We use fast enough algorithm called PMII which is a pretty popular heuristic and we didn't want to use the original greedy algorithm because pretty slow.",
                    "label": 0
                },
                {
                    "sent": "So of course we will get time gains based on it, but PM is performs very well and it's very popular so we use that and we solve it on the smaller graph and then we randomly select one note to zoom out.",
                    "label": 0
                },
                {
                    "sent": "So this is important.",
                    "label": 0
                },
                {
                    "sent": "So you don't want to spend too much effort in actually trying to map the solutions from the course in graph to the original graph, right?",
                    "label": 0
                },
                {
                    "sent": "Because if you want to do that then might as well solve the problem on the original graph right?",
                    "label": 0
                },
                {
                    "sent": "And the way we do the coursing right.",
                    "label": 0
                },
                {
                    "sent": "The way we carefully perform the coarsening attributes.",
                    "label": 0
                },
                {
                    "sent": "All the nodes which have similar diffusive characteristics are in one group.",
                    "label": 0
                },
                {
                    "sent": "You can think of it like that.",
                    "label": 0
                },
                {
                    "sent": "So if you choose one supernode or one group, you can randomly allocate any one of the nodes in that group and the hope is that because the way we have done coarsening, these nodes have similar footprints.",
                    "label": 0
                },
                {
                    "sent": "So that's why this can be performed, right?",
                    "label": 1
                },
                {
                    "sent": "So you can do randomly select any node which is uniformly at random, which is very fast from each selected supernode, so this.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This shows a bit of schematics like take the Big Graph course and it solved influence maximization problem.",
                    "label": 0
                },
                {
                    "sent": "Suppose you see you can just zoom out an choose any any any guy in that group.",
                    "label": 0
                },
                {
                    "sent": "OK, we call the C Smith.",
                    "label": 0
                },
                {
                    "sent": "Let's see how it performs right?",
                    "label": 0
                },
                {
                    "sent": "So if you run PMII on the.",
                    "label": 0
                },
                {
                    "sent": "If you run PMI on the original graph and you run PMI and then you see spin the our framework and this shows the ratio of footprints right?",
                    "label": 0
                },
                {
                    "sent": "This shows the how much footprint or how much spread do you get from the original algorithm and from what we get from our course in method and you can see they are all very close to 1.",
                    "label": 0
                },
                {
                    "sent": "Right, it's versus spread ratio for different networks, and this is spread ratio versus Alpha on a particular network, so it shows that even you can score some 95% of the graph, at least in some graphs and still get maintained the spread, which was pretty nice.",
                    "label": 0
                },
                {
                    "sent": "I mean, that means that it intuitively means that the real structure for network important for this problem is probably not that complicated.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also with respect to Alpha so you can merge up to 95% of the vertices, right?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And scalability is pretty important, so this is a 1.5 million node graph you can.",
                    "label": 0
                },
                {
                    "sent": "This is log scale right?",
                    "label": 1
                },
                {
                    "sent": "So this is time and this is the number of seeds.",
                    "label": 1
                },
                {
                    "sent": "This is, Kay, the budget of the problem.",
                    "label": 0
                },
                {
                    "sent": "You can see that running on the original graphics or like order of ours right?",
                    "label": 0
                },
                {
                    "sent": "Whereas running on the smaller graph takes 8%.",
                    "label": 0
                },
                {
                    "sent": "This includes the time for coarsening, right?",
                    "label": 0
                },
                {
                    "sent": "So this is where we are comparing against the time total time taken by C-SPAN, not just running PMI on the small graph.",
                    "label": 0
                },
                {
                    "sent": "So this can find good solutions in minutes instead of hours.",
                    "label": 1
                },
                {
                    "sent": "The other.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's good.",
                    "label": 0
                },
                {
                    "sent": "That's one.",
                    "label": 0
                },
                {
                    "sent": "Objectivity is to measure what good GC problem is for.",
                    "label": 0
                },
                {
                    "sent": "But we also show a case study in the paper which is on diffusion characterization, which is like, can you characterize diffusion?",
                    "label": 0
                },
                {
                    "sent": "Can it help us understand how the diffusion happens, right?",
                    "label": 0
                },
                {
                    "sent": "So the goal is to use the graph coursing problem to understand information cascades.",
                    "label": 1
                },
                {
                    "sent": "So what we did very quickly, as I only two minutes, we use the data set of Flixster, which is a popular meme data set where the meme is actually a movie.",
                    "label": 0
                },
                {
                    "sent": "And there is a social network, and when movie friends rate movies, you assume that the cascade has happened.",
                    "label": 0
                },
                {
                    "sent": "So of course, so you learn the IC model.",
                    "label": 0
                },
                {
                    "sent": "What we did was we learned an IC model using.",
                    "label": 0
                },
                {
                    "sent": "There are many papers which tried to do that, learn the weights of the graph and once we have learned that we try to course in it to understand what kind of cascades have happened and we course in there.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At work using an Alpha .5 and we studied the form groups right.",
                    "label": 0
                },
                {
                    "sent": "So one quick thing I'll just talk about a couple of observations is like.",
                    "label": 0
                },
                {
                    "sent": "So suppose if you plot the number of movies and the number of groups these movies touch, right?",
                    "label": 0
                },
                {
                    "sent": "So that's like saying that Harmony Cascades.",
                    "label": 0
                },
                {
                    "sent": "Such harmony groups.",
                    "label": 0
                },
                {
                    "sent": "The first observation is that a very large fraction of movies, probably in a very small number of groups which might be expected as most movies are junk, right?",
                    "label": 1
                },
                {
                    "sent": "So the second observation is that the movie spread in a multi modal scale, which is like there are many scales of these spread.",
                    "label": 0
                },
                {
                    "sent": "So movie so you can see these peaks right?",
                    "label": 0
                },
                {
                    "sent": "So that means if a movie is popular.",
                    "label": 0
                },
                {
                    "sent": "If there is multiple peaks of popularity an in fact you can even use this idea to get non network surrogates for super nodes right?",
                    "label": 0
                },
                {
                    "sent": "That means you can get non network surrogates of people having similar diffusive characteristics.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing about the fixture data set is that there are other features as well like age, demographics.",
                    "label": 0
                },
                {
                    "sent": "So you can find what kind of demographics or what kind of properties does each supernode share right?",
                    "label": 0
                },
                {
                    "sent": "And you can figure out that these nodes have similar diffusive characteristics.",
                    "label": 0
                },
                {
                    "sent": "So one thing which we found was correlated with age.",
                    "label": 0
                },
                {
                    "sent": "So you can I mean so.",
                    "label": 0
                },
                {
                    "sent": "If you want to find people with similar diffusion characteristics, you can probably use age as a good surrogate, and you can do this for each data set you have OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To conclude, we propose the graph coarsening problem, which says that given large graphene reduction factor Alpha, how to find the best nodes to coarsen?",
                    "label": 0
                },
                {
                    "sent": "And we also defined what we're coarsening, how we're doing that we gave fast algorithm course net which estimates edge scores in constant time and sub quadratic, but in practice it's almost linear.",
                    "label": 0
                },
                {
                    "sent": "We showed two applications, particularly the paper influence maximization.",
                    "label": 0
                },
                {
                    "sent": "Different characterization showed that even for GCP give a good algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the code is at my website.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the funding.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                }
            ]
        }
    }
}