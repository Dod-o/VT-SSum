{
    "id": "icz5czgy3jcrqhdlsxqhlewhrc7fsc7m",
    "title": "Utilizing Deep Object Detector for Video Surveillance Indexing and Retrieval",
    "info": {
        "author": [
            "Ionel Pop, Foxstream, Vaulx-en-Velin"
        ],
        "published": "Jan. 29, 2019",
        "recorded": "January 2019",
        "category": [
            "Top->Computers->Multimedia"
        ]
    },
    "url": "http://videolectures.net/multimediamodeling2019_pop_object_detector/",
    "segmentation": [
        [
            "Hello everyone, thank you for being here.",
            "My name is John and Bob and I'm going to talk to you about an experiment we did at Fox Stream this summer like last summer.",
            "So me and my colleagues on Mr. Duran, Miss he and Mr Rubino.",
            "We started to."
        ],
        [
            "Look a little bit about new technologies and new application for our company.",
            "So we are both we all four.",
            "We are employees of the boxing company.",
            "A few words about it.",
            "It's a software company for video content analysis.",
            "Small accent with sleeping.",
            "Its main focus area are intrusion detection and flow management.",
            "So basically we try to detect someone.",
            "Trying to get into a protected area or trying this intrusion detection flow management account, number of person in the room for instance.",
            "So sorry, search Department of these companies are about 4%."
        ],
        [
            "And from time to time we try to explore some new technology in the new application.",
            "In this case, we the new technology is deep learning.",
            "For most of us here, I think the there is no longer new technology.",
            "It's something it's established it's not the case for for stream mainly because.",
            "Porter reason so.",
            "It requires specialized and it means expensive hardware.",
            "And it's hard to build it right?",
            "Even afterward, it's easy to use, but it's hard to build it right and we as a company have constraints on the results we provide to our customers.",
            "This application we try to build so it's something completely new for us, so we try to build something of around the video retrieval system and we choose this system.",
            "This sub kind of application because it's less critical than intrusion detection.",
            "So here if you ask for a person, we didn't get it.",
            "We can get it with, let's say, 5 seconds later.",
            "It's not not an issue.",
            "Nevertheless, we want to make it fast and we had some additional constraints.",
            "We have some low resolution video streams, so just to give you an idea right now we are working with something like 600 Vijay videos.",
            "So 640 by 4 hundred 80s images like.",
            "We want to be able to execute in real time.",
            "The indexation part five image per second and ideally, to be able to handle multi stream data on the same server.",
            "So just to give you an idea, at the moment we are handle about between the 3260 video stream on the same on the standard server.",
            "So we have a hard constraint on this."
        ],
        [
            "So.",
            "We had a lot of thought.",
            "We try to do a lot of things.",
            "And finally we get to something like that.",
            "We try to build on top of existing solution.",
            "We describe quickly how does it work, and afterwards I'm going to explain each each part individually.",
            "So the first part here it's a single stage of detector.",
            "In our case we use yellow detector, which gives us position and.",
            "Class of an object with struct objects from this.",
            "From its output.",
            "And for each object, we extract some kind of semi signature on object.",
            "The script or using a tiny neural network.",
            "We build it from scratch.",
            "In the same time.",
            "For each image for the whole sequence, we try to extract.",
            "Keyframes so this purpose of luck discrete keyframes are not to build a summary video, but to have a single image representation of the of the object in the scene in the video.",
            "We put all this data together at the end.",
            "Some kind of storage and then we later we can back and using only this.",
            "Hope so.",
            "I didn't notice that you didn't see my mouse using.",
            "The weather major no.",
            "So usually only this storage we can back get back the information we're looking for.",
            "And this is where the key for my important, because the result will be the key frame where the object is present, so we don't have to store the whole video as we learned this morning in industry, we don't keep data we don't need.",
            "So we are going to delete all images on information, not do not be used."
        ],
        [
            "The key frame extraction, so as I said before, what we want to have, it's a minimal number of image containing a maximum number of objects.",
            "Another constraint we have to do it in real time and real time is not only processing time but only Accessibility of images.",
            "So that means when I have this image right here.",
            "I cannot, sorry.",
            "I cannot afford to go 5 minutes before and compare with an image which was five minutes earlier at this moment.",
            "Our solution was pretty simple, simple.",
            "We use greedy algorithm comparing each two consecutive frames.",
            "And we try to detect if an image was kind of included in one of each of its neighbors.",
            "To detect if two objects are identical or not.",
            "We are what we compare their, their position and their their class."
        ],
        [
            "Now I'm going to talk about this.",
            "Tiny neural network.",
            "For each object, we get its bounding box.",
            "This bounding box is going to be fed into the neural network."
        ],
        [
            "And get the descriptor of 96 features kind of signature of this object, which will be stored for travel later.",
            "The constraints for this architecture we want it to be fast.",
            "We have low resolution input so.",
            "The whole image makes at most 6 five 600 pixels, so we have can have objects around 10 to 15 pixels wide.",
            "We want to be scale invariant, so we choose this.",
            "So.",
            "Kind of picture we make.",
            "I put.",
            "Different size reduction in order to be able to catch all the kind of variation of size.",
            "And at the same time we applied only once on a single image.",
            "So we we thought at the beginning we thought about using some kind of some kind of super resolution technique, but as we wanted to apply once so not on multiple image, we drop this this idea."
        ],
        [
            "Indexing industry but.",
            "After all this, I'm going to store some information.",
            "We're going to store semantic information for each object.",
            "We're going to start its class, so we got from the.",
            "Your classifier at this position.",
            "Last layer from the classifier, this will.",
            "We wanted to use it as a sand descriptor.",
            "So for the moment their results were not so good, so we're going to build on that on that.",
            "An object features so object described descriptor are the last layer from our tiny CNN.",
            "This right here.",
            "And on this database we can make some queries.",
            "So where as I said before, query on the scene using the scene descriptor.",
            "It worked pretty well.",
            "He doesn't impress us enough to.",
            "Communicate about on it.",
            "We have query on the object.",
            "Using the object descriptor and giving the keyframe when the object is present.",
            "And we try also using this text text description.",
            "You use integrated word net in our solution.",
            "So basically we couple this with the class of an object along just to extract query for such such.",
            "Object like red car or blue blue person or small green alien."
        ],
        [
            "What result do you obtain?",
            "For this we use two data sets, so it's a public data sets from up on University of Technology and the second one from our ability especially for this situation.",
            "At our headquarters in France.",
            "The resolutions are about this base.",
            "I would desire 320 by 240 images.",
            "We had we have.",
            "Made several experiments.",
            "So the first one was to confirm that the scene descriptor it's it's relevant to our situation."
        ],
        [
            "For that which compares simply the descriptor of two consecutive frames.",
            "In order to be able to detect to detect on.",
            "Object operation on order on or missing objects.",
            "And we are not sensitive to.",
            "Small variation of light or operational of object.",
            "We are not interested in two.",
            "About later, what kind of object you are looking for?",
            "We compare this against the last layer from exception virtual V3 training on the image net.",
            "We see that we have similar results.",
            "We prefer the final easy to use yellow version.",
            "Because the difference.",
            "Here are objects or not.",
            "It is the interested into which appear in the trailer frame, and here are the objects were interested into Japan to the frame.",
            "And so for the.",
            "We found that the difference is more visible."
        ],
        [
            "About the keyframe selection, we made use a ground ground truth.",
            "For manual, we built a ground truth of one hour and a half with.",
            "Video containing about 100 events.",
            "That means 100 objects.",
            "And we manually.",
            "Compare with the selected keyframes which give us about.",
            "Almost 90% of the keyframes.",
            "Or the same as a manual selected ones.",
            "And in the end we have only three missing objects, so this makes up 1.5% of.",
            "For almost 200 objects."
        ],
        [
            "So onto object detector.",
            "We compare against the Fisher vector share Vector and Resnet 50 Fisher Vector because we want to compare against non not deep learning approach and it seems the most appropriate for task.",
            "And there is not a 50 because it was some.",
            "Seems to have obtained good results for object classification.",
            "We were interested in five classes so person, track, bicycle, motorbike and other classes.",
            "We end XD 7 hours of video.",
            "From both data set.",
            "And we obtain this results.",
            "So precision it means only we compute on the classification results or in the class is right or it's wrong.",
            "And.",
            "Really, Vance means it's a more subjective subject.",
            "Personal interpretation.",
            "A meaning.",
            "So object it's identical with it has the same meaning as the request.",
            "There is a guy that did not seem very good, especially with respect with other results we see here.",
            "I just want to remind you that we're talking about very small images, so it's a part of a explanation at the 2nd one.",
            "Second part.",
            "Is that?",
            "The quality image quality is not excellent so we are very low resolution here.",
            "The assert reason is explained just afterward that.",
            "So we are here.",
            "We are interested in their relevance parameters.",
            "We unfortunately we didn't have enough of bicycle and motorbike examples, so just this class is put diminish the overall results."
        ],
        [
            "Some images from the data sets.",
            "So on the left there is a queried image on the right, the result.",
            "The image on the right there was not is not present in the data sets for, for instance, for the DSL.",
            "Track we Googled the actual track, we get the image, put it in the input.",
            "And we get this this results."
        ],
        [
            "So I conclude with the thing that was a fun, have a lot of fun building this prototype for indexing video data.",
            "We had a lot of problems to.",
            "Solve didn't solve.",
            "We don't sort out all.",
            "The next step is to re watch how can we integrate the send the scene and more deeply the our query language.",
            "And ideally to be the product, but it's not for.",
            "Not soon.",
            "What we do like to to do?",
            "To test on, do some more tests on different scenarios, different scene and different classes.",
            "Expand Our classes.",
            "Evaluate some other architecture of our tiny CNN.",
            "And finally.",
            "Try to optimize the storage of the index index data so we note for seven hour video.",
            "This was not us.",
            "Problem.",
            "We imagine that the one we have.",
            "Continuous video stream.",
            "We have to search from for some better solution.",
            "Thank you.",
            "Yep."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, thank you for being here.",
                    "label": 0
                },
                {
                    "sent": "My name is John and Bob and I'm going to talk to you about an experiment we did at Fox Stream this summer like last summer.",
                    "label": 0
                },
                {
                    "sent": "So me and my colleagues on Mr. Duran, Miss he and Mr Rubino.",
                    "label": 0
                },
                {
                    "sent": "We started to.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look a little bit about new technologies and new application for our company.",
                    "label": 0
                },
                {
                    "sent": "So we are both we all four.",
                    "label": 0
                },
                {
                    "sent": "We are employees of the boxing company.",
                    "label": 0
                },
                {
                    "sent": "A few words about it.",
                    "label": 0
                },
                {
                    "sent": "It's a software company for video content analysis.",
                    "label": 1
                },
                {
                    "sent": "Small accent with sleeping.",
                    "label": 1
                },
                {
                    "sent": "Its main focus area are intrusion detection and flow management.",
                    "label": 0
                },
                {
                    "sent": "So basically we try to detect someone.",
                    "label": 0
                },
                {
                    "sent": "Trying to get into a protected area or trying this intrusion detection flow management account, number of person in the room for instance.",
                    "label": 0
                },
                {
                    "sent": "So sorry, search Department of these companies are about 4%.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And from time to time we try to explore some new technology in the new application.",
                    "label": 0
                },
                {
                    "sent": "In this case, we the new technology is deep learning.",
                    "label": 1
                },
                {
                    "sent": "For most of us here, I think the there is no longer new technology.",
                    "label": 0
                },
                {
                    "sent": "It's something it's established it's not the case for for stream mainly because.",
                    "label": 0
                },
                {
                    "sent": "Porter reason so.",
                    "label": 0
                },
                {
                    "sent": "It requires specialized and it means expensive hardware.",
                    "label": 0
                },
                {
                    "sent": "And it's hard to build it right?",
                    "label": 0
                },
                {
                    "sent": "Even afterward, it's easy to use, but it's hard to build it right and we as a company have constraints on the results we provide to our customers.",
                    "label": 1
                },
                {
                    "sent": "This application we try to build so it's something completely new for us, so we try to build something of around the video retrieval system and we choose this system.",
                    "label": 0
                },
                {
                    "sent": "This sub kind of application because it's less critical than intrusion detection.",
                    "label": 0
                },
                {
                    "sent": "So here if you ask for a person, we didn't get it.",
                    "label": 0
                },
                {
                    "sent": "We can get it with, let's say, 5 seconds later.",
                    "label": 0
                },
                {
                    "sent": "It's not not an issue.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, we want to make it fast and we had some additional constraints.",
                    "label": 1
                },
                {
                    "sent": "We have some low resolution video streams, so just to give you an idea right now we are working with something like 600 Vijay videos.",
                    "label": 1
                },
                {
                    "sent": "So 640 by 4 hundred 80s images like.",
                    "label": 0
                },
                {
                    "sent": "We want to be able to execute in real time.",
                    "label": 0
                },
                {
                    "sent": "The indexation part five image per second and ideally, to be able to handle multi stream data on the same server.",
                    "label": 0
                },
                {
                    "sent": "So just to give you an idea, at the moment we are handle about between the 3260 video stream on the same on the standard server.",
                    "label": 0
                },
                {
                    "sent": "So we have a hard constraint on this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of thought.",
                    "label": 0
                },
                {
                    "sent": "We try to do a lot of things.",
                    "label": 0
                },
                {
                    "sent": "And finally we get to something like that.",
                    "label": 0
                },
                {
                    "sent": "We try to build on top of existing solution.",
                    "label": 0
                },
                {
                    "sent": "We describe quickly how does it work, and afterwards I'm going to explain each each part individually.",
                    "label": 0
                },
                {
                    "sent": "So the first part here it's a single stage of detector.",
                    "label": 0
                },
                {
                    "sent": "In our case we use yellow detector, which gives us position and.",
                    "label": 0
                },
                {
                    "sent": "Class of an object with struct objects from this.",
                    "label": 0
                },
                {
                    "sent": "From its output.",
                    "label": 0
                },
                {
                    "sent": "And for each object, we extract some kind of semi signature on object.",
                    "label": 0
                },
                {
                    "sent": "The script or using a tiny neural network.",
                    "label": 0
                },
                {
                    "sent": "We build it from scratch.",
                    "label": 0
                },
                {
                    "sent": "In the same time.",
                    "label": 0
                },
                {
                    "sent": "For each image for the whole sequence, we try to extract.",
                    "label": 0
                },
                {
                    "sent": "Keyframes so this purpose of luck discrete keyframes are not to build a summary video, but to have a single image representation of the of the object in the scene in the video.",
                    "label": 1
                },
                {
                    "sent": "We put all this data together at the end.",
                    "label": 0
                },
                {
                    "sent": "Some kind of storage and then we later we can back and using only this.",
                    "label": 0
                },
                {
                    "sent": "Hope so.",
                    "label": 0
                },
                {
                    "sent": "I didn't notice that you didn't see my mouse using.",
                    "label": 0
                },
                {
                    "sent": "The weather major no.",
                    "label": 0
                },
                {
                    "sent": "So usually only this storage we can back get back the information we're looking for.",
                    "label": 0
                },
                {
                    "sent": "And this is where the key for my important, because the result will be the key frame where the object is present, so we don't have to store the whole video as we learned this morning in industry, we don't keep data we don't need.",
                    "label": 0
                },
                {
                    "sent": "So we are going to delete all images on information, not do not be used.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The key frame extraction, so as I said before, what we want to have, it's a minimal number of image containing a maximum number of objects.",
                    "label": 0
                },
                {
                    "sent": "Another constraint we have to do it in real time and real time is not only processing time but only Accessibility of images.",
                    "label": 0
                },
                {
                    "sent": "So that means when I have this image right here.",
                    "label": 0
                },
                {
                    "sent": "I cannot, sorry.",
                    "label": 0
                },
                {
                    "sent": "I cannot afford to go 5 minutes before and compare with an image which was five minutes earlier at this moment.",
                    "label": 0
                },
                {
                    "sent": "Our solution was pretty simple, simple.",
                    "label": 0
                },
                {
                    "sent": "We use greedy algorithm comparing each two consecutive frames.",
                    "label": 0
                },
                {
                    "sent": "And we try to detect if an image was kind of included in one of each of its neighbors.",
                    "label": 0
                },
                {
                    "sent": "To detect if two objects are identical or not.",
                    "label": 0
                },
                {
                    "sent": "We are what we compare their, their position and their their class.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to talk about this.",
                    "label": 0
                },
                {
                    "sent": "Tiny neural network.",
                    "label": 0
                },
                {
                    "sent": "For each object, we get its bounding box.",
                    "label": 0
                },
                {
                    "sent": "This bounding box is going to be fed into the neural network.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And get the descriptor of 96 features kind of signature of this object, which will be stored for travel later.",
                    "label": 0
                },
                {
                    "sent": "The constraints for this architecture we want it to be fast.",
                    "label": 0
                },
                {
                    "sent": "We have low resolution input so.",
                    "label": 1
                },
                {
                    "sent": "The whole image makes at most 6 five 600 pixels, so we have can have objects around 10 to 15 pixels wide.",
                    "label": 0
                },
                {
                    "sent": "We want to be scale invariant, so we choose this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Kind of picture we make.",
                    "label": 0
                },
                {
                    "sent": "I put.",
                    "label": 0
                },
                {
                    "sent": "Different size reduction in order to be able to catch all the kind of variation of size.",
                    "label": 0
                },
                {
                    "sent": "And at the same time we applied only once on a single image.",
                    "label": 0
                },
                {
                    "sent": "So we we thought at the beginning we thought about using some kind of some kind of super resolution technique, but as we wanted to apply once so not on multiple image, we drop this this idea.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Indexing industry but.",
                    "label": 0
                },
                {
                    "sent": "After all this, I'm going to store some information.",
                    "label": 0
                },
                {
                    "sent": "We're going to store semantic information for each object.",
                    "label": 0
                },
                {
                    "sent": "We're going to start its class, so we got from the.",
                    "label": 0
                },
                {
                    "sent": "Your classifier at this position.",
                    "label": 0
                },
                {
                    "sent": "Last layer from the classifier, this will.",
                    "label": 1
                },
                {
                    "sent": "We wanted to use it as a sand descriptor.",
                    "label": 0
                },
                {
                    "sent": "So for the moment their results were not so good, so we're going to build on that on that.",
                    "label": 1
                },
                {
                    "sent": "An object features so object described descriptor are the last layer from our tiny CNN.",
                    "label": 0
                },
                {
                    "sent": "This right here.",
                    "label": 0
                },
                {
                    "sent": "And on this database we can make some queries.",
                    "label": 0
                },
                {
                    "sent": "So where as I said before, query on the scene using the scene descriptor.",
                    "label": 0
                },
                {
                    "sent": "It worked pretty well.",
                    "label": 0
                },
                {
                    "sent": "He doesn't impress us enough to.",
                    "label": 0
                },
                {
                    "sent": "Communicate about on it.",
                    "label": 0
                },
                {
                    "sent": "We have query on the object.",
                    "label": 1
                },
                {
                    "sent": "Using the object descriptor and giving the keyframe when the object is present.",
                    "label": 0
                },
                {
                    "sent": "And we try also using this text text description.",
                    "label": 0
                },
                {
                    "sent": "You use integrated word net in our solution.",
                    "label": 0
                },
                {
                    "sent": "So basically we couple this with the class of an object along just to extract query for such such.",
                    "label": 0
                },
                {
                    "sent": "Object like red car or blue blue person or small green alien.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What result do you obtain?",
                    "label": 0
                },
                {
                    "sent": "For this we use two data sets, so it's a public data sets from up on University of Technology and the second one from our ability especially for this situation.",
                    "label": 1
                },
                {
                    "sent": "At our headquarters in France.",
                    "label": 0
                },
                {
                    "sent": "The resolutions are about this base.",
                    "label": 0
                },
                {
                    "sent": "I would desire 320 by 240 images.",
                    "label": 0
                },
                {
                    "sent": "We had we have.",
                    "label": 0
                },
                {
                    "sent": "Made several experiments.",
                    "label": 0
                },
                {
                    "sent": "So the first one was to confirm that the scene descriptor it's it's relevant to our situation.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For that which compares simply the descriptor of two consecutive frames.",
                    "label": 1
                },
                {
                    "sent": "In order to be able to detect to detect on.",
                    "label": 0
                },
                {
                    "sent": "Object operation on order on or missing objects.",
                    "label": 0
                },
                {
                    "sent": "And we are not sensitive to.",
                    "label": 0
                },
                {
                    "sent": "Small variation of light or operational of object.",
                    "label": 0
                },
                {
                    "sent": "We are not interested in two.",
                    "label": 0
                },
                {
                    "sent": "About later, what kind of object you are looking for?",
                    "label": 0
                },
                {
                    "sent": "We compare this against the last layer from exception virtual V3 training on the image net.",
                    "label": 0
                },
                {
                    "sent": "We see that we have similar results.",
                    "label": 0
                },
                {
                    "sent": "We prefer the final easy to use yellow version.",
                    "label": 0
                },
                {
                    "sent": "Because the difference.",
                    "label": 0
                },
                {
                    "sent": "Here are objects or not.",
                    "label": 0
                },
                {
                    "sent": "It is the interested into which appear in the trailer frame, and here are the objects were interested into Japan to the frame.",
                    "label": 0
                },
                {
                    "sent": "And so for the.",
                    "label": 0
                },
                {
                    "sent": "We found that the difference is more visible.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About the keyframe selection, we made use a ground ground truth.",
                    "label": 0
                },
                {
                    "sent": "For manual, we built a ground truth of one hour and a half with.",
                    "label": 1
                },
                {
                    "sent": "Video containing about 100 events.",
                    "label": 0
                },
                {
                    "sent": "That means 100 objects.",
                    "label": 0
                },
                {
                    "sent": "And we manually.",
                    "label": 0
                },
                {
                    "sent": "Compare with the selected keyframes which give us about.",
                    "label": 0
                },
                {
                    "sent": "Almost 90% of the keyframes.",
                    "label": 1
                },
                {
                    "sent": "Or the same as a manual selected ones.",
                    "label": 0
                },
                {
                    "sent": "And in the end we have only three missing objects, so this makes up 1.5% of.",
                    "label": 1
                },
                {
                    "sent": "For almost 200 objects.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So onto object detector.",
                    "label": 0
                },
                {
                    "sent": "We compare against the Fisher vector share Vector and Resnet 50 Fisher Vector because we want to compare against non not deep learning approach and it seems the most appropriate for task.",
                    "label": 0
                },
                {
                    "sent": "And there is not a 50 because it was some.",
                    "label": 0
                },
                {
                    "sent": "Seems to have obtained good results for object classification.",
                    "label": 0
                },
                {
                    "sent": "We were interested in five classes so person, track, bicycle, motorbike and other classes.",
                    "label": 1
                },
                {
                    "sent": "We end XD 7 hours of video.",
                    "label": 0
                },
                {
                    "sent": "From both data set.",
                    "label": 0
                },
                {
                    "sent": "And we obtain this results.",
                    "label": 0
                },
                {
                    "sent": "So precision it means only we compute on the classification results or in the class is right or it's wrong.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Really, Vance means it's a more subjective subject.",
                    "label": 0
                },
                {
                    "sent": "Personal interpretation.",
                    "label": 0
                },
                {
                    "sent": "A meaning.",
                    "label": 0
                },
                {
                    "sent": "So object it's identical with it has the same meaning as the request.",
                    "label": 0
                },
                {
                    "sent": "There is a guy that did not seem very good, especially with respect with other results we see here.",
                    "label": 0
                },
                {
                    "sent": "I just want to remind you that we're talking about very small images, so it's a part of a explanation at the 2nd one.",
                    "label": 0
                },
                {
                    "sent": "Second part.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "The quality image quality is not excellent so we are very low resolution here.",
                    "label": 0
                },
                {
                    "sent": "The assert reason is explained just afterward that.",
                    "label": 0
                },
                {
                    "sent": "So we are here.",
                    "label": 0
                },
                {
                    "sent": "We are interested in their relevance parameters.",
                    "label": 0
                },
                {
                    "sent": "We unfortunately we didn't have enough of bicycle and motorbike examples, so just this class is put diminish the overall results.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some images from the data sets.",
                    "label": 0
                },
                {
                    "sent": "So on the left there is a queried image on the right, the result.",
                    "label": 0
                },
                {
                    "sent": "The image on the right there was not is not present in the data sets for, for instance, for the DSL.",
                    "label": 0
                },
                {
                    "sent": "Track we Googled the actual track, we get the image, put it in the input.",
                    "label": 0
                },
                {
                    "sent": "And we get this this results.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I conclude with the thing that was a fun, have a lot of fun building this prototype for indexing video data.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of problems to.",
                    "label": 0
                },
                {
                    "sent": "Solve didn't solve.",
                    "label": 0
                },
                {
                    "sent": "We don't sort out all.",
                    "label": 0
                },
                {
                    "sent": "The next step is to re watch how can we integrate the send the scene and more deeply the our query language.",
                    "label": 0
                },
                {
                    "sent": "And ideally to be the product, but it's not for.",
                    "label": 0
                },
                {
                    "sent": "Not soon.",
                    "label": 0
                },
                {
                    "sent": "What we do like to to do?",
                    "label": 0
                },
                {
                    "sent": "To test on, do some more tests on different scenarios, different scene and different classes.",
                    "label": 1
                },
                {
                    "sent": "Expand Our classes.",
                    "label": 1
                },
                {
                    "sent": "Evaluate some other architecture of our tiny CNN.",
                    "label": 0
                },
                {
                    "sent": "And finally.",
                    "label": 0
                },
                {
                    "sent": "Try to optimize the storage of the index index data so we note for seven hour video.",
                    "label": 1
                },
                {
                    "sent": "This was not us.",
                    "label": 0
                },
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "We imagine that the one we have.",
                    "label": 0
                },
                {
                    "sent": "Continuous video stream.",
                    "label": 0
                },
                {
                    "sent": "We have to search from for some better solution.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        }
    }
}