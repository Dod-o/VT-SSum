{
    "id": "32nqzqqdm5zgoqljndx7fdlkt6n3uts5",
    "title": "ProbLog and its Application to Link Mining in Biological Networks",
    "info": {
        "author": [
            "Luc De Raedt, Department of Computer Science, KU Leuven"
        ],
        "published": "Aug. 27, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Bioinformatics->Computational Systems Biology",
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/mlg07_de_raedt_paia/",
    "segmentation": [
        [
            "So it's a great pleasure to be here, thanks to the organizers for inviting me.",
            "Thanks to Cody for this very nice introduction.",
            "Today I'm going to talk about a project that we started last year.",
            "It's about probabilistic prolog and also about it application to link mining, and it's very much motivated by a large biological network mining tool that's under development at University of Helsinki, and we actually put it in.",
            "More logical framework and we're going to talk."
        ],
        [
            "A little bit about that.",
            "I do want to stress that.",
            "The logic we are using and I'm going to use is a very simple type of probabilistic logic.",
            "You probably heard of many of the techniques being developed in the area of statistical relational learning.",
            "Probabilistic IOP and others, but this is really the kind of most simple version of such logic that you can produce.",
            "And as I said, it's motivated by a real life application in biological networks and the key ideas that we want to develop useful tools for a life scientist analyzing.",
            "This kind of biological networks."
        ],
        [
            "And so we're actually going to go through three types of techniques, the first of which is a simple inference.",
            "Techniques were going to allow the life scientists to post queries to a kind of probabilistic database, because that is my favorite view of the logic.",
            "Then that's going to be the first part of the talk.",
            "And then I'm also going to talk about a new technique that's going to be presented at ecmel.",
            "It's actually a version of explanation based learning.",
            "Adapted and tailored towards probabilistic logics and that will also allow us to do some kind of reasoning by analogy.",
            "And finally I'm going to talk about compressing the large network, compressing prob lock programs into small networks that should be understandable and meaningful to the kind of life scientists or to the analysis."
        ],
        [
            "List, but before that I'm going to motivate the talk."
        ],
        [
            "And I'm going to do that by taking a first look at a real life problem, one that I'm going to meet tonight.",
            "My daughter is in Florence and she supposed to start from the hotel around 8:00 and I'm going to be at Ponte Vecchio around the 8:44 and the key question as a father for me is will she arrive there at all?",
            "Will she arrive in time or not?",
            "And the reason is that Florence is very attractive city and many of the streets.",
            "Contain loads of attractions for 15 year old kids like Musea, pubs, ice cream, bars, shops and many more and so she might well be going into one of these shops and turn out late.",
            "It's concerning as a father to me but also as a scientist cause as a scientist I would like to have something else than just certainty or uncertainty.",
            "I basically want to know something about the probability that she can."
        ],
        [
            "Right, and that's why I'm going to build a model of this kind of environment, and this would not be the machine learning and graphs workshop.",
            "Demining on learning graphs workshop.",
            "If I would not use a graph to model that, and So what I'm going to do for this real life application is basically model Florence as a large network and the locations are going to be the nodes and my daughter is now at location A which is going to be the hotel the target is to go to prompt evacu which is at the bottom and then the streets or basically the parts of the street from one corner of the street to the next is going to be an edge or a link.",
            "There's going to be labels on the streets, maybe labels of shops or monuments that are over there and then now they will also be kind of degree of belief that informs me how reliable it is for her to take that street.",
            "If there's lots of ice cream bars, it's probably going to have a low probability that if she starts on one corner, she's going to end at the other corner, and so I'm going to associate to each of these links and streets a kind of degree of belief that it is, if she traverses that.",
            "Street she will actually bring her from one corner to the next.",
            "Additionally, I'm going to assume that all streets are independent of one another, which is kind of the simplest assumption you can make from a kind of Azrael point."
        ],
        [
            "Now I'm going to try to answer some of the following questions.",
            "The first question I'm going to be interested in is actually what is the probability that she can actually make it safely at Ponte Vecchio in time and I'm going to model that as probability that there exists a path that brings her from the hotel to Ponte Vacul.",
            "This problem is actually known in the graph literature as the two terminal.",
            "Network reliability problem.",
            "It's a known instance of an NP hard problem, and I'm also going to allow for other queries to be posted later on.",
            "What's also interesting in this context is to find out what is the most likely path, what is cause if I could detect most likely pass, I could tell her, take this person done while I maximize the chances that she will be there.",
            "Finally, if I've got this most likely paths, maybe I can also try to generalize features of that path, and that's kind of the idea of explanation based learning.",
            "I'm going to look at a particular phenomenon and I'm going to try to find an explanation as to why it works.",
            "Maybe the passwords, because there are no ice cream shops, there's no monuments.",
            "It's a very boring St. Then if I get such an explanation, maybe I can reuse that explanation in future contexts, like maybe if well tomorrow I'm going to be at the Dome.",
            "Maybe I can use the explanation there and maybe I can actually transfer explanations from one domain to another and so I could actually try to.",
            "To use the explanation founds in Florence for maybe traversing Venice.",
            "Finally, there is going to be the idea of compression.",
            "Suppose I want to give her a very small map of reliable, interesting streets.",
            "Can actually construct such a map, and the idea will be that I will construct such a map using compression techniques and the input to the compression technique will be actually interesting.",
            "Starting and end points.",
            "I will actually work with passes couples of a start and end points that are interesting, like, say the ones leading to museum.",
            "Interesting, the ones leading to shops or ice cream bars are not interesting, and then the hope is that I can find a very small compressed map.",
            "She can memorize it and actually that will maximize the likelihood of traversing, correct or right."
        ],
        [
            "Streets of course.",
            "This is not the only real life problem.",
            "I'm working with the the one that actually motivated most of the research is, as I said, the biological database that 100 to Ivan and his group is developing in the context of the Bio Mine project.",
            "It's basically a large network of which you see the schema here.",
            "It's a large database and there's loads of entities like proteins, articles, false ways, genes, phenotypes.",
            "Biological process is.",
            "Issues, and there's also relationships amongst these entities, like for instance that proteins belong to pathways that proteins interact with one another.",
            "Got jeans codes for proteins and many more phenomen."
        ],
        [
            "The biological database was actually automatically extracted from public domain sources and about a year ago it contained of the order of 7 million edges and 2 million entities, and it's also the case that becausw the network was automatically constructed from public domain sources that also the links and the relationships that are in the database are kind of not 100% certain.",
            "In addition, because of the field of biology.",
            "You can never be 100% certain about such links, and so there is a particular way that whole new and this group is using.",
            "It's basically he has three factors that together determine the probability that he associate's to one of these links and it's basically taken as a product of reliability, relevance and rarity.",
            "Reliability tells you something about how reliable the origin of the information is, and some databases are more reliable than others.",
            "If you extract something with information extraction or text mining techniques, it's not going to be very reliable.",
            "There is a second factor, which is the kind of relevance factor the relevance determines how relevant a particular piece of information a particular type of link is going to be for the phenomenon that the scientist is currently studying.",
            "And finally, there is a search component which has something to do with Rarity.",
            "There are some articles that refer to well known loads of different genes, and so if the fact that this article refers to a particular gene is not going to give you a lot of information.",
            "And so the rarity is also going to influence that."
        ],
        [
            "Part two, vision.",
            "There's some nice graphical interfaces that allows you to browse and construct subgraphs from that network, and here you see one such sub graph that we will also be working with.",
            "The key problem that he knew and the work we've been doing is dealing with is like whether genes, whether particular types of jeans, are connected to particular diseases, and the example that we most often use is that of jeans and asthma.",
            "And also."
        ],
        [
            "Alzheimer's.",
            "And again, in this context, you can ask exactly the same question as about map influence, the kind of queries that are interesting to the life scientists are.",
            "What is the probability that a particular gene is going to be connected to particular disease?",
            "Also, if you know that a genus connected or related to a particular disease, can you find an explanation for that?",
            "Given an explanation, can you use that explanation to find?",
            "Other genes that might well be related to the same kind of disease and then compression is also something that is of interest.",
            "I mean, it's not just in Maps that you get too much information, but also in this large networks there is very few tools that allow you to browse in an intelligent manner and network containing 10,000,000 edges and 2 million nodes, and so there the idea is that we also would like to provide the life scientists.",
            "Analysts analyst with some tools that, given certain examples of desirable interactions or interactions of interest, given some ones that are not of interest.",
            "Again, find a small network, maybe containing like 20 edges or something that you can then interpret and use to reason and understand hopefully."
        ],
        [
            "The problem.",
            "OK, so.",
            "That is a bit to motivation.",
            "It's also contains the questions I'm going to try to answer in what follows, and what I'm now going to do is very briefly show you how we can query such probabilistic networks, and I'm going to formalize them in the content."
        ],
        [
            "List of Pro Blog which is as is as I said.",
            "Basically Prolog plus some simple probabilistic extensions.",
            "The idea is that each facts and the fact is like a tuple in a database.",
            "It's convenient to view Prob log as a kind of probabilistic database.",
            "Each factor clause is given a particular probability label that indicates the degree of belief that you have in that fact.",
            "In addition, we assume that the facts are independent of one another.",
            "And.",
            "There's no other restrictions, and no other assumptions that we are taken.",
            "We also don't claim that this prob log semantics is new IT has been rediscovered over and over again.",
            "It at least goes back to work by Russian scientist Dumpson who proposed a similar semantics.",
            "Also, Tisocco Soto, who is in the room.",
            "I guess it has proposed very nice formalization of this semantics, and there's been some work.",
            "In the database community, on a logic called B Datalog by Norbert Fuhr, who has a gun done very similar.",
            "Kind of semantics.",
            "What is however knew is the inference procedure that we are going to use to perform inference on large databases on large net."
        ],
        [
            "So to model the kind of problem we're dealing with, we're actually going to allow first of all to use arbitrary prologue to define predicates or arbitrary view predicates or relationships in a database, and then given that we're working with a network, we're going to represent the edges like Edge A.",
            "We're going to represent that by a particular tuple, like there is an arc from a.",
            "To be and we're going to label that with a particular probability value."
        ],
        [
            "A public program.",
            "Then actually defines a distribution over possible logic programs, and then the way that it does this.",
            "So here you've got like the closest together, or the facts together with their probability labels and such a problem program actually defines a probability distribution over programs, logic programs, and these are going to be subsets of the logical parts of that theory.",
            "In the case of the network, it's going to contain a sub graph.",
            "Or subnetwork of that network.",
            "And basically the probability of sampling a particular logic program is the product of those clauses or facts or edges belonging to that program, multiplied by 1 minus probability value of those facts not belonging to that program, right?",
            "So that's a very simple definition.",
            "And given that definition, we then going to look at the probability.",
            "Of the goal, the probability that a goal succeeds in this probabilistic database and that is simply taken.",
            "The probability that this particular query succeeds in this problem program is basically taken as the weighted sum over this probabilities of sampling a given program times, well, one or zero.",
            "Either the query follows from the logic program or it doesn't, and if it follows well, then it's going to give you the success probability of that query.",
            "So in a sense this probability.",
            "Gives you the expected probability that it succeeds in a randomly sampled program according to the distribution that is listed."
        ],
        [
            "Dare.",
            "OK, we can now look at computing this success probabilities and.",
            "Here we are going to use the example that we are interested in finding a path from node A to node C and what you would do if you would run Prolog on this kind of predicate.",
            "You would actually build an SLD tree or a proof tree.",
            "And here you see the proof tree without the logic.",
            "It basically tells you the kind of passes that exists that bring you from.",
            "A to C you can see here from I can actually take this link and then that link and then I actually have success.",
            "I can actually also go from a I can go that way that way and that way.",
            "And that's actually what's listed there.",
            "And so this is going to give you using standard Prolog execution.",
            "It's going to give you or enumerate you all possible proofs of that particular predicate.",
            "What we then do is we know that one particular.",
            "Our proof for one particular pulse is going to succeed, provided that those two links.",
            "I mean this pulse, is going to succeed, provided that this link is present and that link is present right here.",
            "We've got 4 links, and so that's also going to give you a particular expression.",
            "And if you accept that point of view, then the probability that this fact succeeds in a randomly sampled program.",
            "Is actually equal to the probability that this expression succeeds?",
            "Where here you've got a Boolean expression, you have to interpret this as a Boolean expression, either a.",
            "Either facts A&B holds or facts Ed, Ansi, hold or answer on basically.",
            "Again, this is kind of the simpler version."
        ],
        [
            "If you do it in real Prolog, you would get something like that, but again, from successful passes in your proof tree, you can read off the kind of Boolean formula that you then want to compute."
        ],
        [
            "The probability of now the problem of computing the probability of a Boolean variable where each of the Boolean variables are independent from one another is, I mean this sum of products is an NP hard problem.",
            "It's known as the disjoint sum problem and it's actually received quite some attention in the literature on computer architecture and network reliability.",
            "And the reason why it is a hard problem is basically that you can just.",
            "You cannot just take the products of the probabilities of edge A&B, then add that to the product of.",
            "ED&C, and so.",
            "The reason that if you would do that, you would actually not end up with a probability value you would exceed."
        ],
        [
            "One in this particular case, you can also see it in this kind of little schema.",
            "Here you've got a B or AC.",
            "So what you basically want this you want to compute the probability of this kind of region here, and if you would do it naively and just take a B plus AC, you would actually have taken the probability mass of abmc twice, and so the whole challenge in solving this.",
            "Disjoint sum problem is actually in rewriting the Boolean formula in such a way that none of the expressions is overlapping and that you can actually take the product of these expressions and then sum them up."
        ],
        [
            "The naive technique for solving this is the inclusion exclusion principle, and that's also the approach that some people like Norbert fur have tried out.",
            "They've tried it out in their PD problem, PD program called High Spirits, and it's actually infeasible.",
            "They report that as soon as you've got like 10 or more conjunct, then it's not going to work.",
            "And of course in the context of network mining, if you take like a.",
            "Miles between two arbitrary nodes, all possible passes.",
            "There's going to be way more than 10 in, typically even for very small graphs you rapidly end up with hundred thousands of possible passes, not to say millions of possible passes, and so that's not going to work.",
            "There's also some results in network reliability that we've come across, and we've tried to apply and, but these results you can actually go to up to about 100 conjunction.",
            "So that's also not sufficient for tackling this kind of application, and so the thing that does seem to work pretty well is to use beads to represent the Boolean expression, and from the BDD, the binary decision diagram that I will shortly mention.",
            "You can then rapidly find the probability, but even that is not sufficient for coping with larger networks containing a couple of thousands of edges.",
            "Couple of hundreds of nodes, and so we also introduce two approximation algorithms for."
        ],
        [
            "Coping with that, but maybe first I can very briefly introduced as PZ PZ are actually very familiar to most computer scientists, especially those working in computer architecture and verification.",
            "It's one of the areas that receive the most attention in the field of computer science as a whole.",
            "The paper by Bryant, who actually introduced this particular version of DZS amongst most cited ones.",
            "In computer science as a whole for our purposes, it's kind of convenient to view this as a kind of BDD as a kind of a variant of a binary decision tree.",
            "It actually has two types of restrictions.",
            "The first restriction is that there is a fixed variable ordering, and that means that every valuable in the graph or tree or the diagram is only listed at one particular level.",
            "So you see here, there was first a.",
            "Then the two the two sub nodes of a both mentioned B and then here they both mentioned F and so on.",
            "And then finally it's also optimized in the sense that if well in a binary decision diagram, if you've got two nodes at the same level that have identical subtrees, you actually going to remove that level and actually compress to diagram.",
            "There exists ask for satisfiability testing.",
            "There exists very good and elegant and optimized public domain software where you can actually input BDD where you can input a Boolean formula and you can retrieve the kind of BDD and there exist loads of versions of that.",
            "Given the BDD, it's easy."
        ],
        [
            "Easy to compute the probability of the corresponding Boolean formula.",
            "So the thing that we will do is we will first derive from the proof.",
            "Trees will derive this Boolean formula.",
            "Then we put that Boolean formula into this BDD package we retrieved and then we can compute using this simple algorithm that I won't go into detail.",
            "You can actually very easily compute the probability of the original.",
            "A query.",
            "And that works pretty well.",
            "You can go to up to 100,000 of kanjeng."
        ],
        [
            "But if you want to do more than you need approximation techniques in the work on Pro blog, we actually use two different types of approximation methods.",
            "One is a simple Monte Carlo method and the other is bounded inference.",
            "Maybe I can first talk about the Monte Carlo method.",
            "Basically what you do there."
        ],
        [
            "Is you sample Subprograms repeatedly, you search for approval of your query in this sub program and then you actually look at the fraction of sample subprograms in which it succeeds, and you take that as the kind of approximation of the probability we have actually refined that methods a little bit in the sense that we also compute a kind of confidence intervals around the estimate.",
            "And you would typically hold the process if you're like 95% certain that it falls into a particular interval.",
            "We've also optimized it a little bit in the sense that many of the programs that you sample might be similar to one another, and so it does make sense to store successful proofs in a kind of prefix tree to avoid."
        ],
        [
            "Recomputation, there's also another approach that we pursue, and that's a technique based on what we call bounded inference.",
            "It's a technique, due to, or going back to at least David Poole in the early 90s.",
            "What we dare do is, rather than building all proofs for a particular query, we actually cut off the proof other particular level and use that in order to derive two Boolean.",
            "Formulas, one that will give us a lower bound, another one that will give us an upper bound, and then you can actually show that the probability of the query given the temple here is like all proofs."
        ],
        [
            "Of the original query, now you can cut off the proof at any level that you desire, and suppose we cut it off.",
            "Nearest corner Booth dot level or we can actually see that we know that this was a successful truth.",
            "So AB is an already found proof.",
            "We also know that ADC isn't already found.",
            "Proof EFB isn't already found proof, and so we know that the probability of the original query has to be larger than.",
            "Well, the disjunction of all the successful proofs that.",
            "That you've already found killed that level, but you also know is that the only proof that could still succeed by further expanding that proof tree is the one here.",
            "I mean, here we say we cut off potentially successful proof, and so we can actually use a FD and add that to get the kind of upper bound for.",
            "For this probability and so we combine these two here."
        ],
        [
            "Dan.",
            "We combine that ID with the idea of iterative deepening.",
            "So if you want to get certain guarantees, say that the probability is approximated to like 5%.",
            "What you do is you start out a particular level, you compute the lower and the upper bound.",
            "You look whether the difference between upper and lower is less than 5%.",
            "If it is, you stop and output probability.",
            "Otherwise you go to the next level.",
            "So you do some kind of iterative deepening while computing to be DDS."
        ],
        [
            "And the the expressions that you have here again, I didn't show it for Prolog, but the thing I showed for Prolog directly Maps, but I showed for the passes and the networks directly Maps to Prolog where you can do exactly the same using a very sick."
        ],
        [
            "People are interpreter using this versions of inference mechanisms.",
            "We looked at a pretty large graph that we extracted from this enormous network we looked at about 5000 nodes, about 11,000 edges, and the graph was constructed in a particular way by kind of breadth.",
            "First search around for random Alzheimer genes.",
            "And then the kind of queries we're interested in is wedded every exists a connection between two of the jeans and we're working with 10 sequences of subgraphs in our subgraphs of this large biological one.",
            "They are sizes of 204 hundred and some number of edges obtained by randomly sampling the edges from this one, and also all of these subgraphs contained the four random.",
            "Alzheimer genes.",
            "We do approximate inference with Delta equal to 1% and."
        ],
        [
            "Then the typical kind of behavior that you get is if you search till level one or say if you search the level one.",
            "Of course the width of the lower and the interval given by the lower and the upper bound is going to be like one and then it's going to slowly decrease the deeper and deeper you search.",
            "And this is like a typical behavior that you get here.",
            "This is for graphs with 14 edges each, then graphs where we took the average.",
            "And you see that typically after like at level 6 or 7, you already get at very reasonable bounds containing like 5 percent, 5% accuracy or 10% accuracy.",
            "The timings it took for this size of graphs is of the order of 15 seconds to 4 minutes."
        ],
        [
            "To run a query we also did while scalability experiments and what you can see there is that you can actually go up to graphs containing on the order of five thousand 4505 thousand, number of edges, and the runtimes on these are of the order of few seconds to up to four hours on a reasonable workstation for some of the larger graphs.",
            "What you also see is that the limiting factor.",
            "Is a little bit the size of the BDS.",
            "I mean what is important when working with BDS is that they fit into main memory and for some Boolean expressions they can actually become way too large and then you got a problem.",
            "Here is the maximum size for two example graph series.",
            "If you don't use the approximations than you typically go very rapidly that the number of proofs is so high.",
            "That the size of the BDD really explodes.",
            "But if you look at the lower bounds or the upper bounds than you typically get acceptable B."
        ],
        [
            "Savior in recent work.",
            "We also compared the approximation method based on the bounded inference with the Monte Carlo approach, and one result is what you see here for a particular sequence of of graphs.",
            "What you dare see is here, as the number of edges increases.",
            "Of course you need more time to answer queries, but the typical kind of behavior that you get.",
            "Is that using the BDS?",
            "You get better and faster results if the graphs and the problems are reasonably small.",
            "If the graphs become very large than the Monte Carlo methods is going to take over and typically the cutting edge is where the beads don't longer fit into main memory and actually requires so much time to build that it explodes.",
            "You can also compare and that's what you see on the left hand side.",
            "You can compare the kind of results found by the Monte Carlo method.",
            "That's with 95% confidence interval that's marked in red, and then the two bounds are lower and upper bound using the beads and again there you see that the MC method.",
            "Pretty good, gives pretty good approximations with regard to the true probability values lying into lower and upper bounds given by the BDD.",
            "So the confidence intervals that you get are quite."
        ],
        [
            "Reasonable.",
            "OK, so that concludes the first part of the talk.",
            "That's about the approximate inference.",
            "What you can see is that we've got a simple probabilistic logic.",
            "You can build good and efficient approximation algorithms for answering queries.",
            "With that it scales reasonably well at the level that you can really use it.",
            "One thing that we are currently working at looking into is not just looking at kind of simple.",
            "False queries because for simple pass queries you would not need the full power of a database or the full power of Prolog.",
            "But we do want and do intent to encode a lot of additional background knowledge like ontologies into the system and use that to pose much more complex queries.",
            "And that's an item for future research.",
            "The next topic that I want to talk about is.",
            "If that.",
            "Works here.",
            "OK. Papa"
        ],
        [
            "Is a probabilistic explanation based learning?"
        ],
        [
            "And people in machine learning might recall that explanation based learning was a very hot topic in the 80s.",
            "It was largely concerned with speed up learning, and it was also very much knowledge based.",
            "There was also a role for something like finding abductive explanations of certain phenomena in that work at the time.",
            "As far as we know, there was not really a lot of results concerning probabilistic logics or probabilistic.",
            "Versions of explanation based learning and that has actually motivated us to try to adapt the idea of explanation based learning to probabilistic logics.",
            "And of course big cause prob log is so simple we actually apply it to prob log.",
            "In the first case, but we're sure that it can very easily be adapted towards some of the more powerful logics like PRISM or ICL or SLP's.",
            "The idea will be.",
            "That we're going not to focus on speed up learning, but we're going to focus on finding explanations for certain phenomena, and we're going to use this explanations to reason by analogy to reason by cases."
        ],
        [
            "So to say, before going through the details, let me briefly remind you of how EBL worked in IBL.",
            "You basically started from an example that fallout from your theory you would build a proof tree.",
            "For that example you would generalize the proof tree.",
            "Essentially you would do so by deleting certain parts of your proof tree.",
            "Those for so called operational predicates and then you would turn you would collect the leaves of the resulting proof tree.",
            "And turn that into a rule.",
            "Add a rule to your database and use it to reason."
        ],
        [
            "This is like the most famous Ebla example ever.",
            "It has appeared in at least 50 papers on EBL.",
            "I took it this version from a paper by Mooney Manzella.",
            "Basically it's about the Cup problem."
        ],
        [
            "In the cut problem, you're given a database like this.",
            "A Cup is a concept, it's something that's stable liftable an open vessel and then you've got descriptions of training examples.",
            "You've got definition of what is stable, liftable, and so on, and using that."
        ],
        [
            "You can then actually compute approve tree.",
            "Why something is a Cup and if you do that for a particular example for a particular Cup, you'll end up with a large proof tree, and this is already the generalized proof treats generalized in the sense that it has valuable eisd the things that occur in there we talk about not a particular Cup, but about the variable Cup called X.",
            "And you also see that certain parts are actually deleted.",
            "From that proof tree, these are the parts at so called operational predicates where you don't.",
            "You're not interested in the details of proving YB is a part of X&YBL.",
            "The Leafs taken together then constitutes the explanation and are then used to build a new new definition and you rule for Cup that is then added to the database, and it's hoped that using this rule will.",
            "Actually, speed up the inference for future cups.",
            "It's showing that this does not always work.",
            "You have to exercise that with."
        ],
        [
            "Lot of cautious.",
            "That was the disappointment I think in explanation based learning that you have to be very careful about when and how to apply it.",
            "What I'm now going to do is I'm actually going to try to map that context from BBL to this probabilistic logics.",
            "And if you look at the kind of problem we are facing with where you have actually 100 thousands of possible proofs for particular queries, than the first thing is that you have to identify one of them, one amongst generalize and the best candidate for doing that is of course that that is the most likely candidate.",
            "So in this.",
            "Kind of small toy example, we had four possible proofs and so the most likely proof, or the most likely most likely proof for paths would be that of which the probability of these four is actually the highest."
        ],
        [
            "In contrast to finding the kind of probability that there exists proof, which is an NP hard problem with this Boolean formula, finding the most likely proof is a lot easier.",
            "Ascentia Lee, what you do is you do some kind of best first search.",
            "You obtain a simple conjunction conjunctive expression.",
            "You're going to be able to make the proof provided that one conjunction of fact is true, and from that you can simply compute the probability.",
            "By multiplying the probabilities of the individual facts so it's only a product you don't have to cope with the disjoint sub problem, and it's a lot easier and much faster to compute.",
            "So once we've got the most likely proof we can then try to."
        ],
        [
            "Analyze that and that is done in very much the same fashion as you do it for the Cup.",
            "Example.",
            "I mean, once you've got the most likely proof, it's gonna look like this.",
            "It's going to be extended, and then you can basically apply the ID of cutting off at operational predicates, and you're going to get a generalized proof tree like that."
        ],
        [
            "And that is the way that Pebble probabilistic explanation based learning works.",
            "You compute the most likely generalized proof tree of the example.",
            "This is the probability of the most likely proof tree, and then that will fall together in two components.",
            "First, you're going to have to generalize proof, and you can take the probability of that, and then you're going to have the factor that is concerned with proving the operational predicates.",
            "So the lower deleted parts of the generalized proof tree, but other than that there is nothing special about computing of probabilistic generalized proof tree for."
        ],
        [
            "Context of Pablo.",
            "This is again the version with.",
            "So the resolution what you then we'll end up with in the case of our.",
            "Biological networks is expressions of this particular type.",
            "Here the kind of original queries where pulse queries from again a particular gene to a particular phenotype, like Alzheimer and then you see that you got like this kind of explanations.",
            "Now there's no need to look at the logic, you can directly map this kind of explanations into a kind of graphical format, which will basically say there are certain.",
            "Types of links are to be followed and there's a certain type of path to be matched given."
        ],
        [
            "This type of pass you can then use that explanation to find similar passes, and there's two ways of doing that.",
            "You either again look at the graphical representation you retrieve you, use it to retrieve further examples, or you use at the logical one you assert this in your database, and then you run E pass and you'll get extra examples for E Pass.",
            "If you get extra it."
        ],
        [
            "Samples for the pass you can actually.",
            "You can actually.",
            "Also, um.",
            "So.",
            "So you can.",
            "Also you get this extra further examples and if you get further examples you can also compute their probabilities.",
            "The probabilities of these examples can be used to rank them according to likelihoods, and that is what we're going to do to reason by similarity to reason.",
            "By similarity, you start from a given positive example.",
            "You find its explanation.",
            "You then use that explanation to retrieve all further examples that matched his explanation and you can rank them.",
            "Or you compute compute the probabilities of these further instances and then you can say, well, this say you start from a gene related to a disease given the template that you then have, you can again use that to identify maybe further gene gene disease pairs.",
            "And you can compute the likelihood you can predict them that.",
            "The top scoring ones are with high likelihood.",
            "Also gonna be positive inst."
        ],
        [
            "This is, um.",
            "Right, and that is the.",
            "That is the first task that we do with Pebble.",
            "We're actually using the explanation to find other instances.",
            "By analogy, you can also you can also use Pebble too.",
            "To generalize from multiple examples, generalizing from multiple examples was also an issue in early explanation based learning in early explanation based learning the multiple instance example, the multiple example the multiple instance setting was hard to solve.",
            "Again with the probabilistic version it's kind of easy to find the most likely generalized common proof tree amongst a set of examples, and that would also give you further.",
            "For examples, you can also transfer findings from one domain to the next, and I'm going to show how to do that in some of the."
        ],
        [
            "Biological experiments, so again, what we did is we worked with this very same graph network domain from the Helsinki Group and we generated.",
            "2."
        ],
        [
            "Well, various networks of different sizes around the genes.",
            "We worked with Alzheimer with jeans around Alzheimer, and jeans around asthma, and we had four versions of networks containing Alzheimer to asthma and basically the way that these were generated.",
            "I mean, Alzheimer's four was generated by looking at the known Alzheimer's genes in on three and there is like about 140 two of them.",
            "And then starting from those those you actually look at passes of up to size 5 and you collect everything that you encounter on the way.",
            "If you do so, you end up with a network containing about 3000 nodes, about 17,000 edges.",
            "You also get is that of the 142 that you originally have.",
            "12 are no longer connected to this.",
            "The largest component there, so you delete these and there is not only Alzheimer genes, but there was also genes belonging to other phenotypes and there was like 55 of them.",
            "Is in total 6 phenotypes that you will encounter there an so that is the way that this last this Alzheimer's four network was generated.",
            "There are some smaller ones like for Alzheimer's two and one we started from 17 jeans and search the level 5 for Alzheimer's one and three.",
            "We only searched the level for basically.",
            "Similar for us."
        ],
        [
            "What we then did is it's a bit of an artificial example, and I'm sure that Pierre will admit this.",
            "We tried to actually set up an experiment to see how successful this reasoning by similarity.",
            "This reasoning by analogy walls, and in order to do that we took an artificial concept, which is the one seen here.",
            "We defined the predicate Connect which basically says it takes 2 jeans and one phenotype.",
            "And it succeeds if there is a pass from June 1 to the phenotype from June 2 to the phenotype and the 2G.",
            "Note the two genes are connected to one another, and then you can actually take all possible topples satisfying this, maybe up to reorderings, like what gene one and gene two you don't want to get them in the different orders here.",
            "And you then what we done did is we constructed positive examples.",
            "Positive examples are those where gene one and gene two are known according to the database to be connected.",
            "They know, like Alzheimer or they known asthma genes.",
            "So positive examples are those where gene one and gene gene two are like connected to Alzheimer and the phenotype is also Alzheimer's.",
            "All the other couples are negative examples and then we."
        ],
        [
            "Pursuit this ID."
        ],
        [
            "Of the similarity based issue you find."
        ],
        [
            "You find.",
            "An explanation like that from one example you apply that explanation to find other examples, and you rank the other examples according to their probability and."
        ],
        [
            "That actually."
        ],
        [
            "Seems to work."
        ],
        [
            "Works surprisingly well.",
            "The reason is given in this kind of experiment, which is listed here.",
            "I mean here is what you do is if you it's averaged over all possible positive examples and here is if you take the top ranked example and you predict that it's going to be belonging to Alzheimer, how much accuracy do you then get an in 95% of the cases?",
            "The top one is actually belonging to the right kind of disease for Alzheimer's too.",
            "It's a bit lower and Alzheimer 4 as well.",
            "If you take the top three that are ranked, you still get pretty good results.",
            "More than 2.5 out of three are going to be.",
            "Are going to be positive for five.",
            "You're even still around 4:00 and you also see that if you do it from asthma and you apply it to asthma, which is like this corner, you also get very similar results.",
            "This despite the fact that."
        ],
        [
            "In these domains, by the way that we constructed them, by the way that we constructed them, the distribution of positive and negatives is actually like 10 to 90% in most of the cases that you will find here."
        ],
        [
            "The results are very good for this and they actually show that this reasoning by similarity.",
            "There's reasoning by cases does seem to work, at least if you do it in one domain.",
            "You learn an explanation on one graph and you apply it on the same graph to find similar explanations.",
            "We also looked at the issue of transfer learning.",
            "That is, can we apply explanations found on Alzheimer?",
            "Can we apply it?",
            "To asthma and what kind of results do we get there and vice versa?",
            "Can we apply explanations found on asthma?",
            "Can we apply them to Alzheimer and that's like the ones that you find here in this kind of transfer learning setting.",
            "You see, you see that transferring things from Alzheimer to asthma works reasonably well.",
            "I mean, you get like pretty good, you get pretty good accuracies like 4.",
            "I dispose 5, taking the top five ranked you got till like 4 point.",
            "Something that are positive but what's also obvious is that in the other direction, if you look at the explanations found on asthma and you want to apply them on Alzheimer that you get very poor results."
        ],
        [
            "Now there's also reason for that.",
            "The reason is that on the ulzheimer domain we found a lot more explanations.",
            "In total we found like 26 possible explanations using.",
            "The Pebble approach, while on the asthma approach, we only found of the order.",
            "While we've only found three actually, there's also indicates that the idea of using common explanations doesn't work.",
            "A lot of the explanation actually, most of the explanations that are found in both domains are common to many of these examples, and one explanation was actually even shared by about 12 examples.",
            "And so there's also shows or indicate that this issue of learning from multiple learning explanations that are common to multiple instances would make sense and is likely to increase the."
        ],
        [
            "Percy to conclude the parts on Pebble.",
            "Let me.",
            "Say that.",
            "Puts EBL in a kind of new perspective.",
            "And you probabilistic context to the best of my knowledge this.",
            "Use of probabilistic logics in explanation based learning has not yet been done.",
            "It's not about speed up learning, but it's more like finding good explanations and using them to do useful things.",
            "One current and ongoing work is actually expanding on the idea of multiple.",
            "Of an explanation that is common to multiple examples is to expand the current work on Pebble towards local pattern mining and there we are actually looking at query mining techniques.",
            "In this probabilistic logics and we've got first approach is running and."
        ],
        [
            "Up about the compression thing, I don't think I have a lot of time, but five minutes."
        ],
        [
            "Maybe I can very briefly sketch.",
            "Is that with or without questions?",
            "Including questions OK so."
        ],
        [
            "Let me just state the idea here.",
            "I got into biological network.",
            "You might have the situation like what you have here.",
            "There is one phenotype, one disease you're interested in and say these are interesting genes that you're currently interested in.",
            "These are supposedly not to be interested.",
            "You're not interested in those because they might not be related to this kind of disease.",
            "And then the idea is that."
        ],
        [
            "Give positive and negative examples.",
            "So in this case you would give connected from green to blue and from green to blue as positive examples connected from red to blue and red to blue as negative."
        ],
        [
            "Samples and then you would try to compress this database does not work as much as possible.",
            "You can define a kind of likelihood.",
            "You basically want to maximize the product of the likelihoods for the positives times 1 minus the likelihood of the negatives."
        ],
        [
            "What you would then get us a typical kind of behavior.",
            "There would be also parameter K that tells you how much you should compress the network and K would here denote the number of edges and there is then a greedy algorithm that basically would delete links and see what the effect is on the likelihood and would repeatedly remove the least.",
            "Interesting link to least interesting edge for.",
            "The arm.",
            "For the likelihood, if you set K equals to 15, then you see that of course the connections from the bat nodes from red are disappeared.",
            "They turned into dots and if you set K = 2 Five you again see that here it does fine."
        ],
        [
            "Something are reasonable."
        ],
        [
            "Again, we did loads of experiments showing."
        ],
        [
            "Various things there also bit in an artificial setting, but still showing that the technique basically works, so to conclude."
        ],
        [
            "About prologue.",
            "And about the work I've presented, I think I've presented simple but still powerful logic, probabilistic logic.",
            "It provides a link between link mining and logic, and well, there is some future directions, but thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's a great pleasure to be here, thanks to the organizers for inviting me.",
                    "label": 0
                },
                {
                    "sent": "Thanks to Cody for this very nice introduction.",
                    "label": 0
                },
                {
                    "sent": "Today I'm going to talk about a project that we started last year.",
                    "label": 0
                },
                {
                    "sent": "It's about probabilistic prolog and also about it application to link mining, and it's very much motivated by a large biological network mining tool that's under development at University of Helsinki, and we actually put it in.",
                    "label": 1
                },
                {
                    "sent": "More logical framework and we're going to talk.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit about that.",
                    "label": 1
                },
                {
                    "sent": "I do want to stress that.",
                    "label": 0
                },
                {
                    "sent": "The logic we are using and I'm going to use is a very simple type of probabilistic logic.",
                    "label": 1
                },
                {
                    "sent": "You probably heard of many of the techniques being developed in the area of statistical relational learning.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic IOP and others, but this is really the kind of most simple version of such logic that you can produce.",
                    "label": 0
                },
                {
                    "sent": "And as I said, it's motivated by a real life application in biological networks and the key ideas that we want to develop useful tools for a life scientist analyzing.",
                    "label": 1
                },
                {
                    "sent": "This kind of biological networks.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so we're actually going to go through three types of techniques, the first of which is a simple inference.",
                    "label": 1
                },
                {
                    "sent": "Techniques were going to allow the life scientists to post queries to a kind of probabilistic database, because that is my favorite view of the logic.",
                    "label": 0
                },
                {
                    "sent": "Then that's going to be the first part of the talk.",
                    "label": 0
                },
                {
                    "sent": "And then I'm also going to talk about a new technique that's going to be presented at ecmel.",
                    "label": 0
                },
                {
                    "sent": "It's actually a version of explanation based learning.",
                    "label": 1
                },
                {
                    "sent": "Adapted and tailored towards probabilistic logics and that will also allow us to do some kind of reasoning by analogy.",
                    "label": 0
                },
                {
                    "sent": "And finally I'm going to talk about compressing the large network, compressing prob lock programs into small networks that should be understandable and meaningful to the kind of life scientists or to the analysis.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "List, but before that I'm going to motivate the talk.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm going to do that by taking a first look at a real life problem, one that I'm going to meet tonight.",
                    "label": 0
                },
                {
                    "sent": "My daughter is in Florence and she supposed to start from the hotel around 8:00 and I'm going to be at Ponte Vecchio around the 8:44 and the key question as a father for me is will she arrive there at all?",
                    "label": 0
                },
                {
                    "sent": "Will she arrive in time or not?",
                    "label": 0
                },
                {
                    "sent": "And the reason is that Florence is very attractive city and many of the streets.",
                    "label": 0
                },
                {
                    "sent": "Contain loads of attractions for 15 year old kids like Musea, pubs, ice cream, bars, shops and many more and so she might well be going into one of these shops and turn out late.",
                    "label": 0
                },
                {
                    "sent": "It's concerning as a father to me but also as a scientist cause as a scientist I would like to have something else than just certainty or uncertainty.",
                    "label": 0
                },
                {
                    "sent": "I basically want to know something about the probability that she can.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, and that's why I'm going to build a model of this kind of environment, and this would not be the machine learning and graphs workshop.",
                    "label": 0
                },
                {
                    "sent": "Demining on learning graphs workshop.",
                    "label": 0
                },
                {
                    "sent": "If I would not use a graph to model that, and So what I'm going to do for this real life application is basically model Florence as a large network and the locations are going to be the nodes and my daughter is now at location A which is going to be the hotel the target is to go to prompt evacu which is at the bottom and then the streets or basically the parts of the street from one corner of the street to the next is going to be an edge or a link.",
                    "label": 0
                },
                {
                    "sent": "There's going to be labels on the streets, maybe labels of shops or monuments that are over there and then now they will also be kind of degree of belief that informs me how reliable it is for her to take that street.",
                    "label": 1
                },
                {
                    "sent": "If there's lots of ice cream bars, it's probably going to have a low probability that if she starts on one corner, she's going to end at the other corner, and so I'm going to associate to each of these links and streets a kind of degree of belief that it is, if she traverses that.",
                    "label": 1
                },
                {
                    "sent": "Street she will actually bring her from one corner to the next.",
                    "label": 0
                },
                {
                    "sent": "Additionally, I'm going to assume that all streets are independent of one another, which is kind of the simplest assumption you can make from a kind of Azrael point.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to try to answer some of the following questions.",
                    "label": 0
                },
                {
                    "sent": "The first question I'm going to be interested in is actually what is the probability that she can actually make it safely at Ponte Vecchio in time and I'm going to model that as probability that there exists a path that brings her from the hotel to Ponte Vacul.",
                    "label": 0
                },
                {
                    "sent": "This problem is actually known in the graph literature as the two terminal.",
                    "label": 0
                },
                {
                    "sent": "Network reliability problem.",
                    "label": 0
                },
                {
                    "sent": "It's a known instance of an NP hard problem, and I'm also going to allow for other queries to be posted later on.",
                    "label": 0
                },
                {
                    "sent": "What's also interesting in this context is to find out what is the most likely path, what is cause if I could detect most likely pass, I could tell her, take this person done while I maximize the chances that she will be there.",
                    "label": 1
                },
                {
                    "sent": "Finally, if I've got this most likely paths, maybe I can also try to generalize features of that path, and that's kind of the idea of explanation based learning.",
                    "label": 0
                },
                {
                    "sent": "I'm going to look at a particular phenomenon and I'm going to try to find an explanation as to why it works.",
                    "label": 0
                },
                {
                    "sent": "Maybe the passwords, because there are no ice cream shops, there's no monuments.",
                    "label": 0
                },
                {
                    "sent": "It's a very boring St. Then if I get such an explanation, maybe I can reuse that explanation in future contexts, like maybe if well tomorrow I'm going to be at the Dome.",
                    "label": 0
                },
                {
                    "sent": "Maybe I can use the explanation there and maybe I can actually transfer explanations from one domain to another and so I could actually try to.",
                    "label": 0
                },
                {
                    "sent": "To use the explanation founds in Florence for maybe traversing Venice.",
                    "label": 0
                },
                {
                    "sent": "Finally, there is going to be the idea of compression.",
                    "label": 0
                },
                {
                    "sent": "Suppose I want to give her a very small map of reliable, interesting streets.",
                    "label": 0
                },
                {
                    "sent": "Can actually construct such a map, and the idea will be that I will construct such a map using compression techniques and the input to the compression technique will be actually interesting.",
                    "label": 0
                },
                {
                    "sent": "Starting and end points.",
                    "label": 0
                },
                {
                    "sent": "I will actually work with passes couples of a start and end points that are interesting, like, say the ones leading to museum.",
                    "label": 0
                },
                {
                    "sent": "Interesting, the ones leading to shops or ice cream bars are not interesting, and then the hope is that I can find a very small compressed map.",
                    "label": 0
                },
                {
                    "sent": "She can memorize it and actually that will maximize the likelihood of traversing, correct or right.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Streets of course.",
                    "label": 0
                },
                {
                    "sent": "This is not the only real life problem.",
                    "label": 0
                },
                {
                    "sent": "I'm working with the the one that actually motivated most of the research is, as I said, the biological database that 100 to Ivan and his group is developing in the context of the Bio Mine project.",
                    "label": 0
                },
                {
                    "sent": "It's basically a large network of which you see the schema here.",
                    "label": 0
                },
                {
                    "sent": "It's a large database and there's loads of entities like proteins, articles, false ways, genes, phenotypes.",
                    "label": 0
                },
                {
                    "sent": "Biological process is.",
                    "label": 0
                },
                {
                    "sent": "Issues, and there's also relationships amongst these entities, like for instance that proteins belong to pathways that proteins interact with one another.",
                    "label": 0
                },
                {
                    "sent": "Got jeans codes for proteins and many more phenomen.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The biological database was actually automatically extracted from public domain sources and about a year ago it contained of the order of 7 million edges and 2 million entities, and it's also the case that becausw the network was automatically constructed from public domain sources that also the links and the relationships that are in the database are kind of not 100% certain.",
                    "label": 0
                },
                {
                    "sent": "In addition, because of the field of biology.",
                    "label": 0
                },
                {
                    "sent": "You can never be 100% certain about such links, and so there is a particular way that whole new and this group is using.",
                    "label": 0
                },
                {
                    "sent": "It's basically he has three factors that together determine the probability that he associate's to one of these links and it's basically taken as a product of reliability, relevance and rarity.",
                    "label": 0
                },
                {
                    "sent": "Reliability tells you something about how reliable the origin of the information is, and some databases are more reliable than others.",
                    "label": 0
                },
                {
                    "sent": "If you extract something with information extraction or text mining techniques, it's not going to be very reliable.",
                    "label": 0
                },
                {
                    "sent": "There is a second factor, which is the kind of relevance factor the relevance determines how relevant a particular piece of information a particular type of link is going to be for the phenomenon that the scientist is currently studying.",
                    "label": 0
                },
                {
                    "sent": "And finally, there is a search component which has something to do with Rarity.",
                    "label": 0
                },
                {
                    "sent": "There are some articles that refer to well known loads of different genes, and so if the fact that this article refers to a particular gene is not going to give you a lot of information.",
                    "label": 0
                },
                {
                    "sent": "And so the rarity is also going to influence that.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Part two, vision.",
                    "label": 0
                },
                {
                    "sent": "There's some nice graphical interfaces that allows you to browse and construct subgraphs from that network, and here you see one such sub graph that we will also be working with.",
                    "label": 0
                },
                {
                    "sent": "The key problem that he knew and the work we've been doing is dealing with is like whether genes, whether particular types of jeans, are connected to particular diseases, and the example that we most often use is that of jeans and asthma.",
                    "label": 0
                },
                {
                    "sent": "And also.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alzheimer's.",
                    "label": 0
                },
                {
                    "sent": "And again, in this context, you can ask exactly the same question as about map influence, the kind of queries that are interesting to the life scientists are.",
                    "label": 0
                },
                {
                    "sent": "What is the probability that a particular gene is going to be connected to particular disease?",
                    "label": 1
                },
                {
                    "sent": "Also, if you know that a genus connected or related to a particular disease, can you find an explanation for that?",
                    "label": 1
                },
                {
                    "sent": "Given an explanation, can you use that explanation to find?",
                    "label": 0
                },
                {
                    "sent": "Other genes that might well be related to the same kind of disease and then compression is also something that is of interest.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not just in Maps that you get too much information, but also in this large networks there is very few tools that allow you to browse in an intelligent manner and network containing 10,000,000 edges and 2 million nodes, and so there the idea is that we also would like to provide the life scientists.",
                    "label": 0
                },
                {
                    "sent": "Analysts analyst with some tools that, given certain examples of desirable interactions or interactions of interest, given some ones that are not of interest.",
                    "label": 0
                },
                {
                    "sent": "Again, find a small network, maybe containing like 20 edges or something that you can then interpret and use to reason and understand hopefully.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That is a bit to motivation.",
                    "label": 0
                },
                {
                    "sent": "It's also contains the questions I'm going to try to answer in what follows, and what I'm now going to do is very briefly show you how we can query such probabilistic networks, and I'm going to formalize them in the content.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "List of Pro Blog which is as is as I said.",
                    "label": 0
                },
                {
                    "sent": "Basically Prolog plus some simple probabilistic extensions.",
                    "label": 0
                },
                {
                    "sent": "The idea is that each facts and the fact is like a tuple in a database.",
                    "label": 0
                },
                {
                    "sent": "It's convenient to view Prob log as a kind of probabilistic database.",
                    "label": 1
                },
                {
                    "sent": "Each factor clause is given a particular probability label that indicates the degree of belief that you have in that fact.",
                    "label": 1
                },
                {
                    "sent": "In addition, we assume that the facts are independent of one another.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "There's no other restrictions, and no other assumptions that we are taken.",
                    "label": 0
                },
                {
                    "sent": "We also don't claim that this prob log semantics is new IT has been rediscovered over and over again.",
                    "label": 0
                },
                {
                    "sent": "It at least goes back to work by Russian scientist Dumpson who proposed a similar semantics.",
                    "label": 0
                },
                {
                    "sent": "Also, Tisocco Soto, who is in the room.",
                    "label": 0
                },
                {
                    "sent": "I guess it has proposed very nice formalization of this semantics, and there's been some work.",
                    "label": 0
                },
                {
                    "sent": "In the database community, on a logic called B Datalog by Norbert Fuhr, who has a gun done very similar.",
                    "label": 0
                },
                {
                    "sent": "Kind of semantics.",
                    "label": 0
                },
                {
                    "sent": "What is however knew is the inference procedure that we are going to use to perform inference on large databases on large net.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to model the kind of problem we're dealing with, we're actually going to allow first of all to use arbitrary prologue to define predicates or arbitrary view predicates or relationships in a database, and then given that we're working with a network, we're going to represent the edges like Edge A.",
                    "label": 0
                },
                {
                    "sent": "We're going to represent that by a particular tuple, like there is an arc from a.",
                    "label": 0
                },
                {
                    "sent": "To be and we're going to label that with a particular probability value.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A public program.",
                    "label": 0
                },
                {
                    "sent": "Then actually defines a distribution over possible logic programs, and then the way that it does this.",
                    "label": 0
                },
                {
                    "sent": "So here you've got like the closest together, or the facts together with their probability labels and such a problem program actually defines a probability distribution over programs, logic programs, and these are going to be subsets of the logical parts of that theory.",
                    "label": 1
                },
                {
                    "sent": "In the case of the network, it's going to contain a sub graph.",
                    "label": 0
                },
                {
                    "sent": "Or subnetwork of that network.",
                    "label": 0
                },
                {
                    "sent": "And basically the probability of sampling a particular logic program is the product of those clauses or facts or edges belonging to that program, multiplied by 1 minus probability value of those facts not belonging to that program, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a very simple definition.",
                    "label": 0
                },
                {
                    "sent": "And given that definition, we then going to look at the probability.",
                    "label": 1
                },
                {
                    "sent": "Of the goal, the probability that a goal succeeds in this probabilistic database and that is simply taken.",
                    "label": 0
                },
                {
                    "sent": "The probability that this particular query succeeds in this problem program is basically taken as the weighted sum over this probabilities of sampling a given program times, well, one or zero.",
                    "label": 0
                },
                {
                    "sent": "Either the query follows from the logic program or it doesn't, and if it follows well, then it's going to give you the success probability of that query.",
                    "label": 0
                },
                {
                    "sent": "So in a sense this probability.",
                    "label": 0
                },
                {
                    "sent": "Gives you the expected probability that it succeeds in a randomly sampled program according to the distribution that is listed.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dare.",
                    "label": 0
                },
                {
                    "sent": "OK, we can now look at computing this success probabilities and.",
                    "label": 0
                },
                {
                    "sent": "Here we are going to use the example that we are interested in finding a path from node A to node C and what you would do if you would run Prolog on this kind of predicate.",
                    "label": 0
                },
                {
                    "sent": "You would actually build an SLD tree or a proof tree.",
                    "label": 0
                },
                {
                    "sent": "And here you see the proof tree without the logic.",
                    "label": 0
                },
                {
                    "sent": "It basically tells you the kind of passes that exists that bring you from.",
                    "label": 0
                },
                {
                    "sent": "A to C you can see here from I can actually take this link and then that link and then I actually have success.",
                    "label": 0
                },
                {
                    "sent": "I can actually also go from a I can go that way that way and that way.",
                    "label": 0
                },
                {
                    "sent": "And that's actually what's listed there.",
                    "label": 0
                },
                {
                    "sent": "And so this is going to give you using standard Prolog execution.",
                    "label": 0
                },
                {
                    "sent": "It's going to give you or enumerate you all possible proofs of that particular predicate.",
                    "label": 0
                },
                {
                    "sent": "What we then do is we know that one particular.",
                    "label": 0
                },
                {
                    "sent": "Our proof for one particular pulse is going to succeed, provided that those two links.",
                    "label": 0
                },
                {
                    "sent": "I mean this pulse, is going to succeed, provided that this link is present and that link is present right here.",
                    "label": 0
                },
                {
                    "sent": "We've got 4 links, and so that's also going to give you a particular expression.",
                    "label": 0
                },
                {
                    "sent": "And if you accept that point of view, then the probability that this fact succeeds in a randomly sampled program.",
                    "label": 0
                },
                {
                    "sent": "Is actually equal to the probability that this expression succeeds?",
                    "label": 0
                },
                {
                    "sent": "Where here you've got a Boolean expression, you have to interpret this as a Boolean expression, either a.",
                    "label": 0
                },
                {
                    "sent": "Either facts A&B holds or facts Ed, Ansi, hold or answer on basically.",
                    "label": 0
                },
                {
                    "sent": "Again, this is kind of the simpler version.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you do it in real Prolog, you would get something like that, but again, from successful passes in your proof tree, you can read off the kind of Boolean formula that you then want to compute.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The probability of now the problem of computing the probability of a Boolean variable where each of the Boolean variables are independent from one another is, I mean this sum of products is an NP hard problem.",
                    "label": 0
                },
                {
                    "sent": "It's known as the disjoint sum problem and it's actually received quite some attention in the literature on computer architecture and network reliability.",
                    "label": 0
                },
                {
                    "sent": "And the reason why it is a hard problem is basically that you can just.",
                    "label": 0
                },
                {
                    "sent": "You cannot just take the products of the probabilities of edge A&B, then add that to the product of.",
                    "label": 0
                },
                {
                    "sent": "ED&C, and so.",
                    "label": 0
                },
                {
                    "sent": "The reason that if you would do that, you would actually not end up with a probability value you would exceed.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One in this particular case, you can also see it in this kind of little schema.",
                    "label": 0
                },
                {
                    "sent": "Here you've got a B or AC.",
                    "label": 0
                },
                {
                    "sent": "So what you basically want this you want to compute the probability of this kind of region here, and if you would do it naively and just take a B plus AC, you would actually have taken the probability mass of abmc twice, and so the whole challenge in solving this.",
                    "label": 0
                },
                {
                    "sent": "Disjoint sum problem is actually in rewriting the Boolean formula in such a way that none of the expressions is overlapping and that you can actually take the product of these expressions and then sum them up.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The naive technique for solving this is the inclusion exclusion principle, and that's also the approach that some people like Norbert fur have tried out.",
                    "label": 1
                },
                {
                    "sent": "They've tried it out in their PD problem, PD program called High Spirits, and it's actually infeasible.",
                    "label": 0
                },
                {
                    "sent": "They report that as soon as you've got like 10 or more conjunct, then it's not going to work.",
                    "label": 1
                },
                {
                    "sent": "And of course in the context of network mining, if you take like a.",
                    "label": 0
                },
                {
                    "sent": "Miles between two arbitrary nodes, all possible passes.",
                    "label": 0
                },
                {
                    "sent": "There's going to be way more than 10 in, typically even for very small graphs you rapidly end up with hundred thousands of possible passes, not to say millions of possible passes, and so that's not going to work.",
                    "label": 0
                },
                {
                    "sent": "There's also some results in network reliability that we've come across, and we've tried to apply and, but these results you can actually go to up to about 100 conjunction.",
                    "label": 1
                },
                {
                    "sent": "So that's also not sufficient for tackling this kind of application, and so the thing that does seem to work pretty well is to use beads to represent the Boolean expression, and from the BDD, the binary decision diagram that I will shortly mention.",
                    "label": 0
                },
                {
                    "sent": "You can then rapidly find the probability, but even that is not sufficient for coping with larger networks containing a couple of thousands of edges.",
                    "label": 0
                },
                {
                    "sent": "Couple of hundreds of nodes, and so we also introduce two approximation algorithms for.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Coping with that, but maybe first I can very briefly introduced as PZ PZ are actually very familiar to most computer scientists, especially those working in computer architecture and verification.",
                    "label": 1
                },
                {
                    "sent": "It's one of the areas that receive the most attention in the field of computer science as a whole.",
                    "label": 0
                },
                {
                    "sent": "The paper by Bryant, who actually introduced this particular version of DZS amongst most cited ones.",
                    "label": 1
                },
                {
                    "sent": "In computer science as a whole for our purposes, it's kind of convenient to view this as a kind of BDD as a kind of a variant of a binary decision tree.",
                    "label": 0
                },
                {
                    "sent": "It actually has two types of restrictions.",
                    "label": 0
                },
                {
                    "sent": "The first restriction is that there is a fixed variable ordering, and that means that every valuable in the graph or tree or the diagram is only listed at one particular level.",
                    "label": 0
                },
                {
                    "sent": "So you see here, there was first a.",
                    "label": 0
                },
                {
                    "sent": "Then the two the two sub nodes of a both mentioned B and then here they both mentioned F and so on.",
                    "label": 0
                },
                {
                    "sent": "And then finally it's also optimized in the sense that if well in a binary decision diagram, if you've got two nodes at the same level that have identical subtrees, you actually going to remove that level and actually compress to diagram.",
                    "label": 0
                },
                {
                    "sent": "There exists ask for satisfiability testing.",
                    "label": 0
                },
                {
                    "sent": "There exists very good and elegant and optimized public domain software where you can actually input BDD where you can input a Boolean formula and you can retrieve the kind of BDD and there exist loads of versions of that.",
                    "label": 0
                },
                {
                    "sent": "Given the BDD, it's easy.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easy to compute the probability of the corresponding Boolean formula.",
                    "label": 0
                },
                {
                    "sent": "So the thing that we will do is we will first derive from the proof.",
                    "label": 0
                },
                {
                    "sent": "Trees will derive this Boolean formula.",
                    "label": 0
                },
                {
                    "sent": "Then we put that Boolean formula into this BDD package we retrieved and then we can compute using this simple algorithm that I won't go into detail.",
                    "label": 0
                },
                {
                    "sent": "You can actually very easily compute the probability of the original.",
                    "label": 0
                },
                {
                    "sent": "A query.",
                    "label": 0
                },
                {
                    "sent": "And that works pretty well.",
                    "label": 0
                },
                {
                    "sent": "You can go to up to 100,000 of kanjeng.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But if you want to do more than you need approximation techniques in the work on Pro blog, we actually use two different types of approximation methods.",
                    "label": 0
                },
                {
                    "sent": "One is a simple Monte Carlo method and the other is bounded inference.",
                    "label": 1
                },
                {
                    "sent": "Maybe I can first talk about the Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "Basically what you do there.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is you sample Subprograms repeatedly, you search for approval of your query in this sub program and then you actually look at the fraction of sample subprograms in which it succeeds, and you take that as the kind of approximation of the probability we have actually refined that methods a little bit in the sense that we also compute a kind of confidence intervals around the estimate.",
                    "label": 0
                },
                {
                    "sent": "And you would typically hold the process if you're like 95% certain that it falls into a particular interval.",
                    "label": 0
                },
                {
                    "sent": "We've also optimized it a little bit in the sense that many of the programs that you sample might be similar to one another, and so it does make sense to store successful proofs in a kind of prefix tree to avoid.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recomputation, there's also another approach that we pursue, and that's a technique based on what we call bounded inference.",
                    "label": 0
                },
                {
                    "sent": "It's a technique, due to, or going back to at least David Poole in the early 90s.",
                    "label": 0
                },
                {
                    "sent": "What we dare do is, rather than building all proofs for a particular query, we actually cut off the proof other particular level and use that in order to derive two Boolean.",
                    "label": 0
                },
                {
                    "sent": "Formulas, one that will give us a lower bound, another one that will give us an upper bound, and then you can actually show that the probability of the query given the temple here is like all proofs.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the original query, now you can cut off the proof at any level that you desire, and suppose we cut it off.",
                    "label": 0
                },
                {
                    "sent": "Nearest corner Booth dot level or we can actually see that we know that this was a successful truth.",
                    "label": 0
                },
                {
                    "sent": "So AB is an already found proof.",
                    "label": 0
                },
                {
                    "sent": "We also know that ADC isn't already found.",
                    "label": 0
                },
                {
                    "sent": "Proof EFB isn't already found proof, and so we know that the probability of the original query has to be larger than.",
                    "label": 0
                },
                {
                    "sent": "Well, the disjunction of all the successful proofs that.",
                    "label": 0
                },
                {
                    "sent": "That you've already found killed that level, but you also know is that the only proof that could still succeed by further expanding that proof tree is the one here.",
                    "label": 0
                },
                {
                    "sent": "I mean, here we say we cut off potentially successful proof, and so we can actually use a FD and add that to get the kind of upper bound for.",
                    "label": 0
                },
                {
                    "sent": "For this probability and so we combine these two here.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Dan.",
                    "label": 0
                },
                {
                    "sent": "We combine that ID with the idea of iterative deepening.",
                    "label": 0
                },
                {
                    "sent": "So if you want to get certain guarantees, say that the probability is approximated to like 5%.",
                    "label": 0
                },
                {
                    "sent": "What you do is you start out a particular level, you compute the lower and the upper bound.",
                    "label": 0
                },
                {
                    "sent": "You look whether the difference between upper and lower is less than 5%.",
                    "label": 0
                },
                {
                    "sent": "If it is, you stop and output probability.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you go to the next level.",
                    "label": 0
                },
                {
                    "sent": "So you do some kind of iterative deepening while computing to be DDS.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the the expressions that you have here again, I didn't show it for Prolog, but the thing I showed for Prolog directly Maps, but I showed for the passes and the networks directly Maps to Prolog where you can do exactly the same using a very sick.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "People are interpreter using this versions of inference mechanisms.",
                    "label": 0
                },
                {
                    "sent": "We looked at a pretty large graph that we extracted from this enormous network we looked at about 5000 nodes, about 11,000 edges, and the graph was constructed in a particular way by kind of breadth.",
                    "label": 0
                },
                {
                    "sent": "First search around for random Alzheimer genes.",
                    "label": 1
                },
                {
                    "sent": "And then the kind of queries we're interested in is wedded every exists a connection between two of the jeans and we're working with 10 sequences of subgraphs in our subgraphs of this large biological one.",
                    "label": 1
                },
                {
                    "sent": "They are sizes of 204 hundred and some number of edges obtained by randomly sampling the edges from this one, and also all of these subgraphs contained the four random.",
                    "label": 0
                },
                {
                    "sent": "Alzheimer genes.",
                    "label": 0
                },
                {
                    "sent": "We do approximate inference with Delta equal to 1% and.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the typical kind of behavior that you get is if you search till level one or say if you search the level one.",
                    "label": 0
                },
                {
                    "sent": "Of course the width of the lower and the interval given by the lower and the upper bound is going to be like one and then it's going to slowly decrease the deeper and deeper you search.",
                    "label": 0
                },
                {
                    "sent": "And this is like a typical behavior that you get here.",
                    "label": 0
                },
                {
                    "sent": "This is for graphs with 14 edges each, then graphs where we took the average.",
                    "label": 1
                },
                {
                    "sent": "And you see that typically after like at level 6 or 7, you already get at very reasonable bounds containing like 5 percent, 5% accuracy or 10% accuracy.",
                    "label": 0
                },
                {
                    "sent": "The timings it took for this size of graphs is of the order of 15 seconds to 4 minutes.",
                    "label": 1
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To run a query we also did while scalability experiments and what you can see there is that you can actually go up to graphs containing on the order of five thousand 4505 thousand, number of edges, and the runtimes on these are of the order of few seconds to up to four hours on a reasonable workstation for some of the larger graphs.",
                    "label": 0
                },
                {
                    "sent": "What you also see is that the limiting factor.",
                    "label": 0
                },
                {
                    "sent": "Is a little bit the size of the BDS.",
                    "label": 0
                },
                {
                    "sent": "I mean what is important when working with BDS is that they fit into main memory and for some Boolean expressions they can actually become way too large and then you got a problem.",
                    "label": 0
                },
                {
                    "sent": "Here is the maximum size for two example graph series.",
                    "label": 0
                },
                {
                    "sent": "If you don't use the approximations than you typically go very rapidly that the number of proofs is so high.",
                    "label": 0
                },
                {
                    "sent": "That the size of the BDD really explodes.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the lower bounds or the upper bounds than you typically get acceptable B.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Savior in recent work.",
                    "label": 0
                },
                {
                    "sent": "We also compared the approximation method based on the bounded inference with the Monte Carlo approach, and one result is what you see here for a particular sequence of of graphs.",
                    "label": 0
                },
                {
                    "sent": "What you dare see is here, as the number of edges increases.",
                    "label": 0
                },
                {
                    "sent": "Of course you need more time to answer queries, but the typical kind of behavior that you get.",
                    "label": 0
                },
                {
                    "sent": "Is that using the BDS?",
                    "label": 0
                },
                {
                    "sent": "You get better and faster results if the graphs and the problems are reasonably small.",
                    "label": 0
                },
                {
                    "sent": "If the graphs become very large than the Monte Carlo methods is going to take over and typically the cutting edge is where the beads don't longer fit into main memory and actually requires so much time to build that it explodes.",
                    "label": 0
                },
                {
                    "sent": "You can also compare and that's what you see on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "You can compare the kind of results found by the Monte Carlo method.",
                    "label": 0
                },
                {
                    "sent": "That's with 95% confidence interval that's marked in red, and then the two bounds are lower and upper bound using the beads and again there you see that the MC method.",
                    "label": 0
                },
                {
                    "sent": "Pretty good, gives pretty good approximations with regard to the true probability values lying into lower and upper bounds given by the BDD.",
                    "label": 0
                },
                {
                    "sent": "So the confidence intervals that you get are quite.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reasonable.",
                    "label": 0
                },
                {
                    "sent": "OK, so that concludes the first part of the talk.",
                    "label": 0
                },
                {
                    "sent": "That's about the approximate inference.",
                    "label": 0
                },
                {
                    "sent": "What you can see is that we've got a simple probabilistic logic.",
                    "label": 0
                },
                {
                    "sent": "You can build good and efficient approximation algorithms for answering queries.",
                    "label": 0
                },
                {
                    "sent": "With that it scales reasonably well at the level that you can really use it.",
                    "label": 0
                },
                {
                    "sent": "One thing that we are currently working at looking into is not just looking at kind of simple.",
                    "label": 0
                },
                {
                    "sent": "False queries because for simple pass queries you would not need the full power of a database or the full power of Prolog.",
                    "label": 1
                },
                {
                    "sent": "But we do want and do intent to encode a lot of additional background knowledge like ontologies into the system and use that to pose much more complex queries.",
                    "label": 0
                },
                {
                    "sent": "And that's an item for future research.",
                    "label": 0
                },
                {
                    "sent": "The next topic that I want to talk about is.",
                    "label": 0
                },
                {
                    "sent": "If that.",
                    "label": 0
                },
                {
                    "sent": "Works here.",
                    "label": 0
                },
                {
                    "sent": "OK. Papa",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a probabilistic explanation based learning?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And people in machine learning might recall that explanation based learning was a very hot topic in the 80s.",
                    "label": 0
                },
                {
                    "sent": "It was largely concerned with speed up learning, and it was also very much knowledge based.",
                    "label": 0
                },
                {
                    "sent": "There was also a role for something like finding abductive explanations of certain phenomena in that work at the time.",
                    "label": 0
                },
                {
                    "sent": "As far as we know, there was not really a lot of results concerning probabilistic logics or probabilistic.",
                    "label": 0
                },
                {
                    "sent": "Versions of explanation based learning and that has actually motivated us to try to adapt the idea of explanation based learning to probabilistic logics.",
                    "label": 0
                },
                {
                    "sent": "And of course big cause prob log is so simple we actually apply it to prob log.",
                    "label": 0
                },
                {
                    "sent": "In the first case, but we're sure that it can very easily be adapted towards some of the more powerful logics like PRISM or ICL or SLP's.",
                    "label": 1
                },
                {
                    "sent": "The idea will be.",
                    "label": 0
                },
                {
                    "sent": "That we're going not to focus on speed up learning, but we're going to focus on finding explanations for certain phenomena, and we're going to use this explanations to reason by analogy to reason by cases.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to say, before going through the details, let me briefly remind you of how EBL worked in IBL.",
                    "label": 0
                },
                {
                    "sent": "You basically started from an example that fallout from your theory you would build a proof tree.",
                    "label": 1
                },
                {
                    "sent": "For that example you would generalize the proof tree.",
                    "label": 1
                },
                {
                    "sent": "Essentially you would do so by deleting certain parts of your proof tree.",
                    "label": 0
                },
                {
                    "sent": "Those for so called operational predicates and then you would turn you would collect the leaves of the resulting proof tree.",
                    "label": 1
                },
                {
                    "sent": "And turn that into a rule.",
                    "label": 0
                },
                {
                    "sent": "Add a rule to your database and use it to reason.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is like the most famous Ebla example ever.",
                    "label": 0
                },
                {
                    "sent": "It has appeared in at least 50 papers on EBL.",
                    "label": 0
                },
                {
                    "sent": "I took it this version from a paper by Mooney Manzella.",
                    "label": 0
                },
                {
                    "sent": "Basically it's about the Cup problem.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the cut problem, you're given a database like this.",
                    "label": 0
                },
                {
                    "sent": "A Cup is a concept, it's something that's stable liftable an open vessel and then you've got descriptions of training examples.",
                    "label": 0
                },
                {
                    "sent": "You've got definition of what is stable, liftable, and so on, and using that.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can then actually compute approve tree.",
                    "label": 0
                },
                {
                    "sent": "Why something is a Cup and if you do that for a particular example for a particular Cup, you'll end up with a large proof tree, and this is already the generalized proof treats generalized in the sense that it has valuable eisd the things that occur in there we talk about not a particular Cup, but about the variable Cup called X.",
                    "label": 0
                },
                {
                    "sent": "And you also see that certain parts are actually deleted.",
                    "label": 0
                },
                {
                    "sent": "From that proof tree, these are the parts at so called operational predicates where you don't.",
                    "label": 0
                },
                {
                    "sent": "You're not interested in the details of proving YB is a part of X&YBL.",
                    "label": 0
                },
                {
                    "sent": "The Leafs taken together then constitutes the explanation and are then used to build a new new definition and you rule for Cup that is then added to the database, and it's hoped that using this rule will.",
                    "label": 0
                },
                {
                    "sent": "Actually, speed up the inference for future cups.",
                    "label": 0
                },
                {
                    "sent": "It's showing that this does not always work.",
                    "label": 0
                },
                {
                    "sent": "You have to exercise that with.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lot of cautious.",
                    "label": 0
                },
                {
                    "sent": "That was the disappointment I think in explanation based learning that you have to be very careful about when and how to apply it.",
                    "label": 0
                },
                {
                    "sent": "What I'm now going to do is I'm actually going to try to map that context from BBL to this probabilistic logics.",
                    "label": 0
                },
                {
                    "sent": "And if you look at the kind of problem we are facing with where you have actually 100 thousands of possible proofs for particular queries, than the first thing is that you have to identify one of them, one amongst generalize and the best candidate for doing that is of course that that is the most likely candidate.",
                    "label": 0
                },
                {
                    "sent": "So in this.",
                    "label": 0
                },
                {
                    "sent": "Kind of small toy example, we had four possible proofs and so the most likely proof, or the most likely most likely proof for paths would be that of which the probability of these four is actually the highest.",
                    "label": 1
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In contrast to finding the kind of probability that there exists proof, which is an NP hard problem with this Boolean formula, finding the most likely proof is a lot easier.",
                    "label": 0
                },
                {
                    "sent": "Ascentia Lee, what you do is you do some kind of best first search.",
                    "label": 0
                },
                {
                    "sent": "You obtain a simple conjunction conjunctive expression.",
                    "label": 1
                },
                {
                    "sent": "You're going to be able to make the proof provided that one conjunction of fact is true, and from that you can simply compute the probability.",
                    "label": 0
                },
                {
                    "sent": "By multiplying the probabilities of the individual facts so it's only a product you don't have to cope with the disjoint sub problem, and it's a lot easier and much faster to compute.",
                    "label": 0
                },
                {
                    "sent": "So once we've got the most likely proof we can then try to.",
                    "label": 1
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Analyze that and that is done in very much the same fashion as you do it for the Cup.",
                    "label": 1
                },
                {
                    "sent": "Example.",
                    "label": 0
                },
                {
                    "sent": "I mean, once you've got the most likely proof, it's gonna look like this.",
                    "label": 0
                },
                {
                    "sent": "It's going to be extended, and then you can basically apply the ID of cutting off at operational predicates, and you're going to get a generalized proof tree like that.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is the way that Pebble probabilistic explanation based learning works.",
                    "label": 1
                },
                {
                    "sent": "You compute the most likely generalized proof tree of the example.",
                    "label": 1
                },
                {
                    "sent": "This is the probability of the most likely proof tree, and then that will fall together in two components.",
                    "label": 0
                },
                {
                    "sent": "First, you're going to have to generalize proof, and you can take the probability of that, and then you're going to have the factor that is concerned with proving the operational predicates.",
                    "label": 0
                },
                {
                    "sent": "So the lower deleted parts of the generalized proof tree, but other than that there is nothing special about computing of probabilistic generalized proof tree for.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Context of Pablo.",
                    "label": 0
                },
                {
                    "sent": "This is again the version with.",
                    "label": 0
                },
                {
                    "sent": "So the resolution what you then we'll end up with in the case of our.",
                    "label": 0
                },
                {
                    "sent": "Biological networks is expressions of this particular type.",
                    "label": 0
                },
                {
                    "sent": "Here the kind of original queries where pulse queries from again a particular gene to a particular phenotype, like Alzheimer and then you see that you got like this kind of explanations.",
                    "label": 0
                },
                {
                    "sent": "Now there's no need to look at the logic, you can directly map this kind of explanations into a kind of graphical format, which will basically say there are certain.",
                    "label": 0
                },
                {
                    "sent": "Types of links are to be followed and there's a certain type of path to be matched given.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This type of pass you can then use that explanation to find similar passes, and there's two ways of doing that.",
                    "label": 0
                },
                {
                    "sent": "You either again look at the graphical representation you retrieve you, use it to retrieve further examples, or you use at the logical one you assert this in your database, and then you run E pass and you'll get extra examples for E Pass.",
                    "label": 0
                },
                {
                    "sent": "If you get extra it.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Samples for the pass you can actually.",
                    "label": 0
                },
                {
                    "sent": "You can actually.",
                    "label": 0
                },
                {
                    "sent": "Also, um.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "Also you get this extra further examples and if you get further examples you can also compute their probabilities.",
                    "label": 0
                },
                {
                    "sent": "The probabilities of these examples can be used to rank them according to likelihoods, and that is what we're going to do to reason by similarity to reason.",
                    "label": 0
                },
                {
                    "sent": "By similarity, you start from a given positive example.",
                    "label": 0
                },
                {
                    "sent": "You find its explanation.",
                    "label": 0
                },
                {
                    "sent": "You then use that explanation to retrieve all further examples that matched his explanation and you can rank them.",
                    "label": 0
                },
                {
                    "sent": "Or you compute compute the probabilities of these further instances and then you can say, well, this say you start from a gene related to a disease given the template that you then have, you can again use that to identify maybe further gene gene disease pairs.",
                    "label": 0
                },
                {
                    "sent": "And you can compute the likelihood you can predict them that.",
                    "label": 0
                },
                {
                    "sent": "The top scoring ones are with high likelihood.",
                    "label": 0
                },
                {
                    "sent": "Also gonna be positive inst.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is, um.",
                    "label": 0
                },
                {
                    "sent": "Right, and that is the.",
                    "label": 0
                },
                {
                    "sent": "That is the first task that we do with Pebble.",
                    "label": 0
                },
                {
                    "sent": "We're actually using the explanation to find other instances.",
                    "label": 1
                },
                {
                    "sent": "By analogy, you can also you can also use Pebble too.",
                    "label": 0
                },
                {
                    "sent": "To generalize from multiple examples, generalizing from multiple examples was also an issue in early explanation based learning in early explanation based learning the multiple instance example, the multiple example the multiple instance setting was hard to solve.",
                    "label": 0
                },
                {
                    "sent": "Again with the probabilistic version it's kind of easy to find the most likely generalized common proof tree amongst a set of examples, and that would also give you further.",
                    "label": 1
                },
                {
                    "sent": "For examples, you can also transfer findings from one domain to the next, and I'm going to show how to do that in some of the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Biological experiments, so again, what we did is we worked with this very same graph network domain from the Helsinki Group and we generated.",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, various networks of different sizes around the genes.",
                    "label": 1
                },
                {
                    "sent": "We worked with Alzheimer with jeans around Alzheimer, and jeans around asthma, and we had four versions of networks containing Alzheimer to asthma and basically the way that these were generated.",
                    "label": 0
                },
                {
                    "sent": "I mean, Alzheimer's four was generated by looking at the known Alzheimer's genes in on three and there is like about 140 two of them.",
                    "label": 0
                },
                {
                    "sent": "And then starting from those those you actually look at passes of up to size 5 and you collect everything that you encounter on the way.",
                    "label": 0
                },
                {
                    "sent": "If you do so, you end up with a network containing about 3000 nodes, about 17,000 edges.",
                    "label": 0
                },
                {
                    "sent": "You also get is that of the 142 that you originally have.",
                    "label": 0
                },
                {
                    "sent": "12 are no longer connected to this.",
                    "label": 0
                },
                {
                    "sent": "The largest component there, so you delete these and there is not only Alzheimer genes, but there was also genes belonging to other phenotypes and there was like 55 of them.",
                    "label": 0
                },
                {
                    "sent": "Is in total 6 phenotypes that you will encounter there an so that is the way that this last this Alzheimer's four network was generated.",
                    "label": 0
                },
                {
                    "sent": "There are some smaller ones like for Alzheimer's two and one we started from 17 jeans and search the level 5 for Alzheimer's one and three.",
                    "label": 0
                },
                {
                    "sent": "We only searched the level for basically.",
                    "label": 0
                },
                {
                    "sent": "Similar for us.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we then did is it's a bit of an artificial example, and I'm sure that Pierre will admit this.",
                    "label": 0
                },
                {
                    "sent": "We tried to actually set up an experiment to see how successful this reasoning by similarity.",
                    "label": 0
                },
                {
                    "sent": "This reasoning by analogy walls, and in order to do that we took an artificial concept, which is the one seen here.",
                    "label": 0
                },
                {
                    "sent": "We defined the predicate Connect which basically says it takes 2 jeans and one phenotype.",
                    "label": 0
                },
                {
                    "sent": "And it succeeds if there is a pass from June 1 to the phenotype from June 2 to the phenotype and the 2G.",
                    "label": 0
                },
                {
                    "sent": "Note the two genes are connected to one another, and then you can actually take all possible topples satisfying this, maybe up to reorderings, like what gene one and gene two you don't want to get them in the different orders here.",
                    "label": 0
                },
                {
                    "sent": "And you then what we done did is we constructed positive examples.",
                    "label": 0
                },
                {
                    "sent": "Positive examples are those where gene one and gene two are known according to the database to be connected.",
                    "label": 0
                },
                {
                    "sent": "They know, like Alzheimer or they known asthma genes.",
                    "label": 0
                },
                {
                    "sent": "So positive examples are those where gene one and gene gene two are like connected to Alzheimer and the phenotype is also Alzheimer's.",
                    "label": 0
                },
                {
                    "sent": "All the other couples are negative examples and then we.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pursuit this ID.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the similarity based issue you find.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You find.",
                    "label": 0
                },
                {
                    "sent": "An explanation like that from one example you apply that explanation to find other examples, and you rank the other examples according to their probability and.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That actually.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seems to work.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Works surprisingly well.",
                    "label": 0
                },
                {
                    "sent": "The reason is given in this kind of experiment, which is listed here.",
                    "label": 0
                },
                {
                    "sent": "I mean here is what you do is if you it's averaged over all possible positive examples and here is if you take the top ranked example and you predict that it's going to be belonging to Alzheimer, how much accuracy do you then get an in 95% of the cases?",
                    "label": 0
                },
                {
                    "sent": "The top one is actually belonging to the right kind of disease for Alzheimer's too.",
                    "label": 0
                },
                {
                    "sent": "It's a bit lower and Alzheimer 4 as well.",
                    "label": 0
                },
                {
                    "sent": "If you take the top three that are ranked, you still get pretty good results.",
                    "label": 0
                },
                {
                    "sent": "More than 2.5 out of three are going to be.",
                    "label": 0
                },
                {
                    "sent": "Are going to be positive for five.",
                    "label": 0
                },
                {
                    "sent": "You're even still around 4:00 and you also see that if you do it from asthma and you apply it to asthma, which is like this corner, you also get very similar results.",
                    "label": 0
                },
                {
                    "sent": "This despite the fact that.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In these domains, by the way that we constructed them, by the way that we constructed them, the distribution of positive and negatives is actually like 10 to 90% in most of the cases that you will find here.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The results are very good for this and they actually show that this reasoning by similarity.",
                    "label": 0
                },
                {
                    "sent": "There's reasoning by cases does seem to work, at least if you do it in one domain.",
                    "label": 0
                },
                {
                    "sent": "You learn an explanation on one graph and you apply it on the same graph to find similar explanations.",
                    "label": 0
                },
                {
                    "sent": "We also looked at the issue of transfer learning.",
                    "label": 0
                },
                {
                    "sent": "That is, can we apply explanations found on Alzheimer?",
                    "label": 0
                },
                {
                    "sent": "Can we apply it?",
                    "label": 0
                },
                {
                    "sent": "To asthma and what kind of results do we get there and vice versa?",
                    "label": 0
                },
                {
                    "sent": "Can we apply explanations found on asthma?",
                    "label": 0
                },
                {
                    "sent": "Can we apply them to Alzheimer and that's like the ones that you find here in this kind of transfer learning setting.",
                    "label": 0
                },
                {
                    "sent": "You see, you see that transferring things from Alzheimer to asthma works reasonably well.",
                    "label": 0
                },
                {
                    "sent": "I mean, you get like pretty good, you get pretty good accuracies like 4.",
                    "label": 0
                },
                {
                    "sent": "I dispose 5, taking the top five ranked you got till like 4 point.",
                    "label": 0
                },
                {
                    "sent": "Something that are positive but what's also obvious is that in the other direction, if you look at the explanations found on asthma and you want to apply them on Alzheimer that you get very poor results.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's also reason for that.",
                    "label": 0
                },
                {
                    "sent": "The reason is that on the ulzheimer domain we found a lot more explanations.",
                    "label": 0
                },
                {
                    "sent": "In total we found like 26 possible explanations using.",
                    "label": 0
                },
                {
                    "sent": "The Pebble approach, while on the asthma approach, we only found of the order.",
                    "label": 0
                },
                {
                    "sent": "While we've only found three actually, there's also indicates that the idea of using common explanations doesn't work.",
                    "label": 0
                },
                {
                    "sent": "A lot of the explanation actually, most of the explanations that are found in both domains are common to many of these examples, and one explanation was actually even shared by about 12 examples.",
                    "label": 0
                },
                {
                    "sent": "And so there's also shows or indicate that this issue of learning from multiple learning explanations that are common to multiple instances would make sense and is likely to increase the.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Percy to conclude the parts on Pebble.",
                    "label": 0
                },
                {
                    "sent": "Let me.",
                    "label": 0
                },
                {
                    "sent": "Say that.",
                    "label": 0
                },
                {
                    "sent": "Puts EBL in a kind of new perspective.",
                    "label": 0
                },
                {
                    "sent": "And you probabilistic context to the best of my knowledge this.",
                    "label": 0
                },
                {
                    "sent": "Use of probabilistic logics in explanation based learning has not yet been done.",
                    "label": 0
                },
                {
                    "sent": "It's not about speed up learning, but it's more like finding good explanations and using them to do useful things.",
                    "label": 0
                },
                {
                    "sent": "One current and ongoing work is actually expanding on the idea of multiple.",
                    "label": 0
                },
                {
                    "sent": "Of an explanation that is common to multiple examples is to expand the current work on Pebble towards local pattern mining and there we are actually looking at query mining techniques.",
                    "label": 0
                },
                {
                    "sent": "In this probabilistic logics and we've got first approach is running and.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up about the compression thing, I don't think I have a lot of time, but five minutes.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe I can very briefly sketch.",
                    "label": 0
                },
                {
                    "sent": "Is that with or without questions?",
                    "label": 0
                },
                {
                    "sent": "Including questions OK so.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just state the idea here.",
                    "label": 0
                },
                {
                    "sent": "I got into biological network.",
                    "label": 0
                },
                {
                    "sent": "You might have the situation like what you have here.",
                    "label": 0
                },
                {
                    "sent": "There is one phenotype, one disease you're interested in and say these are interesting genes that you're currently interested in.",
                    "label": 0
                },
                {
                    "sent": "These are supposedly not to be interested.",
                    "label": 0
                },
                {
                    "sent": "You're not interested in those because they might not be related to this kind of disease.",
                    "label": 0
                },
                {
                    "sent": "And then the idea is that.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Give positive and negative examples.",
                    "label": 0
                },
                {
                    "sent": "So in this case you would give connected from green to blue and from green to blue as positive examples connected from red to blue and red to blue as negative.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Samples and then you would try to compress this database does not work as much as possible.",
                    "label": 0
                },
                {
                    "sent": "You can define a kind of likelihood.",
                    "label": 0
                },
                {
                    "sent": "You basically want to maximize the product of the likelihoods for the positives times 1 minus the likelihood of the negatives.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you would then get us a typical kind of behavior.",
                    "label": 0
                },
                {
                    "sent": "There would be also parameter K that tells you how much you should compress the network and K would here denote the number of edges and there is then a greedy algorithm that basically would delete links and see what the effect is on the likelihood and would repeatedly remove the least.",
                    "label": 0
                },
                {
                    "sent": "Interesting link to least interesting edge for.",
                    "label": 0
                },
                {
                    "sent": "The arm.",
                    "label": 0
                },
                {
                    "sent": "For the likelihood, if you set K equals to 15, then you see that of course the connections from the bat nodes from red are disappeared.",
                    "label": 0
                },
                {
                    "sent": "They turned into dots and if you set K = 2 Five you again see that here it does fine.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something are reasonable.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, we did loads of experiments showing.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Various things there also bit in an artificial setting, but still showing that the technique basically works, so to conclude.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "About prologue.",
                    "label": 0
                },
                {
                    "sent": "And about the work I've presented, I think I've presented simple but still powerful logic, probabilistic logic.",
                    "label": 0
                },
                {
                    "sent": "It provides a link between link mining and logic, and well, there is some future directions, but thank you.",
                    "label": 0
                }
            ]
        }
    }
}