{
    "id": "yp7lqdehzoo6gnogrmol65lctzyw6qwp",
    "title": "A Game-Theoretic Approach to the Enforcement of Global Consistency in Multi-View Feature Matching",
    "info": {
        "author": [
            "Andrea Torsello, Department of Computer Science, Ca' Foscari University of Venice"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_torsello_mvfm/",
    "segmentation": [
        [
            "Game theoretic approach to enforcement enforcement of global consistency.",
            "Multiview feature matching, which is joint work with him and wanna little Bella and there barely."
        ],
        [
            "So the problem here is with bundle adjustment and there is a fun the rain, but adjustment India is.",
            "We start with two or more shots of the same subject or particular subject.",
            "We extract features or incision with modern feature extractors like safety or service and then we get a set from the descriptors of the features.",
            "We get a set of candidate points between all the images and from the set of those set of candidate points we want to estimate the polar geometry.",
            "So and then the pose.",
            "Between the cameras and use that for construction.",
            "The problem is that.",
            "We do have a good algorithms to extract the pose if we have good candidates.",
            "If you have correct exact correspondence is, then we do.",
            "We do have eight points algorithms and at least square algorithms to get to do the estimation of the polar geology.",
            "The problem is that we very rarely have good candidates.",
            "We have several good candidates but also some outliers and outliers really break the process an usually it's done.",
            "We do have some problem.",
            "Meet some process of outlier elimination by checking, checking with either this distance is the polar line or some other geometric properties."
        ],
        [
            "So here in the typical matching strategies as well, based on the local information, basically only on local information of the feature descriptors we have descriptors on each point.",
            "Annual match points are close and there are close enough and then you get a lot of spurious outliers and we don't have any global Corsica consistency check at all, except ex post.",
            "You do do the estimation you see that estimation is wrong.",
            "Then you have a lot of buttons that do not belong to the polar line.",
            "A lot of respondents do not fit on the people online.",
            "And then we try to eliminate those lie.",
            "So the usual approach is actually filtering approach and filtering approaches are not very robust with respect lies, especially when you have structured noise when you can have, you can have multiple objects or multiple similar textures so that.",
            "There are multiple.",
            "Consistent, locally consistent.",
            "Organizational feature similar to feature points, and this is actually very common approaches.",
            "Anytime you have repeated texture you have problem like that, but it's Jenna."
        ],
        [
            "No problem.",
            "So the idea here is to try to have a way to drive the selection of corresponding points.",
            "No, just stuck with the points, do the summation and uses the estimation to filter because that is not robust.",
            "But try to drive the selection of good correspondence is and we do this by using a game theoretic Miller selection approach where we do have fitness assigned to each set of correspondences correspondences.",
            "Actually players in the game.",
            "And we do have fitness is assigned to each.",
            "Correspondence is depending on how they perform with respect to global consistency measure with respect to other correspondence is so the game is played by two by 2% of correspondences and they do two sets of correspondence can be explained well by a single global probles single global alignment, and then they do get very strong support, otherwise they do get very very low support.",
            "But in the end.",
            "And we want to get only those only a small subset of points that are very consistent with one another, so we don't really the point.",
            "The key point of intersection is, so we have another abundance of post possible correspondences, and we only need a few theoretically only eight to do have good estimation of our transformation, and we actually rather than try to do what run second as that is you pick up.",
            "And that they can then filter out.",
            "We want to select those few elements that are and are most consistent with one another and use those and only those.",
            "And.",
            "To the parameter estimation to the submission of our transformation model.",
            "Other people geometry.",
            "So what we do is we actually model correspondence as a strategy and cooperative game and then just let them compete and the rational and irrational laser coherent group will actually be providing high payoff.",
            "Planner will actually survive this game while driving to extinction.",
            "Everything else."
        ],
        [
            "So we have a large set of initial matching features are the possible strategies are we using and we selected with standard techniques annara pliers are there, they're just matching the initial matches or just anything that.",
            "Exceed a certain threshold in similarities between feature between features in one image and the other, so definitely a lot of Flyers.",
            "We started with initial population vector which is uniform distribution distributed in the complex initialized inside of the standard complex and we define and metric, see which is where the global information comes in.",
            "The final each curve strategy and then we have all the population to the replicator equation, which is this."
        ],
        [
            "And this is just an example.",
            "We have extracted 123456 different correspondences and as we see we can visually see that there are at least two outliers here.",
            "So reasonably high Larry should the reason we have it is that the.",
            "Descriptors are found at the similar, so they might obviously only on local information they might actually fit very well, and this is because this is the metrics we get with one particular.",
            "My considered genetic consistency model will talk about two different models were applied and what do we do when we run?",
            "We run our evolution.",
            "We start with equal pretty much equal distribution of.",
            "The likelihood of the fitness is but then as we as iteration go on those correspondences that are not particularly good here, which is CBCB&EC will actually be driven to extinction and in the end the whole set of correspondences that work well together are extracted as just a subset of the configurations we have.",
            "That is only a one and a 2B1 and B2D1 and D2LC-1 and C2, while the vertical do match.",
            "They're not as good as good as good a fit as the other, so also will be driven to extinction and those two correspondence is actually been after.",
            "Do some form of estimation."
        ],
        [
            "So here we are.",
            "This people actually comparing two different geometric consistency approaches.",
            "So two different ways in which we can define the payoff matrix.",
            "And there are based on the modern person point descriptors, safe service and idea is that we they both require some some local information about orientation, size of the Patch.",
            "So we could we could have local transformations attached to each point information more and we have two approaches.",
            "One is a similar approach that extract.",
            "Local patches that are consistent with a common event information, so we're having we camera perspective or we can find our perspective Locali where we excite local patches of points that are consistent with a single financial information and then we combine them all and second step to obtain the set of full set of the responses and then we have a global approach that has improved consistency with the commentary 3D rigid transformation.",
            "Actually imposes 3D is ometry, so we don't.",
            "We don't get allies, the change of quality of the computer over the configuration."
        ],
        [
            "So to see the similar similar affine model, well, we need to define a compatibility with respect affinity between pairs of pairs of candidate points, and we use this orientation and scale information, and that point is that this orientation and scale will give us an offender information that Maps the appoint in money image to the correspondent party images.",
            "So every correspondence will actually imply a particular fine transformation.",
            "So we're saying that the tourist funds are compatible if they define a similar transformation.",
            "Various systems wherein this week camera model local, at least in the image, all the transformation from 1 from 1 image to the other within this local Patch must be similar.",
            "Must be a similar fine transformation."
        ],
        [
            "And how do you do?",
            "We measure similarity in this event transformation?",
            "Well, we pretty much create virtual points by applying the transformation estimated in one image to the point corresponding pointing the other images.",
            "So if we have this correspondence, we apply to a one the correspondence of Maps that let's say this, there is one matching one image, and this one here B1 and B2M as another match another image and we want to confirm them.",
            "Well, this match here has.",
            "Yeah, this is this information T and this match here.",
            "It says this resulted in transformation T to see how well they fit, we just transform a the deformation aid with the transformation that Maps B1 and B2 obtain this virtual .8 two prime and see.",
            "Look at the distance between a prime time A2 and then do the same.",
            "Here we transform B with their transformation reference from the other points.",
            "Have this virtual point B2 prime Dancy, the distance between.",
            "Two priority so that.",
            "What we do is actually penalize reprojection error between to find transformation and this is important because we we have a measure unit of measure is actually exactly the picture pixel we can go back directly to how many pixels.",
            "So we do know the meaning at least the meaning of the of the parameters we have.",
            "So the similarity is the maximum between the two reprojection errors, and then we do have similarities with our adjusted exponential decay of the similarities with.",
            "Of the projection at maximum protection error."
        ],
        [
            "So.",
            "The there are some limits of this affine model, while of course define assumption sort of works only, but only locally, and so we approach extract only local patches of correspondence points, so all the points that we will get our will be funding pretty much frontal power bar, or at least on a single parallax stack playing plastic plane there will be clustered together, but what we can do is just to repeat the game exacting and use its of correspondences and eliminating.",
            "Because once we have already.",
            "It actually we don't only eliminate those correspondences, but all the correspondences that are within the same image region.",
            "So once we do extract one group of matching correspondences, we just eliminate all groups that are close by in the image."
        ],
        [
            "As I said, we've confirmed front in two different global consistency models.",
            "In this approach.",
            "The second one is global model that impose common tribute transformation where we want to do impose rigidity.",
            "That is, we wanted to inquire conservation of these distances between the underlying 3D points.",
            "And to do that we use again scaling in orientation information about the.",
            "Use that to create virtual points, the direction and scale given by the descriptors."
        ],
        [
            "So the problem we had before is that.",
            "When we do have a lot of parallax, the we have that uniform 30 motion that is just wrote in translation.",
            "This transformation will be going from 1 camera views are together.",
            "We actually imposing unwritten nonuniform transformation in today.",
            "So if you look at the motion vectors and the two views of the two cameras, we actually have motion lexical go all around the place locally.",
            "Of course we can have a sort of similar similar find transformation assumption, which is what the first model did.",
            "But globally that cannot work.",
            "But what we're trying to do is actually try something that will extract globally the consistent configuration."
        ],
        [
            "And what we do that is that as I said, we use Karen Orientation.",
            "Many interesting idea is that scale will offer that the information because variation in scale and all the same Patch into different images will actually indicate it will be inversely proportional to the variation of that between those images and the combination of that scale and orientation will actually give us a second point.",
            "So we are confronting distances between four points rather than distances between two points.",
            "So the idea is that we want to consider to conserve the distances that are here in green.",
            "So we have two these two points with the corresponding virtual points given by the scale orientation of the Patch an we have before possible cross distances between the actual points and virtual points in 3D and we want to keep conserve distances between.",
            "This this distance is in the two projected images."
        ],
        [
            "The problem here is at 4 points are actually not enough to fully constrain transformation to extract the people geometry we have, we need at least five points.",
            "We have a free parameter and the parameter is a parameter Alpha, which is a ratio of scale between the ratio of the Rio three scale of the of the patches were extracted.",
            "So we've seen the scale in scale.",
            "We do have our projected scale in the images, but.",
            "They all correspond to real through the scale of the texture in the Patch and we are just trying to extract.",
            "Features that have pretty much similar or limited variation in real 3D scale now experiments were limiting variation in 3D scale between 1/2 and two.",
            "So we the only limit we have in this global consistency approach is that the actual size of the texture we're looking at should be pretty much similar."
        ],
        [
            "And so just the math, of course, but once you do have work up everything with corresponding points.",
            "P1P2P2AP11 and P12 corresponding points in the first set of corresponding points with money, image and the other.",
            "And we added this as it can be written this way.",
            "And of course points are corresponding and the virtual points can be extracted using the orientation and.",
            "Orientation and scale.",
            "Assuming there is a sort of.",
            "Almost frontal planner.",
            "We have a normal so almost front apply assumption on the observed texture and then when we get back to the similarity of the matches, which is of course dependent on this Alpha parameter is actually the sum of the square distances of all of those four points.",
            "And of course this depends on Alpha and we optimize over over that range of Alpha will range of parameter A that we have given."
        ],
        [
            "So just to give some experimental results, this is the set of final features extracted by the without 3D rigid approach.",
            "This is the set of groups with different images are the different local patches of extract with.",
            "Under today affine loose me local approach and this is the basic bundler key match or used by bundle vary by the bundle or software which is pretty much state of the art right now and here we see that there are some definitely more appliances.",
            "One mapping the point here to here will actually penalizing give us very bad results right?",
            "We can have here is we can see here is that we have generally larger number of.",
            "Good point, we extract with our approach, then became the band wiki, match it as an.",
            "In general, much lower.",
            "Angular are both in the angular rotation an of the difference in the axis of rotation."
        ],
        [
            "This is another set of experiments in another image.",
            "Kimmage and again we see that we have much larger number of matches and much lower.",
            "In the in the estimation of the transformation parameters."
        ],
        [
            "Just include, which we presented a game theoretic approach to enforce consistency in feature matching, and the idea is that robustness is achieved by enforcing global consistency in otherwise setting rather than try to do to exactly consistency exposed.",
            "That is, that only highly compatible matches are enforced where incompatible, incompatible correspondences are driven to extinction.",
            "At the experimental comparison showed the ability of our approach to obtain very accurate estimates much better than the state of the art provided by the bundler key matcher.",
            "Thank you."
        ],
        [
            "Questions.",
            "I have one question.",
            "Extend the.",
            "I love you too of local descriptors is K to the success of the of the process.",
            "For instance, if you have only points.",
            "2D or 3D.",
            "We can do well.",
            "The problem is.",
            "Only points I did not give enough.",
            "Consider not constraint solution enough to the for the people solution.",
            "We could go high order right now that the game is only within two players.",
            "So to several correspondences we could very well raise the order of correspondences and then we can solve the problem.",
            "But will of course it raises the complexity of the approach and.",
            "But the OR if you have different.",
            "If you have different groups of points rather than that, you know that sort of map together, like bag of points.",
            "Also, you could work with bag of points, but then you have to know that that class that is a cluster that Maps in that cluster.",
            "But just points on.",
            "Otherwise setting is not enough to constrain the perpendicular geometry.",
            "OK, thank you more questions.",
            "OK, next send this speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Game theoretic approach to enforcement enforcement of global consistency.",
                    "label": 0
                },
                {
                    "sent": "Multiview feature matching, which is joint work with him and wanna little Bella and there barely.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the problem here is with bundle adjustment and there is a fun the rain, but adjustment India is.",
                    "label": 0
                },
                {
                    "sent": "We start with two or more shots of the same subject or particular subject.",
                    "label": 0
                },
                {
                    "sent": "We extract features or incision with modern feature extractors like safety or service and then we get a set from the descriptors of the features.",
                    "label": 0
                },
                {
                    "sent": "We get a set of candidate points between all the images and from the set of those set of candidate points we want to estimate the polar geometry.",
                    "label": 0
                },
                {
                    "sent": "So and then the pose.",
                    "label": 0
                },
                {
                    "sent": "Between the cameras and use that for construction.",
                    "label": 0
                },
                {
                    "sent": "The problem is that.",
                    "label": 0
                },
                {
                    "sent": "We do have a good algorithms to extract the pose if we have good candidates.",
                    "label": 0
                },
                {
                    "sent": "If you have correct exact correspondence is, then we do.",
                    "label": 0
                },
                {
                    "sent": "We do have eight points algorithms and at least square algorithms to get to do the estimation of the polar geology.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we very rarely have good candidates.",
                    "label": 0
                },
                {
                    "sent": "We have several good candidates but also some outliers and outliers really break the process an usually it's done.",
                    "label": 0
                },
                {
                    "sent": "We do have some problem.",
                    "label": 0
                },
                {
                    "sent": "Meet some process of outlier elimination by checking, checking with either this distance is the polar line or some other geometric properties.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here in the typical matching strategies as well, based on the local information, basically only on local information of the feature descriptors we have descriptors on each point.",
                    "label": 1
                },
                {
                    "sent": "Annual match points are close and there are close enough and then you get a lot of spurious outliers and we don't have any global Corsica consistency check at all, except ex post.",
                    "label": 0
                },
                {
                    "sent": "You do do the estimation you see that estimation is wrong.",
                    "label": 0
                },
                {
                    "sent": "Then you have a lot of buttons that do not belong to the polar line.",
                    "label": 0
                },
                {
                    "sent": "A lot of respondents do not fit on the people online.",
                    "label": 0
                },
                {
                    "sent": "And then we try to eliminate those lie.",
                    "label": 1
                },
                {
                    "sent": "So the usual approach is actually filtering approach and filtering approaches are not very robust with respect lies, especially when you have structured noise when you can have, you can have multiple objects or multiple similar textures so that.",
                    "label": 0
                },
                {
                    "sent": "There are multiple.",
                    "label": 0
                },
                {
                    "sent": "Consistent, locally consistent.",
                    "label": 0
                },
                {
                    "sent": "Organizational feature similar to feature points, and this is actually very common approaches.",
                    "label": 0
                },
                {
                    "sent": "Anytime you have repeated texture you have problem like that, but it's Jenna.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No problem.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is to try to have a way to drive the selection of corresponding points.",
                    "label": 0
                },
                {
                    "sent": "No, just stuck with the points, do the summation and uses the estimation to filter because that is not robust.",
                    "label": 0
                },
                {
                    "sent": "But try to drive the selection of good correspondence is and we do this by using a game theoretic Miller selection approach where we do have fitness assigned to each set of correspondences correspondences.",
                    "label": 1
                },
                {
                    "sent": "Actually players in the game.",
                    "label": 0
                },
                {
                    "sent": "And we do have fitness is assigned to each.",
                    "label": 0
                },
                {
                    "sent": "Correspondence is depending on how they perform with respect to global consistency measure with respect to other correspondence is so the game is played by two by 2% of correspondences and they do two sets of correspondence can be explained well by a single global probles single global alignment, and then they do get very strong support, otherwise they do get very very low support.",
                    "label": 0
                },
                {
                    "sent": "But in the end.",
                    "label": 1
                },
                {
                    "sent": "And we want to get only those only a small subset of points that are very consistent with one another, so we don't really the point.",
                    "label": 0
                },
                {
                    "sent": "The key point of intersection is, so we have another abundance of post possible correspondences, and we only need a few theoretically only eight to do have good estimation of our transformation, and we actually rather than try to do what run second as that is you pick up.",
                    "label": 0
                },
                {
                    "sent": "And that they can then filter out.",
                    "label": 0
                },
                {
                    "sent": "We want to select those few elements that are and are most consistent with one another and use those and only those.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "To the parameter estimation to the submission of our transformation model.",
                    "label": 0
                },
                {
                    "sent": "Other people geometry.",
                    "label": 1
                },
                {
                    "sent": "So what we do is we actually model correspondence as a strategy and cooperative game and then just let them compete and the rational and irrational laser coherent group will actually be providing high payoff.",
                    "label": 0
                },
                {
                    "sent": "Planner will actually survive this game while driving to extinction.",
                    "label": 0
                },
                {
                    "sent": "Everything else.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have a large set of initial matching features are the possible strategies are we using and we selected with standard techniques annara pliers are there, they're just matching the initial matches or just anything that.",
                    "label": 1
                },
                {
                    "sent": "Exceed a certain threshold in similarities between feature between features in one image and the other, so definitely a lot of Flyers.",
                    "label": 1
                },
                {
                    "sent": "We started with initial population vector which is uniform distribution distributed in the complex initialized inside of the standard complex and we define and metric, see which is where the global information comes in.",
                    "label": 1
                },
                {
                    "sent": "The final each curve strategy and then we have all the population to the replicator equation, which is this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is just an example.",
                    "label": 0
                },
                {
                    "sent": "We have extracted 123456 different correspondences and as we see we can visually see that there are at least two outliers here.",
                    "label": 0
                },
                {
                    "sent": "So reasonably high Larry should the reason we have it is that the.",
                    "label": 0
                },
                {
                    "sent": "Descriptors are found at the similar, so they might obviously only on local information they might actually fit very well, and this is because this is the metrics we get with one particular.",
                    "label": 0
                },
                {
                    "sent": "My considered genetic consistency model will talk about two different models were applied and what do we do when we run?",
                    "label": 0
                },
                {
                    "sent": "We run our evolution.",
                    "label": 0
                },
                {
                    "sent": "We start with equal pretty much equal distribution of.",
                    "label": 0
                },
                {
                    "sent": "The likelihood of the fitness is but then as we as iteration go on those correspondences that are not particularly good here, which is CBCB&EC will actually be driven to extinction and in the end the whole set of correspondences that work well together are extracted as just a subset of the configurations we have.",
                    "label": 0
                },
                {
                    "sent": "That is only a one and a 2B1 and B2D1 and D2LC-1 and C2, while the vertical do match.",
                    "label": 0
                },
                {
                    "sent": "They're not as good as good as good a fit as the other, so also will be driven to extinction and those two correspondence is actually been after.",
                    "label": 0
                },
                {
                    "sent": "Do some form of estimation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we are.",
                    "label": 0
                },
                {
                    "sent": "This people actually comparing two different geometric consistency approaches.",
                    "label": 1
                },
                {
                    "sent": "So two different ways in which we can define the payoff matrix.",
                    "label": 0
                },
                {
                    "sent": "And there are based on the modern person point descriptors, safe service and idea is that we they both require some some local information about orientation, size of the Patch.",
                    "label": 0
                },
                {
                    "sent": "So we could we could have local transformations attached to each point information more and we have two approaches.",
                    "label": 0
                },
                {
                    "sent": "One is a similar approach that extract.",
                    "label": 1
                },
                {
                    "sent": "Local patches that are consistent with a common event information, so we're having we camera perspective or we can find our perspective Locali where we excite local patches of points that are consistent with a single financial information and then we combine them all and second step to obtain the set of full set of the responses and then we have a global approach that has improved consistency with the commentary 3D rigid transformation.",
                    "label": 1
                },
                {
                    "sent": "Actually imposes 3D is ometry, so we don't.",
                    "label": 0
                },
                {
                    "sent": "We don't get allies, the change of quality of the computer over the configuration.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to see the similar similar affine model, well, we need to define a compatibility with respect affinity between pairs of pairs of candidate points, and we use this orientation and scale information, and that point is that this orientation and scale will give us an offender information that Maps the appoint in money image to the correspondent party images.",
                    "label": 1
                },
                {
                    "sent": "So every correspondence will actually imply a particular fine transformation.",
                    "label": 1
                },
                {
                    "sent": "So we're saying that the tourist funds are compatible if they define a similar transformation.",
                    "label": 1
                },
                {
                    "sent": "Various systems wherein this week camera model local, at least in the image, all the transformation from 1 from 1 image to the other within this local Patch must be similar.",
                    "label": 0
                },
                {
                    "sent": "Must be a similar fine transformation.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And how do you do?",
                    "label": 0
                },
                {
                    "sent": "We measure similarity in this event transformation?",
                    "label": 0
                },
                {
                    "sent": "Well, we pretty much create virtual points by applying the transformation estimated in one image to the point corresponding pointing the other images.",
                    "label": 0
                },
                {
                    "sent": "So if we have this correspondence, we apply to a one the correspondence of Maps that let's say this, there is one matching one image, and this one here B1 and B2M as another match another image and we want to confirm them.",
                    "label": 0
                },
                {
                    "sent": "Well, this match here has.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is this information T and this match here.",
                    "label": 0
                },
                {
                    "sent": "It says this resulted in transformation T to see how well they fit, we just transform a the deformation aid with the transformation that Maps B1 and B2 obtain this virtual .8 two prime and see.",
                    "label": 0
                },
                {
                    "sent": "Look at the distance between a prime time A2 and then do the same.",
                    "label": 0
                },
                {
                    "sent": "Here we transform B with their transformation reference from the other points.",
                    "label": 0
                },
                {
                    "sent": "Have this virtual point B2 prime Dancy, the distance between.",
                    "label": 0
                },
                {
                    "sent": "Two priority so that.",
                    "label": 0
                },
                {
                    "sent": "What we do is actually penalize reprojection error between to find transformation and this is important because we we have a measure unit of measure is actually exactly the picture pixel we can go back directly to how many pixels.",
                    "label": 1
                },
                {
                    "sent": "So we do know the meaning at least the meaning of the of the parameters we have.",
                    "label": 1
                },
                {
                    "sent": "So the similarity is the maximum between the two reprojection errors, and then we do have similarities with our adjusted exponential decay of the similarities with.",
                    "label": 0
                },
                {
                    "sent": "Of the projection at maximum protection error.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The there are some limits of this affine model, while of course define assumption sort of works only, but only locally, and so we approach extract only local patches of correspondence points, so all the points that we will get our will be funding pretty much frontal power bar, or at least on a single parallax stack playing plastic plane there will be clustered together, but what we can do is just to repeat the game exacting and use its of correspondences and eliminating.",
                    "label": 1
                },
                {
                    "sent": "Because once we have already.",
                    "label": 0
                },
                {
                    "sent": "It actually we don't only eliminate those correspondences, but all the correspondences that are within the same image region.",
                    "label": 0
                },
                {
                    "sent": "So once we do extract one group of matching correspondences, we just eliminate all groups that are close by in the image.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I said, we've confirmed front in two different global consistency models.",
                    "label": 0
                },
                {
                    "sent": "In this approach.",
                    "label": 0
                },
                {
                    "sent": "The second one is global model that impose common tribute transformation where we want to do impose rigidity.",
                    "label": 0
                },
                {
                    "sent": "That is, we wanted to inquire conservation of these distances between the underlying 3D points.",
                    "label": 1
                },
                {
                    "sent": "And to do that we use again scaling in orientation information about the.",
                    "label": 0
                },
                {
                    "sent": "Use that to create virtual points, the direction and scale given by the descriptors.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the problem we had before is that.",
                    "label": 0
                },
                {
                    "sent": "When we do have a lot of parallax, the we have that uniform 30 motion that is just wrote in translation.",
                    "label": 0
                },
                {
                    "sent": "This transformation will be going from 1 camera views are together.",
                    "label": 0
                },
                {
                    "sent": "We actually imposing unwritten nonuniform transformation in today.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the motion vectors and the two views of the two cameras, we actually have motion lexical go all around the place locally.",
                    "label": 0
                },
                {
                    "sent": "Of course we can have a sort of similar similar find transformation assumption, which is what the first model did.",
                    "label": 0
                },
                {
                    "sent": "But globally that cannot work.",
                    "label": 0
                },
                {
                    "sent": "But what we're trying to do is actually try something that will extract globally the consistent configuration.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we do that is that as I said, we use Karen Orientation.",
                    "label": 0
                },
                {
                    "sent": "Many interesting idea is that scale will offer that the information because variation in scale and all the same Patch into different images will actually indicate it will be inversely proportional to the variation of that between those images and the combination of that scale and orientation will actually give us a second point.",
                    "label": 1
                },
                {
                    "sent": "So we are confronting distances between four points rather than distances between two points.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that we want to consider to conserve the distances that are here in green.",
                    "label": 1
                },
                {
                    "sent": "So we have two these two points with the corresponding virtual points given by the scale orientation of the Patch an we have before possible cross distances between the actual points and virtual points in 3D and we want to keep conserve distances between.",
                    "label": 0
                },
                {
                    "sent": "This this distance is in the two projected images.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem here is at 4 points are actually not enough to fully constrain transformation to extract the people geometry we have, we need at least five points.",
                    "label": 1
                },
                {
                    "sent": "We have a free parameter and the parameter is a parameter Alpha, which is a ratio of scale between the ratio of the Rio three scale of the of the patches were extracted.",
                    "label": 0
                },
                {
                    "sent": "So we've seen the scale in scale.",
                    "label": 0
                },
                {
                    "sent": "We do have our projected scale in the images, but.",
                    "label": 0
                },
                {
                    "sent": "They all correspond to real through the scale of the texture in the Patch and we are just trying to extract.",
                    "label": 0
                },
                {
                    "sent": "Features that have pretty much similar or limited variation in real 3D scale now experiments were limiting variation in 3D scale between 1/2 and two.",
                    "label": 0
                },
                {
                    "sent": "So we the only limit we have in this global consistency approach is that the actual size of the texture we're looking at should be pretty much similar.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so just the math, of course, but once you do have work up everything with corresponding points.",
                    "label": 1
                },
                {
                    "sent": "P1P2P2AP11 and P12 corresponding points in the first set of corresponding points with money, image and the other.",
                    "label": 0
                },
                {
                    "sent": "And we added this as it can be written this way.",
                    "label": 0
                },
                {
                    "sent": "And of course points are corresponding and the virtual points can be extracted using the orientation and.",
                    "label": 1
                },
                {
                    "sent": "Orientation and scale.",
                    "label": 0
                },
                {
                    "sent": "Assuming there is a sort of.",
                    "label": 0
                },
                {
                    "sent": "Almost frontal planner.",
                    "label": 0
                },
                {
                    "sent": "We have a normal so almost front apply assumption on the observed texture and then when we get back to the similarity of the matches, which is of course dependent on this Alpha parameter is actually the sum of the square distances of all of those four points.",
                    "label": 0
                },
                {
                    "sent": "And of course this depends on Alpha and we optimize over over that range of Alpha will range of parameter A that we have given.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to give some experimental results, this is the set of final features extracted by the without 3D rigid approach.",
                    "label": 0
                },
                {
                    "sent": "This is the set of groups with different images are the different local patches of extract with.",
                    "label": 0
                },
                {
                    "sent": "Under today affine loose me local approach and this is the basic bundler key match or used by bundle vary by the bundle or software which is pretty much state of the art right now and here we see that there are some definitely more appliances.",
                    "label": 0
                },
                {
                    "sent": "One mapping the point here to here will actually penalizing give us very bad results right?",
                    "label": 0
                },
                {
                    "sent": "We can have here is we can see here is that we have generally larger number of.",
                    "label": 0
                },
                {
                    "sent": "Good point, we extract with our approach, then became the band wiki, match it as an.",
                    "label": 0
                },
                {
                    "sent": "In general, much lower.",
                    "label": 0
                },
                {
                    "sent": "Angular are both in the angular rotation an of the difference in the axis of rotation.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is another set of experiments in another image.",
                    "label": 0
                },
                {
                    "sent": "Kimmage and again we see that we have much larger number of matches and much lower.",
                    "label": 0
                },
                {
                    "sent": "In the in the estimation of the transformation parameters.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just include, which we presented a game theoretic approach to enforce consistency in feature matching, and the idea is that robustness is achieved by enforcing global consistency in otherwise setting rather than try to do to exactly consistency exposed.",
                    "label": 0
                },
                {
                    "sent": "That is, that only highly compatible matches are enforced where incompatible, incompatible correspondences are driven to extinction.",
                    "label": 0
                },
                {
                    "sent": "At the experimental comparison showed the ability of our approach to obtain very accurate estimates much better than the state of the art provided by the bundler key matcher.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "I have one question.",
                    "label": 0
                },
                {
                    "sent": "Extend the.",
                    "label": 0
                },
                {
                    "sent": "I love you too of local descriptors is K to the success of the of the process.",
                    "label": 0
                },
                {
                    "sent": "For instance, if you have only points.",
                    "label": 0
                },
                {
                    "sent": "2D or 3D.",
                    "label": 0
                },
                {
                    "sent": "We can do well.",
                    "label": 0
                },
                {
                    "sent": "The problem is.",
                    "label": 0
                },
                {
                    "sent": "Only points I did not give enough.",
                    "label": 0
                },
                {
                    "sent": "Consider not constraint solution enough to the for the people solution.",
                    "label": 0
                },
                {
                    "sent": "We could go high order right now that the game is only within two players.",
                    "label": 0
                },
                {
                    "sent": "So to several correspondences we could very well raise the order of correspondences and then we can solve the problem.",
                    "label": 0
                },
                {
                    "sent": "But will of course it raises the complexity of the approach and.",
                    "label": 0
                },
                {
                    "sent": "But the OR if you have different.",
                    "label": 0
                },
                {
                    "sent": "If you have different groups of points rather than that, you know that sort of map together, like bag of points.",
                    "label": 0
                },
                {
                    "sent": "Also, you could work with bag of points, but then you have to know that that class that is a cluster that Maps in that cluster.",
                    "label": 0
                },
                {
                    "sent": "But just points on.",
                    "label": 0
                },
                {
                    "sent": "Otherwise setting is not enough to constrain the perpendicular geometry.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you more questions.",
                    "label": 0
                },
                {
                    "sent": "OK, next send this speaker again.",
                    "label": 0
                }
            ]
        }
    }
}