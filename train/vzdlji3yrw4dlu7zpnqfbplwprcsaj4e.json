{
    "id": "vzdlji3yrw4dlu7zpnqfbplwprcsaj4e",
    "title": "How does Clickthrough Data Reflect Retrieval Quality?",
    "info": {
        "author": [
            "Thorsten Joachims, Department of Computer Science, Cornell University"
        ],
        "published": "Nov. 19, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Information Retrieval"
        ]
    },
    "url": "http://videolectures.net/cikm08_joachims_hdcdrrq/",
    "segmentation": [
        [
            "So this is joint work with Phillip and model at MSR now and at Amazon.",
            "So the key question I want to get in this talk is how can we do evaluation based on observable user?"
        ],
        [
            "So in the simplest evaluation problem, we have the following setup.",
            "We have two retrieval functions.",
            "We wanted to side.",
            "Which one is better?",
            "And let's define better in the following way.",
            "We have a distribution of users and queries and.",
            "Let's for each individual query we have a ranking that each of the two functions produces.",
            "So, for example, a function F1 produces this ranking of two produces that ranking for a query SVM issued by myself.",
            "Each of these ranking as a sort of utility.",
            "And let's say we want to optimize expected utility over this distribution.",
            "Now the question is how we would measure this expected utility.",
            "So the first option, the traditional one, is to get explicit feedback.",
            "So draw a sample of queries and users higher relevance judges to get judgments for individual documents and then have some aggregation methods to come up with the utility of the function.",
            "So for example N DCG.",
            "Well, this is a very well understood methodology, but there are a couple of problems with that.",
            "For example, hiring relevant judgments is something that expensive an it's not feasible to do for small collections.",
            "Definitely not for desktop search or for small Internet.",
            "Because it's expensive, we can only do it for small samples, but I think the main problem is that the judges have to do their judgments based on what they think the users wanted.",
            "They don't actually know what the users wanted in that particular context, so we might get biased results that way.",
            "And finally, the whole process is pretty slow.",
            "It would be much now."
        ],
        [
            "So if we could do evaluation in the following way based on implicit feedback.",
            "So we simply feel these two retrieval functions see how users react to the results, compute some metrics, and then have some model of what these metrics tell us about retrieval quality.",
            "We don't have this problem of this disconnect between judges and users.",
            "Users give us the data themselves in their original context and.",
            "So what they think is relevant.",
            "Computing these metrics is really cheap.",
            "We can do that in a very timely fashion for any size collection.",
            "We can do that for large samples, but clearly the main problem is that this connection between metrics and the utility of the retrieval functions or retrieval quality that's not well understood.",
            "So the key point of this talk where the key question of this talk is, what can we learn about this relationship between observable user behavior and retrieval quality?"
        ],
        [
            "Particularly in address 2 questions, first question is, are there absolute metrics that change monotonically with improved quality?",
            "So for example.",
            "Number of clicks?",
            "Does the number of clicks in the results monotonically increase if I get better and better retrieval quality?",
            "Or does my abandonment rate go down if I get better and better retrieval quality?",
            "Would be great if you had such such indicators.",
            "Second question is, well, if the first one fails, can we design particular experiments and actually run these experiments interactively?",
            "That so that we get information about the relative quality between two retrieval functions, and this is going to lead us to pairwise comparison tests.",
            "So."
        ],
        [
            "Address either of the two questions.",
            "We need a.",
            "We actually need to conduct user studies and we wanted to do this in a kind of natural way.",
            "Have a natural distribution of users and have users kind of use the system in their everyday context, so not invite them to a laugh and give them particular task that they need to do So what we did is we implemented an field it full text search engine for archive.org, archive.org is this repository of research papers roughly half a million and it's the way to get research papers in physics.",
            "I am on the right.",
            "There is a screenshot of the search engine kind of in response to a full text query gives you the title, authors Anna context sensitive snippet looks a lot like a web search engine that way.",
            "Now the key problem is since we don't do it in the lab and kind of in a controlled environment.",
            "That way we have to come up with a way of generating ground truth.",
            "Which retrieval function is actually better than the other, and the way we did that is we had a hand tuned retrieval function.",
            "That's what they called a rig here and then we artificially made it worse.",
            "So for example, we took the ranking produced by or Rick and then randomly swapped 2 results from the top five with results lower down.",
            "So we know that this one is going to give us worse retrieval performance than the original 1, and we made it even worse by swapping for results.",
            "So we get this triplet of retrieval functions or Rick swap two and Swap 4 where we know what can reasonably assume the ordering in terms of retrieval quality.",
            "And we created another triplet in a similar way.",
            "We took this original retrieval function which has different fields, for example for title, author and abstract, and giving different weights to the different fields effectively and replace that with a flat retrieval function that just doesn't have field weights at all.",
            "So it's reasonable to assume that again that's worse and then to create something even worse, we took the results from flat and randomize the order of the top 10.",
            "So we get another triple of retrieval functions.",
            "Red, Flat and brand.",
            "We know the order of retrieval quality."
        ],
        [
            "So now we're in a position to run experiments and see how these observable user metrics changed with retrieval quality.",
            "And so for a period of roughly a month, we feel that.",
            "Gay people result from a rig flat or rent and computer different metrics for another month.",
            "We gave him or Rick swap tunes for four, and users were randomly assigned to one of these retrieval functions based on their IP address.",
            "So they were permanently assigns if they came back they always get the same retrieval function.",
            "They always get the same results that way too, so basic stats, roughly 700 queries per day, three on distinct users, and to set everything up we did a dry run.",
            "In November last year workout all the Kings also to identify get data for identifying things like bots and spammers, mostly bots and actually get realistic to filter those out and just a measure of quality control.",
            "Both Madhu Ann Philip each separately implemented all the evaluation code and then we compare the results to make sure there are no bugs."
        ],
        [
            "So these are the absolute metrics that we consider there kind of what you find often papers, abandonment, rate, the percentage of Christmas, no click and we would expect that the independent rate increases.",
            "If we have worse retrieval quality.",
            "Reformulation rate number queries that I followed by reformulated query again.",
            "We would expect that to increase this decreased retrieval quality queries per session number of clicks per query, but expect that to decrease with decreased retrieval quality Max reciprocal rank.",
            "That's one divided by the rank of the highest rank click mean are simple crank averaged over all ranks of clicks.",
            "Time to first click in time to last week.",
            "So we have these eight metrics and some hypothesis of how they should change."
        ],
        [
            "Here the results.",
            "So in the blue bars you see the first triple red bars is the second triple for all the eight metrics, and these little icons above tell you how they have prophesized.",
            "They would change.",
            "And if you look at that.",
            "That's not clear.",
            "Doesn't really change in the expected way, so let's look at a little more detail."
        ],
        [
            "At least one, obviously.",
            "So there are six different pairs of comparisons in these three triplets, right that we can do and we can check for each pair if the metric changed in the expected way.",
            "So this week this column week with the check Mark tells you for example that abandonment rate changed in the expected way on four of the six pairs and changed it the opposite way on two of the pairs.",
            "And if you look down the first 2 columns, none of these metrics actually change consistently with retrieval quality as we expected.",
            "Now part of the problem is that the changes were actually very small and the data pretty noisy, so the second column set of columns.",
            "Here it looks at significant difference and then the thing looks a little bit better but we didn't get significant results for most of the Pro.",
            "Most of the pairs actually, despite the fact that right amount of data.",
            "So what we conclude from that is that actually none of the metrics perfectly reflected the ordering that we expected.",
            "But most of the difference were actually not significant.",
            "After one month of data and what we can conclude is at least that this is not suitable for kind of archive size search engine.",
            "Definitely not for your decks desktop search.",
            "We would need at least a lot more data."
        ],
        [
            "So now let's go to this pair comparison test.",
            "Now, if you let's say you wanted to decide whether Pepsi is better than Coke, Coca Cola, right?",
            "You would not run the following experiments.",
            "You wouldn't take half of the people and give them Pepsi Cola and then having rate on a scale from 1 to 10, how much they liked it and the other half of the people give Coca Cola and again have them rate under scale from 1 to 10 and then compare the ever trading right.",
            "But that's kind of what we did with these absolute metrics.",
            "What he would do instead is he would give everybody both Pepsi Cola and Coca Cola and ask them which one they prefer and outcomes the standard experiment design in like marketing and sensory analysis and it would be nice if we could do something like that also for web search, right?",
            "If it gives you much more powerful results."
        ],
        [
            "So what we could do is we could, you know, compute both rankings that are presented next to each other and see where people click, but at least that would give you a very.",
            "Well, disruptive presentation."
        ],
        [
            "But we can do something else we can actually get the same effect by presenting only one ranking, and that's where this interleaving technique comes into play.",
            "Um?",
            "What we're going to do is we're going to compute 2 rankings, but then present only one interleaf ranking to the user in this interleaf ranking has the property that every cut off point the user has seen the top K from ranking one as well at the top K + -- 1 from ranking two.",
            "So here's how you can construct this ranking.",
            "So let's first flip a coin and let's say if 2 gets to go first.",
            "So F2 would put the 1st result into the interleaved ranking.",
            "Now if one gets to go, oh, it's the same result.",
            "Now we have this invariant property that the top one result is the Union of the top one from our one and the top one from our two flip a coin who gets to go next.",
            "So in that order, maybe and again we have this invariant property, the top three in the interleaved ranking are the Union of the top two of the individual rankings and so on.",
            "So you can construct a ranking in that in that fashion.",
            "And now we can look at.",
            "Where do people click in this interleaved ranking right?",
            "Let's say they clicked on one, three, and seven.",
            "Now we know that they've seen the top four from F1, the top four from F2.",
            "Now we can trace back where the clicks came from, right?",
            "And we see our three of the clicks were actually in the top.",
            "4R2 was only one was in the top four of our one.",
            "So we say our one Earth sorry are two wins in this time in comparison.",
            "Right, so we get this pairwise preference test this way."
        ],
        [
            "There's only one problem.",
            "And we can have by us.",
            "So let's take these two rankings ABCD, and the same ranking but with an X in additional document inserted on the top.",
            "So we compute the.",
            "That's what we called balanced interleaving.",
            "Um?",
            "Now let's consider a random user that just randomly clicks on one of the results in the top five in the interleaved ranking.",
            "So let's say user clicks on the 1st result on X.",
            "Now we can trace back that corresponds to the Union of the top ones, and in this case are two wins, right?",
            "But it clicks on the second rank, second link again a correspond to the Union of the top one and now our one wins on the third link.",
            "Now we're starting to see the problem right.",
            "Clicks on B.",
            "That means the Union of the top two and R1 wins, and this is not going to change anymore, right?",
            "Always going to be that one wins in this situation.",
            "So despite the fact that we now have a randomly clicking user will create a preference for our one.",
            "So we have a bias in here, but it's actually comes not from the interleaving, but from the way we're estimating the cut offs, but that's a different story.",
            "Now the question is, can we come up with interleaving technique that doesn't have this problem?"
        ],
        [
            "Um?",
            "And what proposed in this paper is what we call team game interleaving.",
            "Similar idea we want to create an interleaved ranking, but we're going to do it in a different way, roughly the same way as you would pick teams in a soccer match, like a pickup soccer match.",
            "At least that's what we did in Germany when I grew up.",
            "We would flip a coin on who gets to go first, so we have two team captains and so each of the team captains now has a preference order.",
            "That's exactly the ranking that they have.",
            "Let's say team Captain #2 gets to go first and he would pick the team member that's highest on his preference order.",
            "So that would be the link.",
            "Kernel machines put that into the interleaved ranking and so this link is now on the team too.",
            "Right now the other player gets to go.",
            "Most preferred guy is taken so it takes the next one.",
            "Support vector machine that link and now that link is on team number one.",
            "Flip a coin again.",
            "Who gets to go next?",
            "Maybe Team 2 gets to go next picks the highest rank guy that is not taken yet.",
            "Puts it on the ranking and it's in team two and so on.",
            "So, um.",
            "We get this interleaf ranking now and each link isn't exactly one team.",
            "And now when we get clicks, we can score kind of on a team basis.",
            "So here all the clicks were actually on players from team two.",
            "So team two wins in this direct comparison and it can easily see that this doesn't have this bias problem.",
            "So Even so randomly clicking user will not create a preference in either way."
        ],
        [
            "So.",
            "We've tried these pairwise comparison comparison tests in the same archive setup, in particular at the same time as we did for the.",
            "For the absolute metrics we we presented, these interleaf pairs between original and flat, flat and Rand random and original to each one, 6th of the user base, and scored how often each of those one we did the same in phase two for swap two and swap four and in Phase three we tried the team game interleaving so this other interleaving techniques in the very same way.",
            "Otherwise the experiment setup is exactly the same."
        ],
        [
            "So here are the results for this first interleaving technique, balanced interleaving, and I've ordered the pair so that the better retrieval function is always corresponding to the left bar, and each of these bars shows the percentage of games that are one.",
            "The percentage of queries that are one.",
            "So for example, this bar shows how often does original Percentagewise win against rent and the right hand bar shows how often does rent win against original in this direct comparison so?",
            "Our part of this is that the left bar is always greater than the right bar, which is perfectly replicated here.",
            "So all of these methods actually.",
            "Exactly show the desired order or the expected water and all of these differences are actually statistically significant.",
            "So despite the fact that there is a theoretical problem is biased, interleaving it doesn't seem to be a problem in practice here."
        ],
        [
            "The results for the team game interleaving and it's again the same in all cases.",
            "Kind of the right function wins.",
            "The better retrieval quality function wins.",
            "Here these results are significant at 95% confidence level.",
            "The two other ones here are barely not significant there, but they are significant in the 90% confidence level, so our conclusion is that.",
            "These parent comparison tests actually perfectly reflect the desired order.",
            "Most of the differences are significant after one month, and we also played around with different, you know, data cleaning techniques and different ways of aggregating the data and essentially always got the same results, so it's much more robust than the.",
            "Then the then the absolute metrics and.",
            "I mean it like a bot really doesn't matter here.",
            "It will give you a preference, but in a random order, at least for team game interleaving, whereas a bot can really screw up your measurement of click through rate as an absolute measure.",
            "And from practice perspective doing this, interleaving gives you if you have one good retrieval function and you're trying another one.",
            "You can't really screw up the results to bad.",
            "I mean you always get like half of the results from that retrieval function."
        ],
        [
            "So future work is depression of how we can do learning of the setting and we started to do some work on that.",
            "What if you can only do pairwise comparisons?",
            "You get this exploration exploitation problem of which comparison to do next, so that eventually you find the best retrieval function in the whole space of learning.",
            "Is this kind of just evaluation on steroids?",
            "In a sense we call that the dueling bandit problem and it actually turns out that you can do this kind of learning.",
            "Much more efficiently than in this N squared comparison that you might not.",
            "If you think that would be necessary.",
            "Actually can do it."
        ],
        [
            "So let me summarize.",
            "These absolute interpretations we found to, at least for the data set sizes that we had not to be reliable, doesn't mean that if we had lots more data, like a web search engine, that they would give you the correct indication.",
            "The pair comparison tests give on the other hand, very reliable and significant data, and I think a lot of interesting questions and one I want to point out is the verification of other domains fill up.",
            "It actually put all this search engine code online so you can download it and try it on your own collection.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is joint work with Phillip and model at MSR now and at Amazon.",
                    "label": 0
                },
                {
                    "sent": "So the key question I want to get in this talk is how can we do evaluation based on observable user?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the simplest evaluation problem, we have the following setup.",
                    "label": 0
                },
                {
                    "sent": "We have two retrieval functions.",
                    "label": 1
                },
                {
                    "sent": "We wanted to side.",
                    "label": 0
                },
                {
                    "sent": "Which one is better?",
                    "label": 0
                },
                {
                    "sent": "And let's define better in the following way.",
                    "label": 1
                },
                {
                    "sent": "We have a distribution of users and queries and.",
                    "label": 0
                },
                {
                    "sent": "Let's for each individual query we have a ranking that each of the two functions produces.",
                    "label": 0
                },
                {
                    "sent": "So, for example, a function F1 produces this ranking of two produces that ranking for a query SVM issued by myself.",
                    "label": 0
                },
                {
                    "sent": "Each of these ranking as a sort of utility.",
                    "label": 0
                },
                {
                    "sent": "And let's say we want to optimize expected utility over this distribution.",
                    "label": 1
                },
                {
                    "sent": "Now the question is how we would measure this expected utility.",
                    "label": 0
                },
                {
                    "sent": "So the first option, the traditional one, is to get explicit feedback.",
                    "label": 1
                },
                {
                    "sent": "So draw a sample of queries and users higher relevance judges to get judgments for individual documents and then have some aggregation methods to come up with the utility of the function.",
                    "label": 0
                },
                {
                    "sent": "So for example N DCG.",
                    "label": 0
                },
                {
                    "sent": "Well, this is a very well understood methodology, but there are a couple of problems with that.",
                    "label": 0
                },
                {
                    "sent": "For example, hiring relevant judgments is something that expensive an it's not feasible to do for small collections.",
                    "label": 1
                },
                {
                    "sent": "Definitely not for desktop search or for small Internet.",
                    "label": 0
                },
                {
                    "sent": "Because it's expensive, we can only do it for small samples, but I think the main problem is that the judges have to do their judgments based on what they think the users wanted.",
                    "label": 0
                },
                {
                    "sent": "They don't actually know what the users wanted in that particular context, so we might get biased results that way.",
                    "label": 0
                },
                {
                    "sent": "And finally, the whole process is pretty slow.",
                    "label": 0
                },
                {
                    "sent": "It would be much now.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we could do evaluation in the following way based on implicit feedback.",
                    "label": 0
                },
                {
                    "sent": "So we simply feel these two retrieval functions see how users react to the results, compute some metrics, and then have some model of what these metrics tell us about retrieval quality.",
                    "label": 1
                },
                {
                    "sent": "We don't have this problem of this disconnect between judges and users.",
                    "label": 0
                },
                {
                    "sent": "Users give us the data themselves in their original context and.",
                    "label": 0
                },
                {
                    "sent": "So what they think is relevant.",
                    "label": 0
                },
                {
                    "sent": "Computing these metrics is really cheap.",
                    "label": 0
                },
                {
                    "sent": "We can do that in a very timely fashion for any size collection.",
                    "label": 0
                },
                {
                    "sent": "We can do that for large samples, but clearly the main problem is that this connection between metrics and the utility of the retrieval functions or retrieval quality that's not well understood.",
                    "label": 0
                },
                {
                    "sent": "So the key point of this talk where the key question of this talk is, what can we learn about this relationship between observable user behavior and retrieval quality?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particularly in address 2 questions, first question is, are there absolute metrics that change monotonically with improved quality?",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "Number of clicks?",
                    "label": 0
                },
                {
                    "sent": "Does the number of clicks in the results monotonically increase if I get better and better retrieval quality?",
                    "label": 0
                },
                {
                    "sent": "Or does my abandonment rate go down if I get better and better retrieval quality?",
                    "label": 0
                },
                {
                    "sent": "Would be great if you had such such indicators.",
                    "label": 0
                },
                {
                    "sent": "Second question is, well, if the first one fails, can we design particular experiments and actually run these experiments interactively?",
                    "label": 0
                },
                {
                    "sent": "That so that we get information about the relative quality between two retrieval functions, and this is going to lead us to pairwise comparison tests.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Address either of the two questions.",
                    "label": 0
                },
                {
                    "sent": "We need a.",
                    "label": 0
                },
                {
                    "sent": "We actually need to conduct user studies and we wanted to do this in a kind of natural way.",
                    "label": 0
                },
                {
                    "sent": "Have a natural distribution of users and have users kind of use the system in their everyday context, so not invite them to a laugh and give them particular task that they need to do So what we did is we implemented an field it full text search engine for archive.org, archive.org is this repository of research papers roughly half a million and it's the way to get research papers in physics.",
                    "label": 0
                },
                {
                    "sent": "I am on the right.",
                    "label": 0
                },
                {
                    "sent": "There is a screenshot of the search engine kind of in response to a full text query gives you the title, authors Anna context sensitive snippet looks a lot like a web search engine that way.",
                    "label": 0
                },
                {
                    "sent": "Now the key problem is since we don't do it in the lab and kind of in a controlled environment.",
                    "label": 0
                },
                {
                    "sent": "That way we have to come up with a way of generating ground truth.",
                    "label": 0
                },
                {
                    "sent": "Which retrieval function is actually better than the other, and the way we did that is we had a hand tuned retrieval function.",
                    "label": 0
                },
                {
                    "sent": "That's what they called a rig here and then we artificially made it worse.",
                    "label": 0
                },
                {
                    "sent": "So for example, we took the ranking produced by or Rick and then randomly swapped 2 results from the top five with results lower down.",
                    "label": 0
                },
                {
                    "sent": "So we know that this one is going to give us worse retrieval performance than the original 1, and we made it even worse by swapping for results.",
                    "label": 0
                },
                {
                    "sent": "So we get this triplet of retrieval functions or Rick swap two and Swap 4 where we know what can reasonably assume the ordering in terms of retrieval quality.",
                    "label": 0
                },
                {
                    "sent": "And we created another triplet in a similar way.",
                    "label": 0
                },
                {
                    "sent": "We took this original retrieval function which has different fields, for example for title, author and abstract, and giving different weights to the different fields effectively and replace that with a flat retrieval function that just doesn't have field weights at all.",
                    "label": 0
                },
                {
                    "sent": "So it's reasonable to assume that again that's worse and then to create something even worse, we took the results from flat and randomize the order of the top 10.",
                    "label": 0
                },
                {
                    "sent": "So we get another triple of retrieval functions.",
                    "label": 0
                },
                {
                    "sent": "Red, Flat and brand.",
                    "label": 0
                },
                {
                    "sent": "We know the order of retrieval quality.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we're in a position to run experiments and see how these observable user metrics changed with retrieval quality.",
                    "label": 0
                },
                {
                    "sent": "And so for a period of roughly a month, we feel that.",
                    "label": 0
                },
                {
                    "sent": "Gay people result from a rig flat or rent and computer different metrics for another month.",
                    "label": 0
                },
                {
                    "sent": "We gave him or Rick swap tunes for four, and users were randomly assigned to one of these retrieval functions based on their IP address.",
                    "label": 0
                },
                {
                    "sent": "So they were permanently assigns if they came back they always get the same retrieval function.",
                    "label": 0
                },
                {
                    "sent": "They always get the same results that way too, so basic stats, roughly 700 queries per day, three on distinct users, and to set everything up we did a dry run.",
                    "label": 0
                },
                {
                    "sent": "In November last year workout all the Kings also to identify get data for identifying things like bots and spammers, mostly bots and actually get realistic to filter those out and just a measure of quality control.",
                    "label": 0
                },
                {
                    "sent": "Both Madhu Ann Philip each separately implemented all the evaluation code and then we compare the results to make sure there are no bugs.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the absolute metrics that we consider there kind of what you find often papers, abandonment, rate, the percentage of Christmas, no click and we would expect that the independent rate increases.",
                    "label": 0
                },
                {
                    "sent": "If we have worse retrieval quality.",
                    "label": 0
                },
                {
                    "sent": "Reformulation rate number queries that I followed by reformulated query again.",
                    "label": 0
                },
                {
                    "sent": "We would expect that to increase this decreased retrieval quality queries per session number of clicks per query, but expect that to decrease with decreased retrieval quality Max reciprocal rank.",
                    "label": 0
                },
                {
                    "sent": "That's one divided by the rank of the highest rank click mean are simple crank averaged over all ranks of clicks.",
                    "label": 0
                },
                {
                    "sent": "Time to first click in time to last week.",
                    "label": 0
                },
                {
                    "sent": "So we have these eight metrics and some hypothesis of how they should change.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here the results.",
                    "label": 0
                },
                {
                    "sent": "So in the blue bars you see the first triple red bars is the second triple for all the eight metrics, and these little icons above tell you how they have prophesized.",
                    "label": 0
                },
                {
                    "sent": "They would change.",
                    "label": 0
                },
                {
                    "sent": "And if you look at that.",
                    "label": 0
                },
                {
                    "sent": "That's not clear.",
                    "label": 0
                },
                {
                    "sent": "Doesn't really change in the expected way, so let's look at a little more detail.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At least one, obviously.",
                    "label": 0
                },
                {
                    "sent": "So there are six different pairs of comparisons in these three triplets, right that we can do and we can check for each pair if the metric changed in the expected way.",
                    "label": 0
                },
                {
                    "sent": "So this week this column week with the check Mark tells you for example that abandonment rate changed in the expected way on four of the six pairs and changed it the opposite way on two of the pairs.",
                    "label": 0
                },
                {
                    "sent": "And if you look down the first 2 columns, none of these metrics actually change consistently with retrieval quality as we expected.",
                    "label": 0
                },
                {
                    "sent": "Now part of the problem is that the changes were actually very small and the data pretty noisy, so the second column set of columns.",
                    "label": 0
                },
                {
                    "sent": "Here it looks at significant difference and then the thing looks a little bit better but we didn't get significant results for most of the Pro.",
                    "label": 0
                },
                {
                    "sent": "Most of the pairs actually, despite the fact that right amount of data.",
                    "label": 0
                },
                {
                    "sent": "So what we conclude from that is that actually none of the metrics perfectly reflected the ordering that we expected.",
                    "label": 0
                },
                {
                    "sent": "But most of the difference were actually not significant.",
                    "label": 0
                },
                {
                    "sent": "After one month of data and what we can conclude is at least that this is not suitable for kind of archive size search engine.",
                    "label": 0
                },
                {
                    "sent": "Definitely not for your decks desktop search.",
                    "label": 0
                },
                {
                    "sent": "We would need at least a lot more data.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's go to this pair comparison test.",
                    "label": 0
                },
                {
                    "sent": "Now, if you let's say you wanted to decide whether Pepsi is better than Coke, Coca Cola, right?",
                    "label": 0
                },
                {
                    "sent": "You would not run the following experiments.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't take half of the people and give them Pepsi Cola and then having rate on a scale from 1 to 10, how much they liked it and the other half of the people give Coca Cola and again have them rate under scale from 1 to 10 and then compare the ever trading right.",
                    "label": 0
                },
                {
                    "sent": "But that's kind of what we did with these absolute metrics.",
                    "label": 0
                },
                {
                    "sent": "What he would do instead is he would give everybody both Pepsi Cola and Coca Cola and ask them which one they prefer and outcomes the standard experiment design in like marketing and sensory analysis and it would be nice if we could do something like that also for web search, right?",
                    "label": 0
                },
                {
                    "sent": "If it gives you much more powerful results.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we could do is we could, you know, compute both rankings that are presented next to each other and see where people click, but at least that would give you a very.",
                    "label": 0
                },
                {
                    "sent": "Well, disruptive presentation.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we can do something else we can actually get the same effect by presenting only one ranking, and that's where this interleaving technique comes into play.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What we're going to do is we're going to compute 2 rankings, but then present only one interleaf ranking to the user in this interleaf ranking has the property that every cut off point the user has seen the top K from ranking one as well at the top K + -- 1 from ranking two.",
                    "label": 0
                },
                {
                    "sent": "So here's how you can construct this ranking.",
                    "label": 0
                },
                {
                    "sent": "So let's first flip a coin and let's say if 2 gets to go first.",
                    "label": 0
                },
                {
                    "sent": "So F2 would put the 1st result into the interleaved ranking.",
                    "label": 0
                },
                {
                    "sent": "Now if one gets to go, oh, it's the same result.",
                    "label": 0
                },
                {
                    "sent": "Now we have this invariant property that the top one result is the Union of the top one from our one and the top one from our two flip a coin who gets to go next.",
                    "label": 0
                },
                {
                    "sent": "So in that order, maybe and again we have this invariant property, the top three in the interleaved ranking are the Union of the top two of the individual rankings and so on.",
                    "label": 0
                },
                {
                    "sent": "So you can construct a ranking in that in that fashion.",
                    "label": 0
                },
                {
                    "sent": "And now we can look at.",
                    "label": 0
                },
                {
                    "sent": "Where do people click in this interleaved ranking right?",
                    "label": 0
                },
                {
                    "sent": "Let's say they clicked on one, three, and seven.",
                    "label": 0
                },
                {
                    "sent": "Now we know that they've seen the top four from F1, the top four from F2.",
                    "label": 0
                },
                {
                    "sent": "Now we can trace back where the clicks came from, right?",
                    "label": 0
                },
                {
                    "sent": "And we see our three of the clicks were actually in the top.",
                    "label": 0
                },
                {
                    "sent": "4R2 was only one was in the top four of our one.",
                    "label": 0
                },
                {
                    "sent": "So we say our one Earth sorry are two wins in this time in comparison.",
                    "label": 0
                },
                {
                    "sent": "Right, so we get this pairwise preference test this way.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's only one problem.",
                    "label": 0
                },
                {
                    "sent": "And we can have by us.",
                    "label": 0
                },
                {
                    "sent": "So let's take these two rankings ABCD, and the same ranking but with an X in additional document inserted on the top.",
                    "label": 0
                },
                {
                    "sent": "So we compute the.",
                    "label": 0
                },
                {
                    "sent": "That's what we called balanced interleaving.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Now let's consider a random user that just randomly clicks on one of the results in the top five in the interleaved ranking.",
                    "label": 1
                },
                {
                    "sent": "So let's say user clicks on the 1st result on X.",
                    "label": 0
                },
                {
                    "sent": "Now we can trace back that corresponds to the Union of the top ones, and in this case are two wins, right?",
                    "label": 0
                },
                {
                    "sent": "But it clicks on the second rank, second link again a correspond to the Union of the top one and now our one wins on the third link.",
                    "label": 1
                },
                {
                    "sent": "Now we're starting to see the problem right.",
                    "label": 0
                },
                {
                    "sent": "Clicks on B.",
                    "label": 0
                },
                {
                    "sent": "That means the Union of the top two and R1 wins, and this is not going to change anymore, right?",
                    "label": 0
                },
                {
                    "sent": "Always going to be that one wins in this situation.",
                    "label": 0
                },
                {
                    "sent": "So despite the fact that we now have a randomly clicking user will create a preference for our one.",
                    "label": 0
                },
                {
                    "sent": "So we have a bias in here, but it's actually comes not from the interleaving, but from the way we're estimating the cut offs, but that's a different story.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, can we come up with interleaving technique that doesn't have this problem?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And what proposed in this paper is what we call team game interleaving.",
                    "label": 0
                },
                {
                    "sent": "Similar idea we want to create an interleaved ranking, but we're going to do it in a different way, roughly the same way as you would pick teams in a soccer match, like a pickup soccer match.",
                    "label": 0
                },
                {
                    "sent": "At least that's what we did in Germany when I grew up.",
                    "label": 0
                },
                {
                    "sent": "We would flip a coin on who gets to go first, so we have two team captains and so each of the team captains now has a preference order.",
                    "label": 0
                },
                {
                    "sent": "That's exactly the ranking that they have.",
                    "label": 0
                },
                {
                    "sent": "Let's say team Captain #2 gets to go first and he would pick the team member that's highest on his preference order.",
                    "label": 0
                },
                {
                    "sent": "So that would be the link.",
                    "label": 0
                },
                {
                    "sent": "Kernel machines put that into the interleaved ranking and so this link is now on the team too.",
                    "label": 0
                },
                {
                    "sent": "Right now the other player gets to go.",
                    "label": 0
                },
                {
                    "sent": "Most preferred guy is taken so it takes the next one.",
                    "label": 0
                },
                {
                    "sent": "Support vector machine that link and now that link is on team number one.",
                    "label": 0
                },
                {
                    "sent": "Flip a coin again.",
                    "label": 0
                },
                {
                    "sent": "Who gets to go next?",
                    "label": 0
                },
                {
                    "sent": "Maybe Team 2 gets to go next picks the highest rank guy that is not taken yet.",
                    "label": 0
                },
                {
                    "sent": "Puts it on the ranking and it's in team two and so on.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "We get this interleaf ranking now and each link isn't exactly one team.",
                    "label": 0
                },
                {
                    "sent": "And now when we get clicks, we can score kind of on a team basis.",
                    "label": 0
                },
                {
                    "sent": "So here all the clicks were actually on players from team two.",
                    "label": 0
                },
                {
                    "sent": "So team two wins in this direct comparison and it can easily see that this doesn't have this bias problem.",
                    "label": 0
                },
                {
                    "sent": "So Even so randomly clicking user will not create a preference in either way.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We've tried these pairwise comparison comparison tests in the same archive setup, in particular at the same time as we did for the.",
                    "label": 0
                },
                {
                    "sent": "For the absolute metrics we we presented, these interleaf pairs between original and flat, flat and Rand random and original to each one, 6th of the user base, and scored how often each of those one we did the same in phase two for swap two and swap four and in Phase three we tried the team game interleaving so this other interleaving techniques in the very same way.",
                    "label": 0
                },
                {
                    "sent": "Otherwise the experiment setup is exactly the same.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are the results for this first interleaving technique, balanced interleaving, and I've ordered the pair so that the better retrieval function is always corresponding to the left bar, and each of these bars shows the percentage of games that are one.",
                    "label": 0
                },
                {
                    "sent": "The percentage of queries that are one.",
                    "label": 0
                },
                {
                    "sent": "So for example, this bar shows how often does original Percentagewise win against rent and the right hand bar shows how often does rent win against original in this direct comparison so?",
                    "label": 0
                },
                {
                    "sent": "Our part of this is that the left bar is always greater than the right bar, which is perfectly replicated here.",
                    "label": 0
                },
                {
                    "sent": "So all of these methods actually.",
                    "label": 0
                },
                {
                    "sent": "Exactly show the desired order or the expected water and all of these differences are actually statistically significant.",
                    "label": 0
                },
                {
                    "sent": "So despite the fact that there is a theoretical problem is biased, interleaving it doesn't seem to be a problem in practice here.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results for the team game interleaving and it's again the same in all cases.",
                    "label": 0
                },
                {
                    "sent": "Kind of the right function wins.",
                    "label": 0
                },
                {
                    "sent": "The better retrieval quality function wins.",
                    "label": 0
                },
                {
                    "sent": "Here these results are significant at 95% confidence level.",
                    "label": 0
                },
                {
                    "sent": "The two other ones here are barely not significant there, but they are significant in the 90% confidence level, so our conclusion is that.",
                    "label": 0
                },
                {
                    "sent": "These parent comparison tests actually perfectly reflect the desired order.",
                    "label": 1
                },
                {
                    "sent": "Most of the differences are significant after one month, and we also played around with different, you know, data cleaning techniques and different ways of aggregating the data and essentially always got the same results, so it's much more robust than the.",
                    "label": 1
                },
                {
                    "sent": "Then the then the absolute metrics and.",
                    "label": 0
                },
                {
                    "sent": "I mean it like a bot really doesn't matter here.",
                    "label": 0
                },
                {
                    "sent": "It will give you a preference, but in a random order, at least for team game interleaving, whereas a bot can really screw up your measurement of click through rate as an absolute measure.",
                    "label": 0
                },
                {
                    "sent": "And from practice perspective doing this, interleaving gives you if you have one good retrieval function and you're trying another one.",
                    "label": 0
                },
                {
                    "sent": "You can't really screw up the results to bad.",
                    "label": 0
                },
                {
                    "sent": "I mean you always get like half of the results from that retrieval function.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So future work is depression of how we can do learning of the setting and we started to do some work on that.",
                    "label": 0
                },
                {
                    "sent": "What if you can only do pairwise comparisons?",
                    "label": 0
                },
                {
                    "sent": "You get this exploration exploitation problem of which comparison to do next, so that eventually you find the best retrieval function in the whole space of learning.",
                    "label": 1
                },
                {
                    "sent": "Is this kind of just evaluation on steroids?",
                    "label": 1
                },
                {
                    "sent": "In a sense we call that the dueling bandit problem and it actually turns out that you can do this kind of learning.",
                    "label": 0
                },
                {
                    "sent": "Much more efficiently than in this N squared comparison that you might not.",
                    "label": 0
                },
                {
                    "sent": "If you think that would be necessary.",
                    "label": 0
                },
                {
                    "sent": "Actually can do it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me summarize.",
                    "label": 0
                },
                {
                    "sent": "These absolute interpretations we found to, at least for the data set sizes that we had not to be reliable, doesn't mean that if we had lots more data, like a web search engine, that they would give you the correct indication.",
                    "label": 0
                },
                {
                    "sent": "The pair comparison tests give on the other hand, very reliable and significant data, and I think a lot of interesting questions and one I want to point out is the verification of other domains fill up.",
                    "label": 1
                },
                {
                    "sent": "It actually put all this search engine code online so you can download it and try it on your own collection.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}