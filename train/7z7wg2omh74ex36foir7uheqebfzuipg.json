{
    "id": "7z7wg2omh74ex36foir7uheqebfzuipg",
    "title": "Learning with Kernels",
    "info": {
        "author": [
            "Bernhard Sch\u00f6lkopf, Max Planck Institute for Biological Cybernetics, Max Planck Institute"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "February 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods"
        ]
    },
    "url": "http://videolectures.net/mlss06au_scholkopf_lk/",
    "segmentation": [
        [
            "Introduction.",
            "Doc told me.",
            "Myself.",
            "Watching your video.",
            "I don't know whether anybody will be watching these tapes, but.",
            "I'm done.",
            "I've studied physics and mathematics and other PhD in computer science and walked into machine learning.",
            "At the end of my studies and my PhD already in machine learning.",
            "The less we have left the market used to be at that time.",
            "Advisor and officially I got my PhD from the University in belief that Technical University values.",
            "Afterwards I spent some time in early in Cambridge, UK and New York.",
            "And now I'm just very close to where I come from.",
            "I'm running a chi learning empirical inference departments.",
            "So I want to talk about learning with kernels, but before I actually start would be nice to be delicious idea who's here and what kind of background you have.",
            "So maybe I can up around with this.",
            "Is there anybody who has been to a machine learning summer school before?",
            "OK, that's good because I'm gonna reuse the slice that I've used before.",
            "Australia before.",
            "Anybody has already seen a kangaroo?",
            "So maybe the background service who has a degree in doesn't yet have a first degree.",
            "Do we have undergraduates?",
            "And who?",
            "Doesn't have a PhD.",
            "PhD students, let's talk about this subject.",
            "Computer science.",
            "Mathematics.",
            "Physics.",
            "Engineering.",
            "Psychology.",
            "Biology.",
            "Anything else?",
            "Any other topics?",
            "OK, and so those who are doing a PC, how many already doing their own research.",
            "How many are there in research in machine learning?",
            "How many have already run support vector machine on some datasets?",
            "So I'm trying to adjust the speed of my my lecture, so you probably won't be successful, so you'll have to tell me whether I should go faster or more slowly.",
            "So chances are that I might go too slowly, but my experience is better to start to slowly and then going to speed up a little bit, because if you miss the beginning then.",
            "Many of you might be.",
            "How many of you is now in the middle of the night?",
            "Or or make evening or something like that.",
            "How many?",
            "Australia.",
            "OK, so I guess half you will be challenged now.",
            "Like this?",
            "Just put it up on something and then we fall asleep.",
            "OK so you can interrupt me at anytime and I have too many slides anyway, so I'll have to skip something so we can do it interactively if you like.",
            "I haven't yet.",
            "I was already going for five nights.",
            "Missed.",
            "Something should show up now.",
            "So I was planning.",
            "Maybe this morning?",
            "Because it doesn't take too much time.",
            "ISBN's screen.",
            "OK, so."
        ],
        [
            "So I will start with some elements of statistical learning theory and then move on.",
            "Probably tomorrow morning journals and feature spaces reproducing kernel spaces.",
            "And the day After's Public Library."
        ],
        [
            "And maybe some applications.",
            "OK, so I want to start with just an introduction to somebody that is a machine learning and then."
        ],
        [
            "Some elements of learning theory.",
            "Type introduction and so.",
            "Let's assume we have sets of inputs and outputs.",
            "Sunsets were thinking of learning from data pairs, inputs, outputs and inputs are.",
            "Another task was to be taken from these two sets, calligraphic XY and for trading were given a set of M. Such pairs taken from input in output space or input and output set, and.",
            "In learning we are interested in something that people call generalization.",
            "So given an X point that we haven't seen before.",
            "Given an excellent we have seen before, we would like to find suitable why?",
            "What does that mean?",
            "It means that this PAREXEL agency somehow similar.",
            "Examples that we see.",
            "Then of course you could ask how we measure this similarity, and there are many different answers to this question and the people that are starting kernels in tabular way to measure such similarity on the inputs on the X is a Colonel in the outputs.",
            "It's usually a loss function, so for instance the articles could be just plus minus one, but it could also be something more complicated.",
            "In fact, it could also be a kernel.",
            "I'm not sure whether I will talk about that, but simplicity.",
            "Let's assume outputs might be.",
            "In which case we are talking about something called binary pattern recognition.",
            "And the inputs are compares using a kernel."
        ],
        [
            "Stop for some requirements like this.",
            "We would like to similarity measure to be symmetric function.",
            "So.",
            "XNXX prime prices.",
            "In the special case where all input set is just after the end, we could use something like that.",
            "Those products can only for both product and by this notation.",
            "With this angular brackets and denoting so this X in the brackets up.",
            "I mean I entry of X.",
            "So this is just the sum over the product of corresponding entries of these inputs.",
            "Pictures within projectors now.",
            "This of course applies only in the case where we have a space in which we can kind of products in this.",
            "In this case it was the Euclidean space after the end, but if we don't have the product space, what are we gonna do?",
            "People assume that our similarity measure K has at least a representation as a dot product in some space.",
            "So in a doctor, Rackspace Dot product spaces, in particular vector space or linear space and use the space in vector space interchangeably and by this representation I mean I mean.",
            "There exists a map by that takes our inputs, Maps them into a door, correct space such that if I take 2 inputs X&X prime mapping both into that space and then take the dot product.",
            "This is supposed to be the same as taking the curl on Exit Explorer.",
            "So this cave is similarity measure has a representation as a product.",
            "And the representation is nothing 5.",
            "Sometimes we call the feature map.",
            "So if this is the case, if we have such a similarity measure, and if we use it, that's even ever to measure, then we can think of our inputs.",
            "Sometimes I'm going to use some patterns for the inputs we didn't think of our inputs.",
            "Actually yes 5X5 X plan, because that's the one that we're working within.",
            "The DOT product space, so all our inputs will be transformed into that space.",
            "We think of our inputs as our patterns as these things, and in that case our patterns are actually vectors in space and we can carry out to your metric algorithms in there so we can do whatever we can do using geometric means.",
            "I've already mentioned this."
        ],
        [
            "Features.",
            "So here's a simple example of an algorithm of geometric items that aren't meant for carry out and.",
            "Interesting.",
            "I came up with this example when I was writing the introduction of our book.",
            "You've seen the title page before.",
            "I just look at example, but it turns out it's not so well.",
            "It is trivial, but it's.",
            "Useful next week.",
            "Who is taking these ideas much further and constructing interesting statistical tests based on something very similar?",
            "So sometimes some very simple idea can already take you very far in pushing the machinery is not tested.",
            "Specialized branches of mathematics, so sometimes you think well about something you could already make progress even if you haven't studied the fuse for five years.",
            "So anyway, this is a simple algorithm for classification for binary classification or binary passenger conditions.",
            "So we're assuming we have given two classes of objects here, the pluses and over here we have these circles and we want to classify or we want to find additional rules separating these two classes such that if we give you a new point, this point, let's call this point X and assume it's down here.",
            "Assignments test 1212 tasks based on these training data, we want to start the decision.",
            "For instance this straight line and then use this decision rule to sign this point X one of the two classes.",
            "So here the simplest.",
            "Do it assuming that all points live in such a dark product space, which we can assume right?",
            "Because we have this representation 5.",
            "The simplest way to do it would be first compute the mean of all positive points from its C plus.",
            "So this is the mean.",
            "So we are summing over all points that have positive plus one plus the label, why I?",
            "The points in the feature space.",
            "Divided by the number of such points for doing the same for the negative points, this is the number of negative points we get this Point C minus and then we will simply check whether our test point X is closer to C plus or closer to the minus.",
            "Pending on.",
            "So we can do this in various ways, and one way to do it would be just to compute this Point C, which is halfway in between C minus in C plus, and then we can compute a vector of connecting C to artist point X.",
            "And then we can check whether this vector encloses an angle with this direction.",
            "Here, which is larger or smaller than 90 degrees.",
            "So depending on whether it's loud rose more than next agrees, that point will be on this side or on the side of that dashed line.",
            "It's a simple construction and you might remember that to check whether an endless, smaller or larger than 90 degrees just need to check the cosine of the angle, I need to check the code to compute the cosine of an angle.",
            "You just have to compute the dot product between vectors up to the scaling factor so we can do this in terms of the current product between this vector X -- Y and inspector W."
        ],
        [
            "So let's plug it all in.",
            "If we do that and it's a simple calculation.",
            "And we get the following.",
            "We get this term here which contains, so we have to.",
            "This is this.",
            "And if you go for, it gets decision rule.",
            "You get some overall positive points.",
            "Officer product here.",
            "You get assembling points these dot products.",
            "And you get a constant, just called feed, which I've written down.",
            "Down here, so this is a term that does not depend on X.",
            "This is our first point.",
            "X is constant, only depends on all the credit points.",
            "Now these are products we can compute using our kernel function.",
            "So our decision rule will look like this.",
            "Will take a test point X.",
            "Compared to all the positive points.",
            "In some of these little values divided by the number of such good values.",
            "We will do the same points and here we have some constants, so if you disregard constant say depending on whether the positive points give you more evidence.",
            "Using this.",
            "You would assign the point in first class.",
            "Actually, this is a classifier which is.",
            "Well known from statistics.",
            "So in statistics people study something, or among other things, study something called 1000 Windows Estimator 1000 Windows Estimator is a way of estimating density points.",
            "So assuming that there are some underlying density and it generates these points.",
            "So random experiment sampling points from this density.",
            "But you could ask the question given only the points, how do you estimate the density in one way to estimate it?",
            "Kernel function.",
            "Specific properties so it should be a kernel function which is integral one normalized.",
            "It's non negative.",
            "If you put a kernel function on each point and then divide by the number of such kernel functions you get a passing windows density estimated that class.",
            "So this is a density estimate.",
            "This is 1.",
            "Satisfy these conditions of being negative in normalized and then you get a sort of classifier which is reasonable from the party of statistics.",
            "But what we're doing is actually that we want to know which were not.",
            "We can also use kernel functions that are.",
            "Negative or they can take negative values.",
            "So.",
            "And the other interesting thing is that in our case we divide this classic file by simply computing the mean of a set of points in some feature space.",
            "So this is a purely geometric way of deriving their classifier, and as you will see next week in Arthur Britton scores.",
            "Useful to think of.",
            "Such a density estimates does this mean here is just the density estimates of this point here?",
            "If you want correspondence.",
            "This point, yes, C plus corresponds to this term, and seeing this correspond to this term.",
            "So if you want each of these means here C + C minus our estimators of the density generating the respective class.",
            "So in our case, geometrically, each point in this space if you want, could be a potential estimator of identity.",
            "Surprising, it turns out that for certain kernels, so I'm jumping a little bit helpful.",
            "Certain kernels.",
            "Somehow this these points remember all the individual prices have contributed to them, so you have a lot of points.",
            "Firebase I take the mean over all these points in this PC Plus and sometimes, depending on how the kernel looks like.",
            "At this Point C Plus remembers all the individual one points 5 XI, so you don't lose information by this averaging in some case.",
            "Sounds funny.",
            "Spaces.",
            "This can only work if our feature space is actually pretty dimensional, but don't let this confuse here and it's not important for the moment, so I'm just trying to put in some pointers for those."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Introduction.",
                    "label": 0
                },
                {
                    "sent": "Doc told me.",
                    "label": 0
                },
                {
                    "sent": "Myself.",
                    "label": 0
                },
                {
                    "sent": "Watching your video.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether anybody will be watching these tapes, but.",
                    "label": 0
                },
                {
                    "sent": "I'm done.",
                    "label": 0
                },
                {
                    "sent": "I've studied physics and mathematics and other PhD in computer science and walked into machine learning.",
                    "label": 0
                },
                {
                    "sent": "At the end of my studies and my PhD already in machine learning.",
                    "label": 0
                },
                {
                    "sent": "The less we have left the market used to be at that time.",
                    "label": 0
                },
                {
                    "sent": "Advisor and officially I got my PhD from the University in belief that Technical University values.",
                    "label": 0
                },
                {
                    "sent": "Afterwards I spent some time in early in Cambridge, UK and New York.",
                    "label": 0
                },
                {
                    "sent": "And now I'm just very close to where I come from.",
                    "label": 0
                },
                {
                    "sent": "I'm running a chi learning empirical inference departments.",
                    "label": 0
                },
                {
                    "sent": "So I want to talk about learning with kernels, but before I actually start would be nice to be delicious idea who's here and what kind of background you have.",
                    "label": 1
                },
                {
                    "sent": "So maybe I can up around with this.",
                    "label": 0
                },
                {
                    "sent": "Is there anybody who has been to a machine learning summer school before?",
                    "label": 0
                },
                {
                    "sent": "OK, that's good because I'm gonna reuse the slice that I've used before.",
                    "label": 0
                },
                {
                    "sent": "Australia before.",
                    "label": 0
                },
                {
                    "sent": "Anybody has already seen a kangaroo?",
                    "label": 0
                },
                {
                    "sent": "So maybe the background service who has a degree in doesn't yet have a first degree.",
                    "label": 0
                },
                {
                    "sent": "Do we have undergraduates?",
                    "label": 0
                },
                {
                    "sent": "And who?",
                    "label": 0
                },
                {
                    "sent": "Doesn't have a PhD.",
                    "label": 0
                },
                {
                    "sent": "PhD students, let's talk about this subject.",
                    "label": 0
                },
                {
                    "sent": "Computer science.",
                    "label": 0
                },
                {
                    "sent": "Mathematics.",
                    "label": 0
                },
                {
                    "sent": "Physics.",
                    "label": 0
                },
                {
                    "sent": "Engineering.",
                    "label": 0
                },
                {
                    "sent": "Psychology.",
                    "label": 0
                },
                {
                    "sent": "Biology.",
                    "label": 0
                },
                {
                    "sent": "Anything else?",
                    "label": 0
                },
                {
                    "sent": "Any other topics?",
                    "label": 0
                },
                {
                    "sent": "OK, and so those who are doing a PC, how many already doing their own research.",
                    "label": 0
                },
                {
                    "sent": "How many are there in research in machine learning?",
                    "label": 0
                },
                {
                    "sent": "How many have already run support vector machine on some datasets?",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to adjust the speed of my my lecture, so you probably won't be successful, so you'll have to tell me whether I should go faster or more slowly.",
                    "label": 0
                },
                {
                    "sent": "So chances are that I might go too slowly, but my experience is better to start to slowly and then going to speed up a little bit, because if you miss the beginning then.",
                    "label": 0
                },
                {
                    "sent": "Many of you might be.",
                    "label": 0
                },
                {
                    "sent": "How many of you is now in the middle of the night?",
                    "label": 0
                },
                {
                    "sent": "Or or make evening or something like that.",
                    "label": 0
                },
                {
                    "sent": "How many?",
                    "label": 0
                },
                {
                    "sent": "Australia.",
                    "label": 0
                },
                {
                    "sent": "OK, so I guess half you will be challenged now.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "Just put it up on something and then we fall asleep.",
                    "label": 0
                },
                {
                    "sent": "OK so you can interrupt me at anytime and I have too many slides anyway, so I'll have to skip something so we can do it interactively if you like.",
                    "label": 0
                },
                {
                    "sent": "I haven't yet.",
                    "label": 0
                },
                {
                    "sent": "I was already going for five nights.",
                    "label": 0
                },
                {
                    "sent": "Missed.",
                    "label": 0
                },
                {
                    "sent": "Something should show up now.",
                    "label": 0
                },
                {
                    "sent": "So I was planning.",
                    "label": 0
                },
                {
                    "sent": "Maybe this morning?",
                    "label": 0
                },
                {
                    "sent": "Because it doesn't take too much time.",
                    "label": 0
                },
                {
                    "sent": "ISBN's screen.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I will start with some elements of statistical learning theory and then move on.",
                    "label": 1
                },
                {
                    "sent": "Probably tomorrow morning journals and feature spaces reproducing kernel spaces.",
                    "label": 0
                },
                {
                    "sent": "And the day After's Public Library.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And maybe some applications.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to start with just an introduction to somebody that is a machine learning and then.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some elements of learning theory.",
                    "label": 0
                },
                {
                    "sent": "Type introduction and so.",
                    "label": 0
                },
                {
                    "sent": "Let's assume we have sets of inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "Sunsets were thinking of learning from data pairs, inputs, outputs and inputs are.",
                    "label": 0
                },
                {
                    "sent": "Another task was to be taken from these two sets, calligraphic XY and for trading were given a set of M. Such pairs taken from input in output space or input and output set, and.",
                    "label": 0
                },
                {
                    "sent": "In learning we are interested in something that people call generalization.",
                    "label": 0
                },
                {
                    "sent": "So given an X point that we haven't seen before.",
                    "label": 0
                },
                {
                    "sent": "Given an excellent we have seen before, we would like to find suitable why?",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "It means that this PAREXEL agency somehow similar.",
                    "label": 0
                },
                {
                    "sent": "Examples that we see.",
                    "label": 0
                },
                {
                    "sent": "Then of course you could ask how we measure this similarity, and there are many different answers to this question and the people that are starting kernels in tabular way to measure such similarity on the inputs on the X is a Colonel in the outputs.",
                    "label": 0
                },
                {
                    "sent": "It's usually a loss function, so for instance the articles could be just plus minus one, but it could also be something more complicated.",
                    "label": 0
                },
                {
                    "sent": "In fact, it could also be a kernel.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure whether I will talk about that, but simplicity.",
                    "label": 0
                },
                {
                    "sent": "Let's assume outputs might be.",
                    "label": 0
                },
                {
                    "sent": "In which case we are talking about something called binary pattern recognition.",
                    "label": 0
                },
                {
                    "sent": "And the inputs are compares using a kernel.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Stop for some requirements like this.",
                    "label": 0
                },
                {
                    "sent": "We would like to similarity measure to be symmetric function.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "XNXX prime prices.",
                    "label": 0
                },
                {
                    "sent": "In the special case where all input set is just after the end, we could use something like that.",
                    "label": 0
                },
                {
                    "sent": "Those products can only for both product and by this notation.",
                    "label": 0
                },
                {
                    "sent": "With this angular brackets and denoting so this X in the brackets up.",
                    "label": 0
                },
                {
                    "sent": "I mean I entry of X.",
                    "label": 0
                },
                {
                    "sent": "So this is just the sum over the product of corresponding entries of these inputs.",
                    "label": 0
                },
                {
                    "sent": "Pictures within projectors now.",
                    "label": 0
                },
                {
                    "sent": "This of course applies only in the case where we have a space in which we can kind of products in this.",
                    "label": 0
                },
                {
                    "sent": "In this case it was the Euclidean space after the end, but if we don't have the product space, what are we gonna do?",
                    "label": 0
                },
                {
                    "sent": "People assume that our similarity measure K has at least a representation as a dot product in some space.",
                    "label": 1
                },
                {
                    "sent": "So in a doctor, Rackspace Dot product spaces, in particular vector space or linear space and use the space in vector space interchangeably and by this representation I mean I mean.",
                    "label": 1
                },
                {
                    "sent": "There exists a map by that takes our inputs, Maps them into a door, correct space such that if I take 2 inputs X&X prime mapping both into that space and then take the dot product.",
                    "label": 0
                },
                {
                    "sent": "This is supposed to be the same as taking the curl on Exit Explorer.",
                    "label": 0
                },
                {
                    "sent": "So this cave is similarity measure has a representation as a product.",
                    "label": 0
                },
                {
                    "sent": "And the representation is nothing 5.",
                    "label": 0
                },
                {
                    "sent": "Sometimes we call the feature map.",
                    "label": 0
                },
                {
                    "sent": "So if this is the case, if we have such a similarity measure, and if we use it, that's even ever to measure, then we can think of our inputs.",
                    "label": 0
                },
                {
                    "sent": "Sometimes I'm going to use some patterns for the inputs we didn't think of our inputs.",
                    "label": 0
                },
                {
                    "sent": "Actually yes 5X5 X plan, because that's the one that we're working within.",
                    "label": 0
                },
                {
                    "sent": "The DOT product space, so all our inputs will be transformed into that space.",
                    "label": 1
                },
                {
                    "sent": "We think of our inputs as our patterns as these things, and in that case our patterns are actually vectors in space and we can carry out to your metric algorithms in there so we can do whatever we can do using geometric means.",
                    "label": 0
                },
                {
                    "sent": "I've already mentioned this.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Features.",
                    "label": 0
                },
                {
                    "sent": "So here's a simple example of an algorithm of geometric items that aren't meant for carry out and.",
                    "label": 0
                },
                {
                    "sent": "Interesting.",
                    "label": 0
                },
                {
                    "sent": "I came up with this example when I was writing the introduction of our book.",
                    "label": 0
                },
                {
                    "sent": "You've seen the title page before.",
                    "label": 0
                },
                {
                    "sent": "I just look at example, but it turns out it's not so well.",
                    "label": 0
                },
                {
                    "sent": "It is trivial, but it's.",
                    "label": 0
                },
                {
                    "sent": "Useful next week.",
                    "label": 0
                },
                {
                    "sent": "Who is taking these ideas much further and constructing interesting statistical tests based on something very similar?",
                    "label": 0
                },
                {
                    "sent": "So sometimes some very simple idea can already take you very far in pushing the machinery is not tested.",
                    "label": 0
                },
                {
                    "sent": "Specialized branches of mathematics, so sometimes you think well about something you could already make progress even if you haven't studied the fuse for five years.",
                    "label": 0
                },
                {
                    "sent": "So anyway, this is a simple algorithm for classification for binary classification or binary passenger conditions.",
                    "label": 0
                },
                {
                    "sent": "So we're assuming we have given two classes of objects here, the pluses and over here we have these circles and we want to classify or we want to find additional rules separating these two classes such that if we give you a new point, this point, let's call this point X and assume it's down here.",
                    "label": 0
                },
                {
                    "sent": "Assignments test 1212 tasks based on these training data, we want to start the decision.",
                    "label": 0
                },
                {
                    "sent": "For instance this straight line and then use this decision rule to sign this point X one of the two classes.",
                    "label": 1
                },
                {
                    "sent": "So here the simplest.",
                    "label": 0
                },
                {
                    "sent": "Do it assuming that all points live in such a dark product space, which we can assume right?",
                    "label": 0
                },
                {
                    "sent": "Because we have this representation 5.",
                    "label": 0
                },
                {
                    "sent": "The simplest way to do it would be first compute the mean of all positive points from its C plus.",
                    "label": 0
                },
                {
                    "sent": "So this is the mean.",
                    "label": 0
                },
                {
                    "sent": "So we are summing over all points that have positive plus one plus the label, why I?",
                    "label": 1
                },
                {
                    "sent": "The points in the feature space.",
                    "label": 0
                },
                {
                    "sent": "Divided by the number of such points for doing the same for the negative points, this is the number of negative points we get this Point C minus and then we will simply check whether our test point X is closer to C plus or closer to the minus.",
                    "label": 0
                },
                {
                    "sent": "Pending on.",
                    "label": 0
                },
                {
                    "sent": "So we can do this in various ways, and one way to do it would be just to compute this Point C, which is halfway in between C minus in C plus, and then we can compute a vector of connecting C to artist point X.",
                    "label": 0
                },
                {
                    "sent": "And then we can check whether this vector encloses an angle with this direction.",
                    "label": 0
                },
                {
                    "sent": "Here, which is larger or smaller than 90 degrees.",
                    "label": 0
                },
                {
                    "sent": "So depending on whether it's loud rose more than next agrees, that point will be on this side or on the side of that dashed line.",
                    "label": 0
                },
                {
                    "sent": "It's a simple construction and you might remember that to check whether an endless, smaller or larger than 90 degrees just need to check the cosine of the angle, I need to check the code to compute the cosine of an angle.",
                    "label": 0
                },
                {
                    "sent": "You just have to compute the dot product between vectors up to the scaling factor so we can do this in terms of the current product between this vector X -- Y and inspector W.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's plug it all in.",
                    "label": 0
                },
                {
                    "sent": "If we do that and it's a simple calculation.",
                    "label": 0
                },
                {
                    "sent": "And we get the following.",
                    "label": 0
                },
                {
                    "sent": "We get this term here which contains, so we have to.",
                    "label": 0
                },
                {
                    "sent": "This is this.",
                    "label": 0
                },
                {
                    "sent": "And if you go for, it gets decision rule.",
                    "label": 0
                },
                {
                    "sent": "You get some overall positive points.",
                    "label": 0
                },
                {
                    "sent": "Officer product here.",
                    "label": 0
                },
                {
                    "sent": "You get assembling points these dot products.",
                    "label": 0
                },
                {
                    "sent": "And you get a constant, just called feed, which I've written down.",
                    "label": 0
                },
                {
                    "sent": "Down here, so this is a term that does not depend on X.",
                    "label": 0
                },
                {
                    "sent": "This is our first point.",
                    "label": 0
                },
                {
                    "sent": "X is constant, only depends on all the credit points.",
                    "label": 0
                },
                {
                    "sent": "Now these are products we can compute using our kernel function.",
                    "label": 0
                },
                {
                    "sent": "So our decision rule will look like this.",
                    "label": 0
                },
                {
                    "sent": "Will take a test point X.",
                    "label": 0
                },
                {
                    "sent": "Compared to all the positive points.",
                    "label": 0
                },
                {
                    "sent": "In some of these little values divided by the number of such good values.",
                    "label": 0
                },
                {
                    "sent": "We will do the same points and here we have some constants, so if you disregard constant say depending on whether the positive points give you more evidence.",
                    "label": 0
                },
                {
                    "sent": "Using this.",
                    "label": 0
                },
                {
                    "sent": "You would assign the point in first class.",
                    "label": 0
                },
                {
                    "sent": "Actually, this is a classifier which is.",
                    "label": 0
                },
                {
                    "sent": "Well known from statistics.",
                    "label": 0
                },
                {
                    "sent": "So in statistics people study something, or among other things, study something called 1000 Windows Estimator 1000 Windows Estimator is a way of estimating density points.",
                    "label": 0
                },
                {
                    "sent": "So assuming that there are some underlying density and it generates these points.",
                    "label": 0
                },
                {
                    "sent": "So random experiment sampling points from this density.",
                    "label": 0
                },
                {
                    "sent": "But you could ask the question given only the points, how do you estimate the density in one way to estimate it?",
                    "label": 0
                },
                {
                    "sent": "Kernel function.",
                    "label": 0
                },
                {
                    "sent": "Specific properties so it should be a kernel function which is integral one normalized.",
                    "label": 1
                },
                {
                    "sent": "It's non negative.",
                    "label": 0
                },
                {
                    "sent": "If you put a kernel function on each point and then divide by the number of such kernel functions you get a passing windows density estimated that class.",
                    "label": 0
                },
                {
                    "sent": "So this is a density estimate.",
                    "label": 1
                },
                {
                    "sent": "This is 1.",
                    "label": 0
                },
                {
                    "sent": "Satisfy these conditions of being negative in normalized and then you get a sort of classifier which is reasonable from the party of statistics.",
                    "label": 0
                },
                {
                    "sent": "But what we're doing is actually that we want to know which were not.",
                    "label": 0
                },
                {
                    "sent": "We can also use kernel functions that are.",
                    "label": 0
                },
                {
                    "sent": "Negative or they can take negative values.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And the other interesting thing is that in our case we divide this classic file by simply computing the mean of a set of points in some feature space.",
                    "label": 0
                },
                {
                    "sent": "So this is a purely geometric way of deriving their classifier, and as you will see next week in Arthur Britton scores.",
                    "label": 0
                },
                {
                    "sent": "Useful to think of.",
                    "label": 0
                },
                {
                    "sent": "Such a density estimates does this mean here is just the density estimates of this point here?",
                    "label": 0
                },
                {
                    "sent": "If you want correspondence.",
                    "label": 0
                },
                {
                    "sent": "This point, yes, C plus corresponds to this term, and seeing this correspond to this term.",
                    "label": 0
                },
                {
                    "sent": "So if you want each of these means here C + C minus our estimators of the density generating the respective class.",
                    "label": 0
                },
                {
                    "sent": "So in our case, geometrically, each point in this space if you want, could be a potential estimator of identity.",
                    "label": 0
                },
                {
                    "sent": "Surprising, it turns out that for certain kernels, so I'm jumping a little bit helpful.",
                    "label": 0
                },
                {
                    "sent": "Certain kernels.",
                    "label": 0
                },
                {
                    "sent": "Somehow this these points remember all the individual prices have contributed to them, so you have a lot of points.",
                    "label": 0
                },
                {
                    "sent": "Firebase I take the mean over all these points in this PC Plus and sometimes, depending on how the kernel looks like.",
                    "label": 0
                },
                {
                    "sent": "At this Point C Plus remembers all the individual one points 5 XI, so you don't lose information by this averaging in some case.",
                    "label": 0
                },
                {
                    "sent": "Sounds funny.",
                    "label": 0
                },
                {
                    "sent": "Spaces.",
                    "label": 0
                },
                {
                    "sent": "This can only work if our feature space is actually pretty dimensional, but don't let this confuse here and it's not important for the moment, so I'm just trying to put in some pointers for those.",
                    "label": 0
                }
            ]
        }
    }
}