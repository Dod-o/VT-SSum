{
    "id": "3lsotavl762bfypkar2gq4jxknduh2eb",
    "title": "Uniqueness of ordinal embedding",
    "info": {
        "author": [
            "Matth\u00e4us Kleindessner, Department of Informatics, University of Hamburg"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2014_kleindessner_embedding/",
    "segmentation": [
        [
            "Bedding, which is also known as ordinal or non metric multidimensional."
        ],
        [
            "Internet scaling refers to the following problem.",
            "Assume we are given a set of objects and assume there is some notion of distance or dissimilarity between these objects.",
            "But we know about this dissimilarity ordinal relationships.",
            "That is, we know better object or I this kills the object or J then object OK is to object or L or whether it is the other way round and then the task is to construct an embedding of these objects into Rd for some given dimension V such that all these ordinal relationships are preserved.",
            "Here we have a little example.",
            "You can see 7 movies and for example we know that Indiana Jones is more similar to Lord of the Rings and Killbillies to Titanic and based on all such comparisons we can construct an embedding into the two dimensional plane.",
            "And here you can see the point representing Lord of the Rings is closer to the point representing Indiana Jones and these two points are to each other.",
            "Let me just mention two applications of this approach.",
            "So the first one, but obviously a specialization not only for creating nice pictures, but mainly for visual data exploration.",
            "And the second application, which might be more important for our community, is to run as a preprocessing step for all kinds of geometric machine learning algorithms.",
            "So for example, here you can see these two clusters.",
            "Which seemed to be quite reasonable for those of you who know the films and which we could easily detect by applying the K means algorithm to this embedding.",
            "Let me also mention that such ordinal distance information with such comparisons are usually much easier to gain the numerically dissimilarity values."
        ],
        [
            "So now the title of our papers, uniqueness of embeddings.",
            "But the first observation is that such ordinal embeddings can never be unique for at least two reasons.",
            "So first we can always apply a similarity transformation to an ordinal embedding to obtain another one.",
            "So this is a simple rotation of this original embedding.",
            "On the other hand, we can also move points in the embedding a bit around without violating any of the constraints, and this gives us a second embedding.",
            "Now, one could think that there are even more reasons for ambiguity.",
            "Care?"
        ],
        [
            "However, when running the algorithms, people have never observed any other reason for ambiguity, and in fact have observed even more.",
            "They have observed the amount of possible buckling in the embedding decreases as the number of objects increases.",
            "And this observation gave rise to the following conjecture, which was formulated by Roger Shepherd, one of the founding fathers of ordinal multidimensional scaling.",
            "Already in the 1960s.",
            "For the first time, and which says that as in increases and ordinal embedding is determined more and more uniquely up to similarity transformation.",
            "OK, and up to now there there have been numerous numerically experiments published as supporting evidence, but there hasn't been any formal proof for it.",
            "Now you can find on in our paper.",
            "So before I get more forming on the next slide that we just provide an intuitive argument by this conjecture indeed makes sense.",
            "So when constructing an embedding, you're searching for endpoints in D dimensions.",
            "That is, we have to deal with end times D unknown variables, But these variables have to satisfy in the order of N ^2 1 redundant in qualities.",
            "So if N is large, we have to deal with a highly overdetermined system."
        ],
        [
            "So this is the mathematics set up for our paper.",
            "We want to deal with the question of uniqueness of ordinal embeddings rather than with the question whether embedding exists at all in which dimension exists, and hence we always assume that our data originally comes from RV.",
            "So let X Capital X via points out of our gear and let capital vibe you subset of the same size, and then we called by an all in an embedding of X if for all indices IJK&L.",
            "The following holds whenever XI is closer to exchange an excuse to Excel, then the corresponding points of I should have the same property.",
            "And for our treatment we also need the following definition.",
            "We say that an arbitrary function from from some arbitrary subset Omega of are the two argies isotonic if it has the property that whenever X is closer to live then set it to W, then the image points have the same property.",
            "K."
        ],
        [
            "So at least two definitions are clearly closely related to each other.",
            "Namely, we have the following equivalent.",
            "The points by bumped by NR and ordinal embedding of the points expand to extend if and only if the mapping F which Maps the point excited to the point by I is isotonic and this is important because this now allows us to reformulate shepherds conjecture.",
            "As follows.",
            "So using that, the notion of of isotonic functions, shepherds conjectures, is nothing else that as N increases and also as a tonic function, can be approximated better and better by similarity, and we want to prove this reformulation of shepherds conjecture, which then immediately yields are synthetic uniqueness of ordinal embeddings up to similarity transformations."
        ],
        [
            "So here's a theorem.",
            "We assume that we have a pound ball and we are considering a sequence of points X and it just ends in this ball.",
            "And we are considering a sequence of functions fire in that every function fire N acts on the 1st endpoints of the sequence, and all these functions should map to the same bounded call here.",
            "And we assume these functions to be isotonic.",
            "And then the statement is that there exists a sequence of similarity transformations approximating this sequence of isotonic functions such that the approximation error goes to zero as N goes to Infinity.",
            "So let me just say one word to this assumption here that all these functions fire and map to the same bounded ball.",
            "This is clearly necessary, because otherwise we could simply blow up the configuration in the image space and prevent the approximation here error here from converging.",
            "I don't want to discuss your assumptions we make here right now because we will relax them and provide a more general version of this theorem in a couple of slides."
        ],
        [
            "OK, so how does this work?",
            "I want to sketch the proof for a bunch of dimensional case because this is particularly simply simple, but nevertheless illustrates already one of the main ideas.",
            "So the first observation is that in one dimension, every isotonic function is added strictly increasing or decreasing, and this is easy to verify right from the definition.",
            "Now we do the following.",
            "We consider very particular isotonic function acting on four points zero and one which are assumed to be fixed points and two other points A&B at these two points.",
            "A&B can be chosen arbitrarily from these particular intervals, so they should be.",
            "Located in an interval sitting left of 1/2 and be in should be located in an interval sitting right on half OK and now we already know cause zero and one are fixed points that this function 5 we're considering here is to keep increasing so A&B are mapped to points in between zero and one.",
            "OK, and we know even more.",
            "We know that a is clearly closer to 0 than it is to one, and so the corresponding image point is the same property and we can infer that fee of a sits in the interval from zero to 100."
        ],
        [
            "In the next step.",
            "And obviously, we can consider a function acting on eight points against you and one assumed to be fixed points.",
            "Now we are considering eight points.",
            "Specified on the insofar as they should lie in this very particular intervals here.",
            "Located close to 1/4 + 1/2 and close to three forts OK. And now these intervals are chosen in a very particular way.",
            "They are chosen such that Point C, Independent from its exact location in this interval, is always closer to 0 than it is to the point A.",
            "Enter Points T is always closer to the point B, then it is to zero OK from the last slide.",
            "We already know that fee of a is closer as smaller than 1/2.",
            "And with all this information it is straightforward to infer that.",
            "C is mapped to a point in this open interval here.",
            "And similarly, we can infer that DNA are mapped to points sitting in these intervals here OK, and we can repeat this procedure not iteratively to gain a finer and finer grid on the unit interval together with an estimate for for the image points of the grid points.",
            "And how does this help us now to prove our theorem but first become by simply rescaling guarantee that all our functions fiamm map on points zero and one such that these are fixed points and that it acts on points sitting between zero and one?",
            "OK, now since this sequence X here system to be tense.",
            "Through this rescaling, we can assume that it stands in the interval zero and one and if N is just large enough in each of the intervals we consider here, there is a point, and for these points we immediately have an estimation here.",
            "And for the points in between, we get one because of the monotonicity, and this is enough information to prove that our sequence of rescaled functions Phi N can be approximated by the identity function.",
            "So this is this catch 41 dimension decay."
        ],
        [
            "The case D greater than one is more complicated to deal with and unfortunately I have to skip this right now.",
            "But the idea of considering very party."
        ],
        [
            "Killer's atomic functions acting on point set.",
            "Trump specified on the insofar as that they should lay in some certain open pods.",
            "This is the same here again."
        ],
        [
            "OK, but instead of the proof, let me provide a more more general version of the theorem we have just seen becauses a local version, in contrast to the to the global version.",
            "We have just seen before, OK, and here we assume that K is the union of bounded balls, such union of the interior of the balls is connected.",
            "Again, we assume.",
            "But we have sequence of points which is dancing K and again we are considering a sequence of function Phi an acting on the 1st endpoints.",
            "Every function fight and again they should map to the same board.",
            "But now instead of assuming that the functions for an isotonic and all of their domain.",
            "We just assume that they are isotonic on the intersection of the domain with the balls Ki for every I. OK, not exactly the same statement holds true.",
            "There is a sequence of similarity transformations approximating.",
            "The sequence of functions for N such that the approximation error goes to 0.",
            "And here, of course, there are two important generalizations.",
            "So, first of all, we can deal with more general geometry's.",
            "And the second one is that it's enough to consider functions which are not isotonic, and all of the other main, but just on these small subregions.",
            "OK, but this is a simple corollary of our global version for the following reason.",
            "So assume for simplicity that K is just a union of K1 and K2.",
            "And then from the global version, we know that we can approximate the sequence fire embers sequence of similarities on cave on, and we can do the same on K2.",
            "But now if S1 is a similarity transformation approximating a function fire on Kevin, and there's two, is a similarity transformation approximating function file an NK2?",
            "They're both good approximations for point in the intersection of K1 and K2 now, because as fun, and there's two are both defined functions and.",
            "The Union of Kevin and Katie responded.",
            "These two similarity transformations cannot be two different on all of care.",
            "So this is not not hard to prove.",
            "Once we have the global version."
        ],
        [
            "OK, so I'm almost done with my talk, but I want to address some open questions.",
            "But the first one is in our.",
            "In our paper, we provide the ferum.",
            "Guarantee there are some tatik uniqueness of ordinal embeddings up to similarity transformations, but we don't provide any error bounds.",
            "So in principle one could use our estimates to derive error bounds by making explicit some parameters, but we haven't make this effort.",
            "Um?",
            "'cause we're pretty sure that that their rates we would gain in this way would be much too weak.",
            "So numerically examples suggest.",
            "That the rates of convergence are quite fast, but you can see here is.",
            "The red points are uniformly drawn at random from the unit square.",
            "And the blue points are an ordinal embedding based on all ordinal comparisons coming from the red points OK.",
            "These blueprints were calculated by a standard embedding algorithm and now you should know that all these embedding algorithms infects over minimization problem and I've run this algorithm for 100 times and in the end I never obtained solution reconstructing the red points versed in the blue points, but it brought it here in the figure.",
            "OK, and you can see that for N equal to five, there is some difference between the original red points and its ordinal embedding.",
            "But already for M equal to temp, this difference has almost vanished at all and for N = 30.",
            "It isn't to see anymore at all.",
            "So what I want to say is it is still an open problem to provide meaningful error bounds.",
            "Second, open question.",
            "I want to address.",
            "Here is closely related to the local version.",
            "We have just seen on the previous lead.",
            "So there we have seen that instead of assuming that the functions for N as a tonic and all of their domain, it is sufficient.",
            "To assume them to be as a tonic on small overlapping sub regions.",
            "So this gives to us today question what is the minimum amount of ordinal information that is necessary for guaranteeing a unique ordinal embedding?",
            "Yet the last question is, how can one deal with data that doesn't allow it perfectly limited?"
        ],
        [
            "So that's it.",
            "Let me just say I also prepared a poster, and in case you want to hear about this stuff in more detail, I'm looking forward to seeing you there.",
            "So thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bedding, which is also known as ordinal or non metric multidimensional.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Internet scaling refers to the following problem.",
                    "label": 0
                },
                {
                    "sent": "Assume we are given a set of objects and assume there is some notion of distance or dissimilarity between these objects.",
                    "label": 0
                },
                {
                    "sent": "But we know about this dissimilarity ordinal relationships.",
                    "label": 0
                },
                {
                    "sent": "That is, we know better object or I this kills the object or J then object OK is to object or L or whether it is the other way round and then the task is to construct an embedding of these objects into Rd for some given dimension V such that all these ordinal relationships are preserved.",
                    "label": 0
                },
                {
                    "sent": "Here we have a little example.",
                    "label": 0
                },
                {
                    "sent": "You can see 7 movies and for example we know that Indiana Jones is more similar to Lord of the Rings and Killbillies to Titanic and based on all such comparisons we can construct an embedding into the two dimensional plane.",
                    "label": 0
                },
                {
                    "sent": "And here you can see the point representing Lord of the Rings is closer to the point representing Indiana Jones and these two points are to each other.",
                    "label": 0
                },
                {
                    "sent": "Let me just mention two applications of this approach.",
                    "label": 0
                },
                {
                    "sent": "So the first one, but obviously a specialization not only for creating nice pictures, but mainly for visual data exploration.",
                    "label": 0
                },
                {
                    "sent": "And the second application, which might be more important for our community, is to run as a preprocessing step for all kinds of geometric machine learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "So for example, here you can see these two clusters.",
                    "label": 0
                },
                {
                    "sent": "Which seemed to be quite reasonable for those of you who know the films and which we could easily detect by applying the K means algorithm to this embedding.",
                    "label": 0
                },
                {
                    "sent": "Let me also mention that such ordinal distance information with such comparisons are usually much easier to gain the numerically dissimilarity values.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the title of our papers, uniqueness of embeddings.",
                    "label": 1
                },
                {
                    "sent": "But the first observation is that such ordinal embeddings can never be unique for at least two reasons.",
                    "label": 0
                },
                {
                    "sent": "So first we can always apply a similarity transformation to an ordinal embedding to obtain another one.",
                    "label": 0
                },
                {
                    "sent": "So this is a simple rotation of this original embedding.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we can also move points in the embedding a bit around without violating any of the constraints, and this gives us a second embedding.",
                    "label": 1
                },
                {
                    "sent": "Now, one could think that there are even more reasons for ambiguity.",
                    "label": 0
                },
                {
                    "sent": "Care?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However, when running the algorithms, people have never observed any other reason for ambiguity, and in fact have observed even more.",
                    "label": 0
                },
                {
                    "sent": "They have observed the amount of possible buckling in the embedding decreases as the number of objects increases.",
                    "label": 0
                },
                {
                    "sent": "And this observation gave rise to the following conjecture, which was formulated by Roger Shepherd, one of the founding fathers of ordinal multidimensional scaling.",
                    "label": 0
                },
                {
                    "sent": "Already in the 1960s.",
                    "label": 0
                },
                {
                    "sent": "For the first time, and which says that as in increases and ordinal embedding is determined more and more uniquely up to similarity transformation.",
                    "label": 1
                },
                {
                    "sent": "OK, and up to now there there have been numerous numerically experiments published as supporting evidence, but there hasn't been any formal proof for it.",
                    "label": 0
                },
                {
                    "sent": "Now you can find on in our paper.",
                    "label": 0
                },
                {
                    "sent": "So before I get more forming on the next slide that we just provide an intuitive argument by this conjecture indeed makes sense.",
                    "label": 0
                },
                {
                    "sent": "So when constructing an embedding, you're searching for endpoints in D dimensions.",
                    "label": 1
                },
                {
                    "sent": "That is, we have to deal with end times D unknown variables, But these variables have to satisfy in the order of N ^2 1 redundant in qualities.",
                    "label": 0
                },
                {
                    "sent": "So if N is large, we have to deal with a highly overdetermined system.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the mathematics set up for our paper.",
                    "label": 0
                },
                {
                    "sent": "We want to deal with the question of uniqueness of ordinal embeddings rather than with the question whether embedding exists at all in which dimension exists, and hence we always assume that our data originally comes from RV.",
                    "label": 0
                },
                {
                    "sent": "So let X Capital X via points out of our gear and let capital vibe you subset of the same size, and then we called by an all in an embedding of X if for all indices IJK&L.",
                    "label": 1
                },
                {
                    "sent": "The following holds whenever XI is closer to exchange an excuse to Excel, then the corresponding points of I should have the same property.",
                    "label": 0
                },
                {
                    "sent": "And for our treatment we also need the following definition.",
                    "label": 0
                },
                {
                    "sent": "We say that an arbitrary function from from some arbitrary subset Omega of are the two argies isotonic if it has the property that whenever X is closer to live then set it to W, then the image points have the same property.",
                    "label": 0
                },
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So at least two definitions are clearly closely related to each other.",
                    "label": 0
                },
                {
                    "sent": "Namely, we have the following equivalent.",
                    "label": 0
                },
                {
                    "sent": "The points by bumped by NR and ordinal embedding of the points expand to extend if and only if the mapping F which Maps the point excited to the point by I is isotonic and this is important because this now allows us to reformulate shepherds conjecture.",
                    "label": 0
                },
                {
                    "sent": "As follows.",
                    "label": 0
                },
                {
                    "sent": "So using that, the notion of of isotonic functions, shepherds conjectures, is nothing else that as N increases and also as a tonic function, can be approximated better and better by similarity, and we want to prove this reformulation of shepherds conjecture, which then immediately yields are synthetic uniqueness of ordinal embeddings up to similarity transformations.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a theorem.",
                    "label": 0
                },
                {
                    "sent": "We assume that we have a pound ball and we are considering a sequence of points X and it just ends in this ball.",
                    "label": 0
                },
                {
                    "sent": "And we are considering a sequence of functions fire in that every function fire N acts on the 1st endpoints of the sequence, and all these functions should map to the same bounded call here.",
                    "label": 0
                },
                {
                    "sent": "And we assume these functions to be isotonic.",
                    "label": 0
                },
                {
                    "sent": "And then the statement is that there exists a sequence of similarity transformations approximating this sequence of isotonic functions such that the approximation error goes to zero as N goes to Infinity.",
                    "label": 1
                },
                {
                    "sent": "So let me just say one word to this assumption here that all these functions fire and map to the same bounded ball.",
                    "label": 0
                },
                {
                    "sent": "This is clearly necessary, because otherwise we could simply blow up the configuration in the image space and prevent the approximation here error here from converging.",
                    "label": 0
                },
                {
                    "sent": "I don't want to discuss your assumptions we make here right now because we will relax them and provide a more general version of this theorem in a couple of slides.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how does this work?",
                    "label": 0
                },
                {
                    "sent": "I want to sketch the proof for a bunch of dimensional case because this is particularly simply simple, but nevertheless illustrates already one of the main ideas.",
                    "label": 0
                },
                {
                    "sent": "So the first observation is that in one dimension, every isotonic function is added strictly increasing or decreasing, and this is easy to verify right from the definition.",
                    "label": 1
                },
                {
                    "sent": "Now we do the following.",
                    "label": 0
                },
                {
                    "sent": "We consider very particular isotonic function acting on four points zero and one which are assumed to be fixed points and two other points A&B at these two points.",
                    "label": 0
                },
                {
                    "sent": "A&B can be chosen arbitrarily from these particular intervals, so they should be.",
                    "label": 0
                },
                {
                    "sent": "Located in an interval sitting left of 1/2 and be in should be located in an interval sitting right on half OK and now we already know cause zero and one are fixed points that this function 5 we're considering here is to keep increasing so A&B are mapped to points in between zero and one.",
                    "label": 0
                },
                {
                    "sent": "OK, and we know even more.",
                    "label": 0
                },
                {
                    "sent": "We know that a is clearly closer to 0 than it is to one, and so the corresponding image point is the same property and we can infer that fee of a sits in the interval from zero to 100.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the next step.",
                    "label": 0
                },
                {
                    "sent": "And obviously, we can consider a function acting on eight points against you and one assumed to be fixed points.",
                    "label": 0
                },
                {
                    "sent": "Now we are considering eight points.",
                    "label": 0
                },
                {
                    "sent": "Specified on the insofar as they should lie in this very particular intervals here.",
                    "label": 0
                },
                {
                    "sent": "Located close to 1/4 + 1/2 and close to three forts OK. And now these intervals are chosen in a very particular way.",
                    "label": 1
                },
                {
                    "sent": "They are chosen such that Point C, Independent from its exact location in this interval, is always closer to 0 than it is to the point A.",
                    "label": 0
                },
                {
                    "sent": "Enter Points T is always closer to the point B, then it is to zero OK from the last slide.",
                    "label": 0
                },
                {
                    "sent": "We already know that fee of a is closer as smaller than 1/2.",
                    "label": 0
                },
                {
                    "sent": "And with all this information it is straightforward to infer that.",
                    "label": 0
                },
                {
                    "sent": "C is mapped to a point in this open interval here.",
                    "label": 0
                },
                {
                    "sent": "And similarly, we can infer that DNA are mapped to points sitting in these intervals here OK, and we can repeat this procedure not iteratively to gain a finer and finer grid on the unit interval together with an estimate for for the image points of the grid points.",
                    "label": 0
                },
                {
                    "sent": "And how does this help us now to prove our theorem but first become by simply rescaling guarantee that all our functions fiamm map on points zero and one such that these are fixed points and that it acts on points sitting between zero and one?",
                    "label": 0
                },
                {
                    "sent": "OK, now since this sequence X here system to be tense.",
                    "label": 0
                },
                {
                    "sent": "Through this rescaling, we can assume that it stands in the interval zero and one and if N is just large enough in each of the intervals we consider here, there is a point, and for these points we immediately have an estimation here.",
                    "label": 1
                },
                {
                    "sent": "And for the points in between, we get one because of the monotonicity, and this is enough information to prove that our sequence of rescaled functions Phi N can be approximated by the identity function.",
                    "label": 0
                },
                {
                    "sent": "So this is this catch 41 dimension decay.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The case D greater than one is more complicated to deal with and unfortunately I have to skip this right now.",
                    "label": 0
                },
                {
                    "sent": "But the idea of considering very party.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Killer's atomic functions acting on point set.",
                    "label": 0
                },
                {
                    "sent": "Trump specified on the insofar as that they should lay in some certain open pods.",
                    "label": 0
                },
                {
                    "sent": "This is the same here again.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, but instead of the proof, let me provide a more more general version of the theorem we have just seen becauses a local version, in contrast to the to the global version.",
                    "label": 0
                },
                {
                    "sent": "We have just seen before, OK, and here we assume that K is the union of bounded balls, such union of the interior of the balls is connected.",
                    "label": 0
                },
                {
                    "sent": "Again, we assume.",
                    "label": 0
                },
                {
                    "sent": "But we have sequence of points which is dancing K and again we are considering a sequence of function Phi an acting on the 1st endpoints.",
                    "label": 0
                },
                {
                    "sent": "Every function fight and again they should map to the same board.",
                    "label": 0
                },
                {
                    "sent": "But now instead of assuming that the functions for an isotonic and all of their domain.",
                    "label": 0
                },
                {
                    "sent": "We just assume that they are isotonic on the intersection of the domain with the balls Ki for every I. OK, not exactly the same statement holds true.",
                    "label": 0
                },
                {
                    "sent": "There is a sequence of similarity transformations approximating.",
                    "label": 0
                },
                {
                    "sent": "The sequence of functions for N such that the approximation error goes to 0.",
                    "label": 0
                },
                {
                    "sent": "And here, of course, there are two important generalizations.",
                    "label": 0
                },
                {
                    "sent": "So, first of all, we can deal with more general geometry's.",
                    "label": 0
                },
                {
                    "sent": "And the second one is that it's enough to consider functions which are not isotonic, and all of the other main, but just on these small subregions.",
                    "label": 0
                },
                {
                    "sent": "OK, but this is a simple corollary of our global version for the following reason.",
                    "label": 0
                },
                {
                    "sent": "So assume for simplicity that K is just a union of K1 and K2.",
                    "label": 0
                },
                {
                    "sent": "And then from the global version, we know that we can approximate the sequence fire embers sequence of similarities on cave on, and we can do the same on K2.",
                    "label": 0
                },
                {
                    "sent": "But now if S1 is a similarity transformation approximating a function fire on Kevin, and there's two, is a similarity transformation approximating function file an NK2?",
                    "label": 0
                },
                {
                    "sent": "They're both good approximations for point in the intersection of K1 and K2 now, because as fun, and there's two are both defined functions and.",
                    "label": 0
                },
                {
                    "sent": "The Union of Kevin and Katie responded.",
                    "label": 0
                },
                {
                    "sent": "These two similarity transformations cannot be two different on all of care.",
                    "label": 0
                },
                {
                    "sent": "So this is not not hard to prove.",
                    "label": 0
                },
                {
                    "sent": "Once we have the global version.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm almost done with my talk, but I want to address some open questions.",
                    "label": 0
                },
                {
                    "sent": "But the first one is in our.",
                    "label": 0
                },
                {
                    "sent": "In our paper, we provide the ferum.",
                    "label": 0
                },
                {
                    "sent": "Guarantee there are some tatik uniqueness of ordinal embeddings up to similarity transformations, but we don't provide any error bounds.",
                    "label": 0
                },
                {
                    "sent": "So in principle one could use our estimates to derive error bounds by making explicit some parameters, but we haven't make this effort.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "'cause we're pretty sure that that their rates we would gain in this way would be much too weak.",
                    "label": 0
                },
                {
                    "sent": "So numerically examples suggest.",
                    "label": 0
                },
                {
                    "sent": "That the rates of convergence are quite fast, but you can see here is.",
                    "label": 0
                },
                {
                    "sent": "The red points are uniformly drawn at random from the unit square.",
                    "label": 0
                },
                {
                    "sent": "And the blue points are an ordinal embedding based on all ordinal comparisons coming from the red points OK.",
                    "label": 0
                },
                {
                    "sent": "These blueprints were calculated by a standard embedding algorithm and now you should know that all these embedding algorithms infects over minimization problem and I've run this algorithm for 100 times and in the end I never obtained solution reconstructing the red points versed in the blue points, but it brought it here in the figure.",
                    "label": 0
                },
                {
                    "sent": "OK, and you can see that for N equal to five, there is some difference between the original red points and its ordinal embedding.",
                    "label": 0
                },
                {
                    "sent": "But already for M equal to temp, this difference has almost vanished at all and for N = 30.",
                    "label": 0
                },
                {
                    "sent": "It isn't to see anymore at all.",
                    "label": 0
                },
                {
                    "sent": "So what I want to say is it is still an open problem to provide meaningful error bounds.",
                    "label": 0
                },
                {
                    "sent": "Second, open question.",
                    "label": 0
                },
                {
                    "sent": "I want to address.",
                    "label": 0
                },
                {
                    "sent": "Here is closely related to the local version.",
                    "label": 0
                },
                {
                    "sent": "We have just seen on the previous lead.",
                    "label": 0
                },
                {
                    "sent": "So there we have seen that instead of assuming that the functions for N as a tonic and all of their domain, it is sufficient.",
                    "label": 0
                },
                {
                    "sent": "To assume them to be as a tonic on small overlapping sub regions.",
                    "label": 0
                },
                {
                    "sent": "So this gives to us today question what is the minimum amount of ordinal information that is necessary for guaranteeing a unique ordinal embedding?",
                    "label": 0
                },
                {
                    "sent": "Yet the last question is, how can one deal with data that doesn't allow it perfectly limited?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Let me just say I also prepared a poster, and in case you want to hear about this stuff in more detail, I'm looking forward to seeing you there.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        }
    }
}