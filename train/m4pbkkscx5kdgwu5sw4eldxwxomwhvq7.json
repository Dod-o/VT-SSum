{
    "id": "m4pbkkscx5kdgwu5sw4eldxwxomwhvq7",
    "title": "Comparing Apples and Oranges - Measuring Differences between Data Mining Results",
    "info": {
        "produced by": [
            "Data & Web Mining Lab"
        ],
        "author": [
            "Jilles Vreeken, Department of Mathematics and Computer Science, University of Antwerp"
        ],
        "published": "Nov. 30, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_vreeken_differences/",
    "segmentation": [
        [
            "Everybody still good morning.",
            "Like Doctor said, I'm jealous Vega this is joint work with neglect attic sitting over there.",
            "Both of us are postdocs in the lab of particle Towson University of Antwerp.",
            "And today I'm going to tell you about how you can compare apples to oranges, and do so in a meaningful manner."
        ],
        [
            "Questions today.",
            "Being sold at auction today and just disregard that this is the main question.",
            "How can we decide whether different results and possibly different mining our lives on the same data set actually provide significantly different information?",
            "So are we just rediscovering the same stuff or do we find really different stuff?",
            "The quest"
        ],
        [
            "That we want to address.",
            "So first thing you might ask, why?",
            "Why do you want that?",
            "I mean, we're data miners were fond of generating new algorithms to find new structures and data, so let's not bother with that.",
            "Well, suppose we have one data set an.",
            "Suppose it's a gene amplification data set.",
            "So we have some biologists on board, and we have one.",
            "First one analyst, let's call him Yahoo, Yahoo, home and to be precise.",
            "And yes, analyze this data set quite extensively, mainly through clustering, and he found some interesting things.",
            "And then there's some other day to English, on board so equal.",
            "I for instance before Mumbai and myself to just name example and we are passing minors so we don't bother with clustering readers.",
            "Mind patterns on the data in different sets of patterns, and we're confident that these patterns there really informative.",
            "So now Jacko and jealous example analysts they come together, they meet and like, well, we analyzed this data.",
            "How can we compare results when we might have been discovered the same thing?",
            "You might have been discovering completely different things.",
            "How can we tell?",
            "Well, of course.",
            "1 answers better.",
            "That's just look at your results.",
            "However, data mining results typically are quite complex.",
            "Experts are not abundantly available, particularly experts with lots of time and willing to analyze detailed results.",
            "So it would be nice if we can sort of comfort a way to measure likeness of results ourselves.",
            "The main complexity, of course, is that screen instead of patterns or a clustering well, apples and oranges.",
            "They are clearly different things and we can't just map into the same thing.",
            "It's not like the previous talk.",
            "We have a classification problem where there's one clear objective function, and you could just say OK, AUC is higher for method A.",
            "An lower masterpiece.",
            "OK, would you prefer high AOC?"
        ],
        [
            "So more why?",
            "The main thing of data mining, in our opinion is that OK you have data and want to find as much insight on the date as we can.",
            "I just sent there's with aura of different algorithms out there and there's no way we can run all of them.",
            "Even if we could get all the implementations getting compiled.",
            "Let's say we could.",
            "There's no way that we can analyze all these results, so just purely theoretically speaking, there's no way we can find all information from the data that's possible.",
            "So it would be nice to sort of be able beforehand to identify which results you want analyze or which methods we should be running.",
            "We've already know something with data, for instance.",
            "Which brings us to the second point.",
            "Data mining is actually a really excited procedure.",
            "Mean you have some data and you know something about it, and if you, even if you don't, you start to do something with it.",
            "You analyze some results that gives you some knowledge about the data, but given that knowledge or something you might be interested in other stuff because you don't want to rediscover it.",
            "The same stuff all over again.",
            "So then the main question is like what methods should we apply next?",
            "Or if the method gives a range of resource, which of those results should actually analyze?",
            "Which results gave us most information given we know.",
            "So all we need to measure to be able to see how different we saw."
        ],
        [
            "Star.",
            "Then we come to the main goal, of course, meaning data mining.",
            "If we offer insight that well, what's the objective function?",
            "And there is no.",
            "Never mind we have message but interesting listen clustering their message for similarity, all trying to formalize what is inside, but nobody really captured it completely.",
            "And the other thing is that data mining results, whether clustering or pattern for complex objects.",
            "So there are difficult to compare directly, and it's really difficult to define the generic measure between them.",
            "So it's comparing apples to oranges, and there's no way to do it.",
            "So in order to do it, we need a common language.",
            "We need to be able to translate different results.",
            "I think that we can."
        ],
        [
            "This is the main idea of the paper building right now, so I could almost say this is the most important slide.",
            "But let's wait two or three more slides.",
            "Let's imagine the universe of all possible datasets.",
            "Over the universe, let's say all datasets with the same dimensions today except for analyze.",
            "So this gene application data set, for instance, let's say it's a matrix right now, so that wasn't attributes, thousand rows, whatever.",
            "Universal every possum."
        ],
        [
            "Association so we have some results for this data.",
            "Could be a cluster, but let's keep things really simple.",
            "Let's say my result completely trivially only states that value in the top left corner of the Matrix 10.",
            "Doesn't convey much information, but Alas, it's a result.",
            "Of course, that result sort of limits the number of possible datasets, so it specifies a subset of our big universe.",
            "All possible datasets.",
            "Let's say that's the blue circle here.",
            "Specifies this subset, which for which all the datasets in this model they sort of satisfied your results.",
            "They agree with it.",
            "No."
        ],
        [
            "Best Apple obviously.",
            "We also need an orange, so this is the 2nd result and again specifies some some part of this universe.",
            "And if we have this."
        ],
        [
            "Then you can already see we're going to look at the overlap, because the more 2 results specify the same subspace of the data universe, the more they actually providing the same information.",
            "Cause by specifying a subset of the data space.",
            "That's only be done by giving you a statistical information, statistics, local information on datasets.",
            "Now of course the main question is going to be."
        ],
        [
            "That's great.",
            "How are we going to measure it?",
            "So the main notion before we get to that is that observation we make, so I might even say this is the most important slide bit more formal than previously.",
            "A result are whatever it is.",
            "Maybe a clustering.",
            "So specifying these rows in a data set have a similarity such and.",
            "So this is the centroid at all.",
            "It only holds for a subset of all possible datasets.",
            "Actually, we should make it a bit more probabilistic.",
            "You might even say that the result specifies some datasets are more likely from that perspective than other datasets.",
            "So for instance, in the case that if I say the top left results 10 if it's 9.9, OK, perhaps we might allow it.",
            "If it's zero, OK, quite less likely, so that's a data set that's not part of our data subspace.",
            "So implicitly, any results.",
            "Any data mining result, any information that you give me about a data set implicitly defines a distribution over datasets.",
            "Let's remain observation, making this paper, and then from that.",
            "Believes that if we have similar distributions because similar distributions from two different results are actually looking at results that are providing the same information.",
            "Because they're telling us that they make the same datasets equally likely, which can only happen if they provide the same info."
        ],
        [
            "So hence older son at some point that comparing data mining results on a really abstract level is just comparing distributions distributions over datasets to be precise, and the larger the overlap between these distributions, more more information than to risk results share."
        ],
        [
            "Of course, the big question is how the heck do we measure this overload?",
            "The main thing we want to solve it well, the first thing is the common language.",
            "So we translate our results into a distribution of datasets later in the second.",
            "Once we have these distributions, statistics and information theory to be fair.",
            "To be more specific, provides all sorts of tools to compare between distributions and measure how much they overlap is.",
            "So up till now it's really general.",
            "As you see that."
        ],
        [
            "The orders are nicely colored.",
            "Now we move to a more specific example because we don't solve the complete problem at once.",
            "We first give an example for binary data in this paper.",
            "And now the recipe that we follow is that we can translate resource vibrator into noisy tiles.",
            "The next slide will explain what noisy tires.",
            "Then, given these sets of knowledge tiles which actually are common language, translate them into a probabilistic model.",
            "The maximum entropy model, and then we can build a measure based on kullback Leiber diversions, which is an ocean from information theory that comparison overlay."
        ],
        [
            "Redistributions First things first, how do we translate results to tile sets?",
            "Well, our situation was for binary data.",
            "The most elementary notion of structure that you want to do to capture with the result whether it's a clustering, whether it's a better settlement, is a decision tree, whatnot.",
            "Basically, you're stating that for a submatrix full matrix to see a particular number of once.",
            "Perhaps even follow some structure, but let's keep it simple.",
            "So that I'll know she's just a submatrix and the frequency of how many ones we see there, so probability on each of the entries you might say."
        ],
        [
            "So for instance, well, regular license.",
            "They can naturally be translated into these styles or noisy tires.",
            "It's just looking OK.",
            "Which items do we include?",
            "Which rose do we see in the original data that satisfy the active set and then we are mostly tiles, so fault tolerant item sets you may equally equally easy matrix factorizations looking for dense areas in the data spectral blade data into few factors, same thing.",
            "It's quite straightforward, mean quite close to their original language.",
            "However it's much more general.",
            "So for instance, for clustering, if you sell one distance and say they means, and actually what you're doing, you're giving a centroid and center.",
            "It basically specifies the average of ones that you see for attributes, which is something that we can really easily translate into noisy tiles, because basically for the Rose the cluster specifies for each of the attributes we just created noisy tile specifying.",
            "How many once we actually see the data?",
            "Same thing for subspace clustering.",
            "So subspace clustering on binary data actually is sort of noisy item set mining."
        ],
        [
            "OK, good now we have translated our result into a set of tiles so my results jacos result all results.",
            "So we have all these tile sets.",
            "Now we have to build this probabilistic model for it.",
            "Features to use the maximum entropy model and this is a choice.",
            "There are other options.",
            "We believe the mental model is particularly suited for this case.",
            "Rose has some very really nice properties.",
            "It's full Santa Claus with exponential models, which makes for this case and we can compute it really, really easily.",
            "And Secondly, the really nice thing about the maximum entropy model is that it has no bias.",
            "You put something into the model conditioner model.",
            "That's the only information you can get out.",
            "All the rest we don't know anything about.",
            "It won't say anything about it, so no bias, which is, we believe, good because we don't want to have bias when you're measuring stuff should not be that my result is automatically better than apples result, so let's see.",
            "Inside this is the empty measurement.",
            "Remodel portable, a matrix of bye bye bye and if it's empty for a binary database we know nothing.",
            "So basically for every entry, the probability that we see a 0 / 1 just 5050.",
            "So all these ones has over here.",
            "I would say that we do know something.",
            "So for instance, Jackal threshold specifies the top left corner.",
            "This tile has a frequency of one only once and in the bottom right corner same thing.",
            "However it is larger tile over here.",
            "Well, I know there's ten months.",
            "That's what I observed in the data, but I don't tell you where they are.",
            "Then the maximum entropy distribution because we already have these ones are used in these six, so we already know where eight of the ones are, so there are still 2 ones to be accounted for.",
            "And because there are 12 positions left, the probability within each of these cells were seeing one just one 60.",
            "Same thing for the right hand side example, but that we are considering exact ONS exact tiles or just tell us which frequency zero or one.",
            "Phil."
        ],
        [
            "Boring.",
            "OK, before we go to our measure and how we actually compare between results, let's consider background knowledge because if you already know something about the data and like said, I strongly believe that data mining initiative process you don't start completely naively.",
            "Typically what you already know.",
            "Other data determines what you find interesting, and it might actually be that Yahoo's result, if you take it just on face value, is much more detailed than mine, but it might actually be that some of those details or something we already know.",
            "So then you want to measure like, OK, how much new information does.",
            "Yahoo still bring to the table how much new information that might result into the table so.",
            "This is something our methods measure really usually provides for basically, as long as you can translate your background knowledge into noisy tiles, we can build our mental model and there we go.",
            "And like I said, on binary data, pretty much anything you know about the data can be translated into noise."
        ],
        [
            "OK, finally our measure.",
            "This is what it looks like, but the main thing we have one resultset, but I'll settle for sale Dallas result.",
            "That's T1 and T2.",
            "That onset of my result after translation.",
            "Then we have some background knowledge.",
            "Again, the tile set and if we drop them altogether, so whole tiles in just one big file.",
            "We called N. So the mutual dowsett you could say.",
            "Then normal pullback lighter measures the overlap between distributions, so.",
            "It also nonsymmetric.",
            "Which is something that typically, for a measure we don't really want, so we will measure like this this part over here basically says the pain was divergent between knowing everything and knowing not my result for Jack Russells in the background knowledge.",
            "So basically would say, how much do you miss my result when you want to know the combination?",
            "The right hand side on the bar does the opposite.",
            "So how much do we miss ya cause result if it's not available?",
            "And then we normalize by the whole bunch?",
            "It is a measure and in the sense that it goes to 0 if distributions are like a very very large overlap.",
            "Or complete overlap computer size and it goes to two.",
            "If the piece of information are basic.",
            "Basically conservation area.",
            "And it goes to one if it's orthogonal or providing something slightly different than my quite differently, but the results do agree somewhat.",
            "OK, one fun fact.",
            "I would like to point out.",
            "If you're just considering acceptance so simple case, so not like the frequencies were just specifying this part of the data only zeros here, only ones, that's it.",
            "Actually this measure coincides with Jakarta similarity, which is a nice size resulted.",
            "So give some intuition that we might be on."
        ],
        [
            "My truck here.",
            "OK, good user measure for all sorts of cool things.",
            "Obviously first of all, the main question we started off with our results.",
            "Similar.",
            "We do give a number for that, but that's basically OK, but that's what we're after, so of course we solve that.",
            "What can we do?",
            "Use it more for one of the cool things is we can visualize the big picture as we call it so we can run many algorithms, potentially on many datasets, and you can sort of see it like which methods in general provide similar information.",
            "OK thanks, let's get into it.",
            "Similarly for prescribing partial results and only thing I want to point out in this slide is this mining iteratively.",
            "So basically, let's say that.",
            "You all of you guys give me iteratively bunch of results and I can only analyze for one thing at a time or something, or just a moment is OK.",
            "The expert is tired, but let's let's let's talk with it.",
            "So basically, each time I want to find that result which will provide the most information.",
            "But something that you can easily pick out."
        ],
        [
            "With this method.",
            "OK, good 'cause we also experimented because up till now it was smaller theoretical and then it's very theoretical and the high level.",
            "So we apply 10 different data mining algorithms for different datasets and be considered four different types of back online.",
            "So there were six pattern mining button set mining algorithms which basically for those who are not aware of that and said mining and its intricacies basically comes down.",
            "Find me a small group of patterns that together characterize the data easily.",
            "So for instance you can think of a set cover kind of thing.",
            "Big chunks, every general explanation, and there's a whole range of different orders which specifies slightly differently and give you information.",
            "For clustering, we consider gaming simple K means.",
            "Consider trying to buy clustering or we apply K means of on the rows and columns which has been shown to give realize results.",
            "Clustering paper which is clustered Rosen binary data and subspace clustering algorithm."
        ],
        [
            "This is the big picture.",
            "Also telling you about so this is averaged over 4 datasets that we considered.",
            "I don't want to go into each specific data set, so that's what efforts over here stands for, and basically what we did between for Rachel to datasets and all the results.",
            "We measured the pairwise similarities before this whole matrix, and then we applied multidimensional scaling.",
            "So basically here if stuff is close together typically have small the dissimilarity special.",
            "So for instance, if the background knowledge is just completely empty and you see that the clustering algorithms here in lower left column, they basically provide the same information.",
            "I'll get back to that in a moment while we also see that the more I would mining or I can set bedroom set mining algorithms are also quite clumped together so they sort of give you the same information which makes sense, however.",
            "This is with the account information.",
            "Nothing so basically are.",
            "We don't literally don't know about the data.",
            "However, for most datasets pirate access there are sparse.",
            "Sorry, that's and that's something that you can know pretty much off the bat.",
            "So the moment we apply the density spectrum knowledge, which is basically one huge tile, spending the whole data set and just telling you how many ones do we observe in the whole data set and all of a sudden you see that the clustering algorithms they can spread out quite a bit.",
            "And why is that?",
            "Well, just by the nature of their method.",
            "They pretty much spend the whole day to you.",
            "Give your clusters covering the whole data well.",
            "The item set mining things or they only cover parts of the data.",
            "So the moment.",
            "So in this case basically the clustering algorithms tell you like all the data is really sparse at the moment you already know the data is sparse.",
            "Then you can actually see that they do provide extra information on top of that.",
            "So one thing that you can do with this picture, like previews that let's just consider this picture, is the most easiest.",
            "Currently.",
            "Let's say our expert says, OK, well, I'm kind of tired, but one one hour after supper and I wouldn't mind analyzing 2 results.",
            "That's OK with me and using this picture sort of specify OK, perhaps should pick one from these 'cause they're really similar to each other and just pick one of these.",
            "And then you're basically spanning the information space if you wish quite well.",
            "Good."
        ],
        [
            "One other thing.",
            "One application of our measure, we can redescribe partial results.",
            "And basically this means that we can sort of explain, so you give me one cluster and I can see which parts of my own results a set of patterns provides the same information so I can start, uh, start to grab parts of my pattern set to describe one cluster, or vice versa.",
            "Or I can describe one cluster using other clusters, or I can describe part of a decision tree using clusters.",
            "So here we compare between 3 tile mining methods and on the intuitive data sets the data sets on abstracts from the ICM conferences.",
            "Courtesy to tell the people I don't see someone over there and data is turned into another set database and.",
            "Haha.",
            "And basically what we can do, we can grab some of the patterns from print and we can see which patterns over here best approximate this information without giving extra information.",
            "So this guy gets really specific stuff, but that provides more information than we have here.",
            "So only give me the most general advice over here and this guy only gets really specific things."
        ],
        [
            "Don't get so much so conclusions.",
            "Comparing ourselves is really important and we haven't paid.",
            "We've been being intending it to.",
            "It's pretty much at all in data mining statistics.",
            "We have data mining methods, so we really should do it.",
            "Exploratory data mining.",
            "We gave an example how to do it by measuring information content and we gave a specific example how to do it on binary data.",
            "I've got lots."
        ],
        [
            "Push to shave and stop waving frantically, so that's it.",
            "Thank you, thank you.",
            "Yes, we're running out of time, but we will have some questions.",
            "Thank you for this nice dog.",
            "In your disparity measure, you use at the KL divergent OK, and my question is did you test other dimensions measures, and if so, did you did you?",
            "Obtaining fact the same visual results.",
            "Nope, sorry condolences also know.",
            "And indeed the KL is a choice.",
            "You can use any diversions message that you would like would deem appropriate for your distribution.",
            "Similar with the Messenger solution, it's also a choice we feel that's mean from pretty much lot of evidence in information theory research to actually make a lot of sense.",
            "Chose it because of computation.",
            "So your message is capable of comparing results given the data set of different methods, but for some of the application that you sketched, it would be more desirable to generally run the similarity between methods on the space of all datasets available.",
            "So is there any advance in this direction?",
            "Thinking about it, that's the main thing I mean right now, the best we can do is just run it on different datasets and average results.",
            "That's pretty much what I showed here, and generalizing even more on that.",
            "It's quite easy model.",
            "Basically the probabilistic model for date of specific dimensions.",
            "As long as those are fixed, we can do quite a lot, but this is stable.",
            "So what you showed about clustering, for instance, an pattern discovery.",
            "So that's usually together in.",
            "So I might be totally wrong, but isn't there some relation between this view that you present here and the geometric interpretation of what you do to your data?",
            "So you have the data and then dimensional space, and then you know different data mining operators will cut it in different ways or group it or something like this.",
            "And I think there might be some sort of similarity to that so that you would say that two operators to more or less the same thing.",
            "If you have the same subspaces.",
            "But then it begs the question that in fact there is more to it than that, because if you look at an Association rule, it will also tell you what actually will put things together and your clustering doesn't necessarily tell you that so.",
            "I'm not sure it's exactly the same information that you get.",
            "You know when you say that they will know indeed is even right now.",
            "Our translation ocean tiles is quite crude.",
            "I mean, that's really quite some information that's actually future work.",
            "I wasn't allowed to point out your representation.",
            "Seriously, considering all richer data types of numeric data, for instance as well as Richard translations.",
            "So within these talks within these sub matrices, identifying once the particular structure?",
            "Or was that like an Association rule?",
            "If you tell me this and that correlate such and so something that.",
            "You should be able to quite easily incorporated.",
            "Which barely between members.",
            "Same thing for clustering for different similarity measures.",
            "I mean we can only do so much.",
            "OK, I have to ask you to take the rest of the discussion software and then we continue with the presentation.",
            "Then let's type less once again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Everybody still good morning.",
                    "label": 0
                },
                {
                    "sent": "Like Doctor said, I'm jealous Vega this is joint work with neglect attic sitting over there.",
                    "label": 0
                },
                {
                    "sent": "Both of us are postdocs in the lab of particle Towson University of Antwerp.",
                    "label": 0
                },
                {
                    "sent": "And today I'm going to tell you about how you can compare apples to oranges, and do so in a meaningful manner.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Questions today.",
                    "label": 0
                },
                {
                    "sent": "Being sold at auction today and just disregard that this is the main question.",
                    "label": 0
                },
                {
                    "sent": "How can we decide whether different results and possibly different mining our lives on the same data set actually provide significantly different information?",
                    "label": 1
                },
                {
                    "sent": "So are we just rediscovering the same stuff or do we find really different stuff?",
                    "label": 0
                },
                {
                    "sent": "The quest",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we want to address.",
                    "label": 0
                },
                {
                    "sent": "So first thing you might ask, why?",
                    "label": 0
                },
                {
                    "sent": "Why do you want that?",
                    "label": 0
                },
                {
                    "sent": "I mean, we're data miners were fond of generating new algorithms to find new structures and data, so let's not bother with that.",
                    "label": 0
                },
                {
                    "sent": "Well, suppose we have one data set an.",
                    "label": 0
                },
                {
                    "sent": "Suppose it's a gene amplification data set.",
                    "label": 0
                },
                {
                    "sent": "So we have some biologists on board, and we have one.",
                    "label": 0
                },
                {
                    "sent": "First one analyst, let's call him Yahoo, Yahoo, home and to be precise.",
                    "label": 0
                },
                {
                    "sent": "And yes, analyze this data set quite extensively, mainly through clustering, and he found some interesting things.",
                    "label": 0
                },
                {
                    "sent": "And then there's some other day to English, on board so equal.",
                    "label": 0
                },
                {
                    "sent": "I for instance before Mumbai and myself to just name example and we are passing minors so we don't bother with clustering readers.",
                    "label": 0
                },
                {
                    "sent": "Mind patterns on the data in different sets of patterns, and we're confident that these patterns there really informative.",
                    "label": 0
                },
                {
                    "sent": "So now Jacko and jealous example analysts they come together, they meet and like, well, we analyzed this data.",
                    "label": 0
                },
                {
                    "sent": "How can we compare results when we might have been discovered the same thing?",
                    "label": 1
                },
                {
                    "sent": "You might have been discovering completely different things.",
                    "label": 0
                },
                {
                    "sent": "How can we tell?",
                    "label": 0
                },
                {
                    "sent": "Well, of course.",
                    "label": 0
                },
                {
                    "sent": "1 answers better.",
                    "label": 0
                },
                {
                    "sent": "That's just look at your results.",
                    "label": 0
                },
                {
                    "sent": "However, data mining results typically are quite complex.",
                    "label": 0
                },
                {
                    "sent": "Experts are not abundantly available, particularly experts with lots of time and willing to analyze detailed results.",
                    "label": 0
                },
                {
                    "sent": "So it would be nice if we can sort of comfort a way to measure likeness of results ourselves.",
                    "label": 0
                },
                {
                    "sent": "The main complexity, of course, is that screen instead of patterns or a clustering well, apples and oranges.",
                    "label": 1
                },
                {
                    "sent": "They are clearly different things and we can't just map into the same thing.",
                    "label": 0
                },
                {
                    "sent": "It's not like the previous talk.",
                    "label": 0
                },
                {
                    "sent": "We have a classification problem where there's one clear objective function, and you could just say OK, AUC is higher for method A.",
                    "label": 0
                },
                {
                    "sent": "An lower masterpiece.",
                    "label": 0
                },
                {
                    "sent": "OK, would you prefer high AOC?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So more why?",
                    "label": 0
                },
                {
                    "sent": "The main thing of data mining, in our opinion is that OK you have data and want to find as much insight on the date as we can.",
                    "label": 0
                },
                {
                    "sent": "I just sent there's with aura of different algorithms out there and there's no way we can run all of them.",
                    "label": 1
                },
                {
                    "sent": "Even if we could get all the implementations getting compiled.",
                    "label": 0
                },
                {
                    "sent": "Let's say we could.",
                    "label": 0
                },
                {
                    "sent": "There's no way that we can analyze all these results, so just purely theoretically speaking, there's no way we can find all information from the data that's possible.",
                    "label": 0
                },
                {
                    "sent": "So it would be nice to sort of be able beforehand to identify which results you want analyze or which methods we should be running.",
                    "label": 0
                },
                {
                    "sent": "We've already know something with data, for instance.",
                    "label": 0
                },
                {
                    "sent": "Which brings us to the second point.",
                    "label": 1
                },
                {
                    "sent": "Data mining is actually a really excited procedure.",
                    "label": 0
                },
                {
                    "sent": "Mean you have some data and you know something about it, and if you, even if you don't, you start to do something with it.",
                    "label": 0
                },
                {
                    "sent": "You analyze some results that gives you some knowledge about the data, but given that knowledge or something you might be interested in other stuff because you don't want to rediscover it.",
                    "label": 0
                },
                {
                    "sent": "The same stuff all over again.",
                    "label": 1
                },
                {
                    "sent": "So then the main question is like what methods should we apply next?",
                    "label": 0
                },
                {
                    "sent": "Or if the method gives a range of resource, which of those results should actually analyze?",
                    "label": 0
                },
                {
                    "sent": "Which results gave us most information given we know.",
                    "label": 1
                },
                {
                    "sent": "So all we need to measure to be able to see how different we saw.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Star.",
                    "label": 0
                },
                {
                    "sent": "Then we come to the main goal, of course, meaning data mining.",
                    "label": 0
                },
                {
                    "sent": "If we offer insight that well, what's the objective function?",
                    "label": 0
                },
                {
                    "sent": "And there is no.",
                    "label": 0
                },
                {
                    "sent": "Never mind we have message but interesting listen clustering their message for similarity, all trying to formalize what is inside, but nobody really captured it completely.",
                    "label": 0
                },
                {
                    "sent": "And the other thing is that data mining results, whether clustering or pattern for complex objects.",
                    "label": 0
                },
                {
                    "sent": "So there are difficult to compare directly, and it's really difficult to define the generic measure between them.",
                    "label": 0
                },
                {
                    "sent": "So it's comparing apples to oranges, and there's no way to do it.",
                    "label": 1
                },
                {
                    "sent": "So in order to do it, we need a common language.",
                    "label": 1
                },
                {
                    "sent": "We need to be able to translate different results.",
                    "label": 0
                },
                {
                    "sent": "I think that we can.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the main idea of the paper building right now, so I could almost say this is the most important slide.",
                    "label": 0
                },
                {
                    "sent": "But let's wait two or three more slides.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine the universe of all possible datasets.",
                    "label": 1
                },
                {
                    "sent": "Over the universe, let's say all datasets with the same dimensions today except for analyze.",
                    "label": 0
                },
                {
                    "sent": "So this gene application data set, for instance, let's say it's a matrix right now, so that wasn't attributes, thousand rows, whatever.",
                    "label": 0
                },
                {
                    "sent": "Universal every possum.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Association so we have some results for this data.",
                    "label": 0
                },
                {
                    "sent": "Could be a cluster, but let's keep things really simple.",
                    "label": 0
                },
                {
                    "sent": "Let's say my result completely trivially only states that value in the top left corner of the Matrix 10.",
                    "label": 0
                },
                {
                    "sent": "Doesn't convey much information, but Alas, it's a result.",
                    "label": 0
                },
                {
                    "sent": "Of course, that result sort of limits the number of possible datasets, so it specifies a subset of our big universe.",
                    "label": 0
                },
                {
                    "sent": "All possible datasets.",
                    "label": 0
                },
                {
                    "sent": "Let's say that's the blue circle here.",
                    "label": 0
                },
                {
                    "sent": "Specifies this subset, which for which all the datasets in this model they sort of satisfied your results.",
                    "label": 0
                },
                {
                    "sent": "They agree with it.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best Apple obviously.",
                    "label": 0
                },
                {
                    "sent": "We also need an orange, so this is the 2nd result and again specifies some some part of this universe.",
                    "label": 0
                },
                {
                    "sent": "And if we have this.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you can already see we're going to look at the overlap, because the more 2 results specify the same subspace of the data universe, the more they actually providing the same information.",
                    "label": 0
                },
                {
                    "sent": "Cause by specifying a subset of the data space.",
                    "label": 0
                },
                {
                    "sent": "That's only be done by giving you a statistical information, statistics, local information on datasets.",
                    "label": 0
                },
                {
                    "sent": "Now of course the main question is going to be.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's great.",
                    "label": 0
                },
                {
                    "sent": "How are we going to measure it?",
                    "label": 0
                },
                {
                    "sent": "So the main notion before we get to that is that observation we make, so I might even say this is the most important slide bit more formal than previously.",
                    "label": 0
                },
                {
                    "sent": "A result are whatever it is.",
                    "label": 1
                },
                {
                    "sent": "Maybe a clustering.",
                    "label": 0
                },
                {
                    "sent": "So specifying these rows in a data set have a similarity such and.",
                    "label": 0
                },
                {
                    "sent": "So this is the centroid at all.",
                    "label": 0
                },
                {
                    "sent": "It only holds for a subset of all possible datasets.",
                    "label": 1
                },
                {
                    "sent": "Actually, we should make it a bit more probabilistic.",
                    "label": 0
                },
                {
                    "sent": "You might even say that the result specifies some datasets are more likely from that perspective than other datasets.",
                    "label": 0
                },
                {
                    "sent": "So for instance, in the case that if I say the top left results 10 if it's 9.9, OK, perhaps we might allow it.",
                    "label": 0
                },
                {
                    "sent": "If it's zero, OK, quite less likely, so that's a data set that's not part of our data subspace.",
                    "label": 0
                },
                {
                    "sent": "So implicitly, any results.",
                    "label": 0
                },
                {
                    "sent": "Any data mining result, any information that you give me about a data set implicitly defines a distribution over datasets.",
                    "label": 0
                },
                {
                    "sent": "Let's remain observation, making this paper, and then from that.",
                    "label": 0
                },
                {
                    "sent": "Believes that if we have similar distributions because similar distributions from two different results are actually looking at results that are providing the same information.",
                    "label": 0
                },
                {
                    "sent": "Because they're telling us that they make the same datasets equally likely, which can only happen if they provide the same info.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So hence older son at some point that comparing data mining results on a really abstract level is just comparing distributions distributions over datasets to be precise, and the larger the overlap between these distributions, more more information than to risk results share.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course, the big question is how the heck do we measure this overload?",
                    "label": 1
                },
                {
                    "sent": "The main thing we want to solve it well, the first thing is the common language.",
                    "label": 0
                },
                {
                    "sent": "So we translate our results into a distribution of datasets later in the second.",
                    "label": 1
                },
                {
                    "sent": "Once we have these distributions, statistics and information theory to be fair.",
                    "label": 0
                },
                {
                    "sent": "To be more specific, provides all sorts of tools to compare between distributions and measure how much they overlap is.",
                    "label": 0
                },
                {
                    "sent": "So up till now it's really general.",
                    "label": 0
                },
                {
                    "sent": "As you see that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The orders are nicely colored.",
                    "label": 0
                },
                {
                    "sent": "Now we move to a more specific example because we don't solve the complete problem at once.",
                    "label": 0
                },
                {
                    "sent": "We first give an example for binary data in this paper.",
                    "label": 1
                },
                {
                    "sent": "And now the recipe that we follow is that we can translate resource vibrator into noisy tiles.",
                    "label": 1
                },
                {
                    "sent": "The next slide will explain what noisy tires.",
                    "label": 0
                },
                {
                    "sent": "Then, given these sets of knowledge tiles which actually are common language, translate them into a probabilistic model.",
                    "label": 1
                },
                {
                    "sent": "The maximum entropy model, and then we can build a measure based on kullback Leiber diversions, which is an ocean from information theory that comparison overlay.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Redistributions First things first, how do we translate results to tile sets?",
                    "label": 1
                },
                {
                    "sent": "Well, our situation was for binary data.",
                    "label": 1
                },
                {
                    "sent": "The most elementary notion of structure that you want to do to capture with the result whether it's a clustering, whether it's a better settlement, is a decision tree, whatnot.",
                    "label": 0
                },
                {
                    "sent": "Basically, you're stating that for a submatrix full matrix to see a particular number of once.",
                    "label": 0
                },
                {
                    "sent": "Perhaps even follow some structure, but let's keep it simple.",
                    "label": 0
                },
                {
                    "sent": "So that I'll know she's just a submatrix and the frequency of how many ones we see there, so probability on each of the entries you might say.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for instance, well, regular license.",
                    "label": 0
                },
                {
                    "sent": "They can naturally be translated into these styles or noisy tires.",
                    "label": 0
                },
                {
                    "sent": "It's just looking OK.",
                    "label": 0
                },
                {
                    "sent": "Which items do we include?",
                    "label": 0
                },
                {
                    "sent": "Which rose do we see in the original data that satisfy the active set and then we are mostly tiles, so fault tolerant item sets you may equally equally easy matrix factorizations looking for dense areas in the data spectral blade data into few factors, same thing.",
                    "label": 1
                },
                {
                    "sent": "It's quite straightforward, mean quite close to their original language.",
                    "label": 0
                },
                {
                    "sent": "However it's much more general.",
                    "label": 0
                },
                {
                    "sent": "So for instance, for clustering, if you sell one distance and say they means, and actually what you're doing, you're giving a centroid and center.",
                    "label": 0
                },
                {
                    "sent": "It basically specifies the average of ones that you see for attributes, which is something that we can really easily translate into noisy tiles, because basically for the Rose the cluster specifies for each of the attributes we just created noisy tile specifying.",
                    "label": 0
                },
                {
                    "sent": "How many once we actually see the data?",
                    "label": 0
                },
                {
                    "sent": "Same thing for subspace clustering.",
                    "label": 0
                },
                {
                    "sent": "So subspace clustering on binary data actually is sort of noisy item set mining.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good now we have translated our result into a set of tiles so my results jacos result all results.",
                    "label": 0
                },
                {
                    "sent": "So we have all these tile sets.",
                    "label": 0
                },
                {
                    "sent": "Now we have to build this probabilistic model for it.",
                    "label": 1
                },
                {
                    "sent": "Features to use the maximum entropy model and this is a choice.",
                    "label": 0
                },
                {
                    "sent": "There are other options.",
                    "label": 0
                },
                {
                    "sent": "We believe the mental model is particularly suited for this case.",
                    "label": 0
                },
                {
                    "sent": "Rose has some very really nice properties.",
                    "label": 0
                },
                {
                    "sent": "It's full Santa Claus with exponential models, which makes for this case and we can compute it really, really easily.",
                    "label": 0
                },
                {
                    "sent": "And Secondly, the really nice thing about the maximum entropy model is that it has no bias.",
                    "label": 0
                },
                {
                    "sent": "You put something into the model conditioner model.",
                    "label": 0
                },
                {
                    "sent": "That's the only information you can get out.",
                    "label": 0
                },
                {
                    "sent": "All the rest we don't know anything about.",
                    "label": 0
                },
                {
                    "sent": "It won't say anything about it, so no bias, which is, we believe, good because we don't want to have bias when you're measuring stuff should not be that my result is automatically better than apples result, so let's see.",
                    "label": 0
                },
                {
                    "sent": "Inside this is the empty measurement.",
                    "label": 0
                },
                {
                    "sent": "Remodel portable, a matrix of bye bye bye and if it's empty for a binary database we know nothing.",
                    "label": 0
                },
                {
                    "sent": "So basically for every entry, the probability that we see a 0 / 1 just 5050.",
                    "label": 0
                },
                {
                    "sent": "So all these ones has over here.",
                    "label": 0
                },
                {
                    "sent": "I would say that we do know something.",
                    "label": 0
                },
                {
                    "sent": "So for instance, Jackal threshold specifies the top left corner.",
                    "label": 0
                },
                {
                    "sent": "This tile has a frequency of one only once and in the bottom right corner same thing.",
                    "label": 0
                },
                {
                    "sent": "However it is larger tile over here.",
                    "label": 0
                },
                {
                    "sent": "Well, I know there's ten months.",
                    "label": 0
                },
                {
                    "sent": "That's what I observed in the data, but I don't tell you where they are.",
                    "label": 0
                },
                {
                    "sent": "Then the maximum entropy distribution because we already have these ones are used in these six, so we already know where eight of the ones are, so there are still 2 ones to be accounted for.",
                    "label": 0
                },
                {
                    "sent": "And because there are 12 positions left, the probability within each of these cells were seeing one just one 60.",
                    "label": 0
                },
                {
                    "sent": "Same thing for the right hand side example, but that we are considering exact ONS exact tiles or just tell us which frequency zero or one.",
                    "label": 0
                },
                {
                    "sent": "Phil.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Boring.",
                    "label": 0
                },
                {
                    "sent": "OK, before we go to our measure and how we actually compare between results, let's consider background knowledge because if you already know something about the data and like said, I strongly believe that data mining initiative process you don't start completely naively.",
                    "label": 0
                },
                {
                    "sent": "Typically what you already know.",
                    "label": 1
                },
                {
                    "sent": "Other data determines what you find interesting, and it might actually be that Yahoo's result, if you take it just on face value, is much more detailed than mine, but it might actually be that some of those details or something we already know.",
                    "label": 0
                },
                {
                    "sent": "So then you want to measure like, OK, how much new information does.",
                    "label": 0
                },
                {
                    "sent": "Yahoo still bring to the table how much new information that might result into the table so.",
                    "label": 0
                },
                {
                    "sent": "This is something our methods measure really usually provides for basically, as long as you can translate your background knowledge into noisy tiles, we can build our mental model and there we go.",
                    "label": 0
                },
                {
                    "sent": "And like I said, on binary data, pretty much anything you know about the data can be translated into noise.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, finally our measure.",
                    "label": 0
                },
                {
                    "sent": "This is what it looks like, but the main thing we have one resultset, but I'll settle for sale Dallas result.",
                    "label": 0
                },
                {
                    "sent": "That's T1 and T2.",
                    "label": 0
                },
                {
                    "sent": "That onset of my result after translation.",
                    "label": 0
                },
                {
                    "sent": "Then we have some background knowledge.",
                    "label": 1
                },
                {
                    "sent": "Again, the tile set and if we drop them altogether, so whole tiles in just one big file.",
                    "label": 0
                },
                {
                    "sent": "We called N. So the mutual dowsett you could say.",
                    "label": 0
                },
                {
                    "sent": "Then normal pullback lighter measures the overlap between distributions, so.",
                    "label": 0
                },
                {
                    "sent": "It also nonsymmetric.",
                    "label": 0
                },
                {
                    "sent": "Which is something that typically, for a measure we don't really want, so we will measure like this this part over here basically says the pain was divergent between knowing everything and knowing not my result for Jack Russells in the background knowledge.",
                    "label": 0
                },
                {
                    "sent": "So basically would say, how much do you miss my result when you want to know the combination?",
                    "label": 0
                },
                {
                    "sent": "The right hand side on the bar does the opposite.",
                    "label": 0
                },
                {
                    "sent": "So how much do we miss ya cause result if it's not available?",
                    "label": 0
                },
                {
                    "sent": "And then we normalize by the whole bunch?",
                    "label": 0
                },
                {
                    "sent": "It is a measure and in the sense that it goes to 0 if distributions are like a very very large overlap.",
                    "label": 0
                },
                {
                    "sent": "Or complete overlap computer size and it goes to two.",
                    "label": 0
                },
                {
                    "sent": "If the piece of information are basic.",
                    "label": 0
                },
                {
                    "sent": "Basically conservation area.",
                    "label": 0
                },
                {
                    "sent": "And it goes to one if it's orthogonal or providing something slightly different than my quite differently, but the results do agree somewhat.",
                    "label": 0
                },
                {
                    "sent": "OK, one fun fact.",
                    "label": 0
                },
                {
                    "sent": "I would like to point out.",
                    "label": 0
                },
                {
                    "sent": "If you're just considering acceptance so simple case, so not like the frequencies were just specifying this part of the data only zeros here, only ones, that's it.",
                    "label": 1
                },
                {
                    "sent": "Actually this measure coincides with Jakarta similarity, which is a nice size resulted.",
                    "label": 0
                },
                {
                    "sent": "So give some intuition that we might be on.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "My truck here.",
                    "label": 0
                },
                {
                    "sent": "OK, good user measure for all sorts of cool things.",
                    "label": 0
                },
                {
                    "sent": "Obviously first of all, the main question we started off with our results.",
                    "label": 0
                },
                {
                    "sent": "Similar.",
                    "label": 0
                },
                {
                    "sent": "We do give a number for that, but that's basically OK, but that's what we're after, so of course we solve that.",
                    "label": 0
                },
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "Use it more for one of the cool things is we can visualize the big picture as we call it so we can run many algorithms, potentially on many datasets, and you can sort of see it like which methods in general provide similar information.",
                    "label": 1
                },
                {
                    "sent": "OK thanks, let's get into it.",
                    "label": 1
                },
                {
                    "sent": "Similarly for prescribing partial results and only thing I want to point out in this slide is this mining iteratively.",
                    "label": 0
                },
                {
                    "sent": "So basically, let's say that.",
                    "label": 0
                },
                {
                    "sent": "You all of you guys give me iteratively bunch of results and I can only analyze for one thing at a time or something, or just a moment is OK.",
                    "label": 0
                },
                {
                    "sent": "The expert is tired, but let's let's let's talk with it.",
                    "label": 0
                },
                {
                    "sent": "So basically, each time I want to find that result which will provide the most information.",
                    "label": 0
                },
                {
                    "sent": "But something that you can easily pick out.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this method.",
                    "label": 0
                },
                {
                    "sent": "OK, good 'cause we also experimented because up till now it was smaller theoretical and then it's very theoretical and the high level.",
                    "label": 0
                },
                {
                    "sent": "So we apply 10 different data mining algorithms for different datasets and be considered four different types of back online.",
                    "label": 0
                },
                {
                    "sent": "So there were six pattern mining button set mining algorithms which basically for those who are not aware of that and said mining and its intricacies basically comes down.",
                    "label": 0
                },
                {
                    "sent": "Find me a small group of patterns that together characterize the data easily.",
                    "label": 0
                },
                {
                    "sent": "So for instance you can think of a set cover kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Big chunks, every general explanation, and there's a whole range of different orders which specifies slightly differently and give you information.",
                    "label": 0
                },
                {
                    "sent": "For clustering, we consider gaming simple K means.",
                    "label": 0
                },
                {
                    "sent": "Consider trying to buy clustering or we apply K means of on the rows and columns which has been shown to give realize results.",
                    "label": 0
                },
                {
                    "sent": "Clustering paper which is clustered Rosen binary data and subspace clustering algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the big picture.",
                    "label": 0
                },
                {
                    "sent": "Also telling you about so this is averaged over 4 datasets that we considered.",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into each specific data set, so that's what efforts over here stands for, and basically what we did between for Rachel to datasets and all the results.",
                    "label": 0
                },
                {
                    "sent": "We measured the pairwise similarities before this whole matrix, and then we applied multidimensional scaling.",
                    "label": 0
                },
                {
                    "sent": "So basically here if stuff is close together typically have small the dissimilarity special.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if the background knowledge is just completely empty and you see that the clustering algorithms here in lower left column, they basically provide the same information.",
                    "label": 0
                },
                {
                    "sent": "I'll get back to that in a moment while we also see that the more I would mining or I can set bedroom set mining algorithms are also quite clumped together so they sort of give you the same information which makes sense, however.",
                    "label": 0
                },
                {
                    "sent": "This is with the account information.",
                    "label": 0
                },
                {
                    "sent": "Nothing so basically are.",
                    "label": 0
                },
                {
                    "sent": "We don't literally don't know about the data.",
                    "label": 0
                },
                {
                    "sent": "However, for most datasets pirate access there are sparse.",
                    "label": 0
                },
                {
                    "sent": "Sorry, that's and that's something that you can know pretty much off the bat.",
                    "label": 0
                },
                {
                    "sent": "So the moment we apply the density spectrum knowledge, which is basically one huge tile, spending the whole data set and just telling you how many ones do we observe in the whole data set and all of a sudden you see that the clustering algorithms they can spread out quite a bit.",
                    "label": 0
                },
                {
                    "sent": "And why is that?",
                    "label": 0
                },
                {
                    "sent": "Well, just by the nature of their method.",
                    "label": 0
                },
                {
                    "sent": "They pretty much spend the whole day to you.",
                    "label": 0
                },
                {
                    "sent": "Give your clusters covering the whole data well.",
                    "label": 0
                },
                {
                    "sent": "The item set mining things or they only cover parts of the data.",
                    "label": 0
                },
                {
                    "sent": "So the moment.",
                    "label": 0
                },
                {
                    "sent": "So in this case basically the clustering algorithms tell you like all the data is really sparse at the moment you already know the data is sparse.",
                    "label": 0
                },
                {
                    "sent": "Then you can actually see that they do provide extra information on top of that.",
                    "label": 0
                },
                {
                    "sent": "So one thing that you can do with this picture, like previews that let's just consider this picture, is the most easiest.",
                    "label": 0
                },
                {
                    "sent": "Currently.",
                    "label": 0
                },
                {
                    "sent": "Let's say our expert says, OK, well, I'm kind of tired, but one one hour after supper and I wouldn't mind analyzing 2 results.",
                    "label": 0
                },
                {
                    "sent": "That's OK with me and using this picture sort of specify OK, perhaps should pick one from these 'cause they're really similar to each other and just pick one of these.",
                    "label": 0
                },
                {
                    "sent": "And then you're basically spanning the information space if you wish quite well.",
                    "label": 0
                },
                {
                    "sent": "Good.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One other thing.",
                    "label": 0
                },
                {
                    "sent": "One application of our measure, we can redescribe partial results.",
                    "label": 0
                },
                {
                    "sent": "And basically this means that we can sort of explain, so you give me one cluster and I can see which parts of my own results a set of patterns provides the same information so I can start, uh, start to grab parts of my pattern set to describe one cluster, or vice versa.",
                    "label": 0
                },
                {
                    "sent": "Or I can describe one cluster using other clusters, or I can describe part of a decision tree using clusters.",
                    "label": 0
                },
                {
                    "sent": "So here we compare between 3 tile mining methods and on the intuitive data sets the data sets on abstracts from the ICM conferences.",
                    "label": 0
                },
                {
                    "sent": "Courtesy to tell the people I don't see someone over there and data is turned into another set database and.",
                    "label": 0
                },
                {
                    "sent": "Haha.",
                    "label": 0
                },
                {
                    "sent": "And basically what we can do, we can grab some of the patterns from print and we can see which patterns over here best approximate this information without giving extra information.",
                    "label": 0
                },
                {
                    "sent": "So this guy gets really specific stuff, but that provides more information than we have here.",
                    "label": 0
                },
                {
                    "sent": "So only give me the most general advice over here and this guy only gets really specific things.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Don't get so much so conclusions.",
                    "label": 0
                },
                {
                    "sent": "Comparing ourselves is really important and we haven't paid.",
                    "label": 0
                },
                {
                    "sent": "We've been being intending it to.",
                    "label": 0
                },
                {
                    "sent": "It's pretty much at all in data mining statistics.",
                    "label": 1
                },
                {
                    "sent": "We have data mining methods, so we really should do it.",
                    "label": 0
                },
                {
                    "sent": "Exploratory data mining.",
                    "label": 0
                },
                {
                    "sent": "We gave an example how to do it by measuring information content and we gave a specific example how to do it on binary data.",
                    "label": 1
                },
                {
                    "sent": "I've got lots.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Push to shave and stop waving frantically, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you, thank you.",
                    "label": 0
                },
                {
                    "sent": "Yes, we're running out of time, but we will have some questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you for this nice dog.",
                    "label": 0
                },
                {
                    "sent": "In your disparity measure, you use at the KL divergent OK, and my question is did you test other dimensions measures, and if so, did you did you?",
                    "label": 0
                },
                {
                    "sent": "Obtaining fact the same visual results.",
                    "label": 0
                },
                {
                    "sent": "Nope, sorry condolences also know.",
                    "label": 0
                },
                {
                    "sent": "And indeed the KL is a choice.",
                    "label": 0
                },
                {
                    "sent": "You can use any diversions message that you would like would deem appropriate for your distribution.",
                    "label": 0
                },
                {
                    "sent": "Similar with the Messenger solution, it's also a choice we feel that's mean from pretty much lot of evidence in information theory research to actually make a lot of sense.",
                    "label": 0
                },
                {
                    "sent": "Chose it because of computation.",
                    "label": 0
                },
                {
                    "sent": "So your message is capable of comparing results given the data set of different methods, but for some of the application that you sketched, it would be more desirable to generally run the similarity between methods on the space of all datasets available.",
                    "label": 1
                },
                {
                    "sent": "So is there any advance in this direction?",
                    "label": 0
                },
                {
                    "sent": "Thinking about it, that's the main thing I mean right now, the best we can do is just run it on different datasets and average results.",
                    "label": 0
                },
                {
                    "sent": "That's pretty much what I showed here, and generalizing even more on that.",
                    "label": 0
                },
                {
                    "sent": "It's quite easy model.",
                    "label": 0
                },
                {
                    "sent": "Basically the probabilistic model for date of specific dimensions.",
                    "label": 0
                },
                {
                    "sent": "As long as those are fixed, we can do quite a lot, but this is stable.",
                    "label": 0
                },
                {
                    "sent": "So what you showed about clustering, for instance, an pattern discovery.",
                    "label": 0
                },
                {
                    "sent": "So that's usually together in.",
                    "label": 0
                },
                {
                    "sent": "So I might be totally wrong, but isn't there some relation between this view that you present here and the geometric interpretation of what you do to your data?",
                    "label": 1
                },
                {
                    "sent": "So you have the data and then dimensional space, and then you know different data mining operators will cut it in different ways or group it or something like this.",
                    "label": 0
                },
                {
                    "sent": "And I think there might be some sort of similarity to that so that you would say that two operators to more or less the same thing.",
                    "label": 0
                },
                {
                    "sent": "If you have the same subspaces.",
                    "label": 0
                },
                {
                    "sent": "But then it begs the question that in fact there is more to it than that, because if you look at an Association rule, it will also tell you what actually will put things together and your clustering doesn't necessarily tell you that so.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure it's exactly the same information that you get.",
                    "label": 0
                },
                {
                    "sent": "You know when you say that they will know indeed is even right now.",
                    "label": 0
                },
                {
                    "sent": "Our translation ocean tiles is quite crude.",
                    "label": 1
                },
                {
                    "sent": "I mean, that's really quite some information that's actually future work.",
                    "label": 0
                },
                {
                    "sent": "I wasn't allowed to point out your representation.",
                    "label": 0
                },
                {
                    "sent": "Seriously, considering all richer data types of numeric data, for instance as well as Richard translations.",
                    "label": 0
                },
                {
                    "sent": "So within these talks within these sub matrices, identifying once the particular structure?",
                    "label": 0
                },
                {
                    "sent": "Or was that like an Association rule?",
                    "label": 0
                },
                {
                    "sent": "If you tell me this and that correlate such and so something that.",
                    "label": 0
                },
                {
                    "sent": "You should be able to quite easily incorporated.",
                    "label": 0
                },
                {
                    "sent": "Which barely between members.",
                    "label": 0
                },
                {
                    "sent": "Same thing for clustering for different similarity measures.",
                    "label": 0
                },
                {
                    "sent": "I mean we can only do so much.",
                    "label": 0
                },
                {
                    "sent": "OK, I have to ask you to take the rest of the discussion software and then we continue with the presentation.",
                    "label": 0
                },
                {
                    "sent": "Then let's type less once again.",
                    "label": 0
                }
            ]
        }
    }
}