{
    "id": "jxnngptn56maekdsdatrwhhnsks7a4z5",
    "title": "Neuroscience, cognitive science and machine learning",
    "info": {
        "author": [
            "Konrad K\u00f6rding, Northwestern University"
        ],
        "published": "June 15, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Medicine->Neuroscience",
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss2010_kording_ncsam/",
    "segmentation": [
        [
            "First, laser ponder springstone.",
            "The second laser ponders been lost, so I'll be without a pointer.",
            "It's good that it's the last day of the conference, I guess.",
            "So I will be talking a little bit about neuroscience today.",
            "I understand that that's the first talk about neuroscience, so it will be rather introductory."
        ],
        [
            "And I'll first talk about a couple of general things and then about 3 specific topics and I should also say that the slot then, which I'm talking about it is the slot that I took from Peter Diane who didn't make it here, and therefore he can't defend his onslaught and it got number of the slides are inspired or directly tailored.",
            "A few of the slides are directly taken from his talk, and of course I'm adding my own flavor to it.",
            "Because I can't, I can't channel a perfect Peter talk very fast.",
            "And yeah, exactly let me try to talk a little bit faster.",
            "So yeah, I'll be talking about Level 3 mile implementation.",
            "So what I want to say is, there's certainly something very interesting about the third level of math, and while a lot of the talks here focused on the 1st and the second level, which is what's the objective and what's the best solutions to it?",
            "Suddenly the nervous system uses a specific implementation which happened to be in terms of neurons and the interactions that they have.",
            "Between one another and there may be a number of aspects of cognition that we can only understand once we actually start asking ourselves how it's actually implemented in this certain certain algorithms that will be much more likely given the knowledge that we have about implementation.",
            "So each of the three llama levels of course strongly informs the neighboring mall levels, so if we understand more about what neurons do, we might understand more about about the kinds of algorithms that brightness implementing.",
            "I should also say if we microscopically look at the nervous system, it's neither really suggestive.",
            "Both generative, not discriminative algorithms of learning.",
            "But we rather have these nuns that interact with one another in there, and we characterize how cynapsus changes function of input and output.",
            "But how that Maps on bigger problems?",
            "It's one of the big problems in your sights, and I understand that some of the other speakers today might be talking about that."
        ],
        [
            "So neurons generate spikes and you can say that.",
            "In most cases we don't actually care about the generative model that we do.",
            "There we choose for machine learning problem.",
            "We actually care about the predictions we can get out of it.",
            "So the generative model usually is just a tool that allows us to ask interesting different questions.",
            "But if we want to understand the brain, we can say this is actually one of the cases where we care about the generative model.",
            "If you give me some data for the nervous system and I want to understand another system, it means that I'll be able to understand the generative model that gives rise.",
            "To the data that I'm recording.",
            "So actually in this case I care which probabilistic processes making the data, and this is the primary interest in your science.",
            "What is the process that makes the data that you're measuring your experiments?",
            "And this means that you'd like to have a model of the spikes that you're getting, and ultimately you want to understand this structure and the function of the objectives of the spikes that you find in the nervous system.",
            "No.",
            "Let us first ask ourselves a little bit if this is if this is even more realistic."
        ],
        [
            "And it might.",
            "It might not.",
            "So here we have the brain.",
            "If I had a laser pointer could show it to you, but it's on the right hand side of the slide.",
            "Now investors, this slight issue that there's 10 to the 11 neurons switches in each of these nouns is potentially rather complicated, and we have something of the order of 10 to the 14 synopsis, so it's a big system, and at any point of time we will only be recording from a tiny percentage of these neurons.",
            "Who knows what's the hey, great?",
            "Thanks a lot.",
            "Who knows what's the maximum number of neurons that people usually record from it?",
            "The same time today?",
            "Thousand Yeah 1000 is with with today's optical methods you can get close to 1000.",
            "Well, when it's it's a couple 100 simultaneously recorded neurons with electrodes.",
            "It's about 200 if you only consider the actually published papers so far.",
            "So 200 is the number that we were caught from 10:50, so we have here, and the question is, what can we even say about the nervous system if we have such a small?",
            "If we have?",
            "If we only record from such a small number of neurons, and so we are trying to understand how a system with 10 to the 11 nuance walks.",
            "Based on most experiments only we cut from a single now, so we try to understand this huge system with all these different aspects based on recordings of single neurons usually and in the maximal case from a few 100.",
            "So the question is why should that be possible to work?",
            "Imagine I give you a pen, some processor and your recording from a transistor.",
            "It would be rather difficult to infer the function of it.",
            "But it wouldn't be so hopeless because because if we're in this case, it's been designed by humans, and it does a certain favors, for example, that say the transistors within large areas of it.",
            "I just periodic.",
            "You have served the same elements that are used over and over, so there's different assumptions that you then can make an under those assumptions.",
            "No sense again gets to be possible, and I want to go through these assumptions first, because because they're there, serve the necessary criteria for neuroscience as a field to understand.",
            "Human behavior fight to be possible."
        ],
        [
            "Yes, the first help imagine the brain is a little bit like a city.",
            "It consists of of different brain areas and in each of these brain areas essentially all neurons are identical.",
            "So say if you if we talk about primary visual cortex, the way many people in your sense think about it is these neurons are tuned to Gabor wavelets.",
            "We can describe them as linear filters with Gabor wavelets type kernels and.",
            "A and an apartment and onions identical.",
            "They all have gathered type receptive fields apart from a very small number of largely of parameters switches.",
            "Each neuron has a position and it has his preferred spatial frequency and a preferred orientation and all that.",
            "So so in that sense we can say it's quite analogous to, say, the way we'd writing and your network where we can say, well known, say exactly identical.",
            "Apart from they have the same learning, all same properties, and so forth.",
            "They they just copy and paste it, and if this is the case then your science actually is supremely possible, because all we need to do is we need to find out all the areas, and that's something that say after my research very strongly focuses on and then we need to recover from these neurons, find out what they're tuning properties are, and then what are the axis along which they are different from one another.",
            "And then we just copy and paste.",
            "The only understand how the brain works.",
            "So this is one up and it's a hope that is very compatible with my cutting from single nuts, because if this is how the brain works, recording from single neurons will solve the neuroscience part because all we need to do is we need to record from each from each area one or like a small number of neurons each characterize what that shooting properties are and then we understand how it works.",
            "So here's another."
        ],
        [
            "Here's another way.",
            "So this is 1 assumption under which in our science will work very well.",
            "Here's another possibility.",
            "Imagine that the brain consists of groups of neurons that are essentially doing the same thing, where all neurons in the same group are doing the same thing.",
            "But these groups might.",
            "There might be significantly more of these groups.",
            "Then we have brain areas.",
            "In this case, if if all neurons within each groups occur by esentially identical, we would only need a small number of electrons at the same time.",
            "Even if these groups interact in some interesting way.",
            "As long as we hit each of the groups, we can characterize how they interact with one another and the relationship of the neurons in this for this view might be complicated.",
            "Their interactions might be complicated.",
            "They each group might be very different from the others, and but in this case recording from one neuron in each of these relevant groups would be enough.",
            "In this case, we would still need to record from a large number of neurons to understand how it works, but we would need to record from much less than the 10 to the 11 yards, maybe with a couple thousand would be there."
        ],
        [
            "And then there could be a thought.",
            "Hope that would make no sign swap, which is it could be that all neurons are really fundamentally different from one another, but it could be that the learning rules that give rise to the neurons identical or very similar to one another, and in this case, if we have a brain area and we know the statistics of its input, we can predict all the properties of thin answer there in this.",
            "In this case, if we understand these learning rules that give rise to the properties of the neurons.",
            "We can potentially understand a very complicated nervous system based in very simple ideas, and here I want to show you just some data.",
            "This is the results from a study by Bruno Olshausen.",
            "What he did is took a lot of photos of natural scenes and he said, let's assume that the learning rule that gives rise to the properties of neurons in the primary visual cortex is that the outputs in response to an extra scene size fast as possible, and what you found is that there's lots of different that there's a population of very.",
            "Testing neurons that optimizes this criterion, and of course it needs very few neurons to describe the property.",
            "A very few parameters to describe these properties.",
            "Just assumption of a learning rule effectively, and yet it can produce a wide range of different neuronal properties.",
            "So this does not help."
        ],
        [
            "Kiss another hope, which is which is the technology optimists.",
            "Which is you can say at the moment we only record from a couple 100 yards thousand as you said, and but near technology is advancing rapidly.",
            "And as these technologies advance, we may be able to just scale up the number of neurons from which we we caught an ultimately it might not actually be so difficult to.",
            "I mean, we might actually get close to 10:50 North and a reasonably.",
            "A reasonable period of time and this is just some, some calcium calcium imaging data that you have here is one of the top techniques at the moment.",
            "You can record from a good number of units at the same time.",
            "Now let's talk about something completely different."
        ],
        [
            "Probably most people have seen this graph.",
            "This is Moore's law for computers on this axis of the year of the introduction of microprocessors, and on this ecstasy of the number of transistors there that were on that device.",
            "And you can see that it's been growing exponentially beautifully for long period of time.",
            "The effect of that is, of course that my my phone cheap and simple as it is, would have been an amazing computer a couple decades ago.",
            "And of course, this had a lot of impact."
        ],
        [
            "Patience, I'm computer science.",
            "For example, you don't usually think so much about the actual speed of a of an algorithm, but you focus on how it scales with the number with the number with the size of the data set that you have and you were using the big O notation and and of course.",
            "Who in this room doesn't know the big O notation?",
            "OK, that's so so it's just you ask her and algorithm scare so big O of N squared would be if you have twice as much data you takes for taxes law.",
            "But now it turns out that something like most laws are placed in your science, and that's something we just recently found."
        ],
        [
            "So we went to Google Scholar.",
            "We searched for paper, we searched for the Tom and simultaneously recorded neurons an we only.",
            "We only allowed the first couple of papers that reached us that were above a certain level.",
            "So.",
            "But we have on this axis is the year of the publication of earlier science paper.",
            "On this axis you have the number of simultaneously recorded neurons.",
            "So the lock of that here and you see it grows nicely exponentially of about five decades, is much slower than the than the rate with which things increased in computer science, it doubles every seven years, but there's this nice thing about exponential functions that they actually rise that they actually get pretty far.",
            "If you just wait a little so in the year 2200 if you extra late, this here will be recovering from all the neurons of the brain at the same time.",
            "How far we can extrapolate these things is very unclear.",
            "If you ask newer scientists, how long will this happen?",
            "Continue happening?",
            "This increase, they say about one decade.",
            "It turns out that if you if you look at people write about mostly in computer science, it's the universal invariant that people say.",
            "Most law is over in 10 years time.",
            "It seems to be true.",
            "This law seems to be true for neuroscience as well, that people feel like we're really hitting hard boundaries in about a decade.",
            "But then I spoke with some people who develop action.",
            "You're recording techniques, ask them if they could scale it up by effect of 1000.",
            "And they say if you give me a lot of money, we could suddenly scale it up by a factor.",
            "So now, because this is this."
        ],
        [
            "Some implications when you can say well if news if computer Sciences scaling like that and the effect of that that was that we focus on scaling loss.",
            "We want algorithms that scale well with the amount of data that we have.",
            "We can say the same thing about neuroscience, which is we want data analysis methods that scale well with a number of simultaneously recorded neurons.",
            "We want techniques and can take advantage out of the fact that we were cut from on monuments at the same time and.",
            "First, one time time you might say, well, if we were cut from on monuments won't we run into problems that our computers are too slow for the analysis?",
            "And actually there's some good news about that because at least at the moment computers get twice as fast in two years the number of neurons we cut from gets twice as fast in seven years, so we can use algorithms if it continues like that, we can use algorithms that scale exponentially with the number of neurons.",
            "OK, so great we can do it.",
            "But the thing that we might be interested in is how much information we learn panion.",
            "So how much does the information we get about the nervous system scale as we change the number of neurons simultaneously recorded for, and I'll get to this point towards the end of my talk today.",
            "Oh, and I should say just like yesterday, please interrupt me if anything is unclear.",
            "If you disagree with me."
        ],
        [
            "So today's talk has three like.",
            "I'll talk about three issues.",
            "The first thing is about understanding how onions relate to the outside world.",
            "The second one is I'll briefly mention her neons micro present uncertainty, which is an intense topic of research in computational sense at the moment.",
            "And Lastly, I will talk on about how nuanced relate to one another.",
            "Anything that's very interesting machine is going to be very interesting.",
            "Machine learning applications in this stuff part."
        ],
        [
            "So let's first talk about how Neon's relates to the outside world."
        ],
        [
            "The typical way experiments have been have been done.",
            "I like that you.",
            "Yeah, you take an animal and your record from the from the animal's brain has just a depiction of that.",
            "The animals involved in some ties, either anaesthetize if you just want to know what the properties of of perceptual of the perceptual system is, other animals actually involved in some task, say whenever it sees the certain kind of stimulus it needs to push their hand to the left or to the right.",
            "You very this stimulus you are very what you showed to the animal and you vary the behavioral demand.",
            "You change the task.",
            "Are you required the animal to move into different directions and you measure how they behave and you measure the neural signals that you're getting out and then you try and relate the neural signals.",
            "You have two properties of the stimulus, an properties of the task.",
            "And this is this has been an incredibly useful approach in your science, and we know that for many brain areas, we know the tuning curves of the tuning properties of neurons with with with with respect to movement related or with respect to stimulus related properties."
        ],
        [
            "Example, here's some data.",
            "Here we have a monkey.",
            "The monkey always starts in the middle of its workspace, and the monkeys moving forward, right down left diagonal all directions.",
            "Many repetitions of the same, same thing.",
            "This is what you see.",
            "Hear each of these lines here.",
            "They're called raster plots.",
            "They they they depict at which point of time neurons spiked.",
            "This line.",
            "Here is the time where the monkey actually moved and you can see that for the movements where the monkey moved to the left, you get more spikes him off the.",
            "The vertical bars here and if it moved to the right, you get few of them and then you can plot the numbers of spikes as a function of the movement direction of the monkeys are.",
            "You can plot the firing rate of the new on the average family, then total number of spikes in some interval and it was found that for the movement system there's a very nice cosine tuning between the between the spikes and the direction of movement.",
            "So people people were happy they said OK, great, we understand what's the.",
            "How how are the motor system?",
            "How the primary motor cortex encodes movements and then similar?"
        ],
        [
            "Experiments have been done for the primary visual cortex.",
            "He have data from UBL Inviso, you recut from Mignon in the primary visual cortex.",
            "You show it boss or of different light bars of different direction and you move it over the receptive field of the neuron.",
            "So the the way people think about neurons in the primary visual cortex is that they essentially see a small part of the visual world.",
            "All the rest they don't care bout.",
            "And when if you then show a bar in that in the receptive field of the neuron, it gets to be very active.",
            "So so if you show up but like destiny and doesn't spike it all, if you show it slightly more in this orientation, a few spikes here, lots of them again, few of them and no more at all.",
            "And you can do the same thing.",
            "You can plug the tuning curve where on this axis of the orientation angle of the stimulus and on this axis you have the phone right of the new.",
            "You see two things here.",
            "It it looks like it's in good approximation orgas, and it's caution in the in the orientation of the stimulus.",
            "You in fact also see another thing which is which is the new one appears to be firing Leica.",
            "Leica appears to be passed off firing.",
            "You see that the variance that you have here is larger than the variance that you have here, and there's there's.",
            "There's a very regular relationship between those two."
        ],
        [
            "Here's some more experiments that was done.",
            "This is this stuff by Pojan Talbots.",
            "You look at stimuli that very in depth, so they vary.",
            "In disparity disparity means the there's a difference between for the.",
            "So if a stimulus is closer or further away, it appears at different angles for the two eyes.",
            "So the difference in angles is different.",
            "That's what's called disparity.",
            "If you vary the disparity there 7 yards that have low firing rate, if it's a negative disparity.",
            "So this means if it's closer to your fixation, an high firing rate if it's further away from fixation."
        ],
        [
            "Here's here's another characterization you taker at.",
            "You have the right run around.",
            "You record from cells in the in the rat while it's running around, and you plot the firing rate of the of the of those cells as a function of whether it is so.",
            "You just have this this lady on the rat that measures how it's moving about and you just get the firing rate as a function of the position.",
            "And people have found that their so called great cells, these cells that are active at certain places in space.",
            "So not just one but their cell, but equally fired the readers here.",
            "So this is just special.",
            "This is just space.",
            "This is the rat is moving in this little square box on this axis.",
            "That's just the X axis, the Y axis.",
            "So this is really just the spikes is a function of the firing rate as a function of where the red is, and you find this regular.",
            "Hexagonal great, it's called it's called red cells and what is for?",
            "It's not quite clear, but there's a brain area where lots of neurons have this property.",
            "And then there's another out of right now.",
            "Yeah, the hippocampus where they found that there's some areas in space where the neurons are very strongly active and it's not active in the rest.",
            "And you can say this is a very useful representation because it tells me that I'm at a different place given position in space.",
            "And if I have that information I can.",
            "I can say remember where I get food because they could associate it with activity of these nuts.",
            "But you can see all these different cases.",
            "It's it's.",
            "It's computationally the same thing.",
            "There's something in the outside world and the firing rate relates in a systematic way to the properties in the outside world and properties in the outside world could be my own movement, or could be where I'm in space, or what I'm seeing.",
            "What I feel, anything yes.",
            "I was wondering if this is XY location as opposed to perceptual perceptions, physical location?",
            "Yeah, this is.",
            "This is exactly XY location, so so you literally put the lady onto the onto the rat, measure its XY position.",
            "You ignore anything else, ignore which directions it's heading you ignore all the other aspects, but of course the exploit location is correlated with perception.",
            "Again experiment where they were taken.",
            "Where?",
            "The damn cricket by producing the same perception from the different XY locations.",
            "I mean is there.",
            "They have they have done these things to you.",
            "Make it you can make it so that you can rotate the box.",
            "You leave the rest of the room the same.",
            "You rotate the box.",
            "European people have changed the form of the box and then said OK in some of these cells appear to be fixed to the corner so they they they only only active in the sudden con of the box.",
            "So I mean there's this complicated effects.",
            "Perception it is neither XY location, not perception if you.",
            "Reception over alright?",
            "Yeah, because it is driven by perception.",
            "Maybe you can turn off the light and it still it will.",
            "Still you put the rexes someplace you turn off the light install.",
            "It's still there so.",
            "So all I want to say is is is there something complicated about it and that's that's unfortunately a little bit the option of that if you if you now take keep everything the same in one of these experiments and you change something else, say you keep the position of the same and you change the form of the box or something, you will often find that that also changes the activities.",
            "So in many ways it looks like neurons are more complicated than suggested just by that.",
            "And you can say in German place cells in the mist.",
            "Makes this you get the feeling that it's my location.",
            "Yeah, but the name of any cell is.",
            "If you call motor cortex cells.",
            "If you call them movement cells.",
            "It's also missing Homer because you can change the stem.",
            "You can keep the movement the same you change, you change other aspects of the tasks that you change the poster of the hand or something and you still get in again.",
            "You get different activities and it's a huge debate.",
            "Then what's the coordinate system?",
            "Say it did.",
            "Neurons in motor cortex care about?",
            "Positions, velocities, acceleration, forces muscles many different properties."
        ],
        [
            "His a little more here.",
            "These are recordings from humans.",
            "Actually we don't quite remember the brain area, So what they did is there we caught it from.",
            "From Yonce, while they showed lots of different pictures too.",
            "To the subject participating there an IT it and so I think they used of the several 100 pictures there and they just measured how many spikes they would get out of this up and you can see here these are these are the images for which the neon was most active.",
            "These are the images for which the neon was much less active.",
            "It might be hard to see but this is.",
            "I think this is John McCain.",
            "Not many spikes.",
            "He's getting all these stomach to be pictures of Holly Berberi an.",
            "In fact, here's her name.",
            "So.",
            "So if you show just the word print, it's the sellers very active and if you show her face it's very active.",
            "If you show a drawing of hurts, very active and so So what that shows is that this new one seems to be related to that high level concept.",
            "That person, regardless of the specific modality that is presented at.",
            "This is this is human data actually, but it turns out that they've done similar things with monkeys, and if you have monkeys and they showed it and people people have monkeys watch TV often because monkeys just like a skateboard overtime and it turns out that for these monkeys to then also find related cells to the kinds of stimulated the monkeys are frequently exposed to.",
            "So what's interesting of course about these neurons is that their invariant in an interesting way.",
            "It's not.",
            "They don't have simple properties in terms of brightness or in terms of, so it's hard to to describe this these cells.",
            "They have really interesting properties and.",
            "Yet it still following the same paradigm we we give a set of stimuli and we try to understand for which stimuli we get high activities infer which ones we get low activities.",
            "Now I briefly want to mention the possibility of using Markov chain Monte Carlo for doing that kind of analysis, so, so here's the computational problem where we caught from Mignon.",
            "We get the spikes out, but we always have in relatively small number of spikes, so at best will get a couple of 1000 of them and we might be interested in in tuning properties that have several dimensions.",
            "Say if we talk about the preference of neurons to two bars, we can say well, once the.",
            "One important aspect is the direction of it.",
            "The other one is what's the position where they sell likes the stimulus to be the next one is what's the maximal firing rate you get out of it.",
            "The next one is what's the minimal firing, right?",
            "So these tuning curves and can unfold in at least medium size spaces, say dimension 456.",
            "And given that you only have a certain number of spikes, this is actually a problem with significant uncertainty, so you can be sure what the properties of these cells are, and in fact in many in your science experiments, what do you want to know is here, I do.",
            "I measure the tuning properties of herself, then I do some say I train my monkey and then I want to know have the properties of the neurons changed, and for that I need to get reasonable reasonable understanding of given the data that I have, how certain I can be about the properties of the tuning curves.",
            "And this is where we can stay."
        ],
        [
            "Using Markov chain Monte Color, the technique so it's exactly the same thing that Tom was talking about in his in his tablets.",
            "So imagine we we, we simplify matters, we just say we have the tuning width of a vision Jan, which is how precisely it's tuned to two stimuli, and on this axis we have the preferred orientation of the notes.",
            "And if we do Markov chain Monte Carlo, what we do is we start at some place we initialize, then we have this bun in face where the Markov chain converges to the.",
            "We're probably to distribution and then the system is exploring the space so so we start out here.",
            "Then we proposed this and we accept it because it's close and overtime we get in here.",
            "So so here here what you see as these lines, here are the ice of probability lights which we couldn't include.",
            "Image this, we could actually captured them, and at any point of time the Markov chain will be at one place.",
            "Here we simply use Gossen proposals here.",
            "So we were moving to this space in rank.",
            "You see the ones that were rejected in blue.",
            "You see the ones that were accepted and you can say that that if the proposal goes outside of this range.",
            "It tends to like it's much more likely that it's going to be rejected, but overtime as you keep sampling the dot or the distribution of samples you get in this space approximates the real probability distribution.",
            "Yes, so so something that's always puzzled me is that if you have a highly specific neuron, like Halle Berry in Europe, how on Earth did we ever found it?",
            "And given that we have sometimes found neurons receive that specific, so that makes you suspect that.",
            "They must be well, either there are lots of Halle Berry neurons in ones head because otherwise how come you flipped it fluently?",
            "Found well, but more likely there an awful lot of neurons which respond to Halle Berry and a lot of other things.",
            "And it's just that one didn't try any other didn't drop.",
            "My can't explore the whole space, so I suppose I'm wondering what extent.",
            "What was finding his sort of local minimum, but in fact the same neuron will will be responding to all kind again.",
            "Yes, Sir, so this is a new one.",
            "In the primary visual cortex, and it turns out that you can.",
            "You can actually drive these now and say bye expectation of something which is certainly not in visual task.",
            "Essentially Tele monkey.",
            "Hey, that's gonna somethings gonna appear in your receptive field and then you run changes its properties.",
            "There was, there's a nice paper by many gankers so about that and you can say primary visual cortex is the case where stuff is still most orderly because you have the wheel Walmart less feeding into it, and yet you still have.",
            "Star projections from higher areas, but when we come to these areas where Holly Berry cells are being found, yeah, they probably wouldn't know they might.",
            "It might actually be a bad actor cell or something.",
            "It might be.",
            "Yes.",
            "Sunsets just any regular.",
            "Well, it turns out that in this case you can still show 1000 pictures, and among those thousand pictures, those with Halle Berry on it had by far the most activity.",
            "So people were effectively looking for a large number of different features that could be represented there.",
            "But yeah, it's it's.",
            "It's ultimately a big problem, because because fundamentally, in that you usually get about an hour's worth of data from from those electrophysiological experiments now.",
            "In that time you can't do it.",
            "You can't try nearly the breath of kind of the stimuli that are relevant in the world.",
            "So in all likelihood many of these experiments are missing important features.",
            "An in fact there is, at least when it comes to highly trained monkeys.",
            "There's this general observation that in most areas, if you just look hard enough, and if you overtrain the monkeys to the monkey really does this task frequently.",
            "You tend to find cells in many areas to tend to find cells that are related to the task that you're dealing with.",
            "And I hope I'm doing justice to the part of neuroscience, but it's definitely a problem that unless you already know what the kind of what the right dimensions are for a brain area, you aren't going to find it and you might be finding other things that are just correlated with the things that you care about, and you'd never know.",
            "But in any case, So what do you get with Markov chain Monte Carlo here is you get a distribution or you get a set of samples that are all drawn from the posterior probability of the tuning curve.",
            "Properties of this cells.",
            "Given the spikes that you have.",
            "With this you can then, in a very constrained way, ask the question.",
            "Say, does prefer tuning change between this experiment in that experiment?",
            "And you can.",
            "You can get our balance where you can then say so.",
            "This was a simulated case in black.",
            "You saw the true tuning curve of the cell in Gray.",
            "It's very similar.",
            "You take, you see the median of the of the samples.",
            "So that's the that's the best estimate if you want of the tuning curve properties and then in red you see individual samples.",
            "And of course there's a broad distribution."
        ],
        [
            "Now to the second part of the talk, which is going to be relatively short, which is about how neurons may represent uncertainty, and just as we've been talking a lot about uncertainty and Bayesian algorithms and so forth, the question is what do we know about how the nervous system represents uncertainty?",
            "Ends we have a lot of theories of how the nervous system may represent uncertainty."
        ],
        [
            "And let me talk about a few of them.",
            "So.",
            "So imagine we have a tuning curve on this axis.",
            "We say have the direction of a stimulus and on this axis we have defined weight of the neuron.",
            "Instead we have two different conditions.",
            "We have one case where we have low uncertainty.",
            "You could say this is a high contrast stimulus, something where can be pretty certain that.",
            "Where can be pretty certain that the bar has a sudden orientation, because just phone worser very high.",
            "And then others, or like because it's very bright and it can perfectly see that another slow contrast.",
            "We will have more certainty and the idea of that theory is that you will have more firing rate if your master and it turns out that if we assume that neurons have passed on firing, firing rates, rates, and we think we do optimal decoding of the neural activities, then in this case the.",
            "We have higher firing rates and higher firing rates translates official information through lesson certainty about the properties of the stimulus.",
            "That's up there, so this is 1 theory that people have proposed.",
            "Wajima Alex Pushy have been working on that.",
            "Then we could have the possibility that their separate populations, so we might have a population that encodes properties of stimuli and we might have a different set of neurons that encode the uncertainty that we have about those stimuli.",
            "In this case, these neurons wouldn't care about the tuning curve, so it wouldn't have read tuning curves.",
            "There would only fire, but uncertainty, solo uncertainty, low firing rate, high uncertainty, iPhone, right?",
            "That's one possibility.",
            "Alternatively, it could be that the tuning the tuning curve changes and then will head which Samuel had proposed something along those lines where you can say if we have more uncertain than yours, then we find that neurons have broader tuning curves.",
            "What that would mean for the population is that for a given stimulus.",
            "There would be a broader set of neurons that are active.",
            "All of them would be maybe less active, but you would have generally have monuments that are active in, so this distribution, the fact that so many neurons are involved with signal that we have higher in certainty.",
            "So feed and have made a different proposal where she said, well, it could be that if we're more certain about something, the neurons might just tell us how much we should update the beliefs that we have there for the neurons is therefore, if we're in low uncertainty situation, then understood when we put on the stimulus force, be very active and then stop being active.",
            "Whereas if we're man suddenly on should start being active and keep being active for longer period of time.",
            "So you see this, there's no shortage of theories of how the nervous system could.",
            "Implement and certainty.",
            "Each of these has some level of support.",
            "If you're or, here's another one which is.",
            "Which which is it could effectively be the distribution of firing rate overtime that the signaling uncertainty.",
            "This is this is a sampling idea where you could say imagine we have a low low low uncertainty situation and we have a new one, let's say encodes by its firing.",
            "Wait where long or 1 dimensional axis something is.",
            "If we're if we have low uncertainty than uncut fire very regularly and the firing rate, the instantaneous firing rate would tell me.",
            "Each of each instantaneous family would be a sample from the distribution.",
            "So if we are very certain that none would fire very regularly, and if we are very uncertain, sometimes don't fire very fast and then again, very slowly, and so on and so forth, so.",
            "Should we have sampling so this is a very popular theory in your sense.",
            "At the moment they had a big workshop on that at cosign, with some terms with people going there this is a very popular theory that Alex Posey had many very visible publications on it when it comes to data that we have about it.",
            "It's not nearly that clear, and I should've cause.",
            "Add one more thing, which is that there's Pretty Little reason why the brain should use a code that Conrad can understand how to go well, or that we could understand very well in general.",
            "It could be that you could reach the same performance with codes that we can understand well, but there are nervous system has absolutely no evolutionary pressure to do us the favor to use an algorithm that we can easily read out.",
            "So if you ask me, the probability that it uses in a pure form, any of these is.",
            "Rather unlikely, unless unless there's a very simple, very powerful algorithm that is much more powerful than all the others."
        ],
        [
            "So just just two of these theories, I want to to talk a little bit more about it.",
            "There's there's more of them.",
            "I can't.",
            "I can't focus on all of them, I just want to give you the gist of them.",
            "So the first one is the idea of a distributed representation.",
            "Imagine that we have different neurons here, color coded.",
            "Each of them has a different preferred direction or different preferred properties, and we have then a distribution of of a space of the man that gives us along 1 axis of probability distribution or might have a different access whether Nuance covers a probability distribution like that if we combine them will get a distribution like that.",
            "So what we need here is we need lots of neurons on this access.",
            "We need lots of neurons of that access, so it requires many Indians.",
            "And if we have a number of features at the same time, it might require something like exponential.",
            "Numbers of neurons to represent things to represent multi dimensional probability distributions.",
            "People argue that there may be tricks to make it more efficient.",
            "I don't know."
        ],
        [
            "Another possibility would be by sampling, so here we have overtime.",
            "The instantaneous firing rate of the neuron, sometimes high and low like this, and here instantaneous phone rate of the other neuron.",
            "What is what is nice here is we need very few neurons to see here.",
            "You just need to know answers before you needed this whole distribution along every axis.",
            "But of course here if you want to know anything about the probability distribution, you need to wait until you've gotten enough samples.",
            "So therefore it might be a very slow scheme.",
            "So I want to stop talking about the representation of uncertainty here.",
            "It's it's one of the most exciting topics in neuroscience at the moment, but the data that we have about it isn't particularly strong yet, and therefore I don't feel comfortable putting my head firmly into one of these into associate my or like strongly advance any of these five or six general schemes that we could have about it.",
            "And there's probably different schemes that we could have that we didn't even think about.",
            "So this spring."
        ],
        [
            "Me to the third part, which I feel more comfortable about.",
            "Which is the reverse engineering the way neurons intact the way we can think about a one way of conceptualizing the nervous systems that we can say well there's some new ones that we we caught from these nuns will interact with one another.",
            "Of course there's lots and lots of other neurons that we don't.",
            "We caught from that.",
            "Interact with onions that we do.",
            "We come from.",
            "And of course these nuns can can give us trouble because say if I want to know if X interacts with if X interacts with twice.",
            "If there's a causal link.",
            "Tween X&Y, well, it's hard to know that because all these other neurons excite, both of them are affect both of them, and therefore it could be that, say this neuron at small latency excites this new on an at large latency excites this year.",
            "It would look as if there's an actual causal relationship between them.",
            "And yet, if you want, this is one of the most important questions in your side switches, how do neurons interact with one another?",
            "There's something that we'd really like to know.",
            "But we know that statistic is a little bit problematic.",
            "So what we will do is we will largely ignore this problem, that this the other neurons out there get results and hope that the results that we get are still relevant.",
            "And of course we can hope that overtime our algorithms will get better."
        ],
        [
            "And the reason why it's going to get better is if this continues growing very rapidly.",
            "We will at least record from a higher and higher proportion of the neurons that ND serious.",
            "We can only hope that that for some reason we can do reasonably well with a small number of neurons, But it turns out that we can actually quantify that.",
            "We can say, well, how many neurons do we need to get a certain quality of understanding of what the neurons are doing.",
            "So, so this thing means overtime will be getting will be getting better.",
            "But the question is how good we can do at the moment and I'll first want to introduce a generative model for spikes.",
            "I'll briefly talk about how to do inference on that.",
            "Well then see how good it works in practice and we can then see if it already gives us good enough results that it's it was continuing along these lines."
        ],
        [
            "So here's the generative model of spikes.",
            "Imagine each non I has associated with it and an underlying unobserved firing rate is called a conditional intensity function.",
            "And let's say that this thing is that each of the neurons is affected by all of the other neurons and it's so this is this fast stuff from from one to N over all the neurons and there's an every neuron depends on the past.",
            "So the phone weight of 1 neuron at one point of time depends on the spikes that it.",
            "Please see in the past from all the other neurons an it depends.",
            "So over temporal filter WI Delta T and it depends on the spikes that happened at T minus Delta tears that afternoon.",
            "So this thing is linear here and we take the exponential function of that.",
            "So this is now a nonlinear function and then we assume that the neurons firing is Apostle firing is Opossum process with this intensity function as is right?",
            "You can think about it in different ways.",
            "You can either think about it in terms of biology, where you can say, well, this is a little bit like the input current that you could be getting to a cell, where each of the other cells is producing potentials that change the membrane potential of this cell, and therefore this drives this drives firing.",
            "Alternatively, and in fact this this kind of a model has has the expressive power to deal with with many situations that we know from your sense of kind.",
            "Regarding the index page, because in the left hand side of the problem you have my direct right hand side I used.",
            "I just got a just a little late day.",
            "This should have been a J here and this should have been a J here so J there as well.",
            "Yes yeah babe do best timing.",
            "I did that last night.",
            "Yeah, it's it's the influence of death.",
            "Neon is from all the other neurons, so that index here goes over all the other Neons West.",
            "This is the neuron itself and this one depends on that neuron and all the other neurons.",
            "So this one should have been IJ and this should have been J and this BSJ you have some do it thanks.",
            "So, so this kind of a model has a lot of a lot of expressive power.",
            "For example, it's known that neurons have refractory periods, which means that if a non fires right now there's a duration during which beyond just can't physically fire because it needs to recharge all the all the iron concentrations that it needs to fire again.",
            "Now this this model can can immediately in very easily take care of that by simply making it so that the filter of the neuron onto itself.",
            "At very shortly later is very negative.",
            "It will just make it make this to clamp effectively, this time to be 0, and this is here.",
            "You see data from a simulation there.",
            "This is how it might look like if the neuron has fired.",
            "There's a time during work.",
            "At fastest.",
            "It's very, very unlikely that it would fire, and overtime it recovers to some normal value.",
            "And then there's of course Crosstown.",
            "Say if one neuron fires, it might make the other neuron fire or tend to make the other non fire at some deley.",
            "You can also do.",
            "This model also has the expressive power to allow for Bostik, so it's known that there's many cells in the in the brain that have periods where the neuron fires a lot, and then parents with an honest silence.",
            "So the new one will for a long time it won't fire at all, then it will go tick, tick, tick, tick, and then nothing again, and it will repeat that well.",
            "In this case, if you have a filter that is fast negative for the refractory.",
            "Then goes positive for while then goes back to 0, this naturally.",
            "Can model the idea that neurons bust?",
            "Because because if you sample them from such a generative model, the neon stuff makes itself fire after deley, and that produces bursting in.",
            "If you ever want to get out of the bus again, and then if you go to the right hand side here it often is the negative again.",
            "So it is so this model just intuitively can capture many of the aspects that we expect of reunions to be the case.",
            "So now.",
            "Now, this is what this is.",
            "The biological reason why we want to use something like that.",
            "This is a very good computational reason why we used it, because it turns out that the optimization that you get if you want to do learning in that system is convex.",
            "And because it's convex, we can very efficiently solve that.",
            "Which is probably even more so.",
            "The reason for choosing this model then all these reasons and so so we can do a maximum or posterior estimate of the weights very efficiently."
        ],
        [
            "What is nice about it is that this model supports what's called, explaining away in the typical data analysis methods in.",
            "When it comes to functional connectivity analysis, don't have that property, so imagine we're in this situation with three neurons AB&C, and we caught from all these three neons and we look at the correlation between them.",
            "In this case, we find because a is correlated with.",
            "Here's what we see here.",
            "The correlations A is kirbys correlated with C. So these are what we should expect.",
            "Because it is also correlated to see because B&C are interacting with one another.",
            "But then if you if you fit the such a functional connectivity model, you have explaining away a tons of that the interaction from B to C is sufficient to explain away the influence of A&C.",
            "And if you do estimates with that, it will look like this.",
            "So you really get out the right kind of connections.",
            "Same thing if you have if you have a system like that where you have a which excites B&C, you have a correlation between B&C which is again explained away by that model.",
            "So, so far everything we've done was on simulated neurons, an it it works beautiful and simulated neurons infected works still beautiful or like pretty good.",
            "If we take simulated neurons and we add lots of simulated neurons that are totally that we don't record from, it still does a pretty good job.",
            "And let's look at."
        ],
        [
            "How the feds look like if we do that for reunions.",
            "So here we see just a bunch of so.",
            "So throughout the talk when I show real neurons, almost all of them are from our collaborator Nico Hatsopoulos, who has two greats of 100 electrodes each in primary motor cortex in premotor cortex.",
            "They're both involved in the planning and execution of movement.",
            "There so they use the pretty solid methods to find out which neuron is firing at which point of time, and it's generally something of the order of 118 yarns that are simultaneously recorded.",
            "Now what you see now, let's look at the diagonal.",
            "So the diagonal of the filters often Jan onto itself and what you see here is, and this this one is relatively typical here.",
            "You see for that neon there is a refractory.",
            "So at first it is very negative and then it goes up and it stays up.",
            "So this is a new one that tends to once it gets into a mode of firing itself tends to continue firing.",
            "And and here is, let's see what else.",
            "And then.",
            "Of course, there's exception to that.",
            "Exceptions to that general scheme.",
            "But this these neurons tend to bust a little bit, and you see that in the fault often you're not upon itself, and then you find that some neurons interact with some neurons.",
            "Say this is the first one, with the third one.",
            "Here in that grow, and so on and so forth.",
            "And you can say, well, should we.",
            "What can we do with these with these folders?",
            "I mean, it's a nice description of.",
            "The spiking and we can test statistically how good to model it is for the spiking of the South, but but should we trust that measure at all?",
            "And of course we can do cross validation with invite the training set into different parts.",
            "We see how similar the functional connectivities are between them and they are very, very similar.",
            "So if we repeated just twice, we essentially get the same result twice, so it is a solid measure.",
            "We don't know for the moment what it means, yes.",
            "Use for the interaction debates.",
            "Very good question.",
            "So there's two approaches that we've been using.",
            "One of them is is is a price that we that we get from knowledge about the biology, which is primarily we assume that of all the connections that could exist, we have pretty good prior knowledge that most of them shouldn't exist, so it's a sparse prior over the existence of connections.",
            "Of course, as fast prior over the existence of the connections is something that we couldn't computationally use.",
            "Because we would need to go through extra it's exponential in the number of neurons that we have, not even worse exponential in the number of pairs of neurons that we have.",
            "So that doesn't work by itself, but what we can do is we can put in our.",
            "We can put an L1 prior onto the connection strength between yards.",
            "So effectively we just put us past prior onto the connections between yards and we find we find that if we use double cross validation to get the values of that many of the connections go to zoo.",
            "So that's the first thing from biology.",
            "We also know that their smoothness.",
            "So if an urn is exciting and other non, it is certainly less at 10 milliseconds then probably at 11 milliseconds the volume will be similar.",
            "So you can say we have a smoothness problem.",
            "We have a sparse and spry over connections.",
            "Now it turns out that solving that this kind of ugly.",
            "So it turns out that you need to do if you do them in this case and you have a set of hyperparameters and.",
            "And you have a partition function that's really, really ugly.",
            "It works with this.",
            "There's a paper TMSIE from last year where we've done it, but it turns out that you can get a lot of the mileage you get out of that very cheaply.",
            "What you do is you represent the photos by basis functions.",
            "We have some short once in some medium wants some long ones.",
            "It's Pinsky and Pillow and others have been using that trick before.",
            "And then you put a sparse prior over the individual coefficients of that.",
            "The cool thing is you remade it remains a convex optimization problem and therefore again you can efficiently solve it and in the disadvantage you have vaulted to doing the full Bayesian estimate for the with the with the strong prices.",
            "I mean it really doesn't cost you much.",
            "Great question otherwise."
        ],
        [
            "OK, let's let's talk about the slightly more general problem.",
            "One second place.",
            "So in the previous model we just set nouns interact with one another, but we can of course build hybrid models that have the aspects of tuning curve models and also the aspects of interaction models.",
            "Where we can say that our conditional intensity function is affected.",
            "And yeah, it's the same IJ problem here again, just just to prevent that.",
            "But you can say there's external covariates, say the direction of movement of the monkey.",
            "Or the visual stimulus property.",
            "And so in this case we can give them Yana tuning curve to this time where where small V. Here are the other external properties and we can give it interactions with other neurons, and otherwise it's the same model and we can optimize it in the same way.",
            "Sony owns I affected by their nonsense.",
            "Also affected by the outside world."
        ],
        [
            "For people who like graphical versions of that, here we have human or monkey move into different directions.",
            "We have tuning curves, the tuning curves added to the tuning curves are linear weights of the past of what has happened to the other neurons and the neuron itself.",
            "It's being added up together, that's a nonlinearity and then we have constant spiking on the output, so that's the generative model and.",
            "What we wanted to know then is we don't know necessarily what our results, what our results mean, but we want to be able to compare this to a purchase, which is we could either model it with using only the way neurons interact with the outside world, or we could model it only using onions, interact with one another, and we want to see how good we are predicting your neural spikes based on these two extreme models.",
            "And you can say if interaction models are better than models that are about tuning curves, we can already say that this way of modeling the brain is my use or or is at least better at making predictions.",
            "And the other way of modeling.",
            "And this is what you."
        ],
        [
            "What you see here, what we did is we we took the 118 yards from our collaborator and we subsampled them so we randomly just talk say hundred of them or 10 or five.",
            "We took subsets of them and then we tried how good we can predict firing rates based either on how they relate to the outside world, which is what you see in black here or how they would like to add onions.",
            "And of course if we have a tuning curve model where we say we predict how many spikes we should get.",
            "Based on the properties of, say, the direction of movement of the monkey, it doesn't matter how many neurons we have.",
            "So yeah, I should say on this axis is how many neurons we put into the system on this axis you have the cross validated log likelihood in bits per second.",
            "This is just a measure of how good we are at predicting the spikes that we get out of the neurons, and so we get a certain quality of prediction if we use tuning curves, which is the standard approach that people use in your science.",
            "And of course this doesn't.",
            "Depend on the number of neurons that we record from another cause.",
            "If we we cut from onions will be better predicting then if we were cut from funerals and he invent you see that the information we get appears to be growing linearly in this plot.",
            "So this May in fact if we look at the crossover point, it happens at salty.",
            "So this means as soon as we wake up from 13 yards or more, we're better predicting the spikes of another neuron based on the interactions of that non with the other neurons.",
            "Then we are based on based on how that non relates to the outside world.",
            "So you can say yeah, we're only recalling from a tiny proportion of all the neurons that are in the brain, but we already better than just viewing yarns in terms of how they relate to the outside world.",
            "Now this is data from Moto Coptics and you might say well then maybe maybe there's something special about motorco ticks, maybe maybe it would be different in completely different areas, But it turns out it's very very similar.",
            "So here's the same analysis for for primary visual cortex.",
            "Again on this axis, the logarithm of the network size on this axis.",
            "The information that we get pognon nicely grows linearly.",
            "So now we have two data analysis algorithms.",
            "One of them describes nouns in terms of what they mean about the outside.",
            "What the other one describes nouns and how they relate to the firing of other neurons, and we find that that one of them scales as you see.",
            "This is the information pognon.",
            "And of course, if we have that, if we want to know the total information you need to multiply that with, then the number of neurons.",
            "So here we have one algorithm that gives us oh of N, which is the black one here, and another algorithm which gives us of N lock N which is the connectivity model.",
            "So this means it's scaling better, which is kind of useful because they could yet be other algorithms that would scale better.",
            "Maybe there's an algorithm that scales us over N squared and it turns out that this is actually very important, because if we can.",
            "Because the scaling law is it's driven by this most law for the number of simultaneously recorded neurons.",
            "It's really if we have algorithms that scale better, they're going to get arbitrarily better than the algorithms that scale was.",
            "I also want to point out that, so here in the visual system that cut across over in fact happens at 10.",
            "So you need relatively small numbers of neurons, and you're already better describing them in terms of what other neurons do.",
            "And in some sense, at the moment this approach seems to be benefiting from this hope number two I I talked about in the beginning, which is it appears that we are doing reasonably well, although we only recover from some few neurons, and that is probably because there's many neurons that I'm doing relatively similar things in the nervous system, and therefore it might be that we are doing relatively good based on a small number of them.",
            "So, but then the next thing we wanted to do is if we can already ask some scientifically interesting questions and one of them that I agree.",
            "I very briefly I get this next slide this morning, just a couple of just a couple minutes before my talk.",
            "One aspect that's been described in slices.",
            "So you take you take a brain, you cut it into a small slab and you record from tournaments.",
            "And it's been described that there's this effect called spike timing dependent plasticity.",
            "What that means is if you have one neuron that fires and.",
            "You have a sign access the connection between turnarounds, the presynaptic neuron fires, and then the postsynaptic neuron fires.",
            "And if that happens within a short period of time, it turns out that the influence of the first nouns until the second gets to be stronger.",
            "If you reverse the direction gets to be weaker.",
            "So this is what's called spike timing dependent plasticity.",
            "There's also heavy and learning if turning on Spike at the same time, the connection between them gets right.",
            "Now what we wanted to say is to ask this.",
            "Well, that's what's been done.",
            "On single isolated cells, but if our algorithm start getting at something real, we should be able to see that in cortex for our large number of recordings, and one advantage that we have, there is of course if we were cut from churn with nuns we have 40,000 connections, which means that if we want to know properties of these connections, we can massively average of all the connections that are there and this is."
        ],
        [
            "What we did here?",
            "So what used?",
            "So we extended the model where we set the phone, wait on the influence of one another is a linear influence is linear overtime, but test, but there's a second term elearning time which says if we have a sudden event then this influence gets to be stronger or weaker.",
            "So it's bilinear where we say the influence is a function of the actual weight which we first fit in the function of an interaction term that depends on how what neurons have done with one another.",
            "On this axis you have the time delay between the pre and post synaptic neuron.",
            "On this axis you have the multiplicative strength effect.",
            "If that is happening, so this is how much stronger is the connection afterwards than it is before and what you see here.",
            "Every single black dot is from one pair of neurons.",
            "In blue you have the you have the means and standard errors of the means, and somehow there's a few points up here with.",
            "It's just cut so that only that part is visible and you can see clearly the spike timing dependent plasticity effect here.",
            "If the presynaptic neuron has fired fast and the strength strength get weaker if it's slightly afterwards, the strength gets the strength get weaker and in the end it has no effect at all and you can see it's not quite centered at 0, so it looks like it.",
            "It's all positive.",
            "This is probably just the heavy and learning effect, because both of them have been active at the same time, otherwise this wouldn't have even have been in the in the training set there.",
            "So this means that that with these functional connectivity techniques we can start asking questions that people before would ask about pairs of neurons in in specific slice slice preparation.",
            "So it appears that these techniques are nice way of starting to reverse engineer.",
            "How the nervous system unfolds overtime.",
            "OK, any questions?"
        ],
        [
            "OK, good, so the next question that we then wanted to ask is well if we have fit in where we are fitting these models where we say the phone weight of the neuron depends on the outside world and it depends on the other neurons.",
            "This could have the effect that the tuning cover bunion could change because we have explaining away.",
            "So it might be that anyone isn't changed by itself, it's only tuned because it gets excited by other neurons that happened to be checked.",
            "Of course in the limit, if you if we record from all neurons.",
            "That's only two classes of nouns that have receptive field or tuning curves.",
            "The retinal neurons care about visual stimuli and the movements care about muscle movement production.",
            "No one else should have any tuning curves, but you can say, well, we don't know where we cut from this small number of neurons.",
            "Maybe the tuning curves are still very, very important in this a quantitative question.",
            "And it turns out that there's some neons for which the tuning curve doesn't change.",
            "So here you have in Jan is a Phantom of the direction of the hand movement.",
            "You have this spike.",
            "Count an Inn in blue.",
            "You have the full model where you where you have both an in rack.",
            "You have the case where you only fit cosine tuning for the direction of movement, so in red you have the model that says there's only there's only tuning curves, and in this case it doesn't matter if you should listen on the tuning curve stays the same even if you incorporate all the all the all the rest.",
            "Same thing for this more or less, but then there's many neurons for example this one.",
            "That have very strong tuning curves.",
            "If you analyze it in a traditional way, but if you consider the interactions as well, the tuning cover almost goes away and this is something that we find for a good number of the neurons.",
            "Look here very strong, turning almost not tuning at all.",
            "Same thing here.",
            "So this means that for some reason and I don't quite understand that reason.",
            "It's already at this small number of neurons that we have 200 that that it starts to look as if neurons have very very weak tuning curves by themselves, but they get most of their tuning by the interactions they have with other nodes."
        ],
        [
            "And I should say, I think that in this general, in this general approach, which is how can we understand how neurons relate to one another, there's many machine learning problems, many exciting algorithmic problems where you can say, well, we want to find structure.",
            "So this in all likelihood there's certain classes of neurons that share certain properties.",
            "At the moment, the generative model that I showed to you has no structure at all in this, and this is very important for neuroscience because they get all these neurons and all the interactions.",
            "But they want to know, OK, are there certain subclasses of neurons that have certain properties?",
            "So the question is then OK, can we find hierarchical generative models for spikes that allow us to understand what the different classes of notes are?",
            "We want to use better priors.",
            "We want to link that to cognitive phenomena and we want to reverse engineer learning rules and all kinds of questions that need to be asked about it.",
            "In that ends my talk, I want to.",
            "Of course I want to thank all the collaborators that I did this worth.",
            "Nicely send US data that we could analyze and I want to thank you for listening."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, laser ponder springstone.",
                    "label": 0
                },
                {
                    "sent": "The second laser ponders been lost, so I'll be without a pointer.",
                    "label": 0
                },
                {
                    "sent": "It's good that it's the last day of the conference, I guess.",
                    "label": 0
                },
                {
                    "sent": "So I will be talking a little bit about neuroscience today.",
                    "label": 0
                },
                {
                    "sent": "I understand that that's the first talk about neuroscience, so it will be rather introductory.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I'll first talk about a couple of general things and then about 3 specific topics and I should also say that the slot then, which I'm talking about it is the slot that I took from Peter Diane who didn't make it here, and therefore he can't defend his onslaught and it got number of the slides are inspired or directly tailored.",
                    "label": 0
                },
                {
                    "sent": "A few of the slides are directly taken from his talk, and of course I'm adding my own flavor to it.",
                    "label": 0
                },
                {
                    "sent": "Because I can't, I can't channel a perfect Peter talk very fast.",
                    "label": 0
                },
                {
                    "sent": "And yeah, exactly let me try to talk a little bit faster.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'll be talking about Level 3 mile implementation.",
                    "label": 1
                },
                {
                    "sent": "So what I want to say is, there's certainly something very interesting about the third level of math, and while a lot of the talks here focused on the 1st and the second level, which is what's the objective and what's the best solutions to it?",
                    "label": 0
                },
                {
                    "sent": "Suddenly the nervous system uses a specific implementation which happened to be in terms of neurons and the interactions that they have.",
                    "label": 0
                },
                {
                    "sent": "Between one another and there may be a number of aspects of cognition that we can only understand once we actually start asking ourselves how it's actually implemented in this certain certain algorithms that will be much more likely given the knowledge that we have about implementation.",
                    "label": 0
                },
                {
                    "sent": "So each of the three llama levels of course strongly informs the neighboring mall levels, so if we understand more about what neurons do, we might understand more about about the kinds of algorithms that brightness implementing.",
                    "label": 0
                },
                {
                    "sent": "I should also say if we microscopically look at the nervous system, it's neither really suggestive.",
                    "label": 0
                },
                {
                    "sent": "Both generative, not discriminative algorithms of learning.",
                    "label": 1
                },
                {
                    "sent": "But we rather have these nuns that interact with one another in there, and we characterize how cynapsus changes function of input and output.",
                    "label": 0
                },
                {
                    "sent": "But how that Maps on bigger problems?",
                    "label": 0
                },
                {
                    "sent": "It's one of the big problems in your sights, and I understand that some of the other speakers today might be talking about that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So neurons generate spikes and you can say that.",
                    "label": 1
                },
                {
                    "sent": "In most cases we don't actually care about the generative model that we do.",
                    "label": 0
                },
                {
                    "sent": "There we choose for machine learning problem.",
                    "label": 0
                },
                {
                    "sent": "We actually care about the predictions we can get out of it.",
                    "label": 0
                },
                {
                    "sent": "So the generative model usually is just a tool that allows us to ask interesting different questions.",
                    "label": 0
                },
                {
                    "sent": "But if we want to understand the brain, we can say this is actually one of the cases where we care about the generative model.",
                    "label": 1
                },
                {
                    "sent": "If you give me some data for the nervous system and I want to understand another system, it means that I'll be able to understand the generative model that gives rise.",
                    "label": 0
                },
                {
                    "sent": "To the data that I'm recording.",
                    "label": 0
                },
                {
                    "sent": "So actually in this case I care which probabilistic processes making the data, and this is the primary interest in your science.",
                    "label": 0
                },
                {
                    "sent": "What is the process that makes the data that you're measuring your experiments?",
                    "label": 0
                },
                {
                    "sent": "And this means that you'd like to have a model of the spikes that you're getting, and ultimately you want to understand this structure and the function of the objectives of the spikes that you find in the nervous system.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Let us first ask ourselves a little bit if this is if this is even more realistic.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it might.",
                    "label": 0
                },
                {
                    "sent": "It might not.",
                    "label": 0
                },
                {
                    "sent": "So here we have the brain.",
                    "label": 0
                },
                {
                    "sent": "If I had a laser pointer could show it to you, but it's on the right hand side of the slide.",
                    "label": 0
                },
                {
                    "sent": "Now investors, this slight issue that there's 10 to the 11 neurons switches in each of these nouns is potentially rather complicated, and we have something of the order of 10 to the 14 synopsis, so it's a big system, and at any point of time we will only be recording from a tiny percentage of these neurons.",
                    "label": 0
                },
                {
                    "sent": "Who knows what's the hey, great?",
                    "label": 0
                },
                {
                    "sent": "Thanks a lot.",
                    "label": 0
                },
                {
                    "sent": "Who knows what's the maximum number of neurons that people usually record from it?",
                    "label": 0
                },
                {
                    "sent": "The same time today?",
                    "label": 0
                },
                {
                    "sent": "Thousand Yeah 1000 is with with today's optical methods you can get close to 1000.",
                    "label": 0
                },
                {
                    "sent": "Well, when it's it's a couple 100 simultaneously recorded neurons with electrodes.",
                    "label": 0
                },
                {
                    "sent": "It's about 200 if you only consider the actually published papers so far.",
                    "label": 0
                },
                {
                    "sent": "So 200 is the number that we were caught from 10:50, so we have here, and the question is, what can we even say about the nervous system if we have such a small?",
                    "label": 0
                },
                {
                    "sent": "If we have?",
                    "label": 0
                },
                {
                    "sent": "If we only record from such a small number of neurons, and so we are trying to understand how a system with 10 to the 11 nuance walks.",
                    "label": 1
                },
                {
                    "sent": "Based on most experiments only we cut from a single now, so we try to understand this huge system with all these different aspects based on recordings of single neurons usually and in the maximal case from a few 100.",
                    "label": 0
                },
                {
                    "sent": "So the question is why should that be possible to work?",
                    "label": 0
                },
                {
                    "sent": "Imagine I give you a pen, some processor and your recording from a transistor.",
                    "label": 0
                },
                {
                    "sent": "It would be rather difficult to infer the function of it.",
                    "label": 0
                },
                {
                    "sent": "But it wouldn't be so hopeless because because if we're in this case, it's been designed by humans, and it does a certain favors, for example, that say the transistors within large areas of it.",
                    "label": 0
                },
                {
                    "sent": "I just periodic.",
                    "label": 0
                },
                {
                    "sent": "You have served the same elements that are used over and over, so there's different assumptions that you then can make an under those assumptions.",
                    "label": 0
                },
                {
                    "sent": "No sense again gets to be possible, and I want to go through these assumptions first, because because they're there, serve the necessary criteria for neuroscience as a field to understand.",
                    "label": 0
                },
                {
                    "sent": "Human behavior fight to be possible.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, the first help imagine the brain is a little bit like a city.",
                    "label": 0
                },
                {
                    "sent": "It consists of of different brain areas and in each of these brain areas essentially all neurons are identical.",
                    "label": 1
                },
                {
                    "sent": "So say if you if we talk about primary visual cortex, the way many people in your sense think about it is these neurons are tuned to Gabor wavelets.",
                    "label": 0
                },
                {
                    "sent": "We can describe them as linear filters with Gabor wavelets type kernels and.",
                    "label": 0
                },
                {
                    "sent": "A and an apartment and onions identical.",
                    "label": 0
                },
                {
                    "sent": "They all have gathered type receptive fields apart from a very small number of largely of parameters switches.",
                    "label": 1
                },
                {
                    "sent": "Each neuron has a position and it has his preferred spatial frequency and a preferred orientation and all that.",
                    "label": 0
                },
                {
                    "sent": "So so in that sense we can say it's quite analogous to, say, the way we'd writing and your network where we can say, well known, say exactly identical.",
                    "label": 0
                },
                {
                    "sent": "Apart from they have the same learning, all same properties, and so forth.",
                    "label": 0
                },
                {
                    "sent": "They they just copy and paste it, and if this is the case then your science actually is supremely possible, because all we need to do is we need to find out all the areas, and that's something that say after my research very strongly focuses on and then we need to recover from these neurons, find out what they're tuning properties are, and then what are the axis along which they are different from one another.",
                    "label": 0
                },
                {
                    "sent": "And then we just copy and paste.",
                    "label": 0
                },
                {
                    "sent": "The only understand how the brain works.",
                    "label": 0
                },
                {
                    "sent": "So this is one up and it's a hope that is very compatible with my cutting from single nuts, because if this is how the brain works, recording from single neurons will solve the neuroscience part because all we need to do is we need to record from each from each area one or like a small number of neurons each characterize what that shooting properties are and then we understand how it works.",
                    "label": 0
                },
                {
                    "sent": "So here's another.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's another way.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 assumption under which in our science will work very well.",
                    "label": 0
                },
                {
                    "sent": "Here's another possibility.",
                    "label": 0
                },
                {
                    "sent": "Imagine that the brain consists of groups of neurons that are essentially doing the same thing, where all neurons in the same group are doing the same thing.",
                    "label": 1
                },
                {
                    "sent": "But these groups might.",
                    "label": 0
                },
                {
                    "sent": "There might be significantly more of these groups.",
                    "label": 0
                },
                {
                    "sent": "Then we have brain areas.",
                    "label": 0
                },
                {
                    "sent": "In this case, if if all neurons within each groups occur by esentially identical, we would only need a small number of electrons at the same time.",
                    "label": 0
                },
                {
                    "sent": "Even if these groups interact in some interesting way.",
                    "label": 0
                },
                {
                    "sent": "As long as we hit each of the groups, we can characterize how they interact with one another and the relationship of the neurons in this for this view might be complicated.",
                    "label": 1
                },
                {
                    "sent": "Their interactions might be complicated.",
                    "label": 0
                },
                {
                    "sent": "They each group might be very different from the others, and but in this case recording from one neuron in each of these relevant groups would be enough.",
                    "label": 0
                },
                {
                    "sent": "In this case, we would still need to record from a large number of neurons to understand how it works, but we would need to record from much less than the 10 to the 11 yards, maybe with a couple thousand would be there.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then there could be a thought.",
                    "label": 0
                },
                {
                    "sent": "Hope that would make no sign swap, which is it could be that all neurons are really fundamentally different from one another, but it could be that the learning rules that give rise to the neurons identical or very similar to one another, and in this case, if we have a brain area and we know the statistics of its input, we can predict all the properties of thin answer there in this.",
                    "label": 1
                },
                {
                    "sent": "In this case, if we understand these learning rules that give rise to the properties of the neurons.",
                    "label": 0
                },
                {
                    "sent": "We can potentially understand a very complicated nervous system based in very simple ideas, and here I want to show you just some data.",
                    "label": 0
                },
                {
                    "sent": "This is the results from a study by Bruno Olshausen.",
                    "label": 0
                },
                {
                    "sent": "What he did is took a lot of photos of natural scenes and he said, let's assume that the learning rule that gives rise to the properties of neurons in the primary visual cortex is that the outputs in response to an extra scene size fast as possible, and what you found is that there's lots of different that there's a population of very.",
                    "label": 0
                },
                {
                    "sent": "Testing neurons that optimizes this criterion, and of course it needs very few neurons to describe the property.",
                    "label": 0
                },
                {
                    "sent": "A very few parameters to describe these properties.",
                    "label": 0
                },
                {
                    "sent": "Just assumption of a learning rule effectively, and yet it can produce a wide range of different neuronal properties.",
                    "label": 0
                },
                {
                    "sent": "So this does not help.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Kiss another hope, which is which is the technology optimists.",
                    "label": 0
                },
                {
                    "sent": "Which is you can say at the moment we only record from a couple 100 yards thousand as you said, and but near technology is advancing rapidly.",
                    "label": 0
                },
                {
                    "sent": "And as these technologies advance, we may be able to just scale up the number of neurons from which we we caught an ultimately it might not actually be so difficult to.",
                    "label": 0
                },
                {
                    "sent": "I mean, we might actually get close to 10:50 North and a reasonably.",
                    "label": 0
                },
                {
                    "sent": "A reasonable period of time and this is just some, some calcium calcium imaging data that you have here is one of the top techniques at the moment.",
                    "label": 0
                },
                {
                    "sent": "You can record from a good number of units at the same time.",
                    "label": 1
                },
                {
                    "sent": "Now let's talk about something completely different.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Probably most people have seen this graph.",
                    "label": 0
                },
                {
                    "sent": "This is Moore's law for computers on this axis of the year of the introduction of microprocessors, and on this ecstasy of the number of transistors there that were on that device.",
                    "label": 0
                },
                {
                    "sent": "And you can see that it's been growing exponentially beautifully for long period of time.",
                    "label": 0
                },
                {
                    "sent": "The effect of that is, of course that my my phone cheap and simple as it is, would have been an amazing computer a couple decades ago.",
                    "label": 1
                },
                {
                    "sent": "And of course, this had a lot of impact.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patience, I'm computer science.",
                    "label": 0
                },
                {
                    "sent": "For example, you don't usually think so much about the actual speed of a of an algorithm, but you focus on how it scales with the number with the number with the size of the data set that you have and you were using the big O notation and and of course.",
                    "label": 0
                },
                {
                    "sent": "Who in this room doesn't know the big O notation?",
                    "label": 0
                },
                {
                    "sent": "OK, that's so so it's just you ask her and algorithm scare so big O of N squared would be if you have twice as much data you takes for taxes law.",
                    "label": 0
                },
                {
                    "sent": "But now it turns out that something like most laws are placed in your science, and that's something we just recently found.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we went to Google Scholar.",
                    "label": 0
                },
                {
                    "sent": "We searched for paper, we searched for the Tom and simultaneously recorded neurons an we only.",
                    "label": 0
                },
                {
                    "sent": "We only allowed the first couple of papers that reached us that were above a certain level.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But we have on this axis is the year of the publication of earlier science paper.",
                    "label": 0
                },
                {
                    "sent": "On this axis you have the number of simultaneously recorded neurons.",
                    "label": 1
                },
                {
                    "sent": "So the lock of that here and you see it grows nicely exponentially of about five decades, is much slower than the than the rate with which things increased in computer science, it doubles every seven years, but there's this nice thing about exponential functions that they actually rise that they actually get pretty far.",
                    "label": 0
                },
                {
                    "sent": "If you just wait a little so in the year 2200 if you extra late, this here will be recovering from all the neurons of the brain at the same time.",
                    "label": 0
                },
                {
                    "sent": "How far we can extrapolate these things is very unclear.",
                    "label": 0
                },
                {
                    "sent": "If you ask newer scientists, how long will this happen?",
                    "label": 0
                },
                {
                    "sent": "Continue happening?",
                    "label": 0
                },
                {
                    "sent": "This increase, they say about one decade.",
                    "label": 0
                },
                {
                    "sent": "It turns out that if you if you look at people write about mostly in computer science, it's the universal invariant that people say.",
                    "label": 0
                },
                {
                    "sent": "Most law is over in 10 years time.",
                    "label": 0
                },
                {
                    "sent": "It seems to be true.",
                    "label": 0
                },
                {
                    "sent": "This law seems to be true for neuroscience as well, that people feel like we're really hitting hard boundaries in about a decade.",
                    "label": 0
                },
                {
                    "sent": "But then I spoke with some people who develop action.",
                    "label": 0
                },
                {
                    "sent": "You're recording techniques, ask them if they could scale it up by effect of 1000.",
                    "label": 0
                },
                {
                    "sent": "And they say if you give me a lot of money, we could suddenly scale it up by a factor.",
                    "label": 0
                },
                {
                    "sent": "So now, because this is this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some implications when you can say well if news if computer Sciences scaling like that and the effect of that that was that we focus on scaling loss.",
                    "label": 0
                },
                {
                    "sent": "We want algorithms that scale well with the amount of data that we have.",
                    "label": 0
                },
                {
                    "sent": "We can say the same thing about neuroscience, which is we want data analysis methods that scale well with a number of simultaneously recorded neurons.",
                    "label": 0
                },
                {
                    "sent": "We want techniques and can take advantage out of the fact that we were cut from on monuments at the same time and.",
                    "label": 0
                },
                {
                    "sent": "First, one time time you might say, well, if we were cut from on monuments won't we run into problems that our computers are too slow for the analysis?",
                    "label": 0
                },
                {
                    "sent": "And actually there's some good news about that because at least at the moment computers get twice as fast in two years the number of neurons we cut from gets twice as fast in seven years, so we can use algorithms if it continues like that, we can use algorithms that scale exponentially with the number of neurons.",
                    "label": 0
                },
                {
                    "sent": "OK, so great we can do it.",
                    "label": 0
                },
                {
                    "sent": "But the thing that we might be interested in is how much information we learn panion.",
                    "label": 0
                },
                {
                    "sent": "So how much does the information we get about the nervous system scale as we change the number of neurons simultaneously recorded for, and I'll get to this point towards the end of my talk today.",
                    "label": 0
                },
                {
                    "sent": "Oh, and I should say just like yesterday, please interrupt me if anything is unclear.",
                    "label": 0
                },
                {
                    "sent": "If you disagree with me.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So today's talk has three like.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about three issues.",
                    "label": 0
                },
                {
                    "sent": "The first thing is about understanding how onions relate to the outside world.",
                    "label": 1
                },
                {
                    "sent": "The second one is I'll briefly mention her neons micro present uncertainty, which is an intense topic of research in computational sense at the moment.",
                    "label": 1
                },
                {
                    "sent": "And Lastly, I will talk on about how nuanced relate to one another.",
                    "label": 0
                },
                {
                    "sent": "Anything that's very interesting machine is going to be very interesting.",
                    "label": 0
                },
                {
                    "sent": "Machine learning applications in this stuff part.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's first talk about how Neon's relates to the outside world.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The typical way experiments have been have been done.",
                    "label": 0
                },
                {
                    "sent": "I like that you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you take an animal and your record from the from the animal's brain has just a depiction of that.",
                    "label": 0
                },
                {
                    "sent": "The animals involved in some ties, either anaesthetize if you just want to know what the properties of of perceptual of the perceptual system is, other animals actually involved in some task, say whenever it sees the certain kind of stimulus it needs to push their hand to the left or to the right.",
                    "label": 0
                },
                {
                    "sent": "You very this stimulus you are very what you showed to the animal and you vary the behavioral demand.",
                    "label": 1
                },
                {
                    "sent": "You change the task.",
                    "label": 0
                },
                {
                    "sent": "Are you required the animal to move into different directions and you measure how they behave and you measure the neural signals that you're getting out and then you try and relate the neural signals.",
                    "label": 1
                },
                {
                    "sent": "You have two properties of the stimulus, an properties of the task.",
                    "label": 0
                },
                {
                    "sent": "And this is this has been an incredibly useful approach in your science, and we know that for many brain areas, we know the tuning curves of the tuning properties of neurons with with with with respect to movement related or with respect to stimulus related properties.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, here's some data.",
                    "label": 0
                },
                {
                    "sent": "Here we have a monkey.",
                    "label": 0
                },
                {
                    "sent": "The monkey always starts in the middle of its workspace, and the monkeys moving forward, right down left diagonal all directions.",
                    "label": 0
                },
                {
                    "sent": "Many repetitions of the same, same thing.",
                    "label": 0
                },
                {
                    "sent": "This is what you see.",
                    "label": 0
                },
                {
                    "sent": "Hear each of these lines here.",
                    "label": 0
                },
                {
                    "sent": "They're called raster plots.",
                    "label": 0
                },
                {
                    "sent": "They they they depict at which point of time neurons spiked.",
                    "label": 0
                },
                {
                    "sent": "This line.",
                    "label": 0
                },
                {
                    "sent": "Here is the time where the monkey actually moved and you can see that for the movements where the monkey moved to the left, you get more spikes him off the.",
                    "label": 0
                },
                {
                    "sent": "The vertical bars here and if it moved to the right, you get few of them and then you can plot the numbers of spikes as a function of the movement direction of the monkeys are.",
                    "label": 0
                },
                {
                    "sent": "You can plot the firing rate of the new on the average family, then total number of spikes in some interval and it was found that for the movement system there's a very nice cosine tuning between the between the spikes and the direction of movement.",
                    "label": 0
                },
                {
                    "sent": "So people people were happy they said OK, great, we understand what's the.",
                    "label": 0
                },
                {
                    "sent": "How how are the motor system?",
                    "label": 0
                },
                {
                    "sent": "How the primary motor cortex encodes movements and then similar?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Experiments have been done for the primary visual cortex.",
                    "label": 0
                },
                {
                    "sent": "He have data from UBL Inviso, you recut from Mignon in the primary visual cortex.",
                    "label": 0
                },
                {
                    "sent": "You show it boss or of different light bars of different direction and you move it over the receptive field of the neuron.",
                    "label": 0
                },
                {
                    "sent": "So the the way people think about neurons in the primary visual cortex is that they essentially see a small part of the visual world.",
                    "label": 0
                },
                {
                    "sent": "All the rest they don't care bout.",
                    "label": 0
                },
                {
                    "sent": "And when if you then show a bar in that in the receptive field of the neuron, it gets to be very active.",
                    "label": 0
                },
                {
                    "sent": "So so if you show up but like destiny and doesn't spike it all, if you show it slightly more in this orientation, a few spikes here, lots of them again, few of them and no more at all.",
                    "label": 0
                },
                {
                    "sent": "And you can do the same thing.",
                    "label": 0
                },
                {
                    "sent": "You can plug the tuning curve where on this axis of the orientation angle of the stimulus and on this axis you have the phone right of the new.",
                    "label": 0
                },
                {
                    "sent": "You see two things here.",
                    "label": 0
                },
                {
                    "sent": "It it looks like it's in good approximation orgas, and it's caution in the in the orientation of the stimulus.",
                    "label": 0
                },
                {
                    "sent": "You in fact also see another thing which is which is the new one appears to be firing Leica.",
                    "label": 0
                },
                {
                    "sent": "Leica appears to be passed off firing.",
                    "label": 0
                },
                {
                    "sent": "You see that the variance that you have here is larger than the variance that you have here, and there's there's.",
                    "label": 0
                },
                {
                    "sent": "There's a very regular relationship between those two.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's some more experiments that was done.",
                    "label": 0
                },
                {
                    "sent": "This is this stuff by Pojan Talbots.",
                    "label": 0
                },
                {
                    "sent": "You look at stimuli that very in depth, so they vary.",
                    "label": 0
                },
                {
                    "sent": "In disparity disparity means the there's a difference between for the.",
                    "label": 0
                },
                {
                    "sent": "So if a stimulus is closer or further away, it appears at different angles for the two eyes.",
                    "label": 0
                },
                {
                    "sent": "So the difference in angles is different.",
                    "label": 0
                },
                {
                    "sent": "That's what's called disparity.",
                    "label": 0
                },
                {
                    "sent": "If you vary the disparity there 7 yards that have low firing rate, if it's a negative disparity.",
                    "label": 0
                },
                {
                    "sent": "So this means if it's closer to your fixation, an high firing rate if it's further away from fixation.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's here's another characterization you taker at.",
                    "label": 0
                },
                {
                    "sent": "You have the right run around.",
                    "label": 0
                },
                {
                    "sent": "You record from cells in the in the rat while it's running around, and you plot the firing rate of the of the of those cells as a function of whether it is so.",
                    "label": 0
                },
                {
                    "sent": "You just have this this lady on the rat that measures how it's moving about and you just get the firing rate as a function of the position.",
                    "label": 0
                },
                {
                    "sent": "And people have found that their so called great cells, these cells that are active at certain places in space.",
                    "label": 0
                },
                {
                    "sent": "So not just one but their cell, but equally fired the readers here.",
                    "label": 0
                },
                {
                    "sent": "So this is just special.",
                    "label": 0
                },
                {
                    "sent": "This is just space.",
                    "label": 0
                },
                {
                    "sent": "This is the rat is moving in this little square box on this axis.",
                    "label": 0
                },
                {
                    "sent": "That's just the X axis, the Y axis.",
                    "label": 0
                },
                {
                    "sent": "So this is really just the spikes is a function of the firing rate as a function of where the red is, and you find this regular.",
                    "label": 0
                },
                {
                    "sent": "Hexagonal great, it's called it's called red cells and what is for?",
                    "label": 0
                },
                {
                    "sent": "It's not quite clear, but there's a brain area where lots of neurons have this property.",
                    "label": 0
                },
                {
                    "sent": "And then there's another out of right now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the hippocampus where they found that there's some areas in space where the neurons are very strongly active and it's not active in the rest.",
                    "label": 0
                },
                {
                    "sent": "And you can say this is a very useful representation because it tells me that I'm at a different place given position in space.",
                    "label": 0
                },
                {
                    "sent": "And if I have that information I can.",
                    "label": 0
                },
                {
                    "sent": "I can say remember where I get food because they could associate it with activity of these nuts.",
                    "label": 0
                },
                {
                    "sent": "But you can see all these different cases.",
                    "label": 0
                },
                {
                    "sent": "It's it's.",
                    "label": 0
                },
                {
                    "sent": "It's computationally the same thing.",
                    "label": 0
                },
                {
                    "sent": "There's something in the outside world and the firing rate relates in a systematic way to the properties in the outside world and properties in the outside world could be my own movement, or could be where I'm in space, or what I'm seeing.",
                    "label": 0
                },
                {
                    "sent": "What I feel, anything yes.",
                    "label": 0
                },
                {
                    "sent": "I was wondering if this is XY location as opposed to perceptual perceptions, physical location?",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is.",
                    "label": 0
                },
                {
                    "sent": "This is exactly XY location, so so you literally put the lady onto the onto the rat, measure its XY position.",
                    "label": 0
                },
                {
                    "sent": "You ignore anything else, ignore which directions it's heading you ignore all the other aspects, but of course the exploit location is correlated with perception.",
                    "label": 0
                },
                {
                    "sent": "Again experiment where they were taken.",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                },
                {
                    "sent": "The damn cricket by producing the same perception from the different XY locations.",
                    "label": 0
                },
                {
                    "sent": "I mean is there.",
                    "label": 0
                },
                {
                    "sent": "They have they have done these things to you.",
                    "label": 0
                },
                {
                    "sent": "Make it you can make it so that you can rotate the box.",
                    "label": 0
                },
                {
                    "sent": "You leave the rest of the room the same.",
                    "label": 0
                },
                {
                    "sent": "You rotate the box.",
                    "label": 0
                },
                {
                    "sent": "European people have changed the form of the box and then said OK in some of these cells appear to be fixed to the corner so they they they only only active in the sudden con of the box.",
                    "label": 0
                },
                {
                    "sent": "So I mean there's this complicated effects.",
                    "label": 0
                },
                {
                    "sent": "Perception it is neither XY location, not perception if you.",
                    "label": 0
                },
                {
                    "sent": "Reception over alright?",
                    "label": 0
                },
                {
                    "sent": "Yeah, because it is driven by perception.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can turn off the light and it still it will.",
                    "label": 0
                },
                {
                    "sent": "Still you put the rexes someplace you turn off the light install.",
                    "label": 0
                },
                {
                    "sent": "It's still there so.",
                    "label": 0
                },
                {
                    "sent": "So all I want to say is is is there something complicated about it and that's that's unfortunately a little bit the option of that if you if you now take keep everything the same in one of these experiments and you change something else, say you keep the position of the same and you change the form of the box or something, you will often find that that also changes the activities.",
                    "label": 0
                },
                {
                    "sent": "So in many ways it looks like neurons are more complicated than suggested just by that.",
                    "label": 0
                },
                {
                    "sent": "And you can say in German place cells in the mist.",
                    "label": 0
                },
                {
                    "sent": "Makes this you get the feeling that it's my location.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the name of any cell is.",
                    "label": 0
                },
                {
                    "sent": "If you call motor cortex cells.",
                    "label": 0
                },
                {
                    "sent": "If you call them movement cells.",
                    "label": 0
                },
                {
                    "sent": "It's also missing Homer because you can change the stem.",
                    "label": 0
                },
                {
                    "sent": "You can keep the movement the same you change, you change other aspects of the tasks that you change the poster of the hand or something and you still get in again.",
                    "label": 0
                },
                {
                    "sent": "You get different activities and it's a huge debate.",
                    "label": 0
                },
                {
                    "sent": "Then what's the coordinate system?",
                    "label": 0
                },
                {
                    "sent": "Say it did.",
                    "label": 0
                },
                {
                    "sent": "Neurons in motor cortex care about?",
                    "label": 0
                },
                {
                    "sent": "Positions, velocities, acceleration, forces muscles many different properties.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "His a little more here.",
                    "label": 0
                },
                {
                    "sent": "These are recordings from humans.",
                    "label": 0
                },
                {
                    "sent": "Actually we don't quite remember the brain area, So what they did is there we caught it from.",
                    "label": 0
                },
                {
                    "sent": "From Yonce, while they showed lots of different pictures too.",
                    "label": 0
                },
                {
                    "sent": "To the subject participating there an IT it and so I think they used of the several 100 pictures there and they just measured how many spikes they would get out of this up and you can see here these are these are the images for which the neon was most active.",
                    "label": 0
                },
                {
                    "sent": "These are the images for which the neon was much less active.",
                    "label": 0
                },
                {
                    "sent": "It might be hard to see but this is.",
                    "label": 0
                },
                {
                    "sent": "I think this is John McCain.",
                    "label": 0
                },
                {
                    "sent": "Not many spikes.",
                    "label": 0
                },
                {
                    "sent": "He's getting all these stomach to be pictures of Holly Berberi an.",
                    "label": 0
                },
                {
                    "sent": "In fact, here's her name.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So if you show just the word print, it's the sellers very active and if you show her face it's very active.",
                    "label": 0
                },
                {
                    "sent": "If you show a drawing of hurts, very active and so So what that shows is that this new one seems to be related to that high level concept.",
                    "label": 0
                },
                {
                    "sent": "That person, regardless of the specific modality that is presented at.",
                    "label": 0
                },
                {
                    "sent": "This is this is human data actually, but it turns out that they've done similar things with monkeys, and if you have monkeys and they showed it and people people have monkeys watch TV often because monkeys just like a skateboard overtime and it turns out that for these monkeys to then also find related cells to the kinds of stimulated the monkeys are frequently exposed to.",
                    "label": 0
                },
                {
                    "sent": "So what's interesting of course about these neurons is that their invariant in an interesting way.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "They don't have simple properties in terms of brightness or in terms of, so it's hard to to describe this these cells.",
                    "label": 0
                },
                {
                    "sent": "They have really interesting properties and.",
                    "label": 0
                },
                {
                    "sent": "Yet it still following the same paradigm we we give a set of stimuli and we try to understand for which stimuli we get high activities infer which ones we get low activities.",
                    "label": 0
                },
                {
                    "sent": "Now I briefly want to mention the possibility of using Markov chain Monte Carlo for doing that kind of analysis, so, so here's the computational problem where we caught from Mignon.",
                    "label": 0
                },
                {
                    "sent": "We get the spikes out, but we always have in relatively small number of spikes, so at best will get a couple of 1000 of them and we might be interested in in tuning properties that have several dimensions.",
                    "label": 0
                },
                {
                    "sent": "Say if we talk about the preference of neurons to two bars, we can say well, once the.",
                    "label": 0
                },
                {
                    "sent": "One important aspect is the direction of it.",
                    "label": 0
                },
                {
                    "sent": "The other one is what's the position where they sell likes the stimulus to be the next one is what's the maximal firing rate you get out of it.",
                    "label": 0
                },
                {
                    "sent": "The next one is what's the minimal firing, right?",
                    "label": 0
                },
                {
                    "sent": "So these tuning curves and can unfold in at least medium size spaces, say dimension 456.",
                    "label": 0
                },
                {
                    "sent": "And given that you only have a certain number of spikes, this is actually a problem with significant uncertainty, so you can be sure what the properties of these cells are, and in fact in many in your science experiments, what do you want to know is here, I do.",
                    "label": 0
                },
                {
                    "sent": "I measure the tuning properties of herself, then I do some say I train my monkey and then I want to know have the properties of the neurons changed, and for that I need to get reasonable reasonable understanding of given the data that I have, how certain I can be about the properties of the tuning curves.",
                    "label": 0
                },
                {
                    "sent": "And this is where we can stay.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using Markov chain Monte Color, the technique so it's exactly the same thing that Tom was talking about in his in his tablets.",
                    "label": 0
                },
                {
                    "sent": "So imagine we we, we simplify matters, we just say we have the tuning width of a vision Jan, which is how precisely it's tuned to two stimuli, and on this axis we have the preferred orientation of the notes.",
                    "label": 0
                },
                {
                    "sent": "And if we do Markov chain Monte Carlo, what we do is we start at some place we initialize, then we have this bun in face where the Markov chain converges to the.",
                    "label": 0
                },
                {
                    "sent": "We're probably to distribution and then the system is exploring the space so so we start out here.",
                    "label": 0
                },
                {
                    "sent": "Then we proposed this and we accept it because it's close and overtime we get in here.",
                    "label": 0
                },
                {
                    "sent": "So so here here what you see as these lines, here are the ice of probability lights which we couldn't include.",
                    "label": 0
                },
                {
                    "sent": "Image this, we could actually captured them, and at any point of time the Markov chain will be at one place.",
                    "label": 0
                },
                {
                    "sent": "Here we simply use Gossen proposals here.",
                    "label": 0
                },
                {
                    "sent": "So we were moving to this space in rank.",
                    "label": 0
                },
                {
                    "sent": "You see the ones that were rejected in blue.",
                    "label": 0
                },
                {
                    "sent": "You see the ones that were accepted and you can say that that if the proposal goes outside of this range.",
                    "label": 0
                },
                {
                    "sent": "It tends to like it's much more likely that it's going to be rejected, but overtime as you keep sampling the dot or the distribution of samples you get in this space approximates the real probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Yes, so so something that's always puzzled me is that if you have a highly specific neuron, like Halle Berry in Europe, how on Earth did we ever found it?",
                    "label": 0
                },
                {
                    "sent": "And given that we have sometimes found neurons receive that specific, so that makes you suspect that.",
                    "label": 0
                },
                {
                    "sent": "They must be well, either there are lots of Halle Berry neurons in ones head because otherwise how come you flipped it fluently?",
                    "label": 0
                },
                {
                    "sent": "Found well, but more likely there an awful lot of neurons which respond to Halle Berry and a lot of other things.",
                    "label": 0
                },
                {
                    "sent": "And it's just that one didn't try any other didn't drop.",
                    "label": 0
                },
                {
                    "sent": "My can't explore the whole space, so I suppose I'm wondering what extent.",
                    "label": 0
                },
                {
                    "sent": "What was finding his sort of local minimum, but in fact the same neuron will will be responding to all kind again.",
                    "label": 0
                },
                {
                    "sent": "Yes, Sir, so this is a new one.",
                    "label": 0
                },
                {
                    "sent": "In the primary visual cortex, and it turns out that you can.",
                    "label": 0
                },
                {
                    "sent": "You can actually drive these now and say bye expectation of something which is certainly not in visual task.",
                    "label": 0
                },
                {
                    "sent": "Essentially Tele monkey.",
                    "label": 0
                },
                {
                    "sent": "Hey, that's gonna somethings gonna appear in your receptive field and then you run changes its properties.",
                    "label": 0
                },
                {
                    "sent": "There was, there's a nice paper by many gankers so about that and you can say primary visual cortex is the case where stuff is still most orderly because you have the wheel Walmart less feeding into it, and yet you still have.",
                    "label": 0
                },
                {
                    "sent": "Star projections from higher areas, but when we come to these areas where Holly Berry cells are being found, yeah, they probably wouldn't know they might.",
                    "label": 0
                },
                {
                    "sent": "It might actually be a bad actor cell or something.",
                    "label": 0
                },
                {
                    "sent": "It might be.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Sunsets just any regular.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that in this case you can still show 1000 pictures, and among those thousand pictures, those with Halle Berry on it had by far the most activity.",
                    "label": 0
                },
                {
                    "sent": "So people were effectively looking for a large number of different features that could be represented there.",
                    "label": 0
                },
                {
                    "sent": "But yeah, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's ultimately a big problem, because because fundamentally, in that you usually get about an hour's worth of data from from those electrophysiological experiments now.",
                    "label": 0
                },
                {
                    "sent": "In that time you can't do it.",
                    "label": 0
                },
                {
                    "sent": "You can't try nearly the breath of kind of the stimuli that are relevant in the world.",
                    "label": 0
                },
                {
                    "sent": "So in all likelihood many of these experiments are missing important features.",
                    "label": 0
                },
                {
                    "sent": "An in fact there is, at least when it comes to highly trained monkeys.",
                    "label": 0
                },
                {
                    "sent": "There's this general observation that in most areas, if you just look hard enough, and if you overtrain the monkeys to the monkey really does this task frequently.",
                    "label": 0
                },
                {
                    "sent": "You tend to find cells in many areas to tend to find cells that are related to the task that you're dealing with.",
                    "label": 0
                },
                {
                    "sent": "And I hope I'm doing justice to the part of neuroscience, but it's definitely a problem that unless you already know what the kind of what the right dimensions are for a brain area, you aren't going to find it and you might be finding other things that are just correlated with the things that you care about, and you'd never know.",
                    "label": 0
                },
                {
                    "sent": "But in any case, So what do you get with Markov chain Monte Carlo here is you get a distribution or you get a set of samples that are all drawn from the posterior probability of the tuning curve.",
                    "label": 0
                },
                {
                    "sent": "Properties of this cells.",
                    "label": 0
                },
                {
                    "sent": "Given the spikes that you have.",
                    "label": 0
                },
                {
                    "sent": "With this you can then, in a very constrained way, ask the question.",
                    "label": 0
                },
                {
                    "sent": "Say, does prefer tuning change between this experiment in that experiment?",
                    "label": 0
                },
                {
                    "sent": "And you can.",
                    "label": 0
                },
                {
                    "sent": "You can get our balance where you can then say so.",
                    "label": 0
                },
                {
                    "sent": "This was a simulated case in black.",
                    "label": 0
                },
                {
                    "sent": "You saw the true tuning curve of the cell in Gray.",
                    "label": 1
                },
                {
                    "sent": "It's very similar.",
                    "label": 0
                },
                {
                    "sent": "You take, you see the median of the of the samples.",
                    "label": 0
                },
                {
                    "sent": "So that's the that's the best estimate if you want of the tuning curve properties and then in red you see individual samples.",
                    "label": 0
                },
                {
                    "sent": "And of course there's a broad distribution.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now to the second part of the talk, which is going to be relatively short, which is about how neurons may represent uncertainty, and just as we've been talking a lot about uncertainty and Bayesian algorithms and so forth, the question is what do we know about how the nervous system represents uncertainty?",
                    "label": 0
                },
                {
                    "sent": "Ends we have a lot of theories of how the nervous system may represent uncertainty.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And let me talk about a few of them.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So imagine we have a tuning curve on this axis.",
                    "label": 0
                },
                {
                    "sent": "We say have the direction of a stimulus and on this axis we have defined weight of the neuron.",
                    "label": 0
                },
                {
                    "sent": "Instead we have two different conditions.",
                    "label": 0
                },
                {
                    "sent": "We have one case where we have low uncertainty.",
                    "label": 0
                },
                {
                    "sent": "You could say this is a high contrast stimulus, something where can be pretty certain that.",
                    "label": 0
                },
                {
                    "sent": "Where can be pretty certain that the bar has a sudden orientation, because just phone worser very high.",
                    "label": 0
                },
                {
                    "sent": "And then others, or like because it's very bright and it can perfectly see that another slow contrast.",
                    "label": 0
                },
                {
                    "sent": "We will have more certainty and the idea of that theory is that you will have more firing rate if your master and it turns out that if we assume that neurons have passed on firing, firing rates, rates, and we think we do optimal decoding of the neural activities, then in this case the.",
                    "label": 0
                },
                {
                    "sent": "We have higher firing rates and higher firing rates translates official information through lesson certainty about the properties of the stimulus.",
                    "label": 0
                },
                {
                    "sent": "That's up there, so this is 1 theory that people have proposed.",
                    "label": 0
                },
                {
                    "sent": "Wajima Alex Pushy have been working on that.",
                    "label": 0
                },
                {
                    "sent": "Then we could have the possibility that their separate populations, so we might have a population that encodes properties of stimuli and we might have a different set of neurons that encode the uncertainty that we have about those stimuli.",
                    "label": 0
                },
                {
                    "sent": "In this case, these neurons wouldn't care about the tuning curve, so it wouldn't have read tuning curves.",
                    "label": 0
                },
                {
                    "sent": "There would only fire, but uncertainty, solo uncertainty, low firing rate, high uncertainty, iPhone, right?",
                    "label": 1
                },
                {
                    "sent": "That's one possibility.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, it could be that the tuning the tuning curve changes and then will head which Samuel had proposed something along those lines where you can say if we have more uncertain than yours, then we find that neurons have broader tuning curves.",
                    "label": 0
                },
                {
                    "sent": "What that would mean for the population is that for a given stimulus.",
                    "label": 0
                },
                {
                    "sent": "There would be a broader set of neurons that are active.",
                    "label": 0
                },
                {
                    "sent": "All of them would be maybe less active, but you would have generally have monuments that are active in, so this distribution, the fact that so many neurons are involved with signal that we have higher in certainty.",
                    "label": 0
                },
                {
                    "sent": "So feed and have made a different proposal where she said, well, it could be that if we're more certain about something, the neurons might just tell us how much we should update the beliefs that we have there for the neurons is therefore, if we're in low uncertainty situation, then understood when we put on the stimulus force, be very active and then stop being active.",
                    "label": 0
                },
                {
                    "sent": "Whereas if we're man suddenly on should start being active and keep being active for longer period of time.",
                    "label": 0
                },
                {
                    "sent": "So you see this, there's no shortage of theories of how the nervous system could.",
                    "label": 0
                },
                {
                    "sent": "Implement and certainty.",
                    "label": 0
                },
                {
                    "sent": "Each of these has some level of support.",
                    "label": 0
                },
                {
                    "sent": "If you're or, here's another one which is.",
                    "label": 1
                },
                {
                    "sent": "Which which is it could effectively be the distribution of firing rate overtime that the signaling uncertainty.",
                    "label": 0
                },
                {
                    "sent": "This is this is a sampling idea where you could say imagine we have a low low low uncertainty situation and we have a new one, let's say encodes by its firing.",
                    "label": 0
                },
                {
                    "sent": "Wait where long or 1 dimensional axis something is.",
                    "label": 0
                },
                {
                    "sent": "If we're if we have low uncertainty than uncut fire very regularly and the firing rate, the instantaneous firing rate would tell me.",
                    "label": 1
                },
                {
                    "sent": "Each of each instantaneous family would be a sample from the distribution.",
                    "label": 0
                },
                {
                    "sent": "So if we are very certain that none would fire very regularly, and if we are very uncertain, sometimes don't fire very fast and then again, very slowly, and so on and so forth, so.",
                    "label": 0
                },
                {
                    "sent": "Should we have sampling so this is a very popular theory in your sense.",
                    "label": 0
                },
                {
                    "sent": "At the moment they had a big workshop on that at cosign, with some terms with people going there this is a very popular theory that Alex Posey had many very visible publications on it when it comes to data that we have about it.",
                    "label": 0
                },
                {
                    "sent": "It's not nearly that clear, and I should've cause.",
                    "label": 0
                },
                {
                    "sent": "Add one more thing, which is that there's Pretty Little reason why the brain should use a code that Conrad can understand how to go well, or that we could understand very well in general.",
                    "label": 0
                },
                {
                    "sent": "It could be that you could reach the same performance with codes that we can understand well, but there are nervous system has absolutely no evolutionary pressure to do us the favor to use an algorithm that we can easily read out.",
                    "label": 0
                },
                {
                    "sent": "So if you ask me, the probability that it uses in a pure form, any of these is.",
                    "label": 0
                },
                {
                    "sent": "Rather unlikely, unless unless there's a very simple, very powerful algorithm that is much more powerful than all the others.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just just two of these theories, I want to to talk a little bit more about it.",
                    "label": 0
                },
                {
                    "sent": "There's there's more of them.",
                    "label": 0
                },
                {
                    "sent": "I can't.",
                    "label": 0
                },
                {
                    "sent": "I can't focus on all of them, I just want to give you the gist of them.",
                    "label": 0
                },
                {
                    "sent": "So the first one is the idea of a distributed representation.",
                    "label": 1
                },
                {
                    "sent": "Imagine that we have different neurons here, color coded.",
                    "label": 0
                },
                {
                    "sent": "Each of them has a different preferred direction or different preferred properties, and we have then a distribution of of a space of the man that gives us along 1 axis of probability distribution or might have a different access whether Nuance covers a probability distribution like that if we combine them will get a distribution like that.",
                    "label": 1
                },
                {
                    "sent": "So what we need here is we need lots of neurons on this access.",
                    "label": 0
                },
                {
                    "sent": "We need lots of neurons of that access, so it requires many Indians.",
                    "label": 0
                },
                {
                    "sent": "And if we have a number of features at the same time, it might require something like exponential.",
                    "label": 0
                },
                {
                    "sent": "Numbers of neurons to represent things to represent multi dimensional probability distributions.",
                    "label": 0
                },
                {
                    "sent": "People argue that there may be tricks to make it more efficient.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another possibility would be by sampling, so here we have overtime.",
                    "label": 0
                },
                {
                    "sent": "The instantaneous firing rate of the neuron, sometimes high and low like this, and here instantaneous phone rate of the other neuron.",
                    "label": 0
                },
                {
                    "sent": "What is what is nice here is we need very few neurons to see here.",
                    "label": 0
                },
                {
                    "sent": "You just need to know answers before you needed this whole distribution along every axis.",
                    "label": 0
                },
                {
                    "sent": "But of course here if you want to know anything about the probability distribution, you need to wait until you've gotten enough samples.",
                    "label": 0
                },
                {
                    "sent": "So therefore it might be a very slow scheme.",
                    "label": 0
                },
                {
                    "sent": "So I want to stop talking about the representation of uncertainty here.",
                    "label": 0
                },
                {
                    "sent": "It's it's one of the most exciting topics in neuroscience at the moment, but the data that we have about it isn't particularly strong yet, and therefore I don't feel comfortable putting my head firmly into one of these into associate my or like strongly advance any of these five or six general schemes that we could have about it.",
                    "label": 0
                },
                {
                    "sent": "And there's probably different schemes that we could have that we didn't even think about.",
                    "label": 0
                },
                {
                    "sent": "So this spring.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Me to the third part, which I feel more comfortable about.",
                    "label": 0
                },
                {
                    "sent": "Which is the reverse engineering the way neurons intact the way we can think about a one way of conceptualizing the nervous systems that we can say well there's some new ones that we we caught from these nuns will interact with one another.",
                    "label": 1
                },
                {
                    "sent": "Of course there's lots and lots of other neurons that we don't.",
                    "label": 0
                },
                {
                    "sent": "We caught from that.",
                    "label": 0
                },
                {
                    "sent": "Interact with onions that we do.",
                    "label": 0
                },
                {
                    "sent": "We come from.",
                    "label": 0
                },
                {
                    "sent": "And of course these nuns can can give us trouble because say if I want to know if X interacts with if X interacts with twice.",
                    "label": 0
                },
                {
                    "sent": "If there's a causal link.",
                    "label": 0
                },
                {
                    "sent": "Tween X&Y, well, it's hard to know that because all these other neurons excite, both of them are affect both of them, and therefore it could be that, say this neuron at small latency excites this new on an at large latency excites this year.",
                    "label": 0
                },
                {
                    "sent": "It would look as if there's an actual causal relationship between them.",
                    "label": 0
                },
                {
                    "sent": "And yet, if you want, this is one of the most important questions in your side switches, how do neurons interact with one another?",
                    "label": 0
                },
                {
                    "sent": "There's something that we'd really like to know.",
                    "label": 0
                },
                {
                    "sent": "But we know that statistic is a little bit problematic.",
                    "label": 0
                },
                {
                    "sent": "So what we will do is we will largely ignore this problem, that this the other neurons out there get results and hope that the results that we get are still relevant.",
                    "label": 0
                },
                {
                    "sent": "And of course we can hope that overtime our algorithms will get better.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the reason why it's going to get better is if this continues growing very rapidly.",
                    "label": 0
                },
                {
                    "sent": "We will at least record from a higher and higher proportion of the neurons that ND serious.",
                    "label": 0
                },
                {
                    "sent": "We can only hope that that for some reason we can do reasonably well with a small number of neurons, But it turns out that we can actually quantify that.",
                    "label": 0
                },
                {
                    "sent": "We can say, well, how many neurons do we need to get a certain quality of understanding of what the neurons are doing.",
                    "label": 0
                },
                {
                    "sent": "So, so this thing means overtime will be getting will be getting better.",
                    "label": 0
                },
                {
                    "sent": "But the question is how good we can do at the moment and I'll first want to introduce a generative model for spikes.",
                    "label": 0
                },
                {
                    "sent": "I'll briefly talk about how to do inference on that.",
                    "label": 0
                },
                {
                    "sent": "Well then see how good it works in practice and we can then see if it already gives us good enough results that it's it was continuing along these lines.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the generative model of spikes.",
                    "label": 1
                },
                {
                    "sent": "Imagine each non I has associated with it and an underlying unobserved firing rate is called a conditional intensity function.",
                    "label": 0
                },
                {
                    "sent": "And let's say that this thing is that each of the neurons is affected by all of the other neurons and it's so this is this fast stuff from from one to N over all the neurons and there's an every neuron depends on the past.",
                    "label": 0
                },
                {
                    "sent": "So the phone weight of 1 neuron at one point of time depends on the spikes that it.",
                    "label": 0
                },
                {
                    "sent": "Please see in the past from all the other neurons an it depends.",
                    "label": 0
                },
                {
                    "sent": "So over temporal filter WI Delta T and it depends on the spikes that happened at T minus Delta tears that afternoon.",
                    "label": 0
                },
                {
                    "sent": "So this thing is linear here and we take the exponential function of that.",
                    "label": 0
                },
                {
                    "sent": "So this is now a nonlinear function and then we assume that the neurons firing is Apostle firing is Opossum process with this intensity function as is right?",
                    "label": 0
                },
                {
                    "sent": "You can think about it in different ways.",
                    "label": 0
                },
                {
                    "sent": "You can either think about it in terms of biology, where you can say, well, this is a little bit like the input current that you could be getting to a cell, where each of the other cells is producing potentials that change the membrane potential of this cell, and therefore this drives this drives firing.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, and in fact this this kind of a model has has the expressive power to deal with with many situations that we know from your sense of kind.",
                    "label": 0
                },
                {
                    "sent": "Regarding the index page, because in the left hand side of the problem you have my direct right hand side I used.",
                    "label": 0
                },
                {
                    "sent": "I just got a just a little late day.",
                    "label": 0
                },
                {
                    "sent": "This should have been a J here and this should have been a J here so J there as well.",
                    "label": 0
                },
                {
                    "sent": "Yes yeah babe do best timing.",
                    "label": 0
                },
                {
                    "sent": "I did that last night.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's it's the influence of death.",
                    "label": 0
                },
                {
                    "sent": "Neon is from all the other neurons, so that index here goes over all the other Neons West.",
                    "label": 0
                },
                {
                    "sent": "This is the neuron itself and this one depends on that neuron and all the other neurons.",
                    "label": 0
                },
                {
                    "sent": "So this one should have been IJ and this should have been J and this BSJ you have some do it thanks.",
                    "label": 0
                },
                {
                    "sent": "So, so this kind of a model has a lot of a lot of expressive power.",
                    "label": 0
                },
                {
                    "sent": "For example, it's known that neurons have refractory periods, which means that if a non fires right now there's a duration during which beyond just can't physically fire because it needs to recharge all the all the iron concentrations that it needs to fire again.",
                    "label": 0
                },
                {
                    "sent": "Now this this model can can immediately in very easily take care of that by simply making it so that the filter of the neuron onto itself.",
                    "label": 0
                },
                {
                    "sent": "At very shortly later is very negative.",
                    "label": 0
                },
                {
                    "sent": "It will just make it make this to clamp effectively, this time to be 0, and this is here.",
                    "label": 0
                },
                {
                    "sent": "You see data from a simulation there.",
                    "label": 0
                },
                {
                    "sent": "This is how it might look like if the neuron has fired.",
                    "label": 0
                },
                {
                    "sent": "There's a time during work.",
                    "label": 0
                },
                {
                    "sent": "At fastest.",
                    "label": 0
                },
                {
                    "sent": "It's very, very unlikely that it would fire, and overtime it recovers to some normal value.",
                    "label": 0
                },
                {
                    "sent": "And then there's of course Crosstown.",
                    "label": 0
                },
                {
                    "sent": "Say if one neuron fires, it might make the other neuron fire or tend to make the other non fire at some deley.",
                    "label": 0
                },
                {
                    "sent": "You can also do.",
                    "label": 0
                },
                {
                    "sent": "This model also has the expressive power to allow for Bostik, so it's known that there's many cells in the in the brain that have periods where the neuron fires a lot, and then parents with an honest silence.",
                    "label": 0
                },
                {
                    "sent": "So the new one will for a long time it won't fire at all, then it will go tick, tick, tick, tick, and then nothing again, and it will repeat that well.",
                    "label": 0
                },
                {
                    "sent": "In this case, if you have a filter that is fast negative for the refractory.",
                    "label": 0
                },
                {
                    "sent": "Then goes positive for while then goes back to 0, this naturally.",
                    "label": 0
                },
                {
                    "sent": "Can model the idea that neurons bust?",
                    "label": 0
                },
                {
                    "sent": "Because because if you sample them from such a generative model, the neon stuff makes itself fire after deley, and that produces bursting in.",
                    "label": 0
                },
                {
                    "sent": "If you ever want to get out of the bus again, and then if you go to the right hand side here it often is the negative again.",
                    "label": 0
                },
                {
                    "sent": "So it is so this model just intuitively can capture many of the aspects that we expect of reunions to be the case.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "Now, this is what this is.",
                    "label": 1
                },
                {
                    "sent": "The biological reason why we want to use something like that.",
                    "label": 0
                },
                {
                    "sent": "This is a very good computational reason why we used it, because it turns out that the optimization that you get if you want to do learning in that system is convex.",
                    "label": 0
                },
                {
                    "sent": "And because it's convex, we can very efficiently solve that.",
                    "label": 0
                },
                {
                    "sent": "Which is probably even more so.",
                    "label": 0
                },
                {
                    "sent": "The reason for choosing this model then all these reasons and so so we can do a maximum or posterior estimate of the weights very efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is nice about it is that this model supports what's called, explaining away in the typical data analysis methods in.",
                    "label": 0
                },
                {
                    "sent": "When it comes to functional connectivity analysis, don't have that property, so imagine we're in this situation with three neurons AB&C, and we caught from all these three neons and we look at the correlation between them.",
                    "label": 0
                },
                {
                    "sent": "In this case, we find because a is correlated with.",
                    "label": 0
                },
                {
                    "sent": "Here's what we see here.",
                    "label": 0
                },
                {
                    "sent": "The correlations A is kirbys correlated with C. So these are what we should expect.",
                    "label": 0
                },
                {
                    "sent": "Because it is also correlated to see because B&C are interacting with one another.",
                    "label": 0
                },
                {
                    "sent": "But then if you if you fit the such a functional connectivity model, you have explaining away a tons of that the interaction from B to C is sufficient to explain away the influence of A&C.",
                    "label": 0
                },
                {
                    "sent": "And if you do estimates with that, it will look like this.",
                    "label": 0
                },
                {
                    "sent": "So you really get out the right kind of connections.",
                    "label": 0
                },
                {
                    "sent": "Same thing if you have if you have a system like that where you have a which excites B&C, you have a correlation between B&C which is again explained away by that model.",
                    "label": 0
                },
                {
                    "sent": "So, so far everything we've done was on simulated neurons, an it it works beautiful and simulated neurons infected works still beautiful or like pretty good.",
                    "label": 0
                },
                {
                    "sent": "If we take simulated neurons and we add lots of simulated neurons that are totally that we don't record from, it still does a pretty good job.",
                    "label": 0
                },
                {
                    "sent": "And let's look at.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How the feds look like if we do that for reunions.",
                    "label": 0
                },
                {
                    "sent": "So here we see just a bunch of so.",
                    "label": 0
                },
                {
                    "sent": "So throughout the talk when I show real neurons, almost all of them are from our collaborator Nico Hatsopoulos, who has two greats of 100 electrodes each in primary motor cortex in premotor cortex.",
                    "label": 0
                },
                {
                    "sent": "They're both involved in the planning and execution of movement.",
                    "label": 0
                },
                {
                    "sent": "There so they use the pretty solid methods to find out which neuron is firing at which point of time, and it's generally something of the order of 118 yarns that are simultaneously recorded.",
                    "label": 0
                },
                {
                    "sent": "Now what you see now, let's look at the diagonal.",
                    "label": 0
                },
                {
                    "sent": "So the diagonal of the filters often Jan onto itself and what you see here is, and this this one is relatively typical here.",
                    "label": 0
                },
                {
                    "sent": "You see for that neon there is a refractory.",
                    "label": 0
                },
                {
                    "sent": "So at first it is very negative and then it goes up and it stays up.",
                    "label": 0
                },
                {
                    "sent": "So this is a new one that tends to once it gets into a mode of firing itself tends to continue firing.",
                    "label": 0
                },
                {
                    "sent": "And and here is, let's see what else.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Of course, there's exception to that.",
                    "label": 0
                },
                {
                    "sent": "Exceptions to that general scheme.",
                    "label": 0
                },
                {
                    "sent": "But this these neurons tend to bust a little bit, and you see that in the fault often you're not upon itself, and then you find that some neurons interact with some neurons.",
                    "label": 0
                },
                {
                    "sent": "Say this is the first one, with the third one.",
                    "label": 0
                },
                {
                    "sent": "Here in that grow, and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And you can say, well, should we.",
                    "label": 0
                },
                {
                    "sent": "What can we do with these with these folders?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a nice description of.",
                    "label": 0
                },
                {
                    "sent": "The spiking and we can test statistically how good to model it is for the spiking of the South, but but should we trust that measure at all?",
                    "label": 0
                },
                {
                    "sent": "And of course we can do cross validation with invite the training set into different parts.",
                    "label": 0
                },
                {
                    "sent": "We see how similar the functional connectivities are between them and they are very, very similar.",
                    "label": 0
                },
                {
                    "sent": "So if we repeated just twice, we essentially get the same result twice, so it is a solid measure.",
                    "label": 0
                },
                {
                    "sent": "We don't know for the moment what it means, yes.",
                    "label": 0
                },
                {
                    "sent": "Use for the interaction debates.",
                    "label": 0
                },
                {
                    "sent": "Very good question.",
                    "label": 0
                },
                {
                    "sent": "So there's two approaches that we've been using.",
                    "label": 0
                },
                {
                    "sent": "One of them is is is a price that we that we get from knowledge about the biology, which is primarily we assume that of all the connections that could exist, we have pretty good prior knowledge that most of them shouldn't exist, so it's a sparse prior over the existence of connections.",
                    "label": 0
                },
                {
                    "sent": "Of course, as fast prior over the existence of the connections is something that we couldn't computationally use.",
                    "label": 0
                },
                {
                    "sent": "Because we would need to go through extra it's exponential in the number of neurons that we have, not even worse exponential in the number of pairs of neurons that we have.",
                    "label": 0
                },
                {
                    "sent": "So that doesn't work by itself, but what we can do is we can put in our.",
                    "label": 0
                },
                {
                    "sent": "We can put an L1 prior onto the connection strength between yards.",
                    "label": 0
                },
                {
                    "sent": "So effectively we just put us past prior onto the connections between yards and we find we find that if we use double cross validation to get the values of that many of the connections go to zoo.",
                    "label": 0
                },
                {
                    "sent": "So that's the first thing from biology.",
                    "label": 0
                },
                {
                    "sent": "We also know that their smoothness.",
                    "label": 0
                },
                {
                    "sent": "So if an urn is exciting and other non, it is certainly less at 10 milliseconds then probably at 11 milliseconds the volume will be similar.",
                    "label": 0
                },
                {
                    "sent": "So you can say we have a smoothness problem.",
                    "label": 0
                },
                {
                    "sent": "We have a sparse and spry over connections.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that solving that this kind of ugly.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that you need to do if you do them in this case and you have a set of hyperparameters and.",
                    "label": 0
                },
                {
                    "sent": "And you have a partition function that's really, really ugly.",
                    "label": 0
                },
                {
                    "sent": "It works with this.",
                    "label": 0
                },
                {
                    "sent": "There's a paper TMSIE from last year where we've done it, but it turns out that you can get a lot of the mileage you get out of that very cheaply.",
                    "label": 0
                },
                {
                    "sent": "What you do is you represent the photos by basis functions.",
                    "label": 0
                },
                {
                    "sent": "We have some short once in some medium wants some long ones.",
                    "label": 0
                },
                {
                    "sent": "It's Pinsky and Pillow and others have been using that trick before.",
                    "label": 0
                },
                {
                    "sent": "And then you put a sparse prior over the individual coefficients of that.",
                    "label": 0
                },
                {
                    "sent": "The cool thing is you remade it remains a convex optimization problem and therefore again you can efficiently solve it and in the disadvantage you have vaulted to doing the full Bayesian estimate for the with the with the strong prices.",
                    "label": 0
                },
                {
                    "sent": "I mean it really doesn't cost you much.",
                    "label": 0
                },
                {
                    "sent": "Great question otherwise.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's let's talk about the slightly more general problem.",
                    "label": 0
                },
                {
                    "sent": "One second place.",
                    "label": 0
                },
                {
                    "sent": "So in the previous model we just set nouns interact with one another, but we can of course build hybrid models that have the aspects of tuning curve models and also the aspects of interaction models.",
                    "label": 0
                },
                {
                    "sent": "Where we can say that our conditional intensity function is affected.",
                    "label": 0
                },
                {
                    "sent": "And yeah, it's the same IJ problem here again, just just to prevent that.",
                    "label": 0
                },
                {
                    "sent": "But you can say there's external covariates, say the direction of movement of the monkey.",
                    "label": 0
                },
                {
                    "sent": "Or the visual stimulus property.",
                    "label": 0
                },
                {
                    "sent": "And so in this case we can give them Yana tuning curve to this time where where small V. Here are the other external properties and we can give it interactions with other neurons, and otherwise it's the same model and we can optimize it in the same way.",
                    "label": 0
                },
                {
                    "sent": "Sony owns I affected by their nonsense.",
                    "label": 0
                },
                {
                    "sent": "Also affected by the outside world.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For people who like graphical versions of that, here we have human or monkey move into different directions.",
                    "label": 0
                },
                {
                    "sent": "We have tuning curves, the tuning curves added to the tuning curves are linear weights of the past of what has happened to the other neurons and the neuron itself.",
                    "label": 0
                },
                {
                    "sent": "It's being added up together, that's a nonlinearity and then we have constant spiking on the output, so that's the generative model and.",
                    "label": 0
                },
                {
                    "sent": "What we wanted to know then is we don't know necessarily what our results, what our results mean, but we want to be able to compare this to a purchase, which is we could either model it with using only the way neurons interact with the outside world, or we could model it only using onions, interact with one another, and we want to see how good we are predicting your neural spikes based on these two extreme models.",
                    "label": 0
                },
                {
                    "sent": "And you can say if interaction models are better than models that are about tuning curves, we can already say that this way of modeling the brain is my use or or is at least better at making predictions.",
                    "label": 0
                },
                {
                    "sent": "And the other way of modeling.",
                    "label": 0
                },
                {
                    "sent": "And this is what you.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What you see here, what we did is we we took the 118 yards from our collaborator and we subsampled them so we randomly just talk say hundred of them or 10 or five.",
                    "label": 0
                },
                {
                    "sent": "We took subsets of them and then we tried how good we can predict firing rates based either on how they relate to the outside world, which is what you see in black here or how they would like to add onions.",
                    "label": 0
                },
                {
                    "sent": "And of course if we have a tuning curve model where we say we predict how many spikes we should get.",
                    "label": 0
                },
                {
                    "sent": "Based on the properties of, say, the direction of movement of the monkey, it doesn't matter how many neurons we have.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I should say on this axis is how many neurons we put into the system on this axis you have the cross validated log likelihood in bits per second.",
                    "label": 0
                },
                {
                    "sent": "This is just a measure of how good we are at predicting the spikes that we get out of the neurons, and so we get a certain quality of prediction if we use tuning curves, which is the standard approach that people use in your science.",
                    "label": 0
                },
                {
                    "sent": "And of course this doesn't.",
                    "label": 0
                },
                {
                    "sent": "Depend on the number of neurons that we record from another cause.",
                    "label": 0
                },
                {
                    "sent": "If we we cut from onions will be better predicting then if we were cut from funerals and he invent you see that the information we get appears to be growing linearly in this plot.",
                    "label": 0
                },
                {
                    "sent": "So this May in fact if we look at the crossover point, it happens at salty.",
                    "label": 0
                },
                {
                    "sent": "So this means as soon as we wake up from 13 yards or more, we're better predicting the spikes of another neuron based on the interactions of that non with the other neurons.",
                    "label": 0
                },
                {
                    "sent": "Then we are based on based on how that non relates to the outside world.",
                    "label": 0
                },
                {
                    "sent": "So you can say yeah, we're only recalling from a tiny proportion of all the neurons that are in the brain, but we already better than just viewing yarns in terms of how they relate to the outside world.",
                    "label": 0
                },
                {
                    "sent": "Now this is data from Moto Coptics and you might say well then maybe maybe there's something special about motorco ticks, maybe maybe it would be different in completely different areas, But it turns out it's very very similar.",
                    "label": 0
                },
                {
                    "sent": "So here's the same analysis for for primary visual cortex.",
                    "label": 0
                },
                {
                    "sent": "Again on this axis, the logarithm of the network size on this axis.",
                    "label": 0
                },
                {
                    "sent": "The information that we get pognon nicely grows linearly.",
                    "label": 0
                },
                {
                    "sent": "So now we have two data analysis algorithms.",
                    "label": 0
                },
                {
                    "sent": "One of them describes nouns in terms of what they mean about the outside.",
                    "label": 0
                },
                {
                    "sent": "What the other one describes nouns and how they relate to the firing of other neurons, and we find that that one of them scales as you see.",
                    "label": 0
                },
                {
                    "sent": "This is the information pognon.",
                    "label": 0
                },
                {
                    "sent": "And of course, if we have that, if we want to know the total information you need to multiply that with, then the number of neurons.",
                    "label": 0
                },
                {
                    "sent": "So here we have one algorithm that gives us oh of N, which is the black one here, and another algorithm which gives us of N lock N which is the connectivity model.",
                    "label": 0
                },
                {
                    "sent": "So this means it's scaling better, which is kind of useful because they could yet be other algorithms that would scale better.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's an algorithm that scales us over N squared and it turns out that this is actually very important, because if we can.",
                    "label": 0
                },
                {
                    "sent": "Because the scaling law is it's driven by this most law for the number of simultaneously recorded neurons.",
                    "label": 0
                },
                {
                    "sent": "It's really if we have algorithms that scale better, they're going to get arbitrarily better than the algorithms that scale was.",
                    "label": 0
                },
                {
                    "sent": "I also want to point out that, so here in the visual system that cut across over in fact happens at 10.",
                    "label": 0
                },
                {
                    "sent": "So you need relatively small numbers of neurons, and you're already better describing them in terms of what other neurons do.",
                    "label": 0
                },
                {
                    "sent": "And in some sense, at the moment this approach seems to be benefiting from this hope number two I I talked about in the beginning, which is it appears that we are doing reasonably well, although we only recover from some few neurons, and that is probably because there's many neurons that I'm doing relatively similar things in the nervous system, and therefore it might be that we are doing relatively good based on a small number of them.",
                    "label": 0
                },
                {
                    "sent": "So, but then the next thing we wanted to do is if we can already ask some scientifically interesting questions and one of them that I agree.",
                    "label": 0
                },
                {
                    "sent": "I very briefly I get this next slide this morning, just a couple of just a couple minutes before my talk.",
                    "label": 0
                },
                {
                    "sent": "One aspect that's been described in slices.",
                    "label": 0
                },
                {
                    "sent": "So you take you take a brain, you cut it into a small slab and you record from tournaments.",
                    "label": 0
                },
                {
                    "sent": "And it's been described that there's this effect called spike timing dependent plasticity.",
                    "label": 0
                },
                {
                    "sent": "What that means is if you have one neuron that fires and.",
                    "label": 0
                },
                {
                    "sent": "You have a sign access the connection between turnarounds, the presynaptic neuron fires, and then the postsynaptic neuron fires.",
                    "label": 0
                },
                {
                    "sent": "And if that happens within a short period of time, it turns out that the influence of the first nouns until the second gets to be stronger.",
                    "label": 0
                },
                {
                    "sent": "If you reverse the direction gets to be weaker.",
                    "label": 0
                },
                {
                    "sent": "So this is what's called spike timing dependent plasticity.",
                    "label": 0
                },
                {
                    "sent": "There's also heavy and learning if turning on Spike at the same time, the connection between them gets right.",
                    "label": 0
                },
                {
                    "sent": "Now what we wanted to say is to ask this.",
                    "label": 0
                },
                {
                    "sent": "Well, that's what's been done.",
                    "label": 0
                },
                {
                    "sent": "On single isolated cells, but if our algorithm start getting at something real, we should be able to see that in cortex for our large number of recordings, and one advantage that we have, there is of course if we were cut from churn with nuns we have 40,000 connections, which means that if we want to know properties of these connections, we can massively average of all the connections that are there and this is.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we did here?",
                    "label": 0
                },
                {
                    "sent": "So what used?",
                    "label": 0
                },
                {
                    "sent": "So we extended the model where we set the phone, wait on the influence of one another is a linear influence is linear overtime, but test, but there's a second term elearning time which says if we have a sudden event then this influence gets to be stronger or weaker.",
                    "label": 0
                },
                {
                    "sent": "So it's bilinear where we say the influence is a function of the actual weight which we first fit in the function of an interaction term that depends on how what neurons have done with one another.",
                    "label": 0
                },
                {
                    "sent": "On this axis you have the time delay between the pre and post synaptic neuron.",
                    "label": 0
                },
                {
                    "sent": "On this axis you have the multiplicative strength effect.",
                    "label": 1
                },
                {
                    "sent": "If that is happening, so this is how much stronger is the connection afterwards than it is before and what you see here.",
                    "label": 0
                },
                {
                    "sent": "Every single black dot is from one pair of neurons.",
                    "label": 0
                },
                {
                    "sent": "In blue you have the you have the means and standard errors of the means, and somehow there's a few points up here with.",
                    "label": 0
                },
                {
                    "sent": "It's just cut so that only that part is visible and you can see clearly the spike timing dependent plasticity effect here.",
                    "label": 1
                },
                {
                    "sent": "If the presynaptic neuron has fired fast and the strength strength get weaker if it's slightly afterwards, the strength gets the strength get weaker and in the end it has no effect at all and you can see it's not quite centered at 0, so it looks like it.",
                    "label": 0
                },
                {
                    "sent": "It's all positive.",
                    "label": 0
                },
                {
                    "sent": "This is probably just the heavy and learning effect, because both of them have been active at the same time, otherwise this wouldn't have even have been in the in the training set there.",
                    "label": 0
                },
                {
                    "sent": "So this means that that with these functional connectivity techniques we can start asking questions that people before would ask about pairs of neurons in in specific slice slice preparation.",
                    "label": 0
                },
                {
                    "sent": "So it appears that these techniques are nice way of starting to reverse engineer.",
                    "label": 0
                },
                {
                    "sent": "How the nervous system unfolds overtime.",
                    "label": 0
                },
                {
                    "sent": "OK, any questions?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good, so the next question that we then wanted to ask is well if we have fit in where we are fitting these models where we say the phone weight of the neuron depends on the outside world and it depends on the other neurons.",
                    "label": 0
                },
                {
                    "sent": "This could have the effect that the tuning cover bunion could change because we have explaining away.",
                    "label": 0
                },
                {
                    "sent": "So it might be that anyone isn't changed by itself, it's only tuned because it gets excited by other neurons that happened to be checked.",
                    "label": 0
                },
                {
                    "sent": "Of course in the limit, if you if we record from all neurons.",
                    "label": 0
                },
                {
                    "sent": "That's only two classes of nouns that have receptive field or tuning curves.",
                    "label": 0
                },
                {
                    "sent": "The retinal neurons care about visual stimuli and the movements care about muscle movement production.",
                    "label": 0
                },
                {
                    "sent": "No one else should have any tuning curves, but you can say, well, we don't know where we cut from this small number of neurons.",
                    "label": 0
                },
                {
                    "sent": "Maybe the tuning curves are still very, very important in this a quantitative question.",
                    "label": 1
                },
                {
                    "sent": "And it turns out that there's some neons for which the tuning curve doesn't change.",
                    "label": 0
                },
                {
                    "sent": "So here you have in Jan is a Phantom of the direction of the hand movement.",
                    "label": 0
                },
                {
                    "sent": "You have this spike.",
                    "label": 0
                },
                {
                    "sent": "Count an Inn in blue.",
                    "label": 0
                },
                {
                    "sent": "You have the full model where you where you have both an in rack.",
                    "label": 0
                },
                {
                    "sent": "You have the case where you only fit cosine tuning for the direction of movement, so in red you have the model that says there's only there's only tuning curves, and in this case it doesn't matter if you should listen on the tuning curve stays the same even if you incorporate all the all the all the rest.",
                    "label": 0
                },
                {
                    "sent": "Same thing for this more or less, but then there's many neurons for example this one.",
                    "label": 0
                },
                {
                    "sent": "That have very strong tuning curves.",
                    "label": 0
                },
                {
                    "sent": "If you analyze it in a traditional way, but if you consider the interactions as well, the tuning cover almost goes away and this is something that we find for a good number of the neurons.",
                    "label": 0
                },
                {
                    "sent": "Look here very strong, turning almost not tuning at all.",
                    "label": 0
                },
                {
                    "sent": "Same thing here.",
                    "label": 0
                },
                {
                    "sent": "So this means that for some reason and I don't quite understand that reason.",
                    "label": 0
                },
                {
                    "sent": "It's already at this small number of neurons that we have 200 that that it starts to look as if neurons have very very weak tuning curves by themselves, but they get most of their tuning by the interactions they have with other nodes.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I should say, I think that in this general, in this general approach, which is how can we understand how neurons relate to one another, there's many machine learning problems, many exciting algorithmic problems where you can say, well, we want to find structure.",
                    "label": 0
                },
                {
                    "sent": "So this in all likelihood there's certain classes of neurons that share certain properties.",
                    "label": 0
                },
                {
                    "sent": "At the moment, the generative model that I showed to you has no structure at all in this, and this is very important for neuroscience because they get all these neurons and all the interactions.",
                    "label": 0
                },
                {
                    "sent": "But they want to know, OK, are there certain subclasses of neurons that have certain properties?",
                    "label": 0
                },
                {
                    "sent": "So the question is then OK, can we find hierarchical generative models for spikes that allow us to understand what the different classes of notes are?",
                    "label": 0
                },
                {
                    "sent": "We want to use better priors.",
                    "label": 0
                },
                {
                    "sent": "We want to link that to cognitive phenomena and we want to reverse engineer learning rules and all kinds of questions that need to be asked about it.",
                    "label": 1
                },
                {
                    "sent": "In that ends my talk, I want to.",
                    "label": 0
                },
                {
                    "sent": "Of course I want to thank all the collaborators that I did this worth.",
                    "label": 0
                },
                {
                    "sent": "Nicely send US data that we could analyze and I want to thank you for listening.",
                    "label": 0
                }
            ]
        }
    }
}