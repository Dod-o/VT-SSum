{
    "id": "mcikapfro5pjafgciso6zmep27ztiwnz",
    "title": "Type Inference on Noisy RDF Data",
    "info": {
        "author": [
            "Heiko Paulheim, Institut f\u00fcr Informatik, University of Mannheim"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Information Theory",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2013_paulheim_rdf_data/",
    "segmentation": [
        [
            "Right, and this is joint work with my colleague Chris Pizza from Mannheim."
        ],
        [
            "OK, So what is the problem here that we tackled in this paper?",
            "One central promise of the semantic web?",
            "Why we're all here is like people said you have the web, and one day you will be able to issue structured queries for get answers for them.",
            "Like give me all the presidents that graduated from Harvard Law School.",
            "And what we do as semantic web people.",
            "We write down a sparkle query which we then execute against some endpoints, a DB pedia."
        ],
        [
            "And we get back a result.",
            "In that case we get one result from the pedia, which is, Albert Stephen alters a guy I never heard of until I prepared these slides to be honest.",
            "But yeah, this is the one result."
        ],
        [
            "Yet, but when we look in Wikipedia actually find out there is another guy I actually heard that name before who also graduated from Harvard Law School, and he actually is also a president, but we didn't get that result from our sparkle query, so."
        ],
        [
            "Um, what is going wrong here?",
            "Actually, something in this query must be there at cannot be cannot be found in our knowledge base, and surprisingly, it's not the fact that he graduated from Harvard Law School.",
            "It's actually the fact that he's not of type President Andy Pedia.",
            "So this type information is simply missing.",
            "So the goal of this paper is how can we add missing types automatically?",
            "How can we infer those missing types and knowledge bases?",
            "This is what we're trying to tackle."
        ],
        [
            "Is it a big problem?",
            "Yes it is.",
            "So we made some experiments with the pedia and there was actually at least 2.7 million missing type statements.",
            "And this is a very very pessimistic count.",
            "So actually it's probably quite higher.",
            "We found this by looking at Co.",
            "Occurrence analysis of matching classes in yoga and pedia.",
            "So for some classes in yoga and pedia we know they are the same and we assume that each instance then has to have both types.",
            "And there are instances that have the Jago type but not the corresponding DB pedia type.",
            "So this is.",
            "How we got to this estimates?",
            "So there's like half a million per instance.",
            "At least that are not of type person and 800,000 species that are not of type species.",
            "And as if seen in this Barack Obama example, this is not just hold for some very obscure instances actually.",
            "Also for very prominent instances, for example, Tom Hanks is not of type actor in DB Pedia.",
            "So it's actually not just the far off stuff that is missing.",
            "It's actually really the major stuff."
        ],
        [
            "Um?",
            "So what can we do?",
            "The basic thing you could come up with is to do some naive reasoning.",
            "So without DFS you could just say you have properties, state, means and ranges, and if you occur, if you encounter certain property for which you know the domain or the range you then add the corresponding type to the subject or the object.",
            "So this is what you could do."
        ],
        [
            "Try that in this Barack Obama case, you then can Additionally infer that Barack Obama is also a person function.",
            "An actor in an organization, I think actor is debatable.",
            "Organization and person function is probably both wrong.",
            "Just for fun, we did the same experiment with Germany.",
            "Here you can see that Germany is also an award, a city, a sports team amount in the stadium, record label and so on and so forth.",
            "My personal favorite is military conflict.",
            "I don't know what that tells us about how people see us, but yeah, so this is the stuff you get so you get lots and lots of wrong inferences.",
            "So this naive approach is probably not the way you want to go.",
            "If you want to attack that sort of problem."
        ],
        [
            "The underlying problem is on.",
            "This is pretty much the same as the problem that my previous speaker also tried to attack.",
            "We have the data that is underlying that is noisy, so there is wrong statement somewhere in the pedia and the problem here is that one single wrong statement is enough to get to run wrong.",
            "Conclusion, right?",
            "So we have one statement like somebody.",
            "Kurt H. Davis has an award Germany and since we know that the range of award is the class award, we infer that Germany is an award.",
            "And for those 20 wrong types, we just need twenty such wrong statements.",
            "And for Germany there is a total of almost 70,000 state instead of Germany as an object.",
            "So out of these 70,000 we only need 20s that are wrong, and this is a very very low rate, so we have an error.",
            "We would need an error rate of no more than 0.03% to come up with such totally screwed results.",
            "And actually we would be very happy if you had linked open data sources that have an error rate like that, but this is totally not feasible so.",
            "Yeah, we discounted that approach and try to come up with something different."
        ],
        [
            "Um?",
            "The idea is pretty much like the idea that you use when you do RDF's reasoning like you have these incoming and outgoing properties and they are indicators for resources type.",
            "So if you are an author of something that is an indicator that you are a writer basically.",
            "What we do is speak compiled some basic statistics.",
            "So if we observe a certain property outgoing or incoming, we look at the probability that this property, the instances that have this property, also have a certain type.",
            "So we compute the conditional probabilities.",
            "So for example, things that are starring something are 79% out of those are films and 44% out of those that have an incoming property of author.",
            "44% of these things are actually writers, so we first of all collect all these basic statistics.",
            "We have these statistics now for each property that is incoming or outgoing a certain resource."
        ],
        [
            "And now to compute scores for classes, we just average over all of them.",
            "So we look at the all the properties that are incoming outgoing a certain resource, and then we average the scores for each class and use these as an overall score for the objects.",
            "I'm sure this is probably from a probability theory point of view, something not so correct to do, but as we see as we will see later on it works and so I'm happy with that and I'm happy to violate all the theory of statistics here.",
            "We also introduced some more weights in order to account for skewed distributions in the knowledge base.",
            "So we waited these these conditional properties by the discriminative power that a certain property has.",
            "So the more the class distribution of a property deviates from the overall class distribution, the more discriminative power.",
            "This property hasn't, so we use this as weights in order to.",
            "Get come up with slightly more accurate scores."
        ],
        [
            "OK, and I said it works and I now have to give you the proof probably.",
            "So we did two experiments, one on DVD and Open Psych where we use the given types as sort of a silver standard.",
            "We have just seen it's not a gold standard, but we can try to reproduce that information and we did it in an automatic fashion on 10,000 random instances each of the out of DVD and OPENCYC, and the second experiment we performed we did on untyped pedia resources we picked 100 random untyped.",
            "The procedure resources to run our algorithm and then looked at how precise the predicted types were.",
            "One thing we did for these experiments that we only use the incoming properties but ignore the outgoing properties.",
            "The reason is if you use outgoing properties, the thing that's trivial in the pedia you have an infobox and the input box determines the outgoing properties and the type at the same time.",
            "So if we use the outgoing properties we would be treating actually and we would come up with nice results, but they would actually not be too true so we ignored them for the experiments here."
        ],
        [
            "This is how things look like on DB pedia.",
            "So this is the precision recall curve and you see it actually works out quite nicely.",
            "The curve gets very nicely to the upper right corner and you also see that the more links you have for for a resource the better it works so the lowest line is for the average of all resources and then the next two are resources that have at least 10 ingoing links and at least 25 ingoing links.",
            "And the more ingoing links the resource have the better it works.",
            "So this is just the opposite for to observe when you do the classic RDF's reasoning where you just accumulate all the errors so you have one statement that leads to an.",
            "Or another that needs to an error and you just collect all these errors on the way and then in the end return them all.",
            "And here actually the more information we have, the more we can eliminate the errors."
        ],
        [
            "This is the curve for opencyc and it doesn't look that nice, but with respect to time.",
            "I just know to be honest on opencyc it doesn't work that well because open site gives us a much harder problem at the pedia.",
            "We have very shallow class hierarchy that for example ends at a class called band and then Open Psych.",
            "We have punk rock bands and heavy metal bands and black metal bands and you name it and these are very difficult to tell apart.",
            "So we are very good at predicting the types that are.",
            "Very much up in the hierarchy, but if we have a very fine grade hirake it's very difficult to tell apart of punk rock band from a heavy metal band just looking at the incoming and outgoing properties this is this is the reason why it does not work that well on opencyc."
        ],
        [
            "This is the evaluation on untyped resources.",
            "As I said, we sampled 100 instances out of the pedia that do not have any type, and we let our algorithm run and then manually check the precision, so using different thresholds you can manage to have a precision of 95% for quite a long time, and you get like four to five types at precision level of 95%.",
            "If you do this for untyped resources."
        ],
        [
            "So just just a quick collection of the D results for DPD aware and F measure of nearly 90% on open side.",
            "We have this harder problem of 60% and the general takeaway here is that if you have more links with our approach to actually increase precision instead of just accumulating errors."
        ],
        [
            "OK, we also diploid this life Wendy PDF 3.9 was released a couple of weeks ago.",
            "So indeed PDF 3.9 after the extraction process had run, we collected all the untyped instances, and then we ran our algorithm and did the cut off at where we estimate the precision to be 95%, which is quite a good precision for DB pedia data.",
            "And with that cut off threshold, we were able to add more than 3 million you type statements to DB pedia.",
            "In the current release, what is interesting here is that this also includes results that do not have a Wikipedia page at all.",
            "So if you have an infobox that has a rattling, so a link to a Wikipedia page does not exist, you have a link to that Big Wikipedia page or more from other info boxes.",
            "So actually our algorithm is able to predict types for those, so the PDF 3.9 is the first time that the pedia includes information that is not included in Wikipedia.",
            "So the first time we are slightly ahead.",
            "I'm some words on runtime.",
            "The thing runs linear in the number of property assertions times the number of type assertions, which is not too bad, and on an average machine you can run this algorithm for the whole of DB pedia in about 24 hours.",
            "So it's actually feasible, and it does not take you like years to wait for it."
        ],
        [
            "OK. To wrap up, we have seen this algorithm works at high quality.",
            "There have been quite a few papers in the recent past that tried the same that try to predict types for DB pedia entities and it has been shown that since we have this this high F measure here in our experiments that this outperforms most of those state of the art tools that exist at the moment and redeploy that live 4D PDF 3.9.",
            "So the same approach.",
            "Now this was future work at the time when we wrote that paper.",
            "It is past work now, so the same approach can be used also to validate links.",
            "So you can also look at these statistical distributions to find out whether a link or a problem and property assertion makes sense or not.",
            "And we did this within DB Pedia and Wendy PDF 3.9 was created.",
            "We were also able to remove about 13,000 wrong statements that also a precision level of.",
            "Slightly above 95%, so we removed a lot of noise out of DB pedia.",
            "But we still want to try is to do the same set for links across datasets so using the same mechanism to validate for example, the link set between DB pedia and Freebase.",
            "To find out whether they are wrong links between these different knowledge bases."
        ],
        [
            "Yes, that's basically it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, and this is joint work with my colleague Chris Pizza from Mannheim.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what is the problem here that we tackled in this paper?",
                    "label": 0
                },
                {
                    "sent": "One central promise of the semantic web?",
                    "label": 1
                },
                {
                    "sent": "Why we're all here is like people said you have the web, and one day you will be able to issue structured queries for get answers for them.",
                    "label": 0
                },
                {
                    "sent": "Like give me all the presidents that graduated from Harvard Law School.",
                    "label": 1
                },
                {
                    "sent": "And what we do as semantic web people.",
                    "label": 0
                },
                {
                    "sent": "We write down a sparkle query which we then execute against some endpoints, a DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we get back a result.",
                    "label": 0
                },
                {
                    "sent": "In that case we get one result from the pedia, which is, Albert Stephen alters a guy I never heard of until I prepared these slides to be honest.",
                    "label": 1
                },
                {
                    "sent": "But yeah, this is the one result.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yet, but when we look in Wikipedia actually find out there is another guy I actually heard that name before who also graduated from Harvard Law School, and he actually is also a president, but we didn't get that result from our sparkle query, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, what is going wrong here?",
                    "label": 1
                },
                {
                    "sent": "Actually, something in this query must be there at cannot be cannot be found in our knowledge base, and surprisingly, it's not the fact that he graduated from Harvard Law School.",
                    "label": 1
                },
                {
                    "sent": "It's actually the fact that he's not of type President Andy Pedia.",
                    "label": 0
                },
                {
                    "sent": "So this type information is simply missing.",
                    "label": 0
                },
                {
                    "sent": "So the goal of this paper is how can we add missing types automatically?",
                    "label": 1
                },
                {
                    "sent": "How can we infer those missing types and knowledge bases?",
                    "label": 0
                },
                {
                    "sent": "This is what we're trying to tackle.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it a big problem?",
                    "label": 1
                },
                {
                    "sent": "Yes it is.",
                    "label": 0
                },
                {
                    "sent": "So we made some experiments with the pedia and there was actually at least 2.7 million missing type statements.",
                    "label": 1
                },
                {
                    "sent": "And this is a very very pessimistic count.",
                    "label": 0
                },
                {
                    "sent": "So actually it's probably quite higher.",
                    "label": 1
                },
                {
                    "sent": "We found this by looking at Co.",
                    "label": 0
                },
                {
                    "sent": "Occurrence analysis of matching classes in yoga and pedia.",
                    "label": 0
                },
                {
                    "sent": "So for some classes in yoga and pedia we know they are the same and we assume that each instance then has to have both types.",
                    "label": 0
                },
                {
                    "sent": "And there are instances that have the Jago type but not the corresponding DB pedia type.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "How we got to this estimates?",
                    "label": 0
                },
                {
                    "sent": "So there's like half a million per instance.",
                    "label": 0
                },
                {
                    "sent": "At least that are not of type person and 800,000 species that are not of type species.",
                    "label": 0
                },
                {
                    "sent": "And as if seen in this Barack Obama example, this is not just hold for some very obscure instances actually.",
                    "label": 0
                },
                {
                    "sent": "Also for very prominent instances, for example, Tom Hanks is not of type actor in DB Pedia.",
                    "label": 0
                },
                {
                    "sent": "So it's actually not just the far off stuff that is missing.",
                    "label": 0
                },
                {
                    "sent": "It's actually really the major stuff.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So what can we do?",
                    "label": 0
                },
                {
                    "sent": "The basic thing you could come up with is to do some naive reasoning.",
                    "label": 0
                },
                {
                    "sent": "So without DFS you could just say you have properties, state, means and ranges, and if you occur, if you encounter certain property for which you know the domain or the range you then add the corresponding type to the subject or the object.",
                    "label": 0
                },
                {
                    "sent": "So this is what you could do.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Try that in this Barack Obama case, you then can Additionally infer that Barack Obama is also a person function.",
                    "label": 0
                },
                {
                    "sent": "An actor in an organization, I think actor is debatable.",
                    "label": 0
                },
                {
                    "sent": "Organization and person function is probably both wrong.",
                    "label": 0
                },
                {
                    "sent": "Just for fun, we did the same experiment with Germany.",
                    "label": 1
                },
                {
                    "sent": "Here you can see that Germany is also an award, a city, a sports team amount in the stadium, record label and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "My personal favorite is military conflict.",
                    "label": 0
                },
                {
                    "sent": "I don't know what that tells us about how people see us, but yeah, so this is the stuff you get so you get lots and lots of wrong inferences.",
                    "label": 0
                },
                {
                    "sent": "So this naive approach is probably not the way you want to go.",
                    "label": 0
                },
                {
                    "sent": "If you want to attack that sort of problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The underlying problem is on.",
                    "label": 0
                },
                {
                    "sent": "This is pretty much the same as the problem that my previous speaker also tried to attack.",
                    "label": 0
                },
                {
                    "sent": "We have the data that is underlying that is noisy, so there is wrong statement somewhere in the pedia and the problem here is that one single wrong statement is enough to get to run wrong.",
                    "label": 1
                },
                {
                    "sent": "Conclusion, right?",
                    "label": 0
                },
                {
                    "sent": "So we have one statement like somebody.",
                    "label": 0
                },
                {
                    "sent": "Kurt H. Davis has an award Germany and since we know that the range of award is the class award, we infer that Germany is an award.",
                    "label": 0
                },
                {
                    "sent": "And for those 20 wrong types, we just need twenty such wrong statements.",
                    "label": 1
                },
                {
                    "sent": "And for Germany there is a total of almost 70,000 state instead of Germany as an object.",
                    "label": 0
                },
                {
                    "sent": "So out of these 70,000 we only need 20s that are wrong, and this is a very very low rate, so we have an error.",
                    "label": 0
                },
                {
                    "sent": "We would need an error rate of no more than 0.03% to come up with such totally screwed results.",
                    "label": 1
                },
                {
                    "sent": "And actually we would be very happy if you had linked open data sources that have an error rate like that, but this is totally not feasible so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we discounted that approach and try to come up with something different.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The idea is pretty much like the idea that you use when you do RDF's reasoning like you have these incoming and outgoing properties and they are indicators for resources type.",
                    "label": 1
                },
                {
                    "sent": "So if you are an author of something that is an indicator that you are a writer basically.",
                    "label": 0
                },
                {
                    "sent": "What we do is speak compiled some basic statistics.",
                    "label": 0
                },
                {
                    "sent": "So if we observe a certain property outgoing or incoming, we look at the probability that this property, the instances that have this property, also have a certain type.",
                    "label": 0
                },
                {
                    "sent": "So we compute the conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "So for example, things that are starring something are 79% out of those are films and 44% out of those that have an incoming property of author.",
                    "label": 0
                },
                {
                    "sent": "44% of these things are actually writers, so we first of all collect all these basic statistics.",
                    "label": 0
                },
                {
                    "sent": "We have these statistics now for each property that is incoming or outgoing a certain resource.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now to compute scores for classes, we just average over all of them.",
                    "label": 0
                },
                {
                    "sent": "So we look at the all the properties that are incoming outgoing a certain resource, and then we average the scores for each class and use these as an overall score for the objects.",
                    "label": 0
                },
                {
                    "sent": "I'm sure this is probably from a probability theory point of view, something not so correct to do, but as we see as we will see later on it works and so I'm happy with that and I'm happy to violate all the theory of statistics here.",
                    "label": 0
                },
                {
                    "sent": "We also introduced some more weights in order to account for skewed distributions in the knowledge base.",
                    "label": 0
                },
                {
                    "sent": "So we waited these these conditional properties by the discriminative power that a certain property has.",
                    "label": 0
                },
                {
                    "sent": "So the more the class distribution of a property deviates from the overall class distribution, the more discriminative power.",
                    "label": 1
                },
                {
                    "sent": "This property hasn't, so we use this as weights in order to.",
                    "label": 0
                },
                {
                    "sent": "Get come up with slightly more accurate scores.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and I said it works and I now have to give you the proof probably.",
                    "label": 0
                },
                {
                    "sent": "So we did two experiments, one on DVD and Open Psych where we use the given types as sort of a silver standard.",
                    "label": 0
                },
                {
                    "sent": "We have just seen it's not a gold standard, but we can try to reproduce that information and we did it in an automatic fashion on 10,000 random instances each of the out of DVD and OPENCYC, and the second experiment we performed we did on untyped pedia resources we picked 100 random untyped.",
                    "label": 1
                },
                {
                    "sent": "The procedure resources to run our algorithm and then looked at how precise the predicted types were.",
                    "label": 1
                },
                {
                    "sent": "One thing we did for these experiments that we only use the incoming properties but ignore the outgoing properties.",
                    "label": 0
                },
                {
                    "sent": "The reason is if you use outgoing properties, the thing that's trivial in the pedia you have an infobox and the input box determines the outgoing properties and the type at the same time.",
                    "label": 0
                },
                {
                    "sent": "So if we use the outgoing properties we would be treating actually and we would come up with nice results, but they would actually not be too true so we ignored them for the experiments here.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is how things look like on DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So this is the precision recall curve and you see it actually works out quite nicely.",
                    "label": 0
                },
                {
                    "sent": "The curve gets very nicely to the upper right corner and you also see that the more links you have for for a resource the better it works so the lowest line is for the average of all resources and then the next two are resources that have at least 10 ingoing links and at least 25 ingoing links.",
                    "label": 0
                },
                {
                    "sent": "And the more ingoing links the resource have the better it works.",
                    "label": 0
                },
                {
                    "sent": "So this is just the opposite for to observe when you do the classic RDF's reasoning where you just accumulate all the errors so you have one statement that leads to an.",
                    "label": 0
                },
                {
                    "sent": "Or another that needs to an error and you just collect all these errors on the way and then in the end return them all.",
                    "label": 0
                },
                {
                    "sent": "And here actually the more information we have, the more we can eliminate the errors.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the curve for opencyc and it doesn't look that nice, but with respect to time.",
                    "label": 0
                },
                {
                    "sent": "I just know to be honest on opencyc it doesn't work that well because open site gives us a much harder problem at the pedia.",
                    "label": 0
                },
                {
                    "sent": "We have very shallow class hierarchy that for example ends at a class called band and then Open Psych.",
                    "label": 0
                },
                {
                    "sent": "We have punk rock bands and heavy metal bands and black metal bands and you name it and these are very difficult to tell apart.",
                    "label": 0
                },
                {
                    "sent": "So we are very good at predicting the types that are.",
                    "label": 0
                },
                {
                    "sent": "Very much up in the hierarchy, but if we have a very fine grade hirake it's very difficult to tell apart of punk rock band from a heavy metal band just looking at the incoming and outgoing properties this is this is the reason why it does not work that well on opencyc.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the evaluation on untyped resources.",
                    "label": 1
                },
                {
                    "sent": "As I said, we sampled 100 instances out of the pedia that do not have any type, and we let our algorithm run and then manually check the precision, so using different thresholds you can manage to have a precision of 95% for quite a long time, and you get like four to five types at precision level of 95%.",
                    "label": 1
                },
                {
                    "sent": "If you do this for untyped resources.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just just a quick collection of the D results for DPD aware and F measure of nearly 90% on open side.",
                    "label": 0
                },
                {
                    "sent": "We have this harder problem of 60% and the general takeaway here is that if you have more links with our approach to actually increase precision instead of just accumulating errors.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, we also diploid this life Wendy PDF 3.9 was released a couple of weeks ago.",
                    "label": 0
                },
                {
                    "sent": "So indeed PDF 3.9 after the extraction process had run, we collected all the untyped instances, and then we ran our algorithm and did the cut off at where we estimate the precision to be 95%, which is quite a good precision for DB pedia data.",
                    "label": 0
                },
                {
                    "sent": "And with that cut off threshold, we were able to add more than 3 million you type statements to DB pedia.",
                    "label": 0
                },
                {
                    "sent": "In the current release, what is interesting here is that this also includes results that do not have a Wikipedia page at all.",
                    "label": 1
                },
                {
                    "sent": "So if you have an infobox that has a rattling, so a link to a Wikipedia page does not exist, you have a link to that Big Wikipedia page or more from other info boxes.",
                    "label": 0
                },
                {
                    "sent": "So actually our algorithm is able to predict types for those, so the PDF 3.9 is the first time that the pedia includes information that is not included in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So the first time we are slightly ahead.",
                    "label": 0
                },
                {
                    "sent": "I'm some words on runtime.",
                    "label": 0
                },
                {
                    "sent": "The thing runs linear in the number of property assertions times the number of type assertions, which is not too bad, and on an average machine you can run this algorithm for the whole of DB pedia in about 24 hours.",
                    "label": 1
                },
                {
                    "sent": "So it's actually feasible, and it does not take you like years to wait for it.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. To wrap up, we have seen this algorithm works at high quality.",
                    "label": 1
                },
                {
                    "sent": "There have been quite a few papers in the recent past that tried the same that try to predict types for DB pedia entities and it has been shown that since we have this this high F measure here in our experiments that this outperforms most of those state of the art tools that exist at the moment and redeploy that live 4D PDF 3.9.",
                    "label": 0
                },
                {
                    "sent": "So the same approach.",
                    "label": 0
                },
                {
                    "sent": "Now this was future work at the time when we wrote that paper.",
                    "label": 0
                },
                {
                    "sent": "It is past work now, so the same approach can be used also to validate links.",
                    "label": 1
                },
                {
                    "sent": "So you can also look at these statistical distributions to find out whether a link or a problem and property assertion makes sense or not.",
                    "label": 1
                },
                {
                    "sent": "And we did this within DB Pedia and Wendy PDF 3.9 was created.",
                    "label": 0
                },
                {
                    "sent": "We were also able to remove about 13,000 wrong statements that also a precision level of.",
                    "label": 0
                },
                {
                    "sent": "Slightly above 95%, so we removed a lot of noise out of DB pedia.",
                    "label": 0
                },
                {
                    "sent": "But we still want to try is to do the same set for links across datasets so using the same mechanism to validate for example, the link set between DB pedia and Freebase.",
                    "label": 0
                },
                {
                    "sent": "To find out whether they are wrong links between these different knowledge bases.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, that's basically it.",
                    "label": 0
                }
            ]
        }
    }
}