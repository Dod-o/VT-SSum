{
    "id": "xfr64fpekbljanbqmr24koeyjh4j3ln3",
    "title": "Experiment Databases for Machine Learning / BenchMarking Via Weka",
    "info": {
        "author": [
            "Peter Reutemann, Department of Computer Science, University of Waikato"
        ],
        "published": "Dec. 20, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mloss08_reutemann_edml/",
    "segmentation": [
        [
            "OK um."
        ],
        [
            "Now.",
            "I assume that a few of you here in the room probably already written a few papers in machine learning, and by the time you actually finish your experiments in you put the results into a paper.",
            "What do you put into the paper?",
            "Is more or less an executive summary, and all the details that you had for experiments like pre processing, random seats and all that kind of stuff basically gets lost now is really interested in.",
            "But the problem is if you're trying to reproduce.",
            "Results from a paper where new algorithm has been described as a real pain is coming up with the same numbers that they actually came up in their paper so.",
            "If you really want to share experiments in order for people to reproduce a result, it's necessary to come up with a common description, language, and language which supposed to capture all the details of the experiments were kind of datasets were loading what kind of preprocessing parameters you did and what kind of evaluations and whatever.",
            "So XML, the experiment markup language thing Cloud based dialect is kind of like first attempt to do that, so.",
            "Whenever you run the experiment, you can create next Mail for how we actually ran the experiment.",
            "Now when you produce all those experiment XML files, you can also store that relational information that you have in those XML files in the relational database and can then query it via SQL and do all kinds of funky evaluations on their one an.",
            "Using that stored data from past experiments can save you a lot of time.",
            "You don't have to re run experiments, and you can also do some nice method learning theoretic."
        ],
        [
            "On top of that, now what do we actually want to share experiments?",
            "Well, in good signs results should be reproducible.",
            "There has been in the scientific community lightly a few frauds this being uncovered, which is probably happening in the machine learning community as well.",
            "But who knows?",
            "So if you're able to reproduce results in a paper perfect Now, if.",
            "People produce those XML files.",
            "They will be eventually able to find them, whether it's via Google or specialized service search engine doesn't matter, but they will actually come across previous experiments and see I don't need to rerun all of that, it's already there, and by combining all those experiments kind of like in a map of known approaches you have not only the positive results which normally end up in the paper.",
            "But you also have all the negative results.",
            "All the approaches didn't really work, in which they probably 95%, maybe even a higher number, and you don't really have to try that anymore because somebody tried and said net doesn't work.",
            "So this will for example also save you time.",
            "And if you can just use the results from such experiments, you don't have to rerun everything and just sort of like if you've developed a new algorithm.",
            "Just run tests on that new algorithm and that's it.",
            "And if you have all those.",
            "Experiments in a big big database.",
            "You can also then on top of that do some meta learning or just have in general larger and more generalizable studies in hand."
        ],
        [
            "Now I'm going to give a quick rundown on XML.",
            "The experiment markup language.",
            "And how that's supposed?",
            "To help with the whole approach to repeatability.",
            "First thing is.",
            "A lot of stuff in XML has to be defined.",
            "What kind of?",
            "Type of algorithm you are using.",
            "What specific versions has where you can download it and all the parameters defined and this is for example a simple base learner.",
            "Ordeneaux Sambol learner doesn't.",
            "Isn't regression schemas in classifier all that kind of stuff needs to be defined before you can actually validate against Sikhs melski."
        ],
        [
            "MA.",
            "This class.",
            "Java specific or as far as I know, it's currently heavily based on workers, so.",
            "I'm just presenting it so I guess it's just the first attempt offline.",
            "I think.",
            "I mean, for example, IP version is fine.",
            "Is for example a major release and the version here is for example at CVS.",
            "Tag or revision number.",
            "So the idea is sometimes you have a major release, but you might actually have sort of like bug fixing it, so you never really sure even if you have a release version is really that release or what's the particular version of that algorithm, because sometimes people after they published a paper, the finite loops there was a little bug in there and then changes everything, so it's actually quite an important information in it.",
            "But really it's only a first approach at the whole issue there now.",
            "If you want to run an experiment, you have more or less three parts you have basically algorithm here with specific options and you're running.",
            "You have what kind of data set you're using, for example.",
            "Also what kind of pre processing into did?",
            "For example here is remove percentage and stuff.",
            "It's also important we can download that data set.",
            "Most of the datasets are kind of like never published anywhere.",
            "They just said, yeah, we use that particular data set, but nobody can really reproduce those numbers.",
            "And finally, what kind of evaluation that you were running on?",
            "For example here it's using cross validation method of Wicker with a certain random seed and one with ten folds now.",
            "Conditions that are more difficult to reproduce, like the architecture of the machine that was used, potentially have effects on the random numbers they chose.",
            "Well, you oops.",
            "Hello sorry wrong.",
            "The."
        ],
        [
            "Actually, it's kind of like a meta tag about your environment that you can put in there, so at the moment it's just machine 14, but theoretically could put in the operating system that you've been running in.",
            "For example, what kind of Java version and all that kind of stuff, so that will provide some additional information on what machine that was run also.",
            "And evaluating, for example runtime, that would give you some kind of feedback how quick that really is, or whether you have a benchmark system.",
            "We can have a relative speed variable then.",
            "The doesn't answer the question."
        ],
        [
            "OK, now.",
            "In order to store the actual output of an experiment, you have kind of like.",
            "Summarizing metrics like root, mean squared error accuracy that stuff for classification.",
            "For example a confusion matrix an then also for each of the rows in your test data you have then.",
            "What the classifier or what the scheme returns of like fall for classification problem you would have kind of like the class distribution for Grayson Stream.",
            "Just look like aggression output.",
            "So basically store everything in there.",
            "A lot of information so that you can really dig into details.",
            "So what's the output and so on."
        ],
        [
            "OK.",
            "Since it's only a short overview of that experiment databases, this is a plot that I generated earlier this week and I was interested in.",
            "Using the web interface.",
            "Show me all the classifiers and all the different setups and have been running the latter, UCI data set and show me the accuracy.",
            "So on the right hand side you basically see zero.",
            "It's kind of like the baselines, just predicting the the majority class.",
            "And here on the left hand side you have smol, bagging, random forest and so on.",
            "As you can see with different setups you can achieve achieve rather bad accuracy or actually scoring quite high now.",
            "If you want to do some meta learning so you produce some kind of properties for a data set, for example letter, what kind of attributes enhance what kind of distribution these attributes have?",
            "All kinds of statistics, and you then when you get a new unknown data set, you just look for a data set that has similar properties and then you just say OK, give me all the classifier setups that actually work good on datasets with those properties and instead of searching once again for classifier server that works well.",
            "On that particular data set, you can base just narrow down the search and say hey just give me the top 10 and we'll see how that goes and we still going to improve.",
            "Maybe a little bit on those.",
            "OK um."
        ],
        [
            "In order to make the whole thing work.",
            "You should of course integrate the whole thing.",
            "For example, experimentation tools.",
            "If an experiment is already out there, done, rerun it, just skip it in data mining, machine learning tool benches like for example Waco are.",
            "You could automatically generate those XML files and share them.",
            "Publishing web server, upload them even into a database.",
            "Or if you have data mining assistance tools, if the user gets a new data set just look just what I explained earlier.",
            "Just look for a data set with similar properties and.",
            "Let the user then choose kind of like from a limited choice of setups and make the work a bit quicker and can also run the whole stuff than in grids and for example, the Pub Chem database.",
            "The molecule database, alot of data mining has been performed there, but nobody really knows what really happened there because the exact pre processings and so on, nobody really actually put out there.",
            "And finally don't ask me exactly what inductive databases.",
            "But it's a step beyond as far as I understand that from SQL, and we can actually query for model properties who came?",
            "Now."
        ],
        [
            "Is that an thank you?",
            "Um?",
            "Cool, in my case I'm moving."
        ],
        [
            "On to my actual talk about benchmarking via worker."
        ],
        [
            "Not sure whether everybody is familiar with Echo, so worker stands for the white cat environment.",
            "For knowledge analysis, it's machine learning Workbench completely written in Java and the hard worker you could say is the work experiment and we can test certain classifier setups on certain datasets and then compare them.",
            "Whether one setup is significantly better or worse compared to another one and.",
            "This is.",
            "Well, most people then using their publications."
        ],
        [
            "Um?",
            "Right, so the benefit of Waco was it was really easy plugging in new classifiers, filters and so on.",
            "The whole frame was already there.",
            "It was really limited what the researcher had to do to add a new classifier.",
            "It is also nice framework if you want to statistically evaluate or compare your classifiers, and it's also relatively easy to reproduce.",
            "Experiments have been run with weaker but.",
            "As I said before, it's written in Java.",
            "You don't have any Python support really added.",
            "Some giant and support some time ago, but you can't really use any Numpy, Scipy, and so on with it, so it's really limited to Java and the biggest problem was also whenever you had to create a new Piper, you always had to re run experiments on all the UCI datasets against the comparison on it, so there's no real benchmarks publicly available that you can use now.",
            "The motivation for developing benchmarking benchmarking framework was.",
            "So if like move away from this Java central framework an.",
            "But as social be kind of like a fairly easy framework for other people to extend and add stuff to it, but still kind of like have a central statistical evaluation framework and also kind of like have your experiments easy to reproduce."
        ],
        [
            "So the benchmarking via wrecker framework or short BMW is no longer stand alone application by the client server architecture.",
            "And since the client and the server are communicating via XML, they are no longer limited to Java by itself.",
            "But you can also use Python or any other programming language can understand XML and what the clients and basically do is they obtain data from the server they build their scheme.",
            "For example worker classifier.",
            "And then send back the predictions and on the server side those predictions get evaluated and those results and get stored.",
            "So as you can see here, server stores basically all datasets, experiments and so on and on the client side you can have different clients so far implement Java and Python client and I have wrappers for example for work on mlpy there and."
        ],
        [
            "So.",
            "In order to reproduce experiments, since the datasets need to be uploaded to the server, there pop basically publicly available.",
            "Anybody can play around with those and single experiment that you run in that framework is uniquely identified by the type of evaluation that you're running.",
            "For example, cross validation leave one out, percentage split or whatever, and the scheme set up, which is busy on the general.",
            "For example, the class name.",
            "All the parameters that you using and the particular version of that scheme and finally the data set, which also has a name and version.",
            "Sometimes there are different versions out there of the same data set because some different preprocessing happens, so you want to keep track of what particular version of the data set you are using, and since everything is basically evaluated centrally on the server.",
            "Like generating the training set, generating the test set, and just sending that stuff to the client, and then again after getting back all those.",
            "Statistics are predictions back and the statistics are then evaluated or generated on the server.",
            "The client really doesn't have to worry about anything about any evaluations.",
            "Happens all nicely centrally on the server, and there's also not much faking then going on theoretically."
        ],
        [
            "That's a screenshot of the Java client, so you can either have command line client or a good client both for Java and Python And I was just similar again, so once again you have your datasets that you're testing on and you have in the columns in your different classifiers.",
            "In that case was to regression schemes that just was using for that particular screenshot.",
            "Some waka classifiers like caution process in SVM, Rick, and.",
            "You can also do other bits and pieces with that, like sample, doing rankings on certain datasets.",
            "What schemes perform best and so on."
        ],
        [
            "And finally concluding.",
            "I personally think that it's a step towards straightforward experiment, reproducible, or at least one step, not maybe finally getting there, but it definitely makes it easier.",
            "Having a framework like that that you can evaluate across different languages and across different.",
            "Other like machine learning frameworks like which animal pie?",
            "So it's no longer like Wicca centric, no longer Java centric and with that framework not yet implemented, but still relatively easy to add would be the output of the experiment markup language files so it could be automatically shared online and also for example having a separate experiment database server running, we automatically upload those results to and people can just query that online while web interface."
        ],
        [
            "And.",
            "That would be it then for me.",
            "Thank you very much.",
            "So any specific questions or generally just open discussion?",
            "Is this server client architecture really means that you are on the server and I just installed the client and send it back to themselves or what the whole thing can be hierarchical as well so that theoretically can be one serve at Waikato University can be one in Berlin that serve 1 four year research Group and you have a personal one, so you can basically retrieve experiments from all those different servers, but you can store locally own experiments and theoretically.",
            "It's only early prototypes, so theoretically you would be also able to submit your datasets and your results, and ideally you would also want people to submit the actual code and store that basically with the experiment itself that other people cannot only download the data set, view the results, but also automatically reproduce it by running with their own code, but.",
            "That's a bit further into the future.",
            "It was like and still yeah yeah I mean.",
            "No, but you could.",
            "The thing is you can have public available repositories and you can just awful.",
            "I still do your own thing and so and if you think I would picture nice.",
            "I just talked to you guys and what about submitting that thing and.",
            "Will be an idea.",
            "Yes.",
            "I'm not sure things will change things, but one of the difficulties with that wasn't necessarily the best huge data set, and it did take awhile sometimes.",
            "Things client server architecture in this sort of scaled it or business?",
            "Well, there's definitely some overhead, kind of like, for example, if you're running 10 runs of 10 fold cross validation, there's a lot of communication going on, but as soon as you work with larger datasets.",
            "If all the model buildings happening on this client side, so the server doesn't have to do anything with it, and since it's multithreaded, you just if you have a 16 core machine, well, then use 16 cores into all the things, sort of like sort of like on the fly.",
            "If you're running experiments, for example on 20 data sets times 10 classifiers, they can basically run all in parallel on your client, so you don't have to worry about that, so there was a bit trying to eliminate.",
            "The limitation of worker that you really have to run that in one single core all the time, which was quite annoying.",
            "Even though you could actually parallelize some of it at least.",
            "Speak again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK um.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "I assume that a few of you here in the room probably already written a few papers in machine learning, and by the time you actually finish your experiments in you put the results into a paper.",
                    "label": 0
                },
                {
                    "sent": "What do you put into the paper?",
                    "label": 0
                },
                {
                    "sent": "Is more or less an executive summary, and all the details that you had for experiments like pre processing, random seats and all that kind of stuff basically gets lost now is really interested in.",
                    "label": 0
                },
                {
                    "sent": "But the problem is if you're trying to reproduce.",
                    "label": 0
                },
                {
                    "sent": "Results from a paper where new algorithm has been described as a real pain is coming up with the same numbers that they actually came up in their paper so.",
                    "label": 0
                },
                {
                    "sent": "If you really want to share experiments in order for people to reproduce a result, it's necessary to come up with a common description, language, and language which supposed to capture all the details of the experiments were kind of datasets were loading what kind of preprocessing parameters you did and what kind of evaluations and whatever.",
                    "label": 1
                },
                {
                    "sent": "So XML, the experiment markup language thing Cloud based dialect is kind of like first attempt to do that, so.",
                    "label": 0
                },
                {
                    "sent": "Whenever you run the experiment, you can create next Mail for how we actually ran the experiment.",
                    "label": 0
                },
                {
                    "sent": "Now when you produce all those experiment XML files, you can also store that relational information that you have in those XML files in the relational database and can then query it via SQL and do all kinds of funky evaluations on their one an.",
                    "label": 0
                },
                {
                    "sent": "Using that stored data from past experiments can save you a lot of time.",
                    "label": 1
                },
                {
                    "sent": "You don't have to re run experiments, and you can also do some nice method learning theoretic.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On top of that, now what do we actually want to share experiments?",
                    "label": 0
                },
                {
                    "sent": "Well, in good signs results should be reproducible.",
                    "label": 0
                },
                {
                    "sent": "There has been in the scientific community lightly a few frauds this being uncovered, which is probably happening in the machine learning community as well.",
                    "label": 0
                },
                {
                    "sent": "But who knows?",
                    "label": 0
                },
                {
                    "sent": "So if you're able to reproduce results in a paper perfect Now, if.",
                    "label": 0
                },
                {
                    "sent": "People produce those XML files.",
                    "label": 0
                },
                {
                    "sent": "They will be eventually able to find them, whether it's via Google or specialized service search engine doesn't matter, but they will actually come across previous experiments and see I don't need to rerun all of that, it's already there, and by combining all those experiments kind of like in a map of known approaches you have not only the positive results which normally end up in the paper.",
                    "label": 1
                },
                {
                    "sent": "But you also have all the negative results.",
                    "label": 0
                },
                {
                    "sent": "All the approaches didn't really work, in which they probably 95%, maybe even a higher number, and you don't really have to try that anymore because somebody tried and said net doesn't work.",
                    "label": 0
                },
                {
                    "sent": "So this will for example also save you time.",
                    "label": 0
                },
                {
                    "sent": "And if you can just use the results from such experiments, you don't have to rerun everything and just sort of like if you've developed a new algorithm.",
                    "label": 0
                },
                {
                    "sent": "Just run tests on that new algorithm and that's it.",
                    "label": 0
                },
                {
                    "sent": "And if you have all those.",
                    "label": 1
                },
                {
                    "sent": "Experiments in a big big database.",
                    "label": 1
                },
                {
                    "sent": "You can also then on top of that do some meta learning or just have in general larger and more generalizable studies in hand.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'm going to give a quick rundown on XML.",
                    "label": 0
                },
                {
                    "sent": "The experiment markup language.",
                    "label": 0
                },
                {
                    "sent": "And how that's supposed?",
                    "label": 0
                },
                {
                    "sent": "To help with the whole approach to repeatability.",
                    "label": 0
                },
                {
                    "sent": "First thing is.",
                    "label": 0
                },
                {
                    "sent": "A lot of stuff in XML has to be defined.",
                    "label": 0
                },
                {
                    "sent": "What kind of?",
                    "label": 0
                },
                {
                    "sent": "Type of algorithm you are using.",
                    "label": 0
                },
                {
                    "sent": "What specific versions has where you can download it and all the parameters defined and this is for example a simple base learner.",
                    "label": 0
                },
                {
                    "sent": "Ordeneaux Sambol learner doesn't.",
                    "label": 0
                },
                {
                    "sent": "Isn't regression schemas in classifier all that kind of stuff needs to be defined before you can actually validate against Sikhs melski.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "MA.",
                    "label": 0
                },
                {
                    "sent": "This class.",
                    "label": 0
                },
                {
                    "sent": "Java specific or as far as I know, it's currently heavily based on workers, so.",
                    "label": 0
                },
                {
                    "sent": "I'm just presenting it so I guess it's just the first attempt offline.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "I mean, for example, IP version is fine.",
                    "label": 0
                },
                {
                    "sent": "Is for example a major release and the version here is for example at CVS.",
                    "label": 0
                },
                {
                    "sent": "Tag or revision number.",
                    "label": 0
                },
                {
                    "sent": "So the idea is sometimes you have a major release, but you might actually have sort of like bug fixing it, so you never really sure even if you have a release version is really that release or what's the particular version of that algorithm, because sometimes people after they published a paper, the finite loops there was a little bug in there and then changes everything, so it's actually quite an important information in it.",
                    "label": 0
                },
                {
                    "sent": "But really it's only a first approach at the whole issue there now.",
                    "label": 0
                },
                {
                    "sent": "If you want to run an experiment, you have more or less three parts you have basically algorithm here with specific options and you're running.",
                    "label": 0
                },
                {
                    "sent": "You have what kind of data set you're using, for example.",
                    "label": 0
                },
                {
                    "sent": "Also what kind of pre processing into did?",
                    "label": 0
                },
                {
                    "sent": "For example here is remove percentage and stuff.",
                    "label": 0
                },
                {
                    "sent": "It's also important we can download that data set.",
                    "label": 0
                },
                {
                    "sent": "Most of the datasets are kind of like never published anywhere.",
                    "label": 0
                },
                {
                    "sent": "They just said, yeah, we use that particular data set, but nobody can really reproduce those numbers.",
                    "label": 0
                },
                {
                    "sent": "And finally, what kind of evaluation that you were running on?",
                    "label": 0
                },
                {
                    "sent": "For example here it's using cross validation method of Wicker with a certain random seed and one with ten folds now.",
                    "label": 0
                },
                {
                    "sent": "Conditions that are more difficult to reproduce, like the architecture of the machine that was used, potentially have effects on the random numbers they chose.",
                    "label": 0
                },
                {
                    "sent": "Well, you oops.",
                    "label": 0
                },
                {
                    "sent": "Hello sorry wrong.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, it's kind of like a meta tag about your environment that you can put in there, so at the moment it's just machine 14, but theoretically could put in the operating system that you've been running in.",
                    "label": 0
                },
                {
                    "sent": "For example, what kind of Java version and all that kind of stuff, so that will provide some additional information on what machine that was run also.",
                    "label": 0
                },
                {
                    "sent": "And evaluating, for example runtime, that would give you some kind of feedback how quick that really is, or whether you have a benchmark system.",
                    "label": 0
                },
                {
                    "sent": "We can have a relative speed variable then.",
                    "label": 0
                },
                {
                    "sent": "The doesn't answer the question.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "In order to store the actual output of an experiment, you have kind of like.",
                    "label": 0
                },
                {
                    "sent": "Summarizing metrics like root, mean squared error accuracy that stuff for classification.",
                    "label": 0
                },
                {
                    "sent": "For example a confusion matrix an then also for each of the rows in your test data you have then.",
                    "label": 0
                },
                {
                    "sent": "What the classifier or what the scheme returns of like fall for classification problem you would have kind of like the class distribution for Grayson Stream.",
                    "label": 0
                },
                {
                    "sent": "Just look like aggression output.",
                    "label": 0
                },
                {
                    "sent": "So basically store everything in there.",
                    "label": 0
                },
                {
                    "sent": "A lot of information so that you can really dig into details.",
                    "label": 0
                },
                {
                    "sent": "So what's the output and so on.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Since it's only a short overview of that experiment databases, this is a plot that I generated earlier this week and I was interested in.",
                    "label": 0
                },
                {
                    "sent": "Using the web interface.",
                    "label": 0
                },
                {
                    "sent": "Show me all the classifiers and all the different setups and have been running the latter, UCI data set and show me the accuracy.",
                    "label": 0
                },
                {
                    "sent": "So on the right hand side you basically see zero.",
                    "label": 0
                },
                {
                    "sent": "It's kind of like the baselines, just predicting the the majority class.",
                    "label": 0
                },
                {
                    "sent": "And here on the left hand side you have smol, bagging, random forest and so on.",
                    "label": 0
                },
                {
                    "sent": "As you can see with different setups you can achieve achieve rather bad accuracy or actually scoring quite high now.",
                    "label": 0
                },
                {
                    "sent": "If you want to do some meta learning so you produce some kind of properties for a data set, for example letter, what kind of attributes enhance what kind of distribution these attributes have?",
                    "label": 0
                },
                {
                    "sent": "All kinds of statistics, and you then when you get a new unknown data set, you just look for a data set that has similar properties and then you just say OK, give me all the classifier setups that actually work good on datasets with those properties and instead of searching once again for classifier server that works well.",
                    "label": 0
                },
                {
                    "sent": "On that particular data set, you can base just narrow down the search and say hey just give me the top 10 and we'll see how that goes and we still going to improve.",
                    "label": 0
                },
                {
                    "sent": "Maybe a little bit on those.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to make the whole thing work.",
                    "label": 0
                },
                {
                    "sent": "You should of course integrate the whole thing.",
                    "label": 0
                },
                {
                    "sent": "For example, experimentation tools.",
                    "label": 0
                },
                {
                    "sent": "If an experiment is already out there, done, rerun it, just skip it in data mining, machine learning tool benches like for example Waco are.",
                    "label": 0
                },
                {
                    "sent": "You could automatically generate those XML files and share them.",
                    "label": 0
                },
                {
                    "sent": "Publishing web server, upload them even into a database.",
                    "label": 0
                },
                {
                    "sent": "Or if you have data mining assistance tools, if the user gets a new data set just look just what I explained earlier.",
                    "label": 1
                },
                {
                    "sent": "Just look for a data set with similar properties and.",
                    "label": 0
                },
                {
                    "sent": "Let the user then choose kind of like from a limited choice of setups and make the work a bit quicker and can also run the whole stuff than in grids and for example, the Pub Chem database.",
                    "label": 0
                },
                {
                    "sent": "The molecule database, alot of data mining has been performed there, but nobody really knows what really happened there because the exact pre processings and so on, nobody really actually put out there.",
                    "label": 1
                },
                {
                    "sent": "And finally don't ask me exactly what inductive databases.",
                    "label": 1
                },
                {
                    "sent": "But it's a step beyond as far as I understand that from SQL, and we can actually query for model properties who came?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that an thank you?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Cool, in my case I'm moving.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On to my actual talk about benchmarking via worker.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not sure whether everybody is familiar with Echo, so worker stands for the white cat environment.",
                    "label": 0
                },
                {
                    "sent": "For knowledge analysis, it's machine learning Workbench completely written in Java and the hard worker you could say is the work experiment and we can test certain classifier setups on certain datasets and then compare them.",
                    "label": 0
                },
                {
                    "sent": "Whether one setup is significantly better or worse compared to another one and.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "Well, most people then using their publications.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right, so the benefit of Waco was it was really easy plugging in new classifiers, filters and so on.",
                    "label": 0
                },
                {
                    "sent": "The whole frame was already there.",
                    "label": 0
                },
                {
                    "sent": "It was really limited what the researcher had to do to add a new classifier.",
                    "label": 0
                },
                {
                    "sent": "It is also nice framework if you want to statistically evaluate or compare your classifiers, and it's also relatively easy to reproduce.",
                    "label": 0
                },
                {
                    "sent": "Experiments have been run with weaker but.",
                    "label": 0
                },
                {
                    "sent": "As I said before, it's written in Java.",
                    "label": 0
                },
                {
                    "sent": "You don't have any Python support really added.",
                    "label": 0
                },
                {
                    "sent": "Some giant and support some time ago, but you can't really use any Numpy, Scipy, and so on with it, so it's really limited to Java and the biggest problem was also whenever you had to create a new Piper, you always had to re run experiments on all the UCI datasets against the comparison on it, so there's no real benchmarks publicly available that you can use now.",
                    "label": 0
                },
                {
                    "sent": "The motivation for developing benchmarking benchmarking framework was.",
                    "label": 0
                },
                {
                    "sent": "So if like move away from this Java central framework an.",
                    "label": 0
                },
                {
                    "sent": "But as social be kind of like a fairly easy framework for other people to extend and add stuff to it, but still kind of like have a central statistical evaluation framework and also kind of like have your experiments easy to reproduce.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the benchmarking via wrecker framework or short BMW is no longer stand alone application by the client server architecture.",
                    "label": 0
                },
                {
                    "sent": "And since the client and the server are communicating via XML, they are no longer limited to Java by itself.",
                    "label": 0
                },
                {
                    "sent": "But you can also use Python or any other programming language can understand XML and what the clients and basically do is they obtain data from the server they build their scheme.",
                    "label": 0
                },
                {
                    "sent": "For example worker classifier.",
                    "label": 0
                },
                {
                    "sent": "And then send back the predictions and on the server side those predictions get evaluated and those results and get stored.",
                    "label": 0
                },
                {
                    "sent": "So as you can see here, server stores basically all datasets, experiments and so on and on the client side you can have different clients so far implement Java and Python client and I have wrappers for example for work on mlpy there and.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In order to reproduce experiments, since the datasets need to be uploaded to the server, there pop basically publicly available.",
                    "label": 0
                },
                {
                    "sent": "Anybody can play around with those and single experiment that you run in that framework is uniquely identified by the type of evaluation that you're running.",
                    "label": 0
                },
                {
                    "sent": "For example, cross validation leave one out, percentage split or whatever, and the scheme set up, which is busy on the general.",
                    "label": 0
                },
                {
                    "sent": "For example, the class name.",
                    "label": 0
                },
                {
                    "sent": "All the parameters that you using and the particular version of that scheme and finally the data set, which also has a name and version.",
                    "label": 0
                },
                {
                    "sent": "Sometimes there are different versions out there of the same data set because some different preprocessing happens, so you want to keep track of what particular version of the data set you are using, and since everything is basically evaluated centrally on the server.",
                    "label": 0
                },
                {
                    "sent": "Like generating the training set, generating the test set, and just sending that stuff to the client, and then again after getting back all those.",
                    "label": 0
                },
                {
                    "sent": "Statistics are predictions back and the statistics are then evaluated or generated on the server.",
                    "label": 0
                },
                {
                    "sent": "The client really doesn't have to worry about anything about any evaluations.",
                    "label": 0
                },
                {
                    "sent": "Happens all nicely centrally on the server, and there's also not much faking then going on theoretically.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's a screenshot of the Java client, so you can either have command line client or a good client both for Java and Python And I was just similar again, so once again you have your datasets that you're testing on and you have in the columns in your different classifiers.",
                    "label": 0
                },
                {
                    "sent": "In that case was to regression schemes that just was using for that particular screenshot.",
                    "label": 0
                },
                {
                    "sent": "Some waka classifiers like caution process in SVM, Rick, and.",
                    "label": 0
                },
                {
                    "sent": "You can also do other bits and pieces with that, like sample, doing rankings on certain datasets.",
                    "label": 0
                },
                {
                    "sent": "What schemes perform best and so on.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally concluding.",
                    "label": 0
                },
                {
                    "sent": "I personally think that it's a step towards straightforward experiment, reproducible, or at least one step, not maybe finally getting there, but it definitely makes it easier.",
                    "label": 0
                },
                {
                    "sent": "Having a framework like that that you can evaluate across different languages and across different.",
                    "label": 0
                },
                {
                    "sent": "Other like machine learning frameworks like which animal pie?",
                    "label": 0
                },
                {
                    "sent": "So it's no longer like Wicca centric, no longer Java centric and with that framework not yet implemented, but still relatively easy to add would be the output of the experiment markup language files so it could be automatically shared online and also for example having a separate experiment database server running, we automatically upload those results to and people can just query that online while web interface.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "That would be it then for me.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So any specific questions or generally just open discussion?",
                    "label": 0
                },
                {
                    "sent": "Is this server client architecture really means that you are on the server and I just installed the client and send it back to themselves or what the whole thing can be hierarchical as well so that theoretically can be one serve at Waikato University can be one in Berlin that serve 1 four year research Group and you have a personal one, so you can basically retrieve experiments from all those different servers, but you can store locally own experiments and theoretically.",
                    "label": 0
                },
                {
                    "sent": "It's only early prototypes, so theoretically you would be also able to submit your datasets and your results, and ideally you would also want people to submit the actual code and store that basically with the experiment itself that other people cannot only download the data set, view the results, but also automatically reproduce it by running with their own code, but.",
                    "label": 0
                },
                {
                    "sent": "That's a bit further into the future.",
                    "label": 0
                },
                {
                    "sent": "It was like and still yeah yeah I mean.",
                    "label": 0
                },
                {
                    "sent": "No, but you could.",
                    "label": 0
                },
                {
                    "sent": "The thing is you can have public available repositories and you can just awful.",
                    "label": 0
                },
                {
                    "sent": "I still do your own thing and so and if you think I would picture nice.",
                    "label": 0
                },
                {
                    "sent": "I just talked to you guys and what about submitting that thing and.",
                    "label": 0
                },
                {
                    "sent": "Will be an idea.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure things will change things, but one of the difficulties with that wasn't necessarily the best huge data set, and it did take awhile sometimes.",
                    "label": 0
                },
                {
                    "sent": "Things client server architecture in this sort of scaled it or business?",
                    "label": 0
                },
                {
                    "sent": "Well, there's definitely some overhead, kind of like, for example, if you're running 10 runs of 10 fold cross validation, there's a lot of communication going on, but as soon as you work with larger datasets.",
                    "label": 0
                },
                {
                    "sent": "If all the model buildings happening on this client side, so the server doesn't have to do anything with it, and since it's multithreaded, you just if you have a 16 core machine, well, then use 16 cores into all the things, sort of like sort of like on the fly.",
                    "label": 0
                },
                {
                    "sent": "If you're running experiments, for example on 20 data sets times 10 classifiers, they can basically run all in parallel on your client, so you don't have to worry about that, so there was a bit trying to eliminate.",
                    "label": 0
                },
                {
                    "sent": "The limitation of worker that you really have to run that in one single core all the time, which was quite annoying.",
                    "label": 0
                },
                {
                    "sent": "Even though you could actually parallelize some of it at least.",
                    "label": 0
                },
                {
                    "sent": "Speak again.",
                    "label": 0
                }
            ]
        }
    }
}