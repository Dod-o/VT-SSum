{
    "id": "5q3myadcplh5evu3yrzopkl4ns7khf34",
    "title": "Introduction to CNNs",
    "info": {
        "author": [
            "Richard Zemel, Department of Computer Science, University of Toronto"
        ],
        "published": "July 27, 2017",
        "recorded": "June 2017",
        "category": [
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning"
        ]
    },
    "url": "http://videolectures.net/deeplearning2017_zemel_introduction_cnn/",
    "segmentation": [
        [
            "So, as Aaron mentioned, I'm the director of the new Vector Institute, and so I thought I would use this as an opportunity to tell you the first couple of slides, not about convolution networks, but about vector.",
            "And then we'll get back the convolution networks."
        ],
        [
            "So vectors independent, independent nonprofit Institute located in the Mars Discovery District.",
            "It's a nice big building.",
            "And in Toronto, and it's a fairly new venture, it actually started up just at the end of the summer.",
            "We had discussions with some guys from a local startup company, the Chief Technical Executive officers there, and they got funding in January and launch just at the end of March.",
            "So it's very new.",
            "And the focus of it is on machine learning, research and practice.",
            "So people.",
            "Oh let's try.",
            "There's two mikes.",
            "Let me see the other ones.",
            "OK, yeah.",
            "Turn this one on to that one is fine.",
            "OK alright good perfect alright so?",
            "It's on, so it's actually called the Vector Institute for Artificial Intelligence, but we just call it the Vector Institute.",
            "It's really the name vector comes from the notion that vectors are really important in the kind of work that we do in machine learning.",
            "As you've heard with lots more about vectors and actually one of the original names that we considered for it.",
            "Folks know about the Perimeter Institute, which is the Institute for Theoretical Physics in Waterloo.",
            "So we're going to call it the parameter Institute.",
            "But then we like the idea of vector, so that's our name for it, and so it's all kinds of machine learning research, ranging from theoretical to practical or well."
        ],
        [
            "Compare and these are the people affiliated with it.",
            "Currently we have mostly faculty members who are at the University of Toronto, Jeff Hinton's, the Chief Scientific Advisor, and I'm the research director and then we have a lot of new hires in Toronto as well, including these three down here.",
            "Margier Marotte in young Anne Graham.",
            "Taylor from Guelph is also affiliated with it, so it's not just a UFT venture, but it's in general universities in Ontario or affiliated with it."
        ],
        [
            "Ann were hiring, so I thought take this opportunity to a shameless plug.",
            "With a lot of very smart people here, I'm sure so would be great to consider coming as postdocs or research scientists to vector it's brand new.",
            "This is this is what it looks like down here, so we're going to move in in October and hopefully look a lot better than that.",
            "So if you're interested, you can visit Vector Institute dot AI, email that email us, or also tonight there's a special event.",
            "There's a Toronto night at 6:00 o'clock.",
            "I think it is.",
            "Somewhere off site you can get more, or you probably have more information in your in your booklet, and that's with a group from Toronto, including not just vector but CDL, which is like an accelerator RBC an next day.",
            "I OK enough one."
        ],
        [
            "Here, let's talk about convolution networks.",
            "So I was told as that should really give an introduction to convolution networks.",
            "I'm sure some people here know them very well.",
            "I assume some people don't, so I'm going to do a fairly quick summary of that and spend the first maybe half an hour talking about convolutional networks in recent developments in convolutional networks, and then a little bit of a discussion of what's actually being learned.",
            "I think that's an interesting direction that people are following now as well.",
            "And then I'm going to finish up talking about applications and I'm focusing on the applications that I'm I've been interested in for many years, including things like semantic segmentation, image understanding, an few shot, learning.",
            "Oak."
        ],
        [
            "OK, and I'm going to in general talk about convolution networks in the context of vision and object recognition, just because that's been one of the traditional focuses of the research in that area.",
            "But there's tons of other applications, notably in speech and text, but it's more fun to talk about vision for a talk 'cause I can show pretty pictures.",
            "OK, so we're going to talk about vision.",
            "And to start with, we can say, well, people are really good at recognizing shapes.",
            "It's a really hard problem.",
            "It turns out and computers are bad at it.",
            "At least they have been for years.",
            "We're getting better at it with computers and the."
        ],
        [
            "That is, why is it hard?",
            "So here are some of the things that make vision object recognition shape recognition hard.",
            "You have occlusion, you have issues of scale deformations of the shape.",
            "The shapes often exist in cluttered environments, changing of lighting and the pose of the objects and viewpoint.",
            "All these things make object recognition shape recognition quite difficult.",
            "So these are kind of natural conditions.",
            "And then there's a question of definition right?",
            "What is an object?",
            "And so this is a good exam."
        ],
        [
            "Couple of that right?",
            "So these would all be what we call chairs, but what makes a chair a chair is a fundamental question, right?",
            "And so I think people learn that in a natural way, right?",
            "That we figure out.",
            "Well, there's a shape question, but there's also this idea of utility, right?",
            "So somewhere we can park our butt and sit on naturally is called a chair.",
            "So I think that figuring out what that means is an interesting question that we're getting better at.",
            "Again, getting computers are better at that, but it's a very hard natural problem."
        ],
        [
            "And is also tons of classes, so cycle psychologist named Earth Biederman identified 10,000 to 30,000 different object classes that exist in some natural sense of what an object classes and there's.",
            "So there's tons of them, and we're good at those.",
            "And we're also going to talk about at the end of today is how we learn about new classes."
        ],
        [
            "And we're very good at dealing with invariances things like translation, rotation, scaling.",
            "Some things I was showing before about deformation, contrast, and lighting.",
            "That, but it's really hard to appreciate just how hard it is and how good we are at it.",
            "OK, so we don't really have a good way of dealing with a lot."
        ],
        [
            "These things, so let's talk about applying neural Nets to images.",
            "So you can just do a straightforward application and people did this for years where you would just take an input containing lots of pixels and build a neural network that potentially could have many hidden layers in it.",
            "So here's the standard neural net that you know about.",
            "We learned about this week.",
            "You have input layer, a bunch of hidden layers, and then an output layer, and this is like a fully connected network.",
            "Every unit connects to every other unit when we're dealing with real images where we have mega pixels in the input.",
            "Right, it's prohibitively large in terms of the number of weights that come out of the input layer into the first hidden layer, right?",
            "So there's too many parameters to learn, So what do we do?",
            "We're going to build in some structure, and this is kind of an interesting, I think philosophical problem that keeps coming up in machine learning, which is how.",
            "How much do we want to build in structure like we start with the kind of tabular rasa, a blank slate, or do we want to build in some sort of structure, and so there's some people that firmly believe everything should be learned from scratch, and even the people who believe that though.",
            "Notably, like Jan Lequince is we don't want to build in any kind of structure.",
            "We want to learn everything right?",
            "Why would we assume we know something?",
            "Actually built-in structure into their models and the kinds of structures that are built in a."
        ],
        [
            "Gender thing is having local receptive field so you don't have full connectivity, but instead you have a window of number of units in the layer below that connected the first hidden layer.",
            "So this is an image.",
            "Every dot here is a different pixel so you get a little window.",
            "I think that's about 5 by 5 that connects to the first hidden unit in the array in the second layer and I mean the first hidden layer and then the next hidden unit over connects to the another 5 by 5 window that's just shifted by one pixel here.",
            "So the notion here is that units are arranged.",
            "The term is topographically so that neighboring units have similar properties.",
            "Because they have overlapping receptive fields right?",
            "So the receptive field is this little window in the input space that that unit responds to.",
            "And Topa graphic connections are very interesting.",
            "Also from the standpoint of animals, so Topa graphic."
        ],
        [
            "Maps are well known in our brain.",
            "So, for example, we call the Homunculus, which is you can take neurons along what's called the somato sensory strip in the brain.",
            "And it turns out that neighboring neurons respond to or sensitive to touch in neighboring parts of our bodies.",
            "So it's interesting you can follow along here, right?",
            "You have the tongue, the teeth, the gums, the lips, the face, and you can see the body laid out on top of her fingers all the way different parts.",
            "And so that's.",
            "Topa graphic Maps, meaning that neighboring neurons are responding to neighboring kinds of inputs.",
            "In this case, places on the body and it happens both in terms of touch and motor output responses in those areas.",
            "So that's a Topa graphic map that's common in biology, and it's also been very useful in neural networks.",
            "So that idea I think inspired people to try these local receptive fields in neural network."
        ],
        [
            "And there's another term that's used which is the offset in receptive fields between neighboring units.",
            "So here we're showing astride of one, which means you take the window and you shift it by one pixel.",
            "You have a strider, two.",
            "You shift it by two pixels, so the stride is a kind of hyper parameter that determines the connectivity between one layer and the subsequent layer in the network, right?",
            "Feel free to ask questions or make comments in general during the.",
            "When I'm talking."
        ],
        [
            "So what is a single unit or neuron responding to?",
            "So here's a simple example.",
            "Imagine you have a binary image of zeros and ones, and now you have a filter that looks like this.",
            "What are you doing?",
            "You're actually laying this filter into.",
            "If those are the weights that connect to the first hidden unit, then you're going to lay this filter up in this corner, and you're going to multiply each value here by each value down there, and you'll get 1 + 1 + 1 + 1.",
            "You get a value of four.",
            "Alright, by laying it up in this corner, if you shifted over one, you're going to get a different value right?",
            "So every time you shift it and you apply it to the window in the layer below, you'll get a different different value.",
            "And if we change this filter, then to look somewhat different, so imagine it had ones in this corner, zero in the middle and minus ones on the outside.",
            "What would that and we what kind of input would that respond to anybody?",
            "A gradient good so it would respond when you had, for instance, ones along diagonal.",
            "This way in zeros everywhere else.",
            "So it's looking for like a line or a gradient in the input alright.",
            "This set of weights is known as a feature detector or a kernel or a filter.",
            "OK, those are all terms that are used there, so this is 1 principle that's used in convolution neural networks.",
            "The idea of local connectivity or local receptive fields."
        ],
        [
            "Another one is shared weights, so use many different copies of the same feature detector.",
            "So the thing I just showed you before with a little block of three by three you use that same thing in each position, so you'd lay it down in across the image and it's called replicated features, so the copies have different positions, so you might put it down here, where each one of these colors represents a different weight, and then you apply it in a different part of the image, again with the same set of weights, so the red connections have all the same weights, the green and the blue as well.",
            "So this is replicating across space.",
            "You can also replicate across scale and orientation and people more recently have been trying to do this even though it's a little tricky and expensive to do that they've gotten some success with that and recent neural networks, and so what's the point of replication?",
            "One thing is that it brings down the number of free parameters in the network.",
            "You aren't learning separate weights or parameters in every position you're using the same ones everywhere, but also there's this notion that it's picking up on a feature.",
            "In a position invariant way, right?",
            "So the same edge we just talked about of ones along the diagonal can occur in many spots in the image, and so you want to apply that same filter in lots of spots in the image.",
            "And that comes with the notion of statistical notion of stationarity that statistics are actually going to be similar at different image positions.",
            "So that gives us the definition really of a convolutional neural network.",
            "It has local receptive fields and shared weights.",
            "And then typically you're going to have different feature types or kernels, each with its own replicated pool, right?",
            "So you're going to take the now it's not going to just have one along the diagonal.",
            "This way you might have a one along the diagonal.",
            "This way that's another feature type, right?",
            "So that allows each Patch of the image to be represented in several ways to apply each feature type to every Patch or every little window in the image."
        ],
        [
            "So what are the different feature types look like?",
            "Here's an example of the kinds of feature detectors, so you might have this little image of this animal's head, and so one is just the identity, so you apply little three by three filter there and convolve it, or run it over the image, apply it in every position.",
            "What do you get back if for this filter you get back the original image right?",
            "You're just going to pick out the identity of the center pixel you're going to recover the original image.",
            "If instead you have one that looks more like the gradient filter we talked about before.",
            "It's going to look for an edge where it's lighter here and darker there in the image and that turns out to be up here like above the eye.",
            "An edge detector can go in the other direction.",
            "There's different forms of edge detectors.",
            "There's also other feature detectors you can think of as a sharpening filter, so this is an interesting one that has a big value in the middle and negatives around it, and it turns out if you apply that to the image, you get this right, and you can also do various kinds of blurring to the image as well, so that's what you get with different kinds of feature detectors that you can learn for the image.",
            "OK."
        ],
        [
            "So if you had local receptive fields, so let's take if we didn't do this feature.",
            "This sharing doing the same feature everywhere.",
            "Let's take a look and do some math so we say if we had 200 by 200 image with 40,000 hidden units and let's say our filters were bigger, they were 10 by 10, not three by three.",
            "That gives us 4 million parameters.",
            "And that's really useful if every image had the same pose.",
            "So for instance, you want to recognize faces, and you've done a good job of registering faces in an image, then it makes sense.",
            "You don't necessarily want to have convolve your features everywhere.",
            "You might want to have something specific to particular positions in the image, like the eyes or the mode.",
            "OK, so you don't necessarily recognize those things everywhere in the image.",
            "Alright.",
            "But at the."
        ],
        [
            "Imagine that in general, you don't assume that your images are registered or they aren't always in the same exact pose.",
            "Then we're going to do this feature sharing idea, share the same parameters across different locations, and convolve them with these.",
            "Learn kernels and we're going to get a lot of share of parameter savings.",
            "Alright, so we're going to get the four million down to the new order of 10,000.",
            "OK."
        ],
        [
            "So let's take a closer look at how we're going to build a convolution network, so we're going to start off with, let's say, a 32 by 32 image, and then we have this three channels, which could be like an image.",
            "It could be each RGB, each one of those is a different channel in the image, and then we have a set of weights that go to every curve.",
            "So the feature map or the kernel gets applied.",
            "2 three by three by let's say 32 by 32 Patch here.",
            "And that's the input to one of these units.",
            "In the next level, right?",
            "And then we activate all of these units.",
            "We take the, you know, apply the dot product of the filter to the appropriate region in the image and get an input value and then apply a nonlinear activation learned about this in the neural network talk yesterday and then.",
            "That gives you an output in this area the activation or inactivation as all the activations in this layer is called.",
            "The feature map lets the term that's used a little confusing as you have feature detectors and you have feature Maps.",
            "But the feature map is usually the activation of the layer.",
            "And there's several different hyperparameters for a convolution layer.",
            "It's the number of filters, alright?",
            "That's kind of.",
            "That's the depth of the output volume.",
            "That's like I was saying of how many different types of filters, how many different types of features we're looking for from this layer to this layer, there's the stride as I mentioned, which is how much how many units apart do we apply the filter spatially that controls the spatial size of the output volume, and then we have the size itself of the filter.",
            "What's the width and height?",
            "So those are the hyperparameters of a convolutional layer.",
            "And then in current.",
            "Convolution networks, there's an additional off."
        ],
        [
            "Eration called pooling that that happens after the activation map.",
            "So here we think of it as another layer so you do convolutional layer.",
            "Then you follow it by a pooling layer and you're going to kind of combine all the filter responses within a window.",
            "So here's a picture where we can get.",
            "These will be the feature map, the responses of 64 different types of features in laid out in a 224 by 224 grid.",
            "So these are all the responses activations in a feature map.",
            "Pooling can reduce that right by saying, OK, we're going to do is innocence.",
            "Downsample?",
            "We're going to take a little windows and do something, some operation to combine them into a single like a window of two by two and do something like and Max.",
            "Or an average?",
            "There's different forms of pooling to get a response in this lower dimensional pooled layer here.",
            "So you think of it.",
            "So we've done convolution before this got in this and then we do a pooling layer and get responses here so you can see that have the effect of downsample.",
            "You might have responses that look like this.",
            "Let's get down to 24 by 224, downsampled to 112 by 112.",
            "Alright, so for instance, just to make it clear if you do Max pooling with two by two filters in the stride of two, this little window would be replaced by 6 this.",
            "Window by an 8 etc.",
            "OK, so the effects of this is to both simplify what information is in the convolutional layer, reduce the dimensionality and gain a kind of robustness with respect to spatial location.",
            "So you combine the information within that area and replaced by a single value.",
            "OK."
        ],
        [
            "We put this all together.",
            "We do a sequence of these to make it a really deep network where we do, you know, convolution followed by pooling in this.",
            "In this figure Max pooling and do this several different times.",
            "Every one of these has sets of filters that are associated with it.",
            "We're going to train all those weights of filters and then at the end typically we're going to attach some fully connected layers.",
            "In this case there's a couple of fully connected layers at the end.",
            "And then we're going to do a classification at the end.",
            "At the final step into, let's say, 1000 classes here.",
            "So we have an original image.",
            "Go through all these different layers.",
            "With these learn filters.",
            "Have these dense connections full connections here rather than local receptive fields, followed by a classification, and we want to say cat in this case.",
            "And there's other choices.",
            "There's obviously the hyperparameters I mentioned for the convolution layer, those hyperparameters for the pooling layer to like what's the stride?",
            "What's the window size?",
            "Will kind of pooling.",
            "Are we going to use?",
            "What kind of activation functions, right?",
            "So we've covered some of that before sigmoid, tanh, H Ray lose lose all these different varieties of reylos these days and then they have to choose a loss function for training it versions of log likelihood or hinge loss train, typically by back prop or SGD.",
            "So that's.",
            "Convolution networks in a nutshell."
        ],
        [
            "And this is maybe the mother of all convolution network.",
            "So questions yes."
        ],
        [
            "Or is it?",
            "Supply request cold colors.",
            "So typically that's a choice that's made, but typically a filter would be 3 by width by height.",
            "If it's all color, so it would respond to all three colors.",
            "That would be the first level of filters, right?",
            "I'll say something about that in a minute that doesn't have to be.",
            "That's another architectural choice.",
            "So you could be local in the in the input channels as well.",
            "I was wondering if you do pooling then you invite you increase the number of feature Maps that comes after that and for example, let's say you have a 1015 months.",
            "Then you can filter Max 223 July.",
            "I know that the number of filters that you have correspond to the more feature monthly drug coverage player, but the idea is how do you choose?",
            "How do you go from lower number of each month to hire one?",
            "Do you randomly choose from the previously layers way to convolve?",
            "I mean which which amounts to convolve.",
            "So wait so?",
            "From the previously awaiting for growth, so I think so.",
            "I think that's somewhat connected to the previous question a little bit, so imagine we have.",
            "This might not be the best picture for it.",
            "Let's try this.",
            "That one I meant to get that one.",
            "There we go."
        ],
        [
            "So in this case, so the idea is that this is like 1 feature that is going to look at all three feature Maps in the all three channels in the layer below Anna Anna window of that and it's going to have to learn set of weights for that.",
            "Another feature that's going to be looking at the same set of three by three, 3 by 32 by 32 will have different weights, so there will be a different kind of feature.",
            "So every level.",
            "So there's I think you were saying how many different features are there at this level?",
            "That's kind of an arbitrary.",
            "Architectural decision how many different feature Maps are going to be at every level?"
        ],
        [
            "So if we took a look at this right, it's arbitrarily determined that what we wanted to have in this case were.",
            "So this one had 55 different ones.",
            "Then we had two, 20, seven, 1313 and 13.",
            "Those are kind of architectural decisions about.",
            "Yeah, that answer your question.",
            "Maybe not know, OK?",
            "Consider using.",
            "User.",
            "OK.",
            "Behind this, for example at Ilya Love Pen feature Maps, then you become maximally.",
            "Then you want to increase the number of feature Maps in the next convolution layer already.",
            "Let's say I want to increase the 25th or not.",
            "Then I know I should have 20 different things.",
            "That's already which which I use to convert what's coming from the previous layer, yes?",
            "The previous layer now want to expand it to 20 feature match.",
            "How do I choose appointee filters already which I initialize you randomly or something?",
            "How do I choose which of the feature Maps coming from the previous layer at home?",
            "But you might choose them randomly, so the idea is that we're going to just think of every layer is like an independent decision.",
            "So this case we have 27 different feature Maps and in this case we're going to say there's 27 different thing about the feature Maps become the channels for the next level.",
            "OK, so then the 13 different feature types here.",
            "Each one of them is going to look at all 27 of those feature Maps in the layer below that was the question answered the previous question, and again they can make a choice that is not going to do that, but typically when they think of it.",
            "That way you're going to each one of these is going to respond to all different types of responses in the layer below all the feature types in the layer below, but we can take it offline if that's not clear yet.",
            "Some.",
            "Not useful connected players.",
            "Anymore.",
            "Yeah.",
            "And the sound that does not impact the.",
            "Quality of protection.",
            "That might wanna be using the number of parameters, so what's what's your opinion on that, yeah?",
            "Right, so let me I'll get into kind of more modern things in a minute and get back to that question, OK?",
            "OK."
        ],
        [
            "Good.",
            "So as I was saying, kind of mother of all these things.",
            "In a sense, the original when the original convolution networks was Lynette developed in the really mostly in the 80s on the Clinton colleagues where you tried it out on the MNIST data set handwritten digits and had the main ideas were in there.",
            "This local to global idea of so you think about what's happening, you're taking the beginning, the local receptive fields, the next level, when even when it has a local receptive field.",
            "It's still local.",
            "In the level below, which was combining across different images, different receptive fields in the input.",
            "So in general the receptive fields are going to be growing from level to level and that is going to create more global processing, right?",
            "I'll get back to that in a second.",
            "And it also, but it does keep some sort.",
            "Of course positional information in it.",
            "The techniques we talked about, where weight sharing, where the units are arranged in feature map, and so this is 1 version.",
            "There's all kinds of versions of Lynette where they had convolutions followed by subsampling, which is really a kind of pooling.",
            "And it's several of these, and then had some fully connected levels.",
            "And then did the output and got results that were remarkable at the time of 5% test error on this hard data set.",
            "Alright, so that was one of the original ones.",
            "And so that's my."
        ],
        [
            "Quick summary of convolution networks.",
            "Now I'm going to talk about recent developments."
        ],
        [
            "So I guess five years ago is really talk about modern CNN's coming on the scene.",
            "So Alex net, developed by Alex Kryszewski at Toronto.",
            "Where he just kind of add on his own, he said, well, let's try putting together all kinds of these things in different ways to try to solve the image.",
            "Net challenge with much harder data set then.",
            "The name list more like 1000 classes instead of 10.",
            "So what he did is come up with an architecture that had various things, like convolutions and other kinds of pooling, like local contrast normalization, as well as Max pooling and came up with lot through lots of tinkering and gaining intuition overtime.",
            "A particular sequence of operations of combinations of convolutions and pulling that work very well on the image net data set.",
            "So much so that it kind of beat the current state of the art by about five 5%.",
            "Total number of parameters were 60,000,000 and that sounds like a lot, but it wasn't that much.",
            "If you take into account that how big the images were, as well as all the connections that are in here.",
            "And that's largely through weight sharing.",
            "Got it to 60,000,000 because it was doing really 832 million operations.",
            "When interesting historical tidbit is, the original net was actually more complicated than this.",
            "It was split into two different things.",
            "Two different streams in a way, and that was because he was working on a GPU where the kind of on chip memory wasn't big enough to hold all the the network itself.",
            "So there was two different streams that came out, so there's another kind of parallel stream that was going on here.",
            "I'll get back to that in a second, so.",
            "OK, so that was Alex Net and that really started a whole wave of interest in other kinds of convolution networks or improvements on."
        ],
        [
            "Convolution networks and so next notable one would be the so-called VGG network.",
            "A couple years later where they added more layers.",
            "So here it went to you, inserted a bunch many more layers and trained it up to an again improved on the image net significantly."
        ],
        [
            "So the main lesson there was you could add more layers.",
            "Another thing was work with somebody just mentioned about residual networks so that you could not just add layers but also try different kinds of definition of what is happening inside a layer.",
            "So this was an interesting idea where it was inspired by the LTM gating units, so I think you already covered recurrent networks.",
            "Little yeah, so those are you already heard about those and the idea was just like they combine vanishing gradients in the LS TM using this kind of forget.",
            "Gate right?",
            "Think of it like a like a reset.",
            "So we want to do something now.",
            "We wanted to combat vanishing gradients in a very deep network.",
            "So there's a drawback to going very deep is that you want to get your gradients to go through all these levels?",
            "And that was for years why people thought you couldn't train very deep networks as the gradients would just disappear?",
            "And So what they did was come with the idea.",
            "Well what we want to do is think about what's happening in a network as not just doing your standard weights followed by regular activation followed by weights and really activation.",
            "But you also add this additional input where you're just going to.",
            "Copy the identity so it's like a simple kind of autoregression where you really just going to.",
            "Now you're going to add not only the output here is going to be not only your functions that you created along this stream, but you're going to also add in the identity and so the residual network means that what this guy is really modeling is the residual of what's not already happening in the accounted for by the level above.",
            "So this little module was then inserted into train up very deep networks.",
            "So here you can see VG with 19.",
            "Over here is like you can do a 34 layer that's plain or going to 34 layer that has these little residual modules inserted inside."
        ],
        [
            "Then an elaboration of high weight of residual networks of so called highway networks, where rather than just copying the input like you did here, so rather than just computing a function like this of the input in the weights and plus the copy is, you're going to actually have a little gating network here.",
            "That's going to determine which parts you're going to copy and which ones you aren't, and you're going to do it in an input dependent way, so that's the important ideas that you're going to decide.",
            "So think of this is a more complicated gate combination here where you're going to get an decide well for this input we're going to.",
            "Do more copying of the identity of the identity and less of the raylo right, or vice versa.",
            "So that's really what makes the highway network different than the residual network.",
            "It's dynamically determining when the data gets passed through versus transformed, and the general conclusion of all both of these, though, is that the shortcut connections where you're going to skip players are really useful for deep networks, and that actually had been around for many years.",
            "Like people that use shortcut connections in deep networks for a long time, but not with this specific kind of module idea, they just thrown them in and now.",
            "Showed get a big win for them."
        ],
        [
            "OK, so just to get a sense of how deep so we had six so Alex.",
            "Net had about 10 layers.",
            "Then we went up to 16 layers with VGG 16 Google Net went beyond that.",
            "Resnet had 50 and then up to 152 OK so we're getting very very deep.",
            "So the question is how?",
            "What improvement do we get out of this?",
            "So this is."
        ],
        [
            "One graph to show that you know version of the Alex Net was getting the top five error on image Net was, let's say around 20%.",
            "The cafe implementation of it.",
            "Then versions of VGG.",
            "We're getting that down below.",
            "Closer to 17 and down the 15, the Google net got closer to 10 and then the 16 layer ones closer to VG with seven and then res Nets are pushing it down closer to 7 1/2%.",
            "And so if we scale it all based on the original one and say how much more accurate are we getting?",
            "We've gotten to three times the accuracy in a short amount of time just a couple of years.",
            "So maybe I'll ask you a question.",
            "So what are the tradeoffs for doing that?",
            "So you've gotten better?",
            "What are the tradeoffs?",
            "What have you?",
            "Some of the potential problems?",
            "Sorry.",
            "Heavier models OK?",
            "What is heavier mean?",
            "Lots of memory.",
            "OK, so there's memory issues.",
            "Right, right?",
            "So I'll talk about that.",
            "So potentially you think there might be a lot of lot less, a lot more parameters.",
            "More data OK, more computation good.",
            "So what is their consequences of let's say more data and more computations?",
            "So more computation you might think is that what's bad about more computation?",
            "That means this is burning up energy.",
            "Yeah, sorry.",
            "Less.",
            "Parallelizable, OK, 'cause it's deeper, potentially OK, good.",
            "So back with the more computation idea.",
            "So one thing is that you think it might get slow."
        ],
        [
            "Alright, so let's take a guess how much lower was this guy?",
            "The Resnet 152 compared to the cafe Alex?",
            "How much time slower?",
            "Yeah, running time.",
            "How many people thinks slower?",
            "How many people think faster?",
            "OK, so the actual answer is 5 times slower alright?",
            "So this is the speed that is the number of images per second.",
            "Second all on a Titan X went from, so if you at the scale that again relative to this is a cafe implementation of Alex versus Resonant 152 is about five times slower.",
            "But as somebody said before, it is slower.",
            "It has many more computations to go through, but that's not the only metric that matters.",
            "It's also a question of like how many parameters are there, and it turns out that."
        ],
        [
            "The number of parameters are really about the same, so it's jumped around between these, but you can see roughly if you just look at Cafe de Alex there versus the resonant that they're almost the same.",
            "So because of all of the parameter sharing and they also there was a trick in the one thing that's interesting is that if you go back and look at this that in terms of the slowness, right that the people were saying you think it might not be that slow.",
            "Well, if you look at the VGG one that was considerably slower than.",
            "Then the Alex Net and resonate is actually almost on par with the VGG net, right?",
            "And that's because Fiji has done did some things like they.",
            "Had a smaller window of how many.",
            "I'm sorry that the resident shows a smaller window of what features they were going to respond to.",
            "Alright, so that ended up actually speeding up things a lot, so there's a lot of things you can do in the architecture to make things go faster, such as choosing more local fields in terms of the channels or features from one level to the next back there.",
            "Right, so this is actually for running."
        ],
        [
            "OK, so other recent developments in their own, so that's just kind of getting deeper.",
            "That's one thing.",
            "There's other questions about how you combine things from level levels, so there's been a bunch of work recently on so-called normalization, so one form of this is batch normalization that's become very popular.",
            "The idea is that you want to standardize the response of every feature channel within a batch.",
            "So what does that mean?",
            "So here's an illustration of that is that you have.",
            "This will be the responses of the feature map different feature Maps.",
            "Are shown in this dimension and then we have width by height right?",
            "So this is the tensor innocence of feature map responses.",
            "And then you're going to choose one of the channels and compute the moments.",
            "What is the mean response in the variance response?",
            "Subtract off the mean divided by the variance, and that's going to be your new response shown down here to make it more explicit.",
            "So one thing I should say is I don't have many equations.",
            "I thought for something like this I wanted to keep things more at a picture level, but.",
            "There's a few equations, so this is one of them, so this is the output of the J TH unit on the NTH example and so.",
            "You're going to subtract.",
            "This is the average, right?",
            "So this is averaging over all of the examples in batch B, right?",
            "And they take the average response?",
            "That's the mean response.",
            "Subtract that off of the response on a particular example N, and divide by the variance.",
            "And that's going to be the output here.",
            "One thing to note is this is usually applied after you've done the activation before you've applied the Raylo activation.",
            "Reply this and do the normalization right and then then apply the raylo and an learn the bias.",
            "OK so batch normalization turned out to have a very good effect for a lot of learning.",
            "Deep networks.",
            "There's been other forms of normal, sorry question back there.",
            "Sorry, say it again.",
            "The.",
            "Peter and Gamma, right?",
            "So that's the bias that's added afterwards.",
            "Alright, so you're going to learn some bots some specific bias, and so these are just parameters that are added in to the hyperparameters to tune like how much of the bias versus the scale of this overall right?",
            "So this is 1 and these are just standard variables, but you can scale them.",
            "Alright.",
            "OK."
        ],
        [
            "There's more recently, so last year it was a paper that proposed layer normalization, so rather so one thing that you're doing in batch normalization is you're normalizing by all of the examples in a particular batch of training.",
            "So then you can think about.",
            "Well, maybe you don't want to normalize by examples, but rather within a particular layer.",
            "So that's what their layer normalization does.",
            "It standardizes the responsive units of each feature channel within a layer.",
            "OK, she's doing this for a particular feature channel, and you're saying so.",
            "It's the same type of equation we had before, but the difference is now when you're computing the mean.",
            "For example, you're summing over all of the units K within a particular layer, the same layer as unit J. OK.",
            "So that mean is calculated by.",
            "So for ZSJ the JT unit looks at the calculates the mean of all based on all units in the same layer, and the variance is also calculated layer wise.",
            "And this turned out to be a good results in recurrent networks.",
            "Not as good in convolution networks.",
            "And this.",
            "People have developed other schemes, like various normalizers on weights or spacially.",
            "And this is 1 area where in some ways that people doing neuroscience and studying computational neuroscience of we're ahead of what was going on in convolution networks because they had various schemes like divisive normalization and subtractive normalization.",
            "They had studied for years, and this thought that divisive normalization in particular is a kind of Canonical computation that people have proposed is useful for all kinds of things like redundancy reduction or image compression, for attention for all kinds of different things in the brain.",
            "People proposed of divisive normalization is relevant.",
            "So this is a."
        ],
        [
            "Paper we had last year, this year, and I clear we looked at the vistas.",
            "Normalization is another kind of normalization scheme that could be applied.",
            "So this is a picture.",
            "Will give you an idea of trying to compare these different ones so batch normalization you can think of your these are all the examples.",
            "The different features and then you have examples within, so this is across a layer this way and then the each plane is a different example and then so the idea is that batch normalization is that you're adding up over all the examples in the batch, so the yellow ones layer normalization is you're adding up over doing a separate normalization for every layer.",
            "OK so these are all the features within a given layer.",
            "These are the features in a different layer.",
            "And then the vicious normalization is something that's combining those two.",
            "It's A kind of layer normalization and its spatial OK, so it's only normalizing within a region.",
            "It's not normalizing across the whole layer.",
            "And you're going to put them all in the same form.",
            "Batch normalization layer normalization and divisive normalization.",
            "The key being that you can think of it as just a spatial restriction, like a special kind of layer normalization and one other thing we added was this extra term in here, this Sigma squared.",
            "It's kind of a smoothing term, so rather than just dividing by the variance, you're going to buy the variance plus some smoothing term Sigma.",
            "Alright, so we can think of that as a kind of bias in the normalizer, and it turns out that that is a very."
        ],
        [
            "Important effect, so if you think of the activation function like in a standard raylo, it looks like this as you change the bias.",
            "What it does is it tends to make that reylos saturate so it gives you an interesting new kind of activation function and it turns out that that had very good effects across.",
            "We tried it on a bunch of different datasets, both on convolution networks and recurrent networks.",
            "Tried the same thing, and so here's some accuracy on cifar.",
            "For example with our batch normalization.",
            "You can get pretty good results.",
            "This is with the smoother.",
            "So even if you just add the smoothing to these other kinds of normalizations, you get a win.",
            "So in some cases the divisive normalization which did the spatial thing actually was a win.",
            "Sometimes times the other one.",
            "So this is just an interesting dimension to think about when you're doing forms of normalization.",
            "You think about whether you want to do batchwise layer wise or something that's more spatial and or some combination of those things, OK?"
        ],
        [
            "So another question in.",
            "Current networks in the network design is the choice of the receptive fields, he said.",
            "Like how big should the receptive fields be?",
            "That's another parameter.",
            "You want to choose so they would ship to field.",
            "The definition is what's the image region that influences a particular response of a unit or a neuron.",
            "And the idea is anything outside that receptive field is not visible to the neuron.",
            "So if you think about it, if you have a big large image structure and the unit has a small receptive field that can't really respond to the full image structure, OK, so it can't analyze that full image structure.",
            "And so there's this bidding this notion that what's happening as you go deeper and deeper in a network is that the effective receptive fields are getting larger and larger, and that's a natural thing, right?",
            "If you think about you have one unit that's responding in one region of the image, and another unit that's responding in a different region of the image, and you're deep in the network, and you're actually receiving input from both of those units.",
            "Then you're responding to a wide range in the image, so there's this natural thing when you're doing the local receptive fields with some stride that the receptive fields should grow and grow as you proceed down the layers of the network.",
            "Is that clear everybody?",
            "So, so the receptive field should grow, so we actually did some analysis.",
            "This was an IP paper last year.",
            "We had.",
            "What is the actual receptive field?",
            "So there's this notion of how the receptive field grows that you can get just from the architecture just from knowing how the units connect from one level to another level.",
            "And we called it the effective receptive fields and that's the region in the input that contains some input that doesn't have, not that has a significant impact or non negligible impact, non legible.",
            "We measured is within 2 standard deviation of whatever the center pixels impact was.",
            "And so for convolution networks we can measure impact as the scale of the partial derivatives, right?",
            "That's how you measure how much impact it has and what we found was a little surprise."
        ],
        [
            "Thing is that the effective receptive fields were a lot smaller than we thought.",
            "Alright, so you can do this by analyzing things and 1st, we found that there's a Gaussian distribution in the effective receptive fields, and it grows as on the order of the square root of N over the number of layers in deep convolution networks.",
            "And the theoretical receptive field based on stride and other things should grow as order N. Alright, so there's and so relative to the full theoretical receptive field.",
            "It's occupying 1 / sqrt N What you think that the receptive field should grow from layer to layer and so this is just some pictures of how this 1 / sqrt N looks like as you go from layer to layer and what this receptive field.",
            "Depth of field changes and this is just the beginning with the uniform weights with random weights or random weights followed by the raylo.",
            "So here we're talking about the initial effective receptive fields of units in a deep network.",
            "But after training the effective receptive fields tend to grow.",
            "So this is like we train up a network on Cifar 10 and do the same type of analysis.",
            "So before training it would look like this and after training it grows right and then another data set.",
            "If we train it up on Cam, did it's effectively much smaller before training.",
            "After training it grows some as well, so it's an interesting phenomenon that.",
            "That the receptive fields tend to grow.",
            "So this brings up the question is, well, maybe you want to build in your convolution network some way that would tend to have it be a larger effective receptive field at the beginning to enable it to learn better, right?",
            "So this could be a limiting factor in how."
        ],
        [
            "It learns.",
            "So how could we do that?",
            "Well, one way is to initial change our initialization and diffuse instead of just having a kind of random initialization uniformly in the field.",
            "Is that you can make it so that tends to have higher weights towards the periphery of the filters, and that diffuses the power to the periphery.",
            "You can also replace a large feature bank with a sequence of smaller ones that is also another way of gaining larger receptive fields you can do, or you can sparsified the connections randomly or group.",
            "So this is just an illustration.",
            "This comes back to a question earlier.",
            "If you didn't.",
            "If you don't connect to all of the features in this level, but instead you connect to groups of them and you do it in a sequence of ways, and it turns out that that enlarges the effective receptive field.",
            "Right, and it also reduces the complexity, so the complexity here is shown by.",
            "You know that this number of operations you're doing from one level to another level has to do with the height of the filters divided by the stride.",
            "The width, the filters divide times the number of input channels and the number of output channels, so that's really effectively how many operations you're doing from one level to the next in the convolution network and the number of parameters right is height by width by.",
            "Channels by number of output channels, but if you do this thing where you group them and you make them somewhat sparse, you've saved a lot on complexity where depending on how much how you do your grouping, but your connectivity will look more like this, and it turns out that it will also effectively in larger receptive fields.",
            "Alright, so that's another kind of method that people are looking at these days for how to get receptive fields to be effectively larger in convolution networks.",
            "OK."
        ],
        [
            "So that was always came about.",
            "Recent developments.",
            "Now is a question about can we really understand what's being learned in one of these networks?",
            "And for that I want to talk about it."
        ],
        [
            "Two things, what do we really know about the networks?",
            "How?",
            "What's the relevance to or from biology for these networks?",
            "So there's been.",
            "So that's a question.",
            "A lot of people are studying.",
            "Visualizations is a third thing, and then a little bit about theory and analysis."
        ],
        [
            "So that the original convolution networks were somewhat inspired by visual neuroscience, so hubl in visal the Nobel Prize for coming up with hypothesis that the primary visual cortex forms very simple representations, and then the next level of representation combines those simple representations to form what are called complex cells, right?",
            "That's actually illustrated this well.",
            "This shows up.",
            "But here we have primary visual cortex of the input comes through the eye, goes the primary visual cortex goes through the lateral geniculate nucleus through the primary visual cortex, and then up through different levels of cortex is shown here.",
            "Up through this is primary visual cortex V1, and then this stream is called the ventral, or the object stream where he goes to V2V3V4 and up to inferotemporal cortex, which is meant to represent actual objects or shapes.",
            "So this inspired a lot of the work in the original convolution networks.",
            "And there were actually like roughly 30 different areas now is thought to be more areas than that where this V1 and V2 are the primary cortical areas that are the inputs.",
            "So this was the been around for a long time and inspired in fact."
        ],
        [
            "Work that predated Lynette, so this was Fukushima's Neo con Agra, Cognat Ron and you can see that had a lot of features that were present in Lynette so it had the local connectivity from one level to the next and this is a diagram from his paper so you had retina that went to what he would call the LGN.",
            "Then it went from simple cells to complex cells, lower high, complex, higher order hypercomplex up through every level, and at the end form something that would recognize objects.",
            "Known as the grandmother cell would recognize her grandmother.",
            "OK, so this is Fukushima's original think, so I think so.",
            "This predates Lanette by 10 years or so and I think was an inspiration for it as well.",
            "It had a lot of the same properties of local receptive fields and this deep architecture."
        ],
        [
            "So, but we don't want to put Saints push this too far.",
            "I mean there's some similarities between convolution networks in biology, like the layered architecture in his local connectivity.",
            "There's not really much evidence for shared weights in the biology, I mean, so this is an example in the right now where you have local connectivity from layer to layer inside the retina that comes out, but there's tons of other difference, not just shared weights.",
            "We talked about.",
            "One thing you know?",
            "Potentially there's some operations like the visit normalization that are thought to be happening in.",
            "Biological networks that may also be happening in convolutional networks be useful in convolution networks, right?",
            "So there was 1 interesting study done a few years ago that tried to take this comparison a little more closely, so this study was interesting.",
            "They took images that looked like this.",
            "Don't know if you can see it from where you're sitting, so this is a car at a funny angle with a weird background to kind of ocean background.",
            "Then they took fruits so they had random choice of background.",
            "Random choice of that.",
            "I think there were several different classes and they could be an arbitrary poses on some arbitrary, some randomly chosen background.",
            "So this is an elephant floating above the world.",
            "And they presented this both to monkeys and recorded with multi electrodes and parts of the monkey brain.",
            "So they're picking up signals from lots of neurons simultaneously.",
            "For one of these images, and they also fed these images into what were the currently current best convolution networks at the time and want to compare things.",
            "And so how do you compare in that case?",
            "So what they did was they said, well, let's see how accurate you would be if you looked at the response is building a little classifier, you can take the responses of the.",
            "Monkey neurons, for example, in some layer of the visual cortex I showed, you take those outputs from the monkey neurons and then build a little linear classifier on top of it, like kernel classifiers.",
            "What they use do the same thing for the convolution network, do layer by layer in the convolution network, come up with a bunch of features, take those features an feed them to some linear SVM and the question is how accurate is the feature the feature classification done on the features in the network.",
            "Versus features that were in the monkeys cortex, and how analogous were they all right?",
            "So we have tried a few different models.",
            "They tried ones that were V like modeled after V1, the lower left, lower level that are like edge detectors V2 that are like the complex cells that combine edges and then these were some other models that the authors were interested in, like ones based on hierarchical ands and ORS for example.",
            "And then these were the deep networks there was the Alex Net.",
            "There was a version updated, improved version of the Alex Net Buys Island Fergus that changed the Heights of the hyperparameters.",
            "And then over here, this Gray bar is recordings from V4 Cortex.",
            "So V4 just to go back to this picture along the visual hierarchy.",
            "Along this stream, V4 is up here, so it's a few steps away from V1 and V2.",
            "And then they also recorded from Inferotemporal Cortex, which is closer to actually write with the object recognition happens and what they found was that the inferotemporal cortex.",
            "If you did classification based on that on this task, you get 60% accuracy or so, and the best deep networks were similar.",
            "OK, there was like somewhat analogous to inferotemporal Cortex.",
            "If you recorded from V4 Cortex, the information wasn't as president wasn't as obvious.",
            "It didn't do as well.",
            "So I think this is more not the same that the actual processing that's going on, but more kind of seeing how much information is present in a network to do this.",
            "How much information is present in the brain to do these kinds of classifications?",
            "So it's an interesting study along those lines.",
            "OK, so the."
        ],
        [
            "One that's about the deep networks in biology.",
            "Let's talk about visualization.",
            "So visualization something in the old days in neural networks what we had was so called Hinton diagrams, named after Jeff Hinton.",
            "So you'd say, OK, well, what are the weights into a unit?",
            "And typically you were training on amnestied on digits and so you had black and white inputs.",
            "And you can say, well, the weights could be described by, you know.",
            "Well, so that typically the weights you just want to think of how positive or negative await is so positive weight is white and negative weight is black and the big how big the square is, how big the magnitude of that weight, right?",
            "So you could look at the weights.",
            "This way we always looked at Hinton diagrams and sometimes you could try to when we called it.",
            "Reading the tea leaves trying to make sense of what was going on inside a machine learning inside of neural network.",
            "More recently, in the last few years I think there's been a lot of progress on understanding what's going on in networks.",
            "And so it's an interesting branch of research led some insight into convolution networks.",
            "So for instance, if you take Alex.",
            "Net, the first layer of Alex.",
            "Net, you get these kinds of the filters that were being learned in the first convolution layer.",
            "And so you'll see that there's interesting split here, even though why there's this split.",
            "Sorry.",
            "Right, so we had this split like I mentioned before was because it couldn't all fit on one.",
            "The chip wasn't big enough for the memory, so we had to do two different ones, so this is more of like a historical anachronism that we have these two different kinds of filters.",
            "Nice to say that there was this kind of split that it found, but it didn't found it because that way the system was run.",
            "But in any case it's interesting you got this kind of high frequency black and white here and low frequency color down here for the most part."
        ],
        [
            "Now the go beyond that first layer.",
            "First layer makes sense 'cause you're looking at images.",
            "How are you going to visualize what's happening?",
            "You can't really make sense of the weights very well, 'cause now you're looking at weights on top of these feature Maps, and So what xylan Fergus did a few years ago as they came up with a method where they used, looked at what images activated a neuron a lot.",
            "And then they try to go back and back project to the image space to say what was happening in the image space that led to that high activity.",
            "And they used a technique called deconvolution seed convolutions on the way up deconvolution's on the way down, I'll say something more about the convolutions in a minute, but what they did is they chose the 9 images that for a given neuron the 9 images that excited at the most.",
            "So these would be the nine.",
            "Let's say for this neuron up here and then these over here are when you did this deconvolution and look back at what was happening in image space.",
            "This is what the image look like that corresponded to the activity.",
            "Of the unit when it was shown this input OK, you can think of it as you do convolutions.",
            "Activate the unit.",
            "2D convolutions come back and create an image that corresponds to us is a form of reconstruction in a way of what's happening in the image, right?",
            "So what you see here is at the second level, so each one of these three by three blocks is a different unit, and what you see is that the responding to oriented edges in some circles kind of like what you thought from the Neo Cognat ran right?",
            "You want to go from simple edges to combinations of edges.",
            "The things like extended curves, corners all these types of things.",
            "So this was the theory for a long time.",
            "You have this sequence as high."
        ],
        [
            "Are Archaea features go to layer three and you're seeing that again?",
            "It's looking for combinations.",
            "Interesting combinations now of color and shape, so this is kind of orange ready.",
            "Things that are have this curve in them and that's what seems to be responding to.",
            "So that's."
        ],
        [
            "By doing this you get a little bit of sense, at least of what's happening in the different layers of the network.",
            "And in some cases it's a little surprising, so let's take this one for example over here.",
            "Unless you can see that very well.",
            "So there's are this one, maybe trying to find one that's a little interesting.",
            "So maybe OK, here's a good one that has some variety to it, right?",
            "There's some women in it.",
            "There's dogs, there's cars.",
            "OK, so there's like a real mix of different things, so it's not very clear what's happening in terms of the representation.",
            "But if you look, it seems like you know here it's looking at in general, that things that look a little bit face like, Alright see the face, the dog, the face of this person in the wheel itself.",
            "The hubcap looks a little bit like.",
            "A face, right?",
            "There's other cases where it's picking up on something like here it's looks like it's picking up on the background.",
            "It's actually picking up on things like the grass, so there's."
        ],
        [
            "Interesting representations there.",
            "Another thing that can be done to analyze representations is do a kind of ablation study so you can take the input and remove or mask out part of the input and try that in different areas and look at how that affects the responses so the other one was trying to find what is maximally responding.",
            "Accidentally, making this unit respond and now you can say well, if we subtract this part of the input or Max it out, how does that affect given units respond?",
            "So this is an example where.",
            "You know this is a little mask applied over here.",
            "An applied over here and what you see and this is a heat map of showing when you apply the mask in a position.",
            "How much did it affect the class?",
            "So it said that the in this case the class Pomeranian was very affected, so blue is it means it had a big effect when the mask was applied in the middle, so that affected that output unit a lot and not we anywhere else.",
            "Similarly here the true label car wheel was affected when the mask was applied over here.",
            "And not as much elsewhere, so it gives you some insight into which part of the input is Rep is important for the activity of the unit.",
            "In this case of the class, but you could do that at different levels in the network as well."
        ],
        [
            "So that's just looking at networks and trying to do some analysis you could.",
            "One thing it would be nice to do and this is kind of a longstanding aim, at least in computer vision.",
            "Neural networks is to have find part based representations, so you'd like to learn of the system, learn parts.",
            "So somewhere in the intermediate representation you'd like to say you know, can we represent for a person, represent a nose for a person, for example, different kinds of nose is different in kind of viewpoint, invariant way, right in position invariant way for example.",
            "So we actually did some work at NIPS.",
            "The paper last year where we did clustering along in the as we built this convolution network.",
            "Yeah, we did.",
            "Is clustering along the way to say we would like to replace groups of activities of neurons with a single cluster.",
            "And if you do this in a spatial clustering, what we found is that so that now what we're going to do is say.",
            "All of the the same cluster can occur in different locations.",
            "OK, so we're clustering across space and finding patterns that occur in a location invariant way, and we did.",
            "We found that we actually learn things that did correspond roughly to parts, so this is.",
            "Example of birds where you can see that this would be a unit in that all the examples that make a particular cluster respond, you can see it's responding to something that looks like the head of a bird.",
            "In general, not always right.",
            "So kind of sometimes gets a wing, right?",
            "So so the question is, can this is one step along this way of trying to find ideally a representation that forms parts somewhere in the intermediate representations of a big convolution network.",
            "OK, this was work done by by Renji who somewhere here in the audience I think."
        ],
        [
            "And another interesting direction in terms of visualization is analyzing and analyzing the representation.",
            "So this is been very popular these days where you can start off with a random image and then start changing the image and a gradient ascent way so that you say well what is.",
            "How can we change the image to maximize the activation of this unit so you take a unit anywhere in the in the network and compute the gradient of the image with respect to that activity and follow it so that you want to move the image and directions that make that unit most active.",
            "Again, you can do that for classes, so you can save for the image class Flamingo.",
            "Let's find images that are maximally going to maximize the response of the Flamingo unit or the Pelican Unit.",
            "Or you can do that for units within layers and you form these interesting patterns.",
            "So one conclusion from this that's important is that if you just start from noisy images and do this gradient descent, you typically get fairly difficult to interpret things, and so this has been followed up by a lot of work and.",
            "Adversarial networks that you'll hear about where you try to fool the network by doing something very similar.",
            "But originally this work was done, but for visualization purposes to try to understand what's going on in the network.",
            "And it turns out that natural image priors play an important role where you want to say, let's find an image that not only maximally activates that unit, but also looks like a natural image.",
            "OK, so the best methods these days combine natural image priors with these kind of.",
            "Gradient descent in the unit activity.",
            "OK, there's a whole sequence of work on that."
        ],
        [
            "So in terms of theory, there's been also a whole lot of work done.",
            "James Martin's done.",
            "Some interesting work has been work here in Montreal, Yoshua colleagues on theory of convolution, neural networks.",
            "And I'm just going to highlight a particular recent paper from Tommy Pojo's Group, where the idea was going to compare a shallow and a deep network.",
            "OK, so here's a shallow network, and here's a deep network, so both the shallow in the deep network are universal approximators of functions.",
            "Let's say of eight variables here.",
            "But if you have a compositional function, then the deep network provides a better approximation for compositional functions, so there's been a lot of intuition about this.",
            "This paper actually goes and and has some theorems and proofs of it must have been completely have my head around the proofs yet, but I can tell you what their findings are, and their findings are that one way to think about it.",
            "Is that the deep network?",
            "Has this structure, like here this kind of binary tree like structure and it requires even though that they're going to both be universal approximators?",
            "The deep network requires fewer trainable parameters to achieve the same accuracy, so this is like the distance or the accuracy of the shallow versus the deep network, and R is some control on how much how accurate you want it to be in.",
            "The difference is that the deep network has a.",
            "Negative R / 2 exponent and the shallow network has a negative R / D. Parameter in it alright.",
            "And so it turns out that this is.",
            "D is the number of.",
            "The number of examples.",
            "I'm sorry the number of variables and so this scales poorly with respect to the number of variables as opposed to this one, so it's many fewer trainable parameters.",
            "As you grow these things.",
            "And the main finding is, so it's kind of interesting says that the.",
            "Target function is if that function is scalable.",
            "So the same thing applies across different scales and also shift invariant, right?",
            "So position invariant then these deep networks are natural approximators for those things, and again that fits your intuition right, which is that if it makes sense to be grouping parameters this way, right?",
            "So this network is not going to be very good at picking up long range connections between X1 and X8 the way this one is right, but if your natural function.",
            "Is shift invariant?",
            "Then it's not important to pick up long range connections between X1 and X8.",
            "Alright, so the idea is that as you might expect, deep convolution networks are very good at font at learning things when there are has this property that the shift invariant and that there's somewhat scale invariant as well, it kind of begs the question though, so that is a lot of what people have found success on right?",
            "So they found success on vision that has largely has some shift in variance and some scale invariants, but it also has been a lot of success for convolution networks on other areas.",
            "That aren't don't necessarily have that property.",
            "Like all kinds of text, things that don't even think that text has the same kind of scale invariants or shift in variance, right?",
            "So again, it's so the theory and practice are a little bit different here, but I think this is 1.",
            "The notable thing here is that at least matches our intuitions or give some proofs of the intuitions that deep networks, deep convolution networks are more natural approximators than shallow ones.",
            "For certain classes of functions.",
            "OK, so one other bit of."
        ],
        [
            "Analysis I think that's interesting was people's up.",
            "This is a paper from I clear this year that looked at what kind of representations are being formed in very deep networks, and so they were interested in the fact that if you take a deep like highway or Resnet residual network and that you can lesion that layers like get rid of some of the layers or shuffle some of the layers and that seems to have a fairly minimal effect in a lot of these, right?",
            "So you didn't have that much of an effect.",
            "By doing these things, and that's a little puzzling if you think of the Canonical view.",
            "I've been talking about, you know where you start from lower level and vision like V1V2 up to higher level in vision and you're getting these more complicated edges to combinations of edges to parts to objects, right?",
            "This nice compositional feature hierarchy.",
            "Then in that case, if you got rid of a layer, then it seemed like they have disastrous effects.",
            "Alright, but they found though is that other people found was that if you get rid of those, some layers that doesn't have too much of effect, and so the thinking is that they can now analyze it and said you can think of what's going on inside these residual or highway networks is that they're really kind of finding a new representation and then iteratively refining it and then find that you do that for several layers, and then your next batch of layers is going to get a new representation and then a sequence of layers to refine it.",
            "OK, so this is a picture on it, you can see it from where?",
            "Here's one picture to say, OK.",
            "This is a one layer network.",
            "This is a three layer network that's going to form 3 different representations along the way, and what the what these residual networks style are doing is instead taking this initial representation and then refining, refining it and then passing it on.",
            "Alright, so it can be called 152 layers, but it's really many fewer effective layers of new representations, so they drew this picture.",
            "They say, well, there's all this stuff going on inside a block, and then it goes through this stage, and then there's a dimensionality change you get to new features and then refine them.",
            "And they had underlying, so this unrolled, iterative estimation.",
            "There's an equation for it here that's saying, like the so this is some feature that's being formed AI at layer I, and the idea is that each of the sub layers in that block that index by K the expected value of them is all zero relative to AI, so they're kind of iteratively refining that feature AI, and then they did some empirical work to show that that was the case.",
            "They identified in a deep network one of these highway networks.",
            "Or residual networks and said OK, let's look at what's the estimation error of some particular variable variable.",
            "In that level they identified variable like the average activity and then looked at the estimation error and found that the average estimation error was very small.",
            "You can see that you know some variance, but still the mean is 0.",
            "So it's really kind of four levels of new representations.",
            "In this case, iteratively refine.",
            "So I think that's an interesting analysis begging the question of, you know, when we're having deep networks were really how?",
            "When we have something that deep, what kinds of representations are having are happening at every one of those levels?",
            "How much of it is a new representation versus taking a representation and refining the activity?"
        ],
        [
            "OK.",
            "So the last thing I want to talk about are applications of convolution networks and I'm going to talk about 3 in particular."
        ],
        [
            "First, one semantic segmentation, and that's something that I've been interested in for many years, so this is a figure I dug up from an old paper of mine from 2004 where we had a semantic segmentation problem, and.",
            "We had a convolution network classifier at that point that predicted the pixel labels alright in that convolution network had three layers, sigmoid units and use some weight decay as a regularizer, and what you see here is some images of animals in the hand labeled.",
            "So in that case we had the hand labeled grad student zooming.",
            "Hey, had the hand labeled the images, we didn't.",
            "There were no labeled images at the time and there were as such there were only 100 images that were labeled 60 for training and.",
            "Ready for test.",
            "Images were 80 by 1:20 and you can see the classifier did OK, but not so good there wasn't that much data.",
            "So then we utilized the CRF conditional random field on top to clean it up and then it got pretty good performance.",
            "At the time there were several different classes in this data set.",
            "There was another data set with from the British Aerospace that also had like 8 classes and similar numbers of training examples and you compare that to what's going on now though example that's been popular for awhile and.",
            "In semantic segmentation, right, we want to assign every pixel to a particular label.",
            "There's 80 different categories instead of seven.",
            "There's 200,000 images with 1.2 million instances, right?",
            "So the amount of data has grown a lot, and people are using the kinds of convolution networks that we talked about.",
            "But the convolution networks are not only getting better, but I'm not only getting bigger with more data, but they also have some interesting techniques.",
            "So one time."
        ],
        [
            "And before was upsampling or or deconvolution.",
            "So what happens when you have a standard convolution network is that you do this local connectivity and pooling is that you're downsampling.",
            "You're kind of getting lower resolution representations along the way, and if you want to predict dense pixel labels instead of it, and found that it was very useful to use upsampling.",
            "So you want to make sure that you stay high resolution alright, and so in predict able to predict everything at once rather than predicting a single pixel the way we were doing in our original work, single pixel at a time you want to predict things at multiple pixels simultaneously.",
            "So to do that you can do.",
            "You can do the fractional stride, so that's one way of doing upsampling.",
            "So rather than taking the same receptive field and shifting over by one, if you shifted over by 1/2 right and do that each time you're actually going to upsample and have more responses at the level above.",
            "That's a simple way of doing it.",
            "Another way that's been more recent is called dilated Convolutions, and that one.",
            "The idea is that you're going to take a filter like this and you can dilate it kind of spread it out to look like this, and that's a dilation of stride one or stripe to take the filter and spread it out and apply that.",
            "And people have gotten good results with Upsampling using this kind of convolutions."
        ],
        [
            "Now another one is you can do think of deconvolution.",
            "So I mentioned this before in the context of the work on predicting what was happened, visualizing what's going on in images.",
            "If you think of deconvolution as a kind of convolution, transpose.",
            "So this is the original convolution where you have this matrix that looks like you think of a convolution matrix you're applying to input X as a kind of banded matrix like this.",
            "If you can transpose that right, then what you're going to do is get output, apply at the extra get output.",
            "This higher dimensional than the input originally, right?",
            "So that's the deconvolution ID."
        ],
        [
            "And people have applied this in a number of ways more recently.",
            "So there's one thing called you network where you also have connections along the way.",
            "I've gotten very good results for semantic segmentation from that, and then this is just a straight convolution network followed by deconvolution.",
            "So these are some of the most recent results in semantic segmentation.",
            "Do a great job using both deep convolution networks with lots of data.",
            "I mean deep networks with lots of data and various forms of deconvolution.",
            "OK."
        ],
        [
            "So there's two more quick things I can tell you about image understanding and few shot learning, and this is some recent research.",
            "Mostly the image understanding is the work of Jamie Kiros in our group and.",
            "So.",
            "Deep networks, one thing that's been case in deep networks.",
            "So before I give you this example is that one of the lessons that have been learned is that you can take a deep convolution network kind of cut it off at some level and it forms very useful features that are useful in a variety of tasks.",
            "So you can kind of think of it as you're chaining up a deep network with other things or transferring it to other other kinds of tasks, and this has been really useful in the case of."
        ],
        [
            "Image understanding in particular.",
            "So here I'm going to talk about.",
            "You know we take images and text and embed them together, so this is an example where you have an image and you have a caption and you're going to bed them into some joint space, and so the image you're going to get this embedding in this joint space or embedding you think of it, just mapping the image through a deep convolution network.",
            "The final level isn't classification now it's some feature map an whatever the dimensionality is of that feature map.",
            "That's this being illustrated in this Blue Square in the middle here.",
            "So you've mapped the image.",
            "Through a deep convolution network, each image gets a point in this.",
            "In this space we can apply a similar type of operation to take a sentence and map it to some point in this space too.",
            "So the point is that both the image and the text are being mapped to some common feature space.",
            "So these are the kinds of feature vectors that we get out of it, and the training, in this case, an image captioning.",
            "The idea in the training is that you want a caption that belongs to an image to be nearby in this space, and so each caption with this image should be nearby.",
            "In captions with that should be far away from images that they don't belong to, and so we use a simple kind of ranking objective to achieve that, where the ranking objective is going to say well you want to sum over all the images.",
            "And look at all the different captions that can go with it.",
            "You want to say that the.",
            "Should be near to the so this is like the target caption for this image should be close, so it should have a you want to minimize this.",
            "You want to have.",
            "This would be a high score and the score for all the other captions should be low.",
            "In case you want to push it apart from other captions, bring it nearer to the caption that it should be close to do the same thing for the and do the reverse for the text.",
            "Bring the text close to the caption that it should be.",
            "I mean text close to the image that it should be close to that is paired with and far away from the others.",
            "So it's a simple ranking objective that's being used to.",
            "Train up the embeddings that are being applied both to the images and to the text, right?",
            "And then how can you test this?",
            "Will you test this by I can give you an image and you can just look around in this space and just retrieve the caption.",
            "That's the closest.",
            "Right, and so if it's not image that wasn't used in training, you're saying well, what caption that was seen in training would be the closest caption for this particular image, and you could do the same thing for the other side, you could say here's some new caption We haven't seen before.",
            "Let's embed that caption, Find the closest image to that caption."
        ],
        [
            "And so we did ranking experiments on the Flickr datasets, and each image has five different descriptions and we're both doing image annotation.",
            "That is, finding the the image.",
            "That's the caption that's closest to the given image, and vice versa.",
            "Finding the images close into a given captions.",
            "And you can compute things like recall if you have it, you know what the right catch the right captions in there with how often is the right one found OK, and so that's something that's a retrieval one.",
            "But there's another approach that you can use.",
            "We're going to now take a convolution network and pair it up, not with the convolution network for text in one for images.",
            "Instead, we want to do is combine a convolution network with a recurrent network, and this now the aim is to create a new caption for an image generated caption, not retrieve a caption, but generate a new one.",
            "And we're going RNN for that.",
            "Question so.",
            "Things that are close but not necessarily in the tray.",
            "What is the?",
            "So so.",
            "So you mean the retrieval setting?",
            "We can only retrieve if you have an image we can only retrieve the ones that have already been embedded.",
            "We aren't so.",
            "I have something super similar.",
            "You could use some sort of like Glover bed.",
            "Some other word vector embedding.",
            "Is that something that's interesting and or?",
            "Yeah, some people certainly will.",
            "I mean, I think that's on the kind of text embedding side where you can say OK. Well, how are we going to embed the text?",
            "You can embed it with Glover and better with other things, and I think there is an interesting question.",
            "Can you generalize to new new text that way?",
            "But I think the generation thing is more, I think I think more interesting.",
            "'cause now you are trying to do retrieval, but you're really trying to generate something novel."
        ],
        [
            "So now the idea is again, we're going to take a convolution network, and in this case we're going to create this common space and then on that's what's happening on the top part and then at the bottom part can use a LTM right to take the caption and embedded in this space of the final activity vector of activities in the LTM is this space.",
            "OK, well we'll start with some good results and some not so good results.",
            "So, so this is the idea that you can generate sentences with."
        ],
        [
            "Parts of speech.",
            "And use parts of speech to jet so you have a recurrent network like an L STM that's generating a caption and you can.",
            "You can kind of constrain what you're doing with parts of."
        ],
        [
            "Each and so.",
            "The idea is that you're going to bed the image using a compliment and then condition the language model on the embedding and given a part of speech string, generate sentences that have that particular parts of speech that you can say you know that you want it to be.",
            "Let's say a verb next or a noun next, or various things like that, and then you can get outputs that have that particular part part of speech.",
            "And generated description and score how well that description does repeat it many times and take it."
        ],
        [
            "Higher scoring one, so some good results we get with generation.",
            "So a car is parked in the middle of nowhere so these are generated not by retrieval but by actually generation, right little boy with a bunch of friends on the street."
        ],
        [
            "Some failure types we get that are kind of interesting.",
            "Two birds are trying to be seen in the water.",
            "Can't really count them, but it doesn't.",
            "It's kind of reasonable.",
            "It's a giraffe and a field, so it had a real problem with gender.",
            "So this goes back to what happened.",
            "With Vector we had a demo with this when we had the launch and we had the Minister, the Economics minister for Canada.",
            "We had the mayor of Toronto an the Premier of Ontario is a woman, Kathleen Wynne and two men and they stood in front of it.",
            "And the computer said three men wearing suits, so it's a bit.",
            "It's a problem with doing live demos, just like I guess doing life talks that things go wrong.",
            "And so in general it's not good at gender.",
            "It's not good at it, but it makes some interesting mistakes like this."
        ],
        [
            "OK, so let me just."
        ],
        [
            "Wrap up with last thing, so this goes back to what I was saying about creativity.",
            "So you can try to generate things with particular style.",
            "So in this case we took a network that was trained on text or the text was lots of different and in this case romantic novels.",
            "So this was a skip gram model by Jamie Kiros and it was generating text now that was bias based on the kind of text that it was trained on, which was all romantic novels.",
            "So it saw this image and it wasn't just generating a caption, it was generating like a paragraph.",
            "To go with it.",
            "So if you read it, it reads kind of like you know, a nice romantic novel, right?",
            "OK. Now we took another network that was trained instead of not on romantic novels.",
            "It was trained on Taylor Swift lyrics alright, and if you look at the Taylor Swift lyrics that system and took the same image and now had out."
        ],
        [
            "But something said this one, you're the only person on the beach right now.",
            "You know they will ever fall in love with you when the sea breeze hit to me.",
            "I thought, hey.",
            "So this one I would say is, you know, generating with some creativity.",
            "I claimed the computers somewhat creative.",
            "And this is another favorite."
        ],
        [
            "My like kind of like sumo wrestling, so here's another one with trained on romantic novels faced with a sumo wrestler.",
            "It was a shirtless man in the back of his mind.",
            "I let out a curse.",
            "He leaned over to kiss me on the shoulder.",
            "He wanted to strangle me.",
            "Beautiful boy, I'd be wearing his boxers, OK?",
            "Alright."
        ],
        [
            "So I didn't get that."
        ],
        [
            "I've got my last application, few shot learning just one word about that.",
            "I think it's kind of the most interesting area in machine learning these days.",
            "Yeah, deep networks are very good at train."
        ],
        [
            "With millions of training images or thousands of hours of speech, what we really want to be good at is training with small end, very small number of examples.",
            "So I think this is a really interesting area, done some recent work in it that I'm going to skip through and I'll get to my conclusion which is bum bum bum bum bum?",
            "Dun Dun Dun Dun.",
            "I was optimistic about how much I get through everything.",
            "OK, conclusion."
        ],
        [
            "There's a lot of other topics I haven't gotten through in modern convolution networks, like how do you make processing a lot faster?",
            "And you know various things like Fast Fourier transform and various things like that reduce precision, so making binary weights, binary activities, compressing weights and all kinds of interesting ways like.",
            "Factor matrix factorization, also novel optimization techniques.",
            "Lots of other applications like object detection, tracking, 3D vision very important these days as ego motion estimation.",
            "So this is all in the vision domain.",
            "Tons of non vision ones like text and speech processing and learning to rank.",
            "And so my last."
        ],
        [
            "Glad it says that we still don't really have a good understanding, so I try to talk a little bit about, you know biology and visualization and also a little bit about the theory.",
            "But we still don't really understand learn representations very well and I think gaining a better understanding of that will help us learn better representations.",
            "How do we design optimal mini batches size and design?",
            "How?",
            "What are the links between deep networks and parts based model?",
            "Will try to talk a little bit about that.",
            "Also, causal models.",
            "That's an important area in machine learning these days that hasn't been well explored.",
            "Deep networks, what are the links between causal models and?",
            "I think that's a very interesting questions about that hyperparameter optimization.",
            "We've made progress with things like Bayesian optimization to some degree, but there's a lot of open questions like how do we optimize the architecture?",
            "You know, the size of the filters, numbers of layers, all these questions that came up.",
            "These are very early.",
            "What's the connectivity between layers?",
            "These are all open questions and you know what's the role for the old fashioned non parametric models and.",
            "Probabilistic models, so that's it.",
            "Thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, as Aaron mentioned, I'm the director of the new Vector Institute, and so I thought I would use this as an opportunity to tell you the first couple of slides, not about convolution networks, but about vector.",
                    "label": 0
                },
                {
                    "sent": "And then we'll get back the convolution networks.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So vectors independent, independent nonprofit Institute located in the Mars Discovery District.",
                    "label": 1
                },
                {
                    "sent": "It's a nice big building.",
                    "label": 0
                },
                {
                    "sent": "And in Toronto, and it's a fairly new venture, it actually started up just at the end of the summer.",
                    "label": 0
                },
                {
                    "sent": "We had discussions with some guys from a local startup company, the Chief Technical Executive officers there, and they got funding in January and launch just at the end of March.",
                    "label": 0
                },
                {
                    "sent": "So it's very new.",
                    "label": 0
                },
                {
                    "sent": "And the focus of it is on machine learning, research and practice.",
                    "label": 1
                },
                {
                    "sent": "So people.",
                    "label": 0
                },
                {
                    "sent": "Oh let's try.",
                    "label": 0
                },
                {
                    "sent": "There's two mikes.",
                    "label": 0
                },
                {
                    "sent": "Let me see the other ones.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "Turn this one on to that one is fine.",
                    "label": 0
                },
                {
                    "sent": "OK alright good perfect alright so?",
                    "label": 0
                },
                {
                    "sent": "It's on, so it's actually called the Vector Institute for Artificial Intelligence, but we just call it the Vector Institute.",
                    "label": 0
                },
                {
                    "sent": "It's really the name vector comes from the notion that vectors are really important in the kind of work that we do in machine learning.",
                    "label": 0
                },
                {
                    "sent": "As you've heard with lots more about vectors and actually one of the original names that we considered for it.",
                    "label": 0
                },
                {
                    "sent": "Folks know about the Perimeter Institute, which is the Institute for Theoretical Physics in Waterloo.",
                    "label": 0
                },
                {
                    "sent": "So we're going to call it the parameter Institute.",
                    "label": 0
                },
                {
                    "sent": "But then we like the idea of vector, so that's our name for it, and so it's all kinds of machine learning research, ranging from theoretical to practical or well.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compare and these are the people affiliated with it.",
                    "label": 0
                },
                {
                    "sent": "Currently we have mostly faculty members who are at the University of Toronto, Jeff Hinton's, the Chief Scientific Advisor, and I'm the research director and then we have a lot of new hires in Toronto as well, including these three down here.",
                    "label": 0
                },
                {
                    "sent": "Margier Marotte in young Anne Graham.",
                    "label": 0
                },
                {
                    "sent": "Taylor from Guelph is also affiliated with it, so it's not just a UFT venture, but it's in general universities in Ontario or affiliated with it.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ann were hiring, so I thought take this opportunity to a shameless plug.",
                    "label": 1
                },
                {
                    "sent": "With a lot of very smart people here, I'm sure so would be great to consider coming as postdocs or research scientists to vector it's brand new.",
                    "label": 0
                },
                {
                    "sent": "This is this is what it looks like down here, so we're going to move in in October and hopefully look a lot better than that.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested, you can visit Vector Institute dot AI, email that email us, or also tonight there's a special event.",
                    "label": 0
                },
                {
                    "sent": "There's a Toronto night at 6:00 o'clock.",
                    "label": 0
                },
                {
                    "sent": "I think it is.",
                    "label": 0
                },
                {
                    "sent": "Somewhere off site you can get more, or you probably have more information in your in your booklet, and that's with a group from Toronto, including not just vector but CDL, which is like an accelerator RBC an next day.",
                    "label": 0
                },
                {
                    "sent": "I OK enough one.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here, let's talk about convolution networks.",
                    "label": 0
                },
                {
                    "sent": "So I was told as that should really give an introduction to convolution networks.",
                    "label": 0
                },
                {
                    "sent": "I'm sure some people here know them very well.",
                    "label": 0
                },
                {
                    "sent": "I assume some people don't, so I'm going to do a fairly quick summary of that and spend the first maybe half an hour talking about convolutional networks in recent developments in convolutional networks, and then a little bit of a discussion of what's actually being learned.",
                    "label": 1
                },
                {
                    "sent": "I think that's an interesting direction that people are following now as well.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to finish up talking about applications and I'm focusing on the applications that I'm I've been interested in for many years, including things like semantic segmentation, image understanding, an few shot, learning.",
                    "label": 0
                },
                {
                    "sent": "Oak.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and I'm going to in general talk about convolution networks in the context of vision and object recognition, just because that's been one of the traditional focuses of the research in that area.",
                    "label": 0
                },
                {
                    "sent": "But there's tons of other applications, notably in speech and text, but it's more fun to talk about vision for a talk 'cause I can show pretty pictures.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to talk about vision.",
                    "label": 0
                },
                {
                    "sent": "And to start with, we can say, well, people are really good at recognizing shapes.",
                    "label": 1
                },
                {
                    "sent": "It's a really hard problem.",
                    "label": 0
                },
                {
                    "sent": "It turns out and computers are bad at it.",
                    "label": 1
                },
                {
                    "sent": "At least they have been for years.",
                    "label": 0
                },
                {
                    "sent": "We're getting better at it with computers and the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is, why is it hard?",
                    "label": 0
                },
                {
                    "sent": "So here are some of the things that make vision object recognition shape recognition hard.",
                    "label": 0
                },
                {
                    "sent": "You have occlusion, you have issues of scale deformations of the shape.",
                    "label": 0
                },
                {
                    "sent": "The shapes often exist in cluttered environments, changing of lighting and the pose of the objects and viewpoint.",
                    "label": 0
                },
                {
                    "sent": "All these things make object recognition shape recognition quite difficult.",
                    "label": 0
                },
                {
                    "sent": "So these are kind of natural conditions.",
                    "label": 0
                },
                {
                    "sent": "And then there's a question of definition right?",
                    "label": 0
                },
                {
                    "sent": "What is an object?",
                    "label": 0
                },
                {
                    "sent": "And so this is a good exam.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Couple of that right?",
                    "label": 0
                },
                {
                    "sent": "So these would all be what we call chairs, but what makes a chair a chair is a fundamental question, right?",
                    "label": 0
                },
                {
                    "sent": "And so I think people learn that in a natural way, right?",
                    "label": 0
                },
                {
                    "sent": "That we figure out.",
                    "label": 0
                },
                {
                    "sent": "Well, there's a shape question, but there's also this idea of utility, right?",
                    "label": 0
                },
                {
                    "sent": "So somewhere we can park our butt and sit on naturally is called a chair.",
                    "label": 0
                },
                {
                    "sent": "So I think that figuring out what that means is an interesting question that we're getting better at.",
                    "label": 0
                },
                {
                    "sent": "Again, getting computers are better at that, but it's a very hard natural problem.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And is also tons of classes, so cycle psychologist named Earth Biederman identified 10,000 to 30,000 different object classes that exist in some natural sense of what an object classes and there's.",
                    "label": 0
                },
                {
                    "sent": "So there's tons of them, and we're good at those.",
                    "label": 1
                },
                {
                    "sent": "And we're also going to talk about at the end of today is how we learn about new classes.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we're very good at dealing with invariances things like translation, rotation, scaling.",
                    "label": 1
                },
                {
                    "sent": "Some things I was showing before about deformation, contrast, and lighting.",
                    "label": 1
                },
                {
                    "sent": "That, but it's really hard to appreciate just how hard it is and how good we are at it.",
                    "label": 0
                },
                {
                    "sent": "OK, so we don't really have a good way of dealing with a lot.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These things, so let's talk about applying neural Nets to images.",
                    "label": 1
                },
                {
                    "sent": "So you can just do a straightforward application and people did this for years where you would just take an input containing lots of pixels and build a neural network that potentially could have many hidden layers in it.",
                    "label": 0
                },
                {
                    "sent": "So here's the standard neural net that you know about.",
                    "label": 0
                },
                {
                    "sent": "We learned about this week.",
                    "label": 0
                },
                {
                    "sent": "You have input layer, a bunch of hidden layers, and then an output layer, and this is like a fully connected network.",
                    "label": 0
                },
                {
                    "sent": "Every unit connects to every other unit when we're dealing with real images where we have mega pixels in the input.",
                    "label": 0
                },
                {
                    "sent": "Right, it's prohibitively large in terms of the number of weights that come out of the input layer into the first hidden layer, right?",
                    "label": 0
                },
                {
                    "sent": "So there's too many parameters to learn, So what do we do?",
                    "label": 0
                },
                {
                    "sent": "We're going to build in some structure, and this is kind of an interesting, I think philosophical problem that keeps coming up in machine learning, which is how.",
                    "label": 0
                },
                {
                    "sent": "How much do we want to build in structure like we start with the kind of tabular rasa, a blank slate, or do we want to build in some sort of structure, and so there's some people that firmly believe everything should be learned from scratch, and even the people who believe that though.",
                    "label": 0
                },
                {
                    "sent": "Notably, like Jan Lequince is we don't want to build in any kind of structure.",
                    "label": 0
                },
                {
                    "sent": "We want to learn everything right?",
                    "label": 0
                },
                {
                    "sent": "Why would we assume we know something?",
                    "label": 0
                },
                {
                    "sent": "Actually built-in structure into their models and the kinds of structures that are built in a.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gender thing is having local receptive field so you don't have full connectivity, but instead you have a window of number of units in the layer below that connected the first hidden layer.",
                    "label": 0
                },
                {
                    "sent": "So this is an image.",
                    "label": 0
                },
                {
                    "sent": "Every dot here is a different pixel so you get a little window.",
                    "label": 0
                },
                {
                    "sent": "I think that's about 5 by 5 that connects to the first hidden unit in the array in the second layer and I mean the first hidden layer and then the next hidden unit over connects to the another 5 by 5 window that's just shifted by one pixel here.",
                    "label": 0
                },
                {
                    "sent": "So the notion here is that units are arranged.",
                    "label": 0
                },
                {
                    "sent": "The term is topographically so that neighboring units have similar properties.",
                    "label": 1
                },
                {
                    "sent": "Because they have overlapping receptive fields right?",
                    "label": 0
                },
                {
                    "sent": "So the receptive field is this little window in the input space that that unit responds to.",
                    "label": 0
                },
                {
                    "sent": "And Topa graphic connections are very interesting.",
                    "label": 0
                },
                {
                    "sent": "Also from the standpoint of animals, so Topa graphic.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maps are well known in our brain.",
                    "label": 0
                },
                {
                    "sent": "So, for example, we call the Homunculus, which is you can take neurons along what's called the somato sensory strip in the brain.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that neighboring neurons respond to or sensitive to touch in neighboring parts of our bodies.",
                    "label": 0
                },
                {
                    "sent": "So it's interesting you can follow along here, right?",
                    "label": 0
                },
                {
                    "sent": "You have the tongue, the teeth, the gums, the lips, the face, and you can see the body laid out on top of her fingers all the way different parts.",
                    "label": 0
                },
                {
                    "sent": "And so that's.",
                    "label": 0
                },
                {
                    "sent": "Topa graphic Maps, meaning that neighboring neurons are responding to neighboring kinds of inputs.",
                    "label": 0
                },
                {
                    "sent": "In this case, places on the body and it happens both in terms of touch and motor output responses in those areas.",
                    "label": 0
                },
                {
                    "sent": "So that's a Topa graphic map that's common in biology, and it's also been very useful in neural networks.",
                    "label": 0
                },
                {
                    "sent": "So that idea I think inspired people to try these local receptive fields in neural network.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there's another term that's used which is the offset in receptive fields between neighboring units.",
                    "label": 0
                },
                {
                    "sent": "So here we're showing astride of one, which means you take the window and you shift it by one pixel.",
                    "label": 0
                },
                {
                    "sent": "You have a strider, two.",
                    "label": 0
                },
                {
                    "sent": "You shift it by two pixels, so the stride is a kind of hyper parameter that determines the connectivity between one layer and the subsequent layer in the network, right?",
                    "label": 0
                },
                {
                    "sent": "Feel free to ask questions or make comments in general during the.",
                    "label": 0
                },
                {
                    "sent": "When I'm talking.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is a single unit or neuron responding to?",
                    "label": 1
                },
                {
                    "sent": "So here's a simple example.",
                    "label": 0
                },
                {
                    "sent": "Imagine you have a binary image of zeros and ones, and now you have a filter that looks like this.",
                    "label": 0
                },
                {
                    "sent": "What are you doing?",
                    "label": 0
                },
                {
                    "sent": "You're actually laying this filter into.",
                    "label": 0
                },
                {
                    "sent": "If those are the weights that connect to the first hidden unit, then you're going to lay this filter up in this corner, and you're going to multiply each value here by each value down there, and you'll get 1 + 1 + 1 + 1.",
                    "label": 0
                },
                {
                    "sent": "You get a value of four.",
                    "label": 0
                },
                {
                    "sent": "Alright, by laying it up in this corner, if you shifted over one, you're going to get a different value right?",
                    "label": 0
                },
                {
                    "sent": "So every time you shift it and you apply it to the window in the layer below, you'll get a different different value.",
                    "label": 0
                },
                {
                    "sent": "And if we change this filter, then to look somewhat different, so imagine it had ones in this corner, zero in the middle and minus ones on the outside.",
                    "label": 0
                },
                {
                    "sent": "What would that and we what kind of input would that respond to anybody?",
                    "label": 0
                },
                {
                    "sent": "A gradient good so it would respond when you had, for instance, ones along diagonal.",
                    "label": 0
                },
                {
                    "sent": "This way in zeros everywhere else.",
                    "label": 0
                },
                {
                    "sent": "So it's looking for like a line or a gradient in the input alright.",
                    "label": 1
                },
                {
                    "sent": "This set of weights is known as a feature detector or a kernel or a filter.",
                    "label": 0
                },
                {
                    "sent": "OK, those are all terms that are used there, so this is 1 principle that's used in convolution neural networks.",
                    "label": 0
                },
                {
                    "sent": "The idea of local connectivity or local receptive fields.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another one is shared weights, so use many different copies of the same feature detector.",
                    "label": 1
                },
                {
                    "sent": "So the thing I just showed you before with a little block of three by three you use that same thing in each position, so you'd lay it down in across the image and it's called replicated features, so the copies have different positions, so you might put it down here, where each one of these colors represents a different weight, and then you apply it in a different part of the image, again with the same set of weights, so the red connections have all the same weights, the green and the blue as well.",
                    "label": 0
                },
                {
                    "sent": "So this is replicating across space.",
                    "label": 0
                },
                {
                    "sent": "You can also replicate across scale and orientation and people more recently have been trying to do this even though it's a little tricky and expensive to do that they've gotten some success with that and recent neural networks, and so what's the point of replication?",
                    "label": 1
                },
                {
                    "sent": "One thing is that it brings down the number of free parameters in the network.",
                    "label": 0
                },
                {
                    "sent": "You aren't learning separate weights or parameters in every position you're using the same ones everywhere, but also there's this notion that it's picking up on a feature.",
                    "label": 0
                },
                {
                    "sent": "In a position invariant way, right?",
                    "label": 0
                },
                {
                    "sent": "So the same edge we just talked about of ones along the diagonal can occur in many spots in the image, and so you want to apply that same filter in lots of spots in the image.",
                    "label": 1
                },
                {
                    "sent": "And that comes with the notion of statistical notion of stationarity that statistics are actually going to be similar at different image positions.",
                    "label": 0
                },
                {
                    "sent": "So that gives us the definition really of a convolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "It has local receptive fields and shared weights.",
                    "label": 1
                },
                {
                    "sent": "And then typically you're going to have different feature types or kernels, each with its own replicated pool, right?",
                    "label": 0
                },
                {
                    "sent": "So you're going to take the now it's not going to just have one along the diagonal.",
                    "label": 0
                },
                {
                    "sent": "This way you might have a one along the diagonal.",
                    "label": 0
                },
                {
                    "sent": "This way that's another feature type, right?",
                    "label": 1
                },
                {
                    "sent": "So that allows each Patch of the image to be represented in several ways to apply each feature type to every Patch or every little window in the image.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the different feature types look like?",
                    "label": 0
                },
                {
                    "sent": "Here's an example of the kinds of feature detectors, so you might have this little image of this animal's head, and so one is just the identity, so you apply little three by three filter there and convolve it, or run it over the image, apply it in every position.",
                    "label": 1
                },
                {
                    "sent": "What do you get back if for this filter you get back the original image right?",
                    "label": 0
                },
                {
                    "sent": "You're just going to pick out the identity of the center pixel you're going to recover the original image.",
                    "label": 0
                },
                {
                    "sent": "If instead you have one that looks more like the gradient filter we talked about before.",
                    "label": 0
                },
                {
                    "sent": "It's going to look for an edge where it's lighter here and darker there in the image and that turns out to be up here like above the eye.",
                    "label": 0
                },
                {
                    "sent": "An edge detector can go in the other direction.",
                    "label": 0
                },
                {
                    "sent": "There's different forms of edge detectors.",
                    "label": 0
                },
                {
                    "sent": "There's also other feature detectors you can think of as a sharpening filter, so this is an interesting one that has a big value in the middle and negatives around it, and it turns out if you apply that to the image, you get this right, and you can also do various kinds of blurring to the image as well, so that's what you get with different kinds of feature detectors that you can learn for the image.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you had local receptive fields, so let's take if we didn't do this feature.",
                    "label": 0
                },
                {
                    "sent": "This sharing doing the same feature everywhere.",
                    "label": 0
                },
                {
                    "sent": "Let's take a look and do some math so we say if we had 200 by 200 image with 40,000 hidden units and let's say our filters were bigger, they were 10 by 10, not three by three.",
                    "label": 0
                },
                {
                    "sent": "That gives us 4 million parameters.",
                    "label": 0
                },
                {
                    "sent": "And that's really useful if every image had the same pose.",
                    "label": 0
                },
                {
                    "sent": "So for instance, you want to recognize faces, and you've done a good job of registering faces in an image, then it makes sense.",
                    "label": 0
                },
                {
                    "sent": "You don't necessarily want to have convolve your features everywhere.",
                    "label": 0
                },
                {
                    "sent": "You might want to have something specific to particular positions in the image, like the eyes or the mode.",
                    "label": 0
                },
                {
                    "sent": "OK, so you don't necessarily recognize those things everywhere in the image.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "But at the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imagine that in general, you don't assume that your images are registered or they aren't always in the same exact pose.",
                    "label": 0
                },
                {
                    "sent": "Then we're going to do this feature sharing idea, share the same parameters across different locations, and convolve them with these.",
                    "label": 0
                },
                {
                    "sent": "Learn kernels and we're going to get a lot of share of parameter savings.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we're going to get the four million down to the new order of 10,000.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's take a closer look at how we're going to build a convolution network, so we're going to start off with, let's say, a 32 by 32 image, and then we have this three channels, which could be like an image.",
                    "label": 0
                },
                {
                    "sent": "It could be each RGB, each one of those is a different channel in the image, and then we have a set of weights that go to every curve.",
                    "label": 0
                },
                {
                    "sent": "So the feature map or the kernel gets applied.",
                    "label": 0
                },
                {
                    "sent": "2 three by three by let's say 32 by 32 Patch here.",
                    "label": 0
                },
                {
                    "sent": "And that's the input to one of these units.",
                    "label": 0
                },
                {
                    "sent": "In the next level, right?",
                    "label": 0
                },
                {
                    "sent": "And then we activate all of these units.",
                    "label": 0
                },
                {
                    "sent": "We take the, you know, apply the dot product of the filter to the appropriate region in the image and get an input value and then apply a nonlinear activation learned about this in the neural network talk yesterday and then.",
                    "label": 0
                },
                {
                    "sent": "That gives you an output in this area the activation or inactivation as all the activations in this layer is called.",
                    "label": 0
                },
                {
                    "sent": "The feature map lets the term that's used a little confusing as you have feature detectors and you have feature Maps.",
                    "label": 0
                },
                {
                    "sent": "But the feature map is usually the activation of the layer.",
                    "label": 0
                },
                {
                    "sent": "And there's several different hyperparameters for a convolution layer.",
                    "label": 0
                },
                {
                    "sent": "It's the number of filters, alright?",
                    "label": 1
                },
                {
                    "sent": "That's kind of.",
                    "label": 0
                },
                {
                    "sent": "That's the depth of the output volume.",
                    "label": 1
                },
                {
                    "sent": "That's like I was saying of how many different types of filters, how many different types of features we're looking for from this layer to this layer, there's the stride as I mentioned, which is how much how many units apart do we apply the filter spatially that controls the spatial size of the output volume, and then we have the size itself of the filter.",
                    "label": 1
                },
                {
                    "sent": "What's the width and height?",
                    "label": 0
                },
                {
                    "sent": "So those are the hyperparameters of a convolutional layer.",
                    "label": 0
                },
                {
                    "sent": "And then in current.",
                    "label": 0
                },
                {
                    "sent": "Convolution networks, there's an additional off.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Eration called pooling that that happens after the activation map.",
                    "label": 0
                },
                {
                    "sent": "So here we think of it as another layer so you do convolutional layer.",
                    "label": 0
                },
                {
                    "sent": "Then you follow it by a pooling layer and you're going to kind of combine all the filter responses within a window.",
                    "label": 1
                },
                {
                    "sent": "So here's a picture where we can get.",
                    "label": 0
                },
                {
                    "sent": "These will be the feature map, the responses of 64 different types of features in laid out in a 224 by 224 grid.",
                    "label": 0
                },
                {
                    "sent": "So these are all the responses activations in a feature map.",
                    "label": 0
                },
                {
                    "sent": "Pooling can reduce that right by saying, OK, we're going to do is innocence.",
                    "label": 0
                },
                {
                    "sent": "Downsample?",
                    "label": 0
                },
                {
                    "sent": "We're going to take a little windows and do something, some operation to combine them into a single like a window of two by two and do something like and Max.",
                    "label": 0
                },
                {
                    "sent": "Or an average?",
                    "label": 0
                },
                {
                    "sent": "There's different forms of pooling to get a response in this lower dimensional pooled layer here.",
                    "label": 0
                },
                {
                    "sent": "So you think of it.",
                    "label": 0
                },
                {
                    "sent": "So we've done convolution before this got in this and then we do a pooling layer and get responses here so you can see that have the effect of downsample.",
                    "label": 0
                },
                {
                    "sent": "You might have responses that look like this.",
                    "label": 0
                },
                {
                    "sent": "Let's get down to 24 by 224, downsampled to 112 by 112.",
                    "label": 0
                },
                {
                    "sent": "Alright, so for instance, just to make it clear if you do Max pooling with two by two filters in the stride of two, this little window would be replaced by 6 this.",
                    "label": 0
                },
                {
                    "sent": "Window by an 8 etc.",
                    "label": 0
                },
                {
                    "sent": "OK, so the effects of this is to both simplify what information is in the convolutional layer, reduce the dimensionality and gain a kind of robustness with respect to spatial location.",
                    "label": 0
                },
                {
                    "sent": "So you combine the information within that area and replaced by a single value.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We put this all together.",
                    "label": 0
                },
                {
                    "sent": "We do a sequence of these to make it a really deep network where we do, you know, convolution followed by pooling in this.",
                    "label": 0
                },
                {
                    "sent": "In this figure Max pooling and do this several different times.",
                    "label": 0
                },
                {
                    "sent": "Every one of these has sets of filters that are associated with it.",
                    "label": 0
                },
                {
                    "sent": "We're going to train all those weights of filters and then at the end typically we're going to attach some fully connected layers.",
                    "label": 0
                },
                {
                    "sent": "In this case there's a couple of fully connected layers at the end.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to do a classification at the end.",
                    "label": 0
                },
                {
                    "sent": "At the final step into, let's say, 1000 classes here.",
                    "label": 0
                },
                {
                    "sent": "So we have an original image.",
                    "label": 0
                },
                {
                    "sent": "Go through all these different layers.",
                    "label": 0
                },
                {
                    "sent": "With these learn filters.",
                    "label": 0
                },
                {
                    "sent": "Have these dense connections full connections here rather than local receptive fields, followed by a classification, and we want to say cat in this case.",
                    "label": 0
                },
                {
                    "sent": "And there's other choices.",
                    "label": 0
                },
                {
                    "sent": "There's obviously the hyperparameters I mentioned for the convolution layer, those hyperparameters for the pooling layer to like what's the stride?",
                    "label": 0
                },
                {
                    "sent": "What's the window size?",
                    "label": 0
                },
                {
                    "sent": "Will kind of pooling.",
                    "label": 0
                },
                {
                    "sent": "Are we going to use?",
                    "label": 0
                },
                {
                    "sent": "What kind of activation functions, right?",
                    "label": 0
                },
                {
                    "sent": "So we've covered some of that before sigmoid, tanh, H Ray lose lose all these different varieties of reylos these days and then they have to choose a loss function for training it versions of log likelihood or hinge loss train, typically by back prop or SGD.",
                    "label": 0
                },
                {
                    "sent": "So that's.",
                    "label": 0
                },
                {
                    "sent": "Convolution networks in a nutshell.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is maybe the mother of all convolution network.",
                    "label": 0
                },
                {
                    "sent": "So questions yes.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or is it?",
                    "label": 0
                },
                {
                    "sent": "Supply request cold colors.",
                    "label": 0
                },
                {
                    "sent": "So typically that's a choice that's made, but typically a filter would be 3 by width by height.",
                    "label": 0
                },
                {
                    "sent": "If it's all color, so it would respond to all three colors.",
                    "label": 0
                },
                {
                    "sent": "That would be the first level of filters, right?",
                    "label": 0
                },
                {
                    "sent": "I'll say something about that in a minute that doesn't have to be.",
                    "label": 0
                },
                {
                    "sent": "That's another architectural choice.",
                    "label": 0
                },
                {
                    "sent": "So you could be local in the in the input channels as well.",
                    "label": 0
                },
                {
                    "sent": "I was wondering if you do pooling then you invite you increase the number of feature Maps that comes after that and for example, let's say you have a 1015 months.",
                    "label": 0
                },
                {
                    "sent": "Then you can filter Max 223 July.",
                    "label": 0
                },
                {
                    "sent": "I know that the number of filters that you have correspond to the more feature monthly drug coverage player, but the idea is how do you choose?",
                    "label": 0
                },
                {
                    "sent": "How do you go from lower number of each month to hire one?",
                    "label": 0
                },
                {
                    "sent": "Do you randomly choose from the previously layers way to convolve?",
                    "label": 0
                },
                {
                    "sent": "I mean which which amounts to convolve.",
                    "label": 0
                },
                {
                    "sent": "So wait so?",
                    "label": 0
                },
                {
                    "sent": "From the previously awaiting for growth, so I think so.",
                    "label": 0
                },
                {
                    "sent": "I think that's somewhat connected to the previous question a little bit, so imagine we have.",
                    "label": 0
                },
                {
                    "sent": "This might not be the best picture for it.",
                    "label": 0
                },
                {
                    "sent": "Let's try this.",
                    "label": 0
                },
                {
                    "sent": "That one I meant to get that one.",
                    "label": 0
                },
                {
                    "sent": "There we go.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this case, so the idea is that this is like 1 feature that is going to look at all three feature Maps in the all three channels in the layer below Anna Anna window of that and it's going to have to learn set of weights for that.",
                    "label": 0
                },
                {
                    "sent": "Another feature that's going to be looking at the same set of three by three, 3 by 32 by 32 will have different weights, so there will be a different kind of feature.",
                    "label": 0
                },
                {
                    "sent": "So every level.",
                    "label": 0
                },
                {
                    "sent": "So there's I think you were saying how many different features are there at this level?",
                    "label": 0
                },
                {
                    "sent": "That's kind of an arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Architectural decision how many different feature Maps are going to be at every level?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we took a look at this right, it's arbitrarily determined that what we wanted to have in this case were.",
                    "label": 0
                },
                {
                    "sent": "So this one had 55 different ones.",
                    "label": 0
                },
                {
                    "sent": "Then we had two, 20, seven, 1313 and 13.",
                    "label": 0
                },
                {
                    "sent": "Those are kind of architectural decisions about.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that answer your question.",
                    "label": 0
                },
                {
                    "sent": "Maybe not know, OK?",
                    "label": 0
                },
                {
                    "sent": "Consider using.",
                    "label": 0
                },
                {
                    "sent": "User.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Behind this, for example at Ilya Love Pen feature Maps, then you become maximally.",
                    "label": 0
                },
                {
                    "sent": "Then you want to increase the number of feature Maps in the next convolution layer already.",
                    "label": 0
                },
                {
                    "sent": "Let's say I want to increase the 25th or not.",
                    "label": 0
                },
                {
                    "sent": "Then I know I should have 20 different things.",
                    "label": 0
                },
                {
                    "sent": "That's already which which I use to convert what's coming from the previous layer, yes?",
                    "label": 0
                },
                {
                    "sent": "The previous layer now want to expand it to 20 feature match.",
                    "label": 0
                },
                {
                    "sent": "How do I choose appointee filters already which I initialize you randomly or something?",
                    "label": 0
                },
                {
                    "sent": "How do I choose which of the feature Maps coming from the previous layer at home?",
                    "label": 0
                },
                {
                    "sent": "But you might choose them randomly, so the idea is that we're going to just think of every layer is like an independent decision.",
                    "label": 0
                },
                {
                    "sent": "So this case we have 27 different feature Maps and in this case we're going to say there's 27 different thing about the feature Maps become the channels for the next level.",
                    "label": 0
                },
                {
                    "sent": "OK, so then the 13 different feature types here.",
                    "label": 0
                },
                {
                    "sent": "Each one of them is going to look at all 27 of those feature Maps in the layer below that was the question answered the previous question, and again they can make a choice that is not going to do that, but typically when they think of it.",
                    "label": 0
                },
                {
                    "sent": "That way you're going to each one of these is going to respond to all different types of responses in the layer below all the feature types in the layer below, but we can take it offline if that's not clear yet.",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "Not useful connected players.",
                    "label": 0
                },
                {
                    "sent": "Anymore.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And the sound that does not impact the.",
                    "label": 0
                },
                {
                    "sent": "Quality of protection.",
                    "label": 0
                },
                {
                    "sent": "That might wanna be using the number of parameters, so what's what's your opinion on that, yeah?",
                    "label": 0
                },
                {
                    "sent": "Right, so let me I'll get into kind of more modern things in a minute and get back to that question, OK?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good.",
                    "label": 0
                },
                {
                    "sent": "So as I was saying, kind of mother of all these things.",
                    "label": 0
                },
                {
                    "sent": "In a sense, the original when the original convolution networks was Lynette developed in the really mostly in the 80s on the Clinton colleagues where you tried it out on the MNIST data set handwritten digits and had the main ideas were in there.",
                    "label": 0
                },
                {
                    "sent": "This local to global idea of so you think about what's happening, you're taking the beginning, the local receptive fields, the next level, when even when it has a local receptive field.",
                    "label": 0
                },
                {
                    "sent": "It's still local.",
                    "label": 0
                },
                {
                    "sent": "In the level below, which was combining across different images, different receptive fields in the input.",
                    "label": 0
                },
                {
                    "sent": "So in general the receptive fields are going to be growing from level to level and that is going to create more global processing, right?",
                    "label": 0
                },
                {
                    "sent": "I'll get back to that in a second.",
                    "label": 0
                },
                {
                    "sent": "And it also, but it does keep some sort.",
                    "label": 0
                },
                {
                    "sent": "Of course positional information in it.",
                    "label": 0
                },
                {
                    "sent": "The techniques we talked about, where weight sharing, where the units are arranged in feature map, and so this is 1 version.",
                    "label": 1
                },
                {
                    "sent": "There's all kinds of versions of Lynette where they had convolutions followed by subsampling, which is really a kind of pooling.",
                    "label": 0
                },
                {
                    "sent": "And it's several of these, and then had some fully connected levels.",
                    "label": 0
                },
                {
                    "sent": "And then did the output and got results that were remarkable at the time of 5% test error on this hard data set.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that was one of the original ones.",
                    "label": 0
                },
                {
                    "sent": "And so that's my.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quick summary of convolution networks.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about recent developments.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I guess five years ago is really talk about modern CNN's coming on the scene.",
                    "label": 1
                },
                {
                    "sent": "So Alex net, developed by Alex Kryszewski at Toronto.",
                    "label": 0
                },
                {
                    "sent": "Where he just kind of add on his own, he said, well, let's try putting together all kinds of these things in different ways to try to solve the image.",
                    "label": 0
                },
                {
                    "sent": "Net challenge with much harder data set then.",
                    "label": 0
                },
                {
                    "sent": "The name list more like 1000 classes instead of 10.",
                    "label": 0
                },
                {
                    "sent": "So what he did is come up with an architecture that had various things, like convolutions and other kinds of pooling, like local contrast normalization, as well as Max pooling and came up with lot through lots of tinkering and gaining intuition overtime.",
                    "label": 0
                },
                {
                    "sent": "A particular sequence of operations of combinations of convolutions and pulling that work very well on the image net data set.",
                    "label": 0
                },
                {
                    "sent": "So much so that it kind of beat the current state of the art by about five 5%.",
                    "label": 0
                },
                {
                    "sent": "Total number of parameters were 60,000,000 and that sounds like a lot, but it wasn't that much.",
                    "label": 0
                },
                {
                    "sent": "If you take into account that how big the images were, as well as all the connections that are in here.",
                    "label": 0
                },
                {
                    "sent": "And that's largely through weight sharing.",
                    "label": 0
                },
                {
                    "sent": "Got it to 60,000,000 because it was doing really 832 million operations.",
                    "label": 0
                },
                {
                    "sent": "When interesting historical tidbit is, the original net was actually more complicated than this.",
                    "label": 0
                },
                {
                    "sent": "It was split into two different things.",
                    "label": 0
                },
                {
                    "sent": "Two different streams in a way, and that was because he was working on a GPU where the kind of on chip memory wasn't big enough to hold all the the network itself.",
                    "label": 0
                },
                {
                    "sent": "So there was two different streams that came out, so there's another kind of parallel stream that was going on here.",
                    "label": 0
                },
                {
                    "sent": "I'll get back to that in a second, so.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was Alex Net and that really started a whole wave of interest in other kinds of convolution networks or improvements on.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convolution networks and so next notable one would be the so-called VGG network.",
                    "label": 0
                },
                {
                    "sent": "A couple years later where they added more layers.",
                    "label": 0
                },
                {
                    "sent": "So here it went to you, inserted a bunch many more layers and trained it up to an again improved on the image net significantly.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main lesson there was you could add more layers.",
                    "label": 0
                },
                {
                    "sent": "Another thing was work with somebody just mentioned about residual networks so that you could not just add layers but also try different kinds of definition of what is happening inside a layer.",
                    "label": 0
                },
                {
                    "sent": "So this was an interesting idea where it was inspired by the LTM gating units, so I think you already covered recurrent networks.",
                    "label": 1
                },
                {
                    "sent": "Little yeah, so those are you already heard about those and the idea was just like they combine vanishing gradients in the LS TM using this kind of forget.",
                    "label": 0
                },
                {
                    "sent": "Gate right?",
                    "label": 0
                },
                {
                    "sent": "Think of it like a like a reset.",
                    "label": 0
                },
                {
                    "sent": "So we want to do something now.",
                    "label": 1
                },
                {
                    "sent": "We wanted to combat vanishing gradients in a very deep network.",
                    "label": 0
                },
                {
                    "sent": "So there's a drawback to going very deep is that you want to get your gradients to go through all these levels?",
                    "label": 0
                },
                {
                    "sent": "And that was for years why people thought you couldn't train very deep networks as the gradients would just disappear?",
                    "label": 0
                },
                {
                    "sent": "And So what they did was come with the idea.",
                    "label": 0
                },
                {
                    "sent": "Well what we want to do is think about what's happening in a network as not just doing your standard weights followed by regular activation followed by weights and really activation.",
                    "label": 0
                },
                {
                    "sent": "But you also add this additional input where you're just going to.",
                    "label": 0
                },
                {
                    "sent": "Copy the identity so it's like a simple kind of autoregression where you really just going to.",
                    "label": 0
                },
                {
                    "sent": "Now you're going to add not only the output here is going to be not only your functions that you created along this stream, but you're going to also add in the identity and so the residual network means that what this guy is really modeling is the residual of what's not already happening in the accounted for by the level above.",
                    "label": 0
                },
                {
                    "sent": "So this little module was then inserted into train up very deep networks.",
                    "label": 0
                },
                {
                    "sent": "So here you can see VG with 19.",
                    "label": 0
                },
                {
                    "sent": "Over here is like you can do a 34 layer that's plain or going to 34 layer that has these little residual modules inserted inside.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then an elaboration of high weight of residual networks of so called highway networks, where rather than just copying the input like you did here, so rather than just computing a function like this of the input in the weights and plus the copy is, you're going to actually have a little gating network here.",
                    "label": 0
                },
                {
                    "sent": "That's going to determine which parts you're going to copy and which ones you aren't, and you're going to do it in an input dependent way, so that's the important ideas that you're going to decide.",
                    "label": 0
                },
                {
                    "sent": "So think of this is a more complicated gate combination here where you're going to get an decide well for this input we're going to.",
                    "label": 0
                },
                {
                    "sent": "Do more copying of the identity of the identity and less of the raylo right, or vice versa.",
                    "label": 0
                },
                {
                    "sent": "So that's really what makes the highway network different than the residual network.",
                    "label": 0
                },
                {
                    "sent": "It's dynamically determining when the data gets passed through versus transformed, and the general conclusion of all both of these, though, is that the shortcut connections where you're going to skip players are really useful for deep networks, and that actually had been around for many years.",
                    "label": 0
                },
                {
                    "sent": "Like people that use shortcut connections in deep networks for a long time, but not with this specific kind of module idea, they just thrown them in and now.",
                    "label": 1
                },
                {
                    "sent": "Showed get a big win for them.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so just to get a sense of how deep so we had six so Alex.",
                    "label": 1
                },
                {
                    "sent": "Net had about 10 layers.",
                    "label": 0
                },
                {
                    "sent": "Then we went up to 16 layers with VGG 16 Google Net went beyond that.",
                    "label": 0
                },
                {
                    "sent": "Resnet had 50 and then up to 152 OK so we're getting very very deep.",
                    "label": 0
                },
                {
                    "sent": "So the question is how?",
                    "label": 0
                },
                {
                    "sent": "What improvement do we get out of this?",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One graph to show that you know version of the Alex Net was getting the top five error on image Net was, let's say around 20%.",
                    "label": 0
                },
                {
                    "sent": "The cafe implementation of it.",
                    "label": 0
                },
                {
                    "sent": "Then versions of VGG.",
                    "label": 0
                },
                {
                    "sent": "We're getting that down below.",
                    "label": 0
                },
                {
                    "sent": "Closer to 17 and down the 15, the Google net got closer to 10 and then the 16 layer ones closer to VG with seven and then res Nets are pushing it down closer to 7 1/2%.",
                    "label": 0
                },
                {
                    "sent": "And so if we scale it all based on the original one and say how much more accurate are we getting?",
                    "label": 0
                },
                {
                    "sent": "We've gotten to three times the accuracy in a short amount of time just a couple of years.",
                    "label": 0
                },
                {
                    "sent": "So maybe I'll ask you a question.",
                    "label": 0
                },
                {
                    "sent": "So what are the tradeoffs for doing that?",
                    "label": 0
                },
                {
                    "sent": "So you've gotten better?",
                    "label": 0
                },
                {
                    "sent": "What are the tradeoffs?",
                    "label": 0
                },
                {
                    "sent": "What have you?",
                    "label": 0
                },
                {
                    "sent": "Some of the potential problems?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Heavier models OK?",
                    "label": 0
                },
                {
                    "sent": "What is heavier mean?",
                    "label": 0
                },
                {
                    "sent": "Lots of memory.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's memory issues.",
                    "label": 0
                },
                {
                    "sent": "Right, right?",
                    "label": 0
                },
                {
                    "sent": "So I'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "So potentially you think there might be a lot of lot less, a lot more parameters.",
                    "label": 0
                },
                {
                    "sent": "More data OK, more computation good.",
                    "label": 0
                },
                {
                    "sent": "So what is their consequences of let's say more data and more computations?",
                    "label": 0
                },
                {
                    "sent": "So more computation you might think is that what's bad about more computation?",
                    "label": 0
                },
                {
                    "sent": "That means this is burning up energy.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sorry.",
                    "label": 0
                },
                {
                    "sent": "Less.",
                    "label": 0
                },
                {
                    "sent": "Parallelizable, OK, 'cause it's deeper, potentially OK, good.",
                    "label": 0
                },
                {
                    "sent": "So back with the more computation idea.",
                    "label": 0
                },
                {
                    "sent": "So one thing is that you think it might get slow.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so let's take a guess how much lower was this guy?",
                    "label": 0
                },
                {
                    "sent": "The Resnet 152 compared to the cafe Alex?",
                    "label": 0
                },
                {
                    "sent": "How much time slower?",
                    "label": 0
                },
                {
                    "sent": "Yeah, running time.",
                    "label": 0
                },
                {
                    "sent": "How many people thinks slower?",
                    "label": 0
                },
                {
                    "sent": "How many people think faster?",
                    "label": 0
                },
                {
                    "sent": "OK, so the actual answer is 5 times slower alright?",
                    "label": 1
                },
                {
                    "sent": "So this is the speed that is the number of images per second.",
                    "label": 0
                },
                {
                    "sent": "Second all on a Titan X went from, so if you at the scale that again relative to this is a cafe implementation of Alex versus Resonant 152 is about five times slower.",
                    "label": 0
                },
                {
                    "sent": "But as somebody said before, it is slower.",
                    "label": 0
                },
                {
                    "sent": "It has many more computations to go through, but that's not the only metric that matters.",
                    "label": 0
                },
                {
                    "sent": "It's also a question of like how many parameters are there, and it turns out that.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The number of parameters are really about the same, so it's jumped around between these, but you can see roughly if you just look at Cafe de Alex there versus the resonant that they're almost the same.",
                    "label": 1
                },
                {
                    "sent": "So because of all of the parameter sharing and they also there was a trick in the one thing that's interesting is that if you go back and look at this that in terms of the slowness, right that the people were saying you think it might not be that slow.",
                    "label": 0
                },
                {
                    "sent": "Well, if you look at the VGG one that was considerably slower than.",
                    "label": 0
                },
                {
                    "sent": "Then the Alex Net and resonate is actually almost on par with the VGG net, right?",
                    "label": 0
                },
                {
                    "sent": "And that's because Fiji has done did some things like they.",
                    "label": 0
                },
                {
                    "sent": "Had a smaller window of how many.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry that the resident shows a smaller window of what features they were going to respond to.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that ended up actually speeding up things a lot, so there's a lot of things you can do in the architecture to make things go faster, such as choosing more local fields in terms of the channels or features from one level to the next back there.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is actually for running.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so other recent developments in their own, so that's just kind of getting deeper.",
                    "label": 0
                },
                {
                    "sent": "That's one thing.",
                    "label": 0
                },
                {
                    "sent": "There's other questions about how you combine things from level levels, so there's been a bunch of work recently on so-called normalization, so one form of this is batch normalization that's become very popular.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you want to standardize the response of every feature channel within a batch.",
                    "label": 1
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "So here's an illustration of that is that you have.",
                    "label": 0
                },
                {
                    "sent": "This will be the responses of the feature map different feature Maps.",
                    "label": 0
                },
                {
                    "sent": "Are shown in this dimension and then we have width by height right?",
                    "label": 0
                },
                {
                    "sent": "So this is the tensor innocence of feature map responses.",
                    "label": 0
                },
                {
                    "sent": "And then you're going to choose one of the channels and compute the moments.",
                    "label": 0
                },
                {
                    "sent": "What is the mean response in the variance response?",
                    "label": 0
                },
                {
                    "sent": "Subtract off the mean divided by the variance, and that's going to be your new response shown down here to make it more explicit.",
                    "label": 0
                },
                {
                    "sent": "So one thing I should say is I don't have many equations.",
                    "label": 0
                },
                {
                    "sent": "I thought for something like this I wanted to keep things more at a picture level, but.",
                    "label": 0
                },
                {
                    "sent": "There's a few equations, so this is one of them, so this is the output of the J TH unit on the NTH example and so.",
                    "label": 0
                },
                {
                    "sent": "You're going to subtract.",
                    "label": 0
                },
                {
                    "sent": "This is the average, right?",
                    "label": 0
                },
                {
                    "sent": "So this is averaging over all of the examples in batch B, right?",
                    "label": 0
                },
                {
                    "sent": "And they take the average response?",
                    "label": 0
                },
                {
                    "sent": "That's the mean response.",
                    "label": 0
                },
                {
                    "sent": "Subtract that off of the response on a particular example N, and divide by the variance.",
                    "label": 0
                },
                {
                    "sent": "And that's going to be the output here.",
                    "label": 0
                },
                {
                    "sent": "One thing to note is this is usually applied after you've done the activation before you've applied the Raylo activation.",
                    "label": 0
                },
                {
                    "sent": "Reply this and do the normalization right and then then apply the raylo and an learn the bias.",
                    "label": 0
                },
                {
                    "sent": "OK so batch normalization turned out to have a very good effect for a lot of learning.",
                    "label": 0
                },
                {
                    "sent": "Deep networks.",
                    "label": 0
                },
                {
                    "sent": "There's been other forms of normal, sorry question back there.",
                    "label": 0
                },
                {
                    "sent": "Sorry, say it again.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Peter and Gamma, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the bias that's added afterwards.",
                    "label": 0
                },
                {
                    "sent": "Alright, so you're going to learn some bots some specific bias, and so these are just parameters that are added in to the hyperparameters to tune like how much of the bias versus the scale of this overall right?",
                    "label": 0
                },
                {
                    "sent": "So this is 1 and these are just standard variables, but you can scale them.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's more recently, so last year it was a paper that proposed layer normalization, so rather so one thing that you're doing in batch normalization is you're normalizing by all of the examples in a particular batch of training.",
                    "label": 0
                },
                {
                    "sent": "So then you can think about.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe you don't want to normalize by examples, but rather within a particular layer.",
                    "label": 0
                },
                {
                    "sent": "So that's what their layer normalization does.",
                    "label": 0
                },
                {
                    "sent": "It standardizes the responsive units of each feature channel within a layer.",
                    "label": 1
                },
                {
                    "sent": "OK, she's doing this for a particular feature channel, and you're saying so.",
                    "label": 0
                },
                {
                    "sent": "It's the same type of equation we had before, but the difference is now when you're computing the mean.",
                    "label": 0
                },
                {
                    "sent": "For example, you're summing over all of the units K within a particular layer, the same layer as unit J. OK.",
                    "label": 0
                },
                {
                    "sent": "So that mean is calculated by.",
                    "label": 0
                },
                {
                    "sent": "So for ZSJ the JT unit looks at the calculates the mean of all based on all units in the same layer, and the variance is also calculated layer wise.",
                    "label": 0
                },
                {
                    "sent": "And this turned out to be a good results in recurrent networks.",
                    "label": 1
                },
                {
                    "sent": "Not as good in convolution networks.",
                    "label": 0
                },
                {
                    "sent": "And this.",
                    "label": 0
                },
                {
                    "sent": "People have developed other schemes, like various normalizers on weights or spacially.",
                    "label": 0
                },
                {
                    "sent": "And this is 1 area where in some ways that people doing neuroscience and studying computational neuroscience of we're ahead of what was going on in convolution networks because they had various schemes like divisive normalization and subtractive normalization.",
                    "label": 0
                },
                {
                    "sent": "They had studied for years, and this thought that divisive normalization in particular is a kind of Canonical computation that people have proposed is useful for all kinds of things like redundancy reduction or image compression, for attention for all kinds of different things in the brain.",
                    "label": 0
                },
                {
                    "sent": "People proposed of divisive normalization is relevant.",
                    "label": 0
                },
                {
                    "sent": "So this is a.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paper we had last year, this year, and I clear we looked at the vistas.",
                    "label": 0
                },
                {
                    "sent": "Normalization is another kind of normalization scheme that could be applied.",
                    "label": 0
                },
                {
                    "sent": "So this is a picture.",
                    "label": 0
                },
                {
                    "sent": "Will give you an idea of trying to compare these different ones so batch normalization you can think of your these are all the examples.",
                    "label": 0
                },
                {
                    "sent": "The different features and then you have examples within, so this is across a layer this way and then the each plane is a different example and then so the idea is that batch normalization is that you're adding up over all the examples in the batch, so the yellow ones layer normalization is you're adding up over doing a separate normalization for every layer.",
                    "label": 0
                },
                {
                    "sent": "OK so these are all the features within a given layer.",
                    "label": 0
                },
                {
                    "sent": "These are the features in a different layer.",
                    "label": 0
                },
                {
                    "sent": "And then the vicious normalization is something that's combining those two.",
                    "label": 0
                },
                {
                    "sent": "It's A kind of layer normalization and its spatial OK, so it's only normalizing within a region.",
                    "label": 0
                },
                {
                    "sent": "It's not normalizing across the whole layer.",
                    "label": 0
                },
                {
                    "sent": "And you're going to put them all in the same form.",
                    "label": 0
                },
                {
                    "sent": "Batch normalization layer normalization and divisive normalization.",
                    "label": 0
                },
                {
                    "sent": "The key being that you can think of it as just a spatial restriction, like a special kind of layer normalization and one other thing we added was this extra term in here, this Sigma squared.",
                    "label": 0
                },
                {
                    "sent": "It's kind of a smoothing term, so rather than just dividing by the variance, you're going to buy the variance plus some smoothing term Sigma.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we can think of that as a kind of bias in the normalizer, and it turns out that that is a very.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important effect, so if you think of the activation function like in a standard raylo, it looks like this as you change the bias.",
                    "label": 0
                },
                {
                    "sent": "What it does is it tends to make that reylos saturate so it gives you an interesting new kind of activation function and it turns out that that had very good effects across.",
                    "label": 0
                },
                {
                    "sent": "We tried it on a bunch of different datasets, both on convolution networks and recurrent networks.",
                    "label": 0
                },
                {
                    "sent": "Tried the same thing, and so here's some accuracy on cifar.",
                    "label": 0
                },
                {
                    "sent": "For example with our batch normalization.",
                    "label": 0
                },
                {
                    "sent": "You can get pretty good results.",
                    "label": 0
                },
                {
                    "sent": "This is with the smoother.",
                    "label": 0
                },
                {
                    "sent": "So even if you just add the smoothing to these other kinds of normalizations, you get a win.",
                    "label": 0
                },
                {
                    "sent": "So in some cases the divisive normalization which did the spatial thing actually was a win.",
                    "label": 0
                },
                {
                    "sent": "Sometimes times the other one.",
                    "label": 0
                },
                {
                    "sent": "So this is just an interesting dimension to think about when you're doing forms of normalization.",
                    "label": 0
                },
                {
                    "sent": "You think about whether you want to do batchwise layer wise or something that's more spatial and or some combination of those things, OK?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So another question in.",
                    "label": 0
                },
                {
                    "sent": "Current networks in the network design is the choice of the receptive fields, he said.",
                    "label": 0
                },
                {
                    "sent": "Like how big should the receptive fields be?",
                    "label": 0
                },
                {
                    "sent": "That's another parameter.",
                    "label": 0
                },
                {
                    "sent": "You want to choose so they would ship to field.",
                    "label": 0
                },
                {
                    "sent": "The definition is what's the image region that influences a particular response of a unit or a neuron.",
                    "label": 0
                },
                {
                    "sent": "And the idea is anything outside that receptive field is not visible to the neuron.",
                    "label": 1
                },
                {
                    "sent": "So if you think about it, if you have a big large image structure and the unit has a small receptive field that can't really respond to the full image structure, OK, so it can't analyze that full image structure.",
                    "label": 0
                },
                {
                    "sent": "And so there's this bidding this notion that what's happening as you go deeper and deeper in a network is that the effective receptive fields are getting larger and larger, and that's a natural thing, right?",
                    "label": 0
                },
                {
                    "sent": "If you think about you have one unit that's responding in one region of the image, and another unit that's responding in a different region of the image, and you're deep in the network, and you're actually receiving input from both of those units.",
                    "label": 0
                },
                {
                    "sent": "Then you're responding to a wide range in the image, so there's this natural thing when you're doing the local receptive fields with some stride that the receptive fields should grow and grow as you proceed down the layers of the network.",
                    "label": 0
                },
                {
                    "sent": "Is that clear everybody?",
                    "label": 0
                },
                {
                    "sent": "So, so the receptive field should grow, so we actually did some analysis.",
                    "label": 0
                },
                {
                    "sent": "This was an IP paper last year.",
                    "label": 0
                },
                {
                    "sent": "We had.",
                    "label": 0
                },
                {
                    "sent": "What is the actual receptive field?",
                    "label": 0
                },
                {
                    "sent": "So there's this notion of how the receptive field grows that you can get just from the architecture just from knowing how the units connect from one level to another level.",
                    "label": 0
                },
                {
                    "sent": "And we called it the effective receptive fields and that's the region in the input that contains some input that doesn't have, not that has a significant impact or non negligible impact, non legible.",
                    "label": 0
                },
                {
                    "sent": "We measured is within 2 standard deviation of whatever the center pixels impact was.",
                    "label": 1
                },
                {
                    "sent": "And so for convolution networks we can measure impact as the scale of the partial derivatives, right?",
                    "label": 1
                },
                {
                    "sent": "That's how you measure how much impact it has and what we found was a little surprise.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing is that the effective receptive fields were a lot smaller than we thought.",
                    "label": 0
                },
                {
                    "sent": "Alright, so you can do this by analyzing things and 1st, we found that there's a Gaussian distribution in the effective receptive fields, and it grows as on the order of the square root of N over the number of layers in deep convolution networks.",
                    "label": 0
                },
                {
                    "sent": "And the theoretical receptive field based on stride and other things should grow as order N. Alright, so there's and so relative to the full theoretical receptive field.",
                    "label": 0
                },
                {
                    "sent": "It's occupying 1 / sqrt N What you think that the receptive field should grow from layer to layer and so this is just some pictures of how this 1 / sqrt N looks like as you go from layer to layer and what this receptive field.",
                    "label": 0
                },
                {
                    "sent": "Depth of field changes and this is just the beginning with the uniform weights with random weights or random weights followed by the raylo.",
                    "label": 0
                },
                {
                    "sent": "So here we're talking about the initial effective receptive fields of units in a deep network.",
                    "label": 0
                },
                {
                    "sent": "But after training the effective receptive fields tend to grow.",
                    "label": 0
                },
                {
                    "sent": "So this is like we train up a network on Cifar 10 and do the same type of analysis.",
                    "label": 0
                },
                {
                    "sent": "So before training it would look like this and after training it grows right and then another data set.",
                    "label": 0
                },
                {
                    "sent": "If we train it up on Cam, did it's effectively much smaller before training.",
                    "label": 0
                },
                {
                    "sent": "After training it grows some as well, so it's an interesting phenomenon that.",
                    "label": 0
                },
                {
                    "sent": "That the receptive fields tend to grow.",
                    "label": 0
                },
                {
                    "sent": "So this brings up the question is, well, maybe you want to build in your convolution network some way that would tend to have it be a larger effective receptive field at the beginning to enable it to learn better, right?",
                    "label": 0
                },
                {
                    "sent": "So this could be a limiting factor in how.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It learns.",
                    "label": 0
                },
                {
                    "sent": "So how could we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, one way is to initial change our initialization and diffuse instead of just having a kind of random initialization uniformly in the field.",
                    "label": 0
                },
                {
                    "sent": "Is that you can make it so that tends to have higher weights towards the periphery of the filters, and that diffuses the power to the periphery.",
                    "label": 0
                },
                {
                    "sent": "You can also replace a large feature bank with a sequence of smaller ones that is also another way of gaining larger receptive fields you can do, or you can sparsified the connections randomly or group.",
                    "label": 1
                },
                {
                    "sent": "So this is just an illustration.",
                    "label": 0
                },
                {
                    "sent": "This comes back to a question earlier.",
                    "label": 0
                },
                {
                    "sent": "If you didn't.",
                    "label": 0
                },
                {
                    "sent": "If you don't connect to all of the features in this level, but instead you connect to groups of them and you do it in a sequence of ways, and it turns out that that enlarges the effective receptive field.",
                    "label": 0
                },
                {
                    "sent": "Right, and it also reduces the complexity, so the complexity here is shown by.",
                    "label": 0
                },
                {
                    "sent": "You know that this number of operations you're doing from one level to another level has to do with the height of the filters divided by the stride.",
                    "label": 0
                },
                {
                    "sent": "The width, the filters divide times the number of input channels and the number of output channels, so that's really effectively how many operations you're doing from one level to the next in the convolution network and the number of parameters right is height by width by.",
                    "label": 0
                },
                {
                    "sent": "Channels by number of output channels, but if you do this thing where you group them and you make them somewhat sparse, you've saved a lot on complexity where depending on how much how you do your grouping, but your connectivity will look more like this, and it turns out that it will also effectively in larger receptive fields.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's another kind of method that people are looking at these days for how to get receptive fields to be effectively larger in convolution networks.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that was always came about.",
                    "label": 0
                },
                {
                    "sent": "Recent developments.",
                    "label": 0
                },
                {
                    "sent": "Now is a question about can we really understand what's being learned in one of these networks?",
                    "label": 1
                },
                {
                    "sent": "And for that I want to talk about it.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two things, what do we really know about the networks?",
                    "label": 1
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "What's the relevance to or from biology for these networks?",
                    "label": 0
                },
                {
                    "sent": "So there's been.",
                    "label": 0
                },
                {
                    "sent": "So that's a question.",
                    "label": 0
                },
                {
                    "sent": "A lot of people are studying.",
                    "label": 0
                },
                {
                    "sent": "Visualizations is a third thing, and then a little bit about theory and analysis.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that the original convolution networks were somewhat inspired by visual neuroscience, so hubl in visal the Nobel Prize for coming up with hypothesis that the primary visual cortex forms very simple representations, and then the next level of representation combines those simple representations to form what are called complex cells, right?",
                    "label": 0
                },
                {
                    "sent": "That's actually illustrated this well.",
                    "label": 0
                },
                {
                    "sent": "This shows up.",
                    "label": 0
                },
                {
                    "sent": "But here we have primary visual cortex of the input comes through the eye, goes the primary visual cortex goes through the lateral geniculate nucleus through the primary visual cortex, and then up through different levels of cortex is shown here.",
                    "label": 0
                },
                {
                    "sent": "Up through this is primary visual cortex V1, and then this stream is called the ventral, or the object stream where he goes to V2V3V4 and up to inferotemporal cortex, which is meant to represent actual objects or shapes.",
                    "label": 0
                },
                {
                    "sent": "So this inspired a lot of the work in the original convolution networks.",
                    "label": 0
                },
                {
                    "sent": "And there were actually like roughly 30 different areas now is thought to be more areas than that where this V1 and V2 are the primary cortical areas that are the inputs.",
                    "label": 0
                },
                {
                    "sent": "So this was the been around for a long time and inspired in fact.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work that predated Lynette, so this was Fukushima's Neo con Agra, Cognat Ron and you can see that had a lot of features that were present in Lynette so it had the local connectivity from one level to the next and this is a diagram from his paper so you had retina that went to what he would call the LGN.",
                    "label": 0
                },
                {
                    "sent": "Then it went from simple cells to complex cells, lower high, complex, higher order hypercomplex up through every level, and at the end form something that would recognize objects.",
                    "label": 0
                },
                {
                    "sent": "Known as the grandmother cell would recognize her grandmother.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is Fukushima's original think, so I think so.",
                    "label": 0
                },
                {
                    "sent": "This predates Lanette by 10 years or so and I think was an inspiration for it as well.",
                    "label": 0
                },
                {
                    "sent": "It had a lot of the same properties of local receptive fields and this deep architecture.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, but we don't want to put Saints push this too far.",
                    "label": 0
                },
                {
                    "sent": "I mean there's some similarities between convolution networks in biology, like the layered architecture in his local connectivity.",
                    "label": 1
                },
                {
                    "sent": "There's not really much evidence for shared weights in the biology, I mean, so this is an example in the right now where you have local connectivity from layer to layer inside the retina that comes out, but there's tons of other difference, not just shared weights.",
                    "label": 0
                },
                {
                    "sent": "We talked about.",
                    "label": 0
                },
                {
                    "sent": "One thing you know?",
                    "label": 0
                },
                {
                    "sent": "Potentially there's some operations like the visit normalization that are thought to be happening in.",
                    "label": 0
                },
                {
                    "sent": "Biological networks that may also be happening in convolutional networks be useful in convolution networks, right?",
                    "label": 0
                },
                {
                    "sent": "So there was 1 interesting study done a few years ago that tried to take this comparison a little more closely, so this study was interesting.",
                    "label": 0
                },
                {
                    "sent": "They took images that looked like this.",
                    "label": 0
                },
                {
                    "sent": "Don't know if you can see it from where you're sitting, so this is a car at a funny angle with a weird background to kind of ocean background.",
                    "label": 0
                },
                {
                    "sent": "Then they took fruits so they had random choice of background.",
                    "label": 0
                },
                {
                    "sent": "Random choice of that.",
                    "label": 0
                },
                {
                    "sent": "I think there were several different classes and they could be an arbitrary poses on some arbitrary, some randomly chosen background.",
                    "label": 0
                },
                {
                    "sent": "So this is an elephant floating above the world.",
                    "label": 0
                },
                {
                    "sent": "And they presented this both to monkeys and recorded with multi electrodes and parts of the monkey brain.",
                    "label": 0
                },
                {
                    "sent": "So they're picking up signals from lots of neurons simultaneously.",
                    "label": 0
                },
                {
                    "sent": "For one of these images, and they also fed these images into what were the currently current best convolution networks at the time and want to compare things.",
                    "label": 0
                },
                {
                    "sent": "And so how do you compare in that case?",
                    "label": 0
                },
                {
                    "sent": "So what they did was they said, well, let's see how accurate you would be if you looked at the response is building a little classifier, you can take the responses of the.",
                    "label": 0
                },
                {
                    "sent": "Monkey neurons, for example, in some layer of the visual cortex I showed, you take those outputs from the monkey neurons and then build a little linear classifier on top of it, like kernel classifiers.",
                    "label": 0
                },
                {
                    "sent": "What they use do the same thing for the convolution network, do layer by layer in the convolution network, come up with a bunch of features, take those features an feed them to some linear SVM and the question is how accurate is the feature the feature classification done on the features in the network.",
                    "label": 0
                },
                {
                    "sent": "Versus features that were in the monkeys cortex, and how analogous were they all right?",
                    "label": 0
                },
                {
                    "sent": "So we have tried a few different models.",
                    "label": 0
                },
                {
                    "sent": "They tried ones that were V like modeled after V1, the lower left, lower level that are like edge detectors V2 that are like the complex cells that combine edges and then these were some other models that the authors were interested in, like ones based on hierarchical ands and ORS for example.",
                    "label": 0
                },
                {
                    "sent": "And then these were the deep networks there was the Alex Net.",
                    "label": 0
                },
                {
                    "sent": "There was a version updated, improved version of the Alex Net Buys Island Fergus that changed the Heights of the hyperparameters.",
                    "label": 0
                },
                {
                    "sent": "And then over here, this Gray bar is recordings from V4 Cortex.",
                    "label": 0
                },
                {
                    "sent": "So V4 just to go back to this picture along the visual hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Along this stream, V4 is up here, so it's a few steps away from V1 and V2.",
                    "label": 0
                },
                {
                    "sent": "And then they also recorded from Inferotemporal Cortex, which is closer to actually write with the object recognition happens and what they found was that the inferotemporal cortex.",
                    "label": 0
                },
                {
                    "sent": "If you did classification based on that on this task, you get 60% accuracy or so, and the best deep networks were similar.",
                    "label": 1
                },
                {
                    "sent": "OK, there was like somewhat analogous to inferotemporal Cortex.",
                    "label": 0
                },
                {
                    "sent": "If you recorded from V4 Cortex, the information wasn't as president wasn't as obvious.",
                    "label": 0
                },
                {
                    "sent": "It didn't do as well.",
                    "label": 0
                },
                {
                    "sent": "So I think this is more not the same that the actual processing that's going on, but more kind of seeing how much information is present in a network to do this.",
                    "label": 0
                },
                {
                    "sent": "How much information is present in the brain to do these kinds of classifications?",
                    "label": 0
                },
                {
                    "sent": "So it's an interesting study along those lines.",
                    "label": 0
                },
                {
                    "sent": "OK, so the.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One that's about the deep networks in biology.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about visualization.",
                    "label": 0
                },
                {
                    "sent": "So visualization something in the old days in neural networks what we had was so called Hinton diagrams, named after Jeff Hinton.",
                    "label": 0
                },
                {
                    "sent": "So you'd say, OK, well, what are the weights into a unit?",
                    "label": 0
                },
                {
                    "sent": "And typically you were training on amnestied on digits and so you had black and white inputs.",
                    "label": 0
                },
                {
                    "sent": "And you can say, well, the weights could be described by, you know.",
                    "label": 0
                },
                {
                    "sent": "Well, so that typically the weights you just want to think of how positive or negative await is so positive weight is white and negative weight is black and the big how big the square is, how big the magnitude of that weight, right?",
                    "label": 0
                },
                {
                    "sent": "So you could look at the weights.",
                    "label": 0
                },
                {
                    "sent": "This way we always looked at Hinton diagrams and sometimes you could try to when we called it.",
                    "label": 0
                },
                {
                    "sent": "Reading the tea leaves trying to make sense of what was going on inside a machine learning inside of neural network.",
                    "label": 0
                },
                {
                    "sent": "More recently, in the last few years I think there's been a lot of progress on understanding what's going on in networks.",
                    "label": 0
                },
                {
                    "sent": "And so it's an interesting branch of research led some insight into convolution networks.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you take Alex.",
                    "label": 0
                },
                {
                    "sent": "Net, the first layer of Alex.",
                    "label": 1
                },
                {
                    "sent": "Net, you get these kinds of the filters that were being learned in the first convolution layer.",
                    "label": 0
                },
                {
                    "sent": "And so you'll see that there's interesting split here, even though why there's this split.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Right, so we had this split like I mentioned before was because it couldn't all fit on one.",
                    "label": 0
                },
                {
                    "sent": "The chip wasn't big enough for the memory, so we had to do two different ones, so this is more of like a historical anachronism that we have these two different kinds of filters.",
                    "label": 0
                },
                {
                    "sent": "Nice to say that there was this kind of split that it found, but it didn't found it because that way the system was run.",
                    "label": 0
                },
                {
                    "sent": "But in any case it's interesting you got this kind of high frequency black and white here and low frequency color down here for the most part.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the go beyond that first layer.",
                    "label": 1
                },
                {
                    "sent": "First layer makes sense 'cause you're looking at images.",
                    "label": 0
                },
                {
                    "sent": "How are you going to visualize what's happening?",
                    "label": 0
                },
                {
                    "sent": "You can't really make sense of the weights very well, 'cause now you're looking at weights on top of these feature Maps, and So what xylan Fergus did a few years ago as they came up with a method where they used, looked at what images activated a neuron a lot.",
                    "label": 0
                },
                {
                    "sent": "And then they try to go back and back project to the image space to say what was happening in the image space that led to that high activity.",
                    "label": 0
                },
                {
                    "sent": "And they used a technique called deconvolution seed convolutions on the way up deconvolution's on the way down, I'll say something more about the convolutions in a minute, but what they did is they chose the 9 images that for a given neuron the 9 images that excited at the most.",
                    "label": 0
                },
                {
                    "sent": "So these would be the nine.",
                    "label": 0
                },
                {
                    "sent": "Let's say for this neuron up here and then these over here are when you did this deconvolution and look back at what was happening in image space.",
                    "label": 0
                },
                {
                    "sent": "This is what the image look like that corresponded to the activity.",
                    "label": 0
                },
                {
                    "sent": "Of the unit when it was shown this input OK, you can think of it as you do convolutions.",
                    "label": 0
                },
                {
                    "sent": "Activate the unit.",
                    "label": 0
                },
                {
                    "sent": "2D convolutions come back and create an image that corresponds to us is a form of reconstruction in a way of what's happening in the image, right?",
                    "label": 0
                },
                {
                    "sent": "So what you see here is at the second level, so each one of these three by three blocks is a different unit, and what you see is that the responding to oriented edges in some circles kind of like what you thought from the Neo Cognat ran right?",
                    "label": 0
                },
                {
                    "sent": "You want to go from simple edges to combinations of edges.",
                    "label": 0
                },
                {
                    "sent": "The things like extended curves, corners all these types of things.",
                    "label": 0
                },
                {
                    "sent": "So this was the theory for a long time.",
                    "label": 0
                },
                {
                    "sent": "You have this sequence as high.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are Archaea features go to layer three and you're seeing that again?",
                    "label": 0
                },
                {
                    "sent": "It's looking for combinations.",
                    "label": 0
                },
                {
                    "sent": "Interesting combinations now of color and shape, so this is kind of orange ready.",
                    "label": 0
                },
                {
                    "sent": "Things that are have this curve in them and that's what seems to be responding to.",
                    "label": 0
                },
                {
                    "sent": "So that's.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By doing this you get a little bit of sense, at least of what's happening in the different layers of the network.",
                    "label": 0
                },
                {
                    "sent": "And in some cases it's a little surprising, so let's take this one for example over here.",
                    "label": 0
                },
                {
                    "sent": "Unless you can see that very well.",
                    "label": 0
                },
                {
                    "sent": "So there's are this one, maybe trying to find one that's a little interesting.",
                    "label": 0
                },
                {
                    "sent": "So maybe OK, here's a good one that has some variety to it, right?",
                    "label": 0
                },
                {
                    "sent": "There's some women in it.",
                    "label": 0
                },
                {
                    "sent": "There's dogs, there's cars.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's like a real mix of different things, so it's not very clear what's happening in terms of the representation.",
                    "label": 0
                },
                {
                    "sent": "But if you look, it seems like you know here it's looking at in general, that things that look a little bit face like, Alright see the face, the dog, the face of this person in the wheel itself.",
                    "label": 0
                },
                {
                    "sent": "The hubcap looks a little bit like.",
                    "label": 0
                },
                {
                    "sent": "A face, right?",
                    "label": 0
                },
                {
                    "sent": "There's other cases where it's picking up on something like here it's looks like it's picking up on the background.",
                    "label": 0
                },
                {
                    "sent": "It's actually picking up on things like the grass, so there's.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting representations there.",
                    "label": 0
                },
                {
                    "sent": "Another thing that can be done to analyze representations is do a kind of ablation study so you can take the input and remove or mask out part of the input and try that in different areas and look at how that affects the responses so the other one was trying to find what is maximally responding.",
                    "label": 0
                },
                {
                    "sent": "Accidentally, making this unit respond and now you can say well, if we subtract this part of the input or Max it out, how does that affect given units respond?",
                    "label": 0
                },
                {
                    "sent": "So this is an example where.",
                    "label": 0
                },
                {
                    "sent": "You know this is a little mask applied over here.",
                    "label": 0
                },
                {
                    "sent": "An applied over here and what you see and this is a heat map of showing when you apply the mask in a position.",
                    "label": 0
                },
                {
                    "sent": "How much did it affect the class?",
                    "label": 0
                },
                {
                    "sent": "So it said that the in this case the class Pomeranian was very affected, so blue is it means it had a big effect when the mask was applied in the middle, so that affected that output unit a lot and not we anywhere else.",
                    "label": 0
                },
                {
                    "sent": "Similarly here the true label car wheel was affected when the mask was applied over here.",
                    "label": 0
                },
                {
                    "sent": "And not as much elsewhere, so it gives you some insight into which part of the input is Rep is important for the activity of the unit.",
                    "label": 0
                },
                {
                    "sent": "In this case of the class, but you could do that at different levels in the network as well.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's just looking at networks and trying to do some analysis you could.",
                    "label": 0
                },
                {
                    "sent": "One thing it would be nice to do and this is kind of a longstanding aim, at least in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Neural networks is to have find part based representations, so you'd like to learn of the system, learn parts.",
                    "label": 1
                },
                {
                    "sent": "So somewhere in the intermediate representation you'd like to say you know, can we represent for a person, represent a nose for a person, for example, different kinds of nose is different in kind of viewpoint, invariant way, right in position invariant way for example.",
                    "label": 0
                },
                {
                    "sent": "So we actually did some work at NIPS.",
                    "label": 0
                },
                {
                    "sent": "The paper last year where we did clustering along in the as we built this convolution network.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we did.",
                    "label": 0
                },
                {
                    "sent": "Is clustering along the way to say we would like to replace groups of activities of neurons with a single cluster.",
                    "label": 0
                },
                {
                    "sent": "And if you do this in a spatial clustering, what we found is that so that now what we're going to do is say.",
                    "label": 0
                },
                {
                    "sent": "All of the the same cluster can occur in different locations.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're clustering across space and finding patterns that occur in a location invariant way, and we did.",
                    "label": 0
                },
                {
                    "sent": "We found that we actually learn things that did correspond roughly to parts, so this is.",
                    "label": 0
                },
                {
                    "sent": "Example of birds where you can see that this would be a unit in that all the examples that make a particular cluster respond, you can see it's responding to something that looks like the head of a bird.",
                    "label": 1
                },
                {
                    "sent": "In general, not always right.",
                    "label": 0
                },
                {
                    "sent": "So kind of sometimes gets a wing, right?",
                    "label": 0
                },
                {
                    "sent": "So so the question is, can this is one step along this way of trying to find ideally a representation that forms parts somewhere in the intermediate representations of a big convolution network.",
                    "label": 0
                },
                {
                    "sent": "OK, this was work done by by Renji who somewhere here in the audience I think.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And another interesting direction in terms of visualization is analyzing and analyzing the representation.",
                    "label": 0
                },
                {
                    "sent": "So this is been very popular these days where you can start off with a random image and then start changing the image and a gradient ascent way so that you say well what is.",
                    "label": 0
                },
                {
                    "sent": "How can we change the image to maximize the activation of this unit so you take a unit anywhere in the in the network and compute the gradient of the image with respect to that activity and follow it so that you want to move the image and directions that make that unit most active.",
                    "label": 0
                },
                {
                    "sent": "Again, you can do that for classes, so you can save for the image class Flamingo.",
                    "label": 0
                },
                {
                    "sent": "Let's find images that are maximally going to maximize the response of the Flamingo unit or the Pelican Unit.",
                    "label": 0
                },
                {
                    "sent": "Or you can do that for units within layers and you form these interesting patterns.",
                    "label": 0
                },
                {
                    "sent": "So one conclusion from this that's important is that if you just start from noisy images and do this gradient descent, you typically get fairly difficult to interpret things, and so this has been followed up by a lot of work and.",
                    "label": 0
                },
                {
                    "sent": "Adversarial networks that you'll hear about where you try to fool the network by doing something very similar.",
                    "label": 0
                },
                {
                    "sent": "But originally this work was done, but for visualization purposes to try to understand what's going on in the network.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that natural image priors play an important role where you want to say, let's find an image that not only maximally activates that unit, but also looks like a natural image.",
                    "label": 1
                },
                {
                    "sent": "OK, so the best methods these days combine natural image priors with these kind of.",
                    "label": 1
                },
                {
                    "sent": "Gradient descent in the unit activity.",
                    "label": 0
                },
                {
                    "sent": "OK, there's a whole sequence of work on that.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in terms of theory, there's been also a whole lot of work done.",
                    "label": 0
                },
                {
                    "sent": "James Martin's done.",
                    "label": 0
                },
                {
                    "sent": "Some interesting work has been work here in Montreal, Yoshua colleagues on theory of convolution, neural networks.",
                    "label": 0
                },
                {
                    "sent": "And I'm just going to highlight a particular recent paper from Tommy Pojo's Group, where the idea was going to compare a shallow and a deep network.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a shallow network, and here's a deep network, so both the shallow in the deep network are universal approximators of functions.",
                    "label": 1
                },
                {
                    "sent": "Let's say of eight variables here.",
                    "label": 0
                },
                {
                    "sent": "But if you have a compositional function, then the deep network provides a better approximation for compositional functions, so there's been a lot of intuition about this.",
                    "label": 1
                },
                {
                    "sent": "This paper actually goes and and has some theorems and proofs of it must have been completely have my head around the proofs yet, but I can tell you what their findings are, and their findings are that one way to think about it.",
                    "label": 0
                },
                {
                    "sent": "Is that the deep network?",
                    "label": 0
                },
                {
                    "sent": "Has this structure, like here this kind of binary tree like structure and it requires even though that they're going to both be universal approximators?",
                    "label": 0
                },
                {
                    "sent": "The deep network requires fewer trainable parameters to achieve the same accuracy, so this is like the distance or the accuracy of the shallow versus the deep network, and R is some control on how much how accurate you want it to be in.",
                    "label": 1
                },
                {
                    "sent": "The difference is that the deep network has a.",
                    "label": 0
                },
                {
                    "sent": "Negative R / 2 exponent and the shallow network has a negative R / D. Parameter in it alright.",
                    "label": 0
                },
                {
                    "sent": "And so it turns out that this is.",
                    "label": 0
                },
                {
                    "sent": "D is the number of.",
                    "label": 0
                },
                {
                    "sent": "The number of examples.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry the number of variables and so this scales poorly with respect to the number of variables as opposed to this one, so it's many fewer trainable parameters.",
                    "label": 0
                },
                {
                    "sent": "As you grow these things.",
                    "label": 0
                },
                {
                    "sent": "And the main finding is, so it's kind of interesting says that the.",
                    "label": 1
                },
                {
                    "sent": "Target function is if that function is scalable.",
                    "label": 0
                },
                {
                    "sent": "So the same thing applies across different scales and also shift invariant, right?",
                    "label": 0
                },
                {
                    "sent": "So position invariant then these deep networks are natural approximators for those things, and again that fits your intuition right, which is that if it makes sense to be grouping parameters this way, right?",
                    "label": 0
                },
                {
                    "sent": "So this network is not going to be very good at picking up long range connections between X1 and X8 the way this one is right, but if your natural function.",
                    "label": 0
                },
                {
                    "sent": "Is shift invariant?",
                    "label": 0
                },
                {
                    "sent": "Then it's not important to pick up long range connections between X1 and X8.",
                    "label": 0
                },
                {
                    "sent": "Alright, so the idea is that as you might expect, deep convolution networks are very good at font at learning things when there are has this property that the shift invariant and that there's somewhat scale invariant as well, it kind of begs the question though, so that is a lot of what people have found success on right?",
                    "label": 0
                },
                {
                    "sent": "So they found success on vision that has largely has some shift in variance and some scale invariants, but it also has been a lot of success for convolution networks on other areas.",
                    "label": 0
                },
                {
                    "sent": "That aren't don't necessarily have that property.",
                    "label": 0
                },
                {
                    "sent": "Like all kinds of text, things that don't even think that text has the same kind of scale invariants or shift in variance, right?",
                    "label": 0
                },
                {
                    "sent": "So again, it's so the theory and practice are a little bit different here, but I think this is 1.",
                    "label": 0
                },
                {
                    "sent": "The notable thing here is that at least matches our intuitions or give some proofs of the intuitions that deep networks, deep convolution networks are more natural approximators than shallow ones.",
                    "label": 0
                },
                {
                    "sent": "For certain classes of functions.",
                    "label": 0
                },
                {
                    "sent": "OK, so one other bit of.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Analysis I think that's interesting was people's up.",
                    "label": 0
                },
                {
                    "sent": "This is a paper from I clear this year that looked at what kind of representations are being formed in very deep networks, and so they were interested in the fact that if you take a deep like highway or Resnet residual network and that you can lesion that layers like get rid of some of the layers or shuffle some of the layers and that seems to have a fairly minimal effect in a lot of these, right?",
                    "label": 1
                },
                {
                    "sent": "So you didn't have that much of an effect.",
                    "label": 0
                },
                {
                    "sent": "By doing these things, and that's a little puzzling if you think of the Canonical view.",
                    "label": 0
                },
                {
                    "sent": "I've been talking about, you know where you start from lower level and vision like V1V2 up to higher level in vision and you're getting these more complicated edges to combinations of edges to parts to objects, right?",
                    "label": 0
                },
                {
                    "sent": "This nice compositional feature hierarchy.",
                    "label": 0
                },
                {
                    "sent": "Then in that case, if you got rid of a layer, then it seemed like they have disastrous effects.",
                    "label": 0
                },
                {
                    "sent": "Alright, but they found though is that other people found was that if you get rid of those, some layers that doesn't have too much of effect, and so the thinking is that they can now analyze it and said you can think of what's going on inside these residual or highway networks is that they're really kind of finding a new representation and then iteratively refining it and then find that you do that for several layers, and then your next batch of layers is going to get a new representation and then a sequence of layers to refine it.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a picture on it, you can see it from where?",
                    "label": 0
                },
                {
                    "sent": "Here's one picture to say, OK.",
                    "label": 0
                },
                {
                    "sent": "This is a one layer network.",
                    "label": 0
                },
                {
                    "sent": "This is a three layer network that's going to form 3 different representations along the way, and what the what these residual networks style are doing is instead taking this initial representation and then refining, refining it and then passing it on.",
                    "label": 0
                },
                {
                    "sent": "Alright, so it can be called 152 layers, but it's really many fewer effective layers of new representations, so they drew this picture.",
                    "label": 0
                },
                {
                    "sent": "They say, well, there's all this stuff going on inside a block, and then it goes through this stage, and then there's a dimensionality change you get to new features and then refine them.",
                    "label": 0
                },
                {
                    "sent": "And they had underlying, so this unrolled, iterative estimation.",
                    "label": 1
                },
                {
                    "sent": "There's an equation for it here that's saying, like the so this is some feature that's being formed AI at layer I, and the idea is that each of the sub layers in that block that index by K the expected value of them is all zero relative to AI, so they're kind of iteratively refining that feature AI, and then they did some empirical work to show that that was the case.",
                    "label": 1
                },
                {
                    "sent": "They identified in a deep network one of these highway networks.",
                    "label": 0
                },
                {
                    "sent": "Or residual networks and said OK, let's look at what's the estimation error of some particular variable variable.",
                    "label": 0
                },
                {
                    "sent": "In that level they identified variable like the average activity and then looked at the estimation error and found that the average estimation error was very small.",
                    "label": 0
                },
                {
                    "sent": "You can see that you know some variance, but still the mean is 0.",
                    "label": 0
                },
                {
                    "sent": "So it's really kind of four levels of new representations.",
                    "label": 0
                },
                {
                    "sent": "In this case, iteratively refine.",
                    "label": 0
                },
                {
                    "sent": "So I think that's an interesting analysis begging the question of, you know, when we're having deep networks were really how?",
                    "label": 0
                },
                {
                    "sent": "When we have something that deep, what kinds of representations are having are happening at every one of those levels?",
                    "label": 0
                },
                {
                    "sent": "How much of it is a new representation versus taking a representation and refining the activity?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the last thing I want to talk about are applications of convolution networks and I'm going to talk about 3 in particular.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, one semantic segmentation, and that's something that I've been interested in for many years, so this is a figure I dug up from an old paper of mine from 2004 where we had a semantic segmentation problem, and.",
                    "label": 0
                },
                {
                    "sent": "We had a convolution network classifier at that point that predicted the pixel labels alright in that convolution network had three layers, sigmoid units and use some weight decay as a regularizer, and what you see here is some images of animals in the hand labeled.",
                    "label": 1
                },
                {
                    "sent": "So in that case we had the hand labeled grad student zooming.",
                    "label": 0
                },
                {
                    "sent": "Hey, had the hand labeled the images, we didn't.",
                    "label": 0
                },
                {
                    "sent": "There were no labeled images at the time and there were as such there were only 100 images that were labeled 60 for training and.",
                    "label": 0
                },
                {
                    "sent": "Ready for test.",
                    "label": 0
                },
                {
                    "sent": "Images were 80 by 1:20 and you can see the classifier did OK, but not so good there wasn't that much data.",
                    "label": 1
                },
                {
                    "sent": "So then we utilized the CRF conditional random field on top to clean it up and then it got pretty good performance.",
                    "label": 0
                },
                {
                    "sent": "At the time there were several different classes in this data set.",
                    "label": 0
                },
                {
                    "sent": "There was another data set with from the British Aerospace that also had like 8 classes and similar numbers of training examples and you compare that to what's going on now though example that's been popular for awhile and.",
                    "label": 0
                },
                {
                    "sent": "In semantic segmentation, right, we want to assign every pixel to a particular label.",
                    "label": 0
                },
                {
                    "sent": "There's 80 different categories instead of seven.",
                    "label": 0
                },
                {
                    "sent": "There's 200,000 images with 1.2 million instances, right?",
                    "label": 0
                },
                {
                    "sent": "So the amount of data has grown a lot, and people are using the kinds of convolution networks that we talked about.",
                    "label": 0
                },
                {
                    "sent": "But the convolution networks are not only getting better, but I'm not only getting bigger with more data, but they also have some interesting techniques.",
                    "label": 0
                },
                {
                    "sent": "So one time.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And before was upsampling or or deconvolution.",
                    "label": 0
                },
                {
                    "sent": "So what happens when you have a standard convolution network is that you do this local connectivity and pooling is that you're downsampling.",
                    "label": 0
                },
                {
                    "sent": "You're kind of getting lower resolution representations along the way, and if you want to predict dense pixel labels instead of it, and found that it was very useful to use upsampling.",
                    "label": 1
                },
                {
                    "sent": "So you want to make sure that you stay high resolution alright, and so in predict able to predict everything at once rather than predicting a single pixel the way we were doing in our original work, single pixel at a time you want to predict things at multiple pixels simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So to do that you can do.",
                    "label": 1
                },
                {
                    "sent": "You can do the fractional stride, so that's one way of doing upsampling.",
                    "label": 0
                },
                {
                    "sent": "So rather than taking the same receptive field and shifting over by one, if you shifted over by 1/2 right and do that each time you're actually going to upsample and have more responses at the level above.",
                    "label": 1
                },
                {
                    "sent": "That's a simple way of doing it.",
                    "label": 0
                },
                {
                    "sent": "Another way that's been more recent is called dilated Convolutions, and that one.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you're going to take a filter like this and you can dilate it kind of spread it out to look like this, and that's a dilation of stride one or stripe to take the filter and spread it out and apply that.",
                    "label": 0
                },
                {
                    "sent": "And people have gotten good results with Upsampling using this kind of convolutions.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now another one is you can do think of deconvolution.",
                    "label": 0
                },
                {
                    "sent": "So I mentioned this before in the context of the work on predicting what was happened, visualizing what's going on in images.",
                    "label": 0
                },
                {
                    "sent": "If you think of deconvolution as a kind of convolution, transpose.",
                    "label": 1
                },
                {
                    "sent": "So this is the original convolution where you have this matrix that looks like you think of a convolution matrix you're applying to input X as a kind of banded matrix like this.",
                    "label": 0
                },
                {
                    "sent": "If you can transpose that right, then what you're going to do is get output, apply at the extra get output.",
                    "label": 0
                },
                {
                    "sent": "This higher dimensional than the input originally, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the deconvolution ID.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And people have applied this in a number of ways more recently.",
                    "label": 0
                },
                {
                    "sent": "So there's one thing called you network where you also have connections along the way.",
                    "label": 0
                },
                {
                    "sent": "I've gotten very good results for semantic segmentation from that, and then this is just a straight convolution network followed by deconvolution.",
                    "label": 0
                },
                {
                    "sent": "So these are some of the most recent results in semantic segmentation.",
                    "label": 0
                },
                {
                    "sent": "Do a great job using both deep convolution networks with lots of data.",
                    "label": 0
                },
                {
                    "sent": "I mean deep networks with lots of data and various forms of deconvolution.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's two more quick things I can tell you about image understanding and few shot learning, and this is some recent research.",
                    "label": 0
                },
                {
                    "sent": "Mostly the image understanding is the work of Jamie Kiros in our group and.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Deep networks, one thing that's been case in deep networks.",
                    "label": 0
                },
                {
                    "sent": "So before I give you this example is that one of the lessons that have been learned is that you can take a deep convolution network kind of cut it off at some level and it forms very useful features that are useful in a variety of tasks.",
                    "label": 0
                },
                {
                    "sent": "So you can kind of think of it as you're chaining up a deep network with other things or transferring it to other other kinds of tasks, and this has been really useful in the case of.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image understanding in particular.",
                    "label": 0
                },
                {
                    "sent": "So here I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "You know we take images and text and embed them together, so this is an example where you have an image and you have a caption and you're going to bed them into some joint space, and so the image you're going to get this embedding in this joint space or embedding you think of it, just mapping the image through a deep convolution network.",
                    "label": 0
                },
                {
                    "sent": "The final level isn't classification now it's some feature map an whatever the dimensionality is of that feature map.",
                    "label": 0
                },
                {
                    "sent": "That's this being illustrated in this Blue Square in the middle here.",
                    "label": 1
                },
                {
                    "sent": "So you've mapped the image.",
                    "label": 0
                },
                {
                    "sent": "Through a deep convolution network, each image gets a point in this.",
                    "label": 0
                },
                {
                    "sent": "In this space we can apply a similar type of operation to take a sentence and map it to some point in this space too.",
                    "label": 0
                },
                {
                    "sent": "So the point is that both the image and the text are being mapped to some common feature space.",
                    "label": 0
                },
                {
                    "sent": "So these are the kinds of feature vectors that we get out of it, and the training, in this case, an image captioning.",
                    "label": 0
                },
                {
                    "sent": "The idea in the training is that you want a caption that belongs to an image to be nearby in this space, and so each caption with this image should be nearby.",
                    "label": 0
                },
                {
                    "sent": "In captions with that should be far away from images that they don't belong to, and so we use a simple kind of ranking objective to achieve that, where the ranking objective is going to say well you want to sum over all the images.",
                    "label": 0
                },
                {
                    "sent": "And look at all the different captions that can go with it.",
                    "label": 0
                },
                {
                    "sent": "You want to say that the.",
                    "label": 0
                },
                {
                    "sent": "Should be near to the so this is like the target caption for this image should be close, so it should have a you want to minimize this.",
                    "label": 0
                },
                {
                    "sent": "You want to have.",
                    "label": 0
                },
                {
                    "sent": "This would be a high score and the score for all the other captions should be low.",
                    "label": 0
                },
                {
                    "sent": "In case you want to push it apart from other captions, bring it nearer to the caption that it should be close to do the same thing for the and do the reverse for the text.",
                    "label": 0
                },
                {
                    "sent": "Bring the text close to the caption that it should be.",
                    "label": 0
                },
                {
                    "sent": "I mean text close to the image that it should be close to that is paired with and far away from the others.",
                    "label": 0
                },
                {
                    "sent": "So it's a simple ranking objective that's being used to.",
                    "label": 0
                },
                {
                    "sent": "Train up the embeddings that are being applied both to the images and to the text, right?",
                    "label": 0
                },
                {
                    "sent": "And then how can you test this?",
                    "label": 0
                },
                {
                    "sent": "Will you test this by I can give you an image and you can just look around in this space and just retrieve the caption.",
                    "label": 0
                },
                {
                    "sent": "That's the closest.",
                    "label": 0
                },
                {
                    "sent": "Right, and so if it's not image that wasn't used in training, you're saying well, what caption that was seen in training would be the closest caption for this particular image, and you could do the same thing for the other side, you could say here's some new caption We haven't seen before.",
                    "label": 0
                },
                {
                    "sent": "Let's embed that caption, Find the closest image to that caption.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so we did ranking experiments on the Flickr datasets, and each image has five different descriptions and we're both doing image annotation.",
                    "label": 1
                },
                {
                    "sent": "That is, finding the the image.",
                    "label": 0
                },
                {
                    "sent": "That's the caption that's closest to the given image, and vice versa.",
                    "label": 0
                },
                {
                    "sent": "Finding the images close into a given captions.",
                    "label": 0
                },
                {
                    "sent": "And you can compute things like recall if you have it, you know what the right catch the right captions in there with how often is the right one found OK, and so that's something that's a retrieval one.",
                    "label": 0
                },
                {
                    "sent": "But there's another approach that you can use.",
                    "label": 0
                },
                {
                    "sent": "We're going to now take a convolution network and pair it up, not with the convolution network for text in one for images.",
                    "label": 0
                },
                {
                    "sent": "Instead, we want to do is combine a convolution network with a recurrent network, and this now the aim is to create a new caption for an image generated caption, not retrieve a caption, but generate a new one.",
                    "label": 1
                },
                {
                    "sent": "And we're going RNN for that.",
                    "label": 0
                },
                {
                    "sent": "Question so.",
                    "label": 0
                },
                {
                    "sent": "Things that are close but not necessarily in the tray.",
                    "label": 0
                },
                {
                    "sent": "What is the?",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "So you mean the retrieval setting?",
                    "label": 0
                },
                {
                    "sent": "We can only retrieve if you have an image we can only retrieve the ones that have already been embedded.",
                    "label": 0
                },
                {
                    "sent": "We aren't so.",
                    "label": 0
                },
                {
                    "sent": "I have something super similar.",
                    "label": 0
                },
                {
                    "sent": "You could use some sort of like Glover bed.",
                    "label": 0
                },
                {
                    "sent": "Some other word vector embedding.",
                    "label": 0
                },
                {
                    "sent": "Is that something that's interesting and or?",
                    "label": 0
                },
                {
                    "sent": "Yeah, some people certainly will.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think that's on the kind of text embedding side where you can say OK. Well, how are we going to embed the text?",
                    "label": 0
                },
                {
                    "sent": "You can embed it with Glover and better with other things, and I think there is an interesting question.",
                    "label": 0
                },
                {
                    "sent": "Can you generalize to new new text that way?",
                    "label": 0
                },
                {
                    "sent": "But I think the generation thing is more, I think I think more interesting.",
                    "label": 0
                },
                {
                    "sent": "'cause now you are trying to do retrieval, but you're really trying to generate something novel.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the idea is again, we're going to take a convolution network, and in this case we're going to create this common space and then on that's what's happening on the top part and then at the bottom part can use a LTM right to take the caption and embedded in this space of the final activity vector of activities in the LTM is this space.",
                    "label": 1
                },
                {
                    "sent": "OK, well we'll start with some good results and some not so good results.",
                    "label": 0
                },
                {
                    "sent": "So, so this is the idea that you can generate sentences with.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parts of speech.",
                    "label": 0
                },
                {
                    "sent": "And use parts of speech to jet so you have a recurrent network like an L STM that's generating a caption and you can.",
                    "label": 0
                },
                {
                    "sent": "You can kind of constrain what you're doing with parts of.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each and so.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you're going to bed the image using a compliment and then condition the language model on the embedding and given a part of speech string, generate sentences that have that particular parts of speech that you can say you know that you want it to be.",
                    "label": 1
                },
                {
                    "sent": "Let's say a verb next or a noun next, or various things like that, and then you can get outputs that have that particular part part of speech.",
                    "label": 0
                },
                {
                    "sent": "And generated description and score how well that description does repeat it many times and take it.",
                    "label": 1
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Higher scoring one, so some good results we get with generation.",
                    "label": 0
                },
                {
                    "sent": "So a car is parked in the middle of nowhere so these are generated not by retrieval but by actually generation, right little boy with a bunch of friends on the street.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some failure types we get that are kind of interesting.",
                    "label": 1
                },
                {
                    "sent": "Two birds are trying to be seen in the water.",
                    "label": 1
                },
                {
                    "sent": "Can't really count them, but it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's kind of reasonable.",
                    "label": 1
                },
                {
                    "sent": "It's a giraffe and a field, so it had a real problem with gender.",
                    "label": 0
                },
                {
                    "sent": "So this goes back to what happened.",
                    "label": 0
                },
                {
                    "sent": "With Vector we had a demo with this when we had the launch and we had the Minister, the Economics minister for Canada.",
                    "label": 0
                },
                {
                    "sent": "We had the mayor of Toronto an the Premier of Ontario is a woman, Kathleen Wynne and two men and they stood in front of it.",
                    "label": 0
                },
                {
                    "sent": "And the computer said three men wearing suits, so it's a bit.",
                    "label": 0
                },
                {
                    "sent": "It's a problem with doing live demos, just like I guess doing life talks that things go wrong.",
                    "label": 0
                },
                {
                    "sent": "And so in general it's not good at gender.",
                    "label": 0
                },
                {
                    "sent": "It's not good at it, but it makes some interesting mistakes like this.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me just.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wrap up with last thing, so this goes back to what I was saying about creativity.",
                    "label": 0
                },
                {
                    "sent": "So you can try to generate things with particular style.",
                    "label": 0
                },
                {
                    "sent": "So in this case we took a network that was trained on text or the text was lots of different and in this case romantic novels.",
                    "label": 0
                },
                {
                    "sent": "So this was a skip gram model by Jamie Kiros and it was generating text now that was bias based on the kind of text that it was trained on, which was all romantic novels.",
                    "label": 0
                },
                {
                    "sent": "So it saw this image and it wasn't just generating a caption, it was generating like a paragraph.",
                    "label": 0
                },
                {
                    "sent": "To go with it.",
                    "label": 0
                },
                {
                    "sent": "So if you read it, it reads kind of like you know, a nice romantic novel, right?",
                    "label": 0
                },
                {
                    "sent": "OK. Now we took another network that was trained instead of not on romantic novels.",
                    "label": 0
                },
                {
                    "sent": "It was trained on Taylor Swift lyrics alright, and if you look at the Taylor Swift lyrics that system and took the same image and now had out.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But something said this one, you're the only person on the beach right now.",
                    "label": 0
                },
                {
                    "sent": "You know they will ever fall in love with you when the sea breeze hit to me.",
                    "label": 0
                },
                {
                    "sent": "I thought, hey.",
                    "label": 0
                },
                {
                    "sent": "So this one I would say is, you know, generating with some creativity.",
                    "label": 0
                },
                {
                    "sent": "I claimed the computers somewhat creative.",
                    "label": 0
                },
                {
                    "sent": "And this is another favorite.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My like kind of like sumo wrestling, so here's another one with trained on romantic novels faced with a sumo wrestler.",
                    "label": 0
                },
                {
                    "sent": "It was a shirtless man in the back of his mind.",
                    "label": 0
                },
                {
                    "sent": "I let out a curse.",
                    "label": 0
                },
                {
                    "sent": "He leaned over to kiss me on the shoulder.",
                    "label": 0
                },
                {
                    "sent": "He wanted to strangle me.",
                    "label": 0
                },
                {
                    "sent": "Beautiful boy, I'd be wearing his boxers, OK?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I didn't get that.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I've got my last application, few shot learning just one word about that.",
                    "label": 0
                },
                {
                    "sent": "I think it's kind of the most interesting area in machine learning these days.",
                    "label": 0
                },
                {
                    "sent": "Yeah, deep networks are very good at train.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With millions of training images or thousands of hours of speech, what we really want to be good at is training with small end, very small number of examples.",
                    "label": 0
                },
                {
                    "sent": "So I think this is a really interesting area, done some recent work in it that I'm going to skip through and I'll get to my conclusion which is bum bum bum bum bum?",
                    "label": 0
                },
                {
                    "sent": "Dun Dun Dun Dun.",
                    "label": 0
                },
                {
                    "sent": "I was optimistic about how much I get through everything.",
                    "label": 0
                },
                {
                    "sent": "OK, conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a lot of other topics I haven't gotten through in modern convolution networks, like how do you make processing a lot faster?",
                    "label": 0
                },
                {
                    "sent": "And you know various things like Fast Fourier transform and various things like that reduce precision, so making binary weights, binary activities, compressing weights and all kinds of interesting ways like.",
                    "label": 0
                },
                {
                    "sent": "Factor matrix factorization, also novel optimization techniques.",
                    "label": 0
                },
                {
                    "sent": "Lots of other applications like object detection, tracking, 3D vision very important these days as ego motion estimation.",
                    "label": 1
                },
                {
                    "sent": "So this is all in the vision domain.",
                    "label": 0
                },
                {
                    "sent": "Tons of non vision ones like text and speech processing and learning to rank.",
                    "label": 1
                },
                {
                    "sent": "And so my last.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Glad it says that we still don't really have a good understanding, so I try to talk a little bit about, you know biology and visualization and also a little bit about the theory.",
                    "label": 0
                },
                {
                    "sent": "But we still don't really understand learn representations very well and I think gaining a better understanding of that will help us learn better representations.",
                    "label": 0
                },
                {
                    "sent": "How do we design optimal mini batches size and design?",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "What are the links between deep networks and parts based model?",
                    "label": 0
                },
                {
                    "sent": "Will try to talk a little bit about that.",
                    "label": 0
                },
                {
                    "sent": "Also, causal models.",
                    "label": 0
                },
                {
                    "sent": "That's an important area in machine learning these days that hasn't been well explored.",
                    "label": 0
                },
                {
                    "sent": "Deep networks, what are the links between causal models and?",
                    "label": 1
                },
                {
                    "sent": "I think that's a very interesting questions about that hyperparameter optimization.",
                    "label": 0
                },
                {
                    "sent": "We've made progress with things like Bayesian optimization to some degree, but there's a lot of open questions like how do we optimize the architecture?",
                    "label": 0
                },
                {
                    "sent": "You know, the size of the filters, numbers of layers, all these questions that came up.",
                    "label": 0
                },
                {
                    "sent": "These are very early.",
                    "label": 0
                },
                {
                    "sent": "What's the connectivity between layers?",
                    "label": 1
                },
                {
                    "sent": "These are all open questions and you know what's the role for the old fashioned non parametric models and.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic models, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                }
            ]
        }
    }
}