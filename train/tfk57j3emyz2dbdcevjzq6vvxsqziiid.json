{
    "id": "tfk57j3emyz2dbdcevjzq6vvxsqziiid",
    "title": "Superresolution imaging - from equations to mobile applications",
    "info": {
        "author": [
            "Filip \u0160roubek, Academy of Sciences of the Czech Republic"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_sroubek_mobile/",
    "segmentation": [
        [
            "Alright, so my talk will be about super resolution.",
            "We have heard super resolution here this this word this keyword many times here in the morning and also actually today as well.",
            "Today in the afternoon but I will go maybe in more in depth to this problem.",
            "Super resolution."
        ],
        [
            "So the let's say the goal that we will persuade in this talk is that we assume that we have multiple images that you see here on the left, which are somehow have low resolution that we would like to have.",
            "They are usually noisy and they are blurred and the goal or the aim of the Super resolution algorithm is to obtain an image, a single image which would have much higher resolution which would be sharp an ideal it without any noise."
        ],
        [
            "Alright, I know that most of you are familiar with that, but let me just briefly recall the Nyquist theorem here, and just to show that why or the situations when the supervision can really work.",
            "So if we have a band limited signal which any signal the light when it passes through the optical system, so at least due to the diffraction you get a band limited signal, so the Nyquist tells us that we have to sample with the sampling frequency, which is 2 times higher than the maximum frequency.",
            "'cause then your spectrum become periodical because of the of the sampling and if the sampling is proper than the individual Spectra do not overlap.",
            "That's the idea."
        ],
        [
            "So in case that we have an image which was sampled with the Nyquist according to the Nyquist theorem, then we are really not losing any information and we can recover all the frequencies which were in originally in the signal and the Super resolution cannot do really anything here I cannot do any miracles so it's just scaling and interpolation basically.",
            "However, of course.",
            "But, and that's what we are interested in that if you have a sub Nyquist sampling then there is the aliasing effect.",
            "'cause now the spectral will overlap and some high frequencies are loss around modified.",
            "So when you do just interpolation using one single image then you do not create any new information."
        ],
        [
            "But if you have multiple images which are slightly shifted, then you use the proper super resolution algorithm.",
            "You can create image which has high resolution and you recover the details which were lost due to the aliasing effect."
        ],
        [
            "So let me now talk briefly about the traditional superresolution that appeared maybe 30 years ago.",
            "So if we have.",
            "We have one object that we that we measure by our camera.",
            "Here it's typically by three different cameras, different colors, but it could be the same camera that takes the same image but at a different time instance.",
            "So there is a slight shift so you see slightly different part of the original scene.",
            "Now each camera discretizes the signal which is here depicted by these meshes of these grids."
        ],
        [
            "So if you are able to.",
            "Registered this input images with the subpixel accuracy.",
            "Then you can overlay them and then by doing interpolation on grid which is which is a higher resolution then you are performing super resolution basically."
        ],
        [
            "So let me say it in more likes a picture graphic away.",
            "So here are the input images.",
            "If you take just one and you interpolate it, you do not create any information.",
            "But if you take one and you put it on a high resolution grid and then you add another one with the proper subpixel registration, you add more information and you get something which is slightly better.",
            "For example, you can see the texture on the T shirt, which is now more visible.",
            "But of course you can do even better if you add deconvolution.",
            "Cause the convolution is something which is in its inherent part of the Super resolution, 'cause the sensors that sample the signal.",
            "They are not ideal.",
            "Direct policies of course, and there's because the CCD sensors have a finite size, so there's always an it integrates light over a certain angle of view, so there is there is a convolution process and so you have to apply deconvolution to remove it.",
            "So you have to know the point spread function of your sensor.",
            "To really recover the original signal.",
            "So."
        ],
        [
            "The Mel Digital acquisition model that we assume we will assume in this talk is that you have input originel image here denoted SU.",
            "That's the unknown image.",
            "Now this image is observed K times through K different cameras or could be once in camera but K different time instances.",
            "And the important thing is that we model this observation by convolution with some unknowns point spread function here they notice HK and there is also a. Downsampling operator D, which you see here or a sampling operator then of course we have to add noise because this noise is omnipresent, so we assume additive noise an as the output we get a set of images which have a low resolution than the original one.",
            "They are noisy and they are also blurred in general.",
            "And they are denoted here SDK."
        ],
        [
            "So the realistic super resolution assumes the model which contains noise, blur, shifts and downsampling, and the reconstruction method must perform multi channel blind convolution 'cause we are using multiple images.",
            "In the case of super resolution and then it must contain the shift compensation as well 'cause we have to recover the the translation with the subpixel accuracy and then it contains.",
            "Also it must contain the resolution enhancement.",
            "Yep, so inverting the decimation operator D."
        ],
        [
            "So this is the acquisition acquisition model again.",
            "And we approach the problem using optimization techniques.",
            "So we just formulated energy functional.",
            "This could be actually considered as a map approach.",
            "Of course, that's that's basically the same thing.",
            "So this energy function which we want to optimize in our case we want to minimize it, contains 3 terms.",
            "The first one is nothing else than the data term.",
            "It comes from our model and it measures.",
            "The variance of the noise and the important thing here is that if we assume a Gaussian noise, then it's L2 norm appears there.",
            "Now the second term is some kind of image regularization term.",
            "We heard a lot about that today in the morning.",
            "So in our case we again measure some kind of sparsity of the image gradient.",
            "So it's a type of a total variation regularization term.",
            "But the important thing is that in most of these sparsity measures, you use some kind of L1 normal LP norm with a P less than one.",
            "And the third term is our blur regularization term, and I'm not going to talk about this term match because quote will require some more slides and I don't have time for that.",
            "But just believe me that for the multi channel case we can construct a regularization term, the yellow one which makes the problem very well post, which is the important thing and that term doesn't exist in the single channel case of costs.",
            "And the important thing here again is that we also do even boost the the convergence of the algorithm.",
            "It's good to add the positive positive ITI constraint as well.",
            "Yes please.",
            "Hi Mrs Wright, this is ridiculous.",
            "The primeness of the PSF.",
            "Right, yeah?",
            "So we have functional which combines the L2L1 norm and the positive ITI and we started to work on this six or seven years ago and last one 1/2 year we wanted to.",
            "To come up with a numerical method which would be efficient, which would efficiently solve this type of functionals, where you combine different norms.",
            "And you have positive ITI constraints."
        ],
        [
            "So of course the approach we use we use this map think so to make things very simple, so we have the functional you have seen on the previous slide on the top and then we do the minimization with respect to the image, the use tab and their minimization with respect to the point spread function, which is the H step.",
            "But the now the important thing is that you can apply the variable splitting.",
            "That means that you substitute for the gradient of the image an for the age by."
        ],
        [
            "Adding a new extra variable in the first case is the V in the second case is the and so we transfer the original problem to the one which with the constraint one is, which is more complicated.",
            "But it's the equivalent one.",
            "But the important thing is now that the minimization with respect to the U&V is much easier to perform.",
            "And you can you have to go even further and add the constraint to the problem.",
            "So to convert it to to unconstrained optimization problem for that."
        ],
        [
            "We use the augmented Lagrangian method, which is also extremely old method, but it seems to me that it has been discovered by the image processing community rather recently.",
            "So you add even another variable.",
            "In the first case it's A&B.",
            "It looks dangerous that you are creating problem, which is even more complicated, but actually there is a nice proof which tells us that the minimization of this you step converges to the original minimization of EU step you have seen.",
            "On the previous slide, and the same thing also applies to the H step, but the important thing is now that you can do everything in the Fourier domain you have the minimization with respect to you.",
            "It's just a quadratic functional, so the derivatives are linear equations.",
            "The minimization respect to V is easy to perform, 'cause this is just the element wise.",
            "There's a closed form solution for most of the regularization terms.",
            "Of course it's not general.",
            "And you can also add the positive iti there without really paying anything.",
            "And any extra effort to do that and the update of the variable A&B, which is in some way related to the Lagrangian multipliers, is also element vice kind of calculation, which is very fast and easy to."
        ],
        [
            "Performance, so let me show you now some examples.",
            "So the Super resolution of this short video sequence.",
            "Actually there are 8 frames you see here.",
            "Now that's the video sequence which runs through these 8 frames.",
            "When we first perform a ref registration to get rid of the misregistration you see in the video sequence, here is the result.",
            "After the registration you can see there is still some misalignment left behind.",
            "By the way, the image you see on the right where interpolated to have the resolution of the final super resolved image for the comparison reasons, only an when.",
            "Then we also use the optical zoom to get some kind of a ground truth.",
            "What you see on the bottom on the bottom right, and if we use this 8 frames you see here the low resolution once and apply the Super resolution algorithm I've just described we have obtained something.",
            "What you see here on the bottom left and here we also have the point spread functions that that by the way like jiggle around to model to compensate for the misregistration which you can see on the video sequence after the registration still.",
            "Yeah so."
        ],
        [
            "That's a example.",
            "Now, of course, what's extremely interesting is that how to transfer this space variant case, because most of the video sequences or images have a space variant point spread function.",
            "So we have to deal with that."
        ],
        [
            "But we basically have proposed two different strategies depending on what type of space variance we want to deal with.",
            "The first one is in case of video sequence with the local motion.",
            "So we apply masking.",
            "I will talk about in a minute and the second scenario is that we have a point spread function with which is slowly changing which could be for example induced by the camera motion.",
            "Then you get something what is slowly changing point function and then we use the Patch wise.",
            "Approach."
        ],
        [
            "So in the first case of this masking of a video with a local motion, if you what you see here on the top left is the input video sequence, which is here interpolated again for the comparison reasons an in the middle you see the video sequence after applying the Super resolution algorithm without any any changes and you can see those disturbing artifacts around the moving object in this.",
            "In this case the.",
            "Shake it moving hand."
        ],
        [
            "Of the child, then, if you apply them asking that means you take the video sequence.",
            "You compare the frames and you pick up regions where you where you see where you can find by this simple correlation.",
            "In our case, with simple correlation to identify areas where you have a local motion.",
            "So we mask them out and this masking can be also very easily can be implemented in this resolution algorithm we have seen before.",
            "And using the augmenting Langrangian method as well.",
            "And if you use this masking and you apply the same algorithm then you get the result you see on the on the."
        ],
        [
            "Right, so you see that most of the artifacts are gone now, so of course we are not really doing in the part where there's a motion.",
            "We don't do any kind of soup resolution, it performs, basically interpolation, but you don't have to.",
            "It does it automatically, which is the nice thing."
        ],
        [
            "Alright, so now the second scenario, when we have a slowly changing points but function in this case here I show an example of of House State which was taken by a camera and there was a camera motion during the exposure time.",
            "And here are the estimated points for functions at different parts of the image.",
            "So you can see that even for a simple camera motion in this case it was just a rotation.",
            "You can get an A little bit of translation.",
            "You can get widely different points, but functions of different parts of the image."
        ],
        [
            "What we do is very simple.",
            "We take the element OK. You have a question, yes question."
        ],
        [
            "Then I mean, I'm wondering how do we have to move the camera to get that learn because they're like the poison DEF artificial.",
            "This is artificial, but the way how we generated artificial bird was with the with calculating the camera motion really and how the camera motion.",
            "What kind of point spread function induces?",
            "So this is this?",
            "Is this is a uniform motion of the camera?",
            "But of course if you have the if you have a rotation.",
            "Along the X&Y axis, so that's the pitch and your then you don't get really just just a line, even if it's U1 because of the optics of the camera, so you get slightly bended point functions at the site, and also if there is a little bit of rotation, you can see that here in the middle would be.",
            "Let's say they like the center of of the actually the translation.",
            "What it does is that it moves the pointer function, which would normally look like a like.",
            "A dot will be a Delta function.",
            "It moves it to the site, so I'll show you a real examples pretty soon."
        ],
        [
            "What we do here is that again, we assume that we have multiple images in this case, so to avoid the single channel case because we were afraid of the single channel case an since it's have little post.",
            "But obviously there are now methods which which can at least partially deal with that.",
            "So what we do is that we divide the image non overlapping patches and we apply the algorithm I've just described.",
            "To different parts, we estimate the points, but functions there."
        ],
        [
            "And then do a space variant non blind convolution.",
            "So that's what you see.",
            "Here is the one of the input images and that will be the output we have obtained.",
            "Of course those are synthetically generated data."
        ],
        [
            "But here I should just show you some close up.",
            "So on the top left you see the input low resolution image.",
            "The top right is the originel image, the one which is which is sharp on the bottom right you see the reconstruction.",
            "If you do not assume a space variant point spread function and at the bottom left you see the result of the space variant.",
            "Patch Wise super resolution and deconvolution algorithm."
        ],
        [
            "But you have more than one input in, right?",
            "Yeah, yeah, that's the case here.",
            "So here another example this is.",
            "That's what you see here is again.",
            "You see one of the input images, but there were only two images used in this case, and here are the red rectangles.",
            "Shows you the the areas where we calculate the point spread functions.",
            "And here in the middle, now you see the boys functions that were estimated.",
            "They do not look so nice anymore.",
            "Of course, it's also it's important maybe to notice that at the in the middle of the image the function look quite sharp because they're the convolution model.",
            "Actually is pretty accurate, but at the sight of the image you get aberrations, so the promotion model doesn't have to hold really precisely and then.",
            "You get some blurry point spread functions in this case."
        ],
        [
            "And that's the result.",
            "So the top left you see one of the input images and the top, which was interpolated again for the purposes of comparison, an on the bottom right you see the Super resolved and deconvolved image.",
            "And those are true."
        ],
        [
            "Through images now let me show you at the at the end of my talk just two applications where we applied super resolution and the convolution.",
            "So in the first application that would be super resolution.",
            "In the second actually it would be only the convolution.",
            "So we were asked by one company which is producing infrared camera.",
            "So thermal cameras if we can.",
            "If we can give them in an algorithm which would perform super resolution in real time, they had their input was a video sequence at the frame rate of 9 frames per second, so it's not really very very fast and the resolution was 160 * 120.",
            "And we wanted to have a super resolution algorithm with a factor of two and which can be directly computed inside the camera on their digital signal processor.",
            "So everything has to be done in Fourier domain.",
            "And so we use the things I just talk about.",
            "But we transfer everything through the Fourier domain, so it will be really fast."
        ],
        [
            "And by the way, why they need these things?",
            "The thermal cameras are now widely used mainly to detect leakage in houses in house for seats, and of course it said it would be nice if you can increase the resolution of your of your thermal camera."
        ],
        [
            "And here I show you the output of algorithms.",
            "So the the left video sequence shows the interpolated again video sequence taken by the camera and maybe notice especially these small rectangles with bars, where here is the aliasing effect.",
            "The frequency information is almost gone, whereas in the Super resolved super resolved video sequence you can still see the it's not moving anymore.",
            "OK, you can still see pretty well the.",
            "4 bars there so it really at least visually tells us that some high frequency information has been recovered and probably correctly recovered.",
            "OK, another example."
        ],
        [
            "At the top, that's the interpolated low resolution sequence and the bottom you see the Super resolved and on the right you see the close apps.",
            "So maybe here, just notice the bars over the rips of the heating system there so you see the the aliasing ethic there, whereas it's not.",
            "The aliasing effect is gone in the Super resolved video sequence.",
            "OK, let me go through that once again.",
            "So it works pretty well.",
            "Yeah, here it is.",
            "OK."
        ],
        [
            "And the last application I would like to talk about is how to perform kind of blind deconvolution on smartphones.",
            "So we thought that it would be nice if we can remove blur from from photos taken by the smart phones which have gyroscopes and accelerometers and that it would be even implemented inside the phone so you don't need any computer to do it offline.",
            "So you can do it if you're online.",
            "So we use the accelerometers and gyroscopes which most of the more expensive smartphones now have so you can render basically the trajectory of the of the smartphone while you are shooting an.",
            "You can use that to estimate the point spread function, and that's exactly why."
        ],
        [
            "So we did so by, but we only consider in this first version we are only considering the your and pitch, which is the one which has the widest.",
            "I would say impact on the on the on the scale of the point spread function."
        ],
        [
            "And here I show you an example.",
            "This is the LCD screen which contains a mesh of points but taken by the smartphone.",
            "And so you can see that each now point is this curvy line so that curvy line actually corresponds to the point spread function at that location.",
            "An here in the middle I show you.",
            "The trajectory, or let's say the pointer function that was estimated from the data coming from the accelerometers and gyroscopes.",
            "In this case, only gyroscopes, which is the wide line and the red part is the one which corresponds to the exposure time.",
            "This is by the way problem with these phones.",
            "We use the Android platform that there is no way to detect exactly when you are taking the picture and there's.",
            "Really no way to detect that, so at least we haven't found a way."
        ],
        [
            "Alright, so here is an example how it works, so the left you see the input image that was taken by the phone and on the right you see the deconvolve one on the phone.",
            "Using this gyroscope information.",
            "So the pointer function you see here on the bottom.",
            "Of course it's not perfect, still just use that as is.",
            "You don't do no, we don't do any.",
            "Yeah, the of course there will be a next step to do it, But the problem is that if we want to do.",
            "On the phone, then, that would require more time, but eventually we will probably have to do it.",
            "It's quite surprising how powerful these some of these Android smartphones are, because this is just a Wiener filtering, but in one second you have the result, so it's a 3 megapixel photo and in one second you have the you have the result, which is pretty nice.",
            "I'm quite surprised at 7 for transforms can be done in such a.",
            "Short time."
        ],
        [
            "And then our example gained left.",
            "You see the blurry image taken by the phone and the right is the cone Wolf one and the bottom you see in the middle bottom you see the point spread function which was rendered from the gyroscope data."
        ],
        [
            "Alright, I just have to thank at the end to all my collaborators, because this work has been done with many other people, so mainly I would have to say that the unfulfilled and make sure all incoming ski.",
            "Those are my colleagues from the Institute, so they they collaborated on on the on the Super resolution problem and also payment Milan.",
            "Far from UCSC.",
            "We did some work together as well.",
            "So thank you for your attention.",
            "OK, the question was if.",
            "The question was if we can if since we do not know exactly the time exposure, if we can optimize it because we know the whole trajectory and just find the optimal point.",
            "The beginning of the point spread function definitely that this is something what I guess can be done.",
            "We just started to do that like couple of months ago.",
            "So you know there's still many things that can be improved.",
            "Unfortunately, the when you start to.",
            "Really implement things on different embedded systems you you have to deal with problems that you haven't even thought about it.",
            "You know that's like, for example, rolling shutter, which is something that I didn't know that it relax, but rolling shutter is something which is common in all the phones, so it doesn't expose the whole image at one time instance.",
            "But it's rather moves at window from top to bottom.",
            "So you the point function at the beginning of the point perfection will be.",
            "Slightly different at different points.",
            "That's another thing.",
            "Yeah, the question was if we did some post processing of the data from the gyroscopes, because surprisingly we got such a clean data.",
            "Clean or accurate point function, no.",
            "None.",
            "We haven't done no."
        ],
        [
            "Yeah, so the question is how we how we really did it or how we get these points.",
            "But functions that where they were.",
            "They are the same point.",
            "Special surprise or or it looks like the alignment was just not really proper between those subsequent frames, because yes, OK, so the OK.",
            "The question is like about the alignment.",
            "How we did that?",
            "I'm actually.",
            "I forgot that I'm sorry.",
            "Well, the alignment here was just using using.",
            "Face correlation actually so.",
            "But by the way, it's not really if you have a blurry data, surprisingly not trivial to have quite accurate registration, so I always wonder how people can do subpixel registration with subpixel accuracy, especially if your data are blurred, because there is inherently some ambiguity in the whole process because of the blur, which is so.",
            "We believe that it's actually much better to do it simultaneously, like insight, but it's true that how this algorithm was proposed.",
            "We can only deal with Misregistration just translation.",
            "You know, so by estimating the point spread functions, we can also estimate the shift because the points function can move around and when it moves around it compensates for this translation, but it does it automatically so you don't have to think about it so.",
            "That's that's that's this.",
            "Is this final step, and this one was face correlation or any other registration algorithm you can think of.",
            "The question is, what's the capital D Capital D is the downsampling operator, because of course our input data also discrete date time and our final result U is also a discrete at the end, so the D is just downsampling.",
            "Operator will be.",
            "Ideally I actually it would be something which would have ideally just on the main diagonal.",
            "Non zero values like every second.",
            "Non dagger element would have one.",
            "So, but you could also combine neighboring pixels, right?",
            "Yes, so in practice, the D also does convolution with the point spread function of the sensor.",
            "For example, it would be a Gaussian function, which we normally use in most of the cases, but there are ways how to estimate the point spread function of the sensor.",
            "I guess it can.",
            "It improves the results of a little bit, but we haven't really seen a significant improvement.",
            "If you do some more sophisticated technique of because it's common to all the input data, then this is already a single channel case, so we are not dealing with that.",
            "Don't sound."
        ],
        [
            "OK, so basically the question is how the performance of this of the method if you are increasing the resolution more than 2 * 4 * 8 times.",
            "And of course you have the sufficient number of input data also increases as well.",
            "The test that we did.",
            "If you have a synthetically generated data then we really haven't notice any any any problem with that we would get exactly the same results.",
            "Unfortunately in practice it never works like that and we want our experience tells us that for the Super resolution higher than two doesn't really make much sense in practice.",
            "One of the reasons could be and that's by the way why I was very happy that we could implement super resolution in the thermal cameras, because we're looking really hard to find some good application for super resolution because we found out that in if you apply super resolution to standard photos taken by camera, it doesn't really work so well.",
            "The main reason is that the manufacturers of these cameras they want to avoid the aliasing effect of course.",
            "And the aliasing effect here is something what we need and how they avoid it.",
            "They do as they're optical system is set up in such a way that they have a band limited signal, and so their sampling is basically a Nyquist sampling, so there's really nothing to recover.",
            "Whereas in the in the case of the thermal cameras, that's not a problem.",
            "They can spend a lot of money on optical systems, the optical lenses, but what's very expensive is that the sensor, so yeah."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so my talk will be about super resolution.",
                    "label": 0
                },
                {
                    "sent": "We have heard super resolution here this this word this keyword many times here in the morning and also actually today as well.",
                    "label": 0
                },
                {
                    "sent": "Today in the afternoon but I will go maybe in more in depth to this problem.",
                    "label": 0
                },
                {
                    "sent": "Super resolution.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the let's say the goal that we will persuade in this talk is that we assume that we have multiple images that you see here on the left, which are somehow have low resolution that we would like to have.",
                    "label": 0
                },
                {
                    "sent": "They are usually noisy and they are blurred and the goal or the aim of the Super resolution algorithm is to obtain an image, a single image which would have much higher resolution which would be sharp an ideal it without any noise.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, I know that most of you are familiar with that, but let me just briefly recall the Nyquist theorem here, and just to show that why or the situations when the supervision can really work.",
                    "label": 0
                },
                {
                    "sent": "So if we have a band limited signal which any signal the light when it passes through the optical system, so at least due to the diffraction you get a band limited signal, so the Nyquist tells us that we have to sample with the sampling frequency, which is 2 times higher than the maximum frequency.",
                    "label": 0
                },
                {
                    "sent": "'cause then your spectrum become periodical because of the of the sampling and if the sampling is proper than the individual Spectra do not overlap.",
                    "label": 0
                },
                {
                    "sent": "That's the idea.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in case that we have an image which was sampled with the Nyquist according to the Nyquist theorem, then we are really not losing any information and we can recover all the frequencies which were in originally in the signal and the Super resolution cannot do really anything here I cannot do any miracles so it's just scaling and interpolation basically.",
                    "label": 0
                },
                {
                    "sent": "However, of course.",
                    "label": 0
                },
                {
                    "sent": "But, and that's what we are interested in that if you have a sub Nyquist sampling then there is the aliasing effect.",
                    "label": 1
                },
                {
                    "sent": "'cause now the spectral will overlap and some high frequencies are loss around modified.",
                    "label": 1
                },
                {
                    "sent": "So when you do just interpolation using one single image then you do not create any new information.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you have multiple images which are slightly shifted, then you use the proper super resolution algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can create image which has high resolution and you recover the details which were lost due to the aliasing effect.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me now talk briefly about the traditional superresolution that appeared maybe 30 years ago.",
                    "label": 1
                },
                {
                    "sent": "So if we have.",
                    "label": 0
                },
                {
                    "sent": "We have one object that we that we measure by our camera.",
                    "label": 0
                },
                {
                    "sent": "Here it's typically by three different cameras, different colors, but it could be the same camera that takes the same image but at a different time instance.",
                    "label": 0
                },
                {
                    "sent": "So there is a slight shift so you see slightly different part of the original scene.",
                    "label": 0
                },
                {
                    "sent": "Now each camera discretizes the signal which is here depicted by these meshes of these grids.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you are able to.",
                    "label": 0
                },
                {
                    "sent": "Registered this input images with the subpixel accuracy.",
                    "label": 0
                },
                {
                    "sent": "Then you can overlay them and then by doing interpolation on grid which is which is a higher resolution then you are performing super resolution basically.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me say it in more likes a picture graphic away.",
                    "label": 0
                },
                {
                    "sent": "So here are the input images.",
                    "label": 0
                },
                {
                    "sent": "If you take just one and you interpolate it, you do not create any information.",
                    "label": 0
                },
                {
                    "sent": "But if you take one and you put it on a high resolution grid and then you add another one with the proper subpixel registration, you add more information and you get something which is slightly better.",
                    "label": 0
                },
                {
                    "sent": "For example, you can see the texture on the T shirt, which is now more visible.",
                    "label": 0
                },
                {
                    "sent": "But of course you can do even better if you add deconvolution.",
                    "label": 0
                },
                {
                    "sent": "Cause the convolution is something which is in its inherent part of the Super resolution, 'cause the sensors that sample the signal.",
                    "label": 0
                },
                {
                    "sent": "They are not ideal.",
                    "label": 0
                },
                {
                    "sent": "Direct policies of course, and there's because the CCD sensors have a finite size, so there's always an it integrates light over a certain angle of view, so there is there is a convolution process and so you have to apply deconvolution to remove it.",
                    "label": 0
                },
                {
                    "sent": "So you have to know the point spread function of your sensor.",
                    "label": 0
                },
                {
                    "sent": "To really recover the original signal.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Mel Digital acquisition model that we assume we will assume in this talk is that you have input originel image here denoted SU.",
                    "label": 0
                },
                {
                    "sent": "That's the unknown image.",
                    "label": 0
                },
                {
                    "sent": "Now this image is observed K times through K different cameras or could be once in camera but K different time instances.",
                    "label": 0
                },
                {
                    "sent": "And the important thing is that we model this observation by convolution with some unknowns point spread function here they notice HK and there is also a. Downsampling operator D, which you see here or a sampling operator then of course we have to add noise because this noise is omnipresent, so we assume additive noise an as the output we get a set of images which have a low resolution than the original one.",
                    "label": 0
                },
                {
                    "sent": "They are noisy and they are also blurred in general.",
                    "label": 0
                },
                {
                    "sent": "And they are denoted here SDK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the realistic super resolution assumes the model which contains noise, blur, shifts and downsampling, and the reconstruction method must perform multi channel blind convolution 'cause we are using multiple images.",
                    "label": 1
                },
                {
                    "sent": "In the case of super resolution and then it must contain the shift compensation as well 'cause we have to recover the the translation with the subpixel accuracy and then it contains.",
                    "label": 0
                },
                {
                    "sent": "Also it must contain the resolution enhancement.",
                    "label": 1
                },
                {
                    "sent": "Yep, so inverting the decimation operator D.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the acquisition acquisition model again.",
                    "label": 1
                },
                {
                    "sent": "And we approach the problem using optimization techniques.",
                    "label": 0
                },
                {
                    "sent": "So we just formulated energy functional.",
                    "label": 0
                },
                {
                    "sent": "This could be actually considered as a map approach.",
                    "label": 0
                },
                {
                    "sent": "Of course, that's that's basically the same thing.",
                    "label": 0
                },
                {
                    "sent": "So this energy function which we want to optimize in our case we want to minimize it, contains 3 terms.",
                    "label": 1
                },
                {
                    "sent": "The first one is nothing else than the data term.",
                    "label": 0
                },
                {
                    "sent": "It comes from our model and it measures.",
                    "label": 0
                },
                {
                    "sent": "The variance of the noise and the important thing here is that if we assume a Gaussian noise, then it's L2 norm appears there.",
                    "label": 0
                },
                {
                    "sent": "Now the second term is some kind of image regularization term.",
                    "label": 1
                },
                {
                    "sent": "We heard a lot about that today in the morning.",
                    "label": 0
                },
                {
                    "sent": "So in our case we again measure some kind of sparsity of the image gradient.",
                    "label": 0
                },
                {
                    "sent": "So it's a type of a total variation regularization term.",
                    "label": 0
                },
                {
                    "sent": "But the important thing is that in most of these sparsity measures, you use some kind of L1 normal LP norm with a P less than one.",
                    "label": 0
                },
                {
                    "sent": "And the third term is our blur regularization term, and I'm not going to talk about this term match because quote will require some more slides and I don't have time for that.",
                    "label": 0
                },
                {
                    "sent": "But just believe me that for the multi channel case we can construct a regularization term, the yellow one which makes the problem very well post, which is the important thing and that term doesn't exist in the single channel case of costs.",
                    "label": 0
                },
                {
                    "sent": "And the important thing here again is that we also do even boost the the convergence of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's good to add the positive positive ITI constraint as well.",
                    "label": 0
                },
                {
                    "sent": "Yes please.",
                    "label": 0
                },
                {
                    "sent": "Hi Mrs Wright, this is ridiculous.",
                    "label": 0
                },
                {
                    "sent": "The primeness of the PSF.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah?",
                    "label": 0
                },
                {
                    "sent": "So we have functional which combines the L2L1 norm and the positive ITI and we started to work on this six or seven years ago and last one 1/2 year we wanted to.",
                    "label": 0
                },
                {
                    "sent": "To come up with a numerical method which would be efficient, which would efficiently solve this type of functionals, where you combine different norms.",
                    "label": 0
                },
                {
                    "sent": "And you have positive ITI constraints.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So of course the approach we use we use this map think so to make things very simple, so we have the functional you have seen on the previous slide on the top and then we do the minimization with respect to the image, the use tab and their minimization with respect to the point spread function, which is the H step.",
                    "label": 0
                },
                {
                    "sent": "But the now the important thing is that you can apply the variable splitting.",
                    "label": 0
                },
                {
                    "sent": "That means that you substitute for the gradient of the image an for the age by.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Adding a new extra variable in the first case is the V in the second case is the and so we transfer the original problem to the one which with the constraint one is, which is more complicated.",
                    "label": 0
                },
                {
                    "sent": "But it's the equivalent one.",
                    "label": 0
                },
                {
                    "sent": "But the important thing is now that the minimization with respect to the U&V is much easier to perform.",
                    "label": 0
                },
                {
                    "sent": "And you can you have to go even further and add the constraint to the problem.",
                    "label": 0
                },
                {
                    "sent": "So to convert it to to unconstrained optimization problem for that.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use the augmented Lagrangian method, which is also extremely old method, but it seems to me that it has been discovered by the image processing community rather recently.",
                    "label": 1
                },
                {
                    "sent": "So you add even another variable.",
                    "label": 0
                },
                {
                    "sent": "In the first case it's A&B.",
                    "label": 0
                },
                {
                    "sent": "It looks dangerous that you are creating problem, which is even more complicated, but actually there is a nice proof which tells us that the minimization of this you step converges to the original minimization of EU step you have seen.",
                    "label": 0
                },
                {
                    "sent": "On the previous slide, and the same thing also applies to the H step, but the important thing is now that you can do everything in the Fourier domain you have the minimization with respect to you.",
                    "label": 0
                },
                {
                    "sent": "It's just a quadratic functional, so the derivatives are linear equations.",
                    "label": 0
                },
                {
                    "sent": "The minimization respect to V is easy to perform, 'cause this is just the element wise.",
                    "label": 0
                },
                {
                    "sent": "There's a closed form solution for most of the regularization terms.",
                    "label": 0
                },
                {
                    "sent": "Of course it's not general.",
                    "label": 0
                },
                {
                    "sent": "And you can also add the positive iti there without really paying anything.",
                    "label": 0
                },
                {
                    "sent": "And any extra effort to do that and the update of the variable A&B, which is in some way related to the Lagrangian multipliers, is also element vice kind of calculation, which is very fast and easy to.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Performance, so let me show you now some examples.",
                    "label": 0
                },
                {
                    "sent": "So the Super resolution of this short video sequence.",
                    "label": 0
                },
                {
                    "sent": "Actually there are 8 frames you see here.",
                    "label": 0
                },
                {
                    "sent": "Now that's the video sequence which runs through these 8 frames.",
                    "label": 0
                },
                {
                    "sent": "When we first perform a ref registration to get rid of the misregistration you see in the video sequence, here is the result.",
                    "label": 0
                },
                {
                    "sent": "After the registration you can see there is still some misalignment left behind.",
                    "label": 0
                },
                {
                    "sent": "By the way, the image you see on the right where interpolated to have the resolution of the final super resolved image for the comparison reasons, only an when.",
                    "label": 0
                },
                {
                    "sent": "Then we also use the optical zoom to get some kind of a ground truth.",
                    "label": 1
                },
                {
                    "sent": "What you see on the bottom on the bottom right, and if we use this 8 frames you see here the low resolution once and apply the Super resolution algorithm I've just described we have obtained something.",
                    "label": 0
                },
                {
                    "sent": "What you see here on the bottom left and here we also have the point spread functions that that by the way like jiggle around to model to compensate for the misregistration which you can see on the video sequence after the registration still.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's a example.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, what's extremely interesting is that how to transfer this space variant case, because most of the video sequences or images have a space variant point spread function.",
                    "label": 0
                },
                {
                    "sent": "So we have to deal with that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we basically have proposed two different strategies depending on what type of space variance we want to deal with.",
                    "label": 0
                },
                {
                    "sent": "The first one is in case of video sequence with the local motion.",
                    "label": 1
                },
                {
                    "sent": "So we apply masking.",
                    "label": 0
                },
                {
                    "sent": "I will talk about in a minute and the second scenario is that we have a point spread function with which is slowly changing which could be for example induced by the camera motion.",
                    "label": 1
                },
                {
                    "sent": "Then you get something what is slowly changing point function and then we use the Patch wise.",
                    "label": 0
                },
                {
                    "sent": "Approach.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the first case of this masking of a video with a local motion, if you what you see here on the top left is the input video sequence, which is here interpolated again for the comparison reasons an in the middle you see the video sequence after applying the Super resolution algorithm without any any changes and you can see those disturbing artifacts around the moving object in this.",
                    "label": 0
                },
                {
                    "sent": "In this case the.",
                    "label": 0
                },
                {
                    "sent": "Shake it moving hand.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the child, then, if you apply them asking that means you take the video sequence.",
                    "label": 0
                },
                {
                    "sent": "You compare the frames and you pick up regions where you where you see where you can find by this simple correlation.",
                    "label": 0
                },
                {
                    "sent": "In our case, with simple correlation to identify areas where you have a local motion.",
                    "label": 0
                },
                {
                    "sent": "So we mask them out and this masking can be also very easily can be implemented in this resolution algorithm we have seen before.",
                    "label": 0
                },
                {
                    "sent": "And using the augmenting Langrangian method as well.",
                    "label": 0
                },
                {
                    "sent": "And if you use this masking and you apply the same algorithm then you get the result you see on the on the.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so you see that most of the artifacts are gone now, so of course we are not really doing in the part where there's a motion.",
                    "label": 0
                },
                {
                    "sent": "We don't do any kind of soup resolution, it performs, basically interpolation, but you don't have to.",
                    "label": 0
                },
                {
                    "sent": "It does it automatically, which is the nice thing.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so now the second scenario, when we have a slowly changing points but function in this case here I show an example of of House State which was taken by a camera and there was a camera motion during the exposure time.",
                    "label": 0
                },
                {
                    "sent": "And here are the estimated points for functions at different parts of the image.",
                    "label": 0
                },
                {
                    "sent": "So you can see that even for a simple camera motion in this case it was just a rotation.",
                    "label": 0
                },
                {
                    "sent": "You can get an A little bit of translation.",
                    "label": 0
                },
                {
                    "sent": "You can get widely different points, but functions of different parts of the image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do is very simple.",
                    "label": 0
                },
                {
                    "sent": "We take the element OK. You have a question, yes question.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I mean, I'm wondering how do we have to move the camera to get that learn because they're like the poison DEF artificial.",
                    "label": 0
                },
                {
                    "sent": "This is artificial, but the way how we generated artificial bird was with the with calculating the camera motion really and how the camera motion.",
                    "label": 0
                },
                {
                    "sent": "What kind of point spread function induces?",
                    "label": 0
                },
                {
                    "sent": "So this is this?",
                    "label": 0
                },
                {
                    "sent": "Is this is a uniform motion of the camera?",
                    "label": 0
                },
                {
                    "sent": "But of course if you have the if you have a rotation.",
                    "label": 0
                },
                {
                    "sent": "Along the X&Y axis, so that's the pitch and your then you don't get really just just a line, even if it's U1 because of the optics of the camera, so you get slightly bended point functions at the site, and also if there is a little bit of rotation, you can see that here in the middle would be.",
                    "label": 0
                },
                {
                    "sent": "Let's say they like the center of of the actually the translation.",
                    "label": 0
                },
                {
                    "sent": "What it does is that it moves the pointer function, which would normally look like a like.",
                    "label": 0
                },
                {
                    "sent": "A dot will be a Delta function.",
                    "label": 0
                },
                {
                    "sent": "It moves it to the site, so I'll show you a real examples pretty soon.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do here is that again, we assume that we have multiple images in this case, so to avoid the single channel case because we were afraid of the single channel case an since it's have little post.",
                    "label": 0
                },
                {
                    "sent": "But obviously there are now methods which which can at least partially deal with that.",
                    "label": 0
                },
                {
                    "sent": "So what we do is that we divide the image non overlapping patches and we apply the algorithm I've just described.",
                    "label": 0
                },
                {
                    "sent": "To different parts, we estimate the points, but functions there.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then do a space variant non blind convolution.",
                    "label": 0
                },
                {
                    "sent": "So that's what you see.",
                    "label": 0
                },
                {
                    "sent": "Here is the one of the input images and that will be the output we have obtained.",
                    "label": 0
                },
                {
                    "sent": "Of course those are synthetically generated data.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But here I should just show you some close up.",
                    "label": 0
                },
                {
                    "sent": "So on the top left you see the input low resolution image.",
                    "label": 0
                },
                {
                    "sent": "The top right is the originel image, the one which is which is sharp on the bottom right you see the reconstruction.",
                    "label": 0
                },
                {
                    "sent": "If you do not assume a space variant point spread function and at the bottom left you see the result of the space variant.",
                    "label": 0
                },
                {
                    "sent": "Patch Wise super resolution and deconvolution algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But you have more than one input in, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, that's the case here.",
                    "label": 0
                },
                {
                    "sent": "So here another example this is.",
                    "label": 0
                },
                {
                    "sent": "That's what you see here is again.",
                    "label": 0
                },
                {
                    "sent": "You see one of the input images, but there were only two images used in this case, and here are the red rectangles.",
                    "label": 0
                },
                {
                    "sent": "Shows you the the areas where we calculate the point spread functions.",
                    "label": 0
                },
                {
                    "sent": "And here in the middle, now you see the boys functions that were estimated.",
                    "label": 0
                },
                {
                    "sent": "They do not look so nice anymore.",
                    "label": 0
                },
                {
                    "sent": "Of course, it's also it's important maybe to notice that at the in the middle of the image the function look quite sharp because they're the convolution model.",
                    "label": 0
                },
                {
                    "sent": "Actually is pretty accurate, but at the sight of the image you get aberrations, so the promotion model doesn't have to hold really precisely and then.",
                    "label": 0
                },
                {
                    "sent": "You get some blurry point spread functions in this case.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's the result.",
                    "label": 0
                },
                {
                    "sent": "So the top left you see one of the input images and the top, which was interpolated again for the purposes of comparison, an on the bottom right you see the Super resolved and deconvolved image.",
                    "label": 0
                },
                {
                    "sent": "And those are true.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Through images now let me show you at the at the end of my talk just two applications where we applied super resolution and the convolution.",
                    "label": 0
                },
                {
                    "sent": "So in the first application that would be super resolution.",
                    "label": 0
                },
                {
                    "sent": "In the second actually it would be only the convolution.",
                    "label": 0
                },
                {
                    "sent": "So we were asked by one company which is producing infrared camera.",
                    "label": 0
                },
                {
                    "sent": "So thermal cameras if we can.",
                    "label": 0
                },
                {
                    "sent": "If we can give them in an algorithm which would perform super resolution in real time, they had their input was a video sequence at the frame rate of 9 frames per second, so it's not really very very fast and the resolution was 160 * 120.",
                    "label": 0
                },
                {
                    "sent": "And we wanted to have a super resolution algorithm with a factor of two and which can be directly computed inside the camera on their digital signal processor.",
                    "label": 1
                },
                {
                    "sent": "So everything has to be done in Fourier domain.",
                    "label": 0
                },
                {
                    "sent": "And so we use the things I just talk about.",
                    "label": 0
                },
                {
                    "sent": "But we transfer everything through the Fourier domain, so it will be really fast.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And by the way, why they need these things?",
                    "label": 0
                },
                {
                    "sent": "The thermal cameras are now widely used mainly to detect leakage in houses in house for seats, and of course it said it would be nice if you can increase the resolution of your of your thermal camera.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here I show you the output of algorithms.",
                    "label": 0
                },
                {
                    "sent": "So the the left video sequence shows the interpolated again video sequence taken by the camera and maybe notice especially these small rectangles with bars, where here is the aliasing effect.",
                    "label": 0
                },
                {
                    "sent": "The frequency information is almost gone, whereas in the Super resolved super resolved video sequence you can still see the it's not moving anymore.",
                    "label": 0
                },
                {
                    "sent": "OK, you can still see pretty well the.",
                    "label": 0
                },
                {
                    "sent": "4 bars there so it really at least visually tells us that some high frequency information has been recovered and probably correctly recovered.",
                    "label": 0
                },
                {
                    "sent": "OK, another example.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the top, that's the interpolated low resolution sequence and the bottom you see the Super resolved and on the right you see the close apps.",
                    "label": 0
                },
                {
                    "sent": "So maybe here, just notice the bars over the rips of the heating system there so you see the the aliasing ethic there, whereas it's not.",
                    "label": 0
                },
                {
                    "sent": "The aliasing effect is gone in the Super resolved video sequence.",
                    "label": 0
                },
                {
                    "sent": "OK, let me go through that once again.",
                    "label": 0
                },
                {
                    "sent": "So it works pretty well.",
                    "label": 0
                },
                {
                    "sent": "Yeah, here it is.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the last application I would like to talk about is how to perform kind of blind deconvolution on smartphones.",
                    "label": 1
                },
                {
                    "sent": "So we thought that it would be nice if we can remove blur from from photos taken by the smart phones which have gyroscopes and accelerometers and that it would be even implemented inside the phone so you don't need any computer to do it offline.",
                    "label": 0
                },
                {
                    "sent": "So you can do it if you're online.",
                    "label": 0
                },
                {
                    "sent": "So we use the accelerometers and gyroscopes which most of the more expensive smartphones now have so you can render basically the trajectory of the of the smartphone while you are shooting an.",
                    "label": 0
                },
                {
                    "sent": "You can use that to estimate the point spread function, and that's exactly why.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we did so by, but we only consider in this first version we are only considering the your and pitch, which is the one which has the widest.",
                    "label": 0
                },
                {
                    "sent": "I would say impact on the on the on the scale of the point spread function.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here I show you an example.",
                    "label": 0
                },
                {
                    "sent": "This is the LCD screen which contains a mesh of points but taken by the smartphone.",
                    "label": 0
                },
                {
                    "sent": "And so you can see that each now point is this curvy line so that curvy line actually corresponds to the point spread function at that location.",
                    "label": 0
                },
                {
                    "sent": "An here in the middle I show you.",
                    "label": 0
                },
                {
                    "sent": "The trajectory, or let's say the pointer function that was estimated from the data coming from the accelerometers and gyroscopes.",
                    "label": 0
                },
                {
                    "sent": "In this case, only gyroscopes, which is the wide line and the red part is the one which corresponds to the exposure time.",
                    "label": 0
                },
                {
                    "sent": "This is by the way problem with these phones.",
                    "label": 0
                },
                {
                    "sent": "We use the Android platform that there is no way to detect exactly when you are taking the picture and there's.",
                    "label": 0
                },
                {
                    "sent": "Really no way to detect that, so at least we haven't found a way.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so here is an example how it works, so the left you see the input image that was taken by the phone and on the right you see the deconvolve one on the phone.",
                    "label": 0
                },
                {
                    "sent": "Using this gyroscope information.",
                    "label": 0
                },
                {
                    "sent": "So the pointer function you see here on the bottom.",
                    "label": 0
                },
                {
                    "sent": "Of course it's not perfect, still just use that as is.",
                    "label": 0
                },
                {
                    "sent": "You don't do no, we don't do any.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the of course there will be a next step to do it, But the problem is that if we want to do.",
                    "label": 0
                },
                {
                    "sent": "On the phone, then, that would require more time, but eventually we will probably have to do it.",
                    "label": 0
                },
                {
                    "sent": "It's quite surprising how powerful these some of these Android smartphones are, because this is just a Wiener filtering, but in one second you have the result, so it's a 3 megapixel photo and in one second you have the you have the result, which is pretty nice.",
                    "label": 1
                },
                {
                    "sent": "I'm quite surprised at 7 for transforms can be done in such a.",
                    "label": 0
                },
                {
                    "sent": "Short time.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then our example gained left.",
                    "label": 0
                },
                {
                    "sent": "You see the blurry image taken by the phone and the right is the cone Wolf one and the bottom you see in the middle bottom you see the point spread function which was rendered from the gyroscope data.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, I just have to thank at the end to all my collaborators, because this work has been done with many other people, so mainly I would have to say that the unfulfilled and make sure all incoming ski.",
                    "label": 0
                },
                {
                    "sent": "Those are my colleagues from the Institute, so they they collaborated on on the on the Super resolution problem and also payment Milan.",
                    "label": 0
                },
                {
                    "sent": "Far from UCSC.",
                    "label": 0
                },
                {
                    "sent": "We did some work together as well.",
                    "label": 0
                },
                {
                    "sent": "So thank you for your attention.",
                    "label": 1
                },
                {
                    "sent": "OK, the question was if.",
                    "label": 0
                },
                {
                    "sent": "The question was if we can if since we do not know exactly the time exposure, if we can optimize it because we know the whole trajectory and just find the optimal point.",
                    "label": 0
                },
                {
                    "sent": "The beginning of the point spread function definitely that this is something what I guess can be done.",
                    "label": 0
                },
                {
                    "sent": "We just started to do that like couple of months ago.",
                    "label": 0
                },
                {
                    "sent": "So you know there's still many things that can be improved.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the when you start to.",
                    "label": 0
                },
                {
                    "sent": "Really implement things on different embedded systems you you have to deal with problems that you haven't even thought about it.",
                    "label": 0
                },
                {
                    "sent": "You know that's like, for example, rolling shutter, which is something that I didn't know that it relax, but rolling shutter is something which is common in all the phones, so it doesn't expose the whole image at one time instance.",
                    "label": 0
                },
                {
                    "sent": "But it's rather moves at window from top to bottom.",
                    "label": 0
                },
                {
                    "sent": "So you the point function at the beginning of the point perfection will be.",
                    "label": 0
                },
                {
                    "sent": "Slightly different at different points.",
                    "label": 0
                },
                {
                    "sent": "That's another thing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the question was if we did some post processing of the data from the gyroscopes, because surprisingly we got such a clean data.",
                    "label": 0
                },
                {
                    "sent": "Clean or accurate point function, no.",
                    "label": 0
                },
                {
                    "sent": "None.",
                    "label": 0
                },
                {
                    "sent": "We haven't done no.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, so the question is how we how we really did it or how we get these points.",
                    "label": 0
                },
                {
                    "sent": "But functions that where they were.",
                    "label": 0
                },
                {
                    "sent": "They are the same point.",
                    "label": 0
                },
                {
                    "sent": "Special surprise or or it looks like the alignment was just not really proper between those subsequent frames, because yes, OK, so the OK.",
                    "label": 0
                },
                {
                    "sent": "The question is like about the alignment.",
                    "label": 0
                },
                {
                    "sent": "How we did that?",
                    "label": 0
                },
                {
                    "sent": "I'm actually.",
                    "label": 0
                },
                {
                    "sent": "I forgot that I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Well, the alignment here was just using using.",
                    "label": 0
                },
                {
                    "sent": "Face correlation actually so.",
                    "label": 0
                },
                {
                    "sent": "But by the way, it's not really if you have a blurry data, surprisingly not trivial to have quite accurate registration, so I always wonder how people can do subpixel registration with subpixel accuracy, especially if your data are blurred, because there is inherently some ambiguity in the whole process because of the blur, which is so.",
                    "label": 0
                },
                {
                    "sent": "We believe that it's actually much better to do it simultaneously, like insight, but it's true that how this algorithm was proposed.",
                    "label": 0
                },
                {
                    "sent": "We can only deal with Misregistration just translation.",
                    "label": 0
                },
                {
                    "sent": "You know, so by estimating the point spread functions, we can also estimate the shift because the points function can move around and when it moves around it compensates for this translation, but it does it automatically so you don't have to think about it so.",
                    "label": 0
                },
                {
                    "sent": "That's that's that's this.",
                    "label": 0
                },
                {
                    "sent": "Is this final step, and this one was face correlation or any other registration algorithm you can think of.",
                    "label": 0
                },
                {
                    "sent": "The question is, what's the capital D Capital D is the downsampling operator, because of course our input data also discrete date time and our final result U is also a discrete at the end, so the D is just downsampling.",
                    "label": 0
                },
                {
                    "sent": "Operator will be.",
                    "label": 0
                },
                {
                    "sent": "Ideally I actually it would be something which would have ideally just on the main diagonal.",
                    "label": 0
                },
                {
                    "sent": "Non zero values like every second.",
                    "label": 0
                },
                {
                    "sent": "Non dagger element would have one.",
                    "label": 0
                },
                {
                    "sent": "So, but you could also combine neighboring pixels, right?",
                    "label": 0
                },
                {
                    "sent": "Yes, so in practice, the D also does convolution with the point spread function of the sensor.",
                    "label": 0
                },
                {
                    "sent": "For example, it would be a Gaussian function, which we normally use in most of the cases, but there are ways how to estimate the point spread function of the sensor.",
                    "label": 0
                },
                {
                    "sent": "I guess it can.",
                    "label": 0
                },
                {
                    "sent": "It improves the results of a little bit, but we haven't really seen a significant improvement.",
                    "label": 0
                },
                {
                    "sent": "If you do some more sophisticated technique of because it's common to all the input data, then this is already a single channel case, so we are not dealing with that.",
                    "label": 0
                },
                {
                    "sent": "Don't sound.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so basically the question is how the performance of this of the method if you are increasing the resolution more than 2 * 4 * 8 times.",
                    "label": 0
                },
                {
                    "sent": "And of course you have the sufficient number of input data also increases as well.",
                    "label": 0
                },
                {
                    "sent": "The test that we did.",
                    "label": 0
                },
                {
                    "sent": "If you have a synthetically generated data then we really haven't notice any any any problem with that we would get exactly the same results.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately in practice it never works like that and we want our experience tells us that for the Super resolution higher than two doesn't really make much sense in practice.",
                    "label": 0
                },
                {
                    "sent": "One of the reasons could be and that's by the way why I was very happy that we could implement super resolution in the thermal cameras, because we're looking really hard to find some good application for super resolution because we found out that in if you apply super resolution to standard photos taken by camera, it doesn't really work so well.",
                    "label": 0
                },
                {
                    "sent": "The main reason is that the manufacturers of these cameras they want to avoid the aliasing effect of course.",
                    "label": 0
                },
                {
                    "sent": "And the aliasing effect here is something what we need and how they avoid it.",
                    "label": 0
                },
                {
                    "sent": "They do as they're optical system is set up in such a way that they have a band limited signal, and so their sampling is basically a Nyquist sampling, so there's really nothing to recover.",
                    "label": 0
                },
                {
                    "sent": "Whereas in the in the case of the thermal cameras, that's not a problem.",
                    "label": 0
                },
                {
                    "sent": "They can spend a lot of money on optical systems, the optical lenses, but what's very expensive is that the sensor, so yeah.",
                    "label": 0
                }
            ]
        }
    }
}