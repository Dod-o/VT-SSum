{
    "id": "k3w4n2nfe7hkzgqyl7jqtwlhysol2ene",
    "title": "Preferred Model of Adaptation to Dark for Virtual Reality Headsets",
    "info": {
        "author": [
            "Marek Wernikowski, Faculty of Computer Science, West Pomeranian University of Technology - ZUT"
        ],
        "published": "Jan. 29, 2019",
        "recorded": "January 2019",
        "category": [
            "Top->Computers->Multimedia"
        ]
    },
    "url": "http://videolectures.net/multimediamodeling2019_wernikowski_virtual_reality/",
    "segmentation": [
        [
            "OK, hello everyone and I'm American calfskin.",
            "I'm going to talk about preferred model of adaptation to dark for virtual reality headsets."
        ],
        [
            "So first I will briefly explain what the adaptation actually is.",
            "So this is a mechanism which is possible for human visual system that lets us to see in various different lighting conditions so we can see both in very well lit conditions, like in a sunny day and also in dark places like.",
            "Dark rooms with no lighting source.",
            "And this is possible thanks to photoreceptors which are present on the retina, varries their roots and cones.",
            "Roads are responsible for seeing in the dark.",
            "They are very sensitive to light.",
            "They even allow us to see.",
            "Like single to adapt to even single photons, but on the other hand they cannot really produce the color vision.",
            "That's why in the dark we usually see only in the grayscale, so to say.",
            "Um cones, on the other hand, are able to show us colors, and they are responsible for syncing and normal well, it conditions such as here, for example, right?",
            "The important thing is that we are constantly adapting to the some adaptation level, which is based on what we currently see and this level is constantly changing.",
            "We are not adapting to the same level of the time because we are switching the point we are looking at.",
            "The conditions are changing from time to time, so we have to somehow take this into account.",
            "So this whole adaptation mechanism is very interesting.",
            "Quality improvements that we could also implement, for example in VR goggles.",
            "That's why we started working on this project."
        ],
        [
            "So here are the implementation scheme, very basic of what we are currently doing in this project.",
            "So first of all we have to free the scene with models, textures and light sources.",
            "And we basically just render to texture files to do textures and then on those textures we perform the adaptation.",
            "Which are I will explain later.",
            "Another thing that we need to do as well after calculating the adaptation luminance of the luminous, we are adapting to.",
            "Is to do the tone mapping with also color discrimination because of different behavior of columns and routes, which I also explained."
        ],
        [
            "So the first thing that is important is how do we actually compute this adaptation luminance so?",
            "We have to take into account not only what we see in general, but also what we are currently directly looking at and this is explained by the contrast sensitivity function which shows us what contrasts are we able to see in depending on the eccentricity.",
            "And this is given by this equation here.",
            "And we just.",
            "Treat this equation as a kind of mask for our algorithm, so every single pixel in here corresponds to different weights of the luminance.",
            "So if we render an image, we calculate the luminous for each pixel and multiply it by the weights in this mask.",
            "Here this is of course in this case we are just setting the gaze position to be at the center, but it might change if we use the eye tracker for example."
        ],
        [
            "And the next thing is the the adaptation itself.",
            "So it's quite important to notice that the adaptation doesn't happen instantly.",
            "It takes some time.",
            "And the time it takes depends on many different factors, for example.",
            "It depends on the available light.",
            "And here is the simple graph showing how the adaptation might look like in some example conditions.",
            "In this case.",
            "We can assume that the user was fully adapted to light and went into a dark room.",
            "So at the start, the cones are fully adopted because we were previously in the well lit conditions and we are there slowly reaching higher.",
            "Sensitivity so that we can see better contrasts.",
            "But at some point the cones reached their highest possible level and there are no significant changes in this contrasts later.",
            "So what starts to make a difference are roads which are slowly regaining their sensitivity.",
            "And after some time we are getting used to the to the darkness and we can see something as well.",
            "But as you can see it takes quite a long time.",
            "I guess it might in this case it is like 20 minutes to reach quite good level of adaptation, but there might be cases in which it might take even longer so.",
            "Something that is not really easy to put into implementation.",
            "And notice also that.",
            "Here is not the adaptation luminance, but the threshold in which we see the luminance.",
            "So to convert this threshold to the adaptation luminance, we have to use the Webers low.",
            "Using the.",
            "Threshold versus intensity function."
        ],
        [
            "So this is the curve that the that we used.",
            "I mean this one that we used in our implementation.",
            "This is based on this one, but there are a few differences.",
            "First of all.",
            "There are different levels up.",
            "Are the boundaries are different because the display normal display won't be able to reproduce exact luminance values that we have in the real world, so this is also.",
            "Kind of important.",
            "And the next thing is that we significantly reduce the time of adaptation.",
            "Now it's only 20 seconds.",
            "So yeah, this is basically the model that is.",
            "Comperable to the human visual system.",
            "We also to compare it to the simpler version.",
            "I came up with this other solution which is just a linear model.",
            "So instead of computing this quite complicated equations, we can do just linear in log domain, which is also important.",
            "OK."
        ],
        [
            "So here is an example of comparing two different methods, the perceptual as we call it and the linear one.",
            "So first here's the linear one.",
            "So the luminous were adapted to is given here.",
            "By the way, this name.",
            "And it's constantly changing until we reach the luminance of the scene.",
            "So it's changing linearly in log domain.",
            "And the other one is following this curve so.",
            "In this case, we are adapting using cones, and at some point we reach their fullest sensitivity, so we adopt using rods."
        ],
        [
            "OK, the next thing is tone mapping, which is very important because as I said previously, we we have to take into account the limitations of the display we are using and also the limitations of human visual system.",
            "And we do that according to the works of forward and colleagues.",
            "First we have to somehow convert this luminance that we achieved through rendering to the luminance visible on the display.",
            "And we do that by calculating the thresholds versus intensity functions.",
            "Which I talked about earlier.",
            "And using these equations for.",
            "And different parts of vision.",
            "So for Scott Vision, which is the night vision which we get through roads and also the photopic vision which is available through counts.",
            "And then we compute them together.",
            "We add them together and there's also this additional factor which is K. It corresponds to the meso peak range, so something that is between rods and cones when we are.",
            "In the kind of state that is between darkness and brightness."
        ],
        [
            "And the second thing that is important to do is the color discrimination.",
            "So not only do we have to tone up the image, but we also have to.",
            "Somehow take care of the different color vision in different conditions.",
            "So we do that by adding an additional parameter.",
            "Which is responsible for showing how we perceive colors.",
            "So if the luminance is lower than 0.03 in log domain, then we know that this is complete darkness, so we can only render in grayscale.",
            "If it's higher than free look domain, then we can fully render in color vision and in the middle we use the Sigma Delta function which gives us mixed version of color and.",
            "Grayscale image"
        ],
        [
            "And here some examples of how we can show this so.",
            "Here are some well lit conditions with higher luminance values, and here are adapted to the to the darkness.",
            "So it's pretty much grayscale in some places.",
            "You might see some colors, but it's rather hard to to really notice."
        ],
        [
            "OK, so the next thing that we took care of was two tests.",
            "Which of those models that we did?",
            "So the perceptual and linear is actually better is more suitable for computer games or some kind of other usage.",
            "So we took the experiment in which user has had to compare those two methods.",
            "We didn't tell them which one is which, they just were shown to different adaptation methods for five different scenes.",
            "And were told to choose which one they looked more they like tomorrow.",
            "And this was the first experiment.",
            "There was also a second one in which we were checking which which adaptation speed is the best also for computer games.",
            "So it was pretty similar environment, but in this case they were choosing between 5:15 and 25 seconds."
        ],
        [
            "So here are the results.",
            "The first thing that was quite surprising for us was that users actually preferred the linear version of adaptation instead of the perceptual, which is also quite good for implementation.",
            "'cause it means that we don't really have to.",
            "Put too much pressure into correct version as we can just give the simpler version which is also easier to compute, it less and more efficient.",
            "What about the speed of adaptation?",
            "We can we see that we consider results here an.",
            "They are shown in the normalized number of votes, so 5 seconds.",
            "The five seconds show still lowest preference and 25 seconds is the highest preference in there, and this is for linear and this is for perceptual.",
            "The line connecting those two points indicates how much.",
            "And how many people preferred and the other the other speeds compared to the other one?",
            "If the line is blue, then this means that the results are significant, statistically significant, and if it's not at 9, then it means that we don't have statistical significance.",
            "So in case of perceptual model.",
            "We're mostly close to 50%, so we can't really give too much.",
            "Really say anything about those results, but in this case it is.",
            "We can give a strong assumption that people prefer.",
            "Usually the longer adaptation.",
            "So in this case 25 seconds it was.",
            "Preferred in 82% of cases for between 5 seconds and 25 seconds because people were comparing.",
            "Always between 2 cases.",
            "And also there is a preference of 25 / 15."
        ],
        [
            "So to conclude, we design the model which shows the visual adaptation to darkness and is suitable for VR headsets.",
            "And we take into consideration the effects of the photoreceptors and the guy's position as well, and using the eye tracker.",
            "And it seems that the people usually prefer the simplified model.",
            "Which could lead to some performance improvements.",
            "In the future we are going to use the higher quality displays to see how it could improve our model.",
            "And to also have a better color representation, for example using 10 bits monitors.",
            "And to also add additional features of human visual system such as visual acuity which is changing or some other effects like.",
            "For example, after image effects, which happens as well.",
            "So."
        ],
        [
            "So that's it.",
            "Thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, hello everyone and I'm American calfskin.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about preferred model of adaptation to dark for virtual reality headsets.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first I will briefly explain what the adaptation actually is.",
                    "label": 0
                },
                {
                    "sent": "So this is a mechanism which is possible for human visual system that lets us to see in various different lighting conditions so we can see both in very well lit conditions, like in a sunny day and also in dark places like.",
                    "label": 0
                },
                {
                    "sent": "Dark rooms with no lighting source.",
                    "label": 0
                },
                {
                    "sent": "And this is possible thanks to photoreceptors which are present on the retina, varries their roots and cones.",
                    "label": 0
                },
                {
                    "sent": "Roads are responsible for seeing in the dark.",
                    "label": 0
                },
                {
                    "sent": "They are very sensitive to light.",
                    "label": 0
                },
                {
                    "sent": "They even allow us to see.",
                    "label": 0
                },
                {
                    "sent": "Like single to adapt to even single photons, but on the other hand they cannot really produce the color vision.",
                    "label": 0
                },
                {
                    "sent": "That's why in the dark we usually see only in the grayscale, so to say.",
                    "label": 0
                },
                {
                    "sent": "Um cones, on the other hand, are able to show us colors, and they are responsible for syncing and normal well, it conditions such as here, for example, right?",
                    "label": 0
                },
                {
                    "sent": "The important thing is that we are constantly adapting to the some adaptation level, which is based on what we currently see and this level is constantly changing.",
                    "label": 1
                },
                {
                    "sent": "We are not adapting to the same level of the time because we are switching the point we are looking at.",
                    "label": 0
                },
                {
                    "sent": "The conditions are changing from time to time, so we have to somehow take this into account.",
                    "label": 1
                },
                {
                    "sent": "So this whole adaptation mechanism is very interesting.",
                    "label": 1
                },
                {
                    "sent": "Quality improvements that we could also implement, for example in VR goggles.",
                    "label": 0
                },
                {
                    "sent": "That's why we started working on this project.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are the implementation scheme, very basic of what we are currently doing in this project.",
                    "label": 0
                },
                {
                    "sent": "So first of all we have to free the scene with models, textures and light sources.",
                    "label": 0
                },
                {
                    "sent": "And we basically just render to texture files to do textures and then on those textures we perform the adaptation.",
                    "label": 0
                },
                {
                    "sent": "Which are I will explain later.",
                    "label": 0
                },
                {
                    "sent": "Another thing that we need to do as well after calculating the adaptation luminance of the luminous, we are adapting to.",
                    "label": 0
                },
                {
                    "sent": "Is to do the tone mapping with also color discrimination because of different behavior of columns and routes, which I also explained.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing that is important is how do we actually compute this adaptation luminance so?",
                    "label": 0
                },
                {
                    "sent": "We have to take into account not only what we see in general, but also what we are currently directly looking at and this is explained by the contrast sensitivity function which shows us what contrasts are we able to see in depending on the eccentricity.",
                    "label": 0
                },
                {
                    "sent": "And this is given by this equation here.",
                    "label": 0
                },
                {
                    "sent": "And we just.",
                    "label": 0
                },
                {
                    "sent": "Treat this equation as a kind of mask for our algorithm, so every single pixel in here corresponds to different weights of the luminance.",
                    "label": 0
                },
                {
                    "sent": "So if we render an image, we calculate the luminous for each pixel and multiply it by the weights in this mask.",
                    "label": 0
                },
                {
                    "sent": "Here this is of course in this case we are just setting the gaze position to be at the center, but it might change if we use the eye tracker for example.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the next thing is the the adaptation itself.",
                    "label": 0
                },
                {
                    "sent": "So it's quite important to notice that the adaptation doesn't happen instantly.",
                    "label": 0
                },
                {
                    "sent": "It takes some time.",
                    "label": 0
                },
                {
                    "sent": "And the time it takes depends on many different factors, for example.",
                    "label": 0
                },
                {
                    "sent": "It depends on the available light.",
                    "label": 0
                },
                {
                    "sent": "And here is the simple graph showing how the adaptation might look like in some example conditions.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "We can assume that the user was fully adapted to light and went into a dark room.",
                    "label": 0
                },
                {
                    "sent": "So at the start, the cones are fully adopted because we were previously in the well lit conditions and we are there slowly reaching higher.",
                    "label": 0
                },
                {
                    "sent": "Sensitivity so that we can see better contrasts.",
                    "label": 0
                },
                {
                    "sent": "But at some point the cones reached their highest possible level and there are no significant changes in this contrasts later.",
                    "label": 0
                },
                {
                    "sent": "So what starts to make a difference are roads which are slowly regaining their sensitivity.",
                    "label": 0
                },
                {
                    "sent": "And after some time we are getting used to the to the darkness and we can see something as well.",
                    "label": 0
                },
                {
                    "sent": "But as you can see it takes quite a long time.",
                    "label": 0
                },
                {
                    "sent": "I guess it might in this case it is like 20 minutes to reach quite good level of adaptation, but there might be cases in which it might take even longer so.",
                    "label": 0
                },
                {
                    "sent": "Something that is not really easy to put into implementation.",
                    "label": 0
                },
                {
                    "sent": "And notice also that.",
                    "label": 0
                },
                {
                    "sent": "Here is not the adaptation luminance, but the threshold in which we see the luminance.",
                    "label": 1
                },
                {
                    "sent": "So to convert this threshold to the adaptation luminance, we have to use the Webers low.",
                    "label": 0
                },
                {
                    "sent": "Using the.",
                    "label": 0
                },
                {
                    "sent": "Threshold versus intensity function.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the curve that the that we used.",
                    "label": 0
                },
                {
                    "sent": "I mean this one that we used in our implementation.",
                    "label": 0
                },
                {
                    "sent": "This is based on this one, but there are a few differences.",
                    "label": 1
                },
                {
                    "sent": "First of all.",
                    "label": 0
                },
                {
                    "sent": "There are different levels up.",
                    "label": 0
                },
                {
                    "sent": "Are the boundaries are different because the display normal display won't be able to reproduce exact luminance values that we have in the real world, so this is also.",
                    "label": 1
                },
                {
                    "sent": "Kind of important.",
                    "label": 0
                },
                {
                    "sent": "And the next thing is that we significantly reduce the time of adaptation.",
                    "label": 0
                },
                {
                    "sent": "Now it's only 20 seconds.",
                    "label": 1
                },
                {
                    "sent": "So yeah, this is basically the model that is.",
                    "label": 0
                },
                {
                    "sent": "Comperable to the human visual system.",
                    "label": 0
                },
                {
                    "sent": "We also to compare it to the simpler version.",
                    "label": 0
                },
                {
                    "sent": "I came up with this other solution which is just a linear model.",
                    "label": 0
                },
                {
                    "sent": "So instead of computing this quite complicated equations, we can do just linear in log domain, which is also important.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is an example of comparing two different methods, the perceptual as we call it and the linear one.",
                    "label": 1
                },
                {
                    "sent": "So first here's the linear one.",
                    "label": 0
                },
                {
                    "sent": "So the luminous were adapted to is given here.",
                    "label": 0
                },
                {
                    "sent": "By the way, this name.",
                    "label": 0
                },
                {
                    "sent": "And it's constantly changing until we reach the luminance of the scene.",
                    "label": 0
                },
                {
                    "sent": "So it's changing linearly in log domain.",
                    "label": 0
                },
                {
                    "sent": "And the other one is following this curve so.",
                    "label": 0
                },
                {
                    "sent": "In this case, we are adapting using cones, and at some point we reach their fullest sensitivity, so we adopt using rods.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the next thing is tone mapping, which is very important because as I said previously, we we have to take into account the limitations of the display we are using and also the limitations of human visual system.",
                    "label": 1
                },
                {
                    "sent": "And we do that according to the works of forward and colleagues.",
                    "label": 0
                },
                {
                    "sent": "First we have to somehow convert this luminance that we achieved through rendering to the luminance visible on the display.",
                    "label": 0
                },
                {
                    "sent": "And we do that by calculating the thresholds versus intensity functions.",
                    "label": 0
                },
                {
                    "sent": "Which I talked about earlier.",
                    "label": 0
                },
                {
                    "sent": "And using these equations for.",
                    "label": 0
                },
                {
                    "sent": "And different parts of vision.",
                    "label": 0
                },
                {
                    "sent": "So for Scott Vision, which is the night vision which we get through roads and also the photopic vision which is available through counts.",
                    "label": 1
                },
                {
                    "sent": "And then we compute them together.",
                    "label": 1
                },
                {
                    "sent": "We add them together and there's also this additional factor which is K. It corresponds to the meso peak range, so something that is between rods and cones when we are.",
                    "label": 0
                },
                {
                    "sent": "In the kind of state that is between darkness and brightness.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second thing that is important to do is the color discrimination.",
                    "label": 0
                },
                {
                    "sent": "So not only do we have to tone up the image, but we also have to.",
                    "label": 0
                },
                {
                    "sent": "Somehow take care of the different color vision in different conditions.",
                    "label": 0
                },
                {
                    "sent": "So we do that by adding an additional parameter.",
                    "label": 0
                },
                {
                    "sent": "Which is responsible for showing how we perceive colors.",
                    "label": 0
                },
                {
                    "sent": "So if the luminance is lower than 0.03 in log domain, then we know that this is complete darkness, so we can only render in grayscale.",
                    "label": 0
                },
                {
                    "sent": "If it's higher than free look domain, then we can fully render in color vision and in the middle we use the Sigma Delta function which gives us mixed version of color and.",
                    "label": 0
                },
                {
                    "sent": "Grayscale image",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here some examples of how we can show this so.",
                    "label": 0
                },
                {
                    "sent": "Here are some well lit conditions with higher luminance values, and here are adapted to the to the darkness.",
                    "label": 0
                },
                {
                    "sent": "So it's pretty much grayscale in some places.",
                    "label": 0
                },
                {
                    "sent": "You might see some colors, but it's rather hard to to really notice.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the next thing that we took care of was two tests.",
                    "label": 0
                },
                {
                    "sent": "Which of those models that we did?",
                    "label": 0
                },
                {
                    "sent": "So the perceptual and linear is actually better is more suitable for computer games or some kind of other usage.",
                    "label": 1
                },
                {
                    "sent": "So we took the experiment in which user has had to compare those two methods.",
                    "label": 1
                },
                {
                    "sent": "We didn't tell them which one is which, they just were shown to different adaptation methods for five different scenes.",
                    "label": 1
                },
                {
                    "sent": "And were told to choose which one they looked more they like tomorrow.",
                    "label": 0
                },
                {
                    "sent": "And this was the first experiment.",
                    "label": 0
                },
                {
                    "sent": "There was also a second one in which we were checking which which adaptation speed is the best also for computer games.",
                    "label": 0
                },
                {
                    "sent": "So it was pretty similar environment, but in this case they were choosing between 5:15 and 25 seconds.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results.",
                    "label": 0
                },
                {
                    "sent": "The first thing that was quite surprising for us was that users actually preferred the linear version of adaptation instead of the perceptual, which is also quite good for implementation.",
                    "label": 1
                },
                {
                    "sent": "'cause it means that we don't really have to.",
                    "label": 0
                },
                {
                    "sent": "Put too much pressure into correct version as we can just give the simpler version which is also easier to compute, it less and more efficient.",
                    "label": 0
                },
                {
                    "sent": "What about the speed of adaptation?",
                    "label": 0
                },
                {
                    "sent": "We can we see that we consider results here an.",
                    "label": 0
                },
                {
                    "sent": "They are shown in the normalized number of votes, so 5 seconds.",
                    "label": 1
                },
                {
                    "sent": "The five seconds show still lowest preference and 25 seconds is the highest preference in there, and this is for linear and this is for perceptual.",
                    "label": 0
                },
                {
                    "sent": "The line connecting those two points indicates how much.",
                    "label": 0
                },
                {
                    "sent": "And how many people preferred and the other the other speeds compared to the other one?",
                    "label": 0
                },
                {
                    "sent": "If the line is blue, then this means that the results are significant, statistically significant, and if it's not at 9, then it means that we don't have statistical significance.",
                    "label": 1
                },
                {
                    "sent": "So in case of perceptual model.",
                    "label": 0
                },
                {
                    "sent": "We're mostly close to 50%, so we can't really give too much.",
                    "label": 0
                },
                {
                    "sent": "Really say anything about those results, but in this case it is.",
                    "label": 0
                },
                {
                    "sent": "We can give a strong assumption that people prefer.",
                    "label": 0
                },
                {
                    "sent": "Usually the longer adaptation.",
                    "label": 0
                },
                {
                    "sent": "So in this case 25 seconds it was.",
                    "label": 0
                },
                {
                    "sent": "Preferred in 82% of cases for between 5 seconds and 25 seconds because people were comparing.",
                    "label": 0
                },
                {
                    "sent": "Always between 2 cases.",
                    "label": 0
                },
                {
                    "sent": "And also there is a preference of 25 / 15.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, we design the model which shows the visual adaptation to darkness and is suitable for VR headsets.",
                    "label": 1
                },
                {
                    "sent": "And we take into consideration the effects of the photoreceptors and the guy's position as well, and using the eye tracker.",
                    "label": 1
                },
                {
                    "sent": "And it seems that the people usually prefer the simplified model.",
                    "label": 0
                },
                {
                    "sent": "Which could lead to some performance improvements.",
                    "label": 0
                },
                {
                    "sent": "In the future we are going to use the higher quality displays to see how it could improve our model.",
                    "label": 1
                },
                {
                    "sent": "And to also have a better color representation, for example using 10 bits monitors.",
                    "label": 0
                },
                {
                    "sent": "And to also add additional features of human visual system such as visual acuity which is changing or some other effects like.",
                    "label": 0
                },
                {
                    "sent": "For example, after image effects, which happens as well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}