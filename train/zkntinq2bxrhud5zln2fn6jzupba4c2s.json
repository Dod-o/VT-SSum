{
    "id": "zkntinq2bxrhud5zln2fn6jzupba4c2s",
    "title": "Energy Minimization with Label costs and Applications in Multi-Model Fitting",
    "info": {
        "author": [
            "Yuri Boykov, Department of Computer Science, University of Western Ontario"
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Discrete Optimization",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_boykov_eml/",
    "segmentation": [
        [
            "Alright, well thanks a lot and this is very accurate introduction.",
            "I will try to connect to computer vision.",
            "What's going on in the beginning of a similar and thanks for inviting that.",
            "That's really great opportunities so well.",
            "Basically, I'll talk about the type of functional that involves includes labor costs, which is something relatively new for combinatorial methods and vision, but sort of as I go along.",
            "I basically will give you some idea of where the kind of energy is that.",
            "Related to what was discussed in the other talks used in computer vision.",
            "And more specifically, I'll talk about more."
        ],
        [
            "Eating a lot so.",
            "Give a brief introduction of general types of models that have been used since 80s and before that, and talk about specific label cost functional, how different and what extends, and then talk a lot about the applications for this.",
            "So again, my main goal here is just to show some people who do more like.",
            "More community optimization.",
            "What can be done with this methods in?"
        ],
        [
            "Addition well, let me start with a very, very generic problem in computer vision, which is denoising, and probably many of you know what it is.",
            "Roughly speaking, you have noisy image, so that's what's given, so you have intensities and you'd like to obtain some unknown labels.",
            "Supposedly, in this case corresponding to true image before the noise came in, so that's called image restoration, and the question is how do you compute those labels?",
            "From the data from intensities, and I mean there is no generic because in most other application there is still some data image, typically in some other labels, so it doesn't have to be restored intense, but it's a very simple generic problem too."
        ],
        [
            "Talk about first and then they kind of models that's been proposed early 80s to deal with this type of problems are often based on Markov random fields.",
            "Ideas from statistical physics say so basically well, if you have a grid of pixels and labels are per pixel, for example this week membrane model would have some data Fidelity term that typically comes as a likelihood term, so you can see this is.",
            "Negative log likelihood for some kind of Gaussian noise, but then decides the data Fidelity.",
            "Typically it will be some prior term.",
            "Again, the difference from the energies that we've seen in the beginning of the seminar is this is a negative logarithm of those energies that people talked about earlier.",
            "Then it becomes kind of some of the terms and again this will be the unary potential term and this would be typically pairwise term and just to give you an idea what kind of spatial regularity we're talking about here.",
            "Typically people like to have smoothness term which likes favors labels similar labels, but there is some kind of penalty for what's the largest.",
            "Sort of, the threshold for the largest penalty, and it's important for applications because that's what allows to preserve big jumps.",
            "Big, big, big discontinuity.",
            "So basically, that's where the membrane breaks off this big.",
            "Another maybe a clarification.",
            "So typically in computer vision people minimize energy, so that's another thing to keep in mind.",
            "Because that might be different, and also once you may notice here, I'm talking about the problem where it's not a binary problem like labels could be in principle that could be ordered set of labels like intensities.",
            "In this case you can think it's an order set or for stereo could be disparate, is all sorted set, but often enough if you talking bout for example motion estimation, then their labels do not have to be ordered.",
            "So generally speaking we deal with this type of."
        ],
        [
            "Problems OK, so let me just outline real brief.",
            "What's the state of the art for minimization?",
            "So if you have this type of interaction potentials which are convex, then this is an easy problem and you can find exact solutions in polynomial time.",
            "I'm in.",
            "Pretty much convexity here helps a lot, but this type of potentials they don't preserve sharp boundaries between objects, so people don't well, I mean there are many useful things you can do with it, but it's not as nice as people hope.",
            "So basically you don't like the penalty Gray really fast grow really fast as the difference, so you want to somehow cap it, and if you like among convex interactions, the linear interaction or should I say absolute value interaction is actually better because it doesn't.",
            "Grows fast this quadratic so you wouldn't be over penalizing the differences too fast, but this minimization is already more difficult because of non differentiable functions, so it's still doable.",
            "You still can find global optimum, but it's harder, particularly like creational settings.",
            "People typically try to get rid of this by smoothing it a little bit, or doing other things, and once you get to the problems like this, which nonconvex potentials and for example like I showed truncated here or something like this, then it's NP hard and.",
            "You have to deal with the proximation methods and message passing with some graph cuts based algorithm being proposed to deal with this and they have certain optimality guarantees, but I'm not going to."
        ],
        [
            "Too much with this, so one extra example of discontinuity preserving kept interaction is what's called Ising model in binary case, or in case of labels.",
            "It's called Potts model, and in this case if expansion algorithm in particular is known to give approximation factor of 2.",
            "What kind of problem that you can solve?",
            "This is piecewise constant labeling, so this is kind of different from the first image restoration example, where those kind of gradual change in intensities and this potential wouldn't work well because basically create bends of constant density.",
            "But if you indeed you're labeling you're looking for is piecewise constant, then it's actually pretty good solution and interesting in many problems in vision, and I wouldn't say all not at all, but large number of problems can be formulated speaks with constant labeling, which is what this."
        ],
        [
            "It is about just give you one idea, maybe front of parallel stereo where you have two images left eye right eye and the labels now are not intensities.",
            "Labels are disparities.",
            "Well this is kind of solution.",
            "You're looking for.",
            "This is labeling each colleges represent certain depth layer.",
            "Just my visualization with and perhaps both model can be used.",
            "I'm saying it's just an example of where the labels is something different from intensities you've seen before and the data term here would be.",
            "Not just the square differences would be based on what's called for the consistency, but generally speaking it's not hard to compute.",
            "For example, what you do is you take pixel in the left image at disparity or label that you want, you get a new pixel in the right image, and you compare the intensities that would be for the consistency."
        ],
        [
            "Anyway, So what I'm trying to advocate now is a new term added to this type of images, which we call we refer to it as label costs.",
            "Basically what that adds to the synergies.",
            "Basically it counts in the simplest form of this function counts the number of labels actively used in the solution, and one thing I'd like to mention is in principle this is not a normal functional.",
            "It's been designed and in the context of computer vision by people like Lyrica.",
            "Advertise this in 89 and he advertises from the minimum description length principle.",
            "So basically instead of MRF framework, Markov random fields and statistical justification is all the arguments with dysfunctional seemed to be information theoretic and I kind of really like this.",
            "Maybe if I have time I'll cover a little bit more details in that.",
            "As far as minimization goes, because he still wanted to find the optimal labeling here he had some generation of gradients on convexity.",
            "Basically what this work.",
            "So our work is about is how to do it better in still combinatorial discrete settings, but people other people in computer vision looked at the same functional but equivalent functional formulated in a continuous setting.",
            "Basically, one thing I'd like to mention and computer vision there is lots of people from Community who are interested in combinatorial, discrete algorithms, But there are tons of people who are using variational methods to minimize continuous analogues of this functions, and there are immediately obvious, continuous up analogs of this.",
            "Like, for example, this would be.",
            "Some integral over region of some potential function.",
            "This would be actually some, for example geometric length for the discontinuity between the.",
            "Segments so basically genetic link for the boundary and this still would be the number of segments for example.",
            "So people propose different methods for minimizing this.",
            "Some.",
            "Other group of people worked on functional where you take just these two terms, and in fact this is something nice and I also would mention this in this talk later.",
            "Minimization well again justification for this hyper functional is also based on information theory and acnb icy criteria.",
            "So this is pretty well known work, and in particular he suggested some greedy heuristic method to attempt minimizing this type of functionals.",
            "Lee much more recent work he was using LP relaxation for this functional, but without any kind of optimality guarantees that was more like a heuristic.",
            "Well, let's just do LP relaxation and then truncate, but there was no intent.",
            "Discussion of what guarantees that gives.",
            "Finally, there's some more continuous workout."
        ],
        [
            "Keep that for the sake of giving little going a little faster.",
            "So what we will contribute to this area is basically generalization of life extension method that allows to deal with this and certain optimality guarantees are possible.",
            "So basically it is possible to minimize such a functional with certain guarantees an we also discuss, for example, special case.",
            "We have only this two terms, minimize it with some UFO heuristics and understated incapacitated for steel to location.",
            "Problem basically that's equivalent to it.",
            "Surprisingly, people in computer vision don't know this method so much, and however they could be pretty useful and fast, even though one of the things I'll show you that you really need this term for many problems and will also focus on some of the applications for it, so I hope to give you an idea what this is good for.",
            "However, I'm not going to give you any technical details as to how this works.",
            "So basically one assumptions I'm making here that you don't care about them, or if you care about them just there on paper this.",
            "Not not, not.",
            "Shouldn't be too difficult to read, so I'm kind of more interested in giving you the general idea of what this type of energy is do."
        ],
        [
            "There's also related papers which mean you might similar functionals, and they are all fairly recent address specific applications, but I just.",
            "Kind of presented."
        ],
        [
            "My way anyway, so why label costs and what are those generic model fitting problems?",
            "I'd like to discuss with you which fit into this frame."
        ],
        [
            "Well, let me start with the most basic model feeding problems.",
            "Probably most of you seen before is how to feed the line into a cloud of points and then a simple example like this where you don't really have outliers and what you can do is like your model is described by two parameters, AB.",
            "For each point you can define certain geometric feed error.",
            "It could be vertical distance that could be orthogonal distance, your choice and then you can compute model parameters.",
            "In this case just A&B.",
            "Which minimize the sum of squared differences, for example, and you would have closed formula for many of those cases, and generally speaking maybe not.",
            "But for line fitting."
        ],
        [
            "You have.",
            "Such, but what happens if you add outliers?",
            "Because we're moving into computer vision and in computer vision you never have.",
            "100% inliers, you always have outlines.",
            "In fact, many of them.",
            "So one option you can do is OK. Well, let's move from quadratic loss function to something that doesn't over penalize so much to this linear minimizer.",
            "Basically to get some kind of log for the median filter.",
            "That's possible, except it's immediately harder.",
            "There is no close formula and why it's not differentiable.",
            "That's basically the same reason is what I mentioned for similar problem.",
            "Completely different settings.",
            "So median filter can do, but it's more difficult.",
            "And the other thing it breaks once you have really large number of outliers and in fact in the problems that I'm interested in, the number of outliers is much more than this.",
            "It could be 80, it could be 90, something like that.",
            "Then basically then I'll be doing multimodal fitting.",
            "They are basically in life for one model.",
            "It's like only 10% of the data.",
            "Something like this.",
            "Well, what does the answer to this problem which goes beyond the median filter?",
            "Probably many of you.",
            "I don't know how many, but probably some of you know ransack and ransack is really standard answer in computer vision.",
            "For this type of problems."
        ],
        [
            "Basically, so it seems like pretty simple idea, but I'll tell you why I really like so well.",
            "First, let's the main thing in this idea.",
            "It starts with sampling data points to generate some proposals for what the lines could be, and basically in line featuring.",
            "You need only two points to fit a line, right?",
            "So what you do you randomly sample two points feet align into it?",
            "And what do you do then?",
            "Well, you sign certain quality measures."
        ],
        [
            "This line by counting inliers within predefined threshold.",
            "So threshold is fixed.",
            "So you do is just count how many points in there, let's say 10 and then if you keep sampling you don't stop here.",
            "You don't sample just once you sample certain number of times, say North, and eventually there is certain probabl."
        ],
        [
            "That two points that you sample will be like this in this for example.",
            "So eventually, at some point you will get the sample like this and what will set it apart from other samples.",
            "The number of inliers, so you'll immediately see that there is something special about that particular one, because it has much larger number of inliers.",
            "So basically what you're doing ransack you keep sampling for certain number of times, and from a sample of certain size, you select one model with the largest number of inliers.",
            "So that's as easy as that, and the point is, it works really well.",
            "What's the beauty of it?",
            "I mean, because it seems to me that when I say that it's a really simple heuristic and I mean to some extent, it is the beauty of it.",
            "Is that the answer for the question of how many times you have to sample to have a probability of success, and that's where we'll just success that you indeed sampled the two points which are inlier for the true model.",
            "So basically for any known a priority percentage of outliers, you can compute how many samples you have to do to draw in order to reach certain probability of success.",
            "And just to give you an idea of what makes me excited about this, if you have 80% outliers and you want to achieve 95 probability of success, you need only 20 samples.",
            "I find this amazing.",
            "That's why ransack is an interesting idea, and that's why people use it a lot in computer vision.",
            "But basically, their answer here says surprising, perhaps.",
            "As you know, one of the questions that people typically deal with when they take a first year course on probability.",
            "They tell him what's the probability that you have two people in this group has the same birthday, and basically intuitively everybody will say, but it's very unlikely.",
            "But everybody knows that almost every cluster was a pair of students like that, and if you do the computations you realize this probability is pretty high, so it's pretty much the same thing here.",
            "So basically the beauty of France like is that formula that tells you that you don't need to sample that much to have a probability that you sample.",
            "From two inliers, OK."
        ],
        [
            "Having said that, next thing, what do we do?",
            "Have multiple models and that's what I'm interested in.",
            "This paper in this talk, so it seems like why not do the falling and that's what sort of sequential ransack that or suggestive, 98.",
            "Well, let's just do this iterative.",
            "Let's first sample large number of lines and select from it model with large numbers.",
            "And let's say for example this was model that perhaps would be the largest number in layers and some role model.",
            "Would not have been a large number of inliers, so that's basically the assumption.",
            "Once you got one, which you can do, you can now remove it with its inliers, and keep doing this sequentially.",
            "So basically, then, probably the next strongest model would be this, this, and so on."
        ],
        [
            "That seems like a nice idea, except.",
            "Eventually, if you have actually very large node not allowed amount of noise that stops working.",
            "So basically pretty random model may have large number of inliers, that good model.",
            "Basically, there is no what I'm trying to say.",
            "My point here is, once you have multimodal situations where data supports not just one model but many models besides just one and some outliers, then just this heuristic approach of counting the number of inliers is not a measure that you can trust in this kind of greedy selection of the models.",
            "What I'm going to propose actually looking at the whole problem as labeling of all data points with model.",
            "So basically don't select one at a time.",
            "Try to find an explanation for the whole picture based on certain energy.",
            "That kind of discovered.",
            "This describes situation global."
        ],
        [
            "So well, let me actually advocate this approach, but do one step at a time, basically.",
            "First let me look at the kind of simplistic energy interpretation of transect does in case of a single model.",
            "So forget about multiple models.",
            "Let's just deal with one model.",
            "Basically you saw this functional already right?",
            "I'm saying that L. Here is this pair of parameters for line.",
            "So for that single line that's data supports and basically this distance between point P and the line is for example something like this, it's.",
            "Zero is the distance between P&L.",
            "If this vertical distance or whatever is my geometric areas is, it's less than threshold in this penalty one.",
            "If the distance is larger.",
            "So if I'm minimizing this, you can see that I'm counting the number of inliers correct.",
            "And basically I'm selecting L by minimizing this functional that gives me the largest number of inliers.",
            "OK. Well, what happens if I?"
        ],
        [
            "Try to apply this to multimodal case in the model model case the immediate need is to actually allow each point to have a model because you can't fit one model to all data, so therefore you have to introduce in principle as many labels as potentially points because you don't know in advance how many models are in there.",
            "But if I try to minimize this functional where my energy is now over this labeling, I'm going to get drunk because basically if I just have that.",
            "Every point is going to select line that it sits on.",
            "It doesn't matter which one any.",
            "There will be 0 and that's lowest value for this.",
            "This is not going to work correct, So what do I need and notice the reason?"
        ],
        [
            "It worked in case of single model because there was only one model I have to fit one model."
        ],
        [
            "Do the whole thing OK, but as soon as you have multiple, you need to regularize.",
            "Basically, you need to say I generally speaking, like solutions which are simple enough."
        ],
        [
            "Sense, for example, like they have small number of lines that explain the data.",
            "So basically I'm talking bout here my first term.",
            "That's one alternative for what you can do for regularization."
        ],
        [
            "Another alternative, which actually we also tried and works quite well, is spatial organization.",
            "Well, you may say.",
            "How can I explain this well, and in case the data points are not image pixels, what's my neighborhood structure?",
            "What does my smoothness?",
            "Well you can do nearest neighbor graph or triangulation perhaps, and whatever we tried, it seems like it didn't matter too much.",
            "So basically some kind of.",
            "The logical structure can be induced here alright then, basically then regulation would be the same ports model that I talked about before.",
            "Basically I'm kind of using here the fact that points nearby closer to each other typically tend to have the same label."
        ],
        [
            "Alright, or perhaps all three, and basically what I'll try to convince you that I mean all three.",
            "I meant all three terms, but the old both, both the spatial smoothness and label counts that could be useful, and what kind of solutions I'm going to get.",
            "Well, generally speaking, I hope that this is what is a good solution with respect to the center.",
            "So basically this is the labeling which is optimal respect to the functional.",
            "Why well points tend to be close to the?",
            "Are models that they assigned?",
            "As you can see, most of the discontinued this occur between points which are far from each other, so like this is a cluster of points and they assign the same model.",
            "And finally you explain the solution with few models, not with large numbers.",
            "So basically one way to think about this and this is where I'm deal.",
            "By the way interpretation comes in.",
            "Basically what you see here is the small small number of labels explaining whole data set, so I'm not trying to select one model at the time, I'm just trying to find the whole picture at once.",
            "I'm trying to describe a functional.",
            "That actually tells me what the whole picture is, not just one at a time thing.",
            "OK, well, and then I told you I can minimize the challenges right with life extension.",
            "For example, something in the beginning.",
            "Well, is it so easy?",
            "In this case there is one detail missing, and this detail is actually fairly important, because basically when I'm talking about expansion typically I mean finite number of labels, right?",
            "The number of candidates.",
            "Can labels water labels here model parameters.",
            "So it should be finite and do I have such a thing when I just started solving this problem?",
            "Well know my labels are points in R2 like lines.",
            "So that's the big issue.",
            "And that's actually something that we have to address.",
            "And basically we cannot really directly apply life extensions.",
            "You kind of do a little bit of trickery here.",
            "Basically you have to propose some algorithms dealing with this issue, which sort of explores the space of labels in a way where actually sampling of the data points helps.",
            "So basically you may remember what I told you about RANSAC, right the sampling?",
            "Well, what does it do?",
            "Well there it basically has.",
            "This formula tells you what's the probability.",
            "Of obtaining a success.",
            "Meaning some reasonable model when you sample that many times, and that's basically what I need.",
            "I need just basically to generate certain pool of labels.",
            "Discrete which has large probability of having reasonable models in it.",
            "That's what I need.",
            "So basically to come from the continuous problem.",
            "Within the space of labels, it's continues to something more discreet.",
            "I'll use a little bit of sampling to generate good proposals for me."
        ],
        [
            "So, roughly speaking, what it looks like.",
            "Suppose this is this noisy problem I'm trying to solve.",
            "So how many models do you see?",
            "Five, OK, I would agree to that.",
            "OK five.",
            "12345 alright, well let's see what they are."
        ],
        [
            "Would do so basically the first.",
            "By the way, the algorithm called Pearl, but it's not the same Pearl as I mentioned before.",
            "BRL two so the Pearl stands for proposed expander estimate labels, so proposed.",
            "What's the proposed?",
            "The proposed is basically I need to throw a bunch of labels, which I think have good candidates.",
            "So basically what I'm hoping for, I'm sampling this data points hoping that with certain probability it contains good candidates.",
            "Basically it's my way to discretize the space of labels.",
            "Think about that.",
            "So the space of labels is R2.",
            "I need to discretize it somehow and I think this is smarter than just doing some kind of stupid discretization over DX and DDA&B.",
            "That's all I'm saying.",
            "So this is better because there's a better chance that by doing just a few of them I'll actually cover the good ones.",
            "Alright, so how do I going to make sense out of this mess?",
            "'cause this is a mess?",
            "I mean, how do I know which is good and which is not that I don't know?",
            "I just know with some probability this contains good ones and this is where my energy minimization comes in.",
            "So basically I plug this discrete labels into this.",
            "Energy, and now it's discrete.",
            "Set of labels an I'm using my energy minimization framework.",
            "Will it be with just spatial smoothness of Labor costs?",
            "Doesn't matter.",
            "So basically I'm trying to once I apply this immediately from all this mass, the method selects only few, which makes sense because it doesn't want to like.",
            "I mean I'm trying to get solutions which are good with respect to this energy so it automatically throws out unnecessary models.",
            "By the way, maybe you will be wondering what are those Gray ones?",
            "I'm using a pretty standard trick and MRF based optimization I'm.",
            "Adding one more model which is not align.",
            "This model is just some kind of uniform outline model, where basically it's additional model.",
            "And the data feed for it for every point is just fixed constant.",
            "It's I didn't have to do this, it's just basically I'm."
        ],
        [
            "Sorry if I flip back a little bit, so here I didn't use this model an in this case I'll find lines to explain the whole data set.",
            "If you want to, you can decide for yourself later using some.",
            "I mean it's a philosophical question here.",
            "What's the main line?",
            "What's an outlier, right?",
            "I cannot answer this and you cannot answer this unless you have some kind of well, I mean some other additional answer like you know, can you tell me this is outlier?",
            "I don't know.",
            "Maybe for someone that is outlier for someone that's not.",
            "But what I'm trying to say.",
            "What I've done here with this functional I explained.",
            "All data with the least number of models and you can decide for itself later or."
        ],
        [
            "The alternative solution that I was advocating here.",
            "I had an explicit label discrete one label for an outline model an all of this to difference with lines.",
            "Lines have the penalties which may depend on where the point is and where that line is for the outline model is just fixed costs and basically this points prefer to get this line because the cost is very small.",
            "Well, this point doesn't like any of these lines because it's too far.",
            "It prefers.",
            "Take a fixed cost associated with the outline, but I mean this is this tender trick.",
            "I'm not saying anything you, I just want to make sure that you're not puzzled by those great points, OK?",
            "So you can have basically more points automatically labeled outlier or in life model blah for model block model.",
            "Alright well I mean, but the point is ransacked.",
            "This statistical sampling thing doesn't guarantee that you actually got perfect model samples, so there is actually oppurtunity for me within this energy framework to improve what I have.",
            "What can I do?",
            "Is well, imagine I fixed this term by saying I'm not going to change the inliers, but I'm going to fiddle with the model parameters for a set of inliers here.",
            "And if."
        ],
        [
            "Do this that I'm going calling is their estimation of OK Now the energy is here."
        ],
        [
            "If I estimate the model parameters, Notice my line adjustable, so I'm doing here some coordinate descent.",
            "Obviously Gordon descent with respect to segmentation or assignment stage versus model parameters may see what it does is just basically it's a better way to explore the space of labels.",
            "I'm still minimizing the same function as before, I haven't changed my problem, I'm just trying still to deal with the fact that the number of models I have could be, well, basically, the models are points in R2 and I have combinatorial algorithms to deal with it.",
            "So basically this iterative procedures still uses the same energy.",
            "But in a coordinate descent fashion change iterates the assignment versus re estimation stages to improve the best it can.",
            "I mean these dimensions they just takes care of this term assuming that the assignment of inliers is fixed.",
            "So just likely just the and the point is, you can keep doing this because once you have."
        ],
        [
            "Labels you can."
        ],
        [
            "Re segment on the."
        ],
        [
            "Energy keeps going down by iteration.",
            "In principle you can add more proposals if you want to.",
            "It's up to you and kind of it's always possible, so adding more labels never hurts because they will automatically selects what it wants."
        ],
        [
            "And they."
        ],
        [
            "Quickly the energy goes."
        ],
        [
            "Sound eventually will have those five models.",
            "Well, I mean, obviously I chose.",
            "I'm not going to say it works perfectly 100% of the time, but I mean we've already publications would try to.",
            "There's quite a good level of robustness, robustness."
        ],
        [
            "OK, so let me show you one plot that sort of gives you a little bit of information for what's going on.",
            "What's on this plot?",
            "It's actually still one single model fitting example, so there there basically Holy Grail of ransack because RANSAC works.",
            "If you have one model to fit, I am not going to claim that maximizing the number of inliers based like one of those bad.",
            "It's still good approach, but what I'm trying to say, this energy minimization framework allows you to deal with smaller number of samples and iteratively improve it because.",
            "We keep improving the label Cemetery fashion, something that Rancid can't quite do because there isn't really one unified energy there.",
            "I mean, it's something that perhaps can be debated, but everybody knows that.",
            "And then second, just two steps.",
            "First, select the model with lunch number of lines and then once among those in life, try to feed slightly better model.",
            "But this is basically using exactly the same number of samples, which is along these lines and what you're getting.",
            "The vertical line is the geometric error from its synthetic example, so we know exactly what the ground truth is.",
            "So we could measure the how far the model we converge to is from the ground truth, and basically what you see here is that.",
            "Well, first of all this at magic number to 20 more samples is all you need from ransack to get pretty decent results, so that's kind of right here, but we need fewer models because even from Arruda rough models we can actually fiddle with it and convert to something better, so I'm not going to claim that we can do it faster because there is quite a bit of optimization, But the point here is different.",
            "The point is the number of model."
        ],
        [
            "And again, this is low."
        ],
        [
            "This situation."
        ],
        [
            "RANSAC works.",
            "RANSAC work."
        ],
        [
            "Our method also works as soon as you have high noise."
        ],
        [
            "You're going to get random junk from ransack because exactly what I told you.",
            "Maximizing the number of inliers and selecting Model 1 at a time.",
            "This is going to fail.",
            "So."
        ],
        [
            "But if you look at the whole well, there's some other."
        ],
        [
            "Similar methods if you."
        ],
        [
            "Going to spend time on this, but once you look at the whole situation and the energy.",
            "That's the answer you're getting."
        ],
        [
            "So you can do circles.",
            "Now I'm getting a bit more into applications.",
            "How many minutes do I have?",
            "If I have any.",
            "OK."
        ],
        [
            "So.",
            "Real application, so this is homography fitting.",
            "I'm not going to explain too many details from the application setting point of you, but you have two images and there are some points which been matched by some feature matching algorithms.",
            "I don't know if you know sift, OK, pretty standard thing and everybody is using it for all sorts of things, so I'm trying to feed 3D planes here and this is what you get with our energy method.",
            "I just kind of quickly can tell if you use sequential, ransack or some other methods which uses greedy maximization allies.",
            "They kind of get OK this, but as soon as you're getting noisier stuff, it's kind of difficult."
        ],
        [
            "OK, there's another kind of models you can feed, and this is kind of completely different example and this is closer to what I'm doing.",
            "You lamented this paper 98 or something like this, so that's actually example from their paper an from a model featuring POV, the functional that I'm describing completely fits here.",
            "So what I'm trying to do this in image.",
            "These are data points like this dance pixel grid, and basically I'm trying to fit models which are color distribution.",
            "So basically instead of geometric model, this is called distribution.",
            "I'm trying to describe.",
            "The image with the fewest number of colors."
        ],
        [
            "Tribu shun's, and this is the kind of solution that's what we get.",
            "But I mean the same picture confined in June.",
            "You'll 96 actually.",
            "OK, I was wrong.",
            "Well there is.",
            "I'm using this picture is actually straight.",
            "Also, this different combinations of dysfunctional because I'm kind of interested in this."
        ],
        [
            "Empirical issue, So what exactly is that?"
        ],
        [
            "So here I used all regularity with spatial regulators across label costs, and I'll explain sort of why."
        ],
        [
            "I get this, but this is what happens if you have only spatial regularity, and this is kind of the best solution we could get with it.",
            "Basically what I'm trying to claim, if you use only spatial regularity, this is basically if you start.",
            "If I start increasing the regularization went further, eventually it will merge the horse into one, but it already starts over smooth here, so it will smooth even more.",
            "So if you rely on spatial regularity only to kind of group your pixels into sort of horse, you already doomed because even before the horse got.",
            "One horse you already start over smooth, so basically that's the best result."
        ],
        [
            "Yet without labels.",
            "But as soon as you have labor costs notice you need like labor costs or something that allows you to merge the models together, like trying to minimize the number of holes without really pushing too hard on the smoothness.",
            "Let's go."
        ],
        [
            "Empirical thing but."
        ],
        [
            "Interesting, but if you have only label costs in this column model fitting, you're not getting any regular results.",
            "Also, you do need spatial smoothness here somewhat to kind of give you a reasonable special.",
            "I mean an image analysis.",
            "I'd like to say this regulation.",
            "Specialization makes a lot of sense."
        ],
        [
            "Yes, many cases.",
            "OK, well just typical."
        ],
        [
            "Other examples for this?",
            "Enter really likes this person, so he really wanted to have.",
            "The."
        ],
        [
            "Well, anyway."
        ],
        [
            "Someone well, let me actually do this comparison of these different types of functionals for back to this."
        ],
        [
            "Model fitting, so actually surprisingly, if you use just label costs for regularization.",
            "It works here and the question is why?",
            "Well, why do I get really bad noisy results for when I use label costs for segmentation?",
            "Because they are the model was histogram.",
            "It's completely by itself is whatever.",
            "There's no regularization in it, while if you fitting planes planes have regularity by themselves, sort of.",
            "I don't know if I made it clear because it's not scientifically, but I hope you see what I mean, right?",
            "So basically the only problem here is notice this yellow sports.",
            "What are they doing there?",
            "Well, there isn't why they're there, because if you extend display in here, this is where they intersect this plane and displaying alright.",
            "Well, I'm just happened at this point was just a little closer to this since there is no spatial regularity.",
            "It chooses free to choose which model is closer to what.",
            "I'm trying to say here is that in many applications in particular geometric applications, computer vision, just labor costs works really well, and actually the algorithm for minimizing this is much faster than Alpha expansion.",
            "The CFL heuristic Convention as well by order of magnitude faster.",
            "And basically you can decide.",
            "Well, maybe you can just smooth it out later by some filtering or whatever, well."
        ],
        [
            "In case what happens if I have only spatial regularity, like Now, no label costs, just spatial regularity term.",
            "What do you get the results look good?",
            "There are no those noisy points, but there is a little bit of a problem.",
            "I would like to point out that this and this is the same model.",
            "It's the same plane and.",
            "This, this and this are the same plane.",
            "They are not merged because they're spatially disconnected, so my specialization term has no power to merge them into one model.",
            "As soon as you have two spatial disconnected blocks, specially where it has no force into trying to reduce the number of labels.",
            "So basically that's."
        ],
        [
            "Going on as soon as I have everything notice I have neither garbage here and this is the same.",
            "These three are the same.",
            "These are this in fact this this and this are the same.",
            "So basically you get the best of everything possible and I mean that's kind of empirical, but I hope you sort of see what I'm trying to say is.",
            "Envision you often need both types of."
        ],
        [
            "Causation, well, motion fitting, motion fitting, rigid motion.",
            "Basically you can show that you haven't dependently moving rigid objects, they all are based certain type of models that you can also describe in parametric fashion."
        ],
        [
            "So this is what you get with label costs only.",
            "So it's not bad, but there are those weird things I cannot explain why this feed into the background because my this model somewhat 7 dimensional with feeding fundamental matrices in here, so I cannot quite visualize why this feeds the same motions here, so it wasn't like remember like with the planes I could tell you those, why don't those yellow dots were extensions of that plane?"
        ],
        [
            "Here I don't know.",
            "As soon as I have spatial regularity, I don't have this junk, but notice that this this in this, which is the same background, so they don't move with respect to each other, so there's only one model, but since they're spatially disconnected, sort of."
        ],
        [
            "They're not together.",
            "And finally we have all three terms.",
            "I find the exact number of right number of motions.",
            "There are three motions.",
            "OK and."
        ],
        [
            "The."
        ],
        [
            "Or some other?"
        ],
        [
            "Examples this is just homography feeding but I really like this because.",
            "We found 13 planes here like this.",
            "White is not the same as this white just we ran out of colors OK or this pink is not the same as this pink or that pink just we did know some colors like orange or whatever.",
            "Basically first we were a little bit disappointed.",
            "We thought what's going on here like why is it different plane?"
        ],
        [
            "But we found really large great comfort in seeing that these are steps.",
            "So basically these are not quite the same planes.",
            "OK, so basically it was first a little disappointed only with a big sigh of relief after we saw some other images of the same."
        ],
        [
            "Or the same object well?"
        ],
        [
            "I'll"
        ],
        [
            "Probably skip that.",
            "Let me do you have anytime at all or no.",
            "No, OK, so one last thing I just want to show you remember this segmentation that I described earlier.",
            "Actually there is this MDL interpretation for that's why kind of layer closure and you use it because basically this energy function line minimizing is basically especially if I use a data term, this negative log likelihood this can be thought of the number of bits required to compress this image in the following way.",
            "I'm basically each segment.",
            "Each segment is labeled so just distinct label is a color model.",
            "OK, and basically this for each pixel assign certain column like for example this pixel using this particular model.",
            "That's basically the number of beats that I need to describe this intensity using that color model represented by certain distribution function.",
            "So basically this is number of bits required to express the old images or limited pixels.",
            "What is this?",
            "Well, imagine you sending this image over some channel right?",
            "You need to probably send it into some kind of scan order, right?",
            "So basically as you switch from one model to another, you have to send the signal.",
            "Basically, this is the number of bits required to send when you switching from one column to another.",
            "That's one thing, and this was this.",
            "Why do I need to send the number of models?",
            "Well, because I need to send the coding scheme as well.",
            "So basically this is purely number of beats.",
            "This can be interpreted as number of bits and I'm not the first one to tell.",
            "I click player talks exactly about that.",
            "The reason I'm explaining this."
        ],
        [
            "In detail, because we actually propose certain interesting extension, the words loss, image compression.",
            "So this is the same function as you seen before I added something else.",
            "Basically what I'm trying to do, I'm trying to find some other image high bar.",
            "Which is distorted version of my original image, but which probably compresses better.",
            "So basically I'm trying to find now an image which I'm going to reconstruct.",
            "So I'm going to compress closely.",
            "This image I bar, but I'm allowing my bar to be different from my.",
            "Not too far though in this Lambda controls.",
            "So basically if Lambda is Infinity Notice, then I bought has to be equal to I so it's the same image, so it's lossless,"
        ],
        [
            "And then I get sort of pretty much that we might restoration, but as soon as I kind of starting to decrease Lambda, notice that I get better compression by getting some distortion here.",
            "So it's a standard in the Shannon sense information distortion.",
            "What's this distortion theory anyway?",
            "So is I'm decreasing the Lambda rate distortion theory?",
            "OK, that's the term, as in decreasing the Lambda, I can get better and better compression like this becomes better that I'm finding image which has fewer and fewer bits.",
            "Requires to describe, but I'm allowing it to be further and further away from the true."
        ],
        [
            "And basically."
        ],
        [
            "What happens is I'm increasing and decreasing."
        ],
        [
            "Lambda, so basically this is really easy image to compress, but you can see it's sort of left outside in details."
        ],
        [
            "And this is kind of the standard type of array distortion analysis where this is what we get for different images.",
            "This is the number of the error like basically distortion measure.",
            "This is a compression, but number of rates, number of bits per pixel.",
            "So you see like I get more distortion.",
            "But I have less and less."
        ],
        [
            "Compress and OK, I'm done.",
            "Sorry I was running fast and that's my concluding.",
            "It's like an advertisement, so there's a. I'm organizing some workshop or kind of small conference on energy mutation methods in computer vision.",
            "So if you're interested in, it doesn't have to be, well.",
            "I mean, it's kind of related to computer vision, but there's a lot of optimization there, so that's it.",
            "I'm sorry for the lack of conclusions, but just.",
            "So maybe next week and release.",
            "So we have time for one or two questions, so I think you have slides on how the have transformed verbs, or that yeah.",
            "Oh well, I mean the main point here is that.",
            "Whether it's half transformer North, but implicitly it still maximizes the number of inliers.",
            "Basically what?"
        ],
        [
            "Hang on, what is this?",
            "Basically full possible lines in here.",
            "It tells you, roughly speaking, what's the brightness?",
            "How many inliers are there so you still minimizing maximizing the number of inliers, so that it doesn't work for exact same reason why sequential ransack doesn't work.",
            "Makes sense.",
            "There is no skip that because you know this is a typical question I get, but.",
            "I don't really care about that.",
            "Transfer to watch, OK?",
            "OK, so let's OK. And I'm sorry.",
            "Right?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, well thanks a lot and this is very accurate introduction.",
                    "label": 0
                },
                {
                    "sent": "I will try to connect to computer vision.",
                    "label": 0
                },
                {
                    "sent": "What's going on in the beginning of a similar and thanks for inviting that.",
                    "label": 0
                },
                {
                    "sent": "That's really great opportunities so well.",
                    "label": 0
                },
                {
                    "sent": "Basically, I'll talk about the type of functional that involves includes labor costs, which is something relatively new for combinatorial methods and vision, but sort of as I go along.",
                    "label": 0
                },
                {
                    "sent": "I basically will give you some idea of where the kind of energy is that.",
                    "label": 0
                },
                {
                    "sent": "Related to what was discussed in the other talks used in computer vision.",
                    "label": 0
                },
                {
                    "sent": "And more specifically, I'll talk about more.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Eating a lot so.",
                    "label": 0
                },
                {
                    "sent": "Give a brief introduction of general types of models that have been used since 80s and before that, and talk about specific label cost functional, how different and what extends, and then talk a lot about the applications for this.",
                    "label": 0
                },
                {
                    "sent": "So again, my main goal here is just to show some people who do more like.",
                    "label": 0
                },
                {
                    "sent": "More community optimization.",
                    "label": 0
                },
                {
                    "sent": "What can be done with this methods in?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Addition well, let me start with a very, very generic problem in computer vision, which is denoising, and probably many of you know what it is.",
                    "label": 0
                },
                {
                    "sent": "Roughly speaking, you have noisy image, so that's what's given, so you have intensities and you'd like to obtain some unknown labels.",
                    "label": 0
                },
                {
                    "sent": "Supposedly, in this case corresponding to true image before the noise came in, so that's called image restoration, and the question is how do you compute those labels?",
                    "label": 0
                },
                {
                    "sent": "From the data from intensities, and I mean there is no generic because in most other application there is still some data image, typically in some other labels, so it doesn't have to be restored intense, but it's a very simple generic problem too.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Talk about first and then they kind of models that's been proposed early 80s to deal with this type of problems are often based on Markov random fields.",
                    "label": 0
                },
                {
                    "sent": "Ideas from statistical physics say so basically well, if you have a grid of pixels and labels are per pixel, for example this week membrane model would have some data Fidelity term that typically comes as a likelihood term, so you can see this is.",
                    "label": 0
                },
                {
                    "sent": "Negative log likelihood for some kind of Gaussian noise, but then decides the data Fidelity.",
                    "label": 0
                },
                {
                    "sent": "Typically it will be some prior term.",
                    "label": 0
                },
                {
                    "sent": "Again, the difference from the energies that we've seen in the beginning of the seminar is this is a negative logarithm of those energies that people talked about earlier.",
                    "label": 0
                },
                {
                    "sent": "Then it becomes kind of some of the terms and again this will be the unary potential term and this would be typically pairwise term and just to give you an idea what kind of spatial regularity we're talking about here.",
                    "label": 0
                },
                {
                    "sent": "Typically people like to have smoothness term which likes favors labels similar labels, but there is some kind of penalty for what's the largest.",
                    "label": 0
                },
                {
                    "sent": "Sort of, the threshold for the largest penalty, and it's important for applications because that's what allows to preserve big jumps.",
                    "label": 0
                },
                {
                    "sent": "Big, big, big discontinuity.",
                    "label": 0
                },
                {
                    "sent": "So basically, that's where the membrane breaks off this big.",
                    "label": 0
                },
                {
                    "sent": "Another maybe a clarification.",
                    "label": 0
                },
                {
                    "sent": "So typically in computer vision people minimize energy, so that's another thing to keep in mind.",
                    "label": 0
                },
                {
                    "sent": "Because that might be different, and also once you may notice here, I'm talking about the problem where it's not a binary problem like labels could be in principle that could be ordered set of labels like intensities.",
                    "label": 0
                },
                {
                    "sent": "In this case you can think it's an order set or for stereo could be disparate, is all sorted set, but often enough if you talking bout for example motion estimation, then their labels do not have to be ordered.",
                    "label": 0
                },
                {
                    "sent": "So generally speaking we deal with this type of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems OK, so let me just outline real brief.",
                    "label": 0
                },
                {
                    "sent": "What's the state of the art for minimization?",
                    "label": 0
                },
                {
                    "sent": "So if you have this type of interaction potentials which are convex, then this is an easy problem and you can find exact solutions in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "I'm in.",
                    "label": 0
                },
                {
                    "sent": "Pretty much convexity here helps a lot, but this type of potentials they don't preserve sharp boundaries between objects, so people don't well, I mean there are many useful things you can do with it, but it's not as nice as people hope.",
                    "label": 0
                },
                {
                    "sent": "So basically you don't like the penalty Gray really fast grow really fast as the difference, so you want to somehow cap it, and if you like among convex interactions, the linear interaction or should I say absolute value interaction is actually better because it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Grows fast this quadratic so you wouldn't be over penalizing the differences too fast, but this minimization is already more difficult because of non differentiable functions, so it's still doable.",
                    "label": 0
                },
                {
                    "sent": "You still can find global optimum, but it's harder, particularly like creational settings.",
                    "label": 0
                },
                {
                    "sent": "People typically try to get rid of this by smoothing it a little bit, or doing other things, and once you get to the problems like this, which nonconvex potentials and for example like I showed truncated here or something like this, then it's NP hard and.",
                    "label": 0
                },
                {
                    "sent": "You have to deal with the proximation methods and message passing with some graph cuts based algorithm being proposed to deal with this and they have certain optimality guarantees, but I'm not going to.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Too much with this, so one extra example of discontinuity preserving kept interaction is what's called Ising model in binary case, or in case of labels.",
                    "label": 0
                },
                {
                    "sent": "It's called Potts model, and in this case if expansion algorithm in particular is known to give approximation factor of 2.",
                    "label": 1
                },
                {
                    "sent": "What kind of problem that you can solve?",
                    "label": 0
                },
                {
                    "sent": "This is piecewise constant labeling, so this is kind of different from the first image restoration example, where those kind of gradual change in intensities and this potential wouldn't work well because basically create bends of constant density.",
                    "label": 1
                },
                {
                    "sent": "But if you indeed you're labeling you're looking for is piecewise constant, then it's actually pretty good solution and interesting in many problems in vision, and I wouldn't say all not at all, but large number of problems can be formulated speaks with constant labeling, which is what this.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is about just give you one idea, maybe front of parallel stereo where you have two images left eye right eye and the labels now are not intensities.",
                    "label": 1
                },
                {
                    "sent": "Labels are disparities.",
                    "label": 0
                },
                {
                    "sent": "Well this is kind of solution.",
                    "label": 0
                },
                {
                    "sent": "You're looking for.",
                    "label": 0
                },
                {
                    "sent": "This is labeling each colleges represent certain depth layer.",
                    "label": 0
                },
                {
                    "sent": "Just my visualization with and perhaps both model can be used.",
                    "label": 0
                },
                {
                    "sent": "I'm saying it's just an example of where the labels is something different from intensities you've seen before and the data term here would be.",
                    "label": 0
                },
                {
                    "sent": "Not just the square differences would be based on what's called for the consistency, but generally speaking it's not hard to compute.",
                    "label": 0
                },
                {
                    "sent": "For example, what you do is you take pixel in the left image at disparity or label that you want, you get a new pixel in the right image, and you compare the intensities that would be for the consistency.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, So what I'm trying to advocate now is a new term added to this type of images, which we call we refer to it as label costs.",
                    "label": 0
                },
                {
                    "sent": "Basically what that adds to the synergies.",
                    "label": 0
                },
                {
                    "sent": "Basically it counts in the simplest form of this function counts the number of labels actively used in the solution, and one thing I'd like to mention is in principle this is not a normal functional.",
                    "label": 0
                },
                {
                    "sent": "It's been designed and in the context of computer vision by people like Lyrica.",
                    "label": 0
                },
                {
                    "sent": "Advertise this in 89 and he advertises from the minimum description length principle.",
                    "label": 0
                },
                {
                    "sent": "So basically instead of MRF framework, Markov random fields and statistical justification is all the arguments with dysfunctional seemed to be information theoretic and I kind of really like this.",
                    "label": 0
                },
                {
                    "sent": "Maybe if I have time I'll cover a little bit more details in that.",
                    "label": 0
                },
                {
                    "sent": "As far as minimization goes, because he still wanted to find the optimal labeling here he had some generation of gradients on convexity.",
                    "label": 0
                },
                {
                    "sent": "Basically what this work.",
                    "label": 0
                },
                {
                    "sent": "So our work is about is how to do it better in still combinatorial discrete settings, but people other people in computer vision looked at the same functional but equivalent functional formulated in a continuous setting.",
                    "label": 0
                },
                {
                    "sent": "Basically, one thing I'd like to mention and computer vision there is lots of people from Community who are interested in combinatorial, discrete algorithms, But there are tons of people who are using variational methods to minimize continuous analogues of this functions, and there are immediately obvious, continuous up analogs of this.",
                    "label": 0
                },
                {
                    "sent": "Like, for example, this would be.",
                    "label": 0
                },
                {
                    "sent": "Some integral over region of some potential function.",
                    "label": 0
                },
                {
                    "sent": "This would be actually some, for example geometric length for the discontinuity between the.",
                    "label": 0
                },
                {
                    "sent": "Segments so basically genetic link for the boundary and this still would be the number of segments for example.",
                    "label": 0
                },
                {
                    "sent": "So people propose different methods for minimizing this.",
                    "label": 0
                },
                {
                    "sent": "Some.",
                    "label": 0
                },
                {
                    "sent": "Other group of people worked on functional where you take just these two terms, and in fact this is something nice and I also would mention this in this talk later.",
                    "label": 0
                },
                {
                    "sent": "Minimization well again justification for this hyper functional is also based on information theory and acnb icy criteria.",
                    "label": 0
                },
                {
                    "sent": "So this is pretty well known work, and in particular he suggested some greedy heuristic method to attempt minimizing this type of functionals.",
                    "label": 0
                },
                {
                    "sent": "Lee much more recent work he was using LP relaxation for this functional, but without any kind of optimality guarantees that was more like a heuristic.",
                    "label": 0
                },
                {
                    "sent": "Well, let's just do LP relaxation and then truncate, but there was no intent.",
                    "label": 0
                },
                {
                    "sent": "Discussion of what guarantees that gives.",
                    "label": 0
                },
                {
                    "sent": "Finally, there's some more continuous workout.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Keep that for the sake of giving little going a little faster.",
                    "label": 0
                },
                {
                    "sent": "So what we will contribute to this area is basically generalization of life extension method that allows to deal with this and certain optimality guarantees are possible.",
                    "label": 0
                },
                {
                    "sent": "So basically it is possible to minimize such a functional with certain guarantees an we also discuss, for example, special case.",
                    "label": 0
                },
                {
                    "sent": "We have only this two terms, minimize it with some UFO heuristics and understated incapacitated for steel to location.",
                    "label": 0
                },
                {
                    "sent": "Problem basically that's equivalent to it.",
                    "label": 0
                },
                {
                    "sent": "Surprisingly, people in computer vision don't know this method so much, and however they could be pretty useful and fast, even though one of the things I'll show you that you really need this term for many problems and will also focus on some of the applications for it, so I hope to give you an idea what this is good for.",
                    "label": 0
                },
                {
                    "sent": "However, I'm not going to give you any technical details as to how this works.",
                    "label": 0
                },
                {
                    "sent": "So basically one assumptions I'm making here that you don't care about them, or if you care about them just there on paper this.",
                    "label": 0
                },
                {
                    "sent": "Not not, not.",
                    "label": 0
                },
                {
                    "sent": "Shouldn't be too difficult to read, so I'm kind of more interested in giving you the general idea of what this type of energy is do.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There's also related papers which mean you might similar functionals, and they are all fairly recent address specific applications, but I just.",
                    "label": 0
                },
                {
                    "sent": "Kind of presented.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My way anyway, so why label costs and what are those generic model fitting problems?",
                    "label": 0
                },
                {
                    "sent": "I'd like to discuss with you which fit into this frame.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, let me start with the most basic model feeding problems.",
                    "label": 0
                },
                {
                    "sent": "Probably most of you seen before is how to feed the line into a cloud of points and then a simple example like this where you don't really have outliers and what you can do is like your model is described by two parameters, AB.",
                    "label": 0
                },
                {
                    "sent": "For each point you can define certain geometric feed error.",
                    "label": 0
                },
                {
                    "sent": "It could be vertical distance that could be orthogonal distance, your choice and then you can compute model parameters.",
                    "label": 0
                },
                {
                    "sent": "In this case just A&B.",
                    "label": 0
                },
                {
                    "sent": "Which minimize the sum of squared differences, for example, and you would have closed formula for many of those cases, and generally speaking maybe not.",
                    "label": 0
                },
                {
                    "sent": "But for line fitting.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "Such, but what happens if you add outliers?",
                    "label": 0
                },
                {
                    "sent": "Because we're moving into computer vision and in computer vision you never have.",
                    "label": 0
                },
                {
                    "sent": "100% inliers, you always have outlines.",
                    "label": 0
                },
                {
                    "sent": "In fact, many of them.",
                    "label": 0
                },
                {
                    "sent": "So one option you can do is OK. Well, let's move from quadratic loss function to something that doesn't over penalize so much to this linear minimizer.",
                    "label": 0
                },
                {
                    "sent": "Basically to get some kind of log for the median filter.",
                    "label": 0
                },
                {
                    "sent": "That's possible, except it's immediately harder.",
                    "label": 0
                },
                {
                    "sent": "There is no close formula and why it's not differentiable.",
                    "label": 0
                },
                {
                    "sent": "That's basically the same reason is what I mentioned for similar problem.",
                    "label": 0
                },
                {
                    "sent": "Completely different settings.",
                    "label": 0
                },
                {
                    "sent": "So median filter can do, but it's more difficult.",
                    "label": 0
                },
                {
                    "sent": "And the other thing it breaks once you have really large number of outliers and in fact in the problems that I'm interested in, the number of outliers is much more than this.",
                    "label": 0
                },
                {
                    "sent": "It could be 80, it could be 90, something like that.",
                    "label": 0
                },
                {
                    "sent": "Then basically then I'll be doing multimodal fitting.",
                    "label": 0
                },
                {
                    "sent": "They are basically in life for one model.",
                    "label": 0
                },
                {
                    "sent": "It's like only 10% of the data.",
                    "label": 0
                },
                {
                    "sent": "Something like this.",
                    "label": 0
                },
                {
                    "sent": "Well, what does the answer to this problem which goes beyond the median filter?",
                    "label": 0
                },
                {
                    "sent": "Probably many of you.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many, but probably some of you know ransack and ransack is really standard answer in computer vision.",
                    "label": 0
                },
                {
                    "sent": "For this type of problems.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Basically, so it seems like pretty simple idea, but I'll tell you why I really like so well.",
                    "label": 0
                },
                {
                    "sent": "First, let's the main thing in this idea.",
                    "label": 0
                },
                {
                    "sent": "It starts with sampling data points to generate some proposals for what the lines could be, and basically in line featuring.",
                    "label": 0
                },
                {
                    "sent": "You need only two points to fit a line, right?",
                    "label": 1
                },
                {
                    "sent": "So what you do you randomly sample two points feet align into it?",
                    "label": 0
                },
                {
                    "sent": "And what do you do then?",
                    "label": 0
                },
                {
                    "sent": "Well, you sign certain quality measures.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This line by counting inliers within predefined threshold.",
                    "label": 0
                },
                {
                    "sent": "So threshold is fixed.",
                    "label": 0
                },
                {
                    "sent": "So you do is just count how many points in there, let's say 10 and then if you keep sampling you don't stop here.",
                    "label": 0
                },
                {
                    "sent": "You don't sample just once you sample certain number of times, say North, and eventually there is certain probabl.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That two points that you sample will be like this in this for example.",
                    "label": 1
                },
                {
                    "sent": "So eventually, at some point you will get the sample like this and what will set it apart from other samples.",
                    "label": 0
                },
                {
                    "sent": "The number of inliers, so you'll immediately see that there is something special about that particular one, because it has much larger number of inliers.",
                    "label": 0
                },
                {
                    "sent": "So basically what you're doing ransack you keep sampling for certain number of times, and from a sample of certain size, you select one model with the largest number of inliers.",
                    "label": 1
                },
                {
                    "sent": "So that's as easy as that, and the point is, it works really well.",
                    "label": 0
                },
                {
                    "sent": "What's the beauty of it?",
                    "label": 0
                },
                {
                    "sent": "I mean, because it seems to me that when I say that it's a really simple heuristic and I mean to some extent, it is the beauty of it.",
                    "label": 0
                },
                {
                    "sent": "Is that the answer for the question of how many times you have to sample to have a probability of success, and that's where we'll just success that you indeed sampled the two points which are inlier for the true model.",
                    "label": 0
                },
                {
                    "sent": "So basically for any known a priority percentage of outliers, you can compute how many samples you have to do to draw in order to reach certain probability of success.",
                    "label": 0
                },
                {
                    "sent": "And just to give you an idea of what makes me excited about this, if you have 80% outliers and you want to achieve 95 probability of success, you need only 20 samples.",
                    "label": 0
                },
                {
                    "sent": "I find this amazing.",
                    "label": 0
                },
                {
                    "sent": "That's why ransack is an interesting idea, and that's why people use it a lot in computer vision.",
                    "label": 0
                },
                {
                    "sent": "But basically, their answer here says surprising, perhaps.",
                    "label": 0
                },
                {
                    "sent": "As you know, one of the questions that people typically deal with when they take a first year course on probability.",
                    "label": 0
                },
                {
                    "sent": "They tell him what's the probability that you have two people in this group has the same birthday, and basically intuitively everybody will say, but it's very unlikely.",
                    "label": 0
                },
                {
                    "sent": "But everybody knows that almost every cluster was a pair of students like that, and if you do the computations you realize this probability is pretty high, so it's pretty much the same thing here.",
                    "label": 0
                },
                {
                    "sent": "So basically the beauty of France like is that formula that tells you that you don't need to sample that much to have a probability that you sample.",
                    "label": 0
                },
                {
                    "sent": "From two inliers, OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Having said that, next thing, what do we do?",
                    "label": 0
                },
                {
                    "sent": "Have multiple models and that's what I'm interested in.",
                    "label": 1
                },
                {
                    "sent": "This paper in this talk, so it seems like why not do the falling and that's what sort of sequential ransack that or suggestive, 98.",
                    "label": 0
                },
                {
                    "sent": "Well, let's just do this iterative.",
                    "label": 0
                },
                {
                    "sent": "Let's first sample large number of lines and select from it model with large numbers.",
                    "label": 0
                },
                {
                    "sent": "And let's say for example this was model that perhaps would be the largest number in layers and some role model.",
                    "label": 0
                },
                {
                    "sent": "Would not have been a large number of inliers, so that's basically the assumption.",
                    "label": 0
                },
                {
                    "sent": "Once you got one, which you can do, you can now remove it with its inliers, and keep doing this sequentially.",
                    "label": 0
                },
                {
                    "sent": "So basically, then, probably the next strongest model would be this, this, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That seems like a nice idea, except.",
                    "label": 0
                },
                {
                    "sent": "Eventually, if you have actually very large node not allowed amount of noise that stops working.",
                    "label": 0
                },
                {
                    "sent": "So basically pretty random model may have large number of inliers, that good model.",
                    "label": 1
                },
                {
                    "sent": "Basically, there is no what I'm trying to say.",
                    "label": 0
                },
                {
                    "sent": "My point here is, once you have multimodal situations where data supports not just one model but many models besides just one and some outliers, then just this heuristic approach of counting the number of inliers is not a measure that you can trust in this kind of greedy selection of the models.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to propose actually looking at the whole problem as labeling of all data points with model.",
                    "label": 0
                },
                {
                    "sent": "So basically don't select one at a time.",
                    "label": 0
                },
                {
                    "sent": "Try to find an explanation for the whole picture based on certain energy.",
                    "label": 0
                },
                {
                    "sent": "That kind of discovered.",
                    "label": 0
                },
                {
                    "sent": "This describes situation global.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So well, let me actually advocate this approach, but do one step at a time, basically.",
                    "label": 0
                },
                {
                    "sent": "First let me look at the kind of simplistic energy interpretation of transect does in case of a single model.",
                    "label": 1
                },
                {
                    "sent": "So forget about multiple models.",
                    "label": 0
                },
                {
                    "sent": "Let's just deal with one model.",
                    "label": 0
                },
                {
                    "sent": "Basically you saw this functional already right?",
                    "label": 0
                },
                {
                    "sent": "I'm saying that L. Here is this pair of parameters for line.",
                    "label": 0
                },
                {
                    "sent": "So for that single line that's data supports and basically this distance between point P and the line is for example something like this, it's.",
                    "label": 0
                },
                {
                    "sent": "Zero is the distance between P&L.",
                    "label": 0
                },
                {
                    "sent": "If this vertical distance or whatever is my geometric areas is, it's less than threshold in this penalty one.",
                    "label": 0
                },
                {
                    "sent": "If the distance is larger.",
                    "label": 0
                },
                {
                    "sent": "So if I'm minimizing this, you can see that I'm counting the number of inliers correct.",
                    "label": 0
                },
                {
                    "sent": "And basically I'm selecting L by minimizing this functional that gives me the largest number of inliers.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, what happens if I?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Try to apply this to multimodal case in the model model case the immediate need is to actually allow each point to have a model because you can't fit one model to all data, so therefore you have to introduce in principle as many labels as potentially points because you don't know in advance how many models are in there.",
                    "label": 0
                },
                {
                    "sent": "But if I try to minimize this functional where my energy is now over this labeling, I'm going to get drunk because basically if I just have that.",
                    "label": 0
                },
                {
                    "sent": "Every point is going to select line that it sits on.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter which one any.",
                    "label": 0
                },
                {
                    "sent": "There will be 0 and that's lowest value for this.",
                    "label": 0
                },
                {
                    "sent": "This is not going to work correct, So what do I need and notice the reason?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It worked in case of single model because there was only one model I have to fit one model.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do the whole thing OK, but as soon as you have multiple, you need to regularize.",
                    "label": 0
                },
                {
                    "sent": "Basically, you need to say I generally speaking, like solutions which are simple enough.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sense, for example, like they have small number of lines that explain the data.",
                    "label": 0
                },
                {
                    "sent": "So basically I'm talking bout here my first term.",
                    "label": 0
                },
                {
                    "sent": "That's one alternative for what you can do for regularization.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another alternative, which actually we also tried and works quite well, is spatial organization.",
                    "label": 0
                },
                {
                    "sent": "Well, you may say.",
                    "label": 0
                },
                {
                    "sent": "How can I explain this well, and in case the data points are not image pixels, what's my neighborhood structure?",
                    "label": 0
                },
                {
                    "sent": "What does my smoothness?",
                    "label": 0
                },
                {
                    "sent": "Well you can do nearest neighbor graph or triangulation perhaps, and whatever we tried, it seems like it didn't matter too much.",
                    "label": 0
                },
                {
                    "sent": "So basically some kind of.",
                    "label": 0
                },
                {
                    "sent": "The logical structure can be induced here alright then, basically then regulation would be the same ports model that I talked about before.",
                    "label": 0
                },
                {
                    "sent": "Basically I'm kind of using here the fact that points nearby closer to each other typically tend to have the same label.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, or perhaps all three, and basically what I'll try to convince you that I mean all three.",
                    "label": 0
                },
                {
                    "sent": "I meant all three terms, but the old both, both the spatial smoothness and label counts that could be useful, and what kind of solutions I'm going to get.",
                    "label": 0
                },
                {
                    "sent": "Well, generally speaking, I hope that this is what is a good solution with respect to the center.",
                    "label": 0
                },
                {
                    "sent": "So basically this is the labeling which is optimal respect to the functional.",
                    "label": 0
                },
                {
                    "sent": "Why well points tend to be close to the?",
                    "label": 0
                },
                {
                    "sent": "Are models that they assigned?",
                    "label": 0
                },
                {
                    "sent": "As you can see, most of the discontinued this occur between points which are far from each other, so like this is a cluster of points and they assign the same model.",
                    "label": 0
                },
                {
                    "sent": "And finally you explain the solution with few models, not with large numbers.",
                    "label": 0
                },
                {
                    "sent": "So basically one way to think about this and this is where I'm deal.",
                    "label": 0
                },
                {
                    "sent": "By the way interpretation comes in.",
                    "label": 0
                },
                {
                    "sent": "Basically what you see here is the small small number of labels explaining whole data set, so I'm not trying to select one model at the time, I'm just trying to find the whole picture at once.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to describe a functional.",
                    "label": 0
                },
                {
                    "sent": "That actually tells me what the whole picture is, not just one at a time thing.",
                    "label": 0
                },
                {
                    "sent": "OK, well, and then I told you I can minimize the challenges right with life extension.",
                    "label": 0
                },
                {
                    "sent": "For example, something in the beginning.",
                    "label": 0
                },
                {
                    "sent": "Well, is it so easy?",
                    "label": 0
                },
                {
                    "sent": "In this case there is one detail missing, and this detail is actually fairly important, because basically when I'm talking about expansion typically I mean finite number of labels, right?",
                    "label": 0
                },
                {
                    "sent": "The number of candidates.",
                    "label": 0
                },
                {
                    "sent": "Can labels water labels here model parameters.",
                    "label": 0
                },
                {
                    "sent": "So it should be finite and do I have such a thing when I just started solving this problem?",
                    "label": 0
                },
                {
                    "sent": "Well know my labels are points in R2 like lines.",
                    "label": 0
                },
                {
                    "sent": "So that's the big issue.",
                    "label": 0
                },
                {
                    "sent": "And that's actually something that we have to address.",
                    "label": 0
                },
                {
                    "sent": "And basically we cannot really directly apply life extensions.",
                    "label": 0
                },
                {
                    "sent": "You kind of do a little bit of trickery here.",
                    "label": 0
                },
                {
                    "sent": "Basically you have to propose some algorithms dealing with this issue, which sort of explores the space of labels in a way where actually sampling of the data points helps.",
                    "label": 0
                },
                {
                    "sent": "So basically you may remember what I told you about RANSAC, right the sampling?",
                    "label": 0
                },
                {
                    "sent": "Well, what does it do?",
                    "label": 0
                },
                {
                    "sent": "Well there it basically has.",
                    "label": 0
                },
                {
                    "sent": "This formula tells you what's the probability.",
                    "label": 0
                },
                {
                    "sent": "Of obtaining a success.",
                    "label": 0
                },
                {
                    "sent": "Meaning some reasonable model when you sample that many times, and that's basically what I need.",
                    "label": 0
                },
                {
                    "sent": "I need just basically to generate certain pool of labels.",
                    "label": 0
                },
                {
                    "sent": "Discrete which has large probability of having reasonable models in it.",
                    "label": 0
                },
                {
                    "sent": "That's what I need.",
                    "label": 0
                },
                {
                    "sent": "So basically to come from the continuous problem.",
                    "label": 0
                },
                {
                    "sent": "Within the space of labels, it's continues to something more discreet.",
                    "label": 0
                },
                {
                    "sent": "I'll use a little bit of sampling to generate good proposals for me.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, roughly speaking, what it looks like.",
                    "label": 0
                },
                {
                    "sent": "Suppose this is this noisy problem I'm trying to solve.",
                    "label": 0
                },
                {
                    "sent": "So how many models do you see?",
                    "label": 0
                },
                {
                    "sent": "Five, OK, I would agree to that.",
                    "label": 0
                },
                {
                    "sent": "OK five.",
                    "label": 0
                },
                {
                    "sent": "12345 alright, well let's see what they are.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Would do so basically the first.",
                    "label": 0
                },
                {
                    "sent": "By the way, the algorithm called Pearl, but it's not the same Pearl as I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "BRL two so the Pearl stands for proposed expander estimate labels, so proposed.",
                    "label": 0
                },
                {
                    "sent": "What's the proposed?",
                    "label": 0
                },
                {
                    "sent": "The proposed is basically I need to throw a bunch of labels, which I think have good candidates.",
                    "label": 0
                },
                {
                    "sent": "So basically what I'm hoping for, I'm sampling this data points hoping that with certain probability it contains good candidates.",
                    "label": 0
                },
                {
                    "sent": "Basically it's my way to discretize the space of labels.",
                    "label": 0
                },
                {
                    "sent": "Think about that.",
                    "label": 0
                },
                {
                    "sent": "So the space of labels is R2.",
                    "label": 0
                },
                {
                    "sent": "I need to discretize it somehow and I think this is smarter than just doing some kind of stupid discretization over DX and DDA&B.",
                    "label": 0
                },
                {
                    "sent": "That's all I'm saying.",
                    "label": 0
                },
                {
                    "sent": "So this is better because there's a better chance that by doing just a few of them I'll actually cover the good ones.",
                    "label": 0
                },
                {
                    "sent": "Alright, so how do I going to make sense out of this mess?",
                    "label": 0
                },
                {
                    "sent": "'cause this is a mess?",
                    "label": 0
                },
                {
                    "sent": "I mean, how do I know which is good and which is not that I don't know?",
                    "label": 0
                },
                {
                    "sent": "I just know with some probability this contains good ones and this is where my energy minimization comes in.",
                    "label": 0
                },
                {
                    "sent": "So basically I plug this discrete labels into this.",
                    "label": 0
                },
                {
                    "sent": "Energy, and now it's discrete.",
                    "label": 0
                },
                {
                    "sent": "Set of labels an I'm using my energy minimization framework.",
                    "label": 1
                },
                {
                    "sent": "Will it be with just spatial smoothness of Labor costs?",
                    "label": 0
                },
                {
                    "sent": "Doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "So basically I'm trying to once I apply this immediately from all this mass, the method selects only few, which makes sense because it doesn't want to like.",
                    "label": 0
                },
                {
                    "sent": "I mean I'm trying to get solutions which are good with respect to this energy so it automatically throws out unnecessary models.",
                    "label": 0
                },
                {
                    "sent": "By the way, maybe you will be wondering what are those Gray ones?",
                    "label": 0
                },
                {
                    "sent": "I'm using a pretty standard trick and MRF based optimization I'm.",
                    "label": 0
                },
                {
                    "sent": "Adding one more model which is not align.",
                    "label": 0
                },
                {
                    "sent": "This model is just some kind of uniform outline model, where basically it's additional model.",
                    "label": 0
                },
                {
                    "sent": "And the data feed for it for every point is just fixed constant.",
                    "label": 0
                },
                {
                    "sent": "It's I didn't have to do this, it's just basically I'm.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry if I flip back a little bit, so here I didn't use this model an in this case I'll find lines to explain the whole data set.",
                    "label": 0
                },
                {
                    "sent": "If you want to, you can decide for yourself later using some.",
                    "label": 0
                },
                {
                    "sent": "I mean it's a philosophical question here.",
                    "label": 0
                },
                {
                    "sent": "What's the main line?",
                    "label": 0
                },
                {
                    "sent": "What's an outlier, right?",
                    "label": 0
                },
                {
                    "sent": "I cannot answer this and you cannot answer this unless you have some kind of well, I mean some other additional answer like you know, can you tell me this is outlier?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Maybe for someone that is outlier for someone that's not.",
                    "label": 0
                },
                {
                    "sent": "But what I'm trying to say.",
                    "label": 0
                },
                {
                    "sent": "What I've done here with this functional I explained.",
                    "label": 0
                },
                {
                    "sent": "All data with the least number of models and you can decide for itself later or.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The alternative solution that I was advocating here.",
                    "label": 0
                },
                {
                    "sent": "I had an explicit label discrete one label for an outline model an all of this to difference with lines.",
                    "label": 0
                },
                {
                    "sent": "Lines have the penalties which may depend on where the point is and where that line is for the outline model is just fixed costs and basically this points prefer to get this line because the cost is very small.",
                    "label": 0
                },
                {
                    "sent": "Well, this point doesn't like any of these lines because it's too far.",
                    "label": 0
                },
                {
                    "sent": "It prefers.",
                    "label": 0
                },
                {
                    "sent": "Take a fixed cost associated with the outline, but I mean this is this tender trick.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying anything you, I just want to make sure that you're not puzzled by those great points, OK?",
                    "label": 0
                },
                {
                    "sent": "So you can have basically more points automatically labeled outlier or in life model blah for model block model.",
                    "label": 0
                },
                {
                    "sent": "Alright well I mean, but the point is ransacked.",
                    "label": 0
                },
                {
                    "sent": "This statistical sampling thing doesn't guarantee that you actually got perfect model samples, so there is actually oppurtunity for me within this energy framework to improve what I have.",
                    "label": 0
                },
                {
                    "sent": "What can I do?",
                    "label": 0
                },
                {
                    "sent": "Is well, imagine I fixed this term by saying I'm not going to change the inliers, but I'm going to fiddle with the model parameters for a set of inliers here.",
                    "label": 0
                },
                {
                    "sent": "And if.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do this that I'm going calling is their estimation of OK Now the energy is here.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I estimate the model parameters, Notice my line adjustable, so I'm doing here some coordinate descent.",
                    "label": 0
                },
                {
                    "sent": "Obviously Gordon descent with respect to segmentation or assignment stage versus model parameters may see what it does is just basically it's a better way to explore the space of labels.",
                    "label": 0
                },
                {
                    "sent": "I'm still minimizing the same function as before, I haven't changed my problem, I'm just trying still to deal with the fact that the number of models I have could be, well, basically, the models are points in R2 and I have combinatorial algorithms to deal with it.",
                    "label": 0
                },
                {
                    "sent": "So basically this iterative procedures still uses the same energy.",
                    "label": 0
                },
                {
                    "sent": "But in a coordinate descent fashion change iterates the assignment versus re estimation stages to improve the best it can.",
                    "label": 0
                },
                {
                    "sent": "I mean these dimensions they just takes care of this term assuming that the assignment of inliers is fixed.",
                    "label": 0
                },
                {
                    "sent": "So just likely just the and the point is, you can keep doing this because once you have.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Labels you can.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Re segment on the.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Energy keeps going down by iteration.",
                    "label": 0
                },
                {
                    "sent": "In principle you can add more proposals if you want to.",
                    "label": 0
                },
                {
                    "sent": "It's up to you and kind of it's always possible, so adding more labels never hurts because they will automatically selects what it wants.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quickly the energy goes.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sound eventually will have those five models.",
                    "label": 0
                },
                {
                    "sent": "Well, I mean, obviously I chose.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to say it works perfectly 100% of the time, but I mean we've already publications would try to.",
                    "label": 0
                },
                {
                    "sent": "There's quite a good level of robustness, robustness.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me show you one plot that sort of gives you a little bit of information for what's going on.",
                    "label": 0
                },
                {
                    "sent": "What's on this plot?",
                    "label": 0
                },
                {
                    "sent": "It's actually still one single model fitting example, so there there basically Holy Grail of ransack because RANSAC works.",
                    "label": 0
                },
                {
                    "sent": "If you have one model to fit, I am not going to claim that maximizing the number of inliers based like one of those bad.",
                    "label": 0
                },
                {
                    "sent": "It's still good approach, but what I'm trying to say, this energy minimization framework allows you to deal with smaller number of samples and iteratively improve it because.",
                    "label": 0
                },
                {
                    "sent": "We keep improving the label Cemetery fashion, something that Rancid can't quite do because there isn't really one unified energy there.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's something that perhaps can be debated, but everybody knows that.",
                    "label": 0
                },
                {
                    "sent": "And then second, just two steps.",
                    "label": 0
                },
                {
                    "sent": "First, select the model with lunch number of lines and then once among those in life, try to feed slightly better model.",
                    "label": 0
                },
                {
                    "sent": "But this is basically using exactly the same number of samples, which is along these lines and what you're getting.",
                    "label": 0
                },
                {
                    "sent": "The vertical line is the geometric error from its synthetic example, so we know exactly what the ground truth is.",
                    "label": 0
                },
                {
                    "sent": "So we could measure the how far the model we converge to is from the ground truth, and basically what you see here is that.",
                    "label": 0
                },
                {
                    "sent": "Well, first of all this at magic number to 20 more samples is all you need from ransack to get pretty decent results, so that's kind of right here, but we need fewer models because even from Arruda rough models we can actually fiddle with it and convert to something better, so I'm not going to claim that we can do it faster because there is quite a bit of optimization, But the point here is different.",
                    "label": 0
                },
                {
                    "sent": "The point is the number of model.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again, this is low.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This situation.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "RANSAC works.",
                    "label": 0
                },
                {
                    "sent": "RANSAC work.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our method also works as soon as you have high noise.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You're going to get random junk from ransack because exactly what I told you.",
                    "label": 0
                },
                {
                    "sent": "Maximizing the number of inliers and selecting Model 1 at a time.",
                    "label": 0
                },
                {
                    "sent": "This is going to fail.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if you look at the whole well, there's some other.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Similar methods if you.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to spend time on this, but once you look at the whole situation and the energy.",
                    "label": 0
                },
                {
                    "sent": "That's the answer you're getting.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can do circles.",
                    "label": 0
                },
                {
                    "sent": "Now I'm getting a bit more into applications.",
                    "label": 0
                },
                {
                    "sent": "How many minutes do I have?",
                    "label": 0
                },
                {
                    "sent": "If I have any.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Real application, so this is homography fitting.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to explain too many details from the application setting point of you, but you have two images and there are some points which been matched by some feature matching algorithms.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you know sift, OK, pretty standard thing and everybody is using it for all sorts of things, so I'm trying to feed 3D planes here and this is what you get with our energy method.",
                    "label": 0
                },
                {
                    "sent": "I just kind of quickly can tell if you use sequential, ransack or some other methods which uses greedy maximization allies.",
                    "label": 0
                },
                {
                    "sent": "They kind of get OK this, but as soon as you're getting noisier stuff, it's kind of difficult.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there's another kind of models you can feed, and this is kind of completely different example and this is closer to what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "You lamented this paper 98 or something like this, so that's actually example from their paper an from a model featuring POV, the functional that I'm describing completely fits here.",
                    "label": 0
                },
                {
                    "sent": "So what I'm trying to do this in image.",
                    "label": 0
                },
                {
                    "sent": "These are data points like this dance pixel grid, and basically I'm trying to fit models which are color distribution.",
                    "label": 0
                },
                {
                    "sent": "So basically instead of geometric model, this is called distribution.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to describe.",
                    "label": 0
                },
                {
                    "sent": "The image with the fewest number of colors.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tribu shun's, and this is the kind of solution that's what we get.",
                    "label": 0
                },
                {
                    "sent": "But I mean the same picture confined in June.",
                    "label": 0
                },
                {
                    "sent": "You'll 96 actually.",
                    "label": 0
                },
                {
                    "sent": "OK, I was wrong.",
                    "label": 0
                },
                {
                    "sent": "Well there is.",
                    "label": 0
                },
                {
                    "sent": "I'm using this picture is actually straight.",
                    "label": 0
                },
                {
                    "sent": "Also, this different combinations of dysfunctional because I'm kind of interested in this.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Empirical issue, So what exactly is that?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I used all regularity with spatial regulators across label costs, and I'll explain sort of why.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I get this, but this is what happens if you have only spatial regularity, and this is kind of the best solution we could get with it.",
                    "label": 0
                },
                {
                    "sent": "Basically what I'm trying to claim, if you use only spatial regularity, this is basically if you start.",
                    "label": 0
                },
                {
                    "sent": "If I start increasing the regularization went further, eventually it will merge the horse into one, but it already starts over smooth here, so it will smooth even more.",
                    "label": 0
                },
                {
                    "sent": "So if you rely on spatial regularity only to kind of group your pixels into sort of horse, you already doomed because even before the horse got.",
                    "label": 0
                },
                {
                    "sent": "One horse you already start over smooth, so basically that's the best result.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yet without labels.",
                    "label": 0
                },
                {
                    "sent": "But as soon as you have labor costs notice you need like labor costs or something that allows you to merge the models together, like trying to minimize the number of holes without really pushing too hard on the smoothness.",
                    "label": 0
                },
                {
                    "sent": "Let's go.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Empirical thing but.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interesting, but if you have only label costs in this column model fitting, you're not getting any regular results.",
                    "label": 0
                },
                {
                    "sent": "Also, you do need spatial smoothness here somewhat to kind of give you a reasonable special.",
                    "label": 0
                },
                {
                    "sent": "I mean an image analysis.",
                    "label": 0
                },
                {
                    "sent": "I'd like to say this regulation.",
                    "label": 0
                },
                {
                    "sent": "Specialization makes a lot of sense.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, many cases.",
                    "label": 0
                },
                {
                    "sent": "OK, well just typical.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other examples for this?",
                    "label": 0
                },
                {
                    "sent": "Enter really likes this person, so he really wanted to have.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, anyway.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Someone well, let me actually do this comparison of these different types of functionals for back to this.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model fitting, so actually surprisingly, if you use just label costs for regularization.",
                    "label": 0
                },
                {
                    "sent": "It works here and the question is why?",
                    "label": 0
                },
                {
                    "sent": "Well, why do I get really bad noisy results for when I use label costs for segmentation?",
                    "label": 0
                },
                {
                    "sent": "Because they are the model was histogram.",
                    "label": 0
                },
                {
                    "sent": "It's completely by itself is whatever.",
                    "label": 0
                },
                {
                    "sent": "There's no regularization in it, while if you fitting planes planes have regularity by themselves, sort of.",
                    "label": 1
                },
                {
                    "sent": "I don't know if I made it clear because it's not scientifically, but I hope you see what I mean, right?",
                    "label": 0
                },
                {
                    "sent": "So basically the only problem here is notice this yellow sports.",
                    "label": 0
                },
                {
                    "sent": "What are they doing there?",
                    "label": 0
                },
                {
                    "sent": "Well, there isn't why they're there, because if you extend display in here, this is where they intersect this plane and displaying alright.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm just happened at this point was just a little closer to this since there is no spatial regularity.",
                    "label": 0
                },
                {
                    "sent": "It chooses free to choose which model is closer to what.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to say here is that in many applications in particular geometric applications, computer vision, just labor costs works really well, and actually the algorithm for minimizing this is much faster than Alpha expansion.",
                    "label": 0
                },
                {
                    "sent": "The CFL heuristic Convention as well by order of magnitude faster.",
                    "label": 0
                },
                {
                    "sent": "And basically you can decide.",
                    "label": 0
                },
                {
                    "sent": "Well, maybe you can just smooth it out later by some filtering or whatever, well.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In case what happens if I have only spatial regularity, like Now, no label costs, just spatial regularity term.",
                    "label": 1
                },
                {
                    "sent": "What do you get the results look good?",
                    "label": 0
                },
                {
                    "sent": "There are no those noisy points, but there is a little bit of a problem.",
                    "label": 0
                },
                {
                    "sent": "I would like to point out that this and this is the same model.",
                    "label": 0
                },
                {
                    "sent": "It's the same plane and.",
                    "label": 0
                },
                {
                    "sent": "This, this and this are the same plane.",
                    "label": 0
                },
                {
                    "sent": "They are not merged because they're spatially disconnected, so my specialization term has no power to merge them into one model.",
                    "label": 0
                },
                {
                    "sent": "As soon as you have two spatial disconnected blocks, specially where it has no force into trying to reduce the number of labels.",
                    "label": 0
                },
                {
                    "sent": "So basically that's.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going on as soon as I have everything notice I have neither garbage here and this is the same.",
                    "label": 0
                },
                {
                    "sent": "These three are the same.",
                    "label": 0
                },
                {
                    "sent": "These are this in fact this this and this are the same.",
                    "label": 0
                },
                {
                    "sent": "So basically you get the best of everything possible and I mean that's kind of empirical, but I hope you sort of see what I'm trying to say is.",
                    "label": 0
                },
                {
                    "sent": "Envision you often need both types of.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Causation, well, motion fitting, motion fitting, rigid motion.",
                    "label": 0
                },
                {
                    "sent": "Basically you can show that you haven't dependently moving rigid objects, they all are based certain type of models that you can also describe in parametric fashion.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what you get with label costs only.",
                    "label": 0
                },
                {
                    "sent": "So it's not bad, but there are those weird things I cannot explain why this feed into the background because my this model somewhat 7 dimensional with feeding fundamental matrices in here, so I cannot quite visualize why this feeds the same motions here, so it wasn't like remember like with the planes I could tell you those, why don't those yellow dots were extensions of that plane?",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here I don't know.",
                    "label": 0
                },
                {
                    "sent": "As soon as I have spatial regularity, I don't have this junk, but notice that this this in this, which is the same background, so they don't move with respect to each other, so there's only one model, but since they're spatially disconnected, sort of.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They're not together.",
                    "label": 0
                },
                {
                    "sent": "And finally we have all three terms.",
                    "label": 0
                },
                {
                    "sent": "I find the exact number of right number of motions.",
                    "label": 0
                },
                {
                    "sent": "There are three motions.",
                    "label": 0
                },
                {
                    "sent": "OK and.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or some other?",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples this is just homography feeding but I really like this because.",
                    "label": 0
                },
                {
                    "sent": "We found 13 planes here like this.",
                    "label": 0
                },
                {
                    "sent": "White is not the same as this white just we ran out of colors OK or this pink is not the same as this pink or that pink just we did know some colors like orange or whatever.",
                    "label": 0
                },
                {
                    "sent": "Basically first we were a little bit disappointed.",
                    "label": 0
                },
                {
                    "sent": "We thought what's going on here like why is it different plane?",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we found really large great comfort in seeing that these are steps.",
                    "label": 0
                },
                {
                    "sent": "So basically these are not quite the same planes.",
                    "label": 0
                },
                {
                    "sent": "OK, so basically it was first a little disappointed only with a big sigh of relief after we saw some other images of the same.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or the same object well?",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probably skip that.",
                    "label": 0
                },
                {
                    "sent": "Let me do you have anytime at all or no.",
                    "label": 0
                },
                {
                    "sent": "No, OK, so one last thing I just want to show you remember this segmentation that I described earlier.",
                    "label": 0
                },
                {
                    "sent": "Actually there is this MDL interpretation for that's why kind of layer closure and you use it because basically this energy function line minimizing is basically especially if I use a data term, this negative log likelihood this can be thought of the number of bits required to compress this image in the following way.",
                    "label": 0
                },
                {
                    "sent": "I'm basically each segment.",
                    "label": 0
                },
                {
                    "sent": "Each segment is labeled so just distinct label is a color model.",
                    "label": 0
                },
                {
                    "sent": "OK, and basically this for each pixel assign certain column like for example this pixel using this particular model.",
                    "label": 0
                },
                {
                    "sent": "That's basically the number of beats that I need to describe this intensity using that color model represented by certain distribution function.",
                    "label": 0
                },
                {
                    "sent": "So basically this is number of bits required to express the old images or limited pixels.",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "Well, imagine you sending this image over some channel right?",
                    "label": 0
                },
                {
                    "sent": "You need to probably send it into some kind of scan order, right?",
                    "label": 0
                },
                {
                    "sent": "So basically as you switch from one model to another, you have to send the signal.",
                    "label": 0
                },
                {
                    "sent": "Basically, this is the number of bits required to send when you switching from one column to another.",
                    "label": 0
                },
                {
                    "sent": "That's one thing, and this was this.",
                    "label": 0
                },
                {
                    "sent": "Why do I need to send the number of models?",
                    "label": 0
                },
                {
                    "sent": "Well, because I need to send the coding scheme as well.",
                    "label": 0
                },
                {
                    "sent": "So basically this is purely number of beats.",
                    "label": 0
                },
                {
                    "sent": "This can be interpreted as number of bits and I'm not the first one to tell.",
                    "label": 0
                },
                {
                    "sent": "I click player talks exactly about that.",
                    "label": 0
                },
                {
                    "sent": "The reason I'm explaining this.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In detail, because we actually propose certain interesting extension, the words loss, image compression.",
                    "label": 0
                },
                {
                    "sent": "So this is the same function as you seen before I added something else.",
                    "label": 0
                },
                {
                    "sent": "Basically what I'm trying to do, I'm trying to find some other image high bar.",
                    "label": 0
                },
                {
                    "sent": "Which is distorted version of my original image, but which probably compresses better.",
                    "label": 0
                },
                {
                    "sent": "So basically I'm trying to find now an image which I'm going to reconstruct.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to compress closely.",
                    "label": 0
                },
                {
                    "sent": "This image I bar, but I'm allowing my bar to be different from my.",
                    "label": 0
                },
                {
                    "sent": "Not too far though in this Lambda controls.",
                    "label": 0
                },
                {
                    "sent": "So basically if Lambda is Infinity Notice, then I bought has to be equal to I so it's the same image, so it's lossless,",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I get sort of pretty much that we might restoration, but as soon as I kind of starting to decrease Lambda, notice that I get better compression by getting some distortion here.",
                    "label": 0
                },
                {
                    "sent": "So it's a standard in the Shannon sense information distortion.",
                    "label": 0
                },
                {
                    "sent": "What's this distortion theory anyway?",
                    "label": 0
                },
                {
                    "sent": "So is I'm decreasing the Lambda rate distortion theory?",
                    "label": 0
                },
                {
                    "sent": "OK, that's the term, as in decreasing the Lambda, I can get better and better compression like this becomes better that I'm finding image which has fewer and fewer bits.",
                    "label": 0
                },
                {
                    "sent": "Requires to describe, but I'm allowing it to be further and further away from the true.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And basically.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens is I'm increasing and decreasing.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lambda, so basically this is really easy image to compress, but you can see it's sort of left outside in details.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is kind of the standard type of array distortion analysis where this is what we get for different images.",
                    "label": 0
                },
                {
                    "sent": "This is the number of the error like basically distortion measure.",
                    "label": 0
                },
                {
                    "sent": "This is a compression, but number of rates, number of bits per pixel.",
                    "label": 0
                },
                {
                    "sent": "So you see like I get more distortion.",
                    "label": 0
                },
                {
                    "sent": "But I have less and less.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compress and OK, I'm done.",
                    "label": 0
                },
                {
                    "sent": "Sorry I was running fast and that's my concluding.",
                    "label": 0
                },
                {
                    "sent": "It's like an advertisement, so there's a. I'm organizing some workshop or kind of small conference on energy mutation methods in computer vision.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in, it doesn't have to be, well.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's kind of related to computer vision, but there's a lot of optimization there, so that's it.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for the lack of conclusions, but just.",
                    "label": 0
                },
                {
                    "sent": "So maybe next week and release.",
                    "label": 0
                },
                {
                    "sent": "So we have time for one or two questions, so I think you have slides on how the have transformed verbs, or that yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh well, I mean the main point here is that.",
                    "label": 0
                },
                {
                    "sent": "Whether it's half transformer North, but implicitly it still maximizes the number of inliers.",
                    "label": 0
                },
                {
                    "sent": "Basically what?",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hang on, what is this?",
                    "label": 0
                },
                {
                    "sent": "Basically full possible lines in here.",
                    "label": 0
                },
                {
                    "sent": "It tells you, roughly speaking, what's the brightness?",
                    "label": 0
                },
                {
                    "sent": "How many inliers are there so you still minimizing maximizing the number of inliers, so that it doesn't work for exact same reason why sequential ransack doesn't work.",
                    "label": 0
                },
                {
                    "sent": "Makes sense.",
                    "label": 0
                },
                {
                    "sent": "There is no skip that because you know this is a typical question I get, but.",
                    "label": 0
                },
                {
                    "sent": "I don't really care about that.",
                    "label": 0
                },
                {
                    "sent": "Transfer to watch, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so let's OK. And I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        }
    }
}