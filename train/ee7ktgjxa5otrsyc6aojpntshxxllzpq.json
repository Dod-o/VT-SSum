{
    "id": "ee7ktgjxa5otrsyc6aojpntshxxllzpq",
    "title": "Optimal Support Vector Selection for Kernel Perceptrons",
    "info": {
        "author": [
            "Daniel Garc\u00eda, Autonomous University of Madrid"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/learning06_garcia_osvsk/",
    "segmentation": [
        [
            "I'm going to talk about our work that was researched by Hotel Jerusalem, tell it on myself.",
            "Ann is entitled optimal bug on support vector selection for calendar settings."
        ],
        [
            "OK. A common problem with their support vector machines is there you need a high amount of support vectors in order to generate the output, and the output is the order of the number of support vectors or kernel operations.",
            "So in this work we try to pay a new method to reduce the number of support vector machines on also.",
            "Keep a good accuracy results.",
            "In order to achieve this task, we study the support vector machines training method and how it performs their margin maximization."
        ],
        [
            "OK. And it started with a brief review of support vector machines method.",
            "This important support vector material, sorry support vector machines goal, is to construct a linear classifier in order to classify training sets.",
            "With keeping our maximum margin, we can see the margin as the distance between the separator hyperplane and the nearest pattern to it to it.",
            "We have seen in before that we have to solve this quadratic.",
            "Alright problem.",
            "With which also is constrained by the series or equation that this all equation means that all patterns has to be good classified an we have seen that this problem is quite complex so.",
            "We like another method to avoid this computation."
        ],
        [
            "And this other method is facing the convex Hull normalization.",
            "1st.",
            "We change the input space just by applying the sign for its pattern.",
            "And then we have that the optimum weight vector verifies that is that it has the lowest norm of all the vectors in the outcome of the input space.",
            "Moreover the optimal weight.",
            "Verifies that its margin is equal to its norm.",
            "That is, for any other way better in the convex Hull, we have that it's margin is less or equal that the optimal margin and also it's norm is greater or equal that the optimal node.",
            "We have this language we can stay on UG function that is the difference between the norm at the margin and states this function optimal criterion.",
            "Function.",
            "OK, now."
        ],
        [
            "I announced that Slesinger Casino in Calgary.",
            "This algorithm system unified dysfunction intuitive first is select the pattern.",
            "We have minimal margin.",
            "What is means that if the pattern is wrong classified, it tries to to correct the worst wrong classified pattern?",
            "And also if all patterns are good classified, just the one who have minimum margin.",
            "OK then instead is update the weight vector in a fashion that is similar to Debrecen Battle rule, but we have to keep the weight vector in its combat Hall.",
            "Then we have also have a Lambda parameter that ensures that the new weight vector is.",
            "Is there minimum with the same pattern?",
            "The Slesinger consonant algorithm assumes that in each iteration, the weight norm it's going to be reduced or addressed.",
            "Keep equal."
        ],
        [
            "OK, what problem with Sling Selinger causing the Calgary is that is a linear classification but the we use kernel?",
            "We can avoid this problem, just a.",
            "Put in all the.",
            "The the products in terms of the kernel.",
            "Then we can write their weight vector in its dual form and perform the.",
            "The update in terms only of this Alpha that does the dual coefficients.",
            "And the date of this to our confidence are in custom dynamical patterns."
        ],
        [
            "Also, to speed up the new pattern selection, we keep margin vector for each pattern.",
            "So it's very easy to choose the new pattern to be.",
            "To be a.",
            "To be trained.",
            "Also, this Lambda parameter is very easy to compute and the update of this margin, the vector and all the number."
        ],
        [
            "Very.",
            "The order of the number of patterns and the cost of kernel computation.",
            "This means that the cost of that theater is an escargot algorithm training.",
            "Is in the order of the time of the iteration, number of iterations, per the number of patterns, per the cost of 1 kernel computation.",
            "But then the resulting perfect if it's going to apply to a test set.",
            "It cost will be the number of support vectors per the size of the test set for the order of the kernel computation cost.",
            "And this may be similar to the whole training.",
            "If we have that number of super vector is similar to the whole training patterns."
        ],
        [
            "OK, so we.",
            "We have to try to reduce the amount of support vectors.",
            "One good thing that we are working in that combats all, it's that they would vector.",
            "In the convex Hull, have this property that all these Alpha coefficients someone?",
            "So the question is, is it possible to see this a probabilistic distribution?"
        ],
        [
            "We can, we can see these Alpha coefficients to be about the relative relevance in order to correct classify.",
            "On also, is this Alpha coefficients will be around the same for all the for all their support vectors.",
            "Then we can use this setup to pronounce supervector removal methods.",
            "We consider just remove those patterns we have allow Alpha coefficients.",
            "No, the first idea is, rather than trying aggregate computation, we just iterate the algorithm, remove those support vectors with low Alpha values, and then return again using as our new training set.",
            "Just all the support vectors that we have."
        ],
        [
            "OK, so I'll start innocent.",
            "The method we start with an initial training sample.",
            "We have our initial facts or Delta that must be lower than one.",
            "On after the whole training finished, we keep only those.",
            "Those patterns will have Alpha upper done, so threshold that is threshold is in terms of this data factor and the number of buttons.",
            "Then we will literally apply the salaries.",
            "With increasing Delta values up to one, so the result is a decreasing sequence of the training set.",
            "Additionally, we can use the remote later as a validation set in order to try to know when is we have to stop this.",
            "This president.",
            "We can see this, just stop reduce removing support vectors when the accuracy goes quite low."
        ],
        [
            "OK, now I'll explain how we will experiment.",
            "We have done an.",
            "How we go?",
            "OK, we have worked with C data set from there.",
            "Well known.",
            "You see a repository.",
            "We have used our goals, our kernel with an arbitrary value of Sigma square of 50.",
            "This might be important.",
            "This value of Sigma, but we only want to know if this support removal method works.",
            "We think that it's OK."
        ],
        [
            "Also to Valentina stability, we have expanded project patterns in this way.",
            "This is adding new dimensions with all values are zero except in the index for each pattern that is designed into two and this contact constancy.",
            "This is very easy to work with and Italy were only required to extend the kernel adding this term."
        ],
        [
            "OK. Now.",
            "For each data set we have performed our term growth for validation.",
            "Also, for each data set we have performed auto 20 returns with the consent equals for it.",
            "We have seen that it.",
            "This number of epochs is sufficient to obtain a gold optimal margin.",
            "Then we have to start with Delta value of .5 anusara fixed increment and then given increasing thresholds.",
            "Then after its removal and retraining state, we shall compute their validation, accurate accuracy and the test accuracy.",
            "And then as I stop criterion, we have.",
            "This procedure ends when already China had completed, or when the difference between the accuracy of correlative retraining are greater than the standard deviation.",
            "So.",
            "We have the this May assure that when the accuracy is going too low we will stop."
        ],
        [
            "OK.",
            "This table summarizes the results for each data set.",
            "We have the number of patterns, the initial support vectors they have, and the final supervector we have achieved.",
            "Also, we have some, so here the ratio between the final supervector and initial to perfect your number.",
            "We can see that this ratio is about 50, about 70%.",
            "Which is quite good."
        ],
        [
            "Now in detail from some data sets, starting with the Hardy says data set.",
            "Mr Criterion is met where its value gets positive.",
            "So in this example the secretary is met with at the factor of .7.",
            "We can see that the test accuracy is a little bit worse than the original test accuracy, but we have.",
            "So.",
            "In some degree a good resolution vector.",
            "Would the support vector relax?"
        ],
        [
            "Well, in this other sample.",
            "The stop criterion is never met, so we have performed the whole returnees.",
            "This example is very similar to the last in the terms that they support vector are decreasing the number of super vectors, but Interestingly the accuracy is improved after the removal.",
            "Step."
        ],
        [
            "For this other data set.",
            "Step material is net that deserve the final Test.",
            "Accuracy is equal to the original security or very similar, and again there is a good reflection of the support vectors."
        ],
        [
            "And finally another example.",
            "That is quite similar to the last sample.",
            "The final currency is almost the same as the original 1, and we have a reduction in the number of a pattern.",
            "So in light of this, we can see that these methods provide a good reduction of the support vector number.",
            "And also the accuracy doesn't get.",
            "And worsening alert.",
            "Now."
        ],
        [
            "I saw you some wraps.",
            "This brows are the evolution of the accuracy both in validation, set and estate.",
            "Anybody since it is the upper line and.",
            "They said the lower line.",
            "We can see that as the Delta value gets increasing the.",
            "The accuracies are starting to go alone.",
            "And at that point we have stop.",
            "It's maybe a good point."
        ],
        [
            "Now for that Wisconsin data set.",
            "We have the same constant accuracy, so we have seen that we can keep removing vectors until the end and the accuracy is just OK."
        ],
        [
            "From this case.",
            "It's very.",
            "Strange because the validation accuracy starts getting low but the test accuracy stays at the same level more or less.",
            "We have stopped at this factor .75, but we maybe can continue until the end.",
            "The the South, that may be our stop criterion isn't the best."
        ],
        [
            "And finally, again for another data set that they separate Arian is quite.",
            "But soon, but it may be OK because then after the retraining the accuracy starts going down."
        ],
        [
            "So finally as conclusion, we can see that a common problem for Kinder classifiers is the high number of support vector machines.",
            "They must have used, resulting in a very high cost of the new Python classification.",
            "We have shown that the number of support vectors can be considerably reduced while retaining a good accuracy.",
            "Also, they were presented here has to be seen as as priority natures in terms that we have announced the problem.",
            "We have the problem and trying to look something to to obtain a good result.",
            "Finally as future work.",
            "We have looking for a better stopping criterion.",
            "And also investigate other methods in order to minimize the number of support vectors.",
            "Maybe some of these other methods as it could be a budget algorithm or.",
            "Some other kinds to training with fixed amount of support vectors.",
            "OK, and that's all any question.",
            "Yeah.",
            "Senior procedure to reduce the number of support vectors you're doing.",
            "What we call in feature selection or backward elimination.",
            "So you're stuck with the full set of supervision, yes.",
            "In in doing that.",
            "Yes, I don't know, but you could be eliminating support, decorate and later points would become useful.",
            "So you could be doing a backward than forward.",
            "Have you tried looking back?",
            "Yes, that's true that this method is in this.",
            "In this fashion is a greedy algorithm and it has.",
            "Maybe we can try to do something like, well, we can retrain and then continue to forest to take back some remove vector.",
            "This could be good.",
            "Did you can you stop it?",
            "Partnering doesn't help you stop and sometimes you can go to the end.",
            "You mean that you can have it in the end 0 support picture and Silver Now.",
            "The end is keeping only those vector the those Alpha well do supervector we have the same Alpha that is a one in two 9.",
            "In the end when where N is the number of super vectors.",
            "But of course we can take out all the support vectors, so we have to stop or or a stopping Criterion series.",
            "Or then when all the Holder training and perform.",
            "And then you find that once you have the subscription that you stop when all the coefficients are the same.",
            "Does not conserve too many years ago because we couldn't still remove some.",
            "Yes, maybe you could still remove some, but as we have starting the process is like the important.",
            "The relevance of each pattern is in the Alpha values, so we have no evidence that removing them will increase the classification.",
            "I think that.",
            "Was it some mining something which you might find interesting?",
            "Which is the fact that this is an online algorithm I keep?",
            "The vectors.",
            "As far as they are misclassified.",
            "And I mean there are aseptic results showing that this works well.",
            "So basically you do it interactively and at each point you see whether different vector is misclassified.",
            "If so, you keep it.",
            "Otherwise you will.",
            "This may be another approach.",
            "Baseline.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about our work that was researched by Hotel Jerusalem, tell it on myself.",
                    "label": 0
                },
                {
                    "sent": "Ann is entitled optimal bug on support vector selection for calendar settings.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. A common problem with their support vector machines is there you need a high amount of support vectors in order to generate the output, and the output is the order of the number of support vectors or kernel operations.",
                    "label": 1
                },
                {
                    "sent": "So in this work we try to pay a new method to reduce the number of support vector machines on also.",
                    "label": 0
                },
                {
                    "sent": "Keep a good accuracy results.",
                    "label": 1
                },
                {
                    "sent": "In order to achieve this task, we study the support vector machines training method and how it performs their margin maximization.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And it started with a brief review of support vector machines method.",
                    "label": 1
                },
                {
                    "sent": "This important support vector material, sorry support vector machines goal, is to construct a linear classifier in order to classify training sets.",
                    "label": 1
                },
                {
                    "sent": "With keeping our maximum margin, we can see the margin as the distance between the separator hyperplane and the nearest pattern to it to it.",
                    "label": 1
                },
                {
                    "sent": "We have seen in before that we have to solve this quadratic.",
                    "label": 0
                },
                {
                    "sent": "Alright problem.",
                    "label": 0
                },
                {
                    "sent": "With which also is constrained by the series or equation that this all equation means that all patterns has to be good classified an we have seen that this problem is quite complex so.",
                    "label": 0
                },
                {
                    "sent": "We like another method to avoid this computation.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this other method is facing the convex Hull normalization.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "We change the input space just by applying the sign for its pattern.",
                    "label": 0
                },
                {
                    "sent": "And then we have that the optimum weight vector verifies that is that it has the lowest norm of all the vectors in the outcome of the input space.",
                    "label": 0
                },
                {
                    "sent": "Moreover the optimal weight.",
                    "label": 0
                },
                {
                    "sent": "Verifies that its margin is equal to its norm.",
                    "label": 0
                },
                {
                    "sent": "That is, for any other way better in the convex Hull, we have that it's margin is less or equal that the optimal margin and also it's norm is greater or equal that the optimal node.",
                    "label": 1
                },
                {
                    "sent": "We have this language we can stay on UG function that is the difference between the norm at the margin and states this function optimal criterion.",
                    "label": 0
                },
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I announced that Slesinger Casino in Calgary.",
                    "label": 0
                },
                {
                    "sent": "This algorithm system unified dysfunction intuitive first is select the pattern.",
                    "label": 0
                },
                {
                    "sent": "We have minimal margin.",
                    "label": 0
                },
                {
                    "sent": "What is means that if the pattern is wrong classified, it tries to to correct the worst wrong classified pattern?",
                    "label": 0
                },
                {
                    "sent": "And also if all patterns are good classified, just the one who have minimum margin.",
                    "label": 1
                },
                {
                    "sent": "OK then instead is update the weight vector in a fashion that is similar to Debrecen Battle rule, but we have to keep the weight vector in its combat Hall.",
                    "label": 0
                },
                {
                    "sent": "Then we have also have a Lambda parameter that ensures that the new weight vector is.",
                    "label": 0
                },
                {
                    "sent": "Is there minimum with the same pattern?",
                    "label": 0
                },
                {
                    "sent": "The Slesinger consonant algorithm assumes that in each iteration, the weight norm it's going to be reduced or addressed.",
                    "label": 0
                },
                {
                    "sent": "Keep equal.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, what problem with Sling Selinger causing the Calgary is that is a linear classification but the we use kernel?",
                    "label": 0
                },
                {
                    "sent": "We can avoid this problem, just a.",
                    "label": 0
                },
                {
                    "sent": "Put in all the.",
                    "label": 0
                },
                {
                    "sent": "The the products in terms of the kernel.",
                    "label": 0
                },
                {
                    "sent": "Then we can write their weight vector in its dual form and perform the.",
                    "label": 0
                },
                {
                    "sent": "The update in terms only of this Alpha that does the dual coefficients.",
                    "label": 0
                },
                {
                    "sent": "And the date of this to our confidence are in custom dynamical patterns.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also, to speed up the new pattern selection, we keep margin vector for each pattern.",
                    "label": 1
                },
                {
                    "sent": "So it's very easy to choose the new pattern to be.",
                    "label": 0
                },
                {
                    "sent": "To be a.",
                    "label": 0
                },
                {
                    "sent": "To be trained.",
                    "label": 0
                },
                {
                    "sent": "Also, this Lambda parameter is very easy to compute and the update of this margin, the vector and all the number.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very.",
                    "label": 0
                },
                {
                    "sent": "The order of the number of patterns and the cost of kernel computation.",
                    "label": 1
                },
                {
                    "sent": "This means that the cost of that theater is an escargot algorithm training.",
                    "label": 0
                },
                {
                    "sent": "Is in the order of the time of the iteration, number of iterations, per the number of patterns, per the cost of 1 kernel computation.",
                    "label": 1
                },
                {
                    "sent": "But then the resulting perfect if it's going to apply to a test set.",
                    "label": 0
                },
                {
                    "sent": "It cost will be the number of support vectors per the size of the test set for the order of the kernel computation cost.",
                    "label": 0
                },
                {
                    "sent": "And this may be similar to the whole training.",
                    "label": 1
                },
                {
                    "sent": "If we have that number of super vector is similar to the whole training patterns.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we.",
                    "label": 0
                },
                {
                    "sent": "We have to try to reduce the amount of support vectors.",
                    "label": 0
                },
                {
                    "sent": "One good thing that we are working in that combats all, it's that they would vector.",
                    "label": 0
                },
                {
                    "sent": "In the convex Hull, have this property that all these Alpha coefficients someone?",
                    "label": 0
                },
                {
                    "sent": "So the question is, is it possible to see this a probabilistic distribution?",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can, we can see these Alpha coefficients to be about the relative relevance in order to correct classify.",
                    "label": 1
                },
                {
                    "sent": "On also, is this Alpha coefficients will be around the same for all the for all their support vectors.",
                    "label": 1
                },
                {
                    "sent": "Then we can use this setup to pronounce supervector removal methods.",
                    "label": 0
                },
                {
                    "sent": "We consider just remove those patterns we have allow Alpha coefficients.",
                    "label": 1
                },
                {
                    "sent": "No, the first idea is, rather than trying aggregate computation, we just iterate the algorithm, remove those support vectors with low Alpha values, and then return again using as our new training set.",
                    "label": 1
                },
                {
                    "sent": "Just all the support vectors that we have.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'll start innocent.",
                    "label": 0
                },
                {
                    "sent": "The method we start with an initial training sample.",
                    "label": 1
                },
                {
                    "sent": "We have our initial facts or Delta that must be lower than one.",
                    "label": 0
                },
                {
                    "sent": "On after the whole training finished, we keep only those.",
                    "label": 0
                },
                {
                    "sent": "Those patterns will have Alpha upper done, so threshold that is threshold is in terms of this data factor and the number of buttons.",
                    "label": 0
                },
                {
                    "sent": "Then we will literally apply the salaries.",
                    "label": 0
                },
                {
                    "sent": "With increasing Delta values up to one, so the result is a decreasing sequence of the training set.",
                    "label": 0
                },
                {
                    "sent": "Additionally, we can use the remote later as a validation set in order to try to know when is we have to stop this.",
                    "label": 1
                },
                {
                    "sent": "This president.",
                    "label": 0
                },
                {
                    "sent": "We can see this, just stop reduce removing support vectors when the accuracy goes quite low.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now I'll explain how we will experiment.",
                    "label": 0
                },
                {
                    "sent": "We have done an.",
                    "label": 0
                },
                {
                    "sent": "How we go?",
                    "label": 0
                },
                {
                    "sent": "OK, we have worked with C data set from there.",
                    "label": 0
                },
                {
                    "sent": "Well known.",
                    "label": 0
                },
                {
                    "sent": "You see a repository.",
                    "label": 0
                },
                {
                    "sent": "We have used our goals, our kernel with an arbitrary value of Sigma square of 50.",
                    "label": 1
                },
                {
                    "sent": "This might be important.",
                    "label": 0
                },
                {
                    "sent": "This value of Sigma, but we only want to know if this support removal method works.",
                    "label": 0
                },
                {
                    "sent": "We think that it's OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Also to Valentina stability, we have expanded project patterns in this way.",
                    "label": 0
                },
                {
                    "sent": "This is adding new dimensions with all values are zero except in the index for each pattern that is designed into two and this contact constancy.",
                    "label": 0
                },
                {
                    "sent": "This is very easy to work with and Italy were only required to extend the kernel adding this term.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Now.",
                    "label": 0
                },
                {
                    "sent": "For each data set we have performed our term growth for validation.",
                    "label": 1
                },
                {
                    "sent": "Also, for each data set we have performed auto 20 returns with the consent equals for it.",
                    "label": 0
                },
                {
                    "sent": "We have seen that it.",
                    "label": 0
                },
                {
                    "sent": "This number of epochs is sufficient to obtain a gold optimal margin.",
                    "label": 0
                },
                {
                    "sent": "Then we have to start with Delta value of .5 anusara fixed increment and then given increasing thresholds.",
                    "label": 0
                },
                {
                    "sent": "Then after its removal and retraining state, we shall compute their validation, accurate accuracy and the test accuracy.",
                    "label": 1
                },
                {
                    "sent": "And then as I stop criterion, we have.",
                    "label": 1
                },
                {
                    "sent": "This procedure ends when already China had completed, or when the difference between the accuracy of correlative retraining are greater than the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have the this May assure that when the accuracy is going too low we will stop.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This table summarizes the results for each data set.",
                    "label": 0
                },
                {
                    "sent": "We have the number of patterns, the initial support vectors they have, and the final supervector we have achieved.",
                    "label": 0
                },
                {
                    "sent": "Also, we have some, so here the ratio between the final supervector and initial to perfect your number.",
                    "label": 0
                },
                {
                    "sent": "We can see that this ratio is about 50, about 70%.",
                    "label": 0
                },
                {
                    "sent": "Which is quite good.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now in detail from some data sets, starting with the Hardy says data set.",
                    "label": 0
                },
                {
                    "sent": "Mr Criterion is met where its value gets positive.",
                    "label": 0
                },
                {
                    "sent": "So in this example the secretary is met with at the factor of .7.",
                    "label": 0
                },
                {
                    "sent": "We can see that the test accuracy is a little bit worse than the original test accuracy, but we have.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In some degree a good resolution vector.",
                    "label": 0
                },
                {
                    "sent": "Would the support vector relax?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, in this other sample.",
                    "label": 0
                },
                {
                    "sent": "The stop criterion is never met, so we have performed the whole returnees.",
                    "label": 0
                },
                {
                    "sent": "This example is very similar to the last in the terms that they support vector are decreasing the number of super vectors, but Interestingly the accuracy is improved after the removal.",
                    "label": 0
                },
                {
                    "sent": "Step.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this other data set.",
                    "label": 0
                },
                {
                    "sent": "Step material is net that deserve the final Test.",
                    "label": 0
                },
                {
                    "sent": "Accuracy is equal to the original security or very similar, and again there is a good reflection of the support vectors.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally another example.",
                    "label": 0
                },
                {
                    "sent": "That is quite similar to the last sample.",
                    "label": 0
                },
                {
                    "sent": "The final currency is almost the same as the original 1, and we have a reduction in the number of a pattern.",
                    "label": 0
                },
                {
                    "sent": "So in light of this, we can see that these methods provide a good reduction of the support vector number.",
                    "label": 0
                },
                {
                    "sent": "And also the accuracy doesn't get.",
                    "label": 0
                },
                {
                    "sent": "And worsening alert.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I saw you some wraps.",
                    "label": 0
                },
                {
                    "sent": "This brows are the evolution of the accuracy both in validation, set and estate.",
                    "label": 0
                },
                {
                    "sent": "Anybody since it is the upper line and.",
                    "label": 0
                },
                {
                    "sent": "They said the lower line.",
                    "label": 0
                },
                {
                    "sent": "We can see that as the Delta value gets increasing the.",
                    "label": 0
                },
                {
                    "sent": "The accuracies are starting to go alone.",
                    "label": 0
                },
                {
                    "sent": "And at that point we have stop.",
                    "label": 0
                },
                {
                    "sent": "It's maybe a good point.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now for that Wisconsin data set.",
                    "label": 0
                },
                {
                    "sent": "We have the same constant accuracy, so we have seen that we can keep removing vectors until the end and the accuracy is just OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From this case.",
                    "label": 0
                },
                {
                    "sent": "It's very.",
                    "label": 0
                },
                {
                    "sent": "Strange because the validation accuracy starts getting low but the test accuracy stays at the same level more or less.",
                    "label": 0
                },
                {
                    "sent": "We have stopped at this factor .75, but we maybe can continue until the end.",
                    "label": 0
                },
                {
                    "sent": "The the South, that may be our stop criterion isn't the best.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, again for another data set that they separate Arian is quite.",
                    "label": 0
                },
                {
                    "sent": "But soon, but it may be OK because then after the retraining the accuracy starts going down.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So finally as conclusion, we can see that a common problem for Kinder classifiers is the high number of support vector machines.",
                    "label": 1
                },
                {
                    "sent": "They must have used, resulting in a very high cost of the new Python classification.",
                    "label": 1
                },
                {
                    "sent": "We have shown that the number of support vectors can be considerably reduced while retaining a good accuracy.",
                    "label": 1
                },
                {
                    "sent": "Also, they were presented here has to be seen as as priority natures in terms that we have announced the problem.",
                    "label": 0
                },
                {
                    "sent": "We have the problem and trying to look something to to obtain a good result.",
                    "label": 1
                },
                {
                    "sent": "Finally as future work.",
                    "label": 0
                },
                {
                    "sent": "We have looking for a better stopping criterion.",
                    "label": 1
                },
                {
                    "sent": "And also investigate other methods in order to minimize the number of support vectors.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of these other methods as it could be a budget algorithm or.",
                    "label": 0
                },
                {
                    "sent": "Some other kinds to training with fixed amount of support vectors.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's all any question.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Senior procedure to reduce the number of support vectors you're doing.",
                    "label": 0
                },
                {
                    "sent": "What we call in feature selection or backward elimination.",
                    "label": 0
                },
                {
                    "sent": "So you're stuck with the full set of supervision, yes.",
                    "label": 0
                },
                {
                    "sent": "In in doing that.",
                    "label": 0
                },
                {
                    "sent": "Yes, I don't know, but you could be eliminating support, decorate and later points would become useful.",
                    "label": 0
                },
                {
                    "sent": "So you could be doing a backward than forward.",
                    "label": 0
                },
                {
                    "sent": "Have you tried looking back?",
                    "label": 0
                },
                {
                    "sent": "Yes, that's true that this method is in this.",
                    "label": 0
                },
                {
                    "sent": "In this fashion is a greedy algorithm and it has.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can try to do something like, well, we can retrain and then continue to forest to take back some remove vector.",
                    "label": 0
                },
                {
                    "sent": "This could be good.",
                    "label": 0
                },
                {
                    "sent": "Did you can you stop it?",
                    "label": 0
                },
                {
                    "sent": "Partnering doesn't help you stop and sometimes you can go to the end.",
                    "label": 0
                },
                {
                    "sent": "You mean that you can have it in the end 0 support picture and Silver Now.",
                    "label": 0
                },
                {
                    "sent": "The end is keeping only those vector the those Alpha well do supervector we have the same Alpha that is a one in two 9.",
                    "label": 0
                },
                {
                    "sent": "In the end when where N is the number of super vectors.",
                    "label": 0
                },
                {
                    "sent": "But of course we can take out all the support vectors, so we have to stop or or a stopping Criterion series.",
                    "label": 0
                },
                {
                    "sent": "Or then when all the Holder training and perform.",
                    "label": 0
                },
                {
                    "sent": "And then you find that once you have the subscription that you stop when all the coefficients are the same.",
                    "label": 0
                },
                {
                    "sent": "Does not conserve too many years ago because we couldn't still remove some.",
                    "label": 0
                },
                {
                    "sent": "Yes, maybe you could still remove some, but as we have starting the process is like the important.",
                    "label": 0
                },
                {
                    "sent": "The relevance of each pattern is in the Alpha values, so we have no evidence that removing them will increase the classification.",
                    "label": 0
                },
                {
                    "sent": "I think that.",
                    "label": 0
                },
                {
                    "sent": "Was it some mining something which you might find interesting?",
                    "label": 0
                },
                {
                    "sent": "Which is the fact that this is an online algorithm I keep?",
                    "label": 0
                },
                {
                    "sent": "The vectors.",
                    "label": 0
                },
                {
                    "sent": "As far as they are misclassified.",
                    "label": 0
                },
                {
                    "sent": "And I mean there are aseptic results showing that this works well.",
                    "label": 0
                },
                {
                    "sent": "So basically you do it interactively and at each point you see whether different vector is misclassified.",
                    "label": 0
                },
                {
                    "sent": "If so, you keep it.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you will.",
                    "label": 0
                },
                {
                    "sent": "This may be another approach.",
                    "label": 0
                },
                {
                    "sent": "Baseline.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}