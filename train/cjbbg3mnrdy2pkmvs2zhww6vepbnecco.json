{
    "id": "cjbbg3mnrdy2pkmvs2zhww6vepbnecco",
    "title": "Beyond Stochastic Gradient Descent",
    "info": {
        "author": [
            "Francis R. Bach, INRIA - SIERRA project-team"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization"
        ]
    },
    "url": "http://videolectures.net/roks2013_bach_optimization/",
    "segmentation": [
        [
            "So I would like to thank the organizers for inviting me here, so he'll pleasure to be in a sunny level.",
            "Also, I would like to acknowledge the work of my former postdocs Niccolo and Mark Smith and of my colleague from Telecom Paris Tech equally.",
            "So so before I stop, don't hesitate to interrupt me.",
            "If anything is unclear, or if you disagree, just tell me we can discuss online.",
            "Then after the talk.",
            "So today I'm going to talk about."
        ],
        [
            "The last scale machine learning.",
            "So in the traditional big data set up, when you have like some data you want to run from in that scenario, and then we use computer vision as a motivating example.",
            "But it goes beyond beyond of course computer vision.",
            "We have a lot of every image is quite big, so the dimension of your inputs P is quite large.",
            "Millions of pixels.",
            "For images, the number of images you want to learn from is pretty big.",
            "OK if you.",
            "Any decent that I said we have millions of examples and finally, as it is not a topic of the talk, but I think the topic of high interests you have a lot of tasks to be solved on those images typically have like not one object, but potentially many objects which are present in your image and it sees a circle like multitask setup and maybe massive on table.",
            "We mention it this afternoon.",
            "So in those setup, when both men PNNKA large, you're faced with the problem of computation and ideally you would like your method to learn in the size of your data.",
            "So if you make no assumptions to store like P and images of size, P&K tax, end task K tax and tasks of size K, then you need OPN plus.",
            "Can running the complexity just to look at your data.",
            "And the goal of this talk is really to try to achieve such complexity.",
            "So since I won't care so much about K, we will achieve all of PN and assuming the P is equal to 1.",
            "So here if you want to be to be fast.",
            "There are several alternatives.",
            "The first one is just to do nothing.",
            "OK, so the algorithm that does nothing as a nice complexity but doesn't does not predict very well.",
            "OK, so from the start of a tradeoff between good predictions, an efficient predictions.",
            "OK, so this is what I mean by mixing statistics and optimization.",
            "And in that setup people have gone back to very simple methods, essentially methods from the 50s.",
            "So in a sense it might be a bit depressing because we still use the same method, but I think there's still.",
            "New things to be done, and in particular in this study will try to go beyond Robins model, which is essentially stochastic gradient descent and this will be done using smooth smoothness.",
            "OK, so here the key aspect is tried to use smoothness to go beyond the classical stochastic agent isn't.",
            "So night I will there be too many parts in my toy."
        ],
        [
            "First overview of existing work.",
            "The goal is really to set the scene with all relevant concepts and the key concepts will be stochastic gradient descent and this averaging where you do averaging at the end of the algorithm to improve performance and what will appear key from the literature is the difference between strongly convex functions.",
            "An non strongly convex functions.",
            "So in a nutshell, strongly convex problems are easy.",
            "And not only convex problems, but still convex are a bit harder.",
            "Then show new work so he said NIPS admission with equal in showing that this distinction between strongly convex and not only convex can be.",
            "Merged if you use a smoothness OK and this will.",
            "This will be done with using constant step size and online you turn steps.",
            "So just keep this in mind for the moment an if time permits and probably want I will go over less recent work with Nicola LaRue and Mark Smith trained to deal with the situation where you don't have like an infinite amount of data that you have a finite amount of data and you go and you make several passes passes through it.",
            "OK. And here we are able to achieve.",
            "Dinner convergence rate for 20 convex functions.",
            "So a bit of notation, so I'm going to consider."
        ],
        [
            "Mostly supervised learning problems where the inputs are XI.",
            "The inputs are why I will assume the data ID, and I'm going to use mostly linear predictions.",
            "OK, so really now I'm not in X, but in some feature vector of X which will be of dimension P. So data times 5X will be my prediction and I'm going to consider empirical risk minimization where I will minimize a convex data fitting term.",
            "So this will be a loss L between why I this is what I want to predict and this is my prediction and the loss in this talk will always assume we always be.",
            "Convex and smooth.",
            "OK, so this includes the least squares of course.",
            "Also logistic regression, but this excludes the support vector machine.",
            "OK, so if you want to talk more about this, can do this offline, but here smooth smooth loss, only smooth and convex, and we may add the regularizer to avoid overfitting.",
            "So here in that simple equation you have two several quantities of interests gathered.",
            "Training costs OK, so this is.",
            "So you observe N data points or any pairs of data points and you have access to this training costs.",
            "OK, this is a wonder going to minimize OK, but you really care about is not the performance on your training data set, but the performance on unseen data.",
            "And this is the expectation of our pair XY coming from the same distribution of the same loss between my response and my prediction.",
            "So these are really further testing cost.",
            "So here you have access to EF Hutton.",
            "You want in fact to minimize.",
            "Without 2 main questions, when you're faced with that problem, the first one is an optimization question.",
            "How do you compute that art?",
            "OK, I have a nice context problem so I can get a hat and then you have more statistical question which is once I get to the Hut.",
            "How does it perform on future data?",
            "OK, so those two tasks have been tackled separately for awhile and not really the main message of the talk is that those two tasks have to be handled simultaneously and this is really the topic.",
            "Of today."
        ],
        [
            "So a bit of review of relevant concepts for convexity from convex optimization, so I will use a smoothness so this is not the.",
            "The finest version of smoothness.",
            "But this is the one which is easiest to understand.",
            "Function will be smooth.",
            "Essentially it's second.",
            "Derivatives are bounded from above and so GG.",
            "This is a history of G is bonded with the positive semidefinite order by a type of entity, meaning that the largest eigenvalues of G. The Hessian is, uh, is abundant by end.",
            "OK, so on the left is smooth function.",
            "On the on the right, the non smooth function.",
            "So in the context of machine learning, whether objective functions of have that form, and if L with a loss is as smooth as well."
        ],
        [
            "Then essentially, you're making boundedness assumption on your data.",
            "OK, so this is not so strong.",
            "They assuming the data are bounded is really not super strong.",
            "The next assumption Is's tongue."
        ],
        [
            "Connecting so this is a more stronger assumption.",
            "So function will be amusingly convex if it is above is tangent OK.",
            "This is convexity, but not only this is a tangent at 8A2 OK, but bigger than with some quadratic term and this method entry that you have curvature in every direction.",
            "If your function happens to be also twice differentiable, which will be my case in this talk, then this corresponds now to a lower bound on the eigenvalues of the Haitian.",
            "So of course, I strictly positive bond since order bars are positive because of convexity.",
            "So here this is a convex function which is not only convex because we have a flat pattern out there and this one is as Tony context function and just note that it is non smooth because the concept of non smoothness or smoothness and connectivity after going to each other.",
            "You can be nonsmooth space only convex, but in this talk everything will be smooth anyway OK.",
            "So now they're going to take."
        ],
        [
            "Machine learning this is hunger assumption, so again, if you losses of that form then the Russians are essentially proportional to the covariance matrix of your data and now you have to assume like a lower bound on the eigenvalues of matrix and this correspondence introduced to having an invertible covariance matrix.",
            "So from the start this is a very assumption, the first reason being that you have to assume that N is greater than pee, if any lower than you cannot be invertible.",
            "And so this is a strong assumption, and what people often do, because this is typically never valid in any here that I said.",
            "People do add a regularizer of that form.",
            "OK, so this is.",
            "But people, so we take a certain you OK and then we add organizer.",
            "Things become the functions become strongly convex and life is much easier.",
            "Keep in mind that when you do this, you do add a bias.",
            "OK, you'll get our eyes, you don't optimize the guard function.",
            "So if you want to predictions after adding these to be as good as when you didn't have that term, you need you to go to zero.",
            "OK, so in a sense you need mutebi large for optimizing, but you didn't need to be small for statistics.",
            "There is clearly a tradeoff and you really have to be careful when you say problems are strongly convex.",
            "So one of the main message of the talk is to get rid of that strong convexity altogether.",
            "So little bit overview, unlike simple techniques to do a convex optimization, so I would assume GS convex and smooth, and there are two main algorithms and of course there are much better now."
        ],
        [
            "But here we consider garden dissent where you interact iterative algorithm.",
            "OK, let's go where you go from 1030 -- 1 two 30 by going down the direction of the negative radians, but you're going to show it at here.",
            "The concept of time complexity is what makes the algorithm fast or slow.",
            "This is the exact same algorithm, but if the problem happens to be strongly convex, you get this linear convergence rate.",
            "So at every time step you cut down the error by a certain amount.",
            "While if you just convex, so not strongly convex, you only converted height for novelty.",
            "This is quite slow 'cause if you want to get like a precision of 10s of minor three, so you get once you need to have at least 1000 iterations.",
            "So here the important aspect here is that strong convexity lack is will dictate the complexity of your of your problem.",
            "I just mentioned Newton method here because I'm going to use it later, so typically in a large data set up when P is very large.",
            "Z student step, which we simply rescaled gradient by the Haitian, cannot be around because it's it requires metric conversion.",
            "But if you were able to do it then we get like quality convergence rate.",
            "So you can get easily to arbitrary precision.",
            "So here one of the key insights by Limbo two and early Bousquet is that in the context of machine learning we don't have to solve problems up to measure precisions.",
            "Machine learning is not any context problem.",
            "The first one is.",
            "Since I work as functions of averages, there is this natural variations of one over root N. On there, there mean so trained to go below that is kind of useless because you start to optimize something which has no significance.",
            "And finally so low precision.",
            "Finally, our cost functions are averages.",
            "OK, so maybe we can take this.",
            "You can take this into account to get better algorithms, and it's essentially the topic of stochastic approximation.",
            "OK, So what is statistic approximation?",
            "So is the goal here so defined to minimize the function F?",
            "So this would be convex will be an RP for simple for simplicity."
        ],
        [
            "But we only observe F, not sweet gradients.",
            "So if you knew the gradients could look like a decent, but only through a noisy version of those gradients, and I will call F prime N of the time the noisy version of F prime of data in which is a true gradient.",
            "So this has been looked at a lot in the signal processing community since the 50s.",
            "Typically assumptions of that form that the observer gradient is a gradient plus some additive noise.",
            "And this was done with on a lot of problems not only on minimizing convex functions, and there's a long long literature, and which is a reference in the at the end of the slides.",
            "In the context of machine learning, we don't have this additive noise, but we have something which is a bit more specific, so here I will.",
            "Each of my noisy gradient will come from a single data point.",
            "OK, so here the function I'm going to minimize F is a true generalization error, which I caught up Sir.",
            "OK, so F of data will be the expected value of the loss of an unseen data point, so this I cannot observe.",
            "But what I can observe?",
            "Is a loss and is gradient under a single data point.",
            "OK, so FN this will be my function which I observe at at time N is allowed between the label YN as the input X Ann, just taking the expectation under David differentiating under the expectation the expected value of the gradient of the gradient.",
            "This is a gradient with respect to Theta of a single loss.",
            "Then the expected value of this one is the expected the.",
            "Gradient of the true true generalization error.",
            "So here we are in the set up where the gradient of a single data point is an unbiased estimate of the true.",
            "OK, so now what would be the algorithms so there be two kind of a 2 main assumptions.",
            "Strong convexity or lack thereof and smoothness, so the Kia."
        ],
        [
            "Rhythm game from the 50s.",
            "Robbins Monro is essentially stochastic gradient descent, where at at time N. So here there's a small subtlety.",
            "So here in the context of stochastic approximation, the number of iterations is exactly the number of observed data points.",
            "That's why I use NT use any here and not T OK, every time you see a point, you compute the gradient with respect to your parameter to current iterated AD minus one and you go down the direction of this of this of this graduate with a certain step size gonna end.",
            "So this is this can be so people also consider this so called project Supercharging where at the end of the optimization you take the average of all iterates.",
            "So this is simply post processing of the iterates, so of course if you want to implement this online, it's only one line, one line of code.",
            "Then the key question now is what?",
            "What should gamma in be OK so good man is often called the learning rate sequence and people typically issues typically choose gamma end of the form C / N to the Alpha and the key elements are what you see.",
            "What is Alpha?",
            "So there's been a lot of work on that on that simple problem.",
            "An essentially people have found like both like upper bounds and lower bounds or complexity, which you cannot beat socially.",
            "This was done by Nemerofsky nude in the 80s."
        ],
        [
            "And for nonsmooth optimization, so it is really, really important here.",
            "All those lower bounds only valid for nonsmooth optimization.",
            "Then they have shown that if the problem happens to be strongly convex, then the best you can do is one of RMU in terms of convergence rates.",
            "So here to be explicit, its occurrence rate of the function values to the optimal function value, and this is achieved by average stochastic agency sent with a certain step size, and for non chronic connect function you are slower.",
            "This is looking like the classical deterministic setting where when you have when you don't have strong convexity, you go a bit slower and you go from one of our end to one of the root N. And this is also achieved with stochastic descent and were edged with the different step size.",
            "OK, so this this tells you that you cannot.",
            "You cannot beat this if if you want.",
            "If you want to work with non smooth function.",
            "So another set of result by OK and this.",
            "They had a lot of work trying to do this and to improve on this and I drive to cite everybody in the home and this is not the goal of today.",
            "If you want to know more, you can look at all of these papers.",
            "Particular for extensions two beyond that, if you want to do positive, for example, you have nice paperback.",
            "So do Gene and others to adapt the framework to L1 type problems.",
            "But what I want to fuck."
        ],
        [
            "So nice, well, bipolar can do this key and the whole part, which is of a different nature.",
            "OK, So what they show is that for smooth problem, if you do have a raging and you take any step size of that form, OK, so between one of the road N and 1 / N then first only convex problem you get this one over and convergence rate OK.",
            "So essentially, if you're willing to assume smoothness then you have then do a Virgin.",
            "You have a wide range of step sizes whereas for the non smooth.",
            "Problems you have to.",
            "You need to have a few 20 convex.",
            "You need to have a small step size and it will not only convex.",
            "You have to have large step side.",
            "The first question is, is it possible to get around this?",
            "Having two step sizes for the two situations?",
            "Remember gradient descent was adaptive in the sense that the exact same algorithm was used, and depending on your chance, or depending on the weather function, is convex or not.",
            "Even if you don't, even if you don't know it in advance, it will adapt to it.",
            "Those set of results do not say this.",
            "For this you need to know you need to do it in advance.",
            "If you're going to disconnect or not.",
            "So the first question is, is it possible to get a single algorithm?",
            "Which will be adaptive in the sense that you don't need to tell to tell it what is mu OK and we try to adapt to the best possible value of mu.",
            "OK, and this if you take this, of course you want to.",
            "The hint is.",
            "If you take gamma and being see over Hood N OK, they need to combine this guy and this guy.",
            "You should get what you want.",
            "OK, so it's essentially just a warm up for the later part of the talk.",
            "So what this is this is going to be down for law."
        ],
        [
            "Mystical Russian OK, so discussion is a subcase of the supervised learning problem with labels are in minus one one and the loss is of that form log of 1 plus an exponential and again the goal is not to minimize or training error, but the goal is to minimize the expectation which in which which you never observe.",
            "So first thing, if you if you play with logistic regression, it cannot be scrawny, convex.",
            "Why?",
            "Because this is a logistic loss load of 1 plus exponential minus U and this dense to have flat paths at the community.",
            "So if you want to be strongly convex, you have to restrict the first solution is to restrict the domain to be compact, but then you introduce constants of the form exponential M. So what we're going to do here will be to redefine you not as a global.",
            "Tonka Mystic on stunt not so the global tranquility constant is the minimal lower lower second values overall Hessians at every point.",
            "I'm going to replace this by simply the lowest I can value at the optimum.",
            "OK so local notion of some convexity mubi this lowest again value.",
            "So what I've shown is that if you take."
        ],
        [
            "Step side of the from one of her hood end.",
            "So here there's more subtlety in that when you play with to get visa optimization techniques, you have two types of techniques, the ones that are anytime OK that will put the resort at anytime and once for which you know the horizon in advance and you choose.",
            "I'm going to run an iterations and able to choose a step size accordingly.",
            "Typically the two tend to works question early, so here.",
            "But for simplicity of the result and consider the constant steps up with an owner eyes and and the constant step size does depend on the horizon of the form.",
            "Wonderful would end.",
            "So what what are shown is that if they expected value.",
            "So here while you random random because your your data are random, so this expectation is over the data of the average value minus the best possible value test are, which I assumed to exist, will be bounded by what Bible constant times?",
            "Something which is a minimum of the two regimes.",
            "This easy not only collects regime.",
            "Whenever would N OK this see the strongly convex regime 1 / M U so the same algorithm which does not does not need to know the strong commodity constant can adapt to it if mu is large enough.",
            "One instance of an adaptive algorithm lag gradient descent guidance adaptive in the in the deterministic setup, and this is the case as well if you take stochastic agent isn't.",
            "So here we don't provide anything new in terms of algorithms.",
            "We just take the existing one stochastically, dissent and say that it works as well as we expect.",
            "So for the experts, the proof is based on several gardens or generalized version.",
            "OK, now let's get down to the the meat of the talk, which is trained to go beyond this this problem.",
            "So here still I have this problem that depending whether new is bigger, a big, big or not I get 1 / 10 or one of our end.",
            "So the goal now is try to get rid of this and get rid of you.",
            "OK so you get always 1 / N independently or the problem Yep.",
            "The true you.",
            "Yeah, so this mu.",
            "So this is really important to be adaptive to a newbie, 'cause if you happen to be lucky you can go super fast.",
            "So typically if you add like if you if you impose new for example by adding or squared L2 norm then you do have 'em you.",
            "But often your menu is much nicer because you happen to have like.",
            "Close to the optimum you happen to have the more clever than you think, so it's really important for method to be adaptive to the unknown value of new.",
            "OK, so before."
        ],
        [
            "Going further, let's step back a little and consider even a simpler problem, which is the least squares.",
            "OK, so for least squares essentially same setup.",
            "I have a response by end.",
            "This is my prediction and the goal is to minimize the square loss.",
            "OK, nothing really really different.",
            "Now stick it in.",
            "The dissent is often called the least mean square algorithm LMS and typically this has been studied a lot in single processing and typically without averaging and with a certain decreasing step size is.",
            "Moreover, it has been studied mostly in cases where the covariance matrix is invertible, so it might set up.",
            "It has been analyzed for strongly convex problems, So what what we have done with Eric Moline is first to try to do it for the constant step size.",
            "So here it's really a constant step size and you make some assumptions like bonded data and bonded bonded noise and the key element is that we make new assumptions on the lowest eigenvalues of H and what we obtain is that the.",
            "The expected value of the average iterate.",
            "OK, so here again, this is expectation of other data is less than, so one other end.",
            "OK, this was the goal is to remove one of the Lieutenant to remove the one over mu times a constant OK and this one for those familiar with statistics.",
            "If Texas Square you get Signal square PRN.",
            "So this is known to be the lower bound of statistical estimation.",
            "So namely, that for least squares, even with no computational limits, you cannot beat similar square P / N. And we can achieve it just by a simple single path through the data.",
            "And again with not a new algorithm is missing most of the orders algorithm for stochastic approximation suggest elements.",
            "So the novelty here is really to use this constant step size.",
            "And having a custom step size allows us to get nice interpretation.",
            "OK, which is the following.",
            "So he suggested recursion OK."
        ],
        [
            "So this is a loss for a data point.",
            "Is is your cash and Italian and the key aspect that since you step size is constant, OK, this defines a Markov chain and emotional smacker chain at every time step, so that mix is always the same.",
            "OK, so since you have a Markov chain and weak assumptions, it will converge to a stationary distribution Pi of gamma.",
            "So it depend on gamma, because depending on the dynamics depend on gamma as well.",
            "OK, so since you converge to a stationary distribution?",
            "And I've been called Theater of Gamma the expectation, and there's a special that stationary distribution.",
            "So the key aspect is that for least squares.",
            "This expected value, whatever gamma is, is always the optimal value of your problem.",
            "OK, simply, you can simply check this.",
            "So what this means is that if you consider the constant stepsize LMS, it will not converge to test our why?",
            "Because it's a Markov chain and then data will end up being like distributed according to Pi of Gamma.",
            "So you oscillate around the truth and what you could ensure that those orders code of gamma.",
            "But now it seems you have a Mac of chain and you know the expected value of the stationary distribution.",
            "You know that.",
            "The theorem of course I put no assumptions here, but this is just for the idea that if the other edge of the interes they do convert with the expectation and the rate at which it converges, wanna vote N in terms of distance.",
            "So one of our end in terms of square distance.",
            "OK so here is the fact that we have backup chain allowed us almost immediately to to get this one over and convergence rate and then we simply have to put like numbers behind it just to verify this intuition.",
            "So just to give an example, so C."
        ],
        [
            "Do you like Pickles 20?",
            "Just gotten distributions and I've run so gradually stochastically descent with a constant step size with similar constraints and also with the decaying step size over there, and I've consider in the plane.",
            "This is the average version and in the dash this is the non average version.",
            "So what you can see is that if you don't have user edging, you don't converge.",
            "So here this is N in the log scale and they see the distance to optimum in log scale.",
            "So here.",
            "If you do, if you can step study, don't do everything.",
            "You don't converge OK, you will see later on the optimum an you don't converge and if you lower the constant you do get get lower value.",
            "And if you're really really careful, the width between those two is exactly log 10 or four.",
            "OK, so this just confirm confirm the fact that the distance to optimum tends to be of order gamma.",
            "And as soon as diverging up then you do converge.",
            "So you do get to manage to do just go go lower and lower.",
            "And if you check also the the slope, here is one is 1.",
            "OK so you get convergence right at one of right one of our end.",
            "If you want to do this square roots thing, then the iterates do converge.",
            "OK, add height 1 one over root N and when you do everything you also do converge, but at a slower rate.",
            "OK, so here the key aspect is really the fact that if you don't do a Virgin you don't converge.",
            "OK, that's OK because when you do everything you restore convergence OK, so this is the main thing for squalus.",
            "So now let's go to.",
            "Oh, then you have other simulations."
        ],
        [
            "OK, on more like bigger that I said.",
            "So this is classical benchmarks.",
            "With like moderately large dimensions or large large people, this is a sparse data set.",
            "OK, so here I compare 2 three algorithms, constant stepsize, decaying step size, one of oil algorithms, and here left and right.",
            "Very important is left.",
            "I took the constant which is given by the algorithms.",
            "So by the proof.",
            "OK, typically this is not the good constants.",
            "You can always be a lot faster by increasing the constant and.",
            "This on the right side have optimized the constant to get better convergence.",
            "OK, so the first thing is that the constant step size and we have many more plots in the paper.",
            "The constant step size or in blue is not very sensitive to that sort of step size in the sense that the step size from the bound is not terrible, whereas if you take like one over root N, then if you take the steps of the band it goes very slow and if you start to optimize the concern to get good coverage, that good convergence at the end.",
            "You start to explode at the beginning.",
            "OK, so this is classical behavior of one other would end step size.",
            "You have to taxi so big to get a good good convergent at the end that you start by diverging.",
            "OK, let's go back to non non least squares.",
            "OK so we can try to follow the same Markov chain interpretation."
        ],
        [
            "So we have this immigration since gamma is constant, you still get a Markov chain or merger news Markov chain.",
            "So under weak assumptions it also converges to a stationary distribution Pi of gamma.",
            "I will pay off gamma and what you can show it that that distribution is defined so that the average of the gradient over the distribution is 0.",
            "But the problem now is what that when F is is not quadratic.",
            "If crime is not now and this is not, then the gradient of the expectation is not the expectation of the gradient.",
            "OK, so this means that data data of gamma, which is the average of the stationary distribution, is not the optimal value.",
            "So you still oscillate OK, but around the wrong value.",
            "OK, and what you could ensure that these other situations are bonded of state of order, one of with gamma.",
            "But the problem is the following.",
            "Now if you do a village in with the same negative serum, use converge to data of gamma, which is not the test are OK and what you convert at a fast rate.",
            "It is wrong to the wrong value and what you can show that by doing a village Inn.",
            "You go from square root of gamma.",
            "OK two together.",
            "So you do improve the distance, but still you still getting away from the optimal value so we can see this in the same simulation as before."
        ],
        [
            "So we're simply replace the square loss by the logistics loss.",
            "So again, in plain this is averaged in.",
            "Dottie, this is another edged, so those curves are essentially the same.",
            "So if you don't do apology, you don't converge anyway, neither to test our North route agoma.",
            "And when you start to do another gene then you do converge OK, but to something which is not the correct one.",
            "OK so if you have a large constant OK then you convert to something which is.",
            "You converse quickly to something which is not really good and if you lower the constant go from one over to one of our eight then you converge bit slower to something which is a bit better and you take one of our 32 also get even lower.",
            "So for the if you really look carefully and if you had like a bit more.",
            "If the plug was going a bit a bit longer.",
            "Longer then is the distance between those two is twice this time between those two.",
            "OK, so this is just a hint that the distance is of the order of other guys gonna square, so the goal is to do what is trying to avoid this.",
            "OK, you want to be like we had for the square loss which is to know convergence when you don't do averaging but convergence the true value.",
            "But you do eventually.",
            "Is this for this going to do online?"
        ],
        [
            "And you turn steps.",
            "So what is it you do instead?",
            "OK, so let's consider a certain title field.",
            "OK, so we fix a point and we want to do Newton step with respect to this F, which is the which is the generalization error.",
            "But you cannot observe.",
            "So here again we want to do and you don't step on something which we don't observe.",
            "And of course your step is just minimizing the local Taylor expansion at detailed, which I've written here.",
            "So G of Theta get a constant term linear term aquatic term with the key aspect here is that all of those are expectations.",
            "OK, expedited is the expected value of F prime N something for four days and so now you can put can put the can put the hash and the expectation outside and know what you have to solve you to step.",
            "You have to do what you have to minimize the expectation of aquatic function.",
            "So now what we're going to do is simple to use like least mean square with constant step size to solve that guy.",
            "OK so that guy is a Newton step which we can so efficiently.",
            "OK, so now we're going to do this.",
            "So this is the key to the other key aspects.",
            "So this time I returned the LMS algorithm for that guy.",
            "So I just compute the gradient of this, which is over there and I go down the direction of the negative gradient.",
            "But the key aspect here is that we do Newton step, but we never have to computer any Haitian.",
            "OK, so the only thing that we compute is the one associated to a single data point, but since our last function OK is a projection of.",
            "The feature vector that has senior has rank one, so we never have to actually compute any questions and at the end the complexity of these online you can step is just twice the one of the regular stochastic legend decent.",
            "Why it?",
            "Why?",
            "Is because we have to.",
            "We have to do two.",
            "We have to do predictions one.",
            "OK, so at the end what we need to do, we're going to solve it directly.",
            "Newton steps.",
            "OK, so we should deliberately not optimize the function directly, but since we can do this into the step efficiently at the end we end up with better convergence.",
            "So of course the key is a key issue is what what would be the point of Newton step?",
            "So now we have two strategy."
        ],
        [
            "Is which are?",
            "It's a bit unfortunate this classical when you do a bit of Siri, the one for which you can prove stuff and the one which is working better.",
            "OK, so the one for which we can prove things is really strategy where you first do a certain number of steps of regular stochastic descent to get something which is good enough and then run single didn't step using LMS and for this one which is reminiscent of one step estimator.",
            "So you can show that esentially.",
            "The government is all of PRN.",
            "OK, so for logistic regression.",
            "So here again I'm putting a lot of things under the rug in particular in the in the in the bigger, the bigger, but at the end the key aspect is that we are able to avoid any assumption on the strong convexity of the problem.",
            "We get one of our end convergence rate for any possible.",
            "Problems whether it is 20 Contacts or not.",
            "But you see.",
            "So this is 1, which is a for which we have approved.",
            "But the one which is really working better in practice is the one where.",
            "So we change the support point of the Newton step at every iteration, and we use essentially the current average iterate.",
            "OK, so here at every time step I take the current average value, get above 8 -- 1 and I do.",
            "The linear expansion of the gradient around that died minus one, so this is a constant term for today at about 10 minutes wanted.",
            "See the linear term and we just go down this direction this direction.",
            "This is one line of code and we currently have no proof, but one of our students have found a proof and you should get too.",
            "So you should also get this one of our conscious right.",
            "The notice look in terms of simulations.",
            "OK, so this is the same problem as before.",
            "OK, synthetic data and this."
        ],
        [
            "Was a console step size with the averaging leveling off.",
            "At one point he I consider several Newton Newton Newton schemes.",
            "So in red this is one for which I have a proof.",
            "OK, so I first do so this is NI first to enable disable 2 steps of stochastic descent and then I start constant stepsize LMS.",
            "So one of the key to bugs or feature of constants at Ms.",
            "It's very it's very noisy in the sense that.",
            "If when you start LMS, even if you start from the truth is going to oscillate.",
            "OK, so here when you start here and you start to do constant stepsize LMS, you start to oscillate a lot.",
            "That's why you have a jump about them, so clearly this is not a good algorithm to do today in practice.",
            "So what we have done also is to consider doubling strategy, which is very common in optimization where you run this scheme for to the steps OK and then this will allow you to restart for the next batch of.",
            "Twice to the same size as you."
        ],
        [
            "In a joke was and if you take this simple like Newton scheme, where is this a real bird or phone?",
            "Is another one.",
            "Wow OK good.",
            "Yeah, and here in green and blue those are the two curves are on top of each other.",
            "This is a scheme where we update the support points for the Newton step at every iteration and you get this one of our end commitments.",
            "So this can be done as well for.",
            "The benchmarks and more curves and I want to go into it, but at the end with this phone number and business Newton scheme you are able to be robust to the lack of strong convexity and I won't want to go into the details here 'cause I don't have so much time.",
            "OK, so this was."
        ],
        [
            "The first super smoothness, so here.",
            "Clearly we need we need to be smooth to be able to do to do all this and we were able to essentially escaped this one over root N low amount for certain problems.",
            "OK, this is for just logistic regression and not all convex functions.",
            "Low is good with different aspect for just five minutes.",
            "Which is what people do."
        ],
        [
            "Practice OK, often when the other things which are presented.",
            "The number of iterations with exactly the number of observations.",
            "OK, so this essentially assume that you have.",
            "You see that the points only once, and of course the benefit of all this is that you don't have to deal with overfitting.",
            "OK, just see that at points one and you end up optimizing directly the testing cost.",
            "However, in practice, people had a father said and people tend to make several passes 'cause it always works better.",
            "OK then yes, but as soon as you make 2 passes then you may start to overfit.",
            "So two is OK, but three maybe not four, and then you're you have the problem of knowing where to stop, OK?",
            "So I don't know, but we're going to do is exactly this way to see to study the situation where you do multiple passes through the data.",
            "And now if you start to do multiple passes, you end up minimizing the training costs.",
            "OK, no, you don't need my this, but this.",
            "So now you have to go back to classical statistics where you have to add regularizer to avoid overfitting.",
            "Typically typically there to know.",
            "So here what I'm going to present it will be.",
            "I will try to minimize another edge of functions like this.",
            "OK, and typically this will be the loss over the ice data point.",
            "So we have seen Twitter rhythms.",
            "We have seen gradient descent OK, so this is simply you go down the negative gradient.",
            "So if we assume convexity, the governor's height is there is a."
        ],
        [
            "Is good because it's exponential convergence rate, but every iteration you have to compute the old regions of all functions.",
            "OK, so it's complicated.",
            "So essentially you make you make."
        ],
        [
            "A small number of big steps."
        ],
        [
            "Well, so basically the dissent OK, so here we select one element at Honda and from from my training data OK and I copied these only gradient and I go down this gradient.",
            "This is essentially stochastic.",
            "Don't descend on a finite amount of data.",
            "So here of course every iterations of 1 by design, but now the computer's height is all of University.",
            "OK.",
            "So now what you have is."
        ],
        [
            "Many directions which are cheaper for who.",
            "Here of course, the goal is to get the best of both worlds, as this will be the stochastic."
        ],
        [
            "Don't be the last slider on it, so this was just well with Nicola Nicola Luann Mark Smith, so we're going to do exactly like stochastic dissent going to follow to select at every iteration.",
            "Function computed gradient OK, but what we're going to do is to store all graduates of all functions, so every time I see a gradient, OK. Then I compute it and I keep it so that every time step in my algorithm OK, I've stored versions of gradients, some of them are very old and some of them are very new.",
            "OK, so here Huawei ID is stored version already and I at time T, so when I did I update it by not changing anything except for the gradient which I've observed.",
            "But now since I have versions of all my gradients, I can take the other edge OK and go down the average gradient.",
            "So here this is not a new algorithm.",
            "OK, this essentially algorithm of blood it all OK with one small modification, which is the way we select the gradients.",
            "Those are functions, So what we're doing is simply cycling through the data OK, whereas in our case we just do random selection.",
            "In fact, to be perfectly honest, our goal was simply to analyze their method because of an analyzing organizations easier than analyzing cycling.",
            "And it turns out that you can be.",
            "So much faster.",
            "OK, so if you want to know more concussive paper, but by going from cycling to organizing you can make bigger steps and to achieve bigger convergence rate.",
            "So for the people we think that's doing gradients is a problem.",
            "It is a problem, but in the context of machine learning, since the gradients since the functions rank one projections, the gradients are proportional to the feature vector.",
            "So you have to store only a single single cell number.",
            "This in terms of convergence rate, we were able to show that details and important that we have a linear convergence rate for that problem OK?"
        ],
        [
            "So typically the covenant is 1 / T for that.",
            "For that.",
            "For those type of problem you do successfully sent.",
            "But here with integration costs which is independent of the number of examples were able to get a linear convergence rate which was not possible before.",
            "Of course it works well, but that's not the case.",
            "OK, so to conclude, I've presented 22."
        ],
        [
            "Two algorithms which are strongly better on smoothness.",
            "So the first one was constant step size to castigating dissent.",
            "So in the context of least squares, there's not.",
            "It's not a new algorithm, but in order to be able to benefit from the speed of constant step size we have developed these efficient online.",
            "You can step which can which allows us to go to the traffic problem and also passed quickly through this like stochastic address vergent which is adapted to situations where you have.",
            "A finite amount of data and you want to do multiple facets.",
            "So here, of course there's a lot of extensions which which are possible and I will name, namely 2.",
            "The first one is kernels.",
            "OK, so I think there's kernel somewhere in the title of the of the workshop and all of this was assumed assumed to have an explicit representation of my problem and you fear of X it has it has size be OK, but this is not the problem for many problems which we are faced with like text data takes data.",
            "These huge OK please millions but every fixes pass so you don't really care but about the big the size of P. But if you if you want to start to use kernels for like not permitting problems or let's say computer vision, then really there's no need to be able to do all this in the kernel world.",
            "And of course paralyzing.",
            "I think it's also key a key aspect.",
            "And finally, I want to conclude in this whole of non smoothness in machine learning.",
            "So I think in there not mentioned it yesterday so.",
            "Start people so is very important because you have support vector non smoothness and slowly slowly people are deconstructing this SVM by going back to the simpler things which is least squares energistic and it would be interesting to see if.",
            "Click on side views at one point.",
            "Thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I would like to thank the organizers for inviting me here, so he'll pleasure to be in a sunny level.",
                    "label": 0
                },
                {
                    "sent": "Also, I would like to acknowledge the work of my former postdocs Niccolo and Mark Smith and of my colleague from Telecom Paris Tech equally.",
                    "label": 0
                },
                {
                    "sent": "So so before I stop, don't hesitate to interrupt me.",
                    "label": 0
                },
                {
                    "sent": "If anything is unclear, or if you disagree, just tell me we can discuss online.",
                    "label": 0
                },
                {
                    "sent": "Then after the talk.",
                    "label": 0
                },
                {
                    "sent": "So today I'm going to talk about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last scale machine learning.",
                    "label": 1
                },
                {
                    "sent": "So in the traditional big data set up, when you have like some data you want to run from in that scenario, and then we use computer vision as a motivating example.",
                    "label": 0
                },
                {
                    "sent": "But it goes beyond beyond of course computer vision.",
                    "label": 0
                },
                {
                    "sent": "We have a lot of every image is quite big, so the dimension of your inputs P is quite large.",
                    "label": 0
                },
                {
                    "sent": "Millions of pixels.",
                    "label": 1
                },
                {
                    "sent": "For images, the number of images you want to learn from is pretty big.",
                    "label": 0
                },
                {
                    "sent": "OK if you.",
                    "label": 0
                },
                {
                    "sent": "Any decent that I said we have millions of examples and finally, as it is not a topic of the talk, but I think the topic of high interests you have a lot of tasks to be solved on those images typically have like not one object, but potentially many objects which are present in your image and it sees a circle like multitask setup and maybe massive on table.",
                    "label": 0
                },
                {
                    "sent": "We mention it this afternoon.",
                    "label": 0
                },
                {
                    "sent": "So in those setup, when both men PNNKA large, you're faced with the problem of computation and ideally you would like your method to learn in the size of your data.",
                    "label": 0
                },
                {
                    "sent": "So if you make no assumptions to store like P and images of size, P&K tax, end task K tax and tasks of size K, then you need OPN plus.",
                    "label": 0
                },
                {
                    "sent": "Can running the complexity just to look at your data.",
                    "label": 0
                },
                {
                    "sent": "And the goal of this talk is really to try to achieve such complexity.",
                    "label": 0
                },
                {
                    "sent": "So since I won't care so much about K, we will achieve all of PN and assuming the P is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So here if you want to be to be fast.",
                    "label": 0
                },
                {
                    "sent": "There are several alternatives.",
                    "label": 0
                },
                {
                    "sent": "The first one is just to do nothing.",
                    "label": 0
                },
                {
                    "sent": "OK, so the algorithm that does nothing as a nice complexity but doesn't does not predict very well.",
                    "label": 0
                },
                {
                    "sent": "OK, so from the start of a tradeoff between good predictions, an efficient predictions.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what I mean by mixing statistics and optimization.",
                    "label": 1
                },
                {
                    "sent": "And in that setup people have gone back to very simple methods, essentially methods from the 50s.",
                    "label": 0
                },
                {
                    "sent": "So in a sense it might be a bit depressing because we still use the same method, but I think there's still.",
                    "label": 0
                },
                {
                    "sent": "New things to be done, and in particular in this study will try to go beyond Robins model, which is essentially stochastic gradient descent and this will be done using smooth smoothness.",
                    "label": 1
                },
                {
                    "sent": "OK, so here the key aspect is tried to use smoothness to go beyond the classical stochastic agent isn't.",
                    "label": 0
                },
                {
                    "sent": "So night I will there be too many parts in my toy.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First overview of existing work.",
                    "label": 0
                },
                {
                    "sent": "The goal is really to set the scene with all relevant concepts and the key concepts will be stochastic gradient descent and this averaging where you do averaging at the end of the algorithm to improve performance and what will appear key from the literature is the difference between strongly convex functions.",
                    "label": 0
                },
                {
                    "sent": "An non strongly convex functions.",
                    "label": 1
                },
                {
                    "sent": "So in a nutshell, strongly convex problems are easy.",
                    "label": 0
                },
                {
                    "sent": "And not only convex problems, but still convex are a bit harder.",
                    "label": 0
                },
                {
                    "sent": "Then show new work so he said NIPS admission with equal in showing that this distinction between strongly convex and not only convex can be.",
                    "label": 0
                },
                {
                    "sent": "Merged if you use a smoothness OK and this will.",
                    "label": 0
                },
                {
                    "sent": "This will be done with using constant step size and online you turn steps.",
                    "label": 0
                },
                {
                    "sent": "So just keep this in mind for the moment an if time permits and probably want I will go over less recent work with Nicola LaRue and Mark Smith trained to deal with the situation where you don't have like an infinite amount of data that you have a finite amount of data and you go and you make several passes passes through it.",
                    "label": 0
                },
                {
                    "sent": "OK. And here we are able to achieve.",
                    "label": 0
                },
                {
                    "sent": "Dinner convergence rate for 20 convex functions.",
                    "label": 1
                },
                {
                    "sent": "So a bit of notation, so I'm going to consider.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mostly supervised learning problems where the inputs are XI.",
                    "label": 0
                },
                {
                    "sent": "The inputs are why I will assume the data ID, and I'm going to use mostly linear predictions.",
                    "label": 0
                },
                {
                    "sent": "OK, so really now I'm not in X, but in some feature vector of X which will be of dimension P. So data times 5X will be my prediction and I'm going to consider empirical risk minimization where I will minimize a convex data fitting term.",
                    "label": 1
                },
                {
                    "sent": "So this will be a loss L between why I this is what I want to predict and this is my prediction and the loss in this talk will always assume we always be.",
                    "label": 0
                },
                {
                    "sent": "Convex and smooth.",
                    "label": 0
                },
                {
                    "sent": "OK, so this includes the least squares of course.",
                    "label": 0
                },
                {
                    "sent": "Also logistic regression, but this excludes the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you want to talk more about this, can do this offline, but here smooth smooth loss, only smooth and convex, and we may add the regularizer to avoid overfitting.",
                    "label": 0
                },
                {
                    "sent": "So here in that simple equation you have two several quantities of interests gathered.",
                    "label": 0
                },
                {
                    "sent": "Training costs OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "So you observe N data points or any pairs of data points and you have access to this training costs.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a wonder going to minimize OK, but you really care about is not the performance on your training data set, but the performance on unseen data.",
                    "label": 0
                },
                {
                    "sent": "And this is the expectation of our pair XY coming from the same distribution of the same loss between my response and my prediction.",
                    "label": 1
                },
                {
                    "sent": "So these are really further testing cost.",
                    "label": 0
                },
                {
                    "sent": "So here you have access to EF Hutton.",
                    "label": 0
                },
                {
                    "sent": "You want in fact to minimize.",
                    "label": 0
                },
                {
                    "sent": "Without 2 main questions, when you're faced with that problem, the first one is an optimization question.",
                    "label": 0
                },
                {
                    "sent": "How do you compute that art?",
                    "label": 0
                },
                {
                    "sent": "OK, I have a nice context problem so I can get a hat and then you have more statistical question which is once I get to the Hut.",
                    "label": 0
                },
                {
                    "sent": "How does it perform on future data?",
                    "label": 0
                },
                {
                    "sent": "OK, so those two tasks have been tackled separately for awhile and not really the main message of the talk is that those two tasks have to be handled simultaneously and this is really the topic.",
                    "label": 0
                },
                {
                    "sent": "Of today.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a bit of review of relevant concepts for convexity from convex optimization, so I will use a smoothness so this is not the.",
                    "label": 0
                },
                {
                    "sent": "The finest version of smoothness.",
                    "label": 0
                },
                {
                    "sent": "But this is the one which is easiest to understand.",
                    "label": 0
                },
                {
                    "sent": "Function will be smooth.",
                    "label": 0
                },
                {
                    "sent": "Essentially it's second.",
                    "label": 0
                },
                {
                    "sent": "Derivatives are bounded from above and so GG.",
                    "label": 0
                },
                {
                    "sent": "This is a history of G is bonded with the positive semidefinite order by a type of entity, meaning that the largest eigenvalues of G. The Hessian is, uh, is abundant by end.",
                    "label": 0
                },
                {
                    "sent": "OK, so on the left is smooth function.",
                    "label": 0
                },
                {
                    "sent": "On the on the right, the non smooth function.",
                    "label": 0
                },
                {
                    "sent": "So in the context of machine learning, whether objective functions of have that form, and if L with a loss is as smooth as well.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then essentially, you're making boundedness assumption on your data.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is not so strong.",
                    "label": 0
                },
                {
                    "sent": "They assuming the data are bounded is really not super strong.",
                    "label": 0
                },
                {
                    "sent": "The next assumption Is's tongue.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Connecting so this is a more stronger assumption.",
                    "label": 0
                },
                {
                    "sent": "So function will be amusingly convex if it is above is tangent OK.",
                    "label": 0
                },
                {
                    "sent": "This is convexity, but not only this is a tangent at 8A2 OK, but bigger than with some quadratic term and this method entry that you have curvature in every direction.",
                    "label": 0
                },
                {
                    "sent": "If your function happens to be also twice differentiable, which will be my case in this talk, then this corresponds now to a lower bound on the eigenvalues of the Haitian.",
                    "label": 0
                },
                {
                    "sent": "So of course, I strictly positive bond since order bars are positive because of convexity.",
                    "label": 0
                },
                {
                    "sent": "So here this is a convex function which is not only convex because we have a flat pattern out there and this one is as Tony context function and just note that it is non smooth because the concept of non smoothness or smoothness and connectivity after going to each other.",
                    "label": 0
                },
                {
                    "sent": "You can be nonsmooth space only convex, but in this talk everything will be smooth anyway OK.",
                    "label": 0
                },
                {
                    "sent": "So now they're going to take.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Machine learning this is hunger assumption, so again, if you losses of that form then the Russians are essentially proportional to the covariance matrix of your data and now you have to assume like a lower bound on the eigenvalues of matrix and this correspondence introduced to having an invertible covariance matrix.",
                    "label": 1
                },
                {
                    "sent": "So from the start this is a very assumption, the first reason being that you have to assume that N is greater than pee, if any lower than you cannot be invertible.",
                    "label": 0
                },
                {
                    "sent": "And so this is a strong assumption, and what people often do, because this is typically never valid in any here that I said.",
                    "label": 0
                },
                {
                    "sent": "People do add a regularizer of that form.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "But people, so we take a certain you OK and then we add organizer.",
                    "label": 0
                },
                {
                    "sent": "Things become the functions become strongly convex and life is much easier.",
                    "label": 0
                },
                {
                    "sent": "Keep in mind that when you do this, you do add a bias.",
                    "label": 0
                },
                {
                    "sent": "OK, you'll get our eyes, you don't optimize the guard function.",
                    "label": 0
                },
                {
                    "sent": "So if you want to predictions after adding these to be as good as when you didn't have that term, you need you to go to zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so in a sense you need mutebi large for optimizing, but you didn't need to be small for statistics.",
                    "label": 0
                },
                {
                    "sent": "There is clearly a tradeoff and you really have to be careful when you say problems are strongly convex.",
                    "label": 0
                },
                {
                    "sent": "So one of the main message of the talk is to get rid of that strong convexity altogether.",
                    "label": 0
                },
                {
                    "sent": "So little bit overview, unlike simple techniques to do a convex optimization, so I would assume GS convex and smooth, and there are two main algorithms and of course there are much better now.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But here we consider garden dissent where you interact iterative algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, let's go where you go from 1030 -- 1 two 30 by going down the direction of the negative radians, but you're going to show it at here.",
                    "label": 0
                },
                {
                    "sent": "The concept of time complexity is what makes the algorithm fast or slow.",
                    "label": 0
                },
                {
                    "sent": "This is the exact same algorithm, but if the problem happens to be strongly convex, you get this linear convergence rate.",
                    "label": 1
                },
                {
                    "sent": "So at every time step you cut down the error by a certain amount.",
                    "label": 0
                },
                {
                    "sent": "While if you just convex, so not strongly convex, you only converted height for novelty.",
                    "label": 0
                },
                {
                    "sent": "This is quite slow 'cause if you want to get like a precision of 10s of minor three, so you get once you need to have at least 1000 iterations.",
                    "label": 0
                },
                {
                    "sent": "So here the important aspect here is that strong convexity lack is will dictate the complexity of your of your problem.",
                    "label": 0
                },
                {
                    "sent": "I just mentioned Newton method here because I'm going to use it later, so typically in a large data set up when P is very large.",
                    "label": 0
                },
                {
                    "sent": "Z student step, which we simply rescaled gradient by the Haitian, cannot be around because it's it requires metric conversion.",
                    "label": 0
                },
                {
                    "sent": "But if you were able to do it then we get like quality convergence rate.",
                    "label": 0
                },
                {
                    "sent": "So you can get easily to arbitrary precision.",
                    "label": 0
                },
                {
                    "sent": "So here one of the key insights by Limbo two and early Bousquet is that in the context of machine learning we don't have to solve problems up to measure precisions.",
                    "label": 1
                },
                {
                    "sent": "Machine learning is not any context problem.",
                    "label": 0
                },
                {
                    "sent": "The first one is.",
                    "label": 0
                },
                {
                    "sent": "Since I work as functions of averages, there is this natural variations of one over root N. On there, there mean so trained to go below that is kind of useless because you start to optimize something which has no significance.",
                    "label": 0
                },
                {
                    "sent": "And finally so low precision.",
                    "label": 0
                },
                {
                    "sent": "Finally, our cost functions are averages.",
                    "label": 1
                },
                {
                    "sent": "OK, so maybe we can take this.",
                    "label": 0
                },
                {
                    "sent": "You can take this into account to get better algorithms, and it's essentially the topic of stochastic approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is statistic approximation?",
                    "label": 0
                },
                {
                    "sent": "So is the goal here so defined to minimize the function F?",
                    "label": 0
                },
                {
                    "sent": "So this would be convex will be an RP for simple for simplicity.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we only observe F, not sweet gradients.",
                    "label": 0
                },
                {
                    "sent": "So if you knew the gradients could look like a decent, but only through a noisy version of those gradients, and I will call F prime N of the time the noisy version of F prime of data in which is a true gradient.",
                    "label": 0
                },
                {
                    "sent": "So this has been looked at a lot in the signal processing community since the 50s.",
                    "label": 0
                },
                {
                    "sent": "Typically assumptions of that form that the observer gradient is a gradient plus some additive noise.",
                    "label": 0
                },
                {
                    "sent": "And this was done with on a lot of problems not only on minimizing convex functions, and there's a long long literature, and which is a reference in the at the end of the slides.",
                    "label": 0
                },
                {
                    "sent": "In the context of machine learning, we don't have this additive noise, but we have something which is a bit more specific, so here I will.",
                    "label": 1
                },
                {
                    "sent": "Each of my noisy gradient will come from a single data point.",
                    "label": 0
                },
                {
                    "sent": "OK, so here the function I'm going to minimize F is a true generalization error, which I caught up Sir.",
                    "label": 0
                },
                {
                    "sent": "OK, so F of data will be the expected value of the loss of an unseen data point, so this I cannot observe.",
                    "label": 0
                },
                {
                    "sent": "But what I can observe?",
                    "label": 0
                },
                {
                    "sent": "Is a loss and is gradient under a single data point.",
                    "label": 1
                },
                {
                    "sent": "OK, so FN this will be my function which I observe at at time N is allowed between the label YN as the input X Ann, just taking the expectation under David differentiating under the expectation the expected value of the gradient of the gradient.",
                    "label": 0
                },
                {
                    "sent": "This is a gradient with respect to Theta of a single loss.",
                    "label": 0
                },
                {
                    "sent": "Then the expected value of this one is the expected the.",
                    "label": 0
                },
                {
                    "sent": "Gradient of the true true generalization error.",
                    "label": 1
                },
                {
                    "sent": "So here we are in the set up where the gradient of a single data point is an unbiased estimate of the true.",
                    "label": 0
                },
                {
                    "sent": "OK, so now what would be the algorithms so there be two kind of a 2 main assumptions.",
                    "label": 0
                },
                {
                    "sent": "Strong convexity or lack thereof and smoothness, so the Kia.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Rhythm game from the 50s.",
                    "label": 0
                },
                {
                    "sent": "Robbins Monro is essentially stochastic gradient descent, where at at time N. So here there's a small subtlety.",
                    "label": 1
                },
                {
                    "sent": "So here in the context of stochastic approximation, the number of iterations is exactly the number of observed data points.",
                    "label": 0
                },
                {
                    "sent": "That's why I use NT use any here and not T OK, every time you see a point, you compute the gradient with respect to your parameter to current iterated AD minus one and you go down the direction of this of this of this graduate with a certain step size gonna end.",
                    "label": 0
                },
                {
                    "sent": "So this is this can be so people also consider this so called project Supercharging where at the end of the optimization you take the average of all iterates.",
                    "label": 0
                },
                {
                    "sent": "So this is simply post processing of the iterates, so of course if you want to implement this online, it's only one line, one line of code.",
                    "label": 0
                },
                {
                    "sent": "Then the key question now is what?",
                    "label": 0
                },
                {
                    "sent": "What should gamma in be OK so good man is often called the learning rate sequence and people typically issues typically choose gamma end of the form C / N to the Alpha and the key elements are what you see.",
                    "label": 1
                },
                {
                    "sent": "What is Alpha?",
                    "label": 0
                },
                {
                    "sent": "So there's been a lot of work on that on that simple problem.",
                    "label": 0
                },
                {
                    "sent": "An essentially people have found like both like upper bounds and lower bounds or complexity, which you cannot beat socially.",
                    "label": 0
                },
                {
                    "sent": "This was done by Nemerofsky nude in the 80s.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for nonsmooth optimization, so it is really, really important here.",
                    "label": 1
                },
                {
                    "sent": "All those lower bounds only valid for nonsmooth optimization.",
                    "label": 1
                },
                {
                    "sent": "Then they have shown that if the problem happens to be strongly convex, then the best you can do is one of RMU in terms of convergence rates.",
                    "label": 1
                },
                {
                    "sent": "So here to be explicit, its occurrence rate of the function values to the optimal function value, and this is achieved by average stochastic agency sent with a certain step size, and for non chronic connect function you are slower.",
                    "label": 0
                },
                {
                    "sent": "This is looking like the classical deterministic setting where when you have when you don't have strong convexity, you go a bit slower and you go from one of our end to one of the root N. And this is also achieved with stochastic descent and were edged with the different step size.",
                    "label": 0
                },
                {
                    "sent": "OK, so this this tells you that you cannot.",
                    "label": 0
                },
                {
                    "sent": "You cannot beat this if if you want.",
                    "label": 0
                },
                {
                    "sent": "If you want to work with non smooth function.",
                    "label": 0
                },
                {
                    "sent": "So another set of result by OK and this.",
                    "label": 0
                },
                {
                    "sent": "They had a lot of work trying to do this and to improve on this and I drive to cite everybody in the home and this is not the goal of today.",
                    "label": 0
                },
                {
                    "sent": "If you want to know more, you can look at all of these papers.",
                    "label": 0
                },
                {
                    "sent": "Particular for extensions two beyond that, if you want to do positive, for example, you have nice paperback.",
                    "label": 0
                },
                {
                    "sent": "So do Gene and others to adapt the framework to L1 type problems.",
                    "label": 0
                },
                {
                    "sent": "But what I want to fuck.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So nice, well, bipolar can do this key and the whole part, which is of a different nature.",
                    "label": 0
                },
                {
                    "sent": "OK, So what they show is that for smooth problem, if you do have a raging and you take any step size of that form, OK, so between one of the road N and 1 / N then first only convex problem you get this one over and convergence rate OK.",
                    "label": 1
                },
                {
                    "sent": "So essentially, if you're willing to assume smoothness then you have then do a Virgin.",
                    "label": 0
                },
                {
                    "sent": "You have a wide range of step sizes whereas for the non smooth.",
                    "label": 0
                },
                {
                    "sent": "Problems you have to.",
                    "label": 0
                },
                {
                    "sent": "You need to have a few 20 convex.",
                    "label": 0
                },
                {
                    "sent": "You need to have a small step size and it will not only convex.",
                    "label": 0
                },
                {
                    "sent": "You have to have large step side.",
                    "label": 0
                },
                {
                    "sent": "The first question is, is it possible to get around this?",
                    "label": 1
                },
                {
                    "sent": "Having two step sizes for the two situations?",
                    "label": 1
                },
                {
                    "sent": "Remember gradient descent was adaptive in the sense that the exact same algorithm was used, and depending on your chance, or depending on the weather function, is convex or not.",
                    "label": 0
                },
                {
                    "sent": "Even if you don't, even if you don't know it in advance, it will adapt to it.",
                    "label": 0
                },
                {
                    "sent": "Those set of results do not say this.",
                    "label": 0
                },
                {
                    "sent": "For this you need to know you need to do it in advance.",
                    "label": 0
                },
                {
                    "sent": "If you're going to disconnect or not.",
                    "label": 0
                },
                {
                    "sent": "So the first question is, is it possible to get a single algorithm?",
                    "label": 1
                },
                {
                    "sent": "Which will be adaptive in the sense that you don't need to tell to tell it what is mu OK and we try to adapt to the best possible value of mu.",
                    "label": 0
                },
                {
                    "sent": "OK, and this if you take this, of course you want to.",
                    "label": 0
                },
                {
                    "sent": "The hint is.",
                    "label": 0
                },
                {
                    "sent": "If you take gamma and being see over Hood N OK, they need to combine this guy and this guy.",
                    "label": 0
                },
                {
                    "sent": "You should get what you want.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's essentially just a warm up for the later part of the talk.",
                    "label": 0
                },
                {
                    "sent": "So what this is this is going to be down for law.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mystical Russian OK, so discussion is a subcase of the supervised learning problem with labels are in minus one one and the loss is of that form log of 1 plus an exponential and again the goal is not to minimize or training error, but the goal is to minimize the expectation which in which which you never observe.",
                    "label": 0
                },
                {
                    "sent": "So first thing, if you if you play with logistic regression, it cannot be scrawny, convex.",
                    "label": 1
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because this is a logistic loss load of 1 plus exponential minus U and this dense to have flat paths at the community.",
                    "label": 1
                },
                {
                    "sent": "So if you want to be strongly convex, you have to restrict the first solution is to restrict the domain to be compact, but then you introduce constants of the form exponential M. So what we're going to do here will be to redefine you not as a global.",
                    "label": 0
                },
                {
                    "sent": "Tonka Mystic on stunt not so the global tranquility constant is the minimal lower lower second values overall Hessians at every point.",
                    "label": 0
                },
                {
                    "sent": "I'm going to replace this by simply the lowest I can value at the optimum.",
                    "label": 1
                },
                {
                    "sent": "OK so local notion of some convexity mubi this lowest again value.",
                    "label": 0
                },
                {
                    "sent": "So what I've shown is that if you take.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Step side of the from one of her hood end.",
                    "label": 0
                },
                {
                    "sent": "So here there's more subtlety in that when you play with to get visa optimization techniques, you have two types of techniques, the ones that are anytime OK that will put the resort at anytime and once for which you know the horizon in advance and you choose.",
                    "label": 0
                },
                {
                    "sent": "I'm going to run an iterations and able to choose a step size accordingly.",
                    "label": 0
                },
                {
                    "sent": "Typically the two tend to works question early, so here.",
                    "label": 0
                },
                {
                    "sent": "But for simplicity of the result and consider the constant steps up with an owner eyes and and the constant step size does depend on the horizon of the form.",
                    "label": 0
                },
                {
                    "sent": "Wonderful would end.",
                    "label": 0
                },
                {
                    "sent": "So what what are shown is that if they expected value.",
                    "label": 0
                },
                {
                    "sent": "So here while you random random because your your data are random, so this expectation is over the data of the average value minus the best possible value test are, which I assumed to exist, will be bounded by what Bible constant times?",
                    "label": 0
                },
                {
                    "sent": "Something which is a minimum of the two regimes.",
                    "label": 0
                },
                {
                    "sent": "This easy not only collects regime.",
                    "label": 0
                },
                {
                    "sent": "Whenever would N OK this see the strongly convex regime 1 / M U so the same algorithm which does not does not need to know the strong commodity constant can adapt to it if mu is large enough.",
                    "label": 0
                },
                {
                    "sent": "One instance of an adaptive algorithm lag gradient descent guidance adaptive in the in the deterministic setup, and this is the case as well if you take stochastic agent isn't.",
                    "label": 0
                },
                {
                    "sent": "So here we don't provide anything new in terms of algorithms.",
                    "label": 0
                },
                {
                    "sent": "We just take the existing one stochastically, dissent and say that it works as well as we expect.",
                    "label": 0
                },
                {
                    "sent": "So for the experts, the proof is based on several gardens or generalized version.",
                    "label": 0
                },
                {
                    "sent": "OK, now let's get down to the the meat of the talk, which is trained to go beyond this this problem.",
                    "label": 0
                },
                {
                    "sent": "So here still I have this problem that depending whether new is bigger, a big, big or not I get 1 / 10 or one of our end.",
                    "label": 0
                },
                {
                    "sent": "So the goal now is try to get rid of this and get rid of you.",
                    "label": 0
                },
                {
                    "sent": "OK so you get always 1 / N independently or the problem Yep.",
                    "label": 0
                },
                {
                    "sent": "The true you.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this mu.",
                    "label": 0
                },
                {
                    "sent": "So this is really important to be adaptive to a newbie, 'cause if you happen to be lucky you can go super fast.",
                    "label": 0
                },
                {
                    "sent": "So typically if you add like if you if you impose new for example by adding or squared L2 norm then you do have 'em you.",
                    "label": 0
                },
                {
                    "sent": "But often your menu is much nicer because you happen to have like.",
                    "label": 0
                },
                {
                    "sent": "Close to the optimum you happen to have the more clever than you think, so it's really important for method to be adaptive to the unknown value of new.",
                    "label": 0
                },
                {
                    "sent": "OK, so before.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going further, let's step back a little and consider even a simpler problem, which is the least squares.",
                    "label": 0
                },
                {
                    "sent": "OK, so for least squares essentially same setup.",
                    "label": 0
                },
                {
                    "sent": "I have a response by end.",
                    "label": 0
                },
                {
                    "sent": "This is my prediction and the goal is to minimize the square loss.",
                    "label": 0
                },
                {
                    "sent": "OK, nothing really really different.",
                    "label": 0
                },
                {
                    "sent": "Now stick it in.",
                    "label": 0
                },
                {
                    "sent": "The dissent is often called the least mean square algorithm LMS and typically this has been studied a lot in single processing and typically without averaging and with a certain decreasing step size is.",
                    "label": 1
                },
                {
                    "sent": "Moreover, it has been studied mostly in cases where the covariance matrix is invertible, so it might set up.",
                    "label": 0
                },
                {
                    "sent": "It has been analyzed for strongly convex problems, So what what we have done with Eric Moline is first to try to do it for the constant step size.",
                    "label": 0
                },
                {
                    "sent": "So here it's really a constant step size and you make some assumptions like bonded data and bonded bonded noise and the key element is that we make new assumptions on the lowest eigenvalues of H and what we obtain is that the.",
                    "label": 1
                },
                {
                    "sent": "The expected value of the average iterate.",
                    "label": 0
                },
                {
                    "sent": "OK, so here again, this is expectation of other data is less than, so one other end.",
                    "label": 0
                },
                {
                    "sent": "OK, this was the goal is to remove one of the Lieutenant to remove the one over mu times a constant OK and this one for those familiar with statistics.",
                    "label": 1
                },
                {
                    "sent": "If Texas Square you get Signal square PRN.",
                    "label": 0
                },
                {
                    "sent": "So this is known to be the lower bound of statistical estimation.",
                    "label": 0
                },
                {
                    "sent": "So namely, that for least squares, even with no computational limits, you cannot beat similar square P / N. And we can achieve it just by a simple single path through the data.",
                    "label": 0
                },
                {
                    "sent": "And again with not a new algorithm is missing most of the orders algorithm for stochastic approximation suggest elements.",
                    "label": 0
                },
                {
                    "sent": "So the novelty here is really to use this constant step size.",
                    "label": 0
                },
                {
                    "sent": "And having a custom step size allows us to get nice interpretation.",
                    "label": 0
                },
                {
                    "sent": "OK, which is the following.",
                    "label": 0
                },
                {
                    "sent": "So he suggested recursion OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a loss for a data point.",
                    "label": 0
                },
                {
                    "sent": "Is is your cash and Italian and the key aspect that since you step size is constant, OK, this defines a Markov chain and emotional smacker chain at every time step, so that mix is always the same.",
                    "label": 0
                },
                {
                    "sent": "OK, so since you have a Markov chain and weak assumptions, it will converge to a stationary distribution Pi of gamma.",
                    "label": 1
                },
                {
                    "sent": "So it depend on gamma, because depending on the dynamics depend on gamma as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so since you converge to a stationary distribution?",
                    "label": 0
                },
                {
                    "sent": "And I've been called Theater of Gamma the expectation, and there's a special that stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "So the key aspect is that for least squares.",
                    "label": 0
                },
                {
                    "sent": "This expected value, whatever gamma is, is always the optimal value of your problem.",
                    "label": 0
                },
                {
                    "sent": "OK, simply, you can simply check this.",
                    "label": 0
                },
                {
                    "sent": "So what this means is that if you consider the constant stepsize LMS, it will not converge to test our why?",
                    "label": 0
                },
                {
                    "sent": "Because it's a Markov chain and then data will end up being like distributed according to Pi of Gamma.",
                    "label": 0
                },
                {
                    "sent": "So you oscillate around the truth and what you could ensure that those orders code of gamma.",
                    "label": 0
                },
                {
                    "sent": "But now it seems you have a Mac of chain and you know the expected value of the stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "You know that.",
                    "label": 0
                },
                {
                    "sent": "The theorem of course I put no assumptions here, but this is just for the idea that if the other edge of the interes they do convert with the expectation and the rate at which it converges, wanna vote N in terms of distance.",
                    "label": 0
                },
                {
                    "sent": "So one of our end in terms of square distance.",
                    "label": 0
                },
                {
                    "sent": "OK so here is the fact that we have backup chain allowed us almost immediately to to get this one over and convergence rate and then we simply have to put like numbers behind it just to verify this intuition.",
                    "label": 0
                },
                {
                    "sent": "So just to give an example, so C.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do you like Pickles 20?",
                    "label": 0
                },
                {
                    "sent": "Just gotten distributions and I've run so gradually stochastically descent with a constant step size with similar constraints and also with the decaying step size over there, and I've consider in the plane.",
                    "label": 0
                },
                {
                    "sent": "This is the average version and in the dash this is the non average version.",
                    "label": 0
                },
                {
                    "sent": "So what you can see is that if you don't have user edging, you don't converge.",
                    "label": 0
                },
                {
                    "sent": "So here this is N in the log scale and they see the distance to optimum in log scale.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "If you do, if you can step study, don't do everything.",
                    "label": 0
                },
                {
                    "sent": "You don't converge OK, you will see later on the optimum an you don't converge and if you lower the constant you do get get lower value.",
                    "label": 0
                },
                {
                    "sent": "And if you're really really careful, the width between those two is exactly log 10 or four.",
                    "label": 0
                },
                {
                    "sent": "OK, so this just confirm confirm the fact that the distance to optimum tends to be of order gamma.",
                    "label": 0
                },
                {
                    "sent": "And as soon as diverging up then you do converge.",
                    "label": 0
                },
                {
                    "sent": "So you do get to manage to do just go go lower and lower.",
                    "label": 0
                },
                {
                    "sent": "And if you check also the the slope, here is one is 1.",
                    "label": 0
                },
                {
                    "sent": "OK so you get convergence right at one of right one of our end.",
                    "label": 0
                },
                {
                    "sent": "If you want to do this square roots thing, then the iterates do converge.",
                    "label": 0
                },
                {
                    "sent": "OK, add height 1 one over root N and when you do everything you also do converge, but at a slower rate.",
                    "label": 0
                },
                {
                    "sent": "OK, so here the key aspect is really the fact that if you don't do a Virgin you don't converge.",
                    "label": 0
                },
                {
                    "sent": "OK, that's OK because when you do everything you restore convergence OK, so this is the main thing for squalus.",
                    "label": 0
                },
                {
                    "sent": "So now let's go to.",
                    "label": 0
                },
                {
                    "sent": "Oh, then you have other simulations.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, on more like bigger that I said.",
                    "label": 0
                },
                {
                    "sent": "So this is classical benchmarks.",
                    "label": 0
                },
                {
                    "sent": "With like moderately large dimensions or large large people, this is a sparse data set.",
                    "label": 0
                },
                {
                    "sent": "OK, so here I compare 2 three algorithms, constant stepsize, decaying step size, one of oil algorithms, and here left and right.",
                    "label": 0
                },
                {
                    "sent": "Very important is left.",
                    "label": 0
                },
                {
                    "sent": "I took the constant which is given by the algorithms.",
                    "label": 0
                },
                {
                    "sent": "So by the proof.",
                    "label": 0
                },
                {
                    "sent": "OK, typically this is not the good constants.",
                    "label": 0
                },
                {
                    "sent": "You can always be a lot faster by increasing the constant and.",
                    "label": 0
                },
                {
                    "sent": "This on the right side have optimized the constant to get better convergence.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first thing is that the constant step size and we have many more plots in the paper.",
                    "label": 0
                },
                {
                    "sent": "The constant step size or in blue is not very sensitive to that sort of step size in the sense that the step size from the bound is not terrible, whereas if you take like one over root N, then if you take the steps of the band it goes very slow and if you start to optimize the concern to get good coverage, that good convergence at the end.",
                    "label": 0
                },
                {
                    "sent": "You start to explode at the beginning.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is classical behavior of one other would end step size.",
                    "label": 0
                },
                {
                    "sent": "You have to taxi so big to get a good good convergent at the end that you start by diverging.",
                    "label": 0
                },
                {
                    "sent": "OK, let's go back to non non least squares.",
                    "label": 0
                },
                {
                    "sent": "OK so we can try to follow the same Markov chain interpretation.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have this immigration since gamma is constant, you still get a Markov chain or merger news Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So under weak assumptions it also converges to a stationary distribution Pi of gamma.",
                    "label": 0
                },
                {
                    "sent": "I will pay off gamma and what you can show it that that distribution is defined so that the average of the gradient over the distribution is 0.",
                    "label": 0
                },
                {
                    "sent": "But the problem now is what that when F is is not quadratic.",
                    "label": 1
                },
                {
                    "sent": "If crime is not now and this is not, then the gradient of the expectation is not the expectation of the gradient.",
                    "label": 0
                },
                {
                    "sent": "OK, so this means that data data of gamma, which is the average of the stationary distribution, is not the optimal value.",
                    "label": 0
                },
                {
                    "sent": "So you still oscillate OK, but around the wrong value.",
                    "label": 1
                },
                {
                    "sent": "OK, and what you could ensure that these other situations are bonded of state of order, one of with gamma.",
                    "label": 0
                },
                {
                    "sent": "But the problem is the following.",
                    "label": 0
                },
                {
                    "sent": "Now if you do a village in with the same negative serum, use converge to data of gamma, which is not the test are OK and what you convert at a fast rate.",
                    "label": 0
                },
                {
                    "sent": "It is wrong to the wrong value and what you can show that by doing a village Inn.",
                    "label": 0
                },
                {
                    "sent": "You go from square root of gamma.",
                    "label": 0
                },
                {
                    "sent": "OK two together.",
                    "label": 0
                },
                {
                    "sent": "So you do improve the distance, but still you still getting away from the optimal value so we can see this in the same simulation as before.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're simply replace the square loss by the logistics loss.",
                    "label": 0
                },
                {
                    "sent": "So again, in plain this is averaged in.",
                    "label": 0
                },
                {
                    "sent": "Dottie, this is another edged, so those curves are essentially the same.",
                    "label": 0
                },
                {
                    "sent": "So if you don't do apology, you don't converge anyway, neither to test our North route agoma.",
                    "label": 0
                },
                {
                    "sent": "And when you start to do another gene then you do converge OK, but to something which is not the correct one.",
                    "label": 0
                },
                {
                    "sent": "OK so if you have a large constant OK then you convert to something which is.",
                    "label": 0
                },
                {
                    "sent": "You converse quickly to something which is not really good and if you lower the constant go from one over to one of our eight then you converge bit slower to something which is a bit better and you take one of our 32 also get even lower.",
                    "label": 0
                },
                {
                    "sent": "So for the if you really look carefully and if you had like a bit more.",
                    "label": 0
                },
                {
                    "sent": "If the plug was going a bit a bit longer.",
                    "label": 0
                },
                {
                    "sent": "Longer then is the distance between those two is twice this time between those two.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just a hint that the distance is of the order of other guys gonna square, so the goal is to do what is trying to avoid this.",
                    "label": 0
                },
                {
                    "sent": "OK, you want to be like we had for the square loss which is to know convergence when you don't do averaging but convergence the true value.",
                    "label": 0
                },
                {
                    "sent": "But you do eventually.",
                    "label": 0
                },
                {
                    "sent": "Is this for this going to do online?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you turn steps.",
                    "label": 0
                },
                {
                    "sent": "So what is it you do instead?",
                    "label": 0
                },
                {
                    "sent": "OK, so let's consider a certain title field.",
                    "label": 0
                },
                {
                    "sent": "OK, so we fix a point and we want to do Newton step with respect to this F, which is the which is the generalization error.",
                    "label": 0
                },
                {
                    "sent": "But you cannot observe.",
                    "label": 0
                },
                {
                    "sent": "So here again we want to do and you don't step on something which we don't observe.",
                    "label": 0
                },
                {
                    "sent": "And of course your step is just minimizing the local Taylor expansion at detailed, which I've written here.",
                    "label": 0
                },
                {
                    "sent": "So G of Theta get a constant term linear term aquatic term with the key aspect here is that all of those are expectations.",
                    "label": 0
                },
                {
                    "sent": "OK, expedited is the expected value of F prime N something for four days and so now you can put can put the can put the hash and the expectation outside and know what you have to solve you to step.",
                    "label": 0
                },
                {
                    "sent": "You have to do what you have to minimize the expectation of aquatic function.",
                    "label": 0
                },
                {
                    "sent": "So now what we're going to do is simple to use like least mean square with constant step size to solve that guy.",
                    "label": 0
                },
                {
                    "sent": "OK so that guy is a Newton step which we can so efficiently.",
                    "label": 1
                },
                {
                    "sent": "OK, so now we're going to do this.",
                    "label": 0
                },
                {
                    "sent": "So this is the key to the other key aspects.",
                    "label": 0
                },
                {
                    "sent": "So this time I returned the LMS algorithm for that guy.",
                    "label": 0
                },
                {
                    "sent": "So I just compute the gradient of this, which is over there and I go down the direction of the negative gradient.",
                    "label": 0
                },
                {
                    "sent": "But the key aspect here is that we do Newton step, but we never have to computer any Haitian.",
                    "label": 0
                },
                {
                    "sent": "OK, so the only thing that we compute is the one associated to a single data point, but since our last function OK is a projection of.",
                    "label": 0
                },
                {
                    "sent": "The feature vector that has senior has rank one, so we never have to actually compute any questions and at the end the complexity of these online you can step is just twice the one of the regular stochastic legend decent.",
                    "label": 1
                },
                {
                    "sent": "Why it?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Is because we have to.",
                    "label": 0
                },
                {
                    "sent": "We have to do two.",
                    "label": 0
                },
                {
                    "sent": "We have to do predictions one.",
                    "label": 0
                },
                {
                    "sent": "OK, so at the end what we need to do, we're going to solve it directly.",
                    "label": 0
                },
                {
                    "sent": "Newton steps.",
                    "label": 0
                },
                {
                    "sent": "OK, so we should deliberately not optimize the function directly, but since we can do this into the step efficiently at the end we end up with better convergence.",
                    "label": 0
                },
                {
                    "sent": "So of course the key is a key issue is what what would be the point of Newton step?",
                    "label": 0
                },
                {
                    "sent": "So now we have two strategy.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is which are?",
                    "label": 0
                },
                {
                    "sent": "It's a bit unfortunate this classical when you do a bit of Siri, the one for which you can prove stuff and the one which is working better.",
                    "label": 0
                },
                {
                    "sent": "OK, so the one for which we can prove things is really strategy where you first do a certain number of steps of regular stochastic descent to get something which is good enough and then run single didn't step using LMS and for this one which is reminiscent of one step estimator.",
                    "label": 0
                },
                {
                    "sent": "So you can show that esentially.",
                    "label": 0
                },
                {
                    "sent": "The government is all of PRN.",
                    "label": 0
                },
                {
                    "sent": "OK, so for logistic regression.",
                    "label": 1
                },
                {
                    "sent": "So here again I'm putting a lot of things under the rug in particular in the in the in the bigger, the bigger, but at the end the key aspect is that we are able to avoid any assumption on the strong convexity of the problem.",
                    "label": 1
                },
                {
                    "sent": "We get one of our end convergence rate for any possible.",
                    "label": 0
                },
                {
                    "sent": "Problems whether it is 20 Contacts or not.",
                    "label": 0
                },
                {
                    "sent": "But you see.",
                    "label": 0
                },
                {
                    "sent": "So this is 1, which is a for which we have approved.",
                    "label": 0
                },
                {
                    "sent": "But the one which is really working better in practice is the one where.",
                    "label": 0
                },
                {
                    "sent": "So we change the support point of the Newton step at every iteration, and we use essentially the current average iterate.",
                    "label": 1
                },
                {
                    "sent": "OK, so here at every time step I take the current average value, get above 8 -- 1 and I do.",
                    "label": 0
                },
                {
                    "sent": "The linear expansion of the gradient around that died minus one, so this is a constant term for today at about 10 minutes wanted.",
                    "label": 0
                },
                {
                    "sent": "See the linear term and we just go down this direction this direction.",
                    "label": 0
                },
                {
                    "sent": "This is one line of code and we currently have no proof, but one of our students have found a proof and you should get too.",
                    "label": 0
                },
                {
                    "sent": "So you should also get this one of our conscious right.",
                    "label": 0
                },
                {
                    "sent": "The notice look in terms of simulations.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the same problem as before.",
                    "label": 0
                },
                {
                    "sent": "OK, synthetic data and this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Was a console step size with the averaging leveling off.",
                    "label": 0
                },
                {
                    "sent": "At one point he I consider several Newton Newton Newton schemes.",
                    "label": 0
                },
                {
                    "sent": "So in red this is one for which I have a proof.",
                    "label": 0
                },
                {
                    "sent": "OK, so I first do so this is NI first to enable disable 2 steps of stochastic descent and then I start constant stepsize LMS.",
                    "label": 0
                },
                {
                    "sent": "So one of the key to bugs or feature of constants at Ms.",
                    "label": 0
                },
                {
                    "sent": "It's very it's very noisy in the sense that.",
                    "label": 0
                },
                {
                    "sent": "If when you start LMS, even if you start from the truth is going to oscillate.",
                    "label": 0
                },
                {
                    "sent": "OK, so here when you start here and you start to do constant stepsize LMS, you start to oscillate a lot.",
                    "label": 0
                },
                {
                    "sent": "That's why you have a jump about them, so clearly this is not a good algorithm to do today in practice.",
                    "label": 0
                },
                {
                    "sent": "So what we have done also is to consider doubling strategy, which is very common in optimization where you run this scheme for to the steps OK and then this will allow you to restart for the next batch of.",
                    "label": 0
                },
                {
                    "sent": "Twice to the same size as you.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a joke was and if you take this simple like Newton scheme, where is this a real bird or phone?",
                    "label": 0
                },
                {
                    "sent": "Is another one.",
                    "label": 0
                },
                {
                    "sent": "Wow OK good.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and here in green and blue those are the two curves are on top of each other.",
                    "label": 0
                },
                {
                    "sent": "This is a scheme where we update the support points for the Newton step at every iteration and you get this one of our end commitments.",
                    "label": 0
                },
                {
                    "sent": "So this can be done as well for.",
                    "label": 0
                },
                {
                    "sent": "The benchmarks and more curves and I want to go into it, but at the end with this phone number and business Newton scheme you are able to be robust to the lack of strong convexity and I won't want to go into the details here 'cause I don't have so much time.",
                    "label": 0
                },
                {
                    "sent": "OK, so this was.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first super smoothness, so here.",
                    "label": 0
                },
                {
                    "sent": "Clearly we need we need to be smooth to be able to do to do all this and we were able to essentially escaped this one over root N low amount for certain problems.",
                    "label": 0
                },
                {
                    "sent": "OK, this is for just logistic regression and not all convex functions.",
                    "label": 1
                },
                {
                    "sent": "Low is good with different aspect for just five minutes.",
                    "label": 0
                },
                {
                    "sent": "Which is what people do.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Practice OK, often when the other things which are presented.",
                    "label": 0
                },
                {
                    "sent": "The number of iterations with exactly the number of observations.",
                    "label": 0
                },
                {
                    "sent": "OK, so this essentially assume that you have.",
                    "label": 0
                },
                {
                    "sent": "You see that the points only once, and of course the benefit of all this is that you don't have to deal with overfitting.",
                    "label": 0
                },
                {
                    "sent": "OK, just see that at points one and you end up optimizing directly the testing cost.",
                    "label": 1
                },
                {
                    "sent": "However, in practice, people had a father said and people tend to make several passes 'cause it always works better.",
                    "label": 0
                },
                {
                    "sent": "OK then yes, but as soon as you make 2 passes then you may start to overfit.",
                    "label": 0
                },
                {
                    "sent": "So two is OK, but three maybe not four, and then you're you have the problem of knowing where to stop, OK?",
                    "label": 0
                },
                {
                    "sent": "So I don't know, but we're going to do is exactly this way to see to study the situation where you do multiple passes through the data.",
                    "label": 1
                },
                {
                    "sent": "And now if you start to do multiple passes, you end up minimizing the training costs.",
                    "label": 0
                },
                {
                    "sent": "OK, no, you don't need my this, but this.",
                    "label": 0
                },
                {
                    "sent": "So now you have to go back to classical statistics where you have to add regularizer to avoid overfitting.",
                    "label": 1
                },
                {
                    "sent": "Typically typically there to know.",
                    "label": 0
                },
                {
                    "sent": "So here what I'm going to present it will be.",
                    "label": 1
                },
                {
                    "sent": "I will try to minimize another edge of functions like this.",
                    "label": 0
                },
                {
                    "sent": "OK, and typically this will be the loss over the ice data point.",
                    "label": 0
                },
                {
                    "sent": "So we have seen Twitter rhythms.",
                    "label": 0
                },
                {
                    "sent": "We have seen gradient descent OK, so this is simply you go down the negative gradient.",
                    "label": 0
                },
                {
                    "sent": "So if we assume convexity, the governor's height is there is a.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is good because it's exponential convergence rate, but every iteration you have to compute the old regions of all functions.",
                    "label": 1
                },
                {
                    "sent": "OK, so it's complicated.",
                    "label": 0
                },
                {
                    "sent": "So essentially you make you make.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A small number of big steps.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, so basically the dissent OK, so here we select one element at Honda and from from my training data OK and I copied these only gradient and I go down this gradient.",
                    "label": 0
                },
                {
                    "sent": "This is essentially stochastic.",
                    "label": 0
                },
                {
                    "sent": "Don't descend on a finite amount of data.",
                    "label": 0
                },
                {
                    "sent": "So here of course every iterations of 1 by design, but now the computer's height is all of University.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now what you have is.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many directions which are cheaper for who.",
                    "label": 0
                },
                {
                    "sent": "Here of course, the goal is to get the best of both worlds, as this will be the stochastic.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Don't be the last slider on it, so this was just well with Nicola Nicola Luann Mark Smith, so we're going to do exactly like stochastic dissent going to follow to select at every iteration.",
                    "label": 0
                },
                {
                    "sent": "Function computed gradient OK, but what we're going to do is to store all graduates of all functions, so every time I see a gradient, OK. Then I compute it and I keep it so that every time step in my algorithm OK, I've stored versions of gradients, some of them are very old and some of them are very new.",
                    "label": 1
                },
                {
                    "sent": "OK, so here Huawei ID is stored version already and I at time T, so when I did I update it by not changing anything except for the gradient which I've observed.",
                    "label": 1
                },
                {
                    "sent": "But now since I have versions of all my gradients, I can take the other edge OK and go down the average gradient.",
                    "label": 0
                },
                {
                    "sent": "So here this is not a new algorithm.",
                    "label": 1
                },
                {
                    "sent": "OK, this essentially algorithm of blood it all OK with one small modification, which is the way we select the gradients.",
                    "label": 0
                },
                {
                    "sent": "Those are functions, So what we're doing is simply cycling through the data OK, whereas in our case we just do random selection.",
                    "label": 0
                },
                {
                    "sent": "In fact, to be perfectly honest, our goal was simply to analyze their method because of an analyzing organizations easier than analyzing cycling.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that you can be.",
                    "label": 0
                },
                {
                    "sent": "So much faster.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you want to know more concussive paper, but by going from cycling to organizing you can make bigger steps and to achieve bigger convergence rate.",
                    "label": 0
                },
                {
                    "sent": "So for the people we think that's doing gradients is a problem.",
                    "label": 1
                },
                {
                    "sent": "It is a problem, but in the context of machine learning, since the gradients since the functions rank one projections, the gradients are proportional to the feature vector.",
                    "label": 0
                },
                {
                    "sent": "So you have to store only a single single cell number.",
                    "label": 0
                },
                {
                    "sent": "This in terms of convergence rate, we were able to show that details and important that we have a linear convergence rate for that problem OK?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So typically the covenant is 1 / T for that.",
                    "label": 0
                },
                {
                    "sent": "For that.",
                    "label": 0
                },
                {
                    "sent": "For those type of problem you do successfully sent.",
                    "label": 0
                },
                {
                    "sent": "But here with integration costs which is independent of the number of examples were able to get a linear convergence rate which was not possible before.",
                    "label": 0
                },
                {
                    "sent": "Of course it works well, but that's not the case.",
                    "label": 0
                },
                {
                    "sent": "OK, so to conclude, I've presented 22.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two algorithms which are strongly better on smoothness.",
                    "label": 0
                },
                {
                    "sent": "So the first one was constant step size to castigating dissent.",
                    "label": 0
                },
                {
                    "sent": "So in the context of least squares, there's not.",
                    "label": 0
                },
                {
                    "sent": "It's not a new algorithm, but in order to be able to benefit from the speed of constant step size we have developed these efficient online.",
                    "label": 1
                },
                {
                    "sent": "You can step which can which allows us to go to the traffic problem and also passed quickly through this like stochastic address vergent which is adapted to situations where you have.",
                    "label": 0
                },
                {
                    "sent": "A finite amount of data and you want to do multiple facets.",
                    "label": 0
                },
                {
                    "sent": "So here, of course there's a lot of extensions which which are possible and I will name, namely 2.",
                    "label": 0
                },
                {
                    "sent": "The first one is kernels.",
                    "label": 0
                },
                {
                    "sent": "OK, so I think there's kernel somewhere in the title of the of the workshop and all of this was assumed assumed to have an explicit representation of my problem and you fear of X it has it has size be OK, but this is not the problem for many problems which we are faced with like text data takes data.",
                    "label": 0
                },
                {
                    "sent": "These huge OK please millions but every fixes pass so you don't really care but about the big the size of P. But if you if you want to start to use kernels for like not permitting problems or let's say computer vision, then really there's no need to be able to do all this in the kernel world.",
                    "label": 0
                },
                {
                    "sent": "And of course paralyzing.",
                    "label": 0
                },
                {
                    "sent": "I think it's also key a key aspect.",
                    "label": 0
                },
                {
                    "sent": "And finally, I want to conclude in this whole of non smoothness in machine learning.",
                    "label": 1
                },
                {
                    "sent": "So I think in there not mentioned it yesterday so.",
                    "label": 0
                },
                {
                    "sent": "Start people so is very important because you have support vector non smoothness and slowly slowly people are deconstructing this SVM by going back to the simpler things which is least squares energistic and it would be interesting to see if.",
                    "label": 0
                },
                {
                    "sent": "Click on side views at one point.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}