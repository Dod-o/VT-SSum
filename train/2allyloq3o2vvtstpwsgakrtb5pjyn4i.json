{
    "id": "2allyloq3o2vvtstpwsgakrtb5pjyn4i",
    "title": "Structured Output Prediction on Data Streams",
    "info": {
        "author": [
            "Sa\u0161o D\u017eeroski, Department of Intelligent Systems, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 31, 2017",
        "recorded": "September 2016",
        "category": [
            "Top->Computer Science",
            "Top->Data Science"
        ]
    },
    "url": "http://videolectures.net/miningdata2016_dzeroski_data_streams/",
    "segmentation": [
        [
            "So jealous Key and thank you for coming to my talk which will be on the topic of structured output prediction on data streams."
        ],
        [
            "I gave an extensive introduction to the topic of structured output prediction, but I will be very brief introduction.",
            "First, predictive modeling on data streams just to make sure we know what the problem setting is, what the task is that we're solving, then problem also actually output prediction.",
            "In particular, we will be working on multi tag if degression and Multi Label classification.",
            "For this we will actually use the approach of structured output prediction with predictive clustering, but I will only say very few words about that since I already explained that on the first day.",
            "I will devote, of course, more attention to how we solve this task of structured output prediction on data streams and in particular multi target regression on my head and multi label classification on the.",
            "On the other hand, some directions for further work."
        ],
        [
            "We've also been.",
            "So the fact that we're dealing with Alaska predictive modeling, we have contacted variable that we want to predict from a number of other independent variables if the target variable has discrete values.",
            "We're talking about classification.",
            "If it has continuous values, you're talking about regression Now predict."
        ],
        [
            "Modeling on data streams falls into category of releasing modeling data.",
            "The data can be big because we have a large number of columns or variables in the table that I was showing on the previous slide.",
            "It can be big cause we have a large number of rows and data streams are kind of what happens in the limited number of rows is so large that it goes towards Infinity.",
            "Here the data.",
            "Coming one data after another and very high velocities in a specific order.",
            "And there are number can actually be potentially arbitrarily large.",
            "And we need to deal with this head on the underlying concept of distribution covering the data can also change.",
            "This is one of the major problems in mining data streams.",
            "The problem of concept drift, so we first have to detect such situations and then we have to act accordingly to modify our models that we have built from the data stream so far behind velocity of the arrival of the data requires fast processing.",
            "So essentially we can take a look at.",
            "Each data point as it arrives, and then we have to fast use it for whatever we want.",
            "Typically we update the values of some statistics and after that we simply discard this data point and go on to process the process.",
            "The dynamics in this context it is quite important to economically manage available memory as well.",
            "So very."
        ],
        [
            "Graphical illustration of what this looks like.",
            "The datapoints keep arriving and keep arriving and keep arriving now."
        ],
        [
            "The second level technician that we addressed here, the second dimension of complexity is that we have a task of structured output prediction.",
            "This falls into the second major keyboard for this summer school, namely complex data and predictive modeling tasks.",
            "Structure prediction include, among other multi target prediction, multi classification and regression multi label classification, the hierarchical variable.",
            "This problem and also predicting short time series of the kind that looked at the doroski, was discussing in the morning in the morning session."
        ],
        [
            "Here we just have for reference 2 tables with class with tasks of multi target classification and at the bottom of multi target regression where we need to predict three continuous variables."
        ],
        [
            "The task of multi label Classification is a special case of the multi target classification problem.",
            "Here we need to predict simultaneously a vector or similar binary variables binary targets rather than having an inventory number of discrete class class members.",
            "We have also."
        ],
        [
            "Identical version of this of this problem.",
            "Article Multilabel classification, where the values in the output space are organized in 100.",
            "What we're interested in solving here."
        ],
        [
            "Is a combination of these two dimensions of complexity on one hate, the streaming aspect and on the other hand, this action, and in this particular case we have a streaming multi target regression problem because three target variables so creepy and the data coming incrementally while getting time point and they keep they keep coming so."
        ],
        [
            "How do we?",
            "How do we approach this?",
            "What has been the master plan that we have been following for a number of years now?",
            "So first in the area of mining data streams, decision trees have certainly been a very popular approach and in particular decision trees for classification.",
            "However, the approaches for solving the regression tasks can actually been lagging a bit behind, so the first things that we have done is that we have taken decision tree approaches.",
            "Uh, for learning on data streams an adapted them to solving regression problems.",
            "So like had a PhD student and then also who the hell of a single clarification algorithm on data streams?",
            "This algorithm learns both regression trees which have constant predictions in the leaves and so called model trees, which have linear models in the in the leaves.",
            "In addition, the algorithm, which is called things Didi Didi, sense for drift detection, can also detect changes in the in the data and act accordingly to adapt the models.",
            "The single target regression case we have also developed approaches for learning so called option trees and I will explain what option trees are, but in particular option trees allow multiple splits to be explored.",
            "At least Choicepoint normally in a decision tree.",
            "At each point we choose just one test to put in the tree.",
            "In option trees, we can actually choose several alternative tests.",
            "So after we have extended regression approaches to work on data things because then go on go on to extend multi target regression approaches to work in the case.",
            "And this is mostly the work of another PhD student of mine who is due to be found in approximately half a year.",
            "If yes, we working on multi target dimension model trees, approaches case eveloped approaches to learning option trees for multitarget regulation as well as the sample approaches which learn a number of decision trees for multi target regression and then combine the applications.",
            "We have also used these multivariate regression approaches to solve multi label classification tasks.",
            "So we have used the classification via.",
            "Correction approach Play the later part of the talk.",
            "How we solve this and we are looking also into an extension of these approaches to solve the task of hierarchical multi target regression, which is a task that is not really considered very much.",
            "It has not received considerable attention, but we find instances of these problems in practice and Josh has been extending his software it also.",
            "They also handled that very brief."
        ],
        [
            "Reminder of how in Cedar trees are learn to be able to highlight the difference between the batch case where all the data are available up front and the streaming case where they arrive one at a time and you need to learn connected in the batch case, all of the data are available at the very beginning and.",
            "Decision tree construction algorithm is the currency.",
            "It first looks whether the values of the target variable on the entire data set a homogeneous enough and if they are it actually stops, builds Aleve and produce the predominant class value or the average winter in the reflection case.",
            "If you are not happy with the impurity of the target variable values, which is typically the case, the class ratings are not homogeneous.",
            "Then we have to select some attributes of variables, independent variables to put into the node of the tree and we select those that maximum reduce the impurity of the target.",
            "In the discrete case, the impurity is measured by the entropy of the class values.",
            "In the continuous case, impurity is measured by the variance of the target variable values from that point on.",
            "Algorithm proceeds and recursively calls itself on the subsets which are following the outcomes of the test.",
            "So if we put the test in the trip and it has a positive and negative outcomes, the data are split according to whether they satisfy the test or not, and the algorithm is recursive, recursively called on each of these two subsets, resulting in two subtrees.",
            "So this is a virtual learning approach which assumes that all the data.",
            "Available up front, This is why it can, for example, calculate the variance of the target and what the reduction of the various into target is.",
            "And for this it takes into account really all of the examples in the spring.",
            "In case you will remember the data points are arriving one at a time, so we cannot really do exactly the same and we have to come up with alternative approaches for selecting the test to put in the node of the tree so."
        ],
        [
            "So the key clearance between learning on data streams and virtual learning is that the data points arrive continuously and resorted to the three leaves where they accumulate until Will Smith is possible.",
            "So since we do not have all of the data at the same time, the data points arrive one at a time.",
            "We typically cannot make our mind to make a split in the tree after seeing just one example and even two or three or five we need to accumulate some statistical evidence.",
            "To discriminate, but the difference between the different tests and to say OK, this test is better than the other one.",
            "Once we have accumulated enough examples and collected enough evidence, we actually make.",
            "This leads and continue building the incremental.",
            "So what we do is first we make at least all of the potential splits and then we render on their variance.",
            "Induction and this variance reduction is incrementally updated as the new examples arrive.",
            "So for each leaf we actually look at the two best splits and then we monitor their relative quality and at the moment when we become certain that the first split is much better than the second one, then we select the first split we put it into the node of the tree and from that point on we need to build subtrees for the branches of the tree and it is in these branches of the tree where we collect examples.",
            "Evaluate potential potential tests.",
            "How?"
        ],
        [
            "So potential split over an attribute with operational speed sensor is a sample into two subsamples.",
            "The value goes to the left and then point it goes to the right.",
            "And we raise these potential speeds based on their variance reduction.",
            "Here variance of X is the variance on the entire data sample collected after that point and then we have the variances of the left and the right branch of the of the tree.",
            "And of course the higher the variance reduction the higher the purity of the sense subsamples, and the more desirable discrete so so.",
            "This general discussion here is really the same as in the in the batch case.",
            "For both these differ."
        ],
        [
            "And here we said we monitor the ratio of your recent values of the best to split.",
            "That is the variance reduction of the second speed and the variance reduction of the first split.",
            "When the variance reduction of the second split, it becomes much less than the volume of the first N. For these fields, actually the whole thing bound.",
            "When a predefined threshold is passed, then we will split the leaf and continue with the recursive construction.",
            "So this was implemented in the algorithm called fast incremental Model 3 with Rick detection and."
        ],
        [
            "The prediction that we get in the leaves of the tree.",
            "They can actually be constant.",
            "Constant values like these here.",
            "Or are they can actually be linear linear models which compute the value of the target from the values of the input attributes.",
            "So these are just linear linear equations containing the input attributes, but not necessarily all of them.",
            "Maybe we decide that some of them are not not important and this is learned.",
            "Using a passive from Western approach.",
            "No you go."
        ],
        [
            "Kurt about samples of decision trees.",
            "These are very effective methods.",
            "They are on one hand very powerful in terms of predicting performance.",
            "On the other hand, can be learned quite efficiently, and the approach to learning samples backing is a very famous approach relies on constructing bootstrap replicates of the training set.",
            "Because there are several.",
            "Is that replicates here?",
            "We have 123F replicates and then to each of these booster replicates we apply a decision tree learning algorithm and then we have an example of trees which we can apply to new data points.",
            "Again this relies on having all the data points present at the beginning so that we can do both that replicates.",
            "How do we do about step replicates if we have not seen all of the data that we will encounter?",
            "Luckily there have been some smart solutions to do this.",
            "Through this problem."
        ],
        [
            "Um, there is an algorithm called online banking which considers how varying would act if the size of the sample approaches Infinity and in essence, when an example arrives, this algorithm draws a number according to Apostle distribution, which estimates really the probability of how many times this example will be encountered if we had all of the data at the same at the same time.",
            "So essentially, when each example arrives, we give it a bit of weight, which expects how many times this example would appear if we keep.",
            "If you keep sampling OK.",
            "So then we were similar."
        ],
        [
            "And are we have the approach of building random forests, the only difference being?",
            "Process of decision tree learning is randomized and each step not all of the attributes or input variables are considered, but rather in each node of the tree we take a subset of the number of possible attributes and then.",
            "Select the best among those, and."
        ],
        [
            "Amen, I can.",
            "Almost guys I mentioned also about the approach of random forest to the online online case and that you don't really need to look at the details of this algorithm.",
            "It uses theme DD which I mentioned earlier just in the each internal node.",
            "It selects a subset of the attributes from which it chooses the best.",
            "No um."
        ],
        [
            "The other thing which we have explored is learning so called option trees for regression and there is a special motivation for considering this in the context of data streams.",
            "Namely, sometimes we cannot reliably determine which of the splits is best, so we can keep on sampling for quite awhile, and this variance reduction might still continue to be compatible for the first 2 tests.",
            "What existing learning approaches do in that case is to.",
            "Break that file without with the random with a random choice.",
            "What we have chosen to do in this case is actually.",
            "Then select both of the splits or a number of alternative splits which seem to have the same quality OK, and then we get."
        ],
        [
            "So called option notes.",
            "And an option of really needs that.",
            "We have several alternative subtrees rather than just one something.",
            "Enter these copies.",
            "I wrote it in his tests which appear to us to be all equally good.",
            "OK, and normally in a decision tree when we get a new example to make a prediction, the example travels to the through the three starting at the top and we sort it to the branches according to the outcomes of the tests and in the end we get the prediction from the leaf where the example arise.",
            "In option trees where we encounter an option code example is actually not sent to just one of these, but it is sent to all of the suffix.",
            "We get predictions for all of the subtrees and then we combine these predictions.",
            "You can imagine that we just do the adoration or we might select one of them according to some criterion.",
            "But the easiest thing that we just do the average so the predictions come from each of the sub trees and then we aggregate them to give the overall prediction of the three rooted at the option now OK."
        ],
        [
            "So here is an example of this is an option three progression.",
            "It starts at the very top with an option node was.",
            "This means really is we have 3 alternative trees and this is combining their prediction.",
            "So this is really an ensemble of three regression regression trees.",
            "But an option node can appear only at the very root.",
            "We might have for example, in option.",
            "Note here and then these.",
            "These three would have to suffer is here.",
            "And when we talk about our eyes it will be sorted into two of these.",
            "National Police with the Multitarget case on the first day I."
        ],
        [
            "Saying how we build predictive clustering fees, which allow us to handle multi target prediction.",
            "In essence, the only thing we need to change is we need to use use notion of variance which takes into account that we have a complex target, not just a single scalar value but rather a vector and for example in this case we will sum the variances according to each of the dimensions of the of the vector.",
            "Other than that the algorithm really doesn't change."
        ],
        [
            "Much and I was mentioning dead.",
            "For multivariate classification we can use the sum of the entropies along each of the targets and for multivariate regression we can use the sum of the variances along each of the targets.",
            "And in the."
        ],
        [
            "Pics of learning from data streams.",
            "We're looking at these variance reduction.",
            "These various measures which are mentioned here are no longer just the variances along a single target, but on some of the various is across all of the targets.",
            "OK, so we have here sums and we calculated the differences in this in this some if we had a hierarchical multi target.",
            "Aggression problems we use weights which are higher at the higher level of the hierarchy and lower at the lower levels of hierarchy.",
            "We know that the higher levels of the hierarchy are more important, and This is why they have higher rates in these particular examples.",
            "The way the way is falling exponentially as we go down down to three.",
            "OK."
        ],
        [
            "And here we have a multi target regression feel earned on a data stream.",
            "It is actually dealing with predicting the state over the ankle system at different points in time.",
            "So the case of different points in time and these three is predicting the state of the system at time point K from values in the previous time points K minus one thing under two K -- 3.",
            "And here we have two target variables that we want to predict.",
            "These are distinct variables C and.",
            "The and these are measured by Point K."
        ],
        [
            "For multi target classification, Multi label classification.",
            "In fact we use the approach of market application.",
            "We transform the multi label classification problem into a multi target regression problem.",
            "What we do is for each of the labels.",
            "If an example is labeled with the particular vehicle we get a value of 1.",
            "If it is not labeled with that value we get a value of zero.",
            "OK so we just binarize it because it is a binary.",
            "Problem to begin with.",
            "OK, and since we now have values of zero and one, we can also treat this as a regression problem and this is what we do once we transform it, we apply multivariate regression.",
            "Then when you get a new example to make a prediction, we get a letter of continuous values and this would of course not be exactly 0.",
            "And one thing might happen to be zero, 98 or zero 21 or so long, and at this point to get a multivariable prediction we just apply thresholding.",
            "If you can leave it with you 0.5% threshold and then if a value of greater than 0.5.",
            "Here we say it is available is present.",
            "If a value of less than 0.5.",
            "We say that the value is is absolutely and this is a very simple approach to solving the multi label classification problem via multi target regression."
        ],
        [
            "No, this is all implemented in a piece of software which is called ice, and in particular I said precisely stands for incremental Snapshot album prediction.",
            "We started from the beginning limitation and RE implemented in the more framework.",
            "This is a fact which developed in New Zealand out there.",
            "Defending the bank is the person in the development of what?",
            "Uh, and so now the more we hear the single tablet compression algorithms which I was talking about and they are extensions, single tablet interaction, model trees, option, treason, samples but also the multi target variants of of these.",
            "Portal technical detail is that now continuous attributes but also distinct attitudes are supported in the original implementation, which I mentioned by economics cut.",
            "This could not be handled, so only real negative roots could be handled, but.",
            "So we need his actually remove this technical limitation before finishing.",
            "Let me just very briefly."
        ],
        [
            "He mentioned the key results of the experimental evaluation of these approaches.",
            "So for multi target regression, packing things to work best.",
            "But it is quite computationally demanding.",
            "So random forest random forests represent a very good tradeoff between performance on one hand and resource consumption on the other hand.",
            "There is an interesting point which needs further investigation, which is the option.",
            "Three seems to perform much better in the single target case in the multi targeted case they are not really informative very well and this means a bit of further investigation."
        ],
        [
            "In terms of open label classification, again begging of multitarget trees works best.",
            "Here we have a set of average range diagrams for the different metals.",
            "You can see the banging of model trees at the fire in the fire, right?",
            "And this is only using measures of multi label classification performance which are based on ranking.",
            "There are many different measures using multi label classification.",
            "Those based on ranking are most suited to the mountain.",
            "Able to kacian.",
            "Problem and the results here appeared in better than the competition.",
            "I'll buy another equivalent by Jesse, then opened both Jesse and Albert are in the back and I have to acknowledge their help.",
            "They have been very helpful in actually comparing with their approach.",
            "I think the work very closely with the dash to help help him run these experiments now."
        ],
        [
            "We have lots of further work to do.",
            "Some of which we Luckily have done, so the option three is our approach, which is quite all goes quite way back, but somehow they were never really extensively taken up, not in the regression case, and essentially log into structured output prediction pace.",
            "So here we first develop them for the data stream mining case, but now we have also adopted them to the batch case for structured output prediction.",
            "And this is a paper to be presented in baring into Discovery Science conference this October.",
            "Michelangelo here is responsible for moving this conference to body and making Internet exciting event.",
            "We're looking forward to it.",
            "In terms of hierarchical multi target regression, the implementation is more or less done, but we have to evaluate this.",
            "Browse the nations.",
            "Develop an if you have examples of hierarchical multi target regression problems will be very happy to hear from you.",
            "We need datasets on that.",
            "On that front we know they exist, but we don't have many on our hands.",
            "Then a pretty open problem is change detection increase for structured output prediction on data streams.",
            "Jesse was mentioning some possible approaches in his talk on multi label classification, but this is still largely unexplored country so quite some work is needed there.",
            "And finally saying supervisor about prediction on data streams is an important problem.",
            "People are starting to look at these, but again we don't really have very good solutions.",
            "So far with that, I'd like to acknowledge."
        ],
        [
            "To support over number of projects and I'd like to thank you."
        ],
        [
            "For coming to our summer school.",
            "And finally I."
        ],
        [
            "Like to announce that you know years time, the European Conference on Machine Learning and Knowledge Discovery in databases will be held in scopia here, insomnia again so.",
            "Put these dates in your calendar and if I repeat this once more, don't be angry with me, just just write it down.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So jealous Key and thank you for coming to my talk which will be on the topic of structured output prediction on data streams.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I gave an extensive introduction to the topic of structured output prediction, but I will be very brief introduction.",
                    "label": 0
                },
                {
                    "sent": "First, predictive modeling on data streams just to make sure we know what the problem setting is, what the task is that we're solving, then problem also actually output prediction.",
                    "label": 1
                },
                {
                    "sent": "In particular, we will be working on multi tag if degression and Multi Label classification.",
                    "label": 1
                },
                {
                    "sent": "For this we will actually use the approach of structured output prediction with predictive clustering, but I will only say very few words about that since I already explained that on the first day.",
                    "label": 1
                },
                {
                    "sent": "I will devote, of course, more attention to how we solve this task of structured output prediction on data streams and in particular multi target regression on my head and multi label classification on the.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, some directions for further work.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've also been.",
                    "label": 0
                },
                {
                    "sent": "So the fact that we're dealing with Alaska predictive modeling, we have contacted variable that we want to predict from a number of other independent variables if the target variable has discrete values.",
                    "label": 0
                },
                {
                    "sent": "We're talking about classification.",
                    "label": 0
                },
                {
                    "sent": "If it has continuous values, you're talking about regression Now predict.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Modeling on data streams falls into category of releasing modeling data.",
                    "label": 1
                },
                {
                    "sent": "The data can be big because we have a large number of columns or variables in the table that I was showing on the previous slide.",
                    "label": 1
                },
                {
                    "sent": "It can be big cause we have a large number of rows and data streams are kind of what happens in the limited number of rows is so large that it goes towards Infinity.",
                    "label": 0
                },
                {
                    "sent": "Here the data.",
                    "label": 0
                },
                {
                    "sent": "Coming one data after another and very high velocities in a specific order.",
                    "label": 1
                },
                {
                    "sent": "And there are number can actually be potentially arbitrarily large.",
                    "label": 1
                },
                {
                    "sent": "And we need to deal with this head on the underlying concept of distribution covering the data can also change.",
                    "label": 0
                },
                {
                    "sent": "This is one of the major problems in mining data streams.",
                    "label": 0
                },
                {
                    "sent": "The problem of concept drift, so we first have to detect such situations and then we have to act accordingly to modify our models that we have built from the data stream so far behind velocity of the arrival of the data requires fast processing.",
                    "label": 0
                },
                {
                    "sent": "So essentially we can take a look at.",
                    "label": 0
                },
                {
                    "sent": "Each data point as it arrives, and then we have to fast use it for whatever we want.",
                    "label": 0
                },
                {
                    "sent": "Typically we update the values of some statistics and after that we simply discard this data point and go on to process the process.",
                    "label": 0
                },
                {
                    "sent": "The dynamics in this context it is quite important to economically manage available memory as well.",
                    "label": 0
                },
                {
                    "sent": "So very.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphical illustration of what this looks like.",
                    "label": 0
                },
                {
                    "sent": "The datapoints keep arriving and keep arriving and keep arriving now.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second level technician that we addressed here, the second dimension of complexity is that we have a task of structured output prediction.",
                    "label": 0
                },
                {
                    "sent": "This falls into the second major keyboard for this summer school, namely complex data and predictive modeling tasks.",
                    "label": 1
                },
                {
                    "sent": "Structure prediction include, among other multi target prediction, multi classification and regression multi label classification, the hierarchical variable.",
                    "label": 0
                },
                {
                    "sent": "This problem and also predicting short time series of the kind that looked at the doroski, was discussing in the morning in the morning session.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we just have for reference 2 tables with class with tasks of multi target classification and at the bottom of multi target regression where we need to predict three continuous variables.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The task of multi label Classification is a special case of the multi target classification problem.",
                    "label": 0
                },
                {
                    "sent": "Here we need to predict simultaneously a vector or similar binary variables binary targets rather than having an inventory number of discrete class class members.",
                    "label": 1
                },
                {
                    "sent": "We have also.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Identical version of this of this problem.",
                    "label": 0
                },
                {
                    "sent": "Article Multilabel classification, where the values in the output space are organized in 100.",
                    "label": 0
                },
                {
                    "sent": "What we're interested in solving here.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a combination of these two dimensions of complexity on one hate, the streaming aspect and on the other hand, this action, and in this particular case we have a streaming multi target regression problem because three target variables so creepy and the data coming incrementally while getting time point and they keep they keep coming so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we?",
                    "label": 0
                },
                {
                    "sent": "How do we approach this?",
                    "label": 0
                },
                {
                    "sent": "What has been the master plan that we have been following for a number of years now?",
                    "label": 0
                },
                {
                    "sent": "So first in the area of mining data streams, decision trees have certainly been a very popular approach and in particular decision trees for classification.",
                    "label": 0
                },
                {
                    "sent": "However, the approaches for solving the regression tasks can actually been lagging a bit behind, so the first things that we have done is that we have taken decision tree approaches.",
                    "label": 0
                },
                {
                    "sent": "Uh, for learning on data streams an adapted them to solving regression problems.",
                    "label": 1
                },
                {
                    "sent": "So like had a PhD student and then also who the hell of a single clarification algorithm on data streams?",
                    "label": 0
                },
                {
                    "sent": "This algorithm learns both regression trees which have constant predictions in the leaves and so called model trees, which have linear models in the in the leaves.",
                    "label": 1
                },
                {
                    "sent": "In addition, the algorithm, which is called things Didi Didi, sense for drift detection, can also detect changes in the in the data and act accordingly to adapt the models.",
                    "label": 0
                },
                {
                    "sent": "The single target regression case we have also developed approaches for learning so called option trees and I will explain what option trees are, but in particular option trees allow multiple splits to be explored.",
                    "label": 0
                },
                {
                    "sent": "At least Choicepoint normally in a decision tree.",
                    "label": 0
                },
                {
                    "sent": "At each point we choose just one test to put in the tree.",
                    "label": 0
                },
                {
                    "sent": "In option trees, we can actually choose several alternative tests.",
                    "label": 0
                },
                {
                    "sent": "So after we have extended regression approaches to work on data things because then go on go on to extend multi target regression approaches to work in the case.",
                    "label": 0
                },
                {
                    "sent": "And this is mostly the work of another PhD student of mine who is due to be found in approximately half a year.",
                    "label": 0
                },
                {
                    "sent": "If yes, we working on multi target dimension model trees, approaches case eveloped approaches to learning option trees for multitarget regulation as well as the sample approaches which learn a number of decision trees for multi target regression and then combine the applications.",
                    "label": 0
                },
                {
                    "sent": "We have also used these multivariate regression approaches to solve multi label classification tasks.",
                    "label": 0
                },
                {
                    "sent": "So we have used the classification via.",
                    "label": 0
                },
                {
                    "sent": "Correction approach Play the later part of the talk.",
                    "label": 0
                },
                {
                    "sent": "How we solve this and we are looking also into an extension of these approaches to solve the task of hierarchical multi target regression, which is a task that is not really considered very much.",
                    "label": 0
                },
                {
                    "sent": "It has not received considerable attention, but we find instances of these problems in practice and Josh has been extending his software it also.",
                    "label": 0
                },
                {
                    "sent": "They also handled that very brief.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reminder of how in Cedar trees are learn to be able to highlight the difference between the batch case where all the data are available up front and the streaming case where they arrive one at a time and you need to learn connected in the batch case, all of the data are available at the very beginning and.",
                    "label": 0
                },
                {
                    "sent": "Decision tree construction algorithm is the currency.",
                    "label": 0
                },
                {
                    "sent": "It first looks whether the values of the target variable on the entire data set a homogeneous enough and if they are it actually stops, builds Aleve and produce the predominant class value or the average winter in the reflection case.",
                    "label": 0
                },
                {
                    "sent": "If you are not happy with the impurity of the target variable values, which is typically the case, the class ratings are not homogeneous.",
                    "label": 0
                },
                {
                    "sent": "Then we have to select some attributes of variables, independent variables to put into the node of the tree and we select those that maximum reduce the impurity of the target.",
                    "label": 0
                },
                {
                    "sent": "In the discrete case, the impurity is measured by the entropy of the class values.",
                    "label": 1
                },
                {
                    "sent": "In the continuous case, impurity is measured by the variance of the target variable values from that point on.",
                    "label": 1
                },
                {
                    "sent": "Algorithm proceeds and recursively calls itself on the subsets which are following the outcomes of the test.",
                    "label": 0
                },
                {
                    "sent": "So if we put the test in the trip and it has a positive and negative outcomes, the data are split according to whether they satisfy the test or not, and the algorithm is recursive, recursively called on each of these two subsets, resulting in two subtrees.",
                    "label": 1
                },
                {
                    "sent": "So this is a virtual learning approach which assumes that all the data.",
                    "label": 0
                },
                {
                    "sent": "Available up front, This is why it can, for example, calculate the variance of the target and what the reduction of the various into target is.",
                    "label": 0
                },
                {
                    "sent": "And for this it takes into account really all of the examples in the spring.",
                    "label": 0
                },
                {
                    "sent": "In case you will remember the data points are arriving one at a time, so we cannot really do exactly the same and we have to come up with alternative approaches for selecting the test to put in the node of the tree so.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key clearance between learning on data streams and virtual learning is that the data points arrive continuously and resorted to the three leaves where they accumulate until Will Smith is possible.",
                    "label": 1
                },
                {
                    "sent": "So since we do not have all of the data at the same time, the data points arrive one at a time.",
                    "label": 0
                },
                {
                    "sent": "We typically cannot make our mind to make a split in the tree after seeing just one example and even two or three or five we need to accumulate some statistical evidence.",
                    "label": 1
                },
                {
                    "sent": "To discriminate, but the difference between the different tests and to say OK, this test is better than the other one.",
                    "label": 1
                },
                {
                    "sent": "Once we have accumulated enough examples and collected enough evidence, we actually make.",
                    "label": 0
                },
                {
                    "sent": "This leads and continue building the incremental.",
                    "label": 0
                },
                {
                    "sent": "So what we do is first we make at least all of the potential splits and then we render on their variance.",
                    "label": 0
                },
                {
                    "sent": "Induction and this variance reduction is incrementally updated as the new examples arrive.",
                    "label": 0
                },
                {
                    "sent": "So for each leaf we actually look at the two best splits and then we monitor their relative quality and at the moment when we become certain that the first split is much better than the second one, then we select the first split we put it into the node of the tree and from that point on we need to build subtrees for the branches of the tree and it is in these branches of the tree where we collect examples.",
                    "label": 1
                },
                {
                    "sent": "Evaluate potential potential tests.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So potential split over an attribute with operational speed sensor is a sample into two subsamples.",
                    "label": 1
                },
                {
                    "sent": "The value goes to the left and then point it goes to the right.",
                    "label": 1
                },
                {
                    "sent": "And we raise these potential speeds based on their variance reduction.",
                    "label": 0
                },
                {
                    "sent": "Here variance of X is the variance on the entire data sample collected after that point and then we have the variances of the left and the right branch of the of the tree.",
                    "label": 0
                },
                {
                    "sent": "And of course the higher the variance reduction the higher the purity of the sense subsamples, and the more desirable discrete so so.",
                    "label": 1
                },
                {
                    "sent": "This general discussion here is really the same as in the in the batch case.",
                    "label": 0
                },
                {
                    "sent": "For both these differ.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we said we monitor the ratio of your recent values of the best to split.",
                    "label": 1
                },
                {
                    "sent": "That is the variance reduction of the second speed and the variance reduction of the first split.",
                    "label": 0
                },
                {
                    "sent": "When the variance reduction of the second split, it becomes much less than the volume of the first N. For these fields, actually the whole thing bound.",
                    "label": 1
                },
                {
                    "sent": "When a predefined threshold is passed, then we will split the leaf and continue with the recursive construction.",
                    "label": 0
                },
                {
                    "sent": "So this was implemented in the algorithm called fast incremental Model 3 with Rick detection and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The prediction that we get in the leaves of the tree.",
                    "label": 0
                },
                {
                    "sent": "They can actually be constant.",
                    "label": 0
                },
                {
                    "sent": "Constant values like these here.",
                    "label": 0
                },
                {
                    "sent": "Or are they can actually be linear linear models which compute the value of the target from the values of the input attributes.",
                    "label": 1
                },
                {
                    "sent": "So these are just linear linear equations containing the input attributes, but not necessarily all of them.",
                    "label": 0
                },
                {
                    "sent": "Maybe we decide that some of them are not not important and this is learned.",
                    "label": 0
                },
                {
                    "sent": "Using a passive from Western approach.",
                    "label": 0
                },
                {
                    "sent": "No you go.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kurt about samples of decision trees.",
                    "label": 0
                },
                {
                    "sent": "These are very effective methods.",
                    "label": 0
                },
                {
                    "sent": "They are on one hand very powerful in terms of predicting performance.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, can be learned quite efficiently, and the approach to learning samples backing is a very famous approach relies on constructing bootstrap replicates of the training set.",
                    "label": 0
                },
                {
                    "sent": "Because there are several.",
                    "label": 0
                },
                {
                    "sent": "Is that replicates here?",
                    "label": 0
                },
                {
                    "sent": "We have 123F replicates and then to each of these booster replicates we apply a decision tree learning algorithm and then we have an example of trees which we can apply to new data points.",
                    "label": 0
                },
                {
                    "sent": "Again this relies on having all the data points present at the beginning so that we can do both that replicates.",
                    "label": 0
                },
                {
                    "sent": "How do we do about step replicates if we have not seen all of the data that we will encounter?",
                    "label": 0
                },
                {
                    "sent": "Luckily there have been some smart solutions to do this.",
                    "label": 0
                },
                {
                    "sent": "Through this problem.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, there is an algorithm called online banking which considers how varying would act if the size of the sample approaches Infinity and in essence, when an example arrives, this algorithm draws a number according to Apostle distribution, which estimates really the probability of how many times this example will be encountered if we had all of the data at the same at the same time.",
                    "label": 1
                },
                {
                    "sent": "So essentially, when each example arrives, we give it a bit of weight, which expects how many times this example would appear if we keep.",
                    "label": 0
                },
                {
                    "sent": "If you keep sampling OK.",
                    "label": 0
                },
                {
                    "sent": "So then we were similar.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And are we have the approach of building random forests, the only difference being?",
                    "label": 0
                },
                {
                    "sent": "Process of decision tree learning is randomized and each step not all of the attributes or input variables are considered, but rather in each node of the tree we take a subset of the number of possible attributes and then.",
                    "label": 0
                },
                {
                    "sent": "Select the best among those, and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Amen, I can.",
                    "label": 0
                },
                {
                    "sent": "Almost guys I mentioned also about the approach of random forest to the online online case and that you don't really need to look at the details of this algorithm.",
                    "label": 0
                },
                {
                    "sent": "It uses theme DD which I mentioned earlier just in the each internal node.",
                    "label": 0
                },
                {
                    "sent": "It selects a subset of the attributes from which it chooses the best.",
                    "label": 0
                },
                {
                    "sent": "No um.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other thing which we have explored is learning so called option trees for regression and there is a special motivation for considering this in the context of data streams.",
                    "label": 1
                },
                {
                    "sent": "Namely, sometimes we cannot reliably determine which of the splits is best, so we can keep on sampling for quite awhile, and this variance reduction might still continue to be compatible for the first 2 tests.",
                    "label": 1
                },
                {
                    "sent": "What existing learning approaches do in that case is to.",
                    "label": 0
                },
                {
                    "sent": "Break that file without with the random with a random choice.",
                    "label": 0
                },
                {
                    "sent": "What we have chosen to do in this case is actually.",
                    "label": 0
                },
                {
                    "sent": "Then select both of the splits or a number of alternative splits which seem to have the same quality OK, and then we get.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So called option notes.",
                    "label": 0
                },
                {
                    "sent": "And an option of really needs that.",
                    "label": 0
                },
                {
                    "sent": "We have several alternative subtrees rather than just one something.",
                    "label": 0
                },
                {
                    "sent": "Enter these copies.",
                    "label": 0
                },
                {
                    "sent": "I wrote it in his tests which appear to us to be all equally good.",
                    "label": 0
                },
                {
                    "sent": "OK, and normally in a decision tree when we get a new example to make a prediction, the example travels to the through the three starting at the top and we sort it to the branches according to the outcomes of the tests and in the end we get the prediction from the leaf where the example arise.",
                    "label": 0
                },
                {
                    "sent": "In option trees where we encounter an option code example is actually not sent to just one of these, but it is sent to all of the suffix.",
                    "label": 0
                },
                {
                    "sent": "We get predictions for all of the subtrees and then we combine these predictions.",
                    "label": 0
                },
                {
                    "sent": "You can imagine that we just do the adoration or we might select one of them according to some criterion.",
                    "label": 0
                },
                {
                    "sent": "But the easiest thing that we just do the average so the predictions come from each of the sub trees and then we aggregate them to give the overall prediction of the three rooted at the option now OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is an example of this is an option three progression.",
                    "label": 0
                },
                {
                    "sent": "It starts at the very top with an option node was.",
                    "label": 0
                },
                {
                    "sent": "This means really is we have 3 alternative trees and this is combining their prediction.",
                    "label": 0
                },
                {
                    "sent": "So this is really an ensemble of three regression regression trees.",
                    "label": 0
                },
                {
                    "sent": "But an option node can appear only at the very root.",
                    "label": 0
                },
                {
                    "sent": "We might have for example, in option.",
                    "label": 0
                },
                {
                    "sent": "Note here and then these.",
                    "label": 0
                },
                {
                    "sent": "These three would have to suffer is here.",
                    "label": 0
                },
                {
                    "sent": "And when we talk about our eyes it will be sorted into two of these.",
                    "label": 0
                },
                {
                    "sent": "National Police with the Multitarget case on the first day I.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Saying how we build predictive clustering fees, which allow us to handle multi target prediction.",
                    "label": 0
                },
                {
                    "sent": "In essence, the only thing we need to change is we need to use use notion of variance which takes into account that we have a complex target, not just a single scalar value but rather a vector and for example in this case we will sum the variances according to each of the dimensions of the of the vector.",
                    "label": 0
                },
                {
                    "sent": "Other than that the algorithm really doesn't change.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much and I was mentioning dead.",
                    "label": 0
                },
                {
                    "sent": "For multivariate classification we can use the sum of the entropies along each of the targets and for multivariate regression we can use the sum of the variances along each of the targets.",
                    "label": 0
                },
                {
                    "sent": "And in the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pics of learning from data streams.",
                    "label": 0
                },
                {
                    "sent": "We're looking at these variance reduction.",
                    "label": 1
                },
                {
                    "sent": "These various measures which are mentioned here are no longer just the variances along a single target, but on some of the various is across all of the targets.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have here sums and we calculated the differences in this in this some if we had a hierarchical multi target.",
                    "label": 0
                },
                {
                    "sent": "Aggression problems we use weights which are higher at the higher level of the hierarchy and lower at the lower levels of hierarchy.",
                    "label": 1
                },
                {
                    "sent": "We know that the higher levels of the hierarchy are more important, and This is why they have higher rates in these particular examples.",
                    "label": 1
                },
                {
                    "sent": "The way the way is falling exponentially as we go down down to three.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here we have a multi target regression feel earned on a data stream.",
                    "label": 1
                },
                {
                    "sent": "It is actually dealing with predicting the state over the ankle system at different points in time.",
                    "label": 0
                },
                {
                    "sent": "So the case of different points in time and these three is predicting the state of the system at time point K from values in the previous time points K minus one thing under two K -- 3.",
                    "label": 0
                },
                {
                    "sent": "And here we have two target variables that we want to predict.",
                    "label": 0
                },
                {
                    "sent": "These are distinct variables C and.",
                    "label": 0
                },
                {
                    "sent": "The and these are measured by Point K.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For multi target classification, Multi label classification.",
                    "label": 0
                },
                {
                    "sent": "In fact we use the approach of market application.",
                    "label": 0
                },
                {
                    "sent": "We transform the multi label classification problem into a multi target regression problem.",
                    "label": 0
                },
                {
                    "sent": "What we do is for each of the labels.",
                    "label": 0
                },
                {
                    "sent": "If an example is labeled with the particular vehicle we get a value of 1.",
                    "label": 0
                },
                {
                    "sent": "If it is not labeled with that value we get a value of zero.",
                    "label": 0
                },
                {
                    "sent": "OK so we just binarize it because it is a binary.",
                    "label": 0
                },
                {
                    "sent": "Problem to begin with.",
                    "label": 0
                },
                {
                    "sent": "OK, and since we now have values of zero and one, we can also treat this as a regression problem and this is what we do once we transform it, we apply multivariate regression.",
                    "label": 0
                },
                {
                    "sent": "Then when you get a new example to make a prediction, we get a letter of continuous values and this would of course not be exactly 0.",
                    "label": 0
                },
                {
                    "sent": "And one thing might happen to be zero, 98 or zero 21 or so long, and at this point to get a multivariable prediction we just apply thresholding.",
                    "label": 0
                },
                {
                    "sent": "If you can leave it with you 0.5% threshold and then if a value of greater than 0.5.",
                    "label": 0
                },
                {
                    "sent": "Here we say it is available is present.",
                    "label": 0
                },
                {
                    "sent": "If a value of less than 0.5.",
                    "label": 0
                },
                {
                    "sent": "We say that the value is is absolutely and this is a very simple approach to solving the multi label classification problem via multi target regression.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, this is all implemented in a piece of software which is called ice, and in particular I said precisely stands for incremental Snapshot album prediction.",
                    "label": 0
                },
                {
                    "sent": "We started from the beginning limitation and RE implemented in the more framework.",
                    "label": 1
                },
                {
                    "sent": "This is a fact which developed in New Zealand out there.",
                    "label": 0
                },
                {
                    "sent": "Defending the bank is the person in the development of what?",
                    "label": 0
                },
                {
                    "sent": "Uh, and so now the more we hear the single tablet compression algorithms which I was talking about and they are extensions, single tablet interaction, model trees, option, treason, samples but also the multi target variants of of these.",
                    "label": 0
                },
                {
                    "sent": "Portal technical detail is that now continuous attributes but also distinct attitudes are supported in the original implementation, which I mentioned by economics cut.",
                    "label": 0
                },
                {
                    "sent": "This could not be handled, so only real negative roots could be handled, but.",
                    "label": 0
                },
                {
                    "sent": "So we need his actually remove this technical limitation before finishing.",
                    "label": 0
                },
                {
                    "sent": "Let me just very briefly.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He mentioned the key results of the experimental evaluation of these approaches.",
                    "label": 0
                },
                {
                    "sent": "So for multi target regression, packing things to work best.",
                    "label": 0
                },
                {
                    "sent": "But it is quite computationally demanding.",
                    "label": 0
                },
                {
                    "sent": "So random forest random forests represent a very good tradeoff between performance on one hand and resource consumption on the other hand.",
                    "label": 1
                },
                {
                    "sent": "There is an interesting point which needs further investigation, which is the option.",
                    "label": 0
                },
                {
                    "sent": "Three seems to perform much better in the single target case in the multi targeted case they are not really informative very well and this means a bit of further investigation.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In terms of open label classification, again begging of multitarget trees works best.",
                    "label": 1
                },
                {
                    "sent": "Here we have a set of average range diagrams for the different metals.",
                    "label": 0
                },
                {
                    "sent": "You can see the banging of model trees at the fire in the fire, right?",
                    "label": 0
                },
                {
                    "sent": "And this is only using measures of multi label classification performance which are based on ranking.",
                    "label": 0
                },
                {
                    "sent": "There are many different measures using multi label classification.",
                    "label": 0
                },
                {
                    "sent": "Those based on ranking are most suited to the mountain.",
                    "label": 0
                },
                {
                    "sent": "Able to kacian.",
                    "label": 1
                },
                {
                    "sent": "Problem and the results here appeared in better than the competition.",
                    "label": 0
                },
                {
                    "sent": "I'll buy another equivalent by Jesse, then opened both Jesse and Albert are in the back and I have to acknowledge their help.",
                    "label": 0
                },
                {
                    "sent": "They have been very helpful in actually comparing with their approach.",
                    "label": 0
                },
                {
                    "sent": "I think the work very closely with the dash to help help him run these experiments now.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have lots of further work to do.",
                    "label": 1
                },
                {
                    "sent": "Some of which we Luckily have done, so the option three is our approach, which is quite all goes quite way back, but somehow they were never really extensively taken up, not in the regression case, and essentially log into structured output prediction pace.",
                    "label": 0
                },
                {
                    "sent": "So here we first develop them for the data stream mining case, but now we have also adopted them to the batch case for structured output prediction.",
                    "label": 0
                },
                {
                    "sent": "And this is a paper to be presented in baring into Discovery Science conference this October.",
                    "label": 0
                },
                {
                    "sent": "Michelangelo here is responsible for moving this conference to body and making Internet exciting event.",
                    "label": 0
                },
                {
                    "sent": "We're looking forward to it.",
                    "label": 0
                },
                {
                    "sent": "In terms of hierarchical multi target regression, the implementation is more or less done, but we have to evaluate this.",
                    "label": 0
                },
                {
                    "sent": "Browse the nations.",
                    "label": 0
                },
                {
                    "sent": "Develop an if you have examples of hierarchical multi target regression problems will be very happy to hear from you.",
                    "label": 1
                },
                {
                    "sent": "We need datasets on that.",
                    "label": 0
                },
                {
                    "sent": "On that front we know they exist, but we don't have many on our hands.",
                    "label": 0
                },
                {
                    "sent": "Then a pretty open problem is change detection increase for structured output prediction on data streams.",
                    "label": 1
                },
                {
                    "sent": "Jesse was mentioning some possible approaches in his talk on multi label classification, but this is still largely unexplored country so quite some work is needed there.",
                    "label": 0
                },
                {
                    "sent": "And finally saying supervisor about prediction on data streams is an important problem.",
                    "label": 0
                },
                {
                    "sent": "People are starting to look at these, but again we don't really have very good solutions.",
                    "label": 0
                },
                {
                    "sent": "So far with that, I'd like to acknowledge.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To support over number of projects and I'd like to thank you.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For coming to our summer school.",
                    "label": 0
                },
                {
                    "sent": "And finally I.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like to announce that you know years time, the European Conference on Machine Learning and Knowledge Discovery in databases will be held in scopia here, insomnia again so.",
                    "label": 0
                },
                {
                    "sent": "Put these dates in your calendar and if I repeat this once more, don't be angry with me, just just write it down.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}