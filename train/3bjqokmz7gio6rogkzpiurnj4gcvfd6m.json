{
    "id": "3bjqokmz7gio6rogkzpiurnj4gcvfd6m",
    "title": "Leveraging Community-built Knowledge for Type Coercion in Question Answering",
    "info": {
        "author": [
            "Aditya Kalyanpur, IBM Research"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Natural Language Processing"
        ]
    },
    "url": "http://videolectures.net/iswc2011_kalyanpur_leveraging/",
    "segmentation": [
        [
            "So I'm Aditya kalyanpur.",
            "I'm from IBM research and a member of the team that built the Watson system that won the Jeopardy Challenge.",
            "And I'm here to talk to you about type coercion in the Watson system and how we used Community built knowledge in order to improve type coercion.",
            "Specifically, we use Wikipedia DB Pedia and Jago.",
            "And I'm going to talk about how these helped and this is work that I did with Bill Murdoch, James Fan and Chris Welty.",
            "And if you heard.",
            "Chris in the morning he said his name should be in a larger font size, so I changed that after hearing it."
        ],
        [
            "OK, so a quick introduction on what is Watson or other?",
            "Who is Watson?",
            "Most of you know this Watson is an automatic open domain question answering system.",
            "What probably most of you don't know is that Watson also won the Webby person of the Year award for 2011.",
            "And this is interesting because the Webby Awards are given for Internet applications.",
            "And when I think of an Internet app, I don't think of Watson immediately.",
            "But I think what this shows is that we did use a lot of web knowledge in Watson, even though Watson was not connected to the Internet.",
            "It used a lot of web knowledge sources like Wikipedia and so on.",
            "So what the system does is a question answering system.",
            "Given an input which is rich natural language questions, so the input is a question in plain text form, not a sparkle query.",
            "The job of the machine is to understand the question.",
            "Question can be over a broad domain of knowledge.",
            "It could be on any topic and the idea then is to deliver a precise answer right?",
            "So not just the document that contains the answer.",
            "The exact answer to the question.",
            "To do this very quickly and two other key points, one is to produce accurate confidences.",
            "So the idea here is that Watson should tell you how short it is that the answer is correct, and if Watson can produce a reliable confidence score, then you can trust the system better.",
            "You know that the confidence is high.",
            "The answer is probably correct.",
            "If it's wrong, then you probably need to figure out why Watson was not confident and the related point here is justifications.",
            "It would be nice if Watson can explain how it came up with the answer how we can justify what evidence did find for the answer."
        ],
        [
            "So we applied Watson to the Jeopardy Challenge.",
            "An most of you know, Jeopardy is.",
            "I'm not going to go into details about the game, but basically what jeopardy does is first of all, it's a.",
            "It's a quiz show in the US it's very popular and they ask questions on a whole host of different topics.",
            "An early challenges automatic QA technology because it pushes it along.",
            "Five it test QA technology along five key dimensions.",
            "First broad and open domain.",
            "2nd is complex language.",
            "They use puns, metaphors and so on in order confuse humans, which makes it very hard for a machine to correctly understand.",
            "So here are some examples of jeopardy questions.",
            "And given the venue, I thought I'll take questions that involve Germany little bit, so I don't know how many of you know the answers to these questions.",
            "The first one says Breakdown Germany and get this Sally whom Harry met on film.",
            "The answer is Meg Ryan.",
            "Because you can read it's an anagram for Germany.",
            "Here's another question.",
            "A map of Europe on this country's 1997 thousand lire coin had such errors as depicting Denmark as part of Germany.",
            "The answer is Italy, and it's something you get just by seeing the thousand lire coin right.",
            "And the point here is that there's a lot of redundant information in the question which humans can easily see, but a machine can go down the wrong path.",
            "And here's a question I don't know how many of you know this $1000 question.",
            "You don't have to pull the feathers of this chilly pink sparkling wine originally from Germany.",
            "Does anybody know the answer to this?",
            "Sorry.",
            "No, it's cold duck.",
            "Level order this.",
            "Anyway, so the point is that in jeopardy they ask you questions like this that cover a whole range of different topics, extremely complicated language, and the machine in order to win at Jeopardy, has to be extremely precise, has to produce a reliable confidence score, and it has to be fast."
        ],
        [
            "Now let's look at the typing problem in jeopardy.",
            "So you know the the the key point of this slide that in question Jeopardy.",
            "Questions the answer type, right?",
            "It varies a lot.",
            "It can pretty much be any string in the English language, so you know some examples in the first question is asking for a kettle.",
            "It's basically the question is it's basically a big cattle with a close fitting lid used to cook pot roast and stools.",
            "He also.",
            "So Dutch oven.",
            "In the second question, they're asking for a scare fest, which is another word for a horror movie, so unlucky things happen at Camp Crystal Lake.",
            "In this 1980s Scarefest.",
            "The answer is Friday the 13th.",
            "And the last question this question actually we got in the exhibition game that we played against Ken and Brad and Watson got this answer correct.",
            "The question is wanted for general evilness last seen at the Tower of Murder is a giant eye folks kind of hard to miss.",
            "Exactly, so it on an again here it's relatively easy for humans to do one if they know Lord the rings trivia.",
            "They can make the connection.",
            "They know that sort on is an eye, but for a machine to do this kind of type checking is extremely hard.",
            "You're going to find a Dictionary of eyes with an instance of sword, right?",
            "So the point is that in jeopardy these answer types vary a lot.",
            "They go from very specific things to very vague things.",
            "And what does not work is traditional techniques.",
            "Traditional approaches in QA systems to do answer typing, and this does not work.",
            "So this is something we don't do.",
            "It's closed domain types."
        ],
        [
            "Sting and the idea is based on a type and generate principle.",
            "What that means is you first figure out what are the interesting types in your domain in your application, and you come up with this list of types.",
            "So you determine this beforehand.",
            "Things like people, places, organizations.",
            "For these types you run named entity recognizers over your corpus to pull out instances of these types.",
            "And so you create these like a dictionary and then at runtime given a question, you detect what is the answer type in the question you map it to one of these types and then you generate candidates from this pre compiled list of instances.",
            "So as you can see before, this cannot simply work for jeopardy, right?",
            "It's lots of limitations.",
            "The most obvious ones are it's very brittle, right?",
            "The QA system breaks down if you can't recognize the type, right?",
            "Related point is you need to you need to enumerate all the relevant types beforehand, right?",
            "So it limits of coverage and also dependent on the quality of your name.",
            "Denni, recognizers, right?",
            "So Newton is also a town in Massachusetts, right?",
            "So if it hasn't detected that, you're going to lose information.",
            "So the approach we take is completely different and something that works really well.",
            "And this is what I'm going to talk about here.",
            "It's called open domain type coercion or tie code, and we sort of invert this principle.",
            "What we say it's called generate and type.",
            "So the idea is."
        ],
        [
            "You generate candidate answers without looking at the lexical answer type first.",
            "You then go and find all possible type information that you can for a candidate and you check can that candidate be coerced into that.",
            "So we do this secondary step later on, we don't filter candidates based on type.",
            "Instead, we do this coercion later on.",
            "We use a suite of type codes and algorithms and I'm going to talk about some of these in more detail.",
            "And then we use machine learning to combine information from all these different types of algorithms.",
            "So they wanted this compared to the previous system.",
            "With some of this advantages, one is more flexible, right?",
            "So if you're curious system does not breakdown if you can't detect a meaningful type because it doesn't rely solely on time.",
            "You don't filter answers based on type and you can get a much wider coverage of types by using this approach because you use a whole bunch of different sources and algorithms to go and find whether the candidate can be coerced into the type or not."
        ],
        [
            "So how does this fit into the deep QA architecture into the Watson architecture?",
            "So we actually had a Watson tutorial on Sunday, so some of you attended that.",
            "You know about this and I'm just going to give you like a one minute sorry, one.",
            "Slide overview of Watson at a very high level.",
            "Just try to explain how Watson works with an example.",
            "So let's say that Watson sees this question in 1698.",
            "This comet discoverer took a ship called the Parramore Pink.",
            "On the 1st purely scientific see voyage.",
            "Now we know the answer to this question.",
            "Yes, that's correct.",
            "So the first thing that wasn't as we analyze the question, we figure out what are the keywords.",
            "What are the named entities?",
            "What is the answer type?",
            "The lexical answer type, which is a string in this case, is Comet Discoverer.",
            "We plowed dates, we pull out any relationships that are in the questions we do some relationship detection.",
            "And then we go and do a search based on our question analysis.",
            "If you search lots of content related content, both unstructured and structured content, and generate a whole bunch of different candidate answers, then for each of these scanner answers Watson goes and finds supporting evidence for each of them, and then the score is this evidence along 500 different dimensions, right?",
            "And do some examples of the evidence to mentions lexical?",
            "How good is there a lexical or keyword match between the passages found for a candidate and the question Tycho?",
            "Or this is the code.",
            "All of this talk, which is how is there a good type match between the candidate and the lexical answer type.",
            "And as you can see here, Tyco is just another answer feature.",
            "But this is 1 feature in a whole bag of different features that we use, and we let the machine learning assign weights to the different core features.",
            "Alright, so we don't do any filtering of candidates based on types we treat type is just another feature and we use a bunch of different type or algorithms so that I could.",
            "Actually there is a block of different algorithms, so there's not just one type of feature, so there are many and they can sort of binary score is not 01.",
            "It can be real value and there are other dimensions as well, like relations.",
            "How well do the relations for the candidate match what is required in the question temporal in this case is a date in the question.",
            "Does the candidate you know have a temporal matches it?",
            "Doesn't make sense in the temporal context of the question, and so now you've analyzed this evidence along all these different dimensions, and we produce basically feature vectors for each of these dimensions, and we give this to a machine learning model.",
            "That is being trained on previous questions.",
            "And based on the training, it knows it has assigned weights to these different features, so it knows.",
            "For example, there is a date in the clue.",
            "You should trust the temporal mode and so on, and so the machine learning model then does a ranking of the answers and also comes up with confidence scores.",
            "So come over the rank list of answers and in this case it means he is the correct answer, has a high confidence of .85."
        ],
        [
            "So not digging going into that, I code framework input for the Tyco framework is just two strings.",
            "The lexical answer type and the Canary.",
            "And the job of the framework is to figure out can the candidate be coerced into the type and we break it.",
            "Break down this type code framework in four steps.",
            "We call them EDM.",
            "Entity disambiguation matching.",
            "PR type retrieval predicate disintegration matching and type alignment.",
            "So here's an example of how these four steps work.",
            "Let's say your candidate is a string.",
            "JFK and your lexical answer type is a string facility.",
            "So the job is to figure out.",
            "Is JFK a kind of facility?",
            "The first step we do is EDM, so we take this candidate string and we try to map it to some resource in some knowledge base and we use Wikipedia because it has excellent coverage.",
            "For instance, is right, so we call this the EDM problem because it requires you to identify exactly what JFK means, another simulated as well.",
            "Because JFK could mean different things in different contexts.",
            "So in this example they show you.",
            "Let's say we have identified it as John F Kennedy International and there's also a score that you can see a .7.",
            "And the point here is that.",
            "This process produces not one entity, but a list of mappings with some uncertainties associated with them, and I'm just showing you the top mapping here in this example.",
            "The next step is type retrieval.",
            "So once we have these instances, we go and find types for them and we use a bunch of different sources.",
            "Water them is.",
            "I'm going to talk about this is DB Pedia and Jago Jago Ontology.",
            "And in this case for example you can see that as a Yahoo type of airport and again in this step we don't produce just one type of a bunch of different types all with different scores.",
            "So in this case it has a direct type of Jago.",
            "Airports score of 1.",
            "The third step is PDM, which is taking the lat and try to map that to a type.",
            "And in this case, again, you have to do sense disambiguation because the word facility can mean different things.",
            "In this case, let's say you mapped it to the word net sense of the physical facility.",
            "Again, there's a score associated.",
            "And finally we have a type matching problem.",
            "You compare the type that you got from the lexical answer string and the type that we got from the candidate and compare those two.",
            "And in this case it's quite straightforward, because actually there are links between YAGO and word net, so another good point about linked data.",
            "You can exploit these links and in this case it's simple.",
            "Airport is a kind of facility.",
            "And you get a direct match and the final Tyco score is some combination of the four step scores and you could either take some heuristic combination like you could just multiply the four scores, or you could actually have a machine learning approach where you could make these 4 scores features in a model.",
            "You could train it on data and you could learn weights for these four steps.",
            "So with this framework you can do things like this.",
            "Some examples of some interesting examples of what I code allows you to info.",
            "You can say Ramadan is a month interpreter is a job, castling is a maneuver, and so on is.",
            "And I right?"
        ],
        [
            "OK, so I'm going to talk about these steps in some more details, so the first is EDM.",
            "This is a fundamental problem in NLP.",
            "As you use entity string and you want to map it to some meaningful reference in a knowledge base and so for example the string link in the entity Abraham Lincoln can be represented in different places in different strings.",
            "It could be called President Lincoln, Abe Lincoln, but conceptually they all mean the same person and you want to be able to make this connection.",
            "And there are two big issues there.",
            "The first synonymy right there are many different ways to say the same thing they have.",
            "You know, spelling variations, aliases, nicknames, Gaddafi.",
            "They think the 100 different ways to spell Gaddafi.",
            "I don't know, I hope they got his spelling correct on his death certificate.",
            "Polysomy this is another problem which is that this is another extremely hard problem for machine is you need to take this context into account in order to do the correct sentence immigration, right?",
            "Because even the string JFK in different contexts can mean different things and humans are very good at figuring out what the sensors is.",
            "Much harder for the machine to do."
        ],
        [
            "So the way we use community built knowledge in EDM is we use it for both these steps for both matching as well As for disambiguation.",
            "And here are some examples of the resources that we used for matching.",
            "We use things like Wikipedia redirects, right?",
            "So Mama redirected to Burma, so that gives you an alternate name for Bama.",
            "We did things like we extracted synonyms and aliases and nicknames and stuff like that from the introductory paragraph of Wikipedia page, because that's a nice location where they actually specify these kinds of variants, so we could learn.",
            "For example, IBM has a nickname of Big Blue.",
            "We use the DB Pedia name labels.",
            "There are over 100 different properties that specify.",
            "Names in DB pedia.",
            "And some of these are noisy and so the point is that you have all these different resources, but you can learn to weigh these differently, right?",
            "So we give more weight to Wikipedia redirects because they're more precise.",
            "Then repeat their name labels.",
            "And then for disambiguation, we use primarily Wikipedia disambiguation pages, because it scored excellent coverage for different sensors an there are more than 2008 when we did this analysis, there were more than 15150 thousand disambiguation pages in DB pedia and to give an idea, Java, for example, has more than 20 distinct types, right?",
            "So the point is that these disambiguation pages are an excellent inventory of sense information, because each of these different sensors has its own page with keywords on that page and links to.",
            "Rated entities and type information.",
            "All this contextual information that you can use when you're trying to do EDM an you what you want to do is measure the similarity between the contextual information in that sense repository with the contextual information in your for your data right in your text, and you can use different techniques for doing this.",
            "You could use bag of words you could use LSA and so I'm not going to go into details of that, but the point is that Wikipedia is excellent, excellent repository for this kind of information.",
            "And the output of EDM is a ranked list of entity resources.",
            "In this case, the outputs are Wikipedia, ur eyes and the ranking is based on a combination of features I mentioned here.",
            "So we look at the source where it came from.",
            "Is it redirected to DB Pedia property?",
            "We look at popularity of the entity using different kinds of metrics like link analysis and the contextual similarity as well for disambiguation.",
            "So we combine all this and again you could combine this juristically or using machine learning and.",
            "Based on this, we produce an output of rank list of sources.",
            "We evaluated our IDM algorithm on Wikipedia data.",
            "So the idea here is the way we set up this evaluation is we take a Wikipedia page which has links and it has anchor tags with links.",
            "So what we do is we remove the links on the anchor tag and we see can we get back the links using our technique and this is a traditional technique that other people have also used for valid for evaluating that EDM solution.",
            "And what we've got is state of the art performance with pretty high precision and recall scores."
        ],
        [
            "The next step is type retrieval.",
            "So again, now that you mapped your candidate string to some instance in a knowledge base, you want to find types for these, we use a whole bunch of different types sources.",
            "Things like word, net, Wikipedia lists, categories, YAGO, Ontology, and also the automatically mind text.",
            "And the point here is that these sources also have varying precision and recall, right?",
            "So for example, word NET is extremely precise, but it doesn't have good recall, whereas something like the automatically mintex types that we get from text.",
            "How much better recall?",
            "But they suffer from noise.",
            "Some interesting points here is that the type systems are linked.",
            "So as I mentioned earlier, that links between Yahoo and Word Net so we can leverage this because if you're type from your lat points to one type system and the type that comes from the counters in a different type system, you can use links between these two, come up with the final ticor score.",
            "The wiki categories and lists contain extra sort of modifier information about types, so they contain sort of fine grained type information that you can use.",
            "So for example, the categories for Ryan Center German inventor.",
            "Swiss vegetarian patent examiner and so on.",
            "And the point is that when we are matching the types in a question, we can look not just at the main word of the type but also the modifyers and match them separately.",
            "And also another key issue here is that the automatically mind types reflect real world usage.",
            "The way people actually use types, right?",
            "So, for example, fluid is a liquid is something that we get from text because people use these terms interchangeably, though strictly speaking semantically this other way around, right liquid is a kind of fluid."
        ],
        [
            "Without step is PDM predicate disambiguation and matching.",
            "So this is like the word sense disambiguation problem.",
            "You have a concept award which represents a concept and you want to map it to the right sense.",
            "So for example, if the lexical answer type is star, it could mean either the astronomical object or the celebrity.",
            "And again you have to look at the context to figure out.",
            "You know what concept it means, and it's very similar in principle to entity disintegration.",
            "Matching the main difference is that in the DMS you're mapping a named entity to some instance in a knowledge base.",
            "In PDM you're mapping or generic noun or a class to some concept or type in a knowledge base.",
            "The techniques that we use in deep QA, two things.",
            "One is, we have again an algorithm to map these lexical answer types toward net concepts based on the context and also using the rank information that's there in Word net and one of the interesting point is we also pull in lat types that are statistically related in DB pedia.",
            "So the idea here is that if you get the latter brand, we also compute how often is the case in DB pedia that an instance of type brand also has the instance of type product.",
            "And we see that so this conditional probability is very high.",
            "It's about some threshold.",
            "Right, so the point in this case it's like .8 three.",
            "So the point is, if you see that type of brand, we can also pull in related that type of product.",
            "By doing this kind of statistical analysis over DB pedia."
        ],
        [
            "And last step is type alignment.",
            "Again, you compare to compare two sets of types.",
            "We use a bunch of different type heuristics.",
            "For example, the obvious one is a direct equivalence class match or a subclass match.",
            "So if your lattice a facility and your candidate type is an airport, you got a strong match your sibling matches.",
            "So you know the lack type in the candidate.",
            "Have siblings you know type system will give a lower score and so on.",
            "One interesting thing is the notion of disjoint types.",
            "So here the idea is that if your laptop is train station and a candidate type is aerodrome that is disjoint.",
            "So this place it produces a negative type match and this is a separate signal in deep QA separate feature in our model we call it the anti code feature antique or an.",
            "This feature gets a negative weight in the model and it helps push down candid answers that don't match the correct type.",
            "And so, in order to do this kind of disjoint reasoning, we had to add disjointness axioms in Jago, because Yahoo does not have disjointness, and we did this in a reasonably smart way.",
            "Yahoo is a very big ontology, it has more than 100,000 types, so we didn't add pairwise disjoint between all the types that we thought were disjoint.",
            "We added distance at a high level in the taxonomy, and then we just propagated disjoints down using reasoning simple reasoning.",
            "So for example, if Organism is disjoint with geopolitical entity, than any subclass of organisms respond with any subclasses.",
            "Jeep."
        ],
        [
            "And so on.",
            "So putting it all together, the final Tyco scores.",
            "As I said, some combination of the four step scores.",
            "One thing you'll note is that if you take this combination as a simple product, your final Tyco score will be 0.",
            "If any of the step fails, so the two options one is, you can consider doing some kind of smoothing so you put non 0 scores.",
            "Another thing that we found interesting and works well is you actually expose which step failed to your model.",
            "So you add special features for like a EDM failure and a PDM failure.",
            "The model can learn how to weigh these features.",
            "As I mentioned, anti corza separate signal that we had.",
            "So this is an interesting case.",
            "When the type alignment score is minus one, we had a separate feature to the model and what this does is it helps push down candidates whose types are incompatible with the lexical answer type.",
            "And there's another point is if you have multiple laps in the question, you need some way to come up with the final Tyco score.",
            "What we do is we take a weighted sum of the lack confidence and the respective Tyco scores for each of those lats.",
            "So that Igor algorithm Sweden dqa has around 14 takeovers, three of which that use Wikipedia and DB pedia Ticos follow these four core steps and each Tyco score is a separate separate feature in the model.",
            "The model can learn how to weigh in comparison with the other features and known to balance the weights on these features."
        ],
        [
            "So for the evaluation, I'm going to talk about two sets of evaluations.",
            "The first is evaluating how the Tyco is do on ground truth.",
            "So what this means is how well the Ticos do on checking if a candidate is an instance of a type.",
            "This is not part of a QA task, but this is just separately the entity type matching problem.",
            "So in order to do this we created a benchmark from jeopardy.",
            "We took around 1600 Jeopardy questions.",
            "We identified the lexical answer type for each of them.",
            "And we took the top ten candidate answers that Watson came up with for these questions.",
            "And just to be clear, we took a version of Watson that did not have Vicodin it to take these top 10 answers because we want to bias our sample in anyway, and then for each of these top ten candidates we did a manual judgment.",
            "Does the candidate mass a lot or not?",
            "And so basically we obtained a whole bunch of LAT candidate pairs.",
            "The reason we didn't obtain 16,000 is because questions have multiple laps, so that's why we see about 26,000 total lack and repairs.",
            "And this is our benchmark for testing and we evaluated these three type cores that use Wikipedia and DB pedia.",
            "The list category on the DB Pedia slash Chagatai code and what I'm showing you here are the precision recall scores for these three Tigers and what you can see is all of them do fairly well.",
            "Couple of interesting points.",
            "One is what surprised us was a list.",
            "I code has very good precision, much better than categories or Jago.",
            "There's something about the way that people nameless, Ann and put things in a list that makes them that precisely constructed.",
            "At least from my perspective.",
            "The other thing that was interesting in that category is actually provide pretty good type information.",
            "As on par with DB Pedia and Jago.",
            "And this probably makes sense because we're dealing with this open domain type checking what types are loosely defined, their words right and so categories are more like tags that people use and they provide useful information here, whereas DPR go obviously is more more well structured, has better semantics and so on.",
            "So they all provide sort of complementary information."
        ],
        [
            "And finally we evaluated the codes on Watson on Watson's performance end to end question, answering performance, and again we have two different configurations of Watson and Watson Light and Watson full.",
            "The Watson Light is the full framework of Watson, except there's no answer scoring at all, and the Watson full is we put in the answer scoring.",
            "For each of these configurations, what we did was we took out ticor and then we added these components one by one and saw how much impact they had.",
            "And this is also regard so on the left hand side you can see the results for Watson Light on the right is what's in full.",
            "The first blue bar that you see is the performance of Watson without any tie code.",
            "So you can see that for the Watson light case the accuracy is around 50% as you add in the list ticor accuracy goes up by about 3%.",
            "Separately, add in the category and the Yahoo.",
            "They go up by 4% and if you add in all three, you actually gain 5 to 6%.",
            "Yes question.",
            "This is each individual, yes, but the last thing is a combination of all three.",
            "So two key points, one is all gains over the note I court case are statistically significant in this case, and that as you can see for both the Watson Light and the Watson full combined gain of adding all three Tigers is better than anyone, so they actually complement each other quite nicely.",
            "And this game is 5 to 6%, which is pretty big.",
            "Just to give you a sense."
        ],
        [
            "How big this is is a quick charge not showing you.",
            "Those of you who attended the Watson total.",
            "We have seen this quite a few times.",
            "The dots there are performance or jeopardy.",
            "Windows and the red dots are the performance of graph of Ken Jennings.",
            "And what you can see on the X axis is the percentage of question answer like recall.",
            "And the Y axis is precision and the point simply is that the red line is the system without ticor.",
            "Once you Add all the tikosyn is a huge bump in performance and that can make a difference between being competitive with average Jeopardy players and being competitive with the best Jeopardy players."
        ],
        [
            "So, just to summarize, quickly we provide theoretical nice theoretical framework for doing type coercion, 2 core ideas.",
            "One St type is just another answer scoring feature.",
            "Don't do this hard filtering of types.",
            "We separated out the four steps in Ticor.",
            "Each of these steps produces a mapping between terms, either from unstructured to structure or structure to structure, and there's uncertainty associated with them, and you can use machine learning to combine these.",
            "Implementation we showed how we could use community built knowledge.",
            "Things like Wikipedia DB pedia in Jago in order to improve ticor and finally from an application standpoint, Tycoon has significant impact in QA and after all what's in one the Jeopardy Challenge.",
            "An also moving forward beyond jeopardy.",
            "We're looking at medical applications or Watson.",
            "Ann is another place where we hope to use a lot of type information, both semi structure as well as structured things like UML is another medical ontologies in there, so that's it.",
            "Thank you.",
            "Little stupid question, but how does like say question answering system like Siri from Apple compared to what Watson does?",
            "It's simplistic one.",
            "It's a control book domain it which is answering but just any your comments on that?",
            "No, I'm actually you answer the question.",
            "I mean for my we don't know too many details about Siri, but just from the face of it.",
            "It's obviously a much simpler version of Watson from what I've read, it works pretty well, but it's a very controlled setting, controlled vocabulary, very narrow set of commands that you can do.",
            "Watson obviously deals with much more complex language and many more topics than said he does, but I'm not sure I can say much more than that.",
            "But it is good to see that question answering is getting out there in the real world.",
            "The people actually seeing the value of this technology.",
            "So you said that the Wikipedia lists were most valuable former position standpoint.",
            "Yeah, and but then you wouldn't have any subclass relationships between these pseudo types.",
            "If you wish, right?",
            "So is this that subclass another kind of deeper representations of a type system are not that important?",
            "Or where do you see these things going in the long term?",
            "That's a good question.",
            "I think.",
            "To me it depends on how much redundancy is there in your type sources.",
            "So the reason you probably don't need subclasses for things like lists.",
            "And in categories we don't use a subclass hierarchy, the category hierarchy because it's pretty noisy, but the fact is people add multiple tags, multiple categories and they put things in multiple lists that are related.",
            "So if you have redundancy in your type information, if people express the same type in different ways, you can get by without using a strict class hierarchy.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm Aditya kalyanpur.",
                    "label": 0
                },
                {
                    "sent": "I'm from IBM research and a member of the team that built the Watson system that won the Jeopardy Challenge.",
                    "label": 0
                },
                {
                    "sent": "And I'm here to talk to you about type coercion in the Watson system and how we used Community built knowledge in order to improve type coercion.",
                    "label": 0
                },
                {
                    "sent": "Specifically, we use Wikipedia DB Pedia and Jago.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to talk about how these helped and this is work that I did with Bill Murdoch, James Fan and Chris Welty.",
                    "label": 1
                },
                {
                    "sent": "And if you heard.",
                    "label": 0
                },
                {
                    "sent": "Chris in the morning he said his name should be in a larger font size, so I changed that after hearing it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so a quick introduction on what is Watson or other?",
                    "label": 0
                },
                {
                    "sent": "Who is Watson?",
                    "label": 0
                },
                {
                    "sent": "Most of you know this Watson is an automatic open domain question answering system.",
                    "label": 0
                },
                {
                    "sent": "What probably most of you don't know is that Watson also won the Webby person of the Year award for 2011.",
                    "label": 1
                },
                {
                    "sent": "And this is interesting because the Webby Awards are given for Internet applications.",
                    "label": 0
                },
                {
                    "sent": "And when I think of an Internet app, I don't think of Watson immediately.",
                    "label": 0
                },
                {
                    "sent": "But I think what this shows is that we did use a lot of web knowledge in Watson, even though Watson was not connected to the Internet.",
                    "label": 0
                },
                {
                    "sent": "It used a lot of web knowledge sources like Wikipedia and so on.",
                    "label": 0
                },
                {
                    "sent": "So what the system does is a question answering system.",
                    "label": 0
                },
                {
                    "sent": "Given an input which is rich natural language questions, so the input is a question in plain text form, not a sparkle query.",
                    "label": 0
                },
                {
                    "sent": "The job of the machine is to understand the question.",
                    "label": 0
                },
                {
                    "sent": "Question can be over a broad domain of knowledge.",
                    "label": 1
                },
                {
                    "sent": "It could be on any topic and the idea then is to deliver a precise answer right?",
                    "label": 0
                },
                {
                    "sent": "So not just the document that contains the answer.",
                    "label": 0
                },
                {
                    "sent": "The exact answer to the question.",
                    "label": 0
                },
                {
                    "sent": "To do this very quickly and two other key points, one is to produce accurate confidences.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is that Watson should tell you how short it is that the answer is correct, and if Watson can produce a reliable confidence score, then you can trust the system better.",
                    "label": 0
                },
                {
                    "sent": "You know that the confidence is high.",
                    "label": 0
                },
                {
                    "sent": "The answer is probably correct.",
                    "label": 0
                },
                {
                    "sent": "If it's wrong, then you probably need to figure out why Watson was not confident and the related point here is justifications.",
                    "label": 0
                },
                {
                    "sent": "It would be nice if Watson can explain how it came up with the answer how we can justify what evidence did find for the answer.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we applied Watson to the Jeopardy Challenge.",
                    "label": 0
                },
                {
                    "sent": "An most of you know, Jeopardy is.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into details about the game, but basically what jeopardy does is first of all, it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a quiz show in the US it's very popular and they ask questions on a whole host of different topics.",
                    "label": 0
                },
                {
                    "sent": "An early challenges automatic QA technology because it pushes it along.",
                    "label": 0
                },
                {
                    "sent": "Five it test QA technology along five key dimensions.",
                    "label": 0
                },
                {
                    "sent": "First broad and open domain.",
                    "label": 0
                },
                {
                    "sent": "2nd is complex language.",
                    "label": 0
                },
                {
                    "sent": "They use puns, metaphors and so on in order confuse humans, which makes it very hard for a machine to correctly understand.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples of jeopardy questions.",
                    "label": 0
                },
                {
                    "sent": "And given the venue, I thought I'll take questions that involve Germany little bit, so I don't know how many of you know the answers to these questions.",
                    "label": 0
                },
                {
                    "sent": "The first one says Breakdown Germany and get this Sally whom Harry met on film.",
                    "label": 1
                },
                {
                    "sent": "The answer is Meg Ryan.",
                    "label": 0
                },
                {
                    "sent": "Because you can read it's an anagram for Germany.",
                    "label": 0
                },
                {
                    "sent": "Here's another question.",
                    "label": 0
                },
                {
                    "sent": "A map of Europe on this country's 1997 thousand lire coin had such errors as depicting Denmark as part of Germany.",
                    "label": 1
                },
                {
                    "sent": "The answer is Italy, and it's something you get just by seeing the thousand lire coin right.",
                    "label": 0
                },
                {
                    "sent": "And the point here is that there's a lot of redundant information in the question which humans can easily see, but a machine can go down the wrong path.",
                    "label": 0
                },
                {
                    "sent": "And here's a question I don't know how many of you know this $1000 question.",
                    "label": 1
                },
                {
                    "sent": "You don't have to pull the feathers of this chilly pink sparkling wine originally from Germany.",
                    "label": 0
                },
                {
                    "sent": "Does anybody know the answer to this?",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "No, it's cold duck.",
                    "label": 0
                },
                {
                    "sent": "Level order this.",
                    "label": 0
                },
                {
                    "sent": "Anyway, so the point is that in jeopardy they ask you questions like this that cover a whole range of different topics, extremely complicated language, and the machine in order to win at Jeopardy, has to be extremely precise, has to produce a reliable confidence score, and it has to be fast.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's look at the typing problem in jeopardy.",
                    "label": 0
                },
                {
                    "sent": "So you know the the the key point of this slide that in question Jeopardy.",
                    "label": 0
                },
                {
                    "sent": "Questions the answer type, right?",
                    "label": 0
                },
                {
                    "sent": "It varies a lot.",
                    "label": 0
                },
                {
                    "sent": "It can pretty much be any string in the English language, so you know some examples in the first question is asking for a kettle.",
                    "label": 0
                },
                {
                    "sent": "It's basically the question is it's basically a big cattle with a close fitting lid used to cook pot roast and stools.",
                    "label": 1
                },
                {
                    "sent": "He also.",
                    "label": 0
                },
                {
                    "sent": "So Dutch oven.",
                    "label": 1
                },
                {
                    "sent": "In the second question, they're asking for a scare fest, which is another word for a horror movie, so unlucky things happen at Camp Crystal Lake.",
                    "label": 0
                },
                {
                    "sent": "In this 1980s Scarefest.",
                    "label": 0
                },
                {
                    "sent": "The answer is Friday the 13th.",
                    "label": 0
                },
                {
                    "sent": "And the last question this question actually we got in the exhibition game that we played against Ken and Brad and Watson got this answer correct.",
                    "label": 0
                },
                {
                    "sent": "The question is wanted for general evilness last seen at the Tower of Murder is a giant eye folks kind of hard to miss.",
                    "label": 1
                },
                {
                    "sent": "Exactly, so it on an again here it's relatively easy for humans to do one if they know Lord the rings trivia.",
                    "label": 0
                },
                {
                    "sent": "They can make the connection.",
                    "label": 0
                },
                {
                    "sent": "They know that sort on is an eye, but for a machine to do this kind of type checking is extremely hard.",
                    "label": 0
                },
                {
                    "sent": "You're going to find a Dictionary of eyes with an instance of sword, right?",
                    "label": 0
                },
                {
                    "sent": "So the point is that in jeopardy these answer types vary a lot.",
                    "label": 0
                },
                {
                    "sent": "They go from very specific things to very vague things.",
                    "label": 0
                },
                {
                    "sent": "And what does not work is traditional techniques.",
                    "label": 0
                },
                {
                    "sent": "Traditional approaches in QA systems to do answer typing, and this does not work.",
                    "label": 0
                },
                {
                    "sent": "So this is something we don't do.",
                    "label": 0
                },
                {
                    "sent": "It's closed domain types.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sting and the idea is based on a type and generate principle.",
                    "label": 1
                },
                {
                    "sent": "What that means is you first figure out what are the interesting types in your domain in your application, and you come up with this list of types.",
                    "label": 0
                },
                {
                    "sent": "So you determine this beforehand.",
                    "label": 1
                },
                {
                    "sent": "Things like people, places, organizations.",
                    "label": 1
                },
                {
                    "sent": "For these types you run named entity recognizers over your corpus to pull out instances of these types.",
                    "label": 0
                },
                {
                    "sent": "And so you create these like a dictionary and then at runtime given a question, you detect what is the answer type in the question you map it to one of these types and then you generate candidates from this pre compiled list of instances.",
                    "label": 1
                },
                {
                    "sent": "So as you can see before, this cannot simply work for jeopardy, right?",
                    "label": 0
                },
                {
                    "sent": "It's lots of limitations.",
                    "label": 1
                },
                {
                    "sent": "The most obvious ones are it's very brittle, right?",
                    "label": 1
                },
                {
                    "sent": "The QA system breaks down if you can't recognize the type, right?",
                    "label": 0
                },
                {
                    "sent": "Related point is you need to you need to enumerate all the relevant types beforehand, right?",
                    "label": 0
                },
                {
                    "sent": "So it limits of coverage and also dependent on the quality of your name.",
                    "label": 0
                },
                {
                    "sent": "Denni, recognizers, right?",
                    "label": 0
                },
                {
                    "sent": "So Newton is also a town in Massachusetts, right?",
                    "label": 0
                },
                {
                    "sent": "So if it hasn't detected that, you're going to lose information.",
                    "label": 0
                },
                {
                    "sent": "So the approach we take is completely different and something that works really well.",
                    "label": 0
                },
                {
                    "sent": "And this is what I'm going to talk about here.",
                    "label": 0
                },
                {
                    "sent": "It's called open domain type coercion or tie code, and we sort of invert this principle.",
                    "label": 0
                },
                {
                    "sent": "What we say it's called generate and type.",
                    "label": 0
                },
                {
                    "sent": "So the idea is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You generate candidate answers without looking at the lexical answer type first.",
                    "label": 0
                },
                {
                    "sent": "You then go and find all possible type information that you can for a candidate and you check can that candidate be coerced into that.",
                    "label": 0
                },
                {
                    "sent": "So we do this secondary step later on, we don't filter candidates based on type.",
                    "label": 0
                },
                {
                    "sent": "Instead, we do this coercion later on.",
                    "label": 0
                },
                {
                    "sent": "We use a suite of type codes and algorithms and I'm going to talk about some of these in more detail.",
                    "label": 1
                },
                {
                    "sent": "And then we use machine learning to combine information from all these different types of algorithms.",
                    "label": 1
                },
                {
                    "sent": "So they wanted this compared to the previous system.",
                    "label": 0
                },
                {
                    "sent": "With some of this advantages, one is more flexible, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're curious system does not breakdown if you can't detect a meaningful type because it doesn't rely solely on time.",
                    "label": 0
                },
                {
                    "sent": "You don't filter answers based on type and you can get a much wider coverage of types by using this approach because you use a whole bunch of different sources and algorithms to go and find whether the candidate can be coerced into the type or not.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does this fit into the deep QA architecture into the Watson architecture?",
                    "label": 0
                },
                {
                    "sent": "So we actually had a Watson tutorial on Sunday, so some of you attended that.",
                    "label": 0
                },
                {
                    "sent": "You know about this and I'm just going to give you like a one minute sorry, one.",
                    "label": 0
                },
                {
                    "sent": "Slide overview of Watson at a very high level.",
                    "label": 0
                },
                {
                    "sent": "Just try to explain how Watson works with an example.",
                    "label": 0
                },
                {
                    "sent": "So let's say that Watson sees this question in 1698.",
                    "label": 0
                },
                {
                    "sent": "This comet discoverer took a ship called the Parramore Pink.",
                    "label": 1
                },
                {
                    "sent": "On the 1st purely scientific see voyage.",
                    "label": 0
                },
                {
                    "sent": "Now we know the answer to this question.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's correct.",
                    "label": 0
                },
                {
                    "sent": "So the first thing that wasn't as we analyze the question, we figure out what are the keywords.",
                    "label": 0
                },
                {
                    "sent": "What are the named entities?",
                    "label": 0
                },
                {
                    "sent": "What is the answer type?",
                    "label": 0
                },
                {
                    "sent": "The lexical answer type, which is a string in this case, is Comet Discoverer.",
                    "label": 0
                },
                {
                    "sent": "We plowed dates, we pull out any relationships that are in the questions we do some relationship detection.",
                    "label": 0
                },
                {
                    "sent": "And then we go and do a search based on our question analysis.",
                    "label": 0
                },
                {
                    "sent": "If you search lots of content related content, both unstructured and structured content, and generate a whole bunch of different candidate answers, then for each of these scanner answers Watson goes and finds supporting evidence for each of them, and then the score is this evidence along 500 different dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "And do some examples of the evidence to mentions lexical?",
                    "label": 0
                },
                {
                    "sent": "How good is there a lexical or keyword match between the passages found for a candidate and the question Tycho?",
                    "label": 0
                },
                {
                    "sent": "Or this is the code.",
                    "label": 0
                },
                {
                    "sent": "All of this talk, which is how is there a good type match between the candidate and the lexical answer type.",
                    "label": 0
                },
                {
                    "sent": "And as you can see here, Tyco is just another answer feature.",
                    "label": 0
                },
                {
                    "sent": "But this is 1 feature in a whole bag of different features that we use, and we let the machine learning assign weights to the different core features.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we don't do any filtering of candidates based on types we treat type is just another feature and we use a bunch of different type or algorithms so that I could.",
                    "label": 0
                },
                {
                    "sent": "Actually there is a block of different algorithms, so there's not just one type of feature, so there are many and they can sort of binary score is not 01.",
                    "label": 0
                },
                {
                    "sent": "It can be real value and there are other dimensions as well, like relations.",
                    "label": 0
                },
                {
                    "sent": "How well do the relations for the candidate match what is required in the question temporal in this case is a date in the question.",
                    "label": 0
                },
                {
                    "sent": "Does the candidate you know have a temporal matches it?",
                    "label": 0
                },
                {
                    "sent": "Doesn't make sense in the temporal context of the question, and so now you've analyzed this evidence along all these different dimensions, and we produce basically feature vectors for each of these dimensions, and we give this to a machine learning model.",
                    "label": 0
                },
                {
                    "sent": "That is being trained on previous questions.",
                    "label": 0
                },
                {
                    "sent": "And based on the training, it knows it has assigned weights to these different features, so it knows.",
                    "label": 0
                },
                {
                    "sent": "For example, there is a date in the clue.",
                    "label": 0
                },
                {
                    "sent": "You should trust the temporal mode and so on, and so the machine learning model then does a ranking of the answers and also comes up with confidence scores.",
                    "label": 0
                },
                {
                    "sent": "So come over the rank list of answers and in this case it means he is the correct answer, has a high confidence of .85.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So not digging going into that, I code framework input for the Tyco framework is just two strings.",
                    "label": 0
                },
                {
                    "sent": "The lexical answer type and the Canary.",
                    "label": 0
                },
                {
                    "sent": "And the job of the framework is to figure out can the candidate be coerced into the type and we break it.",
                    "label": 0
                },
                {
                    "sent": "Break down this type code framework in four steps.",
                    "label": 0
                },
                {
                    "sent": "We call them EDM.",
                    "label": 0
                },
                {
                    "sent": "Entity disambiguation matching.",
                    "label": 0
                },
                {
                    "sent": "PR type retrieval predicate disintegration matching and type alignment.",
                    "label": 1
                },
                {
                    "sent": "So here's an example of how these four steps work.",
                    "label": 0
                },
                {
                    "sent": "Let's say your candidate is a string.",
                    "label": 0
                },
                {
                    "sent": "JFK and your lexical answer type is a string facility.",
                    "label": 0
                },
                {
                    "sent": "So the job is to figure out.",
                    "label": 0
                },
                {
                    "sent": "Is JFK a kind of facility?",
                    "label": 0
                },
                {
                    "sent": "The first step we do is EDM, so we take this candidate string and we try to map it to some resource in some knowledge base and we use Wikipedia because it has excellent coverage.",
                    "label": 0
                },
                {
                    "sent": "For instance, is right, so we call this the EDM problem because it requires you to identify exactly what JFK means, another simulated as well.",
                    "label": 0
                },
                {
                    "sent": "Because JFK could mean different things in different contexts.",
                    "label": 0
                },
                {
                    "sent": "So in this example they show you.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have identified it as John F Kennedy International and there's also a score that you can see a .7.",
                    "label": 0
                },
                {
                    "sent": "And the point here is that.",
                    "label": 0
                },
                {
                    "sent": "This process produces not one entity, but a list of mappings with some uncertainties associated with them, and I'm just showing you the top mapping here in this example.",
                    "label": 0
                },
                {
                    "sent": "The next step is type retrieval.",
                    "label": 0
                },
                {
                    "sent": "So once we have these instances, we go and find types for them and we use a bunch of different sources.",
                    "label": 0
                },
                {
                    "sent": "Water them is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about this is DB Pedia and Jago Jago Ontology.",
                    "label": 0
                },
                {
                    "sent": "And in this case for example you can see that as a Yahoo type of airport and again in this step we don't produce just one type of a bunch of different types all with different scores.",
                    "label": 0
                },
                {
                    "sent": "So in this case it has a direct type of Jago.",
                    "label": 0
                },
                {
                    "sent": "Airports score of 1.",
                    "label": 0
                },
                {
                    "sent": "The third step is PDM, which is taking the lat and try to map that to a type.",
                    "label": 0
                },
                {
                    "sent": "And in this case, again, you have to do sense disambiguation because the word facility can mean different things.",
                    "label": 0
                },
                {
                    "sent": "In this case, let's say you mapped it to the word net sense of the physical facility.",
                    "label": 0
                },
                {
                    "sent": "Again, there's a score associated.",
                    "label": 0
                },
                {
                    "sent": "And finally we have a type matching problem.",
                    "label": 0
                },
                {
                    "sent": "You compare the type that you got from the lexical answer string and the type that we got from the candidate and compare those two.",
                    "label": 0
                },
                {
                    "sent": "And in this case it's quite straightforward, because actually there are links between YAGO and word net, so another good point about linked data.",
                    "label": 0
                },
                {
                    "sent": "You can exploit these links and in this case it's simple.",
                    "label": 0
                },
                {
                    "sent": "Airport is a kind of facility.",
                    "label": 0
                },
                {
                    "sent": "And you get a direct match and the final Tyco score is some combination of the four step scores and you could either take some heuristic combination like you could just multiply the four scores, or you could actually have a machine learning approach where you could make these 4 scores features in a model.",
                    "label": 0
                },
                {
                    "sent": "You could train it on data and you could learn weights for these four steps.",
                    "label": 0
                },
                {
                    "sent": "So with this framework you can do things like this.",
                    "label": 0
                },
                {
                    "sent": "Some examples of some interesting examples of what I code allows you to info.",
                    "label": 0
                },
                {
                    "sent": "You can say Ramadan is a month interpreter is a job, castling is a maneuver, and so on is.",
                    "label": 1
                },
                {
                    "sent": "And I right?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm going to talk about these steps in some more details, so the first is EDM.",
                    "label": 0
                },
                {
                    "sent": "This is a fundamental problem in NLP.",
                    "label": 0
                },
                {
                    "sent": "As you use entity string and you want to map it to some meaningful reference in a knowledge base and so for example the string link in the entity Abraham Lincoln can be represented in different places in different strings.",
                    "label": 0
                },
                {
                    "sent": "It could be called President Lincoln, Abe Lincoln, but conceptually they all mean the same person and you want to be able to make this connection.",
                    "label": 1
                },
                {
                    "sent": "And there are two big issues there.",
                    "label": 0
                },
                {
                    "sent": "The first synonymy right there are many different ways to say the same thing they have.",
                    "label": 1
                },
                {
                    "sent": "You know, spelling variations, aliases, nicknames, Gaddafi.",
                    "label": 0
                },
                {
                    "sent": "They think the 100 different ways to spell Gaddafi.",
                    "label": 0
                },
                {
                    "sent": "I don't know, I hope they got his spelling correct on his death certificate.",
                    "label": 0
                },
                {
                    "sent": "Polysomy this is another problem which is that this is another extremely hard problem for machine is you need to take this context into account in order to do the correct sentence immigration, right?",
                    "label": 0
                },
                {
                    "sent": "Because even the string JFK in different contexts can mean different things and humans are very good at figuring out what the sensors is.",
                    "label": 0
                },
                {
                    "sent": "Much harder for the machine to do.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way we use community built knowledge in EDM is we use it for both these steps for both matching as well As for disambiguation.",
                    "label": 0
                },
                {
                    "sent": "And here are some examples of the resources that we used for matching.",
                    "label": 0
                },
                {
                    "sent": "We use things like Wikipedia redirects, right?",
                    "label": 1
                },
                {
                    "sent": "So Mama redirected to Burma, so that gives you an alternate name for Bama.",
                    "label": 0
                },
                {
                    "sent": "We did things like we extracted synonyms and aliases and nicknames and stuff like that from the introductory paragraph of Wikipedia page, because that's a nice location where they actually specify these kinds of variants, so we could learn.",
                    "label": 0
                },
                {
                    "sent": "For example, IBM has a nickname of Big Blue.",
                    "label": 0
                },
                {
                    "sent": "We use the DB Pedia name labels.",
                    "label": 0
                },
                {
                    "sent": "There are over 100 different properties that specify.",
                    "label": 0
                },
                {
                    "sent": "Names in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And some of these are noisy and so the point is that you have all these different resources, but you can learn to weigh these differently, right?",
                    "label": 0
                },
                {
                    "sent": "So we give more weight to Wikipedia redirects because they're more precise.",
                    "label": 0
                },
                {
                    "sent": "Then repeat their name labels.",
                    "label": 1
                },
                {
                    "sent": "And then for disambiguation, we use primarily Wikipedia disambiguation pages, because it scored excellent coverage for different sensors an there are more than 2008 when we did this analysis, there were more than 15150 thousand disambiguation pages in DB pedia and to give an idea, Java, for example, has more than 20 distinct types, right?",
                    "label": 1
                },
                {
                    "sent": "So the point is that these disambiguation pages are an excellent inventory of sense information, because each of these different sensors has its own page with keywords on that page and links to.",
                    "label": 0
                },
                {
                    "sent": "Rated entities and type information.",
                    "label": 0
                },
                {
                    "sent": "All this contextual information that you can use when you're trying to do EDM an you what you want to do is measure the similarity between the contextual information in that sense repository with the contextual information in your for your data right in your text, and you can use different techniques for doing this.",
                    "label": 0
                },
                {
                    "sent": "You could use bag of words you could use LSA and so I'm not going to go into details of that, but the point is that Wikipedia is excellent, excellent repository for this kind of information.",
                    "label": 1
                },
                {
                    "sent": "And the output of EDM is a ranked list of entity resources.",
                    "label": 0
                },
                {
                    "sent": "In this case, the outputs are Wikipedia, ur eyes and the ranking is based on a combination of features I mentioned here.",
                    "label": 0
                },
                {
                    "sent": "So we look at the source where it came from.",
                    "label": 0
                },
                {
                    "sent": "Is it redirected to DB Pedia property?",
                    "label": 0
                },
                {
                    "sent": "We look at popularity of the entity using different kinds of metrics like link analysis and the contextual similarity as well for disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So we combine all this and again you could combine this juristically or using machine learning and.",
                    "label": 0
                },
                {
                    "sent": "Based on this, we produce an output of rank list of sources.",
                    "label": 0
                },
                {
                    "sent": "We evaluated our IDM algorithm on Wikipedia data.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is the way we set up this evaluation is we take a Wikipedia page which has links and it has anchor tags with links.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we remove the links on the anchor tag and we see can we get back the links using our technique and this is a traditional technique that other people have also used for valid for evaluating that EDM solution.",
                    "label": 0
                },
                {
                    "sent": "And what we've got is state of the art performance with pretty high precision and recall scores.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The next step is type retrieval.",
                    "label": 0
                },
                {
                    "sent": "So again, now that you mapped your candidate string to some instance in a knowledge base, you want to find types for these, we use a whole bunch of different types sources.",
                    "label": 0
                },
                {
                    "sent": "Things like word, net, Wikipedia lists, categories, YAGO, Ontology, and also the automatically mind text.",
                    "label": 1
                },
                {
                    "sent": "And the point here is that these sources also have varying precision and recall, right?",
                    "label": 0
                },
                {
                    "sent": "So for example, word NET is extremely precise, but it doesn't have good recall, whereas something like the automatically mintex types that we get from text.",
                    "label": 0
                },
                {
                    "sent": "How much better recall?",
                    "label": 0
                },
                {
                    "sent": "But they suffer from noise.",
                    "label": 0
                },
                {
                    "sent": "Some interesting points here is that the type systems are linked.",
                    "label": 1
                },
                {
                    "sent": "So as I mentioned earlier, that links between Yahoo and Word Net so we can leverage this because if you're type from your lat points to one type system and the type that comes from the counters in a different type system, you can use links between these two, come up with the final ticor score.",
                    "label": 0
                },
                {
                    "sent": "The wiki categories and lists contain extra sort of modifier information about types, so they contain sort of fine grained type information that you can use.",
                    "label": 0
                },
                {
                    "sent": "So for example, the categories for Ryan Center German inventor.",
                    "label": 0
                },
                {
                    "sent": "Swiss vegetarian patent examiner and so on.",
                    "label": 0
                },
                {
                    "sent": "And the point is that when we are matching the types in a question, we can look not just at the main word of the type but also the modifyers and match them separately.",
                    "label": 1
                },
                {
                    "sent": "And also another key issue here is that the automatically mind types reflect real world usage.",
                    "label": 0
                },
                {
                    "sent": "The way people actually use types, right?",
                    "label": 0
                },
                {
                    "sent": "So, for example, fluid is a liquid is something that we get from text because people use these terms interchangeably, though strictly speaking semantically this other way around, right liquid is a kind of fluid.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Without step is PDM predicate disambiguation and matching.",
                    "label": 1
                },
                {
                    "sent": "So this is like the word sense disambiguation problem.",
                    "label": 0
                },
                {
                    "sent": "You have a concept award which represents a concept and you want to map it to the right sense.",
                    "label": 0
                },
                {
                    "sent": "So for example, if the lexical answer type is star, it could mean either the astronomical object or the celebrity.",
                    "label": 0
                },
                {
                    "sent": "And again you have to look at the context to figure out.",
                    "label": 1
                },
                {
                    "sent": "You know what concept it means, and it's very similar in principle to entity disintegration.",
                    "label": 1
                },
                {
                    "sent": "Matching the main difference is that in the DMS you're mapping a named entity to some instance in a knowledge base.",
                    "label": 0
                },
                {
                    "sent": "In PDM you're mapping or generic noun or a class to some concept or type in a knowledge base.",
                    "label": 0
                },
                {
                    "sent": "The techniques that we use in deep QA, two things.",
                    "label": 0
                },
                {
                    "sent": "One is, we have again an algorithm to map these lexical answer types toward net concepts based on the context and also using the rank information that's there in Word net and one of the interesting point is we also pull in lat types that are statistically related in DB pedia.",
                    "label": 1
                },
                {
                    "sent": "So the idea here is that if you get the latter brand, we also compute how often is the case in DB pedia that an instance of type brand also has the instance of type product.",
                    "label": 0
                },
                {
                    "sent": "And we see that so this conditional probability is very high.",
                    "label": 0
                },
                {
                    "sent": "It's about some threshold.",
                    "label": 0
                },
                {
                    "sent": "Right, so the point in this case it's like .8 three.",
                    "label": 0
                },
                {
                    "sent": "So the point is, if you see that type of brand, we can also pull in related that type of product.",
                    "label": 0
                },
                {
                    "sent": "By doing this kind of statistical analysis over DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And last step is type alignment.",
                    "label": 1
                },
                {
                    "sent": "Again, you compare to compare two sets of types.",
                    "label": 0
                },
                {
                    "sent": "We use a bunch of different type heuristics.",
                    "label": 1
                },
                {
                    "sent": "For example, the obvious one is a direct equivalence class match or a subclass match.",
                    "label": 0
                },
                {
                    "sent": "So if your lattice a facility and your candidate type is an airport, you got a strong match your sibling matches.",
                    "label": 0
                },
                {
                    "sent": "So you know the lack type in the candidate.",
                    "label": 0
                },
                {
                    "sent": "Have siblings you know type system will give a lower score and so on.",
                    "label": 1
                },
                {
                    "sent": "One interesting thing is the notion of disjoint types.",
                    "label": 0
                },
                {
                    "sent": "So here the idea is that if your laptop is train station and a candidate type is aerodrome that is disjoint.",
                    "label": 0
                },
                {
                    "sent": "So this place it produces a negative type match and this is a separate signal in deep QA separate feature in our model we call it the anti code feature antique or an.",
                    "label": 0
                },
                {
                    "sent": "This feature gets a negative weight in the model and it helps push down candid answers that don't match the correct type.",
                    "label": 0
                },
                {
                    "sent": "And so, in order to do this kind of disjoint reasoning, we had to add disjointness axioms in Jago, because Yahoo does not have disjointness, and we did this in a reasonably smart way.",
                    "label": 0
                },
                {
                    "sent": "Yahoo is a very big ontology, it has more than 100,000 types, so we didn't add pairwise disjoint between all the types that we thought were disjoint.",
                    "label": 0
                },
                {
                    "sent": "We added distance at a high level in the taxonomy, and then we just propagated disjoints down using reasoning simple reasoning.",
                    "label": 0
                },
                {
                    "sent": "So for example, if Organism is disjoint with geopolitical entity, than any subclass of organisms respond with any subclasses.",
                    "label": 0
                },
                {
                    "sent": "Jeep.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "So putting it all together, the final Tyco scores.",
                    "label": 1
                },
                {
                    "sent": "As I said, some combination of the four step scores.",
                    "label": 0
                },
                {
                    "sent": "One thing you'll note is that if you take this combination as a simple product, your final Tyco score will be 0.",
                    "label": 1
                },
                {
                    "sent": "If any of the step fails, so the two options one is, you can consider doing some kind of smoothing so you put non 0 scores.",
                    "label": 0
                },
                {
                    "sent": "Another thing that we found interesting and works well is you actually expose which step failed to your model.",
                    "label": 1
                },
                {
                    "sent": "So you add special features for like a EDM failure and a PDM failure.",
                    "label": 0
                },
                {
                    "sent": "The model can learn how to weigh these features.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, anti corza separate signal that we had.",
                    "label": 0
                },
                {
                    "sent": "So this is an interesting case.",
                    "label": 0
                },
                {
                    "sent": "When the type alignment score is minus one, we had a separate feature to the model and what this does is it helps push down candidates whose types are incompatible with the lexical answer type.",
                    "label": 0
                },
                {
                    "sent": "And there's another point is if you have multiple laps in the question, you need some way to come up with the final Tyco score.",
                    "label": 0
                },
                {
                    "sent": "What we do is we take a weighted sum of the lack confidence and the respective Tyco scores for each of those lats.",
                    "label": 0
                },
                {
                    "sent": "So that Igor algorithm Sweden dqa has around 14 takeovers, three of which that use Wikipedia and DB pedia Ticos follow these four core steps and each Tyco score is a separate separate feature in the model.",
                    "label": 1
                },
                {
                    "sent": "The model can learn how to weigh in comparison with the other features and known to balance the weights on these features.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the evaluation, I'm going to talk about two sets of evaluations.",
                    "label": 0
                },
                {
                    "sent": "The first is evaluating how the Tyco is do on ground truth.",
                    "label": 1
                },
                {
                    "sent": "So what this means is how well the Ticos do on checking if a candidate is an instance of a type.",
                    "label": 0
                },
                {
                    "sent": "This is not part of a QA task, but this is just separately the entity type matching problem.",
                    "label": 0
                },
                {
                    "sent": "So in order to do this we created a benchmark from jeopardy.",
                    "label": 0
                },
                {
                    "sent": "We took around 1600 Jeopardy questions.",
                    "label": 0
                },
                {
                    "sent": "We identified the lexical answer type for each of them.",
                    "label": 0
                },
                {
                    "sent": "And we took the top ten candidate answers that Watson came up with for these questions.",
                    "label": 0
                },
                {
                    "sent": "And just to be clear, we took a version of Watson that did not have Vicodin it to take these top 10 answers because we want to bias our sample in anyway, and then for each of these top ten candidates we did a manual judgment.",
                    "label": 0
                },
                {
                    "sent": "Does the candidate mass a lot or not?",
                    "label": 1
                },
                {
                    "sent": "And so basically we obtained a whole bunch of LAT candidate pairs.",
                    "label": 0
                },
                {
                    "sent": "The reason we didn't obtain 16,000 is because questions have multiple laps, so that's why we see about 26,000 total lack and repairs.",
                    "label": 0
                },
                {
                    "sent": "And this is our benchmark for testing and we evaluated these three type cores that use Wikipedia and DB pedia.",
                    "label": 0
                },
                {
                    "sent": "The list category on the DB Pedia slash Chagatai code and what I'm showing you here are the precision recall scores for these three Tigers and what you can see is all of them do fairly well.",
                    "label": 0
                },
                {
                    "sent": "Couple of interesting points.",
                    "label": 0
                },
                {
                    "sent": "One is what surprised us was a list.",
                    "label": 0
                },
                {
                    "sent": "I code has very good precision, much better than categories or Jago.",
                    "label": 0
                },
                {
                    "sent": "There's something about the way that people nameless, Ann and put things in a list that makes them that precisely constructed.",
                    "label": 0
                },
                {
                    "sent": "At least from my perspective.",
                    "label": 0
                },
                {
                    "sent": "The other thing that was interesting in that category is actually provide pretty good type information.",
                    "label": 0
                },
                {
                    "sent": "As on par with DB Pedia and Jago.",
                    "label": 0
                },
                {
                    "sent": "And this probably makes sense because we're dealing with this open domain type checking what types are loosely defined, their words right and so categories are more like tags that people use and they provide useful information here, whereas DPR go obviously is more more well structured, has better semantics and so on.",
                    "label": 0
                },
                {
                    "sent": "So they all provide sort of complementary information.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally we evaluated the codes on Watson on Watson's performance end to end question, answering performance, and again we have two different configurations of Watson and Watson Light and Watson full.",
                    "label": 0
                },
                {
                    "sent": "The Watson Light is the full framework of Watson, except there's no answer scoring at all, and the Watson full is we put in the answer scoring.",
                    "label": 1
                },
                {
                    "sent": "For each of these configurations, what we did was we took out ticor and then we added these components one by one and saw how much impact they had.",
                    "label": 0
                },
                {
                    "sent": "And this is also regard so on the left hand side you can see the results for Watson Light on the right is what's in full.",
                    "label": 0
                },
                {
                    "sent": "The first blue bar that you see is the performance of Watson without any tie code.",
                    "label": 0
                },
                {
                    "sent": "So you can see that for the Watson light case the accuracy is around 50% as you add in the list ticor accuracy goes up by about 3%.",
                    "label": 0
                },
                {
                    "sent": "Separately, add in the category and the Yahoo.",
                    "label": 0
                },
                {
                    "sent": "They go up by 4% and if you add in all three, you actually gain 5 to 6%.",
                    "label": 0
                },
                {
                    "sent": "Yes question.",
                    "label": 0
                },
                {
                    "sent": "This is each individual, yes, but the last thing is a combination of all three.",
                    "label": 0
                },
                {
                    "sent": "So two key points, one is all gains over the note I court case are statistically significant in this case, and that as you can see for both the Watson Light and the Watson full combined gain of adding all three Tigers is better than anyone, so they actually complement each other quite nicely.",
                    "label": 1
                },
                {
                    "sent": "And this game is 5 to 6%, which is pretty big.",
                    "label": 0
                },
                {
                    "sent": "Just to give you a sense.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How big this is is a quick charge not showing you.",
                    "label": 0
                },
                {
                    "sent": "Those of you who attended the Watson total.",
                    "label": 0
                },
                {
                    "sent": "We have seen this quite a few times.",
                    "label": 0
                },
                {
                    "sent": "The dots there are performance or jeopardy.",
                    "label": 0
                },
                {
                    "sent": "Windows and the red dots are the performance of graph of Ken Jennings.",
                    "label": 0
                },
                {
                    "sent": "And what you can see on the X axis is the percentage of question answer like recall.",
                    "label": 0
                },
                {
                    "sent": "And the Y axis is precision and the point simply is that the red line is the system without ticor.",
                    "label": 0
                },
                {
                    "sent": "Once you Add all the tikosyn is a huge bump in performance and that can make a difference between being competitive with average Jeopardy players and being competitive with the best Jeopardy players.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, just to summarize, quickly we provide theoretical nice theoretical framework for doing type coercion, 2 core ideas.",
                    "label": 0
                },
                {
                    "sent": "One St type is just another answer scoring feature.",
                    "label": 1
                },
                {
                    "sent": "Don't do this hard filtering of types.",
                    "label": 0
                },
                {
                    "sent": "We separated out the four steps in Ticor.",
                    "label": 0
                },
                {
                    "sent": "Each of these steps produces a mapping between terms, either from unstructured to structure or structure to structure, and there's uncertainty associated with them, and you can use machine learning to combine these.",
                    "label": 0
                },
                {
                    "sent": "Implementation we showed how we could use community built knowledge.",
                    "label": 1
                },
                {
                    "sent": "Things like Wikipedia DB pedia in Jago in order to improve ticor and finally from an application standpoint, Tycoon has significant impact in QA and after all what's in one the Jeopardy Challenge.",
                    "label": 1
                },
                {
                    "sent": "An also moving forward beyond jeopardy.",
                    "label": 1
                },
                {
                    "sent": "We're looking at medical applications or Watson.",
                    "label": 0
                },
                {
                    "sent": "Ann is another place where we hope to use a lot of type information, both semi structure as well as structured things like UML is another medical ontologies in there, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Little stupid question, but how does like say question answering system like Siri from Apple compared to what Watson does?",
                    "label": 0
                },
                {
                    "sent": "It's simplistic one.",
                    "label": 0
                },
                {
                    "sent": "It's a control book domain it which is answering but just any your comments on that?",
                    "label": 0
                },
                {
                    "sent": "No, I'm actually you answer the question.",
                    "label": 0
                },
                {
                    "sent": "I mean for my we don't know too many details about Siri, but just from the face of it.",
                    "label": 0
                },
                {
                    "sent": "It's obviously a much simpler version of Watson from what I've read, it works pretty well, but it's a very controlled setting, controlled vocabulary, very narrow set of commands that you can do.",
                    "label": 1
                },
                {
                    "sent": "Watson obviously deals with much more complex language and many more topics than said he does, but I'm not sure I can say much more than that.",
                    "label": 0
                },
                {
                    "sent": "But it is good to see that question answering is getting out there in the real world.",
                    "label": 0
                },
                {
                    "sent": "The people actually seeing the value of this technology.",
                    "label": 0
                },
                {
                    "sent": "So you said that the Wikipedia lists were most valuable former position standpoint.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and but then you wouldn't have any subclass relationships between these pseudo types.",
                    "label": 0
                },
                {
                    "sent": "If you wish, right?",
                    "label": 0
                },
                {
                    "sent": "So is this that subclass another kind of deeper representations of a type system are not that important?",
                    "label": 0
                },
                {
                    "sent": "Or where do you see these things going in the long term?",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "To me it depends on how much redundancy is there in your type sources.",
                    "label": 0
                },
                {
                    "sent": "So the reason you probably don't need subclasses for things like lists.",
                    "label": 0
                },
                {
                    "sent": "And in categories we don't use a subclass hierarchy, the category hierarchy because it's pretty noisy, but the fact is people add multiple tags, multiple categories and they put things in multiple lists that are related.",
                    "label": 0
                },
                {
                    "sent": "So if you have redundancy in your type information, if people express the same type in different ways, you can get by without using a strict class hierarchy.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}