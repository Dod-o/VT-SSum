{
    "id": "c6dt7viv5ihbkqsaa4wcyuvp5kvhm2nn",
    "title": "Dynamic Time Warping\u2019s New Youth",
    "info": {
        "author": [
            "Xavier Anguera Miro, ELSA Corp"
        ],
        "recorded by": [
            "IEEE ICME"
        ],
        "published": "Sept. 18, 2012",
        "recorded": "July 2012",
        "category": [
            "Top->Computer Science",
            "Top->Computer Science->Digital Signal Processing"
        ]
    },
    "url": "http://videolectures.net/icme2012_anguera_time_warping/",
    "segmentation": [
        [
            "My speech today is going to be about dynamic time warping Newth.",
            "And."
        ],
        [
            "Gallon of the talk will be first.",
            "To see if there was anything before dynamic time warping, we will review a little bit.",
            "For those of you that maybe a little old and maybe don't remember already or lose your points and say what is?",
            "That will be what the networking is.",
            "Then of course, here comes HMMS.",
            "That's what destroyed dynamically working at the 80s.",
            "Then everything working come back I'm gonna tell him of what has come.",
            "In the last few years that maybe would be useful for the community between algorithms, speed and scalability applications, and then finally I'll conclude with some conclusions and future trends that we can observe so."
        ],
        [
            "Before then, everything working.",
            "How would people do speech processing?",
            "How will people do speech recognition for example?",
            "Well, before that, I'm talking about the 50s, the 40s at beginning of the 60s, people were trying to match patterns, predefined patterns, small sequences of of.",
            "Values that they would capture with very regimented microphones.",
            "They will try to match them with the input they would get from these microphones to try to see what the words or sequences of words were said by the user.",
            "Something in that, nothing like connected speech recognition or anything like that but just digits.",
            "Simple words, commands, things that were able to be done at that time.",
            "Remember, you know that time computers were kind of elementary.",
            "We were programming with cars.",
            "We know they were provided with parts of you.",
            "I was not even alive.",
            "At that time.",
            "Alex, what would happen when there were sequences?",
            "Our speeches are very varietal, very nonlinear signal, which means that sometimes we pronounce about a little longer than than another time, and sometimes a little shorter concerns etc etc.",
            "For example, here we have an example of hello where this is my voice.",
            "In the first one I said hello in a normal way.",
            "Here I said hello and of course the E is much longer.",
            "How do you match that?",
            "Well, some people were trying to do some linear normalization of these signals, but of course once they were matching.",
            "Help me watching this part with this part.",
            "This part was too short or the other way around so they couldn't get it, and linear mapping between the two sounds, so that's why the night time warping came and try to solve this thing, make a nonlinear mapping of two sequences of symbols or the sequences of data to try to match them up again to try to compare them better."
        ],
        [
            "So a little more mathematically described diameter working would be optimal if I will find a lot of alignment between two sets of symbols of the set of data X&Y, which are can be the dimensional International Space, we can have feature vectors there, or we can just have audio audio samples and we're trying to find optimal mapping by allowing some inclusions or or some deletions.",
            "Between the timing of the points.",
            "Talulah"
        ],
        [
            "We normally compute this similarity matrix.",
            "We have one single.",
            "He run sequence here, one sequence here and we try to find the optimal alignment which will be this function F which is a nonlinear mapping between the starting point of 1 scene of 1 sequence with the ending point of the other sequence.",
            "To do that we have to define this set this matrix which is similarity matrix according to some distance D. We can use the median distance we can use.",
            "Doctoral normalizer product anything you can think of to build this matrix and then with dynamic programming we can find this optimal path from start to end.",
            "So that's all this is Larry working.",
            "This is so so."
        ],
        [
            "Evil.",
            "In order to make this feasible and to write a speech, there is some constraints that were imposed.",
            "The first of those is automatically, which means that the working path is always increasing or you know the problem with the same values or increasing values you don't know.",
            "You don't go back in speech to myself in the voice already previous.",
            "So local constraints, which means for a given point, which possible points from before, we can come from this is the constraints that were proposed by the initial one of the initial papers, which is the security of paper 1978.",
            "And then I know that later on dropping a proposed some other constraints that were also useful for speech recognition."
        ],
        [
            "I'm further on those were local constraints.",
            "We can apply some global constraints because of course if you have these two signals and this is speech, you might consider that maybe speaking I'm gonna start watching here and go over, you know and stop warping alot.",
            "A little at the end, so you can apply some global constraints there to say, OK, my work is going to be bounded between.",
            "Maybe this security aren't all between these.",
            "Around so I'm not going to get out.",
            "My is my order.",
            "You will not get out of this band so I don't need to compute all this data.",
            "I just compute the center thing and unbound my search on there.",
            "So."
        ],
        [
            "In order to put your little bit in context.",
            "There is some signal work that was done on dynamic time warping.",
            "Two of the domain works and the most known I would say are these two.",
            "Here the first one that I could not find.",
            "Imprinting, if any of you knows of their existence, please send it to me.",
            "But I know it exists.",
            "It's referenced in papers from 20 years ago.",
            "So is this paper from 1971 the first one where the Sequoia and she started talking about that every time?",
            "Warping another paper that everybody has everybody knows he's a 1978 transactions on our streets and signal processing paper that where they redefined all they talk about everything working and they talk about these bands is constrained.",
            "Global constraints now when I was studying these papers and I was looking a little bit at the River fee, somebody pointed me out to hey, maybe this this is not the first word that actually talked about that everything working or something similar to that and they gave me a couple references."
        ],
        [
            "One of them is the one here and I was really surprised this is.",
            "Those previous ones were from Japan.",
            "This is Russian gentleman.",
            "1968 already had a paper about something that is similar to dynamic time warping in this case in this paper, but very mathematical paper she's talking about.",
            "The similar between a speech synthesis so that it's all other warping of the speech synthesis, like periods to make sympathies longer or shorter.",
            "In this case against a minimum length reference pattern.",
            "So the minimum minimal pattern that you would like to match too, and he's warping it, so allowing only inclusion.",
            "So repetitions of some of the period thing here in order to match an input query.",
            "So this is kind of the first.",
            "I would say reference to what we call now dynamical working that exist in the literature further on."
        ],
        [
            "I found another Russian, actually two Russians here.",
            "These guys were even Martina Mass Institute in Siberia.",
            "I don't know if they were there for other reasons and then math, but they were United 70 and this is actually.",
            "This is one of the plus from their paper.",
            "This is actually a similarity matrix photodynamic.",
            "I'm working where they where.",
            "They allow insertion Zelda lesions.",
            "They allow exact matching between one point and the other sequence one sequence sequence too.",
            "So this.",
            "For me is the exact paper the first instance of dynamic time warping that exists in the literature?",
            "I'm sorry for Sequoia Shiba, no.",
            "The only time warping DTW for short was has not left until today.",
            "As Diablo.",
            "You know, we use for speech recognition.",
            "Why, well in the 80s?"
        ],
        [
            "There were some people, and particularly first of them guy called or a gentleman called Bomb from the palm oil job or even done saying hey, we have something called Hmm's.",
            "We have machines have memory.",
            "We can store models.",
            "We can do some statistical processing on them.",
            "Why don't we try training states?",
            "OK training models to different states.",
            "So returning like arrows and some progress and arrows.",
            "With this we can decode the signal and we can do this warming effect, but without having patterns that we match with.",
            "So then some people like Robin are one.",
            "They started working on it.",
            "They progressed a lot and since then we forgot about everything worry.",
            "So nowadays we get a lot of data.",
            "We got lots of paid students to label these data, so we have all the phonemes we have.",
            "Everything very well labeled and we train these models and we get fantastic.",
            "Result, and that's why we got fantastic results.",
            "I mean, sometimes we would like to get 100%, we don't.",
            "We have city and we have things at work, right?",
            "Now."
        ],
        [
            "Let's see, that's a little comparison between ASR using Hmm's and using the W. So we dynamically working.",
            "Remember we have to have patterns which are matching.",
            "So we have our set of patterns.",
            "So these are some examples.",
            "You know we don't need to label them, we just know that this is hello, this is goodbye, you know and we just try to match them with our with our test data.",
            "On the other hand, hidden Markov models.",
            "They need a lot of training data.",
            "They need to.",
            "We need to label them well.",
            "We need to train our models.",
            "Now when training our models dynamic.",
            "'cause we have to use some algorithm that trade and it's maybe slowly.",
            "It takes a few days, but once it's training the test is very fast.",
            "We use with Terry and whom we have result.",
            "We have matching's.",
            "On the other hand I have everything working.",
            "We don't need any training, we just have the the batteries.",
            "But we might have 100,000 patterns.",
            "So at Test time it takes time to myself and find whatever pattern is best.",
            "Movies at anytime we come achieve the mid to high accuracy we can get pretty High Priest nowadays much into patterns with hidden Markov models.",
            "Depending on the acoustic conditions of course on the matching of the acoustics with the training, but we can have pretty high accuracy.",
            "So bottom line people abandons them into working for ASR and that has been the rule.",
            "For most researchers I would say except these guys here.",
            "These are these are from the Netherlands.",
            "This paper is the first one that appeared in 2007 that they do ASR with dynamic time warping, so is hard with matching in their case of phoneme based sequences and this is a group of 3rd party component.",
            "Pronounce it well, OK, and it's very interesting work to look at, but I'm not going to talk about.",
            "Start in the way they do.",
            "I'm going to talk about then everything working in another way which."
        ],
        [
            "Describe it always is.",
            "Diablo.",
            "Like I'm going to talk about the only thing working to solve these problems.",
            "So what will happen if you have a language where you don't have many speakers or happens at your language doesn't have much economical power in the world is a lot of small country, so you cannot pay a lot of students to label your data.",
            "Or at least see the label there later, so you will have no transcriber in data.",
            "You might know, dictionaries.",
            "You might not even have knowledge of the linguistic content and this happened.",
            "Yes.",
            "African languages.",
            "Indonesian language is lots of languages in the world.",
            "Actually there is only a few languages that do have plenty of resources for ASR.",
            "There is lots of dollars that don't.",
            "So what can you do with this?",
            "How we still do something?",
            "How you still drive some knowledge extraction knowledge from that?",
            "Yes we can and."
        ],
        [
            "That's how we say dynamic networking come back.",
            "Now.",
            "Process of dynamic time working for this task is yes, we can.",
            "We work with patterns.",
            "We don't need any knowledge about labeling.",
            "We don't need any knowledge about the language to try to extract something, but what a big problem.",
            "Dynamic time warping us.",
            "If you remember from the definition works from the beginning of a pattern to the end of a pattern.",
            "We need to know the beginning and the end of the patterns in order to match.",
            "So cases like this."
        ],
        [
            "For example, when we have maybe two sequences and we know that only or we want to find whether something inside is matching or one big sequence, and we want to find repetitions of words that might be several times that's complicated.",
            "OK, so."
        ],
        [
            "How do you solve that?",
            "People started looking at it, started thinking about it and said OK, can we modify dynamic time warping to try to work on the settings so that we don't have to define these stand on end points so you know in the case of dynamic standard and everything we would match from here to here and from here to here which wouldn't normally match anything.",
            "So for this reason they appeared several algorithms in here.",
            "I have five of them and I'm sure there's couple more around that try to find this subsequence matching using dynamic time warping derived algorithms.",
            "So we have the segmental DTW image.",
            "Basically W motive discovery if it only for music and unbounded only.",
            "I'm going to briefly very briefly 'cause if not Mark's, gonna give me up.",
            "Talk to you up."
        ],
        [
            "Them because I think they are very interesting.",
            "First of all, people said mentality value.",
            "This was initialized, initialized.",
            "Buy in MIT in around 2006.",
            "With that, remember we have these two sequences long sequences, one here and one here, and they exhaustively search.",
            "Along time along the two sequences for subsequences matching in the two subject in the two sequences.",
            "So they get these bonds and for each family trying to find if there is any subsequence matching.",
            "This is kind of computationally intensive.",
            "This is."
        ],
        [
            "I later on I just at the John Hopkins.",
            "There was an injunction and company that started thinking, can we make it faster and they did make it faster using some image based techniques.",
            "In this case, this is the first paper that they wrote or no one of the first papers they broke.",
            "They use half transform.",
            "Any much technique to find diagonals to quickly spot if there is any.",
            "Like in here you see that there is this kind of diagonal here to find if there is any subsequences that might be matching.",
            "And that might could be approximately a make approximately at a diagonal line, and then once they have these areas then they do a segmental DTW to find exactly the the matching path."
        ],
        [
            "Other people, and we're going to France now.",
            "We jump from US to France.",
            "Other people have done similar things.",
            "This is for broadcast news.",
            "This is a most cardiolog younger here at Trent University and they are looking in broadcast news within a window of two 3 minutes.",
            "Which words are repeated within this window?",
            "I'm not going to go into the details.",
            "You can find the paper easily on the web."
        ],
        [
            "Similarly, now we jump to music we have may not murder.",
            "Has been working with finding time to find general matching or general structure analysis of songs by finding.",
            "Also this is a movie, a similarity matrix over some self similarity metrics.",
            "Finding these areas where the song is most similar between them.",
            "So in a song you can imagine that we normally repeat end of paragraphs or repeat things in the song.",
            "So here he finds the peaks of these repetitions.",
            "And then expense them in one side on the other to find similarity pass or to find warping pass so subsequences and match.",
            "This can be also applied for speak with no problem."
        ],
        [
            "And finally, here is my algorithm they presented couple years ago, maybe three years, and then where I say OK, people want to have to compute all these big similarity matrix for a 4 two subsequences A&BI don't want to do that.",
            "So can I do the same with my just subsample this similarity matrix matrix?",
            "So you hear this point is the only points I compute from dissimilarity matrix access subsample it with a minimum distance, so that I will not loose.",
            "Any any working path, any similarity working back and then?"
        ],
        [
            "They do for each of the points I check if there is a working path in the two directions.",
            "So with that I can find also the the path and I save about 5060% of the computation of the similarity matrix.",
            "Still dynamic programming has to be the same, or maybe a little more costly.",
            "Now."
        ],
        [
            "So much some of you might say, well, very nice, very good.",
            "But Hmm's are faster.",
            "Victory is very fast.",
            "We can do this very fast.",
            "You have nothing to do in here.",
            "Well, we had the same thing you wanted me to be controversial.",
            "You would have done the same thing and that's why people started thinking about it and started proposing algorithms.",
            "And these are some of them.",
            "So people have thought OK, can we dissimilarity matrix?",
            "Can we make it smaller?",
            "Can we do a course to find the matching and that's the paper from Salvadoran Chan in 2004 that started looking into that.",
            "OK, can we do a fast matching and then when we know an area then we we we going in until we find the exact matching working part?",
            "Or we can also do an intelligent bound of the dynamic time warping.",
            "We don't need to compute everything.",
            "We can just focus on on the areas where we think we might have some matching.",
            "There is interesting word by human Kirk on the stand on the traditional DTW.",
            "Lots of work from him rings.",
            "It's worth to take a look at it and work from Zenon Glass from MIT.",
            "Also looking at bounding bounding regions do not compute all the all the similarity values.",
            "I'm finally very interesting word from.",
            "Jason and John Hopkins trying to use MSH and similar techniques to do an information retrieval approach to dynamic time warping so that we don't compute the whole similarity matrix and we might do this matching much faster, so this is something worth looking at."
        ],
        [
            "Now.",
            "Finally two to finalize my talk.",
            "OK, you know we can match, but how do we use it?",
            "I mean like in nature and we don't want other ways how we don't want to compete with HMMS.",
            "We know they're there for a reason.",
            "But we can do things and we know that there is killer applications out there to be used for dynamic time warping.",
            "This is just a few of them.",
            "Maybe we can find structure.",
            "As I said in a language which we don't know anything about and we can find a structure in the language find like a child learns a new language, try to extract something from it by just looking at it or listening to it.",
            "We can also even learn ASR models, help ASR, but learning models initially from this language without knowing any transcription.",
            "And that's what's done in the Jackson 2011 paper.",
            "I have the references at the end.",
            "We can also do even some natural language processing directly on the acoustics if you can find the repetitions, we can do some kind of TF IDF.",
            "We can compare documents we can see which documents are similar.",
            "We can put them into topics etc etc.",
            "That's very interesting down my dress day in 2010.",
            "We can do some query by example search like in the mid medieval evaluation.",
            "Where we have queries and we search for them in a big database.",
            "Last year we did it on Indian languages, languages that I could not even understand, but my system could.",
            "We can do some spoken term discovery as I spoke about most Carrero and Gravier and some spoken summarization.",
            "Very interesting work.",
            "We've done it with a student from it in 2011 and Johnson has also done it.",
            "We have audio and we want to summarize it.",
            "We would have a small quantity of audio where we can find information from.",
            "We can find the summary of this audio or we can even have acoustic indexing enhancement via transcription propagation.",
            "Well, this is some very very big imagined.",
            "We started driving and your system proposes you transcription for new pile of your audio, which he automatically found that are similar to yours.",
            "Conversion."
        ],
        [
            "Old VW is back and he's going to stay.",
            "I think that is many areas where we are complementary to.",
            "It's hard.",
            "We don't want tickets are out, but we also know we need a lot of research on this area and I would encourage any of you that's working on all that likes this.",
            "Take a look at the papers and there is work to be done on scalability.",
            "Making models, working patterns general, making them speaking independent, making them robust, robust to noise or restoration.",
            "I think the set of problems is similar but complementary to the ASR problems.",
            "So here there."
        ],
        [
            "Friends one."
        ],
        [
            "Two, they are going to be in the video lectures, so thank you very much and I'm open for questions.",
            "So I think the major reason by his architect or switch Maps is the efficiency on the testing sites because they want to SRV online and time smaller races, however.",
            "What I'm going to visit is dead now with.",
            "Comments on.",
            "So a gentleman over here asked about.",
            "Capabilities of parallelization of the dynamic time warping to make it much faster at search time.",
            "Yes, I mean nowadays you can paralyze.",
            "You can get bigger computers, I mean more slow units can stop.",
            "But I really believe that on algorithms, if you can make our lives much faster, you can even run it in a in a crappy cell phone from from an Indian village, right?",
            "Who's not going to have cooler in his cell phone.",
            "I think as always and we've talked about it in other kinds of algorithms.",
            "It's we can find algorithms and December Sage approach.",
            "I think it's very interesting the one from John Hopkins.",
            "We can have algorithms that can run then everything working very fast and even with that if we can even put it in cool or paralyzing, paralyzing it even better, right?",
            "I mean I think I mean the burden of dynamic time warping of course is that we don't train so it's very fast, but a testing we need to compute with compared with many sequences, so I mean.",
            "I'm sure you will always get it faster with ASR, but as I said we are not competing for the same kind of applications.",
            "Xbox is a Xbox.",
            "So I just want to give a call here.",
            "Maybe this family programming has been used in computations for long time.",
            "OK, so if it is a communication tool we have so called up determine coding always.",
            "It's also sort of this kind.",
            "So maybe I mean for the history part of you that one is older.",
            "Patient here.",
            "Yes, I agree, but victory decoding normally uses models but is used in Hmm's to the code and you normally have you have this state.",
            "This kiss came out and all this Markov chains where you go.",
            "You jump from one change from one note to the other.",
            "You go self looks and then in dynamic time warping you have something totally different.",
            "When you have you have actual date and you try to match this data by warping it or not.",
            "But yeah I mean there's it's all machine learning and it's already similar, yeah?",
            "Question it just like that.",
            "I'm working in the same manner that you're searching for that keywords that is not represented or existing offering that I also spoke pensive.",
            "He was in videos to Lick Wish YouTube videos before it works or not.",
            "First we wouldn't find any database on cricket or label that parents at work.",
            "So we use DTW with only only was even one example, maybe sometimes more.",
            "You don't care, we could very well last period for this, but I'm very happy to listen.",
            "This is where the vision becauses targeted to who makes my supervisor.",
            "Maybe I should go back to the devil.",
            "Avoiding me.",
            "Provisor talk to him.",
            "So let's take speaker one."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My speech today is going to be about dynamic time warping Newth.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gallon of the talk will be first.",
                    "label": 0
                },
                {
                    "sent": "To see if there was anything before dynamic time warping, we will review a little bit.",
                    "label": 0
                },
                {
                    "sent": "For those of you that maybe a little old and maybe don't remember already or lose your points and say what is?",
                    "label": 0
                },
                {
                    "sent": "That will be what the networking is.",
                    "label": 0
                },
                {
                    "sent": "Then of course, here comes HMMS.",
                    "label": 1
                },
                {
                    "sent": "That's what destroyed dynamically working at the 80s.",
                    "label": 0
                },
                {
                    "sent": "Then everything working come back I'm gonna tell him of what has come.",
                    "label": 0
                },
                {
                    "sent": "In the last few years that maybe would be useful for the community between algorithms, speed and scalability applications, and then finally I'll conclude with some conclusions and future trends that we can observe so.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before then, everything working.",
                    "label": 0
                },
                {
                    "sent": "How would people do speech processing?",
                    "label": 0
                },
                {
                    "sent": "How will people do speech recognition for example?",
                    "label": 1
                },
                {
                    "sent": "Well, before that, I'm talking about the 50s, the 40s at beginning of the 60s, people were trying to match patterns, predefined patterns, small sequences of of.",
                    "label": 0
                },
                {
                    "sent": "Values that they would capture with very regimented microphones.",
                    "label": 0
                },
                {
                    "sent": "They will try to match them with the input they would get from these microphones to try to see what the words or sequences of words were said by the user.",
                    "label": 0
                },
                {
                    "sent": "Something in that, nothing like connected speech recognition or anything like that but just digits.",
                    "label": 1
                },
                {
                    "sent": "Simple words, commands, things that were able to be done at that time.",
                    "label": 0
                },
                {
                    "sent": "Remember, you know that time computers were kind of elementary.",
                    "label": 0
                },
                {
                    "sent": "We were programming with cars.",
                    "label": 0
                },
                {
                    "sent": "We know they were provided with parts of you.",
                    "label": 0
                },
                {
                    "sent": "I was not even alive.",
                    "label": 0
                },
                {
                    "sent": "At that time.",
                    "label": 0
                },
                {
                    "sent": "Alex, what would happen when there were sequences?",
                    "label": 0
                },
                {
                    "sent": "Our speeches are very varietal, very nonlinear signal, which means that sometimes we pronounce about a little longer than than another time, and sometimes a little shorter concerns etc etc.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have an example of hello where this is my voice.",
                    "label": 0
                },
                {
                    "sent": "In the first one I said hello in a normal way.",
                    "label": 0
                },
                {
                    "sent": "Here I said hello and of course the E is much longer.",
                    "label": 1
                },
                {
                    "sent": "How do you match that?",
                    "label": 0
                },
                {
                    "sent": "Well, some people were trying to do some linear normalization of these signals, but of course once they were matching.",
                    "label": 0
                },
                {
                    "sent": "Help me watching this part with this part.",
                    "label": 0
                },
                {
                    "sent": "This part was too short or the other way around so they couldn't get it, and linear mapping between the two sounds, so that's why the night time warping came and try to solve this thing, make a nonlinear mapping of two sequences of symbols or the sequences of data to try to match them up again to try to compare them better.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a little more mathematically described diameter working would be optimal if I will find a lot of alignment between two sets of symbols of the set of data X&Y, which are can be the dimensional International Space, we can have feature vectors there, or we can just have audio audio samples and we're trying to find optimal mapping by allowing some inclusions or or some deletions.",
                    "label": 1
                },
                {
                    "sent": "Between the timing of the points.",
                    "label": 0
                },
                {
                    "sent": "Talulah",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We normally compute this similarity matrix.",
                    "label": 0
                },
                {
                    "sent": "We have one single.",
                    "label": 0
                },
                {
                    "sent": "He run sequence here, one sequence here and we try to find the optimal alignment which will be this function F which is a nonlinear mapping between the starting point of 1 scene of 1 sequence with the ending point of the other sequence.",
                    "label": 0
                },
                {
                    "sent": "To do that we have to define this set this matrix which is similarity matrix according to some distance D. We can use the median distance we can use.",
                    "label": 0
                },
                {
                    "sent": "Doctoral normalizer product anything you can think of to build this matrix and then with dynamic programming we can find this optimal path from start to end.",
                    "label": 0
                },
                {
                    "sent": "So that's all this is Larry working.",
                    "label": 0
                },
                {
                    "sent": "This is so so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evil.",
                    "label": 0
                },
                {
                    "sent": "In order to make this feasible and to write a speech, there is some constraints that were imposed.",
                    "label": 0
                },
                {
                    "sent": "The first of those is automatically, which means that the working path is always increasing or you know the problem with the same values or increasing values you don't know.",
                    "label": 0
                },
                {
                    "sent": "You don't go back in speech to myself in the voice already previous.",
                    "label": 0
                },
                {
                    "sent": "So local constraints, which means for a given point, which possible points from before, we can come from this is the constraints that were proposed by the initial one of the initial papers, which is the security of paper 1978.",
                    "label": 0
                },
                {
                    "sent": "And then I know that later on dropping a proposed some other constraints that were also useful for speech recognition.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm further on those were local constraints.",
                    "label": 0
                },
                {
                    "sent": "We can apply some global constraints because of course if you have these two signals and this is speech, you might consider that maybe speaking I'm gonna start watching here and go over, you know and stop warping alot.",
                    "label": 0
                },
                {
                    "sent": "A little at the end, so you can apply some global constraints there to say, OK, my work is going to be bounded between.",
                    "label": 0
                },
                {
                    "sent": "Maybe this security aren't all between these.",
                    "label": 0
                },
                {
                    "sent": "Around so I'm not going to get out.",
                    "label": 0
                },
                {
                    "sent": "My is my order.",
                    "label": 0
                },
                {
                    "sent": "You will not get out of this band so I don't need to compute all this data.",
                    "label": 0
                },
                {
                    "sent": "I just compute the center thing and unbound my search on there.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to put your little bit in context.",
                    "label": 0
                },
                {
                    "sent": "There is some signal work that was done on dynamic time warping.",
                    "label": 0
                },
                {
                    "sent": "Two of the domain works and the most known I would say are these two.",
                    "label": 0
                },
                {
                    "sent": "Here the first one that I could not find.",
                    "label": 0
                },
                {
                    "sent": "Imprinting, if any of you knows of their existence, please send it to me.",
                    "label": 0
                },
                {
                    "sent": "But I know it exists.",
                    "label": 0
                },
                {
                    "sent": "It's referenced in papers from 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "So is this paper from 1971 the first one where the Sequoia and she started talking about that every time?",
                    "label": 0
                },
                {
                    "sent": "Warping another paper that everybody has everybody knows he's a 1978 transactions on our streets and signal processing paper that where they redefined all they talk about everything working and they talk about these bands is constrained.",
                    "label": 1
                },
                {
                    "sent": "Global constraints now when I was studying these papers and I was looking a little bit at the River fee, somebody pointed me out to hey, maybe this this is not the first word that actually talked about that everything working or something similar to that and they gave me a couple references.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One of them is the one here and I was really surprised this is.",
                    "label": 0
                },
                {
                    "sent": "Those previous ones were from Japan.",
                    "label": 0
                },
                {
                    "sent": "This is Russian gentleman.",
                    "label": 0
                },
                {
                    "sent": "1968 already had a paper about something that is similar to dynamic time warping in this case in this paper, but very mathematical paper she's talking about.",
                    "label": 0
                },
                {
                    "sent": "The similar between a speech synthesis so that it's all other warping of the speech synthesis, like periods to make sympathies longer or shorter.",
                    "label": 0
                },
                {
                    "sent": "In this case against a minimum length reference pattern.",
                    "label": 1
                },
                {
                    "sent": "So the minimum minimal pattern that you would like to match too, and he's warping it, so allowing only inclusion.",
                    "label": 0
                },
                {
                    "sent": "So repetitions of some of the period thing here in order to match an input query.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of the first.",
                    "label": 0
                },
                {
                    "sent": "I would say reference to what we call now dynamical working that exist in the literature further on.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I found another Russian, actually two Russians here.",
                    "label": 0
                },
                {
                    "sent": "These guys were even Martina Mass Institute in Siberia.",
                    "label": 0
                },
                {
                    "sent": "I don't know if they were there for other reasons and then math, but they were United 70 and this is actually.",
                    "label": 0
                },
                {
                    "sent": "This is one of the plus from their paper.",
                    "label": 0
                },
                {
                    "sent": "This is actually a similarity matrix photodynamic.",
                    "label": 0
                },
                {
                    "sent": "I'm working where they where.",
                    "label": 0
                },
                {
                    "sent": "They allow insertion Zelda lesions.",
                    "label": 0
                },
                {
                    "sent": "They allow exact matching between one point and the other sequence one sequence sequence too.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "For me is the exact paper the first instance of dynamic time warping that exists in the literature?",
                    "label": 0
                },
                {
                    "sent": "I'm sorry for Sequoia Shiba, no.",
                    "label": 0
                },
                {
                    "sent": "The only time warping DTW for short was has not left until today.",
                    "label": 0
                },
                {
                    "sent": "As Diablo.",
                    "label": 0
                },
                {
                    "sent": "You know, we use for speech recognition.",
                    "label": 0
                },
                {
                    "sent": "Why, well in the 80s?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There were some people, and particularly first of them guy called or a gentleman called Bomb from the palm oil job or even done saying hey, we have something called Hmm's.",
                    "label": 0
                },
                {
                    "sent": "We have machines have memory.",
                    "label": 0
                },
                {
                    "sent": "We can store models.",
                    "label": 0
                },
                {
                    "sent": "We can do some statistical processing on them.",
                    "label": 1
                },
                {
                    "sent": "Why don't we try training states?",
                    "label": 0
                },
                {
                    "sent": "OK training models to different states.",
                    "label": 0
                },
                {
                    "sent": "So returning like arrows and some progress and arrows.",
                    "label": 0
                },
                {
                    "sent": "With this we can decode the signal and we can do this warming effect, but without having patterns that we match with.",
                    "label": 0
                },
                {
                    "sent": "So then some people like Robin are one.",
                    "label": 0
                },
                {
                    "sent": "They started working on it.",
                    "label": 0
                },
                {
                    "sent": "They progressed a lot and since then we forgot about everything worry.",
                    "label": 0
                },
                {
                    "sent": "So nowadays we get a lot of data.",
                    "label": 0
                },
                {
                    "sent": "We got lots of paid students to label these data, so we have all the phonemes we have.",
                    "label": 1
                },
                {
                    "sent": "Everything very well labeled and we train these models and we get fantastic.",
                    "label": 0
                },
                {
                    "sent": "Result, and that's why we got fantastic results.",
                    "label": 0
                },
                {
                    "sent": "I mean, sometimes we would like to get 100%, we don't.",
                    "label": 0
                },
                {
                    "sent": "We have city and we have things at work, right?",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's see, that's a little comparison between ASR using Hmm's and using the W. So we dynamically working.",
                    "label": 0
                },
                {
                    "sent": "Remember we have to have patterns which are matching.",
                    "label": 0
                },
                {
                    "sent": "So we have our set of patterns.",
                    "label": 0
                },
                {
                    "sent": "So these are some examples.",
                    "label": 0
                },
                {
                    "sent": "You know we don't need to label them, we just know that this is hello, this is goodbye, you know and we just try to match them with our with our test data.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, hidden Markov models.",
                    "label": 0
                },
                {
                    "sent": "They need a lot of training data.",
                    "label": 0
                },
                {
                    "sent": "They need to.",
                    "label": 0
                },
                {
                    "sent": "We need to label them well.",
                    "label": 0
                },
                {
                    "sent": "We need to train our models.",
                    "label": 0
                },
                {
                    "sent": "Now when training our models dynamic.",
                    "label": 0
                },
                {
                    "sent": "'cause we have to use some algorithm that trade and it's maybe slowly.",
                    "label": 0
                },
                {
                    "sent": "It takes a few days, but once it's training the test is very fast.",
                    "label": 0
                },
                {
                    "sent": "We use with Terry and whom we have result.",
                    "label": 0
                },
                {
                    "sent": "We have matching's.",
                    "label": 0
                },
                {
                    "sent": "On the other hand I have everything working.",
                    "label": 0
                },
                {
                    "sent": "We don't need any training, we just have the the batteries.",
                    "label": 0
                },
                {
                    "sent": "But we might have 100,000 patterns.",
                    "label": 0
                },
                {
                    "sent": "So at Test time it takes time to myself and find whatever pattern is best.",
                    "label": 0
                },
                {
                    "sent": "Movies at anytime we come achieve the mid to high accuracy we can get pretty High Priest nowadays much into patterns with hidden Markov models.",
                    "label": 1
                },
                {
                    "sent": "Depending on the acoustic conditions of course on the matching of the acoustics with the training, but we can have pretty high accuracy.",
                    "label": 0
                },
                {
                    "sent": "So bottom line people abandons them into working for ASR and that has been the rule.",
                    "label": 0
                },
                {
                    "sent": "For most researchers I would say except these guys here.",
                    "label": 0
                },
                {
                    "sent": "These are these are from the Netherlands.",
                    "label": 0
                },
                {
                    "sent": "This paper is the first one that appeared in 2007 that they do ASR with dynamic time warping, so is hard with matching in their case of phoneme based sequences and this is a group of 3rd party component.",
                    "label": 0
                },
                {
                    "sent": "Pronounce it well, OK, and it's very interesting work to look at, but I'm not going to talk about.",
                    "label": 0
                },
                {
                    "sent": "Start in the way they do.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about then everything working in another way which.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Describe it always is.",
                    "label": 0
                },
                {
                    "sent": "Diablo.",
                    "label": 0
                },
                {
                    "sent": "Like I'm going to talk about the only thing working to solve these problems.",
                    "label": 0
                },
                {
                    "sent": "So what will happen if you have a language where you don't have many speakers or happens at your language doesn't have much economical power in the world is a lot of small country, so you cannot pay a lot of students to label your data.",
                    "label": 0
                },
                {
                    "sent": "Or at least see the label there later, so you will have no transcriber in data.",
                    "label": 1
                },
                {
                    "sent": "You might know, dictionaries.",
                    "label": 0
                },
                {
                    "sent": "You might not even have knowledge of the linguistic content and this happened.",
                    "label": 1
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "African languages.",
                    "label": 0
                },
                {
                    "sent": "Indonesian language is lots of languages in the world.",
                    "label": 0
                },
                {
                    "sent": "Actually there is only a few languages that do have plenty of resources for ASR.",
                    "label": 0
                },
                {
                    "sent": "There is lots of dollars that don't.",
                    "label": 0
                },
                {
                    "sent": "So what can you do with this?",
                    "label": 0
                },
                {
                    "sent": "How we still do something?",
                    "label": 0
                },
                {
                    "sent": "How you still drive some knowledge extraction knowledge from that?",
                    "label": 0
                },
                {
                    "sent": "Yes we can and.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's how we say dynamic networking come back.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Process of dynamic time working for this task is yes, we can.",
                    "label": 0
                },
                {
                    "sent": "We work with patterns.",
                    "label": 0
                },
                {
                    "sent": "We don't need any knowledge about labeling.",
                    "label": 0
                },
                {
                    "sent": "We don't need any knowledge about the language to try to extract something, but what a big problem.",
                    "label": 1
                },
                {
                    "sent": "Dynamic time warping us.",
                    "label": 0
                },
                {
                    "sent": "If you remember from the definition works from the beginning of a pattern to the end of a pattern.",
                    "label": 0
                },
                {
                    "sent": "We need to know the beginning and the end of the patterns in order to match.",
                    "label": 1
                },
                {
                    "sent": "So cases like this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, when we have maybe two sequences and we know that only or we want to find whether something inside is matching or one big sequence, and we want to find repetitions of words that might be several times that's complicated.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do you solve that?",
                    "label": 0
                },
                {
                    "sent": "People started looking at it, started thinking about it and said OK, can we modify dynamic time warping to try to work on the settings so that we don't have to define these stand on end points so you know in the case of dynamic standard and everything we would match from here to here and from here to here which wouldn't normally match anything.",
                    "label": 0
                },
                {
                    "sent": "So for this reason they appeared several algorithms in here.",
                    "label": 0
                },
                {
                    "sent": "I have five of them and I'm sure there's couple more around that try to find this subsequence matching using dynamic time warping derived algorithms.",
                    "label": 0
                },
                {
                    "sent": "So we have the segmental DTW image.",
                    "label": 0
                },
                {
                    "sent": "Basically W motive discovery if it only for music and unbounded only.",
                    "label": 0
                },
                {
                    "sent": "I'm going to briefly very briefly 'cause if not Mark's, gonna give me up.",
                    "label": 0
                },
                {
                    "sent": "Talk to you up.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Them because I think they are very interesting.",
                    "label": 0
                },
                {
                    "sent": "First of all, people said mentality value.",
                    "label": 0
                },
                {
                    "sent": "This was initialized, initialized.",
                    "label": 0
                },
                {
                    "sent": "Buy in MIT in around 2006.",
                    "label": 0
                },
                {
                    "sent": "With that, remember we have these two sequences long sequences, one here and one here, and they exhaustively search.",
                    "label": 0
                },
                {
                    "sent": "Along time along the two sequences for subsequences matching in the two subject in the two sequences.",
                    "label": 0
                },
                {
                    "sent": "So they get these bonds and for each family trying to find if there is any subsequence matching.",
                    "label": 0
                },
                {
                    "sent": "This is kind of computationally intensive.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I later on I just at the John Hopkins.",
                    "label": 0
                },
                {
                    "sent": "There was an injunction and company that started thinking, can we make it faster and they did make it faster using some image based techniques.",
                    "label": 0
                },
                {
                    "sent": "In this case, this is the first paper that they wrote or no one of the first papers they broke.",
                    "label": 0
                },
                {
                    "sent": "They use half transform.",
                    "label": 0
                },
                {
                    "sent": "Any much technique to find diagonals to quickly spot if there is any.",
                    "label": 0
                },
                {
                    "sent": "Like in here you see that there is this kind of diagonal here to find if there is any subsequences that might be matching.",
                    "label": 0
                },
                {
                    "sent": "And that might could be approximately a make approximately at a diagonal line, and then once they have these areas then they do a segmental DTW to find exactly the the matching path.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other people, and we're going to France now.",
                    "label": 0
                },
                {
                    "sent": "We jump from US to France.",
                    "label": 0
                },
                {
                    "sent": "Other people have done similar things.",
                    "label": 0
                },
                {
                    "sent": "This is for broadcast news.",
                    "label": 0
                },
                {
                    "sent": "This is a most cardiolog younger here at Trent University and they are looking in broadcast news within a window of two 3 minutes.",
                    "label": 0
                },
                {
                    "sent": "Which words are repeated within this window?",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into the details.",
                    "label": 0
                },
                {
                    "sent": "You can find the paper easily on the web.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Similarly, now we jump to music we have may not murder.",
                    "label": 0
                },
                {
                    "sent": "Has been working with finding time to find general matching or general structure analysis of songs by finding.",
                    "label": 1
                },
                {
                    "sent": "Also this is a movie, a similarity matrix over some self similarity metrics.",
                    "label": 0
                },
                {
                    "sent": "Finding these areas where the song is most similar between them.",
                    "label": 0
                },
                {
                    "sent": "So in a song you can imagine that we normally repeat end of paragraphs or repeat things in the song.",
                    "label": 0
                },
                {
                    "sent": "So here he finds the peaks of these repetitions.",
                    "label": 0
                },
                {
                    "sent": "And then expense them in one side on the other to find similarity pass or to find warping pass so subsequences and match.",
                    "label": 0
                },
                {
                    "sent": "This can be also applied for speak with no problem.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, here is my algorithm they presented couple years ago, maybe three years, and then where I say OK, people want to have to compute all these big similarity matrix for a 4 two subsequences A&BI don't want to do that.",
                    "label": 0
                },
                {
                    "sent": "So can I do the same with my just subsample this similarity matrix matrix?",
                    "label": 0
                },
                {
                    "sent": "So you hear this point is the only points I compute from dissimilarity matrix access subsample it with a minimum distance, so that I will not loose.",
                    "label": 0
                },
                {
                    "sent": "Any any working path, any similarity working back and then?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They do for each of the points I check if there is a working path in the two directions.",
                    "label": 0
                },
                {
                    "sent": "So with that I can find also the the path and I save about 5060% of the computation of the similarity matrix.",
                    "label": 0
                },
                {
                    "sent": "Still dynamic programming has to be the same, or maybe a little more costly.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So much some of you might say, well, very nice, very good.",
                    "label": 0
                },
                {
                    "sent": "But Hmm's are faster.",
                    "label": 0
                },
                {
                    "sent": "Victory is very fast.",
                    "label": 0
                },
                {
                    "sent": "We can do this very fast.",
                    "label": 0
                },
                {
                    "sent": "You have nothing to do in here.",
                    "label": 0
                },
                {
                    "sent": "Well, we had the same thing you wanted me to be controversial.",
                    "label": 0
                },
                {
                    "sent": "You would have done the same thing and that's why people started thinking about it and started proposing algorithms.",
                    "label": 0
                },
                {
                    "sent": "And these are some of them.",
                    "label": 0
                },
                {
                    "sent": "So people have thought OK, can we dissimilarity matrix?",
                    "label": 0
                },
                {
                    "sent": "Can we make it smaller?",
                    "label": 0
                },
                {
                    "sent": "Can we do a course to find the matching and that's the paper from Salvadoran Chan in 2004 that started looking into that.",
                    "label": 0
                },
                {
                    "sent": "OK, can we do a fast matching and then when we know an area then we we we going in until we find the exact matching working part?",
                    "label": 0
                },
                {
                    "sent": "Or we can also do an intelligent bound of the dynamic time warping.",
                    "label": 1
                },
                {
                    "sent": "We don't need to compute everything.",
                    "label": 0
                },
                {
                    "sent": "We can just focus on on the areas where we think we might have some matching.",
                    "label": 0
                },
                {
                    "sent": "There is interesting word by human Kirk on the stand on the traditional DTW.",
                    "label": 0
                },
                {
                    "sent": "Lots of work from him rings.",
                    "label": 0
                },
                {
                    "sent": "It's worth to take a look at it and work from Zenon Glass from MIT.",
                    "label": 0
                },
                {
                    "sent": "Also looking at bounding bounding regions do not compute all the all the similarity values.",
                    "label": 0
                },
                {
                    "sent": "I'm finally very interesting word from.",
                    "label": 1
                },
                {
                    "sent": "Jason and John Hopkins trying to use MSH and similar techniques to do an information retrieval approach to dynamic time warping so that we don't compute the whole similarity matrix and we might do this matching much faster, so this is something worth looking at.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Finally two to finalize my talk.",
                    "label": 0
                },
                {
                    "sent": "OK, you know we can match, but how do we use it?",
                    "label": 0
                },
                {
                    "sent": "I mean like in nature and we don't want other ways how we don't want to compete with HMMS.",
                    "label": 0
                },
                {
                    "sent": "We know they're there for a reason.",
                    "label": 0
                },
                {
                    "sent": "But we can do things and we know that there is killer applications out there to be used for dynamic time warping.",
                    "label": 0
                },
                {
                    "sent": "This is just a few of them.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can find structure.",
                    "label": 0
                },
                {
                    "sent": "As I said in a language which we don't know anything about and we can find a structure in the language find like a child learns a new language, try to extract something from it by just looking at it or listening to it.",
                    "label": 0
                },
                {
                    "sent": "We can also even learn ASR models, help ASR, but learning models initially from this language without knowing any transcription.",
                    "label": 0
                },
                {
                    "sent": "And that's what's done in the Jackson 2011 paper.",
                    "label": 0
                },
                {
                    "sent": "I have the references at the end.",
                    "label": 0
                },
                {
                    "sent": "We can also do even some natural language processing directly on the acoustics if you can find the repetitions, we can do some kind of TF IDF.",
                    "label": 0
                },
                {
                    "sent": "We can compare documents we can see which documents are similar.",
                    "label": 0
                },
                {
                    "sent": "We can put them into topics etc etc.",
                    "label": 0
                },
                {
                    "sent": "That's very interesting down my dress day in 2010.",
                    "label": 0
                },
                {
                    "sent": "We can do some query by example search like in the mid medieval evaluation.",
                    "label": 0
                },
                {
                    "sent": "Where we have queries and we search for them in a big database.",
                    "label": 0
                },
                {
                    "sent": "Last year we did it on Indian languages, languages that I could not even understand, but my system could.",
                    "label": 0
                },
                {
                    "sent": "We can do some spoken term discovery as I spoke about most Carrero and Gravier and some spoken summarization.",
                    "label": 1
                },
                {
                    "sent": "Very interesting work.",
                    "label": 0
                },
                {
                    "sent": "We've done it with a student from it in 2011 and Johnson has also done it.",
                    "label": 0
                },
                {
                    "sent": "We have audio and we want to summarize it.",
                    "label": 0
                },
                {
                    "sent": "We would have a small quantity of audio where we can find information from.",
                    "label": 0
                },
                {
                    "sent": "We can find the summary of this audio or we can even have acoustic indexing enhancement via transcription propagation.",
                    "label": 1
                },
                {
                    "sent": "Well, this is some very very big imagined.",
                    "label": 0
                },
                {
                    "sent": "We started driving and your system proposes you transcription for new pile of your audio, which he automatically found that are similar to yours.",
                    "label": 0
                },
                {
                    "sent": "Conversion.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Old VW is back and he's going to stay.",
                    "label": 1
                },
                {
                    "sent": "I think that is many areas where we are complementary to.",
                    "label": 0
                },
                {
                    "sent": "It's hard.",
                    "label": 0
                },
                {
                    "sent": "We don't want tickets are out, but we also know we need a lot of research on this area and I would encourage any of you that's working on all that likes this.",
                    "label": 0
                },
                {
                    "sent": "Take a look at the papers and there is work to be done on scalability.",
                    "label": 1
                },
                {
                    "sent": "Making models, working patterns general, making them speaking independent, making them robust, robust to noise or restoration.",
                    "label": 0
                },
                {
                    "sent": "I think the set of problems is similar but complementary to the ASR problems.",
                    "label": 0
                },
                {
                    "sent": "So here there.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Friends one.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two, they are going to be in the video lectures, so thank you very much and I'm open for questions.",
                    "label": 0
                },
                {
                    "sent": "So I think the major reason by his architect or switch Maps is the efficiency on the testing sites because they want to SRV online and time smaller races, however.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to visit is dead now with.",
                    "label": 0
                },
                {
                    "sent": "Comments on.",
                    "label": 0
                },
                {
                    "sent": "So a gentleman over here asked about.",
                    "label": 0
                },
                {
                    "sent": "Capabilities of parallelization of the dynamic time warping to make it much faster at search time.",
                    "label": 0
                },
                {
                    "sent": "Yes, I mean nowadays you can paralyze.",
                    "label": 0
                },
                {
                    "sent": "You can get bigger computers, I mean more slow units can stop.",
                    "label": 0
                },
                {
                    "sent": "But I really believe that on algorithms, if you can make our lives much faster, you can even run it in a in a crappy cell phone from from an Indian village, right?",
                    "label": 0
                },
                {
                    "sent": "Who's not going to have cooler in his cell phone.",
                    "label": 0
                },
                {
                    "sent": "I think as always and we've talked about it in other kinds of algorithms.",
                    "label": 0
                },
                {
                    "sent": "It's we can find algorithms and December Sage approach.",
                    "label": 0
                },
                {
                    "sent": "I think it's very interesting the one from John Hopkins.",
                    "label": 0
                },
                {
                    "sent": "We can have algorithms that can run then everything working very fast and even with that if we can even put it in cool or paralyzing, paralyzing it even better, right?",
                    "label": 0
                },
                {
                    "sent": "I mean I think I mean the burden of dynamic time warping of course is that we don't train so it's very fast, but a testing we need to compute with compared with many sequences, so I mean.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you will always get it faster with ASR, but as I said we are not competing for the same kind of applications.",
                    "label": 0
                },
                {
                    "sent": "Xbox is a Xbox.",
                    "label": 0
                },
                {
                    "sent": "So I just want to give a call here.",
                    "label": 0
                },
                {
                    "sent": "Maybe this family programming has been used in computations for long time.",
                    "label": 0
                },
                {
                    "sent": "OK, so if it is a communication tool we have so called up determine coding always.",
                    "label": 0
                },
                {
                    "sent": "It's also sort of this kind.",
                    "label": 0
                },
                {
                    "sent": "So maybe I mean for the history part of you that one is older.",
                    "label": 0
                },
                {
                    "sent": "Patient here.",
                    "label": 0
                },
                {
                    "sent": "Yes, I agree, but victory decoding normally uses models but is used in Hmm's to the code and you normally have you have this state.",
                    "label": 0
                },
                {
                    "sent": "This kiss came out and all this Markov chains where you go.",
                    "label": 0
                },
                {
                    "sent": "You jump from one change from one note to the other.",
                    "label": 0
                },
                {
                    "sent": "You go self looks and then in dynamic time warping you have something totally different.",
                    "label": 0
                },
                {
                    "sent": "When you have you have actual date and you try to match this data by warping it or not.",
                    "label": 0
                },
                {
                    "sent": "But yeah I mean there's it's all machine learning and it's already similar, yeah?",
                    "label": 0
                },
                {
                    "sent": "Question it just like that.",
                    "label": 0
                },
                {
                    "sent": "I'm working in the same manner that you're searching for that keywords that is not represented or existing offering that I also spoke pensive.",
                    "label": 0
                },
                {
                    "sent": "He was in videos to Lick Wish YouTube videos before it works or not.",
                    "label": 0
                },
                {
                    "sent": "First we wouldn't find any database on cricket or label that parents at work.",
                    "label": 0
                },
                {
                    "sent": "So we use DTW with only only was even one example, maybe sometimes more.",
                    "label": 0
                },
                {
                    "sent": "You don't care, we could very well last period for this, but I'm very happy to listen.",
                    "label": 0
                },
                {
                    "sent": "This is where the vision becauses targeted to who makes my supervisor.",
                    "label": 0
                },
                {
                    "sent": "Maybe I should go back to the devil.",
                    "label": 0
                },
                {
                    "sent": "Avoiding me.",
                    "label": 0
                },
                {
                    "sent": "Provisor talk to him.",
                    "label": 0
                },
                {
                    "sent": "So let's take speaker one.",
                    "label": 0
                }
            ]
        }
    }
}