{
    "id": "bvl4om5qqhjntmblbevffjbd7ei5o2z4",
    "title": "Doulion: Counting Triangles in Massive Graphs with a Coin",
    "info": {
        "author": [
            "Charalampos E. Tsourakakis, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Aug. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Graph Mining"
        ]
    },
    "url": "http://videolectures.net/kdd09_tsourakakis_dctmgwc/",
    "segmentation": [
        [
            "So hello everybody, my name is Bob it's Rockies.",
            "And I'm going to present the book Julian Counting triangles in massive graphs with the coin, which is joint work with UConn.",
            "Gary Miller increases followers."
        ],
        [
            "So this is outline of my talk.",
            "First I will give some motivation behind the problem.",
            "Then I will present the related work how we describe our proposed method.",
            "Show some of our results.",
            "Then I will conclude and if I have some time I will present some extra material."
        ],
        [
            "OK so I will present some motivation for the triangle counting problem, mainly from the graph mining perspective.",
            "So in complex network analysis to offer most frequent two at least measures that are typically computed are the clustering coefficients and the transitivity ratio, both of which.",
            "Rely on counting triangles, and especially in the context of social networks.",
            "Triangles have a straightforward interpretation.",
            "Friends of friends tend to be friends themselves, so triangles are absent in social networks.",
            "So here I have listed as well three of the papers that also use triangles to solve the problem of interest.",
            "One of those papers was presented last year in KDD by Boschetti Baldy Castillo and Harris Journeys where they also introduced an algorithm for counting triangles in a semi streaming setting.",
            "So trying accounting is important in graph mining and that's some reasons."
        ],
        [
            "Motivating the problem, but there is also a personal component in my motivation behind the this work.",
            "So last year in ICBM I took advantage of in a paper I took advantage of the spectral properties of real world networks to contract sufficiently.",
            "So if you plotted the specter of real world networks because typically realgar tech networks have a very secured degree distribution which implies a skewed eigenvalue distribution.",
            "You will see the following.",
            "Most of the eigenvalues are symmetric around zero, almost symmetric, around zero, and some of them are, well detached from the rest.",
            "So by proving these two theorems here, these two formulas, which gives a number of triangles in a graph and the number of trends per node using eigenvalues that eigenvectors, which I'm not going to present in detail now because it's a previous paper, you can just keep few of them and get a very good approximation.",
            "So my motivation is that I would like to have an algorithm that works independently of the graph.",
            "Independently of the spectral properties of the graph, so this is what I'm going to talk about so."
        ],
        [
            "Some related work."
        ],
        [
            "As far as exact counting methods are concerned, we have the following standard facts.",
            "So the fastest methods rely on matrix matrix multiplication.",
            "The state of the Art for Matrix matrix multiplication is then to the .37 due to coppersmith and Winograd, but unfortunately, even if asymptotically it's a faster one, it has a very very high complexity, and the memory requirements do not allow this.",
            "Methods to scale in real world networks in large networks only for medium size.",
            "So in practice what one does is he he or she applies a listing method rather than just count the number of triangles he can enumerate the nodes that participate in each triangle.",
            "So these methods in the case of dense graphs result in a cubic algorithm.",
            "The space complexity is order M, where now I'm since the graph is dense again and square, but the constants are much smaller, so their applicability.",
            "Practice and for the sparse graph case one can I play some other type of algorithm, typically called iterative algorithms, where one can consider each edge separately and count how many triangles that edge participates in, or the algorithm that I described here the complexity of that method described here called the node aerator, where you consider each node the neighborhood of that node and then count how many edges exist among those nodes.",
            "So the simple upper bound of the complexities N times a maximum degree squared.",
            "So as I said, the matrix multiplication algorithm is not practical, and the nice survey for these exact counting methods with theory and experiments is you can find it, and it's by Matthew Lappin."
        ],
        [
            "So now I will describe to sampling methods becausw the method that we propose disassembling one.",
            "The first one is the most naive one and the second one is the one that gives a state of the art solution to this problem.",
            "So the most simple one is choose three nodes randomly from the graph and see if they form a triangle.",
            "If you choose, who knows, there are four things for things that you can see, either 3 edges, zero edges, one edge, or two edges we call, let's say, T0 the number of.",
            "People that have no edge T11 edge and so so if you see one triangle by doing this sample then your estimate is one other, otherwise it's 0.",
            "The expected value of your estimate is equal to this expression.",
            "Here the number of triangles divided by this sum, which in our case is endustri.",
            "Since every triple belongs to exactly one of those types, and we haven't choose three of them, so your output is anxious three times, the expected the average of your of the number of samples that you took.",
            "So the question is what are should be?",
            "How many samples do you have to take in order to grantee ago?"
        ],
        [
            "Approximation so in order to guarantee a good approximation with high probability and we think epsilon and epsilon relative approximation.",
            "So the number of samples depends quadratically on the epsilon.",
            "The accuracy log one over Delta for the probability of success.",
            "And then you have this term here.",
            "This term here is very bad cause for us in practice becausw it requires that your graph is very dense.",
            "With respect to the triangles.",
            "So if your graph has lessened and square triangles, then you're in trouble.",
            "You have no, not that good quality approximation, so it works well for when, for example, the graph is more than N squared log in triangles.",
            "This this condition here does not happen in practice.",
            "In practice we have much."
        ],
        [
            "Order number of trends.",
            "So the state of the art sampling approaches due to brione filing at all.",
            "So what they do is a sample and edge and the node in dependently and then they check if they form a triangle.",
            "If they form a triangle then they make an estimate and the details are omitted here.",
            "But what we care about is the number of samples that they have to take the number of something they have to take is better than the naive one.",
            "Sorry then then I have one but still requires a graph to be fairly."
        ],
        [
            "Since so now I'm going to present our proposed map."
        ],
        [
            "What happens in our proposed method, you toss a coin for each edge in dependently and if veg succeeds to survive then you re weighted by 1 / P where P was a probability for the edge to serve."
        ],
        [
            "If there if the coin that this guy tosses says that this should be deleted with probability 1 -- P, then it dies."
        ],
        [
            "So here is our algorithm.",
            "It's exactly what I described through the comic before you toss a coin with probability P of keeping an edge.",
            "If the edge succeeds, you re weighted by 1 / P, otherwise you delete it.",
            "Then you get the sparsified graph and then you apply any triangle counting algorithm that specify."
        ],
        [
            "Graph.",
            "So just to give some intuition why this works, and on a single graph, let's say that you have the complete graph, which has anxious three triangles.",
            "Initially, after you toss a coin, let's say a fair coin, probability 5 heads probability .5 tails.",
            "You get random mental strain graph with probability of an edge equal 2.5.",
            "In expectation.",
            "In this area training graph you have picked up time entries for triangles, and since we count now weighted triangles.",
            "You multiply by 1 / P cube, so in expectation you get exactly the same number of triangles."
        ],
        [
            "So.",
            "In the paper we prove some basic properties of this method.",
            "The first basic properties at the expected value of our estimate is the true number of triangles.",
            "We prove we show what the variance of our estimate is.",
            "It depends on the number of non edge disjoint triangles.",
            "So intuitively you can think that if you have an indicator variable for each triangle and you throw away the common edge, then when you have non edge disjoint triangles like here these two then those indicator variables are correlated.",
            "Therefore you get this term here.",
            "So the more edge disjoint triangles you have, the better."
        ],
        [
            "Approximation is so some results."
        ],
        [
            "We used as our triangle counting books, the No decorator that I described before and."
        ],
        [
            "Here, let me say what the expected speedup is if you choose a parameter P to specify the graph, then your expected speedup is 1 / P ^2.",
            "The proof is 2 lines, since the complex of the Nodata rater is the sum of the degrees squared after the sparsification, you get this P square factor here.",
            "So, so the expected speedup is 1 / P ^2, as I say."
        ],
        [
            "Some results in the Wikipedia 2006 September Graph, 3 million nodes, 35 million edges.",
            "We use constant P .1.",
            "You get a speedup of 110 times and very high accuracy.",
            "The other points you see here correspond to point 9.8 and stepping by .1 backwards until you get to .1 the same from Flickr.",
            "Very high accuracy.",
            "Very big speedup.",
            "Close to this expected one."
        ],
        [
            "You see 100.",
            "The same Wikipedia, November Wikipedia 2007 you get very big speedups and a very very high accuracy estimation of the number of trying."
        ],
        [
            "So the conclusion is that in this paper we present a new sampling approach that counts triangles approximately.",
            "We present the basic analysis of the estimate and in the experiments that I showed, we used constant.",
            "So what we see is that you can get the constant speed up of 1 / P ^2."
        ],
        [
            "So natural question that comes up and is not answered in Julian is how small can PB we care a lot about this?",
            "Because if, for example, you could make Pier small as one over root N you would get a linear speedup order end.",
            "Here are some values just to show you if you could use these P then you would get 1,000,000 speedup and very high accuracy."
        ],
        [
            "So here is extra work."
        ],
        [
            "A few weeks ago with Professor Colin Jackson, Gary Gary Miller, we answered."
        ],
        [
            "Question and we answered it by proving something very strong about this procedure an under very mild conditions on the triangle density of the graph which come from maybe the details of the firm.",
            "Just I will guide you if you pick P here equal to 1.",
            "So you make no specification.",
            "You see that the triangle density is could be very small and times log to the 6 plus gamma and gamma arbitrarily small.",
            "We give the conditions that you can choose P as small as possible.",
            "We give a concentration result for this specific choice and the critical quantities in this theorem.",
            "RT, the number of triangles and Delta the size of the largest collection of triangles with a common edge."
        ],
        [
            "So a practitioners guide for counting triangles.",
            "You can pick P1 over root N in practice and keep doubling it until you use a concentration so that I did that for many graphs like or could You Tube Wikipedia graphs?",
            "This is a good rule of."
        ],
        [
            "Because the problem here in this hearing is that you don't know T and you don't know Delta.",
            "So what the optimal P depends on the things that you want to compute."
        ],
        [
            "Priority so this a rule of thumb that works very well for real world networks.",
            "1 / N keep doubling you introduce it at most a small logarithmic factor in the whole procedure.",
            "And here's what you see.",
            "Let's say that we have the Wikipedia 2005 graph.",
            "You pick initially one overall 10, let's say .005.",
            "You don't get the concentration.",
            "You doublet, .01 you get better concentration when you go to .02.",
            "You see this concentration here.",
            "You do 10 experiments.",
            "You can see that.",
            "It's concentrated, so if you keep on just for sanity."
        ],
        [
            "Check you get a very strong concentration and somebody distances for the algorithm is at the following.",
            "If you have linear number of triangles in the graph, then Dylan cannot work because if you throw this edge out then your variance would be very bad.",
            "You lose all the trends and other bad instances when you have weighted graphs since if W is very very big then if you throw one of these edge then you get a bad estimate too.",
            "So it works well for anti."
        ],
        [
            "Rated unweighted graphs.",
            "So in the spirit of reproducible research, I make datasets code available and."
        ],
        [
            "Thank you very much.",
            "Here are the references.",
            "The last speaker setup.",
            "OK, so we can have one question doing this because his equipment please.",
            "Can you play method to Cox making the clustering vector?",
            "The classroom coefficients for so, so this method is for the global triangle counting problem.",
            "So it could be applied for the transitivity ratio, since when you specify as you may guess, the degree of each node gets P times degree.",
            "When you have small degrees, you lose those nodes.",
            "One piece very small.",
            "What we get here is a concentration on the total number of triangles, not the classroom coefficients.",
            "OK, thank you.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So hello everybody, my name is Bob it's Rockies.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to present the book Julian Counting triangles in massive graphs with the coin, which is joint work with UConn.",
                    "label": 1
                },
                {
                    "sent": "Gary Miller increases followers.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "First I will give some motivation behind the problem.",
                    "label": 0
                },
                {
                    "sent": "Then I will present the related work how we describe our proposed method.",
                    "label": 1
                },
                {
                    "sent": "Show some of our results.",
                    "label": 0
                },
                {
                    "sent": "Then I will conclude and if I have some time I will present some extra material.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so I will present some motivation for the triangle counting problem, mainly from the graph mining perspective.",
                    "label": 1
                },
                {
                    "sent": "So in complex network analysis to offer most frequent two at least measures that are typically computed are the clustering coefficients and the transitivity ratio, both of which.",
                    "label": 1
                },
                {
                    "sent": "Rely on counting triangles, and especially in the context of social networks.",
                    "label": 1
                },
                {
                    "sent": "Triangles have a straightforward interpretation.",
                    "label": 0
                },
                {
                    "sent": "Friends of friends tend to be friends themselves, so triangles are absent in social networks.",
                    "label": 1
                },
                {
                    "sent": "So here I have listed as well three of the papers that also use triangles to solve the problem of interest.",
                    "label": 0
                },
                {
                    "sent": "One of those papers was presented last year in KDD by Boschetti Baldy Castillo and Harris Journeys where they also introduced an algorithm for counting triangles in a semi streaming setting.",
                    "label": 0
                },
                {
                    "sent": "So trying accounting is important in graph mining and that's some reasons.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Motivating the problem, but there is also a personal component in my motivation behind the this work.",
                    "label": 0
                },
                {
                    "sent": "So last year in ICBM I took advantage of in a paper I took advantage of the spectral properties of real world networks to contract sufficiently.",
                    "label": 0
                },
                {
                    "sent": "So if you plotted the specter of real world networks because typically realgar tech networks have a very secured degree distribution which implies a skewed eigenvalue distribution.",
                    "label": 0
                },
                {
                    "sent": "You will see the following.",
                    "label": 0
                },
                {
                    "sent": "Most of the eigenvalues are symmetric around zero, almost symmetric, around zero, and some of them are, well detached from the rest.",
                    "label": 0
                },
                {
                    "sent": "So by proving these two theorems here, these two formulas, which gives a number of triangles in a graph and the number of trends per node using eigenvalues that eigenvectors, which I'm not going to present in detail now because it's a previous paper, you can just keep few of them and get a very good approximation.",
                    "label": 0
                },
                {
                    "sent": "So my motivation is that I would like to have an algorithm that works independently of the graph.",
                    "label": 0
                },
                {
                    "sent": "Independently of the spectral properties of the graph, so this is what I'm going to talk about so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some related work.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As far as exact counting methods are concerned, we have the following standard facts.",
                    "label": 0
                },
                {
                    "sent": "So the fastest methods rely on matrix matrix multiplication.",
                    "label": 0
                },
                {
                    "sent": "The state of the Art for Matrix matrix multiplication is then to the .37 due to coppersmith and Winograd, but unfortunately, even if asymptotically it's a faster one, it has a very very high complexity, and the memory requirements do not allow this.",
                    "label": 0
                },
                {
                    "sent": "Methods to scale in real world networks in large networks only for medium size.",
                    "label": 0
                },
                {
                    "sent": "So in practice what one does is he he or she applies a listing method rather than just count the number of triangles he can enumerate the nodes that participate in each triangle.",
                    "label": 0
                },
                {
                    "sent": "So these methods in the case of dense graphs result in a cubic algorithm.",
                    "label": 1
                },
                {
                    "sent": "The space complexity is order M, where now I'm since the graph is dense again and square, but the constants are much smaller, so their applicability.",
                    "label": 0
                },
                {
                    "sent": "Practice and for the sparse graph case one can I play some other type of algorithm, typically called iterative algorithms, where one can consider each edge separately and count how many triangles that edge participates in, or the algorithm that I described here the complexity of that method described here called the node aerator, where you consider each node the neighborhood of that node and then count how many edges exist among those nodes.",
                    "label": 0
                },
                {
                    "sent": "So the simple upper bound of the complexities N times a maximum degree squared.",
                    "label": 0
                },
                {
                    "sent": "So as I said, the matrix multiplication algorithm is not practical, and the nice survey for these exact counting methods with theory and experiments is you can find it, and it's by Matthew Lappin.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I will describe to sampling methods becausw the method that we propose disassembling one.",
                    "label": 0
                },
                {
                    "sent": "The first one is the most naive one and the second one is the one that gives a state of the art solution to this problem.",
                    "label": 0
                },
                {
                    "sent": "So the most simple one is choose three nodes randomly from the graph and see if they form a triangle.",
                    "label": 0
                },
                {
                    "sent": "If you choose, who knows, there are four things for things that you can see, either 3 edges, zero edges, one edge, or two edges we call, let's say, T0 the number of.",
                    "label": 0
                },
                {
                    "sent": "People that have no edge T11 edge and so so if you see one triangle by doing this sample then your estimate is one other, otherwise it's 0.",
                    "label": 0
                },
                {
                    "sent": "The expected value of your estimate is equal to this expression.",
                    "label": 0
                },
                {
                    "sent": "Here the number of triangles divided by this sum, which in our case is endustri.",
                    "label": 0
                },
                {
                    "sent": "Since every triple belongs to exactly one of those types, and we haven't choose three of them, so your output is anxious three times, the expected the average of your of the number of samples that you took.",
                    "label": 0
                },
                {
                    "sent": "So the question is what are should be?",
                    "label": 0
                },
                {
                    "sent": "How many samples do you have to take in order to grantee ago?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approximation so in order to guarantee a good approximation with high probability and we think epsilon and epsilon relative approximation.",
                    "label": 0
                },
                {
                    "sent": "So the number of samples depends quadratically on the epsilon.",
                    "label": 0
                },
                {
                    "sent": "The accuracy log one over Delta for the probability of success.",
                    "label": 0
                },
                {
                    "sent": "And then you have this term here.",
                    "label": 0
                },
                {
                    "sent": "This term here is very bad cause for us in practice becausw it requires that your graph is very dense.",
                    "label": 0
                },
                {
                    "sent": "With respect to the triangles.",
                    "label": 0
                },
                {
                    "sent": "So if your graph has lessened and square triangles, then you're in trouble.",
                    "label": 0
                },
                {
                    "sent": "You have no, not that good quality approximation, so it works well for when, for example, the graph is more than N squared log in triangles.",
                    "label": 0
                },
                {
                    "sent": "This this condition here does not happen in practice.",
                    "label": 0
                },
                {
                    "sent": "In practice we have much.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Order number of trends.",
                    "label": 0
                },
                {
                    "sent": "So the state of the art sampling approaches due to brione filing at all.",
                    "label": 0
                },
                {
                    "sent": "So what they do is a sample and edge and the node in dependently and then they check if they form a triangle.",
                    "label": 0
                },
                {
                    "sent": "If they form a triangle then they make an estimate and the details are omitted here.",
                    "label": 0
                },
                {
                    "sent": "But what we care about is the number of samples that they have to take the number of something they have to take is better than the naive one.",
                    "label": 0
                },
                {
                    "sent": "Sorry then then I have one but still requires a graph to be fairly.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since so now I'm going to present our proposed map.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What happens in our proposed method, you toss a coin for each edge in dependently and if veg succeeds to survive then you re weighted by 1 / P where P was a probability for the edge to serve.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If there if the coin that this guy tosses says that this should be deleted with probability 1 -- P, then it dies.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is our algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's exactly what I described through the comic before you toss a coin with probability P of keeping an edge.",
                    "label": 0
                },
                {
                    "sent": "If the edge succeeds, you re weighted by 1 / P, otherwise you delete it.",
                    "label": 0
                },
                {
                    "sent": "Then you get the sparsified graph and then you apply any triangle counting algorithm that specify.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graph.",
                    "label": 0
                },
                {
                    "sent": "So just to give some intuition why this works, and on a single graph, let's say that you have the complete graph, which has anxious three triangles.",
                    "label": 0
                },
                {
                    "sent": "Initially, after you toss a coin, let's say a fair coin, probability 5 heads probability .5 tails.",
                    "label": 0
                },
                {
                    "sent": "You get random mental strain graph with probability of an edge equal 2.5.",
                    "label": 0
                },
                {
                    "sent": "In expectation.",
                    "label": 0
                },
                {
                    "sent": "In this area training graph you have picked up time entries for triangles, and since we count now weighted triangles.",
                    "label": 0
                },
                {
                    "sent": "You multiply by 1 / P cube, so in expectation you get exactly the same number of triangles.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In the paper we prove some basic properties of this method.",
                    "label": 0
                },
                {
                    "sent": "The first basic properties at the expected value of our estimate is the true number of triangles.",
                    "label": 0
                },
                {
                    "sent": "We prove we show what the variance of our estimate is.",
                    "label": 1
                },
                {
                    "sent": "It depends on the number of non edge disjoint triangles.",
                    "label": 0
                },
                {
                    "sent": "So intuitively you can think that if you have an indicator variable for each triangle and you throw away the common edge, then when you have non edge disjoint triangles like here these two then those indicator variables are correlated.",
                    "label": 0
                },
                {
                    "sent": "Therefore you get this term here.",
                    "label": 0
                },
                {
                    "sent": "So the more edge disjoint triangles you have, the better.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approximation is so some results.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We used as our triangle counting books, the No decorator that I described before and.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here, let me say what the expected speedup is if you choose a parameter P to specify the graph, then your expected speedup is 1 / P ^2.",
                    "label": 1
                },
                {
                    "sent": "The proof is 2 lines, since the complex of the Nodata rater is the sum of the degrees squared after the sparsification, you get this P square factor here.",
                    "label": 0
                },
                {
                    "sent": "So, so the expected speedup is 1 / P ^2, as I say.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some results in the Wikipedia 2006 September Graph, 3 million nodes, 35 million edges.",
                    "label": 1
                },
                {
                    "sent": "We use constant P .1.",
                    "label": 0
                },
                {
                    "sent": "You get a speedup of 110 times and very high accuracy.",
                    "label": 0
                },
                {
                    "sent": "The other points you see here correspond to point 9.8 and stepping by .1 backwards until you get to .1 the same from Flickr.",
                    "label": 0
                },
                {
                    "sent": "Very high accuracy.",
                    "label": 0
                },
                {
                    "sent": "Very big speedup.",
                    "label": 0
                },
                {
                    "sent": "Close to this expected one.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see 100.",
                    "label": 0
                },
                {
                    "sent": "The same Wikipedia, November Wikipedia 2007 you get very big speedups and a very very high accuracy estimation of the number of trying.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the conclusion is that in this paper we present a new sampling approach that counts triangles approximately.",
                    "label": 1
                },
                {
                    "sent": "We present the basic analysis of the estimate and in the experiments that I showed, we used constant.",
                    "label": 0
                },
                {
                    "sent": "So what we see is that you can get the constant speed up of 1 / P ^2.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So natural question that comes up and is not answered in Julian is how small can PB we care a lot about this?",
                    "label": 1
                },
                {
                    "sent": "Because if, for example, you could make Pier small as one over root N you would get a linear speedup order end.",
                    "label": 0
                },
                {
                    "sent": "Here are some values just to show you if you could use these P then you would get 1,000,000 speedup and very high accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is extra work.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A few weeks ago with Professor Colin Jackson, Gary Gary Miller, we answered.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Question and we answered it by proving something very strong about this procedure an under very mild conditions on the triangle density of the graph which come from maybe the details of the firm.",
                    "label": 0
                },
                {
                    "sent": "Just I will guide you if you pick P here equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So you make no specification.",
                    "label": 0
                },
                {
                    "sent": "You see that the triangle density is could be very small and times log to the 6 plus gamma and gamma arbitrarily small.",
                    "label": 0
                },
                {
                    "sent": "We give the conditions that you can choose P as small as possible.",
                    "label": 1
                },
                {
                    "sent": "We give a concentration result for this specific choice and the critical quantities in this theorem.",
                    "label": 0
                },
                {
                    "sent": "RT, the number of triangles and Delta the size of the largest collection of triangles with a common edge.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a practitioners guide for counting triangles.",
                    "label": 0
                },
                {
                    "sent": "You can pick P1 over root N in practice and keep doubling it until you use a concentration so that I did that for many graphs like or could You Tube Wikipedia graphs?",
                    "label": 1
                },
                {
                    "sent": "This is a good rule of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because the problem here in this hearing is that you don't know T and you don't know Delta.",
                    "label": 0
                },
                {
                    "sent": "So what the optimal P depends on the things that you want to compute.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Priority so this a rule of thumb that works very well for real world networks.",
                    "label": 0
                },
                {
                    "sent": "1 / N keep doubling you introduce it at most a small logarithmic factor in the whole procedure.",
                    "label": 0
                },
                {
                    "sent": "And here's what you see.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we have the Wikipedia 2005 graph.",
                    "label": 1
                },
                {
                    "sent": "You pick initially one overall 10, let's say .005.",
                    "label": 0
                },
                {
                    "sent": "You don't get the concentration.",
                    "label": 0
                },
                {
                    "sent": "You doublet, .01 you get better concentration when you go to .02.",
                    "label": 0
                },
                {
                    "sent": "You see this concentration here.",
                    "label": 0
                },
                {
                    "sent": "You do 10 experiments.",
                    "label": 0
                },
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "It's concentrated, so if you keep on just for sanity.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Check you get a very strong concentration and somebody distances for the algorithm is at the following.",
                    "label": 0
                },
                {
                    "sent": "If you have linear number of triangles in the graph, then Dylan cannot work because if you throw this edge out then your variance would be very bad.",
                    "label": 0
                },
                {
                    "sent": "You lose all the trends and other bad instances when you have weighted graphs since if W is very very big then if you throw one of these edge then you get a bad estimate too.",
                    "label": 0
                },
                {
                    "sent": "So it works well for anti.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rated unweighted graphs.",
                    "label": 0
                },
                {
                    "sent": "So in the spirit of reproducible research, I make datasets code available and.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Here are the references.",
                    "label": 0
                },
                {
                    "sent": "The last speaker setup.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can have one question doing this because his equipment please.",
                    "label": 0
                },
                {
                    "sent": "Can you play method to Cox making the clustering vector?",
                    "label": 0
                },
                {
                    "sent": "The classroom coefficients for so, so this method is for the global triangle counting problem.",
                    "label": 0
                },
                {
                    "sent": "So it could be applied for the transitivity ratio, since when you specify as you may guess, the degree of each node gets P times degree.",
                    "label": 0
                },
                {
                    "sent": "When you have small degrees, you lose those nodes.",
                    "label": 0
                },
                {
                    "sent": "One piece very small.",
                    "label": 0
                },
                {
                    "sent": "What we get here is a concentration on the total number of triangles, not the classroom coefficients.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}