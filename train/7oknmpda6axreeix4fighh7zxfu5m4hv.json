{
    "id": "7oknmpda6axreeix4fighh7zxfu5m4hv",
    "title": "Multi-Task Discriminative Estimation for Generative Models and Probabilities",
    "info": {
        "author": [
            "Tony Jebara, Department of Computer Science, Columbia University"
        ],
        "published": "March 26, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Multi-Task Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_jebara_mtdegmp/",
    "segmentation": [
        [
            "I'm getting the recipe.",
            "He wrote a book on Jen and discredit, so we're happy to have invited speaker.",
            "You want to carry a word in 2004 and also was one of the inventor of the maximum entropy discrimination framework, which is I think you will talk about it today and some extensions, but it was a good way to combine both worlds.",
            "OK, thank you see more thanks to the organizers for bringing this workshop together.",
            "So what I'll be talking about today is how do you estimate generative models but but as well, introduce constraints so that these generative models do the right discriminative tasks that we want them to do?"
        ],
        [
            "And I'll be covering a few things, including.",
            "OK, here we go.",
            "Including the maximum entropy discrimination approach, which basically adds constraints to probability density estimation, and I'll talk about how that's useful for things like feature in kernel sparsity, and then I'll talk about multitask discrimination constraints, so not just the usual single task discrimination and how we can solve many of these problems as sequential quadratic programs, and then I'll talk at the end about relative margin constraints, which are another family of constraints.",
            "You can also incorporate into this framework, which gives some improvements."
        ],
        [
            "So the setup is going to be fairly simple were given some samples IID from some unknown distribution X, Y or X is some inputs why's typically discrete output spaces, binary or multi class and we have T samples we don't know P of X, Y.",
            "But what we really want is not to recover P of X, Y.",
            "That's a hard problem.",
            "What we'd rather have as a rule that produces an estimate yhat from the input X discriminatively that has low error."
        ],
        [
            "All we really care about when we're doing discrimination.",
            "And so to contrast that with a generative Bayesian approach in a generative approach, you would assume some kind of model, so you'd assume a family of models Theta, where Theta, some parameter Anna prior over the parameters, and you say, well, this is how I'm going to explore all possible relationships between X&Y through this parametric model.",
            "And then you estimate a posterior from that prior, which is just given to the usual Bayes rule.",
            "It's the product of your IID likelihoods times your prior.",
            "And that posterior is then used to make a prediction by integrating over all models weighted by how well the posterior like them.",
            "So you say for this new query I can predict it by integrating over all models according to this posterior score.",
            "And then you say, let me predict by maximum."
        ],
        [
            "Going over this function over X&Y at the end after this integral, so this is the generative Bayesian approach.",
            "A slight variant is to do a conditional Bayesian approach where you say I'm going to just deal with conditional models of Y given X, assume a parametric form of these conditional models, so these could be, let's say, log linear models Anna prior over all possible parameter settings.",
            "And then again, the posteriors given by the same old Bayes rule.",
            "It's a product of the IID likelihoods times your prior, and then your prediction.",
            "If you're just following the standard Bayesian recipe is again integrate over all models, all conditional models.",
            "We waited by the posterior, and then predict yhat, which maximizes this function over X&Y after that integral.",
            "So these are the kind of generative standard approaches you make some assumptions about your model and the prior.",
            "And then you integrate so."
        ],
        [
            "This will work well if you predict if you knew what model to use and if you knew what prior to use.",
            "But if you made.",
            "Bad assumptions you'll often see high training and testing error when you solve these integrals and use that rule for prediction and of the Canonical Bayesian approach.",
            "So one idea is to add margin constraints and say OK, I don't want to just use these vanilla predictors.",
            "I want to force the predictors to also correctly predict the good label for the teeth example to predict YT when I give it XD.",
            "And to predict that with the score that beats all other predictions by a margin of gamma.",
            "So when you do this Arg maximization, make sure that the correct one dominates the others by gamma."
        ],
        [
            "OK, so here's the conditional Bayes approach and what we're going to do is again, use that same prediction rule.",
            "You get the posterior, you wait all the models.",
            "By how well they did under the posterior, and you predict.",
            "And what you're using is in conditional Bayes the posterior, which is the product of your IID likelihoods times in prior right.",
            "That's the posterior using.",
            "You can view this as a minimization over all possible.",
            "Let's say probability distributions that look like this posterior in terms of KL and of course the minimization is going to set this posterior to that product of priors times sorry product of prior times likelihood's.",
            "So we can view this as an optimization.",
            "Now conditional Bayes is really minimizing its choice of the posterior to come as close as possible to the product of likelihoods times the prior.",
            "And now we can add constraints.",
            "This optimization can say, well, wait a minute.",
            "Let's not just use what it naturally wants to pick with this KL divergent, you could use any other divergent to your Bregman divergences like the previous speaker was talking about.",
            "Anything that's going to want to pull this towards this.",
            "Bayesian."
        ],
        [
            "Formula, but now we're going to add some constraints.",
            "This minimization and say in addition I want my prediction rule to correctly predict on my on my training examples.",
            "So here's my prediction rule from over there, and I want the prediction rule to give a higher score for the true label then for all other labels that were incorrect and also to beat the the incorrect labels by at least gamma.",
            "So I'm going to add a whole bunch of these linear classification constraints on the probability.",
            "PDF data instead of using the Canonical one, that base tells me to use.",
            "I'm just going to go out and shop all the let's say incorrect ones, that will give me imperfect classification.",
            "So it turns out this is an interesting problem and we can try to solve things like this.",
            "We're working on this right now.",
            "It gets a little nasty mathematically.",
            "Using healthy Bible wife likes physical traits individually.",
            "Variable Y twice.",
            "Yeah, so this is all other labelings.",
            "You have.",
            "Hooters labels, yeah, so this can you can abstract this away and say this is some prior.",
            "Instead of thinking of it as a product of likelihoods and priors, just think of this as some prior pulling towards if that's easier.",
            "So just one way to view this is just forget the fact that we're pulling towards the Bayesian solution as a prior, we're going to pull towards some prior solution that's easier.",
            "So this is a little tricky to work with.",
            "What we end up doing is actually modifying it and doing this kind of."
        ],
        [
            "Log conditional Bayes where I'm going to introduce logs in here before my actual.",
            "Conditional model over here and the prediction rule as well, so I'm just going to modify things by taking the logarithm, and this is going to make things a lot easier.",
            "So this is a slight modification to the rule, but you can see how we're trying to approximate the standard Bayesian type of inference.",
            "And now it turns out this is very nice to solve.",
            "We"
        ],
        [
            "Can also add slack.",
            "Just the way the SVM would add slack and say, well, I can violate some of these margin constraints as well.",
            "I don't have to get them all perfectly accurately because it might be impossible to find a distribution that gets everything right, so I can add some slack with C dollars per slack usage and now Slack in all these constraints."
        ],
        [
            "It turns out this is exactly what the maximum entropy discrimination framework is doing in solving this type of problem.",
            "Minimizing KL from from for posterior towards some prior distribution, which could be the Bayesian choice.",
            "While enforcing these classification constraints and you allow some of these constraints be violated with Slack and so this permits the Hall of allowable probability distributions to be not vacuous because we're adding some slack here, you might actually cut away too many things if you add too many constraints.",
            "OK, so here's the primal problem and I've."
        ],
        [
            "Simplify things by just saying pull towards some prior you could have used the prior.",
            "That base tells you to use which is the product of the prior times the IID likelihood, or just some arbitrary prior.",
            "If you have something else in mind, minimize the KL from your posterior to the prior subject to these classification constraints which are on average over your posterior.",
            "Your log kind of discriminants your log conditionals for the correct label should be the log conditional for the incorrect label when average overall models.",
            "Given by the posterior with some slack in some margin, you can write the dual of this optimization problem nicely because of it's really a Maxent problem and it just becomes a maximization of a negative log partition function over here.",
            "And here is your actual solution distribution.",
            "Your posterior is going to be a product of your prior times.",
            "These ratios of well, really times the constraints, the exponentiated constraints over here and now there are some lambdas which take these to the powers.",
            "Anna Flounder was set to one.",
            "You basically get back the original Bayesian solution.",
            "But now we're going to.",
            "We're going to explore different lambdas on these.",
            "You can think of these like these IID likelihood terms.",
            "So we're going to take the ID, likely returns to powers, multiplying them by the prior, and that's going to give us the posterior and the way we picked alarm.",
            "This is by solving this dual optimization problem over lambdas, and if you had this slacken version of the Cal minimization you're going to get a box constraint on your lambdas, automatically pops out for free, so this is starting to look a little like in SVM."
        ],
        [
            "So it turns out for the for binary classification, the problem simplifies a little bit.",
            "Let's assume Y could be positive or negative.",
            "And we're going to explore.",
            "Conditionals like this, which belong to the exponential family.",
            "So P of Y given X and your parameters looks like this exponential family form some inner product between X and Theta minus some partition function involving Theta and something to do with the bias term B.",
            "Here this is just a bias term almost like an SVM and so none of my parameters are Theta plus which is a descriptor of the positive class.",
            "Conditional theater minus is the negative class conditional and B is just some bias parameter.",
            "And I picked the prior again, I have to pick priors in this framework.",
            "When I minimize KL divergent's, I'll pick the priors to be conjugate to my two exponential families.",
            "The positive exponential family for the positive class and the negative exponential family for the negative class, and I'll put a noninformative prior on this bias parameter saying any bias is fine.",
            "And then if you solve this.",
            "Immediate problem, the dual actually looks like this.",
            "It starts to look a lot like an SVM.",
            "You've got box constraints in your lambdas.",
            "You've got that single linear constraint the SVM has on your lambdas.",
            "And then you've got the sum of the lambdas here times gamma, which is often one.",
            "So this looks just like the first term in an SVM and then minus this basically cumulant generating function from your conjugate exponential family.",
            "And then minus the conjugate exponential families.",
            "Jim was generating function for the negative class and so these would be just quadratics.",
            "If you were dealing with Gaussians.",
            "So if you just recognise this being a quadratic mapping quadratic, we're going to basically get back in SVM, so the conjugate to the Gaussian is going to be again Gaussian were this.",
            "Calligraphic Kate is just a quadratic, but now we can solve SVM's for things that aren't just Gaussians, and we're going to get something that's not quite quadratic here, but it's always going to be a convex program.",
            "We can solve it with the ellipsoid method.",
            "So was this uptain by minimizing the KL between.",
            "And and prior orders.",
            "So here this is obtained for minimizing the KL to some prior that I'm manually setting here, which you could say is going to be the posterior that Bayes wants to use as well if you like.",
            "So.",
            "Here I'm just I.",
            "If you had you had prior endotracheal yes.",
            "How do you say are you still in computing tonight with them or you not think so?",
            "Now I'm calling this P hack and saying this is the posterior from yeah so you want include also.",
            "Yeah, I want to the likelihood that you can think of it as being absorbed by the definition of the of the of the conjugate family.",
            "So I'm going to pick up a conjugate prior.",
            "I can make that conjugate fire equal to the Bayesian posterior just by adjusting the parameters, and that's what I would suggest to do, yeah?",
            "But I'm just making things simple by not writing that just probably get some brighter.",
            "Bayesian posterior as good properties.",
            "Inconsistent.",
            "So you want to use that as far as you can, and in fact you will stay with the Bayesian posterior if it predicts perfectly in your training data, because you will satisfy all of the constraints.",
            "So I'm only adding these constraints that will kick in when you make mistakes on the training data.",
            "If you don't make any mistakes on the training data with your Bayesian posterior, it'll stay there because that's the one that minimizes KL.",
            "OK."
        ],
        [
            "So here is an example of.",
            "The.",
            "Estimation of two Gaussians I've got X isanos positive and negative data, and I'm trying to fit to Gaussian models the maximum, like a solution on this data set is going to give you about 50% accuracy.",
            "You're just going to find the mean of those in the mean of the ex is, and they're going to have the same covariance.",
            "Or get this linear decision boundary.",
            "But if you run the MD optimization problem in the dual, you're going to see that this is going to change Gaussian.",
            "A and Gaussian B or the positive Gaussian in the negative Gaussian.",
            "Squeeze them and stretch them around until we get this large margin.",
            "Exactly separable decision boundary out of your two Gaussians.",
            "So I'm using this log likelihood ratio of two Gaussian models and if I solve the problem Now, I'm getting zero classification errors, whereas in the original problem.",
            "With maximum likelihood or even the Bayesian version, you're going to get this type of setup.",
            "So I've just solved for a constraint."
        ],
        [
            "Type problem pulling towards this posterior, pulling towards the prior sorry.",
            "And then you can also say, well, let me just deal with log linear models.",
            "This is the simplest possible model for your conditional.",
            "It's a log linear model.",
            "I've got an inner product with X and Theta plus B and then some classification with Y.",
            "If that's my log linear model and I use a prior which is non informative over the over the bias and then the Gaussian prior over the over the parameters of the linear classifier and they solve the dual immediate problem, I get back exactly support vector machines.",
            "Is that 10 minutes or 0 minutes OK?",
            "So that's nice.",
            "So we recover for this simple assumption.",
            "The SVM and we had all these other exponential families that weren't quite log linear, but.",
            "With this type of product they were slightly different and you got.",
            "Other convex programs instead of this quadratic program and the prediction rule from me is exactly the same as in SVM and you can solve this with quadratic programming in cubic time, But it turns out if you only want to epsilon accuracy, you can use very fast solvers.",
            "I would recommend Pegasos."
        ],
        [
            "You can also do feature selection where you also introduce a binary switch vector which is D dimensional sparse affies your model and so now my conditional has not just X and Theta but it has this binary switch vector which turns features on and off and zeros them out and so now my linear models and inner product with X and Theta.",
            "But there's also this S in there which is zeroing out some parts of X.",
            "And I can again put a prior over that, just like I had a prior over the linear model and a non informative prior.",
            "The bias that can also put a Bernoulli prior over my switches saying I want on average 20% of my switches to be on.",
            "And 80% of the switches to be off.",
            "This row parameter tells you in this prior how many features are going to be keeping, and then you can look at the dual and now the dual looks.",
            "A little like than SVM, but now we've got these ugly log arhythmic terms, but if I say I don't want any feature selection Alpha over here becomes 0.",
            "That's kind of related to the feature selection level log hits E and I get back exactly the SVM equation.",
            "So if I say keep all the features I get back in SVM.",
            "But now I'm getting basically a slight variant of the QP of an SVM.",
            "The prediction rule is basically, you know, the usual linear prediction rule where these switches are not killing off some of my dimensions, and these are the values of the switches that MBD recovers once you solve the optimization problem.",
            "OK, so you can do feature selection and it turns out."
        ],
        [
            "Feature selection is in this.",
            "In this format is mimicking what a lasso type of regularization is doing.",
            "In effect, it's more like an elastic elastic net because as you adjust Alpha, you go from quadratic slowly towards an L1 norm.",
            "So for a very large alphas you're going to get an L1 norm regularization when Alpha is equal to 0, you're going to get back a quadratic and it looks just like.",
            "The elastic net.",
            "It's not exactly the same analytically, but visually looks like the same type of regularization."
        ],
        [
            "Xavier and so here's an example of running this for across different regularization values for the C parameter and different row values and so on.",
            "When row equals one, we have an SVM and this is the accuracy of an SVM on this classification problem, and as I introduce more and more feature selection, I'm seeing much higher classification accuracy because I'm sparsifying the model.",
            "This is for some sequence classification in some biology problem.",
            "You can also do kernel selection with the same as."
        ],
        [
            "Roach in kernel selection.",
            "Instead of turning features off and on, you turn off mappings to Hilbert space off and on, so I have the mappings to Hilbert space.",
            "I want to pick a subset of those mappings an add them and say that's going to be my final mapping.",
            "Talbert space and so.",
            "Then my model looks like.",
            "A bunch of inner product between my linear parameters an my mappings to Hilbert space, but I kill off some of these mappings with a switch which can go to between zero and one so I can for some of the mappings to be equal to 0 and turn them off basically.",
            "And then the dual looks again pretty much just like what we had before.",
            "For feature selection you get this thing which looks like a log plus a quadratic term in here, inside the exponent exponentiation.",
            "And again, if A0 you get back in Kentucky and SVM where you just use the kernel which is equal to the average of the base kernels you were given, you just average all the kernels.",
            "But now we can actually pick a subset of the kernels by solving this problem, just like we did feature selection and the prediction will again is going to specify.",
            "The use of the kernels and you're going to multiply some kernels by zero in some kernels by 1.",
            "Yeah, so are some of the best farms.",
            "So some of these values are supposed to go to zero.",
            "There are not going to be exactly 0, because this formula is is going to go towards you over not be exactly, so you have to actually threshold it in the end.",
            "That's a good point.",
            "You can also do this in a multi task setting in a multi task."
        ],
        [
            "Setting I have many different tasks, but they all share a common feature selection, so I might be trying to or common kernel selection.",
            "I might be trying to classify images of faces and some of them are being classified as male, female summer being classified as adult or child and I want to pick the best kernel combination for both tasks, but each task is going to use a different linear model and so then the optimization problem again looks really similar to what we just had before.",
            "The key is this log Alpha plus exponentiated quadratic term.",
            "And the prediction rule is very easy.",
            "It all falls out of the same integrals we were using for me before.",
            "Anne, what's interesting is."
        ],
        [
            "So this is a 20 task problem where you have 29 different tasks and here is the size of the training set for each task and you see an improvement when we do multi task sparsity versus running independent VM's.",
            "So I'm forcing all the tasks to agree on a common kernel selection here say all the tasks out of these 29 tasks have to use the same kernel selection.",
            "And then I I sweep across different sizes of training data and here I'm cross validating to pick Alpha and see.",
            "So you see an improvement when you do multi task kernel selection versus just doing independence, PHMSA with the red line.",
            "This is on the landmine data set, which I don't think is the best for this problem, But anyway."
        ],
        [
            "So how do we optimize this ugly expression which involves these log Alpha plus exponentiated quadratic terms?",
            "This is not a QP, this is is going to look nasty and what we suggest is replacing these log terms with the quadratic upper bound.",
            "Or actually in this case lower bound.",
            "Sorry, negative log terms are going to lower bounded by quadratic, so here's a nice theorem.",
            "It's available in the paper that's that appear in jam alarm my website.",
            "You replace all these negative log terms with this.",
            "Lower bound, which is quadratic in the parameters I care bout in the use.",
            "This is just a quadratic bound.",
            "Now if I do this for all the log terms I see in my Medhi optimization problems, I get back a quadratic optimization problem and I can just solve it with QP.",
            "So this is about you can use to get away from these log terms and it's fairly tight.",
            "So then the recipe is you initialize set."
        ],
        [
            "Our little branch multipliers to zero and you apply the bound and you solve the QP.",
            "And if you change your solution a little bit from the previous step, you go back and you try and you bound.",
            "So it's a variational method and then solve the QP again and you keep iterating.",
            "And we have a theorem that shows that you're not going to iterate more than a constant number of times, so you're going to solve the QP problem, which is really an SVM.",
            "When you use the quadratic bounds that we just saw you going to run that iteration this many times.",
            "So it's about a constant factor.",
            "More work than an SVM.",
            "It's very fast, takes about."
        ],
        [
            "10 or so iterations, and the way you prove this is because we can sandwich the media objective function with two quadratics, a lower bounded quadratic in an upper bounded quadratic, and you look at the curvature of those two quadratics.",
            "The curvatures are the same, you will need one QP to solve that, because it's the sandwiched function is itself a quadratic.",
            "And as the curvatures get different, more and more different between the upper and lower bound, eating more iterations, but you can quickly bound the number of iterations using this trick.",
            "Anne."
        ],
        [
            "And as one last step, why stop with just the margin constraints?",
            "So we just add a constraint to the Bayesian approach saying you should predict better with the correct label and all the other incorrect labels your.",
            "Your posterior should give a higher score for the correct label and then all the others.",
            "Another thing we can add is say, your correct label should not beat the weakest guy by too much.",
            "OK, so the usual constraint is the correct label should beat the second runner up by gamma some margin, but also make sure you don't beat that poor guy who is really messing up the weakest, the weakest guy by too much by more than beta.",
            "So we added these constraints in the relative margin machine in 2008.",
            "Basically it's the same optimization problem where minimizing KL.",
            "We add these constraints saying the correct guy should beat all the other guys by gamma, but it shouldn't beat the.",
            "The weakest guy by more than beta.",
            "Will be it is larger than gamma obviously.",
            "So in an SVM the constraints are basically really simple.",
            "You minimize the magnitude of W, but you make sure you get the correct classification.",
            "You score more than gamma, but you also don't score too high.",
            "Yeah, alright, I'll show you how to do it.",
            "Additional info if I'm expecting which.",
            "ASCII.",
            "Yeah, so you can do dynamic programming when you have very large.",
            "Why spaces here as well?",
            "As demonstrated by Zoom and shake with an empty technique last year."
        ],
        [
            "So it's basically going on is, let's say these these two classes, some squares and some triangles.",
            "The SVM like to separate them this way, that's the maximum margin, thickest red line I could draw between the two classes, but this green line is actually what we're suggesting in this relative margin approach.",
            "I want to separate these.",
            "Triangles and squares by a lot, but not by too much.",
            "So if I look at the projections, the green decision boundary projects all these points to minus one.",
            "All these points to plus one.",
            "And so here gamma is basically one, and beta is let's say 1.1.",
            "Whereas the SVM projects things with a lot of spread.",
            "Got it so you get stuff that's less than negative.",
            "One correctly classified, but sometimes negative three out here for some of these predictions and positive.",
            "Three out here for some of these predictions.",
            "And so also if you scale the data, this thing starts to get worse and worse.",
            "The SVM decision boundary starts to move more and more, whereas this relative margin method, which is limiting the prediction so that you don't predict too high or too low in addition to clear by plus or minus one, stay stable.",
            "So it turns out this solution is invariant to affine transformations of your data.",
            "The SVM isn't.",
            "This is another advantage of the RMM."
        ],
        [
            "Versus the SVM.",
            "And so we tried this on many different datasets.",
            "Here's the SVM, his kernel Fisher discriminant analysis, a couple of other flavors of SVM's, and in a star you see significantly better than other methods, and the ARM method is basically significantly better more than half the time when all these datasets you know once SVM is significantly better, once kernel Fisher discriminant simply significantly better, but the arm is about 60% of the time significantly better than the other methods, just by introducing.",
            "This other strange constraint, which is a little like a discrimination constraint, but it's saying don't get too confident."
        ],
        [
            "And we also applied this to structured prediction and June Zoo and Eric Jing should hike and apply MBD to structured prediction problems in 2009 and also in 2008.",
            "You can also add these relative margin constraints to structured prediction problems so you don't just have to deal with why being binary the same formula is actually you just have to be efficient and how you compute your argmax and your argument by doing dynamic programming.",
            "Here's a multi class setup.",
            "We have different polynomial kernels were doing multiclass classification and you see the error rate of these structures.",
            "RMM is much lower than instructs VM because of these extra bounding constraints.",
            "These red constraint not just discrimination with margin but limiting spread.",
            "And then here's the named entity recognition problem and the parts of speech problem and you can see the same improvement from CRF to struct.",
            "SVM continues to struct RMM.",
            "One of the same amount of error reduction and actually dramatic error reduction on the parts of speech tagging from the CRF to struct STM, and then a really dramatic almost 1% error.",
            "That's saying that I'm finished this nice.",
            "Music and I'll just go to Michael."
        ],
        [
            "Allusion slide and say you can add margin constraints.",
            "The generative learning.",
            "This leads to this maximum entropy discrimination framework.",
            "It's a natural tool to explore multitask problems.",
            "Feature selection and kernel selection.",
            "The optimizations can be solved as sequential quadratic programs, and you can bound the number of iterations of this sequential quadratic program so you don't need more than a constant number of iterations, so it's not much more than constant work more than SVM.",
            "And then you can also add these relative margin constraints which look like the margin constraints we added to the Bayesian estimate.",
            "But they're just saying the correct label should beat all the other ones by.",
            "Gamma, but shouldn't beat anybody by more than beta.",
            "And this leads to further improvement, and in fact I think this relative margin ideas a little generative in it's it's kind of flavor because it's not just looking at the discrimination boundary, it's also looking at the spread, which is something generative models often do.",
            "But discriminative models say just focus on the decision boundary and don't care about what's happening far away from it.",
            "And I'll stop here.",
            "So I have a technical question and a high level question, so the technical question is for this quadratic optimization thing in the.",
            "In the variational formulation you have this thing that would like log something, plus either be landed be where they seem to be is like your variational parameter.",
            "But so how do you get the variational parameter if?",
            "I mean, if you're trying to minimize be, this looks like exactly the original thing that you're trying to minimize.",
            "So how does it make it any easier?",
            "OK, so that's a good question.",
            "I can just jump back to it.",
            "It's really the V is your previous setting of the LaGrange multipliers, so your your you don't have to do any extra.",
            "Work to recover VV is what you used to be.",
            "At the previous setting, and so this bound is as tight an exact when V = U.",
            "And then yeah, from there you say I'm going to try to take a step.",
            "Yeah, just quadratic questions like the sort of relative margin idea is very good when you have many more dimensions than examples, but I've never had a great intuition for why.",
            "Why sort of artist?",
            "Standard regularizers that we use or even like these L1 regularizer's aren't enough?",
            "Like why did you Additionally want this relative margin?",
            "So I mean the relative margin idea I've just presented intuitively here we have some bounds actually that show.",
            "So a lot of the.",
            "The generalization guarantees in learning theory use McDermott and how things bounds and it turns out if you use some of these variants based balance, like Bernstein and Bennetts bounds, you can show why limiting the spread, which basically limits the variance is going to lead to better generalization.",
            "And now there's an empirical Bernstein.",
            "Inequality, which was proposed in call 2009, where you can use a plug in for the for the variance, which is an empirical measurement, not.",
            "You know the troop variance and so when you use that you're basically saying I want my.",
            "My y * F of X, let's say margin values to be concentrated around let's say, plus one.",
            "So I'm pretty thing well.",
            "Or always be larger than one, but also not to have too much variance.",
            "Because if you have a high variance and everybody is larger than one, it's easier for a high variance Gaussian to see kind of a jump across the zero origin, which leads to an error.",
            "So high variance it makes it easier for things in the future to be sampled far away, and that leads to more errors.",
            "That's the general flavor for the theory.",
            "The following onto that was kind of intuition that is being tends to run tends to over a store underneath, make the management server estimate the margin in the sense that the data have been sampled somewhere, but there's still kind of tails of the distribution that falls into the margin so that ideal distribution will will be.",
            "Type it faster than tablet K, so that's kind of intuition.",
            "From what you say, but if that intuition is really true, then probably what you want to do is look at the density near the margin and make sure that's tight rather than the whole density over the entire region of the class.",
            "Yeah, so that's an interesting point.",
            "So you want to focus on that.",
            "Let's say the density near the margin, you're right, yeah, open the SPM in some sense that you wanted more logistic decay or something in that in that little region with the management.",
            "Yeah, so again, the logistic is capturing some of this intuition as well, because there's a soft focus on how things are spreading away and you get penalties.",
            "It's not just are you above one or not, but in addition, I think even logistic regression.",
            "Is sensitive to affine transformations, so both logistic an SVM in optimizing their quantities and not looking at the spread.",
            "You can get them to actually do fairly badly by adversarially.",
            "Transforming your data within a fine transformation an invertible affine transformation.",
            "So we've seen some scenarios where we're able to keep increasing the error of the SVM.",
            "Let's say double, double, and tripling it by doing these adverse aerial affine transformations which are completely invertible.",
            "So we're not destroying anything when we're doing them, whereas this method stays stable and same for logistic regression as well.",
            "Could you say a little bit more about how the actual discriminants differ between 2 cases in the credit score mean?",
            "Have you seen?",
            "It's very important to mention that kind of how things differ.",
            "People said it is being.",
            "So things different typically because you see things more concentrated around let's say, plus one and minus one with the RMM, the SVM you see larger margins, but there's a.",
            "There's a big variation, it's hard to describe exactly what's going on in high dimensional data.",
            "But yeah, I mean the affine kind of adverse aerial affine transformations.",
            "Another another idea, so we're seeing some scenarios where if you scale your data badly, the SVM gets really confused.",
            "For my class.",
            "Is the origonal SPN is obviously Angels?",
            "If there's an odometer class, so people example X official.",
            "From the tree distribution, then it says improvement.",
            "Fun to scoring function Dot assign all the labels to to the same.",
            "Probably that's why it cost the officiating consciousness cause the inconsistent.",
            "Bring in your case, if you add the RMA in whether having the same problem with there's no majority class.",
            "So when there's no majority class so you know the setup is very similar to the random label noise setup.",
            "Is that we are referring to is like some like giving the songs that we got so she should be no like.",
            "Heister hoping, but less than half yeah, Darkest Swim will fail.",
            "But if he's not, he's asking for work fine, so, well, alright then, so we haven't looked specifically at those cases with, you know, when there's no real clear winning class or there's high label noise.",
            "But I do know there was a theorem by Rocko Cervetti on Phil Long, saying that any convex optimization problem is going to get fooled by random label noise, and so the key is to avoid the convexity.",
            "In the solver, use conditioner view all.",
            "Is this consistent no matter?",
            "Ocelot um, I'd have to.",
            "I'd have to think about that offline.",
            "I can't say off the top of my head.",
            "We haven't.",
            "We haven't looked into this problem in detail with the arm, so maybe it has the same problems as the SVM or maybe gets away from them and is still consistent.",
            "I'm not sure.",
            "So I guess it's a good time to be defined with some thinking, thinking, speaker game.",
            "Thanks.",
            "Until.",
            "The session starts again at 3:50 PM."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm getting the recipe.",
                    "label": 0
                },
                {
                    "sent": "He wrote a book on Jen and discredit, so we're happy to have invited speaker.",
                    "label": 0
                },
                {
                    "sent": "You want to carry a word in 2004 and also was one of the inventor of the maximum entropy discrimination framework, which is I think you will talk about it today and some extensions, but it was a good way to combine both worlds.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you see more thanks to the organizers for bringing this workshop together.",
                    "label": 0
                },
                {
                    "sent": "So what I'll be talking about today is how do you estimate generative models but but as well, introduce constraints so that these generative models do the right discriminative tasks that we want them to do?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I'll be covering a few things, including.",
                    "label": 0
                },
                {
                    "sent": "OK, here we go.",
                    "label": 0
                },
                {
                    "sent": "Including the maximum entropy discrimination approach, which basically adds constraints to probability density estimation, and I'll talk about how that's useful for things like feature in kernel sparsity, and then I'll talk about multitask discrimination constraints, so not just the usual single task discrimination and how we can solve many of these problems as sequential quadratic programs, and then I'll talk at the end about relative margin constraints, which are another family of constraints.",
                    "label": 1
                },
                {
                    "sent": "You can also incorporate into this framework, which gives some improvements.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the setup is going to be fairly simple were given some samples IID from some unknown distribution X, Y or X is some inputs why's typically discrete output spaces, binary or multi class and we have T samples we don't know P of X, Y.",
                    "label": 0
                },
                {
                    "sent": "But what we really want is not to recover P of X, Y.",
                    "label": 0
                },
                {
                    "sent": "That's a hard problem.",
                    "label": 0
                },
                {
                    "sent": "What we'd rather have as a rule that produces an estimate yhat from the input X discriminatively that has low error.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All we really care about when we're doing discrimination.",
                    "label": 0
                },
                {
                    "sent": "And so to contrast that with a generative Bayesian approach in a generative approach, you would assume some kind of model, so you'd assume a family of models Theta, where Theta, some parameter Anna prior over the parameters, and you say, well, this is how I'm going to explore all possible relationships between X&Y through this parametric model.",
                    "label": 0
                },
                {
                    "sent": "And then you estimate a posterior from that prior, which is just given to the usual Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "It's the product of your IID likelihoods times your prior.",
                    "label": 0
                },
                {
                    "sent": "And that posterior is then used to make a prediction by integrating over all models weighted by how well the posterior like them.",
                    "label": 0
                },
                {
                    "sent": "So you say for this new query I can predict it by integrating over all models according to this posterior score.",
                    "label": 0
                },
                {
                    "sent": "And then you say, let me predict by maximum.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going over this function over X&Y at the end after this integral, so this is the generative Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "A slight variant is to do a conditional Bayesian approach where you say I'm going to just deal with conditional models of Y given X, assume a parametric form of these conditional models, so these could be, let's say, log linear models Anna prior over all possible parameter settings.",
                    "label": 0
                },
                {
                    "sent": "And then again, the posteriors given by the same old Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "It's a product of the IID likelihoods times your prior, and then your prediction.",
                    "label": 0
                },
                {
                    "sent": "If you're just following the standard Bayesian recipe is again integrate over all models, all conditional models.",
                    "label": 0
                },
                {
                    "sent": "We waited by the posterior, and then predict yhat, which maximizes this function over X&Y after that integral.",
                    "label": 0
                },
                {
                    "sent": "So these are the kind of generative standard approaches you make some assumptions about your model and the prior.",
                    "label": 0
                },
                {
                    "sent": "And then you integrate so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This will work well if you predict if you knew what model to use and if you knew what prior to use.",
                    "label": 0
                },
                {
                    "sent": "But if you made.",
                    "label": 0
                },
                {
                    "sent": "Bad assumptions you'll often see high training and testing error when you solve these integrals and use that rule for prediction and of the Canonical Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "So one idea is to add margin constraints and say OK, I don't want to just use these vanilla predictors.",
                    "label": 0
                },
                {
                    "sent": "I want to force the predictors to also correctly predict the good label for the teeth example to predict YT when I give it XD.",
                    "label": 0
                },
                {
                    "sent": "And to predict that with the score that beats all other predictions by a margin of gamma.",
                    "label": 0
                },
                {
                    "sent": "So when you do this Arg maximization, make sure that the correct one dominates the others by gamma.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's the conditional Bayes approach and what we're going to do is again, use that same prediction rule.",
                    "label": 0
                },
                {
                    "sent": "You get the posterior, you wait all the models.",
                    "label": 0
                },
                {
                    "sent": "By how well they did under the posterior, and you predict.",
                    "label": 0
                },
                {
                    "sent": "And what you're using is in conditional Bayes the posterior, which is the product of your IID likelihoods times in prior right.",
                    "label": 0
                },
                {
                    "sent": "That's the posterior using.",
                    "label": 0
                },
                {
                    "sent": "You can view this as a minimization over all possible.",
                    "label": 0
                },
                {
                    "sent": "Let's say probability distributions that look like this posterior in terms of KL and of course the minimization is going to set this posterior to that product of priors times sorry product of prior times likelihood's.",
                    "label": 0
                },
                {
                    "sent": "So we can view this as an optimization.",
                    "label": 0
                },
                {
                    "sent": "Now conditional Bayes is really minimizing its choice of the posterior to come as close as possible to the product of likelihoods times the prior.",
                    "label": 0
                },
                {
                    "sent": "And now we can add constraints.",
                    "label": 0
                },
                {
                    "sent": "This optimization can say, well, wait a minute.",
                    "label": 0
                },
                {
                    "sent": "Let's not just use what it naturally wants to pick with this KL divergent, you could use any other divergent to your Bregman divergences like the previous speaker was talking about.",
                    "label": 0
                },
                {
                    "sent": "Anything that's going to want to pull this towards this.",
                    "label": 0
                },
                {
                    "sent": "Bayesian.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formula, but now we're going to add some constraints.",
                    "label": 0
                },
                {
                    "sent": "This minimization and say in addition I want my prediction rule to correctly predict on my on my training examples.",
                    "label": 0
                },
                {
                    "sent": "So here's my prediction rule from over there, and I want the prediction rule to give a higher score for the true label then for all other labels that were incorrect and also to beat the the incorrect labels by at least gamma.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to add a whole bunch of these linear classification constraints on the probability.",
                    "label": 0
                },
                {
                    "sent": "PDF data instead of using the Canonical one, that base tells me to use.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to go out and shop all the let's say incorrect ones, that will give me imperfect classification.",
                    "label": 0
                },
                {
                    "sent": "So it turns out this is an interesting problem and we can try to solve things like this.",
                    "label": 0
                },
                {
                    "sent": "We're working on this right now.",
                    "label": 0
                },
                {
                    "sent": "It gets a little nasty mathematically.",
                    "label": 0
                },
                {
                    "sent": "Using healthy Bible wife likes physical traits individually.",
                    "label": 0
                },
                {
                    "sent": "Variable Y twice.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is all other labelings.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "Hooters labels, yeah, so this can you can abstract this away and say this is some prior.",
                    "label": 0
                },
                {
                    "sent": "Instead of thinking of it as a product of likelihoods and priors, just think of this as some prior pulling towards if that's easier.",
                    "label": 0
                },
                {
                    "sent": "So just one way to view this is just forget the fact that we're pulling towards the Bayesian solution as a prior, we're going to pull towards some prior solution that's easier.",
                    "label": 0
                },
                {
                    "sent": "So this is a little tricky to work with.",
                    "label": 0
                },
                {
                    "sent": "What we end up doing is actually modifying it and doing this kind of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Log conditional Bayes where I'm going to introduce logs in here before my actual.",
                    "label": 1
                },
                {
                    "sent": "Conditional model over here and the prediction rule as well, so I'm just going to modify things by taking the logarithm, and this is going to make things a lot easier.",
                    "label": 0
                },
                {
                    "sent": "So this is a slight modification to the rule, but you can see how we're trying to approximate the standard Bayesian type of inference.",
                    "label": 0
                },
                {
                    "sent": "And now it turns out this is very nice to solve.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can also add slack.",
                    "label": 0
                },
                {
                    "sent": "Just the way the SVM would add slack and say, well, I can violate some of these margin constraints as well.",
                    "label": 0
                },
                {
                    "sent": "I don't have to get them all perfectly accurately because it might be impossible to find a distribution that gets everything right, so I can add some slack with C dollars per slack usage and now Slack in all these constraints.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It turns out this is exactly what the maximum entropy discrimination framework is doing in solving this type of problem.",
                    "label": 0
                },
                {
                    "sent": "Minimizing KL from from for posterior towards some prior distribution, which could be the Bayesian choice.",
                    "label": 0
                },
                {
                    "sent": "While enforcing these classification constraints and you allow some of these constraints be violated with Slack and so this permits the Hall of allowable probability distributions to be not vacuous because we're adding some slack here, you might actually cut away too many things if you add too many constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's the primal problem and I've.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simplify things by just saying pull towards some prior you could have used the prior.",
                    "label": 0
                },
                {
                    "sent": "That base tells you to use which is the product of the prior times the IID likelihood, or just some arbitrary prior.",
                    "label": 0
                },
                {
                    "sent": "If you have something else in mind, minimize the KL from your posterior to the prior subject to these classification constraints which are on average over your posterior.",
                    "label": 0
                },
                {
                    "sent": "Your log kind of discriminants your log conditionals for the correct label should be the log conditional for the incorrect label when average overall models.",
                    "label": 0
                },
                {
                    "sent": "Given by the posterior with some slack in some margin, you can write the dual of this optimization problem nicely because of it's really a Maxent problem and it just becomes a maximization of a negative log partition function over here.",
                    "label": 0
                },
                {
                    "sent": "And here is your actual solution distribution.",
                    "label": 0
                },
                {
                    "sent": "Your posterior is going to be a product of your prior times.",
                    "label": 0
                },
                {
                    "sent": "These ratios of well, really times the constraints, the exponentiated constraints over here and now there are some lambdas which take these to the powers.",
                    "label": 0
                },
                {
                    "sent": "Anna Flounder was set to one.",
                    "label": 0
                },
                {
                    "sent": "You basically get back the original Bayesian solution.",
                    "label": 0
                },
                {
                    "sent": "But now we're going to.",
                    "label": 0
                },
                {
                    "sent": "We're going to explore different lambdas on these.",
                    "label": 0
                },
                {
                    "sent": "You can think of these like these IID likelihood terms.",
                    "label": 0
                },
                {
                    "sent": "So we're going to take the ID, likely returns to powers, multiplying them by the prior, and that's going to give us the posterior and the way we picked alarm.",
                    "label": 0
                },
                {
                    "sent": "This is by solving this dual optimization problem over lambdas, and if you had this slacken version of the Cal minimization you're going to get a box constraint on your lambdas, automatically pops out for free, so this is starting to look a little like in SVM.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it turns out for the for binary classification, the problem simplifies a little bit.",
                    "label": 0
                },
                {
                    "sent": "Let's assume Y could be positive or negative.",
                    "label": 0
                },
                {
                    "sent": "And we're going to explore.",
                    "label": 0
                },
                {
                    "sent": "Conditionals like this, which belong to the exponential family.",
                    "label": 1
                },
                {
                    "sent": "So P of Y given X and your parameters looks like this exponential family form some inner product between X and Theta minus some partition function involving Theta and something to do with the bias term B.",
                    "label": 0
                },
                {
                    "sent": "Here this is just a bias term almost like an SVM and so none of my parameters are Theta plus which is a descriptor of the positive class.",
                    "label": 0
                },
                {
                    "sent": "Conditional theater minus is the negative class conditional and B is just some bias parameter.",
                    "label": 0
                },
                {
                    "sent": "And I picked the prior again, I have to pick priors in this framework.",
                    "label": 0
                },
                {
                    "sent": "When I minimize KL divergent's, I'll pick the priors to be conjugate to my two exponential families.",
                    "label": 0
                },
                {
                    "sent": "The positive exponential family for the positive class and the negative exponential family for the negative class, and I'll put a noninformative prior on this bias parameter saying any bias is fine.",
                    "label": 0
                },
                {
                    "sent": "And then if you solve this.",
                    "label": 0
                },
                {
                    "sent": "Immediate problem, the dual actually looks like this.",
                    "label": 0
                },
                {
                    "sent": "It starts to look a lot like an SVM.",
                    "label": 0
                },
                {
                    "sent": "You've got box constraints in your lambdas.",
                    "label": 0
                },
                {
                    "sent": "You've got that single linear constraint the SVM has on your lambdas.",
                    "label": 0
                },
                {
                    "sent": "And then you've got the sum of the lambdas here times gamma, which is often one.",
                    "label": 0
                },
                {
                    "sent": "So this looks just like the first term in an SVM and then minus this basically cumulant generating function from your conjugate exponential family.",
                    "label": 0
                },
                {
                    "sent": "And then minus the conjugate exponential families.",
                    "label": 1
                },
                {
                    "sent": "Jim was generating function for the negative class and so these would be just quadratics.",
                    "label": 0
                },
                {
                    "sent": "If you were dealing with Gaussians.",
                    "label": 0
                },
                {
                    "sent": "So if you just recognise this being a quadratic mapping quadratic, we're going to basically get back in SVM, so the conjugate to the Gaussian is going to be again Gaussian were this.",
                    "label": 1
                },
                {
                    "sent": "Calligraphic Kate is just a quadratic, but now we can solve SVM's for things that aren't just Gaussians, and we're going to get something that's not quite quadratic here, but it's always going to be a convex program.",
                    "label": 1
                },
                {
                    "sent": "We can solve it with the ellipsoid method.",
                    "label": 0
                },
                {
                    "sent": "So was this uptain by minimizing the KL between.",
                    "label": 0
                },
                {
                    "sent": "And and prior orders.",
                    "label": 0
                },
                {
                    "sent": "So here this is obtained for minimizing the KL to some prior that I'm manually setting here, which you could say is going to be the posterior that Bayes wants to use as well if you like.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here I'm just I.",
                    "label": 0
                },
                {
                    "sent": "If you had you had prior endotracheal yes.",
                    "label": 1
                },
                {
                    "sent": "How do you say are you still in computing tonight with them or you not think so?",
                    "label": 0
                },
                {
                    "sent": "Now I'm calling this P hack and saying this is the posterior from yeah so you want include also.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I want to the likelihood that you can think of it as being absorbed by the definition of the of the of the conjugate family.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to pick up a conjugate prior.",
                    "label": 0
                },
                {
                    "sent": "I can make that conjugate fire equal to the Bayesian posterior just by adjusting the parameters, and that's what I would suggest to do, yeah?",
                    "label": 0
                },
                {
                    "sent": "But I'm just making things simple by not writing that just probably get some brighter.",
                    "label": 0
                },
                {
                    "sent": "Bayesian posterior as good properties.",
                    "label": 0
                },
                {
                    "sent": "Inconsistent.",
                    "label": 0
                },
                {
                    "sent": "So you want to use that as far as you can, and in fact you will stay with the Bayesian posterior if it predicts perfectly in your training data, because you will satisfy all of the constraints.",
                    "label": 0
                },
                {
                    "sent": "So I'm only adding these constraints that will kick in when you make mistakes on the training data.",
                    "label": 0
                },
                {
                    "sent": "If you don't make any mistakes on the training data with your Bayesian posterior, it'll stay there because that's the one that minimizes KL.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is an example of.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Estimation of two Gaussians I've got X isanos positive and negative data, and I'm trying to fit to Gaussian models the maximum, like a solution on this data set is going to give you about 50% accuracy.",
                    "label": 0
                },
                {
                    "sent": "You're just going to find the mean of those in the mean of the ex is, and they're going to have the same covariance.",
                    "label": 0
                },
                {
                    "sent": "Or get this linear decision boundary.",
                    "label": 0
                },
                {
                    "sent": "But if you run the MD optimization problem in the dual, you're going to see that this is going to change Gaussian.",
                    "label": 0
                },
                {
                    "sent": "A and Gaussian B or the positive Gaussian in the negative Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Squeeze them and stretch them around until we get this large margin.",
                    "label": 0
                },
                {
                    "sent": "Exactly separable decision boundary out of your two Gaussians.",
                    "label": 0
                },
                {
                    "sent": "So I'm using this log likelihood ratio of two Gaussian models and if I solve the problem Now, I'm getting zero classification errors, whereas in the original problem.",
                    "label": 0
                },
                {
                    "sent": "With maximum likelihood or even the Bayesian version, you're going to get this type of setup.",
                    "label": 0
                },
                {
                    "sent": "So I've just solved for a constraint.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Type problem pulling towards this posterior, pulling towards the prior sorry.",
                    "label": 0
                },
                {
                    "sent": "And then you can also say, well, let me just deal with log linear models.",
                    "label": 0
                },
                {
                    "sent": "This is the simplest possible model for your conditional.",
                    "label": 0
                },
                {
                    "sent": "It's a log linear model.",
                    "label": 0
                },
                {
                    "sent": "I've got an inner product with X and Theta plus B and then some classification with Y.",
                    "label": 1
                },
                {
                    "sent": "If that's my log linear model and I use a prior which is non informative over the over the bias and then the Gaussian prior over the over the parameters of the linear classifier and they solve the dual immediate problem, I get back exactly support vector machines.",
                    "label": 1
                },
                {
                    "sent": "Is that 10 minutes or 0 minutes OK?",
                    "label": 0
                },
                {
                    "sent": "So that's nice.",
                    "label": 0
                },
                {
                    "sent": "So we recover for this simple assumption.",
                    "label": 0
                },
                {
                    "sent": "The SVM and we had all these other exponential families that weren't quite log linear, but.",
                    "label": 0
                },
                {
                    "sent": "With this type of product they were slightly different and you got.",
                    "label": 0
                },
                {
                    "sent": "Other convex programs instead of this quadratic program and the prediction rule from me is exactly the same as in SVM and you can solve this with quadratic programming in cubic time, But it turns out if you only want to epsilon accuracy, you can use very fast solvers.",
                    "label": 1
                },
                {
                    "sent": "I would recommend Pegasos.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also do feature selection where you also introduce a binary switch vector which is D dimensional sparse affies your model and so now my conditional has not just X and Theta but it has this binary switch vector which turns features on and off and zeros them out and so now my linear models and inner product with X and Theta.",
                    "label": 0
                },
                {
                    "sent": "But there's also this S in there which is zeroing out some parts of X.",
                    "label": 0
                },
                {
                    "sent": "And I can again put a prior over that, just like I had a prior over the linear model and a non informative prior.",
                    "label": 0
                },
                {
                    "sent": "The bias that can also put a Bernoulli prior over my switches saying I want on average 20% of my switches to be on.",
                    "label": 0
                },
                {
                    "sent": "And 80% of the switches to be off.",
                    "label": 0
                },
                {
                    "sent": "This row parameter tells you in this prior how many features are going to be keeping, and then you can look at the dual and now the dual looks.",
                    "label": 0
                },
                {
                    "sent": "A little like than SVM, but now we've got these ugly log arhythmic terms, but if I say I don't want any feature selection Alpha over here becomes 0.",
                    "label": 0
                },
                {
                    "sent": "That's kind of related to the feature selection level log hits E and I get back exactly the SVM equation.",
                    "label": 0
                },
                {
                    "sent": "So if I say keep all the features I get back in SVM.",
                    "label": 0
                },
                {
                    "sent": "But now I'm getting basically a slight variant of the QP of an SVM.",
                    "label": 0
                },
                {
                    "sent": "The prediction rule is basically, you know, the usual linear prediction rule where these switches are not killing off some of my dimensions, and these are the values of the switches that MBD recovers once you solve the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can do feature selection and it turns out.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feature selection is in this.",
                    "label": 0
                },
                {
                    "sent": "In this format is mimicking what a lasso type of regularization is doing.",
                    "label": 0
                },
                {
                    "sent": "In effect, it's more like an elastic elastic net because as you adjust Alpha, you go from quadratic slowly towards an L1 norm.",
                    "label": 0
                },
                {
                    "sent": "So for a very large alphas you're going to get an L1 norm regularization when Alpha is equal to 0, you're going to get back a quadratic and it looks just like.",
                    "label": 0
                },
                {
                    "sent": "The elastic net.",
                    "label": 0
                },
                {
                    "sent": "It's not exactly the same analytically, but visually looks like the same type of regularization.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Xavier and so here's an example of running this for across different regularization values for the C parameter and different row values and so on.",
                    "label": 0
                },
                {
                    "sent": "When row equals one, we have an SVM and this is the accuracy of an SVM on this classification problem, and as I introduce more and more feature selection, I'm seeing much higher classification accuracy because I'm sparsifying the model.",
                    "label": 1
                },
                {
                    "sent": "This is for some sequence classification in some biology problem.",
                    "label": 0
                },
                {
                    "sent": "You can also do kernel selection with the same as.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Roach in kernel selection.",
                    "label": 0
                },
                {
                    "sent": "Instead of turning features off and on, you turn off mappings to Hilbert space off and on, so I have the mappings to Hilbert space.",
                    "label": 1
                },
                {
                    "sent": "I want to pick a subset of those mappings an add them and say that's going to be my final mapping.",
                    "label": 0
                },
                {
                    "sent": "Talbert space and so.",
                    "label": 0
                },
                {
                    "sent": "Then my model looks like.",
                    "label": 0
                },
                {
                    "sent": "A bunch of inner product between my linear parameters an my mappings to Hilbert space, but I kill off some of these mappings with a switch which can go to between zero and one so I can for some of the mappings to be equal to 0 and turn them off basically.",
                    "label": 0
                },
                {
                    "sent": "And then the dual looks again pretty much just like what we had before.",
                    "label": 0
                },
                {
                    "sent": "For feature selection you get this thing which looks like a log plus a quadratic term in here, inside the exponent exponentiation.",
                    "label": 0
                },
                {
                    "sent": "And again, if A0 you get back in Kentucky and SVM where you just use the kernel which is equal to the average of the base kernels you were given, you just average all the kernels.",
                    "label": 0
                },
                {
                    "sent": "But now we can actually pick a subset of the kernels by solving this problem, just like we did feature selection and the prediction will again is going to specify.",
                    "label": 0
                },
                {
                    "sent": "The use of the kernels and you're going to multiply some kernels by zero in some kernels by 1.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so are some of the best farms.",
                    "label": 0
                },
                {
                    "sent": "So some of these values are supposed to go to zero.",
                    "label": 0
                },
                {
                    "sent": "There are not going to be exactly 0, because this formula is is going to go towards you over not be exactly, so you have to actually threshold it in the end.",
                    "label": 0
                },
                {
                    "sent": "That's a good point.",
                    "label": 0
                },
                {
                    "sent": "You can also do this in a multi task setting in a multi task.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Setting I have many different tasks, but they all share a common feature selection, so I might be trying to or common kernel selection.",
                    "label": 0
                },
                {
                    "sent": "I might be trying to classify images of faces and some of them are being classified as male, female summer being classified as adult or child and I want to pick the best kernel combination for both tasks, but each task is going to use a different linear model and so then the optimization problem again looks really similar to what we just had before.",
                    "label": 0
                },
                {
                    "sent": "The key is this log Alpha plus exponentiated quadratic term.",
                    "label": 0
                },
                {
                    "sent": "And the prediction rule is very easy.",
                    "label": 0
                },
                {
                    "sent": "It all falls out of the same integrals we were using for me before.",
                    "label": 0
                },
                {
                    "sent": "Anne, what's interesting is.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a 20 task problem where you have 29 different tasks and here is the size of the training set for each task and you see an improvement when we do multi task sparsity versus running independent VM's.",
                    "label": 0
                },
                {
                    "sent": "So I'm forcing all the tasks to agree on a common kernel selection here say all the tasks out of these 29 tasks have to use the same kernel selection.",
                    "label": 1
                },
                {
                    "sent": "And then I I sweep across different sizes of training data and here I'm cross validating to pick Alpha and see.",
                    "label": 0
                },
                {
                    "sent": "So you see an improvement when you do multi task kernel selection versus just doing independence, PHMSA with the red line.",
                    "label": 1
                },
                {
                    "sent": "This is on the landmine data set, which I don't think is the best for this problem, But anyway.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we optimize this ugly expression which involves these log Alpha plus exponentiated quadratic terms?",
                    "label": 0
                },
                {
                    "sent": "This is not a QP, this is is going to look nasty and what we suggest is replacing these log terms with the quadratic upper bound.",
                    "label": 1
                },
                {
                    "sent": "Or actually in this case lower bound.",
                    "label": 1
                },
                {
                    "sent": "Sorry, negative log terms are going to lower bounded by quadratic, so here's a nice theorem.",
                    "label": 0
                },
                {
                    "sent": "It's available in the paper that's that appear in jam alarm my website.",
                    "label": 0
                },
                {
                    "sent": "You replace all these negative log terms with this.",
                    "label": 1
                },
                {
                    "sent": "Lower bound, which is quadratic in the parameters I care bout in the use.",
                    "label": 0
                },
                {
                    "sent": "This is just a quadratic bound.",
                    "label": 0
                },
                {
                    "sent": "Now if I do this for all the log terms I see in my Medhi optimization problems, I get back a quadratic optimization problem and I can just solve it with QP.",
                    "label": 0
                },
                {
                    "sent": "So this is about you can use to get away from these log terms and it's fairly tight.",
                    "label": 0
                },
                {
                    "sent": "So then the recipe is you initialize set.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our little branch multipliers to zero and you apply the bound and you solve the QP.",
                    "label": 1
                },
                {
                    "sent": "And if you change your solution a little bit from the previous step, you go back and you try and you bound.",
                    "label": 0
                },
                {
                    "sent": "So it's a variational method and then solve the QP again and you keep iterating.",
                    "label": 0
                },
                {
                    "sent": "And we have a theorem that shows that you're not going to iterate more than a constant number of times, so you're going to solve the QP problem, which is really an SVM.",
                    "label": 0
                },
                {
                    "sent": "When you use the quadratic bounds that we just saw you going to run that iteration this many times.",
                    "label": 1
                },
                {
                    "sent": "So it's about a constant factor.",
                    "label": 0
                },
                {
                    "sent": "More work than an SVM.",
                    "label": 1
                },
                {
                    "sent": "It's very fast, takes about.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "10 or so iterations, and the way you prove this is because we can sandwich the media objective function with two quadratics, a lower bounded quadratic in an upper bounded quadratic, and you look at the curvature of those two quadratics.",
                    "label": 0
                },
                {
                    "sent": "The curvatures are the same, you will need one QP to solve that, because it's the sandwiched function is itself a quadratic.",
                    "label": 0
                },
                {
                    "sent": "And as the curvatures get different, more and more different between the upper and lower bound, eating more iterations, but you can quickly bound the number of iterations using this trick.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And as one last step, why stop with just the margin constraints?",
                    "label": 1
                },
                {
                    "sent": "So we just add a constraint to the Bayesian approach saying you should predict better with the correct label and all the other incorrect labels your.",
                    "label": 0
                },
                {
                    "sent": "Your posterior should give a higher score for the correct label and then all the others.",
                    "label": 0
                },
                {
                    "sent": "Another thing we can add is say, your correct label should not beat the weakest guy by too much.",
                    "label": 0
                },
                {
                    "sent": "OK, so the usual constraint is the correct label should beat the second runner up by gamma some margin, but also make sure you don't beat that poor guy who is really messing up the weakest, the weakest guy by too much by more than beta.",
                    "label": 0
                },
                {
                    "sent": "So we added these constraints in the relative margin machine in 2008.",
                    "label": 0
                },
                {
                    "sent": "Basically it's the same optimization problem where minimizing KL.",
                    "label": 0
                },
                {
                    "sent": "We add these constraints saying the correct guy should beat all the other guys by gamma, but it shouldn't beat the.",
                    "label": 0
                },
                {
                    "sent": "The weakest guy by more than beta.",
                    "label": 0
                },
                {
                    "sent": "Will be it is larger than gamma obviously.",
                    "label": 0
                },
                {
                    "sent": "So in an SVM the constraints are basically really simple.",
                    "label": 0
                },
                {
                    "sent": "You minimize the magnitude of W, but you make sure you get the correct classification.",
                    "label": 0
                },
                {
                    "sent": "You score more than gamma, but you also don't score too high.",
                    "label": 0
                },
                {
                    "sent": "Yeah, alright, I'll show you how to do it.",
                    "label": 0
                },
                {
                    "sent": "Additional info if I'm expecting which.",
                    "label": 0
                },
                {
                    "sent": "ASCII.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you can do dynamic programming when you have very large.",
                    "label": 1
                },
                {
                    "sent": "Why spaces here as well?",
                    "label": 0
                },
                {
                    "sent": "As demonstrated by Zoom and shake with an empty technique last year.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's basically going on is, let's say these these two classes, some squares and some triangles.",
                    "label": 0
                },
                {
                    "sent": "The SVM like to separate them this way, that's the maximum margin, thickest red line I could draw between the two classes, but this green line is actually what we're suggesting in this relative margin approach.",
                    "label": 0
                },
                {
                    "sent": "I want to separate these.",
                    "label": 0
                },
                {
                    "sent": "Triangles and squares by a lot, but not by too much.",
                    "label": 0
                },
                {
                    "sent": "So if I look at the projections, the green decision boundary projects all these points to minus one.",
                    "label": 0
                },
                {
                    "sent": "All these points to plus one.",
                    "label": 0
                },
                {
                    "sent": "And so here gamma is basically one, and beta is let's say 1.1.",
                    "label": 0
                },
                {
                    "sent": "Whereas the SVM projects things with a lot of spread.",
                    "label": 0
                },
                {
                    "sent": "Got it so you get stuff that's less than negative.",
                    "label": 0
                },
                {
                    "sent": "One correctly classified, but sometimes negative three out here for some of these predictions and positive.",
                    "label": 0
                },
                {
                    "sent": "Three out here for some of these predictions.",
                    "label": 0
                },
                {
                    "sent": "And so also if you scale the data, this thing starts to get worse and worse.",
                    "label": 0
                },
                {
                    "sent": "The SVM decision boundary starts to move more and more, whereas this relative margin method, which is limiting the prediction so that you don't predict too high or too low in addition to clear by plus or minus one, stay stable.",
                    "label": 0
                },
                {
                    "sent": "So it turns out this solution is invariant to affine transformations of your data.",
                    "label": 0
                },
                {
                    "sent": "The SVM isn't.",
                    "label": 0
                },
                {
                    "sent": "This is another advantage of the RMM.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Versus the SVM.",
                    "label": 0
                },
                {
                    "sent": "And so we tried this on many different datasets.",
                    "label": 0
                },
                {
                    "sent": "Here's the SVM, his kernel Fisher discriminant analysis, a couple of other flavors of SVM's, and in a star you see significantly better than other methods, and the ARM method is basically significantly better more than half the time when all these datasets you know once SVM is significantly better, once kernel Fisher discriminant simply significantly better, but the arm is about 60% of the time significantly better than the other methods, just by introducing.",
                    "label": 0
                },
                {
                    "sent": "This other strange constraint, which is a little like a discrimination constraint, but it's saying don't get too confident.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we also applied this to structured prediction and June Zoo and Eric Jing should hike and apply MBD to structured prediction problems in 2009 and also in 2008.",
                    "label": 1
                },
                {
                    "sent": "You can also add these relative margin constraints to structured prediction problems so you don't just have to deal with why being binary the same formula is actually you just have to be efficient and how you compute your argmax and your argument by doing dynamic programming.",
                    "label": 1
                },
                {
                    "sent": "Here's a multi class setup.",
                    "label": 0
                },
                {
                    "sent": "We have different polynomial kernels were doing multiclass classification and you see the error rate of these structures.",
                    "label": 0
                },
                {
                    "sent": "RMM is much lower than instructs VM because of these extra bounding constraints.",
                    "label": 1
                },
                {
                    "sent": "These red constraint not just discrimination with margin but limiting spread.",
                    "label": 0
                },
                {
                    "sent": "And then here's the named entity recognition problem and the parts of speech problem and you can see the same improvement from CRF to struct.",
                    "label": 0
                },
                {
                    "sent": "SVM continues to struct RMM.",
                    "label": 0
                },
                {
                    "sent": "One of the same amount of error reduction and actually dramatic error reduction on the parts of speech tagging from the CRF to struct STM, and then a really dramatic almost 1% error.",
                    "label": 0
                },
                {
                    "sent": "That's saying that I'm finished this nice.",
                    "label": 0
                },
                {
                    "sent": "Music and I'll just go to Michael.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Allusion slide and say you can add margin constraints.",
                    "label": 1
                },
                {
                    "sent": "The generative learning.",
                    "label": 0
                },
                {
                    "sent": "This leads to this maximum entropy discrimination framework.",
                    "label": 1
                },
                {
                    "sent": "It's a natural tool to explore multitask problems.",
                    "label": 1
                },
                {
                    "sent": "Feature selection and kernel selection.",
                    "label": 0
                },
                {
                    "sent": "The optimizations can be solved as sequential quadratic programs, and you can bound the number of iterations of this sequential quadratic program so you don't need more than a constant number of iterations, so it's not much more than constant work more than SVM.",
                    "label": 0
                },
                {
                    "sent": "And then you can also add these relative margin constraints which look like the margin constraints we added to the Bayesian estimate.",
                    "label": 1
                },
                {
                    "sent": "But they're just saying the correct label should beat all the other ones by.",
                    "label": 0
                },
                {
                    "sent": "Gamma, but shouldn't beat anybody by more than beta.",
                    "label": 0
                },
                {
                    "sent": "And this leads to further improvement, and in fact I think this relative margin ideas a little generative in it's it's kind of flavor because it's not just looking at the discrimination boundary, it's also looking at the spread, which is something generative models often do.",
                    "label": 1
                },
                {
                    "sent": "But discriminative models say just focus on the decision boundary and don't care about what's happening far away from it.",
                    "label": 0
                },
                {
                    "sent": "And I'll stop here.",
                    "label": 0
                },
                {
                    "sent": "So I have a technical question and a high level question, so the technical question is for this quadratic optimization thing in the.",
                    "label": 0
                },
                {
                    "sent": "In the variational formulation you have this thing that would like log something, plus either be landed be where they seem to be is like your variational parameter.",
                    "label": 0
                },
                {
                    "sent": "But so how do you get the variational parameter if?",
                    "label": 0
                },
                {
                    "sent": "I mean, if you're trying to minimize be, this looks like exactly the original thing that you're trying to minimize.",
                    "label": 0
                },
                {
                    "sent": "So how does it make it any easier?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a good question.",
                    "label": 0
                },
                {
                    "sent": "I can just jump back to it.",
                    "label": 0
                },
                {
                    "sent": "It's really the V is your previous setting of the LaGrange multipliers, so your your you don't have to do any extra.",
                    "label": 0
                },
                {
                    "sent": "Work to recover VV is what you used to be.",
                    "label": 0
                },
                {
                    "sent": "At the previous setting, and so this bound is as tight an exact when V = U.",
                    "label": 0
                },
                {
                    "sent": "And then yeah, from there you say I'm going to try to take a step.",
                    "label": 0
                },
                {
                    "sent": "Yeah, just quadratic questions like the sort of relative margin idea is very good when you have many more dimensions than examples, but I've never had a great intuition for why.",
                    "label": 0
                },
                {
                    "sent": "Why sort of artist?",
                    "label": 0
                },
                {
                    "sent": "Standard regularizers that we use or even like these L1 regularizer's aren't enough?",
                    "label": 0
                },
                {
                    "sent": "Like why did you Additionally want this relative margin?",
                    "label": 0
                },
                {
                    "sent": "So I mean the relative margin idea I've just presented intuitively here we have some bounds actually that show.",
                    "label": 0
                },
                {
                    "sent": "So a lot of the.",
                    "label": 0
                },
                {
                    "sent": "The generalization guarantees in learning theory use McDermott and how things bounds and it turns out if you use some of these variants based balance, like Bernstein and Bennetts bounds, you can show why limiting the spread, which basically limits the variance is going to lead to better generalization.",
                    "label": 0
                },
                {
                    "sent": "And now there's an empirical Bernstein.",
                    "label": 0
                },
                {
                    "sent": "Inequality, which was proposed in call 2009, where you can use a plug in for the for the variance, which is an empirical measurement, not.",
                    "label": 0
                },
                {
                    "sent": "You know the troop variance and so when you use that you're basically saying I want my.",
                    "label": 0
                },
                {
                    "sent": "My y * F of X, let's say margin values to be concentrated around let's say, plus one.",
                    "label": 0
                },
                {
                    "sent": "So I'm pretty thing well.",
                    "label": 0
                },
                {
                    "sent": "Or always be larger than one, but also not to have too much variance.",
                    "label": 0
                },
                {
                    "sent": "Because if you have a high variance and everybody is larger than one, it's easier for a high variance Gaussian to see kind of a jump across the zero origin, which leads to an error.",
                    "label": 0
                },
                {
                    "sent": "So high variance it makes it easier for things in the future to be sampled far away, and that leads to more errors.",
                    "label": 0
                },
                {
                    "sent": "That's the general flavor for the theory.",
                    "label": 0
                },
                {
                    "sent": "The following onto that was kind of intuition that is being tends to run tends to over a store underneath, make the management server estimate the margin in the sense that the data have been sampled somewhere, but there's still kind of tails of the distribution that falls into the margin so that ideal distribution will will be.",
                    "label": 0
                },
                {
                    "sent": "Type it faster than tablet K, so that's kind of intuition.",
                    "label": 0
                },
                {
                    "sent": "From what you say, but if that intuition is really true, then probably what you want to do is look at the density near the margin and make sure that's tight rather than the whole density over the entire region of the class.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's an interesting point.",
                    "label": 0
                },
                {
                    "sent": "So you want to focus on that.",
                    "label": 0
                },
                {
                    "sent": "Let's say the density near the margin, you're right, yeah, open the SPM in some sense that you wanted more logistic decay or something in that in that little region with the management.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so again, the logistic is capturing some of this intuition as well, because there's a soft focus on how things are spreading away and you get penalties.",
                    "label": 0
                },
                {
                    "sent": "It's not just are you above one or not, but in addition, I think even logistic regression.",
                    "label": 0
                },
                {
                    "sent": "Is sensitive to affine transformations, so both logistic an SVM in optimizing their quantities and not looking at the spread.",
                    "label": 0
                },
                {
                    "sent": "You can get them to actually do fairly badly by adversarially.",
                    "label": 0
                },
                {
                    "sent": "Transforming your data within a fine transformation an invertible affine transformation.",
                    "label": 0
                },
                {
                    "sent": "So we've seen some scenarios where we're able to keep increasing the error of the SVM.",
                    "label": 0
                },
                {
                    "sent": "Let's say double, double, and tripling it by doing these adverse aerial affine transformations which are completely invertible.",
                    "label": 0
                },
                {
                    "sent": "So we're not destroying anything when we're doing them, whereas this method stays stable and same for logistic regression as well.",
                    "label": 0
                },
                {
                    "sent": "Could you say a little bit more about how the actual discriminants differ between 2 cases in the credit score mean?",
                    "label": 0
                },
                {
                    "sent": "Have you seen?",
                    "label": 0
                },
                {
                    "sent": "It's very important to mention that kind of how things differ.",
                    "label": 0
                },
                {
                    "sent": "People said it is being.",
                    "label": 0
                },
                {
                    "sent": "So things different typically because you see things more concentrated around let's say, plus one and minus one with the RMM, the SVM you see larger margins, but there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a big variation, it's hard to describe exactly what's going on in high dimensional data.",
                    "label": 0
                },
                {
                    "sent": "But yeah, I mean the affine kind of adverse aerial affine transformations.",
                    "label": 0
                },
                {
                    "sent": "Another another idea, so we're seeing some scenarios where if you scale your data badly, the SVM gets really confused.",
                    "label": 0
                },
                {
                    "sent": "For my class.",
                    "label": 0
                },
                {
                    "sent": "Is the origonal SPN is obviously Angels?",
                    "label": 0
                },
                {
                    "sent": "If there's an odometer class, so people example X official.",
                    "label": 0
                },
                {
                    "sent": "From the tree distribution, then it says improvement.",
                    "label": 0
                },
                {
                    "sent": "Fun to scoring function Dot assign all the labels to to the same.",
                    "label": 0
                },
                {
                    "sent": "Probably that's why it cost the officiating consciousness cause the inconsistent.",
                    "label": 0
                },
                {
                    "sent": "Bring in your case, if you add the RMA in whether having the same problem with there's no majority class.",
                    "label": 1
                },
                {
                    "sent": "So when there's no majority class so you know the setup is very similar to the random label noise setup.",
                    "label": 0
                },
                {
                    "sent": "Is that we are referring to is like some like giving the songs that we got so she should be no like.",
                    "label": 0
                },
                {
                    "sent": "Heister hoping, but less than half yeah, Darkest Swim will fail.",
                    "label": 0
                },
                {
                    "sent": "But if he's not, he's asking for work fine, so, well, alright then, so we haven't looked specifically at those cases with, you know, when there's no real clear winning class or there's high label noise.",
                    "label": 0
                },
                {
                    "sent": "But I do know there was a theorem by Rocko Cervetti on Phil Long, saying that any convex optimization problem is going to get fooled by random label noise, and so the key is to avoid the convexity.",
                    "label": 0
                },
                {
                    "sent": "In the solver, use conditioner view all.",
                    "label": 0
                },
                {
                    "sent": "Is this consistent no matter?",
                    "label": 0
                },
                {
                    "sent": "Ocelot um, I'd have to.",
                    "label": 0
                },
                {
                    "sent": "I'd have to think about that offline.",
                    "label": 0
                },
                {
                    "sent": "I can't say off the top of my head.",
                    "label": 0
                },
                {
                    "sent": "We haven't.",
                    "label": 0
                },
                {
                    "sent": "We haven't looked into this problem in detail with the arm, so maybe it has the same problems as the SVM or maybe gets away from them and is still consistent.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "So I guess it's a good time to be defined with some thinking, thinking, speaker game.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Until.",
                    "label": 0
                },
                {
                    "sent": "The session starts again at 3:50 PM.",
                    "label": 0
                }
            ]
        }
    }
}