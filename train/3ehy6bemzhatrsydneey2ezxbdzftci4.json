{
    "id": "3ehy6bemzhatrsydneey2ezxbdzftci4",
    "title": "Patterns of Temporal Variation in Online Media",
    "info": {
        "author": [
            "Jaewon Yang, Department of Electrical Engineering, Stanford University"
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_yang_tvo/",
    "segmentation": [
        [
            "I'm Joanne an I will talk about patterns of temporal variation in online media.",
            "Yeah, this is joint work with Julie."
        ],
        [
            "So today we're content is becoming increasingly dynamic and the recent emergence of social media and user generated generated content further intensifies is so these days.",
            "For example, we have Twitter and social network sites like Facebook and many blog sites, and these sites run by very different mechanism than traditional news media websites like New York Times with CNN.",
            "And the interaction among these different kinds of websites govern how content grows and fades overtime, so some content grows very popular and some don't, and we are interested in how these changes of popularity of web content happen.",
            "So we hope to address some of these kind of questions.",
            "One is what are typical patterns of popularity of web content overtime?",
            "And 2nd is how do these patterns arise?"
        ],
        [
            "So let me show some example of temporal variation of popularity of web content.",
            "So here we plot the popularity of three web content overtime and so here is popularity, and we're going to call each piece of content as an item.",
            "So each item could be some individual texture, phrase or URL or hashtag.",
            "And in order to measure popularity, we measure how many times these item is mentioned on the web.",
            "So this is the popularity about some diffusion of some individual piece of information, so it's different from quality popularity that is discussed in previous talk.",
            "And as in the previous talk, if you look at the shape of these time series time series or volume of each item, then you can see how volume of each item changes overtime.",
            "So we wanted to find out some temporal patterns of popularity.",
            "Now it becomes finding finding shape among common shape among a set of time series."
        ],
        [
            "So we define our problem so we have a set of time series of our volume of web content item and we want to find out, discover some types of shapes.",
            "So we will do this by clustering time series by shape.",
            "So for example, we have four times is here, X1 to X4 and if we if we can somehow cluster them by shape, then each cluster will tell about distinct pattern of temporal variation of popularity.",
            "So one cluster on the top shows a pattern with two picks, an second cluster on the bottom will show up at."
        ],
        [
            "Single peak.",
            "So let me discuss why this is hard problem.",
            "One could imagine just applying Euclidean distance and K means, but in order to do so we need to normalize timeseries because they have all different level of values.",
            "And sometimes it's hard to know which normalization normalization would work the best, for example.",
            "So here we have again for time series and we normalize them so that they have all same peak.",
            "If we do that, then X2 Red one is become becomes in fact to be closer to X3 and X4.",
            "So if we learn K means with this setting and we're going to get wrong clustering."
        ],
        [
            "So now we we.",
            "We need something different.",
            "Some different approach to deal with our problem of clustering volume time series by shape.",
            "So I will first describe our approach.",
            "So we will explain about the distance measure we will use to measure the similarity of the shape of time series and then we will present new algorithm to cluster Time series by shape.",
            "We will call this algorithm as KFC.",
            "Name we will apply KFC to real data set and we found six distinct patterns of temporal variation.",
            "In other words, six distinct shape of time series in two kinds of different datasets and final task is exploring the possibility of predicting shape.",
            "So we show that we can predict the temporal variation of content item based on who or which website mentioned the item."
        ],
        [
            "So from the previous example we saw that Euclidean distance depends on normalization, so we need some new measure for similarity of time series shape.",
            "Then let's think about what kind of property do we need about similarity measure in time series shape.",
            "First one would be invariant to scaling.",
            "Here we have XI and XJ, two time series, and both XJ is just scaled version of XI.",
            "But they have same shape, so we want our measure to tell that they have same shape.",
            "Second one is invariant to translation.",
            "Here again we have XI and XC and XC is shifted version of XI.",
            "But they look same.",
            "So we want our measure to."
        ],
        [
            "Are they are same?",
            "So we will use this measure to to evaluate the similarity of shape of time series and we will call it SSI distance measure because it's invariant to scaling and shifting.",
            "So how it works is like this.",
            "Given two time Series XI and XJ, it shift and scale XJ1 Time series, namely XJ, such that distance from XI is minimized.",
            "An report or compute the minimum distance.",
            "So because it is with scaling and shifting automatically, it's invariant to scaling and shifting.",
            "So if we use this measure to four time series in the previous example, especially to measure distance between X1 and X2 and X3 and X4, then now XD becomes much more much closer to X1 then before an.",
            "If we run our algorithm then we get right clustering."
        ],
        [
            "So we I described about the distance measure of shape of time series we will use now we need a clustering algorithm.",
            "Also we want to find out some kind of typical shape or some very common shape for each cluster we will call it cluster centroids.",
            "Because if we can, if we can find them then just looking at them with tells us about typical shape of each cluster.",
            "So again, K means is not the best algorithm for SSI measure in terms of finding centroid.",
            "Becausw Kimmins find compute centroid as an average of all the time series.",
            "But everything minimize the sum of squared Euclidean distance, but we're not using Euclidean distance, so we propose new algorithm which is similar to K means.",
            "Ann about finds best centroid.",
            "Under our SSI distance measure.",
            "And we will call this algorithm as K spectral centroid algorithm or."
        ],
        [
            "ASC.",
            "So KS is very similar to came in, so it says same input and output as an input.",
            "It has a set of time series and we should know how many closed, how many clusters we want.",
            "That came in as an output.",
            "It has cluster membership of she work from C1 to CK about which which time series belong to which cluster and also it returns closer centuries.",
            "For each cluster you want to UK again, UK is typical shape, so it it minimizes.",
            "Or it's it's the time series that is closest to order time series in the cluster K. NCFC is iterative algorithm like came in.",
            "So it iterates between 2 steps.",
            "One is given cluster centroids, update cluster membership by just assigning time series to the closest cluster and 2nd is given membership given cluster membership, update cluster centroid for."
        ],
        [
            "Each cluster.",
            "So finding cluster membership is same as K means just assign each time series to the closest cluster and now it's a bit different in finding cluster centroid.",
            "Now we want our cluster centroid to be the closest to the old times in the cluster key under our distance measure SSA distance measure.",
            "That's why we call UK is the typical shape of the times."
        ],
        [
            "Then how do you do that?",
            "So this is the optimization minimization problem that we need to solve.",
            "We have mu as a variable is a, it's just a time series.",
            "But we want to mute.",
            "The minimize this function.",
            "This is the sum of the squared distance from all the time series in the cluster K. And this is the expression for our SSI measure and it will be easier if you think everything in vector.",
            "So this this is just form.",
            "Anne.",
            "And it turns out this this this distance can be converted to some function of you, especially in some kind of quadratic function of you, and we can then aggregate all the contribution of distance from each order each time series in the cluster into one large matrix, which we call MK.",
            "Then it becomes this final form, so we want to minimize some quadratic formula mu divided by some Euclidean norm of mu.",
            "And.",
            "If you look at it, it comes from.",
            "I mean from the definition of eigenvector you can see that I again eigenvector of MK corresponding to the smallest eigenvalue minimizes this function.",
            "So finding cluster centroid have has a closed form solution, so we can efficiently finding update update, central cluster centroid and then iterates between 2 steps."
        ],
        [
            "So so far I described about described about a distance measure and knew clustering algorithm to cluster time series by shape.",
            "Now we will apply our algorithm to real data set.",
            "We used two different kinds of data set.",
            "One is mental data set is about a diffusion of short texture phrases.",
            "And so we tracked the show texture phrases between quotation mark because they are easier to track.",
            "So here each item is true texture phrases.",
            "And second, data set is Twitter.",
            "We observe the adoption, the adoption or diffusion of Twitter hashtags.",
            "So each item is to the."
        ],
        [
            "Sex.",
            "An for each item we construct time series of volume using one hour's time unit.",
            "And it turns out, and we found that most time series are very spiky.",
            "The popularity of each item doesn't go for like one week or so, so we caught every time series just during 5 days around the peak volume.",
            "And we choose top 1000 times.",
            "It is for each of us texture phrase an."
        ],
        [
            "Two die stick.",
            "And now we will learn KSE, but before doing so, we need to know how many clusters we want.",
            "And there's no clear answer.",
            "But we measure some scoring functions and they like hartigans index or average silhouette and they suggest K = 6 is the good value.",
            "And we inspected the result of clustering, even if even when we use K = 12.",
            "Here is here at the result.",
            "But it turns out we can manually group them into six clusters.",
            "So we use cake with six and we run KFC 2 Twitter hashtags with K = 6 Now."
        ],
        [
            "Here are the result, so these are the cluster centroids of six clusters.",
            "So this this time series represents some typical shape of all the times in each cluster.",
            "So first top three ones have just single and very sharp peak, but typical one has smoother than smooth rise and smoothie K well one hit wonder is very quick rise and quick decay.",
            "And third one is electric shock is is it comes with very sudden spike but flows slowly the case, so it's a symmetric and 2nd next 2 ones are due each other they have.",
            "2 pics but in better today.",
            "One today's pick.",
            "First pick is higher and better.",
            "Tomorrow one is a second pick was higher.",
            "And next one is die hard.",
            "Yeah, it really ties hard.",
            "So yeah, it goes like forever up and down, up and down.",
            "So this was the most unique cluster shape in our."
        ],
        [
            "Dataset.",
            "We run KFC in winter data set as well and we found same patterns.",
            "Yeah, it was so surprising to me at the first sight.",
            "So again, 3 ones on the top helps single peak an 3 one on the bottom have multiple peaks.",
            "An especially in this data set.",
            "It was about which website to mention which phrase is so.",
            "We could, uh.",
            "Yeah, we could classify websites into five different types, so we classify the websites into five types, like a newspaper or professional blogs or news agency or television or personal blogs.",
            "And then for each type we measured when each type of which when our website of each type tend to mention or phrase in the cluster in average and we plot them with blue scale.",
            "So you can see that the order of the mention from each type is quite different for each cluster, so you can.",
            "We can see that different types of media give rise to different temporal pattern of popularity."
        ],
        [
            "So now look at look at the cluster in more detail, so I contrast two very different clusters, 1.",
            "First one is electric shark.",
            "Electric shock and this one begins with very sudden spike with use from news agency like AP or Reuters.",
            "And then the story populates to other other news media like newspaper and professional blogs and television and finally comes to blog.",
            "So in this cluster, blogs tend to mention 1.3 hours after news media.",
            "An volumes from more participation from global users are pretty low.",
            "But in this cluster it's very different.",
            "Here the public popularity is begins with mention from global users.",
            "And then it seems like mentions from blog users provoke some debate or lengthy lengthy debate.",
            "And then some news television or newspaper on professional blogs start to deal with the phrase in the cluster.",
            "And then finally news agency.",
            "So it was the only cluster that bloggers mentioned.",
            "The phrase or head of time than other news.",
            "Other types of media.",
            "And blood volume is was also majority of the volume or the volume."
        ],
        [
            "So so far we've seen that different types of media give rise to different temporal pattern of web content item.",
            "Then next question is that if we can if can you go the other way like without looking at the shape?",
            "Just we observe the temporal pattern.",
            "I mean timing of websites mentions or just we observe which way which media site mentioned or certain phrases and then can you predict the temporal pattern of popularity of the phrase?",
            "So if it could do that, then we can have a better idea of the temporal pattern of popularity of web content without measuring the shape or method without measuring the temporal variation of popularity actually.",
            "So that was the motivating question, and so we set up the classification test code whether or phrase belong to a cluster or not.",
            "And also if we can do that, then next question would be what kind of information would be most informative because we could look at the time or mention from each website or the amount of or the number of mentions from each website.",
            "So you know the two ends to answer this question, we set up classification task with using three different different kinds of features an compare the performance."
        ],
        [
            "So here's the setup in detail.",
            "So we classify the popularity pattern of an item based on who mentioned it.",
            "Based on which mention which website mentioned it, so we pick some number like W. Like 15 highest volume websites and then for each item for each phrase will record when writing W mentions it.",
            "And we use we record 3 different kinds of features.",
            "One is TF IDF scores.",
            "An so where websites are word and phrase is a document and 2nd is volume.",
            "How many times our website mentioned it and 3rd is temporal when when the website first mentioned the phrase and we trained logic."
        ],
        [
            "Regression model and here are the result.",
            "So first thing to notice that the accuracy is pretty high, so it was over 75%, even if when we use just 50 websites.",
            "And we note that temporal feature worked the best.",
            "OK, so we can conclude that based on when and feature of the 50 websites mentioned, the phrase we can predict the shape of the volume time series reliably.",
            "An in other work we show that we can.",
            "Actually we can go further.",
            "We can not only predict the shape, not only predict the temporal pattern we can but also predict the exact amount of future popularity of item using same information using which website mentioned at what time."
        ],
        [
            "So here is conclusion.",
            "We propose a new algorithm to cluster Time series by shape.",
            "And we apply this algorithm to real data set and surprisingly found six different patterns at 6 distinct patterns from two kinds of datasets.",
            "And also we show that we reliably predict the pattern using information of 50 website."
        ],
        [
            "And there are more results in Paperin.",
            "Thank you for your attention.",
            "Interesting talk sex and I'm just curious whether this work can be easily extended to multidimensional Time series data.",
            "Yeah, I think yeah, the metric we used is just some modification of Euclidean Euclidean distance, so I think we can easily extend our algorithm to multi dimensional Time series.",
            "Hi, thanks for the talk.",
            "I just I was just wondering that the method that you've described the clustering method that you've described is very similar to Newman's modularity algorithm.",
            "Can you please give the differences and the similarities with it?",
            "Newman's modularity algorithm for graph partitioning?",
            "Yeah.",
            "Lots of us findings.",
            "A set of nodes that optimize some modularity function.",
            "Is that what you mean?",
            "Yeah, and they have a very similar formalism as you've used.",
            "OK, we will discuss it offline.",
            "Yeah yeah, I think yeah, this very interesting question anyway.",
            "Hi yeah, I agree it's very interesting so your how much do you think that the predictive ability that you observed in terms of predicting the shape from the from the timing of the websites?",
            "How much do you think that's due to the fact that you picked the top 50?",
            "I mean, do you require some amount of volume in order to.",
            "Get that kind of predictive accuracy.",
            "Yeah, very nice question and yeah.",
            "Yeah, I think it depends on how the network is constructed or how network is formed.",
            "Cause yeah, it depends.",
            "Just we're looking at very important or few important nodes in the network like 50 is not the big number compared to other nodes in the real web or in others any other social networks.",
            "So if the network is concentrated on very very centrally like like metrical data set we observed.",
            "It's about diffusion of some news articles, so AP or some other some of you very notable websites dominates the network.",
            "In the case our main classification method would work well, but in other some there will be some other network then where our method can not work as well as in the page.",
            "In this paper, thank you.",
            "Look me off some book by Steve Chen at Nicolee Malika from 2005, where they looked at the temple patterns of queries on the web, and their approach was.",
            "Some variant of locality sensitive hashing.",
            "To contrast your algorithm said mean.",
            "Uh, yeah, I think.",
            "Yeah, I think I could be.",
            "I could give better answer after in offline.",
            "Yeah yeah any.",
            "It was very interesting question.",
            "Well, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm Joanne an I will talk about patterns of temporal variation in online media.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is joint work with Julie.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So today we're content is becoming increasingly dynamic and the recent emergence of social media and user generated generated content further intensifies is so these days.",
                    "label": 1
                },
                {
                    "sent": "For example, we have Twitter and social network sites like Facebook and many blog sites, and these sites run by very different mechanism than traditional news media websites like New York Times with CNN.",
                    "label": 0
                },
                {
                    "sent": "And the interaction among these different kinds of websites govern how content grows and fades overtime, so some content grows very popular and some don't, and we are interested in how these changes of popularity of web content happen.",
                    "label": 0
                },
                {
                    "sent": "So we hope to address some of these kind of questions.",
                    "label": 0
                },
                {
                    "sent": "One is what are typical patterns of popularity of web content overtime?",
                    "label": 1
                },
                {
                    "sent": "And 2nd is how do these patterns arise?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me show some example of temporal variation of popularity of web content.",
                    "label": 0
                },
                {
                    "sent": "So here we plot the popularity of three web content overtime and so here is popularity, and we're going to call each piece of content as an item.",
                    "label": 1
                },
                {
                    "sent": "So each item could be some individual texture, phrase or URL or hashtag.",
                    "label": 0
                },
                {
                    "sent": "And in order to measure popularity, we measure how many times these item is mentioned on the web.",
                    "label": 0
                },
                {
                    "sent": "So this is the popularity about some diffusion of some individual piece of information, so it's different from quality popularity that is discussed in previous talk.",
                    "label": 0
                },
                {
                    "sent": "And as in the previous talk, if you look at the shape of these time series time series or volume of each item, then you can see how volume of each item changes overtime.",
                    "label": 1
                },
                {
                    "sent": "So we wanted to find out some temporal patterns of popularity.",
                    "label": 0
                },
                {
                    "sent": "Now it becomes finding finding shape among common shape among a set of time series.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we define our problem so we have a set of time series of our volume of web content item and we want to find out, discover some types of shapes.",
                    "label": 1
                },
                {
                    "sent": "So we will do this by clustering time series by shape.",
                    "label": 1
                },
                {
                    "sent": "So for example, we have four times is here, X1 to X4 and if we if we can somehow cluster them by shape, then each cluster will tell about distinct pattern of temporal variation of popularity.",
                    "label": 0
                },
                {
                    "sent": "So one cluster on the top shows a pattern with two picks, an second cluster on the bottom will show up at.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Single peak.",
                    "label": 0
                },
                {
                    "sent": "So let me discuss why this is hard problem.",
                    "label": 0
                },
                {
                    "sent": "One could imagine just applying Euclidean distance and K means, but in order to do so we need to normalize timeseries because they have all different level of values.",
                    "label": 0
                },
                {
                    "sent": "And sometimes it's hard to know which normalization normalization would work the best, for example.",
                    "label": 0
                },
                {
                    "sent": "So here we have again for time series and we normalize them so that they have all same peak.",
                    "label": 1
                },
                {
                    "sent": "If we do that, then X2 Red one is become becomes in fact to be closer to X3 and X4.",
                    "label": 0
                },
                {
                    "sent": "So if we learn K means with this setting and we're going to get wrong clustering.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we we.",
                    "label": 0
                },
                {
                    "sent": "We need something different.",
                    "label": 0
                },
                {
                    "sent": "Some different approach to deal with our problem of clustering volume time series by shape.",
                    "label": 1
                },
                {
                    "sent": "So I will first describe our approach.",
                    "label": 0
                },
                {
                    "sent": "So we will explain about the distance measure we will use to measure the similarity of the shape of time series and then we will present new algorithm to cluster Time series by shape.",
                    "label": 1
                },
                {
                    "sent": "We will call this algorithm as KFC.",
                    "label": 0
                },
                {
                    "sent": "Name we will apply KFC to real data set and we found six distinct patterns of temporal variation.",
                    "label": 0
                },
                {
                    "sent": "In other words, six distinct shape of time series in two kinds of different datasets and final task is exploring the possibility of predicting shape.",
                    "label": 1
                },
                {
                    "sent": "So we show that we can predict the temporal variation of content item based on who or which website mentioned the item.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So from the previous example we saw that Euclidean distance depends on normalization, so we need some new measure for similarity of time series shape.",
                    "label": 0
                },
                {
                    "sent": "Then let's think about what kind of property do we need about similarity measure in time series shape.",
                    "label": 1
                },
                {
                    "sent": "First one would be invariant to scaling.",
                    "label": 1
                },
                {
                    "sent": "Here we have XI and XJ, two time series, and both XJ is just scaled version of XI.",
                    "label": 0
                },
                {
                    "sent": "But they have same shape, so we want our measure to tell that they have same shape.",
                    "label": 0
                },
                {
                    "sent": "Second one is invariant to translation.",
                    "label": 1
                },
                {
                    "sent": "Here again we have XI and XC and XC is shifted version of XI.",
                    "label": 0
                },
                {
                    "sent": "But they look same.",
                    "label": 0
                },
                {
                    "sent": "So we want our measure to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are they are same?",
                    "label": 0
                },
                {
                    "sent": "So we will use this measure to to evaluate the similarity of shape of time series and we will call it SSI distance measure because it's invariant to scaling and shifting.",
                    "label": 0
                },
                {
                    "sent": "So how it works is like this.",
                    "label": 0
                },
                {
                    "sent": "Given two time Series XI and XJ, it shift and scale XJ1 Time series, namely XJ, such that distance from XI is minimized.",
                    "label": 0
                },
                {
                    "sent": "An report or compute the minimum distance.",
                    "label": 0
                },
                {
                    "sent": "So because it is with scaling and shifting automatically, it's invariant to scaling and shifting.",
                    "label": 1
                },
                {
                    "sent": "So if we use this measure to four time series in the previous example, especially to measure distance between X1 and X2 and X3 and X4, then now XD becomes much more much closer to X1 then before an.",
                    "label": 0
                },
                {
                    "sent": "If we run our algorithm then we get right clustering.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we I described about the distance measure of shape of time series we will use now we need a clustering algorithm.",
                    "label": 1
                },
                {
                    "sent": "Also we want to find out some kind of typical shape or some very common shape for each cluster we will call it cluster centroids.",
                    "label": 0
                },
                {
                    "sent": "Because if we can, if we can find them then just looking at them with tells us about typical shape of each cluster.",
                    "label": 0
                },
                {
                    "sent": "So again, K means is not the best algorithm for SSI measure in terms of finding centroid.",
                    "label": 0
                },
                {
                    "sent": "Becausw Kimmins find compute centroid as an average of all the time series.",
                    "label": 1
                },
                {
                    "sent": "But everything minimize the sum of squared Euclidean distance, but we're not using Euclidean distance, so we propose new algorithm which is similar to K means.",
                    "label": 1
                },
                {
                    "sent": "Ann about finds best centroid.",
                    "label": 0
                },
                {
                    "sent": "Under our SSI distance measure.",
                    "label": 0
                },
                {
                    "sent": "And we will call this algorithm as K spectral centroid algorithm or.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "ASC.",
                    "label": 0
                },
                {
                    "sent": "So KS is very similar to came in, so it says same input and output as an input.",
                    "label": 1
                },
                {
                    "sent": "It has a set of time series and we should know how many closed, how many clusters we want.",
                    "label": 0
                },
                {
                    "sent": "That came in as an output.",
                    "label": 0
                },
                {
                    "sent": "It has cluster membership of she work from C1 to CK about which which time series belong to which cluster and also it returns closer centuries.",
                    "label": 0
                },
                {
                    "sent": "For each cluster you want to UK again, UK is typical shape, so it it minimizes.",
                    "label": 0
                },
                {
                    "sent": "Or it's it's the time series that is closest to order time series in the cluster K. NCFC is iterative algorithm like came in.",
                    "label": 1
                },
                {
                    "sent": "So it iterates between 2 steps.",
                    "label": 0
                },
                {
                    "sent": "One is given cluster centroids, update cluster membership by just assigning time series to the closest cluster and 2nd is given membership given cluster membership, update cluster centroid for.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each cluster.",
                    "label": 0
                },
                {
                    "sent": "So finding cluster membership is same as K means just assign each time series to the closest cluster and now it's a bit different in finding cluster centroid.",
                    "label": 1
                },
                {
                    "sent": "Now we want our cluster centroid to be the closest to the old times in the cluster key under our distance measure SSA distance measure.",
                    "label": 1
                },
                {
                    "sent": "That's why we call UK is the typical shape of the times.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then how do you do that?",
                    "label": 0
                },
                {
                    "sent": "So this is the optimization minimization problem that we need to solve.",
                    "label": 0
                },
                {
                    "sent": "We have mu as a variable is a, it's just a time series.",
                    "label": 0
                },
                {
                    "sent": "But we want to mute.",
                    "label": 0
                },
                {
                    "sent": "The minimize this function.",
                    "label": 0
                },
                {
                    "sent": "This is the sum of the squared distance from all the time series in the cluster K. And this is the expression for our SSI measure and it will be easier if you think everything in vector.",
                    "label": 0
                },
                {
                    "sent": "So this this is just form.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And it turns out this this this distance can be converted to some function of you, especially in some kind of quadratic function of you, and we can then aggregate all the contribution of distance from each order each time series in the cluster into one large matrix, which we call MK.",
                    "label": 0
                },
                {
                    "sent": "Then it becomes this final form, so we want to minimize some quadratic formula mu divided by some Euclidean norm of mu.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If you look at it, it comes from.",
                    "label": 0
                },
                {
                    "sent": "I mean from the definition of eigenvector you can see that I again eigenvector of MK corresponding to the smallest eigenvalue minimizes this function.",
                    "label": 0
                },
                {
                    "sent": "So finding cluster centroid have has a closed form solution, so we can efficiently finding update update, central cluster centroid and then iterates between 2 steps.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so far I described about described about a distance measure and knew clustering algorithm to cluster time series by shape.",
                    "label": 0
                },
                {
                    "sent": "Now we will apply our algorithm to real data set.",
                    "label": 0
                },
                {
                    "sent": "We used two different kinds of data set.",
                    "label": 0
                },
                {
                    "sent": "One is mental data set is about a diffusion of short texture phrases.",
                    "label": 0
                },
                {
                    "sent": "And so we tracked the show texture phrases between quotation mark because they are easier to track.",
                    "label": 0
                },
                {
                    "sent": "So here each item is true texture phrases.",
                    "label": 0
                },
                {
                    "sent": "And second, data set is Twitter.",
                    "label": 0
                },
                {
                    "sent": "We observe the adoption, the adoption or diffusion of Twitter hashtags.",
                    "label": 1
                },
                {
                    "sent": "So each item is to the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sex.",
                    "label": 0
                },
                {
                    "sent": "An for each item we construct time series of volume using one hour's time unit.",
                    "label": 0
                },
                {
                    "sent": "And it turns out, and we found that most time series are very spiky.",
                    "label": 1
                },
                {
                    "sent": "The popularity of each item doesn't go for like one week or so, so we caught every time series just during 5 days around the peak volume.",
                    "label": 1
                },
                {
                    "sent": "And we choose top 1000 times.",
                    "label": 0
                },
                {
                    "sent": "It is for each of us texture phrase an.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two die stick.",
                    "label": 0
                },
                {
                    "sent": "And now we will learn KSE, but before doing so, we need to know how many clusters we want.",
                    "label": 1
                },
                {
                    "sent": "And there's no clear answer.",
                    "label": 1
                },
                {
                    "sent": "But we measure some scoring functions and they like hartigans index or average silhouette and they suggest K = 6 is the good value.",
                    "label": 0
                },
                {
                    "sent": "And we inspected the result of clustering, even if even when we use K = 12.",
                    "label": 0
                },
                {
                    "sent": "Here is here at the result.",
                    "label": 0
                },
                {
                    "sent": "But it turns out we can manually group them into six clusters.",
                    "label": 0
                },
                {
                    "sent": "So we use cake with six and we run KFC 2 Twitter hashtags with K = 6 Now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here are the result, so these are the cluster centroids of six clusters.",
                    "label": 0
                },
                {
                    "sent": "So this this time series represents some typical shape of all the times in each cluster.",
                    "label": 0
                },
                {
                    "sent": "So first top three ones have just single and very sharp peak, but typical one has smoother than smooth rise and smoothie K well one hit wonder is very quick rise and quick decay.",
                    "label": 0
                },
                {
                    "sent": "And third one is electric shock is is it comes with very sudden spike but flows slowly the case, so it's a symmetric and 2nd next 2 ones are due each other they have.",
                    "label": 0
                },
                {
                    "sent": "2 pics but in better today.",
                    "label": 1
                },
                {
                    "sent": "One today's pick.",
                    "label": 0
                },
                {
                    "sent": "First pick is higher and better.",
                    "label": 0
                },
                {
                    "sent": "Tomorrow one is a second pick was higher.",
                    "label": 1
                },
                {
                    "sent": "And next one is die hard.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it really ties hard.",
                    "label": 0
                },
                {
                    "sent": "So yeah, it goes like forever up and down, up and down.",
                    "label": 0
                },
                {
                    "sent": "So this was the most unique cluster shape in our.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dataset.",
                    "label": 0
                },
                {
                    "sent": "We run KFC in winter data set as well and we found same patterns.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it was so surprising to me at the first sight.",
                    "label": 0
                },
                {
                    "sent": "So again, 3 ones on the top helps single peak an 3 one on the bottom have multiple peaks.",
                    "label": 0
                },
                {
                    "sent": "An especially in this data set.",
                    "label": 0
                },
                {
                    "sent": "It was about which website to mention which phrase is so.",
                    "label": 0
                },
                {
                    "sent": "We could, uh.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we could classify websites into five different types, so we classify the websites into five types, like a newspaper or professional blogs or news agency or television or personal blogs.",
                    "label": 1
                },
                {
                    "sent": "And then for each type we measured when each type of which when our website of each type tend to mention or phrase in the cluster in average and we plot them with blue scale.",
                    "label": 0
                },
                {
                    "sent": "So you can see that the order of the mention from each type is quite different for each cluster, so you can.",
                    "label": 0
                },
                {
                    "sent": "We can see that different types of media give rise to different temporal pattern of popularity.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now look at look at the cluster in more detail, so I contrast two very different clusters, 1.",
                    "label": 0
                },
                {
                    "sent": "First one is electric shark.",
                    "label": 0
                },
                {
                    "sent": "Electric shock and this one begins with very sudden spike with use from news agency like AP or Reuters.",
                    "label": 0
                },
                {
                    "sent": "And then the story populates to other other news media like newspaper and professional blogs and television and finally comes to blog.",
                    "label": 0
                },
                {
                    "sent": "So in this cluster, blogs tend to mention 1.3 hours after news media.",
                    "label": 1
                },
                {
                    "sent": "An volumes from more participation from global users are pretty low.",
                    "label": 0
                },
                {
                    "sent": "But in this cluster it's very different.",
                    "label": 0
                },
                {
                    "sent": "Here the public popularity is begins with mention from global users.",
                    "label": 0
                },
                {
                    "sent": "And then it seems like mentions from blog users provoke some debate or lengthy lengthy debate.",
                    "label": 0
                },
                {
                    "sent": "And then some news television or newspaper on professional blogs start to deal with the phrase in the cluster.",
                    "label": 0
                },
                {
                    "sent": "And then finally news agency.",
                    "label": 1
                },
                {
                    "sent": "So it was the only cluster that bloggers mentioned.",
                    "label": 0
                },
                {
                    "sent": "The phrase or head of time than other news.",
                    "label": 0
                },
                {
                    "sent": "Other types of media.",
                    "label": 0
                },
                {
                    "sent": "And blood volume is was also majority of the volume or the volume.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so far we've seen that different types of media give rise to different temporal pattern of web content item.",
                    "label": 0
                },
                {
                    "sent": "Then next question is that if we can if can you go the other way like without looking at the shape?",
                    "label": 0
                },
                {
                    "sent": "Just we observe the temporal pattern.",
                    "label": 0
                },
                {
                    "sent": "I mean timing of websites mentions or just we observe which way which media site mentioned or certain phrases and then can you predict the temporal pattern of popularity of the phrase?",
                    "label": 0
                },
                {
                    "sent": "So if it could do that, then we can have a better idea of the temporal pattern of popularity of web content without measuring the shape or method without measuring the temporal variation of popularity actually.",
                    "label": 0
                },
                {
                    "sent": "So that was the motivating question, and so we set up the classification test code whether or phrase belong to a cluster or not.",
                    "label": 1
                },
                {
                    "sent": "And also if we can do that, then next question would be what kind of information would be most informative because we could look at the time or mention from each website or the amount of or the number of mentions from each website.",
                    "label": 1
                },
                {
                    "sent": "So you know the two ends to answer this question, we set up classification task with using three different different kinds of features an compare the performance.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the setup in detail.",
                    "label": 0
                },
                {
                    "sent": "So we classify the popularity pattern of an item based on who mentioned it.",
                    "label": 1
                },
                {
                    "sent": "Based on which mention which website mentioned it, so we pick some number like W. Like 15 highest volume websites and then for each item for each phrase will record when writing W mentions it.",
                    "label": 0
                },
                {
                    "sent": "And we use we record 3 different kinds of features.",
                    "label": 0
                },
                {
                    "sent": "One is TF IDF scores.",
                    "label": 0
                },
                {
                    "sent": "An so where websites are word and phrase is a document and 2nd is volume.",
                    "label": 1
                },
                {
                    "sent": "How many times our website mentioned it and 3rd is temporal when when the website first mentioned the phrase and we trained logic.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regression model and here are the result.",
                    "label": 0
                },
                {
                    "sent": "So first thing to notice that the accuracy is pretty high, so it was over 75%, even if when we use just 50 websites.",
                    "label": 0
                },
                {
                    "sent": "And we note that temporal feature worked the best.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can conclude that based on when and feature of the 50 websites mentioned, the phrase we can predict the shape of the volume time series reliably.",
                    "label": 1
                },
                {
                    "sent": "An in other work we show that we can.",
                    "label": 0
                },
                {
                    "sent": "Actually we can go further.",
                    "label": 0
                },
                {
                    "sent": "We can not only predict the shape, not only predict the temporal pattern we can but also predict the exact amount of future popularity of item using same information using which website mentioned at what time.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is conclusion.",
                    "label": 0
                },
                {
                    "sent": "We propose a new algorithm to cluster Time series by shape.",
                    "label": 1
                },
                {
                    "sent": "And we apply this algorithm to real data set and surprisingly found six different patterns at 6 distinct patterns from two kinds of datasets.",
                    "label": 1
                },
                {
                    "sent": "And also we show that we reliably predict the pattern using information of 50 website.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there are more results in Paperin.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Interesting talk sex and I'm just curious whether this work can be easily extended to multidimensional Time series data.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think yeah, the metric we used is just some modification of Euclidean Euclidean distance, so I think we can easily extend our algorithm to multi dimensional Time series.",
                    "label": 0
                },
                {
                    "sent": "Hi, thanks for the talk.",
                    "label": 0
                },
                {
                    "sent": "I just I was just wondering that the method that you've described the clustering method that you've described is very similar to Newman's modularity algorithm.",
                    "label": 0
                },
                {
                    "sent": "Can you please give the differences and the similarities with it?",
                    "label": 0
                },
                {
                    "sent": "Newman's modularity algorithm for graph partitioning?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Lots of us findings.",
                    "label": 0
                },
                {
                    "sent": "A set of nodes that optimize some modularity function.",
                    "label": 0
                },
                {
                    "sent": "Is that what you mean?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and they have a very similar formalism as you've used.",
                    "label": 0
                },
                {
                    "sent": "OK, we will discuss it offline.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, I think yeah, this very interesting question anyway.",
                    "label": 0
                },
                {
                    "sent": "Hi yeah, I agree it's very interesting so your how much do you think that the predictive ability that you observed in terms of predicting the shape from the from the timing of the websites?",
                    "label": 0
                },
                {
                    "sent": "How much do you think that's due to the fact that you picked the top 50?",
                    "label": 0
                },
                {
                    "sent": "I mean, do you require some amount of volume in order to.",
                    "label": 0
                },
                {
                    "sent": "Get that kind of predictive accuracy.",
                    "label": 0
                },
                {
                    "sent": "Yeah, very nice question and yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it depends on how the network is constructed or how network is formed.",
                    "label": 0
                },
                {
                    "sent": "Cause yeah, it depends.",
                    "label": 0
                },
                {
                    "sent": "Just we're looking at very important or few important nodes in the network like 50 is not the big number compared to other nodes in the real web or in others any other social networks.",
                    "label": 0
                },
                {
                    "sent": "So if the network is concentrated on very very centrally like like metrical data set we observed.",
                    "label": 0
                },
                {
                    "sent": "It's about diffusion of some news articles, so AP or some other some of you very notable websites dominates the network.",
                    "label": 0
                },
                {
                    "sent": "In the case our main classification method would work well, but in other some there will be some other network then where our method can not work as well as in the page.",
                    "label": 1
                },
                {
                    "sent": "In this paper, thank you.",
                    "label": 0
                },
                {
                    "sent": "Look me off some book by Steve Chen at Nicolee Malika from 2005, where they looked at the temple patterns of queries on the web, and their approach was.",
                    "label": 0
                },
                {
                    "sent": "Some variant of locality sensitive hashing.",
                    "label": 0
                },
                {
                    "sent": "To contrast your algorithm said mean.",
                    "label": 0
                },
                {
                    "sent": "Uh, yeah, I think.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think I could be.",
                    "label": 0
                },
                {
                    "sent": "I could give better answer after in offline.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah any.",
                    "label": 0
                },
                {
                    "sent": "It was very interesting question.",
                    "label": 0
                },
                {
                    "sent": "Well, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}