{
    "id": "wnmppsyo2tyanhahy7x3744jww7oa2yf",
    "title": "Large Scale Learning at Twitter",
    "info": {
        "chairman": [
            "Marko Grobelnik, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "author": [
            "Aleksander Ko\u0142cz, Twitter, Inc."
        ],
        "published": "Aug. 13, 2012",
        "recorded": "May 2012",
        "category": [
            "Top->Computers->Social Networking",
            "Top->Computer Science->Text Mining",
            "Top->Computer Science->Data Modeling"
        ]
    },
    "url": "http://videolectures.net/eswc2012_kolcz_twitter/",
    "segmentation": [
        [
            "OK, welcome this afternoon session.",
            "So the intention with this stock was to have somebody who would really give information from within Twitter.",
            "We all deal with Twitter, but from the outside side.",
            "So here we have somebody who sees Twitter from the inside site and probably best person we can get or one of the best people of this kind would be Alec.",
            "So few words about the Alex so, but he was doing big data even before anybody mentioned this word.",
            "So in the whole series of big companies.",
            "So back in early 2000s he was in AOL, so he sold his AOL streams of data doing.",
            "Spam detection and detecting all this shady business which happens on the Internet from the AOL site.",
            "So lots of experience on that side.",
            "Then he moved to Microsoft to Life Labs.",
            "So he was in this core group, which evolved I guess in today's Bing and two years ago, right two years ago I like moved to Twitter when Twitter was already around, but not as popular as today.",
            "Remember, it was big announcements.",
            "Smart person from Microsoft going to Twitter.",
            "So this was Alec.",
            "Anne.",
            "And now he works in this, let's say research side of Twitter and pretty much he.",
            "He touches the data every day, which we would only wish to touch most of us.",
            "And so the idea is basically to give us a little bit of a flavor.",
            "What happens behind that?",
            "So curtain not really well curtain Alex please.",
            "Thank you, Marco.",
            "Thank you all for coming.",
            "So let me begin by referring to the previous keynote speaker and and I was actually also at SIGMOD last week, and it's interesting to see how certain concepts.",
            "Spread around pretty fast with this research network if you like, so there was a keynote speech at SIGMOD which referred to.",
            "People's database experts, data scientists, and data enthusiasts and think they.",
            "The previous speaker correctly classified this community as being of very cool database experts, which are probably right.",
            "So my talk is more about machine learning and I think for the machine learning perspective, this community is probably community of machine learning enthusiasts, so machine learning is not the key problem, but turns out to be quite useful in all applications.",
            "So what I'm going to talk about this something which is rarely discussed, is how they actually build a fairly large machine learning system over whatever we call big data right now, and I'm going to talk about later whether or not we can call Twitter big data, but I think it's got some of the kind of processes and thought processes that we went through in trying to make it scalable and trying to make it useful for both data experts or scientists feel like.",
            "And that enthusiasm.",
            "So let me ask everybody how many people actually use their.",
            "Their hands so lot so I wasn't quite sure how much they have to explain about Twitter about me.",
            "Just show some."
        ],
        [
            "Some cool pictures, so this is an event which happened a few years ago in Los Angeles, so there's a mid sized earthquake.",
            "Which then caused a whole lot of damage, but we managed to shook to shake supermarket shelves.",
            "As you can see.",
            "So this is an interesting statistics about how the news about this information spread.",
            "So the national media in the US caught on to this in about 9 minutes.",
            "Now the local media in Airlaid Radio stations, if you like, was faster.",
            "So only about four minutes.",
            "3 problems event.",
            "Now the first tweet about this happened 5 seconds.",
            "After and by the time the national media caught onto it, if you actually combined all the tweets about this event, you could publish a whole book.",
            "So like I'll give you a picture of the spread of information on Twitter and the real time aspects of it.",
            "Let's take a look at."
        ],
        [
            "Other example, So what you see here is essentially add replies to and from Japan over Twitter network.",
            "This is kind of like a normal day.",
            "Go often going and going.",
            "Nothing much changes.",
            "So right now what's happening is like big Earthquake in Japan.",
            "See the increase of volume.",
            "So those are just add replies.",
            "People who follow people in Japan out applying them and vice versa.",
            "Anne."
        ],
        [
            "This is a corresponding traffic of retweets.",
            "So retweeting people from Japan was the kind of pinkish color.",
            "And then the retweets propagate over the rest of the world over the green network.",
            "So with the exception of very very cold countries and very very hot countries before we cover the whole world."
        ],
        [
            "So, in a nutshell, water square.",
            "So some people call it microblogging service with a lot of this term so much.",
            "But it's probably true.",
            "It's really about having this open channel communication network in which people can share opinions and exchange information in the person to person present a group of people, person to everybody, essentially Mallory.",
            "So the.",
            "Characterizing factor is that the tweets are restricted to 140 characters, which probably everybody knows, and so some people see it as a constraint.",
            "But actually it doesn't.",
            "To be pretty handy when it comes to sharing important ideas and helping people to organize and exchange information so."
        ],
        [
            "To give some concrete examples.",
            "So those are some events from last year, so we probably all aware of the Arab Spring movement which happened all over Northern Africa and the Middle East so.",
            "What happened is that we're actually is quite useful for helping people to figure out where those protests happening.",
            "What is going on?",
            "Where is the police intervention so on so forth, and typically the way people do this on Twitter via hashtags.",
            "So by inserting hashtags in tweets, people can search for them and find out what is going on right now with respect to the speaker on topic.",
            "And interest."
        ],
        [
            "Only a very similar effect happened first in the US and then it spread actually all over the world again with respect to the Occupy Wall Street movement.",
            "So again very similar concept trying to exchange information and inform ourselves kind of outside the established media channels which don't necessarily reporting this all the time, or can perhaps sometimes marginalized what is going on."
        ],
        [
            "So there's a scale of three right now, so this is not exactly up to the information is from April, so the numbers could have changed a little bit, but with about 140 million active users, so people who use it fairly frequently, there's about 340 million tweets.",
            "Published per day and essentially much, many more consume.",
            "There's 400 million visitors through.com domain.",
            "And about 50 million people log into Twitter every day.",
            "Soldiers.",
            "Large scale stats."
        ],
        [
            "So you can interface that we have a number of ways.",
            "Some people just use the web interface.",
            "Some people use various apps like Tweetdeck for example, which is displayed in the whole here.",
            "There's also SMS and whereas mobile phone clients and actually over 50% of our users are mobile users, so it's actually particularly useful for people who check stuff out on the on the mobile phones while sitting in a box I guess.",
            "And not only.",
            "It was about really about the real time distribution of content or close to real time.",
            "And it's not only that there's also services which sit on top of it and help users to find interesting information.",
            "So what are those services?"
        ],
        [
            "This all while there's search and there is user recommendation and there's various other forms of recommendation which help people to understand what is going on.",
            "So do they extend?",
            "Machine learning is relevant?",
            "Where is relevant in helping?",
            "To help users to find relevant stuff.",
            "It's not the only way of to do so, but it turns out it can be actually quite useful."
        ],
        [
            "So let's take a look at the problems which I need to solve with machine learning and otherwise.",
            "So one of such problems, this search, or the relevance in search?",
            "So when people come to search on Twitter, their search for number of things, one of such things is users.",
            "So people want to find other users.",
            "The users could be celebrities.",
            "Could be bloggers clear people.",
            "I already know from somewhere else, so I'm really find them.",
            "A lot of things could be events.",
            "So I know something is happening.",
            "I want to come up here and find out what is going on about this particular event.",
            "Maybe there's election happening, maybe there's an earthquake, maybe something else.",
            "And really, people have two mindsets about this, so one is show me the freshest stuff about this thing, whatever it is, even if it's noisy.",
            "So this is typical when people follow hashtags.",
            "It's kind of interesting the rofi.",
            "And another way to look at it, and it's like I really want to find the relevant information about a particular event, so I really want to find out about the Occupy Wall Street movement, but not the kind of blow by blow accounts of what everybody is doing.",
            "But maybe just the things that more informative people had said about this event in the recent past.",
            "So those things are not necessarily In Sync, so they clash with each other.",
            "So the trick is is to solve the relevance problem real time search, which really is an open question right now in the research community, how did this so best?"
        ],
        [
            "The second problem is how to grow the tree graph.",
            "So as you probably know, the way to receive information into here is to follow other people.",
            "So I can follow other people for a variety of reasons.",
            "Those could be our friends and family, colleagues, coworkers, so forth.",
            "But they also could be media sources.",
            "Could be influential.",
            "Bloggers could be government agencies and so forth, so it could be a vast variety of reasons why I should be following somebody.",
            "And on top of this, there's also the timescale of the interest I could be interested in somebody for a very short time or forever.",
            "So to figure it out, actually it's quite tricky."
        ],
        [
            "And the third recommendation problem is the problem of content recommendations so.",
            "Yes, I can be following other users, but they're not necessarily guaranteed to provide me with all information which I could be finding interesting.",
            "So for example, new stories, media video school pictures.",
            "Also for something that could be happening into it right now, which could be interesting to me, how do we actually figure out what to show to what to who?",
            "Anne."
        ],
        [
            "There's a bunch of other problems, so there is.",
            "How do they take the trending topics?",
            "How text is like language?",
            "How to do antispam antimalware?",
            "How to optimize our revenue?",
            "How to optimize our growth and so on so forth?",
            "So it's like a myriad of problems, at least for some of the machine learning can or is playing a crucial component."
        ],
        [
            "So you can see from those examples the problems we're trying to solve can be cost more or less as recommender style problems, which I recommend people to people.",
            "Items to people, URLs to people, whatever.",
            "Essentially those are recommended style problems and they can be solved partially through solving secondary problems such as such as classification and clustering.",
            "So classic machine learning problems."
        ],
        [
            "Now, so is this really big data?",
            "So we do the math.",
            "If you think OK, wealthier in 50 million tweets per day.",
            "If we just multiplied by the size of the tweet.",
            "So you could probably fit in the laptop.",
            "So it's not really that big.",
            "But then, if you actually combined all the associated media which come with those tweets.",
            "And the clickstream of all the various events that could be happening.",
            "Blouse updates to the graph, and so on, so forth.",
            "It becomes pretty large.",
            "So just to give an interesting number, so just the injectors for log data in just about 10 terabytes per day and then analytics pipeline.",
            "So.",
            "I guess if you say well, if you need a data center to process this data in the long term, that's probably big data.",
            "OK."
        ],
        [
            "Now, what are the challenges?",
            "I mean, there's many challenges just to name a few.",
            "Very international, so over 70% of our users actually.",
            "Are outside of the US.",
            "And as I mentioned before, there is real time.",
            "And I mean this is very important.",
            "So people come to Twitter and really expect things to be relevant to whatever is happening right now.",
            "And that's the key.",
            "And of course, the brevity tweets are very short, then other shoulder search queries, but really short and sometimes very noisy."
        ],
        [
            "So having said that.",
            ", the question is, So what type of machine learning do actually need to solve any of those problems?",
            "So I'm going to claim that we don't need any new type of machine learning as I was showing before a lot of those problems are really known problems in some form.",
            "However, there is specificity which is.",
            "Pertinent to the Twitter data and Twitter traffic which we need to solve.",
            "And also there is the questions about where this thing actually operating.",
            "What is our infrastructure?",
            "How do we actually put it in?",
            "And the decisions on what to build.",
            "What algorithm should be applied, applying and so forth are really dependent on this kind of infrastructure implementational issues.",
            "Plus the problems we're trying to solve."
        ],
        [
            "So let me start by saying we more or less trying to apply machine learning to social networks so Twitter is a social network, if you like.",
            "And there's a social network where a lot of information comes in the form of text.",
            "So what does it really?",
            "Tell us, I mean tells us that.",
            "We probably can get away with using fairly simple models, and why can I say that whether it's like long, long, long line of research papers, both by people like adima.",
            "Any industry which tend to show that for problems involving tests takes an especially large quantities of text.",
            "It pays off to use fairly simple models.",
            "Which can actually process lots of data rather than concentrating or on complex models, which most likely really cannot handle this data at all in the first place.",
            "And if you actually can tell the data, the accuracy gains are pretty small.",
            "If they actually exist at all.",
            "Now.",
            "The second thing which is probably more important, is.",
            "We want to use machine learning for social networks in a way which is really easy to use.",
            "So not everybody is a machine learning expert, and even not everybody is a data scientist.",
            "So a lot of people who want to apply those models need to be able to actually apply them in a way which fits with their day-to-day dealing with the data.",
            "So if you use it or some kind of analytic pipeline, you probably have your own tool set of things you like to do.",
            "You know how to do, and to the extent you would like to play with models you want to be able to integrate them very easily.",
            "And to us it was a key requirement for making this happen."
        ],
        [
            "So.",
            "Machine learning for social networks.",
            "Of course, social networks, as the name suggests, are graphs.",
            "But this graph processing really requirement, I would say the existence of graphs really provides an asset to whatever we do.",
            "It's not necessarily a hard requirement for whatever machine learning want to apply.",
            "It really stems from the power of the social graph, so the graphic connected by users usually for purpose and the signal propagation in the graph tends to bring relevance.",
            "So even if we apply simple models over a graph, degradation over the graph increases the power of those models, making them more accurate.",
            "So it's a plus."
        ],
        [
            "Now the real requirement is scalability.",
            "So we need to scale to all the data we have and all that they were going to have.",
            "We need to scale with the time of the data arrival, so processing over data streams and we need to update those models pretty fast."
        ],
        [
            "Now.",
            "So it's pretty tall order.",
            "They should build all of this together and we get a bunch of engineers and researchers and scientists in the room.",
            "The natural tendency is to kind of build a lot of stuff.",
            "Let's just call this thing up.",
            "So yes, I mean it's possible to build everything from scratch, but what's the real benefit in doing so?",
            "We probably wouldn't be able to finish anything.",
            "So the real questions are, I mean, what do we actually need to build?",
            "In our infrastructure to make it happen and how can we possibly reuse existing stuff from wherever it comes?",
            "So we should be building should be laying low level machine learning libraries.",
            "The feature extraction pipelines, maybe they distributed processing platforms.",
            "Maybe the glue code.",
            "This whole visualization code and so on so forth.",
            "So those are kind of the questions which naturally come to mind and need to be answered in order to build the real system."
        ],
        [
            "So Fortunately when we started looking at this problem, we're not operating in a vacuum, so to some extent the answers are constrained by whatever infrastructure was already in place.",
            "So just to show you some of the things which are operating in our pipeline.",
            "It's about the Hadoop, essentially with a lot of components around it, so the.",
            "The languages such as Scala and Java and Pig.",
            "There's things which make the cluster happen, such as missiles and zookeeper and storage component such as Cassandra and Edge base and so forth.",
            "So those things provide like real constraints to how we're going to build stuff."
        ],
        [
            "And naturally, we decided that.",
            "We want to capitalize on the use of Hadoop.",
            "So the data can be processed in in many different ways, but because our analytics pipeline already produces everything in Hadoop.",
            "We wanted really to do everything Hadoop as well, essentially as as fitting into the map reduce process.",
            "Secondly, most of our pipeline operates using one particular technology called Pig.",
            "So for those who don't know much about magic, produce big is a high level dataflow language that people write MapReduce jobs with is much easier to work with pig than with working with low level Java code for example.",
            "They wanted to integrate our pipeline as close as possible with Peg to make it easy for users to actually use it."
        ],
        [
            "And we wanted to avoid certain processes that are actually very common and probably some of you have done this in the past are doing this.",
            "I'm doing this myself once in awhile, but let me call it the janky modeling process.",
            "So we are facing this big data somewhere in the cluster and I want to do some modeling on it so we have some tool of choice sitting in our laptop and obviously we cannot fit this data onto the laptop.",
            "So what do we do?",
            "Well, probably going to downsample and somehow so whatever we get fits in the laptop OK?",
            "Well, how do we know that you know this is the right sampling rate or we don't know really?",
            "I mean, if it's in the laptop, right?",
            "So next we're going to build some kind of a model, test it a little bit.",
            "And then maybe push back to this cluster and let it drop.",
            "So what's wrong with this picture?",
            "Well, maybe the model is actually good.",
            "I don't know, maybe not.",
            "But the biggest problem is that there is no.",
            "Guarantee this thing actually works and the next person which comes around and tries to like work and update this model.",
            "I mean doesn't really know what happened.",
            "You know what tool actually was used to build it?",
            "Was the analytical process what really happened?",
            "I mean, nobody knows.",
            "So it's really unmaintainable."
        ],
        [
            "And by saying so I'm not really shooting down the experimentation with small data.",
            "I think experimentation with small data is very valuable.",
            "It can provide a lot of insights, but when you have a lot of people doing this over production pipelines.",
            "It really becomes a mess.",
            "And we can't really have it as, like the defector standard of whatever you do."
        ],
        [
            "So for those of you who probably know about marriages, frameworks and maybe machine learning frameworks operate on it.",
            "So the natural question would be OK, why don't you just take one of the existing learning frameworks which already operates Papa Juice?",
            "Just put it in.",
            "So one such open source framework is called Mahal.",
            "Which is also in the project project and we actually thought hard about it.",
            "Could we use Apache mahout for whatever we do?",
            "And the answer was not really primarily for one particular reason, and the reason was ease of integration.",
            "We really wanted to make whatever we do really easy for users to actually interface with and use it in day-to-day analysis.",
            "And they said to integrate Mahout into pig.",
            "Processing flows is pretty hard and not natural.",
            "I'm going to show example later on how this can be done, but this is something which would probably prevent a lot of people from getting the maximum benefit from using any machine learning."
        ],
        [
            "So having said that, what did we actually do?",
            "So first of all we built a library of machine learning routines.",
            "As I mentioned before, we focused on fairly simple models such as logistic regression for example, which are very easy to implement.",
            "And by implementing things ourselves, we're able to put some extra optimizations which would otherwise.",
            "It's difficult to get from outside, but we also integrated bunch of our libraries to the extent we could, so we did everything.",
            "Implementing from scratch.",
            "Now the important thing was to build a bridge between this library and the high level processing languages that people use for doing the analytics jobs.",
            "So in this case Pig and Scala and Python, which some people use but not most of the people.",
            "So big email is the primary and result of this effort which I'm going to talk about in detail in a little bit."
        ],
        [
            "So this is how it works.",
            "So there is this library.",
            "Of low level code which actually performs the learning and execution of machine learning.",
            "There is our data pipeline which produces the data.",
            "There's an integration of internal next door components in the form of this library.",
            "There's execution of jobs dope using big and there is this marriage of Pagan machine learning via the pig email bridge which I'm going to show you in a second."
        ],
        [
            "So let's start with just having a very, very brief overview of how MapReduce works.",
            "So usually we take the data in the form of key value pairs produced by some process.",
            "We randomly partition this.",
            "Into a number of mappers which do some processing of this data so they can be for example doing some feature extraction or transformations of words and maybe some approximate matching.",
            "So and so forth.",
            "And this produces another layer of key value.",
            "Pairs which are sorted by the value of the key.",
            "So once we sort by the value of the key, we can essentially send all the.",
            "All the elements of the same key value to this particular processor called Reducer, which is going to do something with them.",
            "For example, we can count the number of words we can, the summary statistics on words which would be fairly common to do when we do text processing, and at the end we store this data to the Hadoop file system and do something else with it.",
            "So that's in a nutshell the MapReduce pipeline."
        ],
        [
            "Now, this is how you program this more or less in Java, which is the primary language for who do so right?",
            "A lot of.",
            "Lower level boilerplate code, which is actually pretty hard to do, and almost nobody does it.",
            "So what we do instead?",
            "Well, right this very very.",
            "Short script which does everything everything for us so allows the data that some grouping of the data by some key.",
            "It does some statistics you can do joining of different tables and so on and so forth and at the end of the day we just store the results to file let's say.",
            "So a lot of people can get very proficient very fast writing.",
            "This kind of code."
        ],
        [
            "So how we do machine learning integration into this process?",
            "So they want to embed whatever machine learning you want to do into the pig processing language.",
            "We want to make it flow naturally with other people are already doing.",
            "And we want to minimize the learning curve for for our users."
        ],
        [
            "So let's say we want to learn a model of some kind.",
            "So what we do here we load the data from file and we're assuming here the data is being processed in some way, so we may be our label and some features.",
            "And."
        ],
        [
            "The.",
            "What we do next.",
            "We just store this data.",
            "With some extra parameters and the special storage function.",
            "And that's it."
        ],
        [
            "So essentially our our whole learner is just a storage function.",
            "So from the end user perspective, they're not doing anything different than before, which is loading the data.",
            "Maybe they do some extra transformations on it and they store it, let's say so the whole whole learning is actually in capsulated in the storage function."
        ],
        [
            "Well, let's say we have a learned model.",
            "Want to apply to some new data.",
            "So.",
            "Well, we load the model from file with some special evaluated function."
        ],
        [
            "But otherwise we just processing as before.",
            "Which is a lot of data.",
            "We apply our model to the data via mapper.",
            "We do some maybe statistical processing of the result and we store the results.",
            "So that's pretty much it."
        ],
        [
            "Now it's going to be important to understand.",
            "Well, the limitation of this kind of framework so.",
            "All the mappers and reducers are used here, actually implemented via so-called user defined functions.",
            "Pig and.",
            "So using the find function sitting in the reducer has limited resources.",
            "So remember we operating over big Data, so we cannot really pump.",
            "Gigabytes of data into single reducer, which at best kind of a couple of gigs of RAM.",
            "So this poses certain limitations for what kind of machine learning we can actually do over this.",
            "And primarily we cannot iterate over the whole data while doing the learning.",
            "It just wouldn't work.",
            "OK.",
            "So this leaves the option of doing online learning or learning with.",
            "Fairly small amounts of data per single reducer.",
            "So how do we solve this problem?",
            "So.",
            "Let me."
        ],
        [
            "Just give a very quick overview of.",
            "How generally this whole process works?",
            "I mean machine learning.",
            "So we got some data which comes in the form of some.",
            "Oh well, maybe not so fast so that it comes in the form of.",
            "Some input vectors feature vectors, and probably some labels, maybe class labels, maybe some target functions.",
            "So that's our training set.",
            "And we want to find the mapping from our input representation to our labels.",
            "Such that we minimize some kind of a loss function.",
            "So this is our loss function.",
            "And.",
            "Essentially, we're doing an optimization problem of finding some kind of vector of parameters, usually, which leads to the minimum value of this loss function.",
            "So.",
            "One of the things to keep in mind is closed form solutions of this another possible, so we have to solve it numerically."
        ],
        [
            "And one such numerical optimization technique which people use a lot of this called gradient descent.",
            "Think probably a lot of people already familiar with this.",
            "So we compute the gradient of this loss function by looking at.",
            "The values of of whatever we actually optimizing.",
            "He returned for every single amount of data set, and this implies we're doing an iteration over all of our data.",
            "Just be able to compute one value of this gradient.",
            "So we need to consider everything actually to compute this gradient.",
            "So this is actually pretty bad, right?",
            "Because I mean we cannot hold this thing in memory in computers all the time.",
            "So the option is to do something called the Gothic gradient descent.",
            "So what's the difference is instead of computing the whole gradient over all of our data, we approximated by looking at the value of this gradient for one instance.",
            "So what does it mean?",
            "We can stream from a data set 1 by 1 and essentially update our problem from parameter vector after seeing each example in the sequence.",
            "So it's very efficient.",
            "Essentially, we're doing online learning.",
            "And you might say it doesn't really work.",
            "Are we losing anything?",
            "Well, it turns out in practice we almost never lose anything.",
            "Essentially works just as well as doing the full gradient.",
            "So it solves our iteration iterative process, so we all need to go over our data over and over again.",
            "We can just stream all our data for a single reducer, even with very limited memory resources.",
            "So that's very important.",
            "But what we we have a huge data set?",
            "Do we really need to stream it through a single node in a cluster which could potentially call cause a network congestion problem?"
        ],
        [
            "And the answer is ensembles so classifying ensembles are classified.",
            "Committees have been used extensively in the machine learning community and usually perform extremely well, and boosting is 1 example, which unfortunately doesn't fit into the map reduce framework very well.",
            "But there are others which are made based on randomization which actually fit into this framework very well."
        ],
        [
            "So how do we compare a single classifier?",
            "Learning with a somber learning?",
            "It's actually very analogous, so in a single graph for learning.",
            "We take the data which we loaded from disk and we process via mappers.",
            "And we bump it to single register.",
            "That's it.",
            "And there is some storage function which essentially learns the model.",
            "Now.",
            "Let's say we now.",
            "Do the same thing as before, but instead of pumping everything for a single reducer here, which is randomly split this data so that someday that goes to this producer someday that goes into this reducer.",
            "So effectively we're training two different models on different subsets of the data.",
            "And we'll make the prediction.",
            "There's really no difference.",
            "We blow the model as a single file.",
            "And apply our UDF.",
            "Overload the model is a collection of model files and internally do the model aggregation.",
            "Apply the model, that's it."
        ],
        [
            "So what is and what is an individual modeling symbol?",
            "It can be also a linear model trained over stochastic gradient descent, or it could be something else, such as a decision tree.",
            "Which creates an architecture which some people call a random forest."
        ],
        [
            "There is another interesting uses of over clusters, such as parameter tuning and learning.",
            "Counting based model such navbase, but this is perhaps not so interesting."
        ],
        [
            "So let me give you a concrete example which is probably relevant to this Community, so this is sentiment detection.",
            "So sentiment detection is something that people like to study for tweets.",
            "For a variety of reasons, let's say I want to predict the election results went to the target.",
            "People like certain colors or not.",
            "Or maybe they people want to figure out if people like certain movies or not.",
            "So in our case we wanted to apply a very, very simple technique for doing so and see if it works with a large quantity of data, and more importantly, how does it actually depend on the amount of data we apply to the problem.",
            "So one problem with sentiment detection people face is how to get the label data.",
            "I mean how do we actually know if something is like positive sentiment and negative negative sentiment is a hard problem and we kind of cheated a little bit by using the emoticons.",
            "So the emoticons smileys is something people are very often attached to.",
            "Personal messages or tweets or not?",
            "So we took the assumption that the :) happy face represents the positive sentiment and sad face and negative sentiment.",
            "So we took this data and instead of doing fairly deep deep semantic analysis of what keywords are likely to be sentiment bearing and so forth, we actually just extracted all four grams from those tweets.",
            "By 4 grams I mean character based programs, not word level 4 grams.",
            "And we build a logistic regression model or a collection of such."
        ],
        [
            "And these are the results.",
            "So what it shows is that if we change a single or just aggression model over such a presentation using more data definitely improves the performance.",
            "I mean clearly.",
            "Now, Interestingly, even a small sample of three classifiers.",
            "Vastly outperforms a single model.",
            "Using fewer data, so this is trained with 100 million.",
            "Examples and all of those are trained with just 10,000,000 examples and this is the number of ensemble elements in the collection.",
            "Securely one element with.",
            "100 million examples is not as good as three trained with just 10,000,000.",
            "So symbols win, and it's interesting that those are examples of linear classifiers, which often find people which often people find to be not as effective as long as classifiers.",
            "But in this case they work pretty well.",
            "And there is a lot of diminishing returns by going into essentially.",
            "More data with with with the samples through the use of ensembles was more important in this case.",
            "In the use of of more data, but more later still helps."
        ],
        [
            "So.",
            "Some people may ask.",
            "OK, so you proposing this category descent online algorithm?",
            "Which streams for the data.",
            "But what I what if I really have something which requires iterations?",
            "So what do I do now?",
            "So there is a few options.",
            "I mean, it's not impossible.",
            "So if the number of iterations really small, we can just like manually unroll them.",
            "You know we can just unroll the loop and then we can do it straight in pig.",
            "Well, the problem is like we've very often done, know the number of iterations ahead of time, and even if we did, it would probably be fairly large.",
            "Well, the second is to.",
            "Actually implement this thing in.",
            "In something like cascading Framework in Python Scala, but it's extra work, it doesn't really fit well with whatever we do.",
            "Recently there's been some options of adding custom control flow to pick, but I mean it's very recent.",
            "It's actually not fully baked yet.",
            "So the really option is to write the custom map reduce job.",
            "Or use something like an external framework like Mahal which can do it for us.",
            "So really faced one particula."
        ],
        [
            "Problem where this was interesting, that was stopping modeling.",
            "So topic modeling is something a lot of people study for a variety of reasons and we also found it useful for our applications.",
            "So what you see here is like one particular topic.",
            "Corresponding to GOP or Republican primaries in the states from sometime spring this year, you can recognize a lot of candidate names and politician names here.",
            "Just to give one example."
        ],
        [
            "And the technique we used I wanted to use it's called LDA or latent rich location is beige and soft clustering technique.",
            "A lot of people like to use for topic modeling.",
            "And we also like to be able to do this over our data.",
            "And what do we care?",
            "Or we care about it because we want to model the interests so want to employ, improve our ability to figure out what things could be good.",
            "Could be good for recommending to what users."
        ],
        [
            "So this is how that kind of a problem can be solved.",
            "So we can still process our data in our pipeline using Pig.",
            "At some point we have to break this thing altogether.",
            "Launch another process, in this case Mahal, which is going to compute the whole day model for us using whatever number of iterations needs and then one is done.",
            "We need to then relaunch our.",
            "Whatever is left of our of our pipeline pig to finish off the model creation and then maybe apply the model to data so it's not exactly seamless but doable in some special instances like this or perhaps in others like page rank of other cases of problems where we really need to go over everything."
        ],
        [
            "So I'm going to skip the LD applications because.",
            "I already mentioned them."
        ],
        [
            "And just wanted to add the one thing that people.",
            "I found interesting in LDA or useful when applying them to data over and over again is to anchor them to specific topics.",
            "So let's say we recompute the topic model over and over again.",
            "You lose the ability to.",
            "To assign clear semantic labels to individual topic groups, unless we do the manual labeling process ourselves or we have a very good way of doing so automatically.",
            "But typically what is actually more useful is to.",
            "Maintain some kind of a consistency in the process, so either see those topics with known topics or essentially use the results of previous iterations for the new iterations.",
            "So I think you get the picture that we.",
            "We had."
        ],
        [
            "We use a lot of open source software and we contribute back to open source, so just wanted to mention a few things we actually actively contributing to Soma.",
            "How'd I mentioned already?",
            "We have one over one of our engineers.",
            "Jake Mannix is A is a one of the committers there.",
            "We also have a custom graph processing platform which we.",
            "Recently released to GitHub.",
            "I also contribute to pick two cascading with Python And Scala and number of other things."
        ],
        [
            "So the talk is about machine learning in Twitter, but there's also a large community of people which do machine learning outside of Twitter.",
            "I think I'd like to mention that also, and it's interesting to see what people.",
            "Find as being exciting outside of Twitter.",
            "So a lot of people do sentiment analysis, sentiment detection.",
            "People do event tracking, such as disease tracking.",
            "Natural disaster tracking so so forth people are interested in politics.",
            "People interested in locality detection, geotagging, so, and so forth.",
            "And some people interested in his spam detection."
        ],
        [
            "So actually on this last topic.",
            "Which is actually a topic close to my heart.",
            "I did a quick search in the number of publications on Twitter spam in Google Scholar not so long ago, and as you can see, although tour is still very very new, the number of publications catches onto the more established times of sound people already published on."
        ],
        [
            "And on the flip side, if you look at what?",
            "Other people are publishing about potentially spammer interesting topics, and Amazon there is a fair number of interest.",
            "Or making money on Twitter in a variety of forms, and none of which are legit."
        ],
        [
            "So what we apply machine learning other techniques too.",
            "That I can do is farm.",
            "What do we actually look at where we actually try to track and I'm sure some people here I gave are going to be complaining to me about queer spam.",
            "So let me just.",
            "Describe the broad types of spam we see it or so.",
            "The first category is the the old replies that mentions so, so this is very much like emails from somebody is going to contact you directly and try to offer you something.",
            "Probably clicking on the link.",
            "All.",
            "We have transparent.",
            "So people trying to monetize searches very similarly to people trying to monetize web searches.",
            "And we have follow spam in which spammers are trying to essentially build out their following follower network.",
            "And then sell it for money or spam to them sometime in the future.",
            "So if you look at those types of spam that can be classified into long term interest and short-term interest.",
            "So they follow.",
            "Spammers are probably long term interest because it takes time to actually build those networks.",
            "And those guys are very much shorter, so as long as they can monetize things pretty fast.",
            "It is a quick game for them.",
            "So the question is like can we actually detect detect interesting patterns of things in Twitter for spam detection and.",
            "Just to show you a Cup."
        ],
        [
            "All of examples.",
            "This is probably not very visible here, but.",
            "What this shows essentially is the patterns of user interaction in terms of other applying.",
            "For regular pre users and.",
            "You probably don't see those kind of connections here, but what is interesting here is that a lot of normal users.",
            "Quote unquote in Twitter, communicate primarily locally so people have friends.",
            "People they follow in more or less the same geographical location.",
            "Now."
        ],
        [
            "If you look at the patterns of spam, which infinitely are not all visible here, but we should be seeing here is that there's a lot of long-term collections.",
            "Coming from various places.",
            "And not so many connections corresponding to people living in the same area.",
            "So those are ad mentions essentially corresponding to spam interactions.",
            "So there's definitely data related to the interaction and the network, which is very meaningful for detecting spam.",
            "So.",
            "Just to run."
        ],
        [
            "Up up, I really wanted to give credit to a lot of people which worked.",
            "We're on building out infrastructure and from various size bubble in the core machine learning and building pipelines, and think feature extraction so it's not giving credit to all of them, but those colleagues of mine that primary creators of the system and."
        ],
        [
            "That I wanted to end and ask you for questions.",
            "So you made an interesting comment when you talked about what the definition of big data is and the definition was something like.",
            "If you have to have a data warehouse, then it's big data.",
            "And then my question is, can researchers like us who don't happen to have data warehouses lying around actually ever do research on big data?",
            "Um?",
            "I think so.",
            "I mean, the interesting thing about the big data is that.",
            "When you analyze various problems, you very rarely need all of the data at the same time.",
            "So if I say that we need the data warehouse to process the data, it means that all of the components of the surveys needed, but each of the components you know touches perhaps only a fraction of this data.",
            "So from the research perspective, you can definitely look at large data repositories, but you know maybe which fit on, not in the data center.",
            "Can you maybe talk about how you did the recommendations for The Who to follow?",
            "Task because this is doesn't really fit in what you said so far.",
            "I mean, you can do it with the methods you just mentioned, but maybe there are better ones for doing that more suitable.",
            "Well, I cannot give you like all the details on how it works.",
            "But you know who to follow is a problem involving essentially recommendation of a graph.",
            "So you might say that there are variety of of relevance propagation on the graph, which don't necessarily require machine learning.",
            "But I'm just going to say that if you take the same signals which you can build, you know heuristically or via some formulas and use them in features in the machine learning process where you have labels from user interactions.",
            "You can probably improve on this quite a bit.",
            "So hopefully that kind of answers the question.",
            "Do you have indicators of how this is impacting in Twitter users?",
            "How is it impacting on Twitter scissors?",
            "I mean how they're perceiving the benefit of these different techniques and the.",
            "In the daily use of two.",
            "Well, sure, I mean I cannot tell you well it's improving by X percent, But definitely for everything we do, we try to measure the impact and essentially use it only if it proves useful.",
            "So the whole the whole premise is not not to build machine learning for its own right.",
            "Just because we can, but you know that's actually improve.",
            "Our metrics are people more happy with the content or engaging more?",
            "Are they interacting more?",
            "Essentially all those measures are applied to figure out what methods are useful and what methods should be retained, or which ones should be scrapped.",
            "So we have sort of similar questions with the training topics you have global training topics.",
            "You have local training topics.",
            "I've been debating questions and how you compute those training topics is clearly a mixture between freshness of the new hashtag and whether you can analyze recurring trending topics.",
            "And if you do something with this sort of question.",
            "Well, it's a good question with which.",
            "Again, I've I can only provide a vague answer.",
            "So training topic is clearly like an important thing that people like to see on Twitter.",
            "And I can say there is a number of competing models which are being evaluated and it's really very much work in progress, so we try to improve.",
            "What is the trending topic?",
            "Is the definition an how they are personalizing of visibly different users?",
            "But unfortunately I can't really tell you.",
            "OK, this is exactly how we do it.",
            "OK, so I understand that of course it's not possible like see the details on a lot of these techniques.",
            "I was wondering if it would be possible for lack organization like Twitter, but we could ask the same question to the Google just today.",
            "Is there if there's kind of a mean half at least share like the way these techniques are evaluated and kind of evaluation set?",
            "Or if these brings in some problem because just showing like the the data set that are used to evaluate this techniques is the kind of way to reveal also how the techniques work.",
            "Well, it's a good question and I think evaluation itself is a fairly big problem for a lot of things in Twitter, because as I mentioned before, because of the real time aspect of a lot of things.",
            "So to the extent that you can have static data set which actually tells you K is this method performing better than others, it's actually pretty difficult without doing like a proper AB test and doing a live test.",
            "So that is really the crux of the problem that they really figure out if something is.",
            "Is better than something else you really need to do a real user study on the life system.",
            "To show if your your metrics in terms of user.",
            "Satisfaction of the data are better or not.",
            "So publishing a static set probably would not be very useful.",
            "I have a question on the topic computation.",
            "So at the beginning of the talk you started saying that well, sometimes simpler classifiers perform extremely well on certain tasks, right?",
            "Then I was puzzled to see I mean LDA on your slides becausw.",
            "I mean, this is a relatively complex and computationally demanding.",
            "Model, you know compared to something as simple as I know, K means clustering to find to mind the topic.",
            "So do you have evidence that you're finding better topics using?",
            "Something relatively complex is a compared to simpler approaches to find topics.",
            "Well, it's it's a very good question, so to some extent the LDA in this case is an exception to the rule.",
            "So the vast majority, the vast majority of models were trying to use as I described, the actually quite simple and follow the online learning paradigm.",
            "The topics are, I mean, the way we actually implemented LDNY was really to do large scale.",
            "Study internally, to the extent that we work, very or not.",
            "Anne at this point is still a study in progress, so we found it interesting enough to try it to see if they perform better.",
            "But as far as I can say, the jury is still out.",
            "The jury is still out.",
            "Yes, my question is regarding the number of topics that you are defining in the LDA model.",
            "How do you get that number?",
            "So we essentially do well.",
            "You would want to do.",
            "We tried different numbers mean there is.",
            "We have some, of course a priority information about other techniques which we use for simple tasks from which we can derive the likely number of topics.",
            "But really answer the question.",
            "OK, is the prior actually a good prior failed EA?",
            "There is a little basis for saying so, so really kind of expand the number or contract the number of topics to see which which combination actually is better.",
            "So it's like a data driven approach if you like.",
            "Let's see if you would have a chance to re decide.",
            "Which platform to choose?",
            "Would you do something else nowadays or how?",
            "It's a good question, I think at this point there is a lot of upcoming experimental technologies which some of them may be offering.",
            "You know better processing capabilities in the future or or.",
            "Essentially, more processing in memory, less of touching the source so forth.",
            "But the advantage, even today of something like dope, is the maturity.",
            "So in terms of doing things for a fairly large amount of data, such as it were, you have to think about performance and also maturity of the technology and the tools around it.",
            "So even today, probably it will be the right choice, although I'm not a Hindu backspin myself so I cannot say this is a definitive answer, but that's what I think.",
            "What about a framework that is built for large graphs, such as something like Pregel or the other graph based systems?",
            "It's a good question so.",
            "So our graph processing actually predates Pregel, and if you remember from one of the slides I mentioned cassowary, which is our custom graph structure, which is open source and we have internally kind of new generation of this platform that we use internally.",
            "So for pure graph processing, which we have something which is essentially specially suited for that.",
            "But I mean Pregel and the giraffe and other things are actually quite relevant, and if we didn't have anything already, would probably look at using them.",
            "So I have another question, so there's another thing you didn't much talk about, but you couldn't talk about everything in the Twitter ecosystems.",
            "There is also all the things that concerns media that you attach new to it.",
            "So Twitpic, Twitvid and all this stuff on Twitter now you start seeing when we search for topics.",
            "So events Major Gary generated.",
            "Sometimes we've even duplicates removed, and so on.",
            "So what type of machine learning?",
            "Again, I'm going to apply on this and what are your plans on on media attached to tweets.",
            "Well, I think we we plan to.",
            "To use more of it because people interact with media quite a lot and media is interesting.",
            "As far as I know, the amount of machine learning actually in the current.",
            "Product the stuff you see is not that high and this is something we are trying to expand it to.",
            "Could it be a good idea to include information from the list in Twitter in the topic the detection algorithm?",
            "It probably probably would be a good idea about the topic, so if we talk about topics the topics can be understood in many different ways, so the topics I showed in the graphs where topics detected from the tweets themselves, the list information thank you also refer to your own paper actually on this.",
            "The list I used by other users in the form of tagging what the users who those users are.",
            "So it's an alternative way of classifying users, but essentially it's not a guarantee.",
            "I mean, there's there's.",
            "There's a correspondence between what the user is is tagged with and what the user is tweeting about.",
            "Although the guarantee is kind of vague, so even if I use the list data too.",
            "Aid in the detection of topics I probably need to look at the text itself.",
            "Actually have some very confident about those topics.",
            "OK, I guess we exhausted questions like Thanks Alec will be around I guess today.",
            "So yeah, I'll be around if you have more questions.",
            "So just grab me.",
            "Yeah, the secret parameters.",
            "Uh.",
            "OK, thanks again.",
            "Well thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, welcome this afternoon session.",
                    "label": 0
                },
                {
                    "sent": "So the intention with this stock was to have somebody who would really give information from within Twitter.",
                    "label": 0
                },
                {
                    "sent": "We all deal with Twitter, but from the outside side.",
                    "label": 0
                },
                {
                    "sent": "So here we have somebody who sees Twitter from the inside site and probably best person we can get or one of the best people of this kind would be Alec.",
                    "label": 0
                },
                {
                    "sent": "So few words about the Alex so, but he was doing big data even before anybody mentioned this word.",
                    "label": 0
                },
                {
                    "sent": "So in the whole series of big companies.",
                    "label": 0
                },
                {
                    "sent": "So back in early 2000s he was in AOL, so he sold his AOL streams of data doing.",
                    "label": 0
                },
                {
                    "sent": "Spam detection and detecting all this shady business which happens on the Internet from the AOL site.",
                    "label": 0
                },
                {
                    "sent": "So lots of experience on that side.",
                    "label": 0
                },
                {
                    "sent": "Then he moved to Microsoft to Life Labs.",
                    "label": 0
                },
                {
                    "sent": "So he was in this core group, which evolved I guess in today's Bing and two years ago, right two years ago I like moved to Twitter when Twitter was already around, but not as popular as today.",
                    "label": 0
                },
                {
                    "sent": "Remember, it was big announcements.",
                    "label": 0
                },
                {
                    "sent": "Smart person from Microsoft going to Twitter.",
                    "label": 0
                },
                {
                    "sent": "So this was Alec.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And now he works in this, let's say research side of Twitter and pretty much he.",
                    "label": 0
                },
                {
                    "sent": "He touches the data every day, which we would only wish to touch most of us.",
                    "label": 0
                },
                {
                    "sent": "And so the idea is basically to give us a little bit of a flavor.",
                    "label": 0
                },
                {
                    "sent": "What happens behind that?",
                    "label": 0
                },
                {
                    "sent": "So curtain not really well curtain Alex please.",
                    "label": 0
                },
                {
                    "sent": "Thank you, Marco.",
                    "label": 0
                },
                {
                    "sent": "Thank you all for coming.",
                    "label": 0
                },
                {
                    "sent": "So let me begin by referring to the previous keynote speaker and and I was actually also at SIGMOD last week, and it's interesting to see how certain concepts.",
                    "label": 0
                },
                {
                    "sent": "Spread around pretty fast with this research network if you like, so there was a keynote speech at SIGMOD which referred to.",
                    "label": 0
                },
                {
                    "sent": "People's database experts, data scientists, and data enthusiasts and think they.",
                    "label": 0
                },
                {
                    "sent": "The previous speaker correctly classified this community as being of very cool database experts, which are probably right.",
                    "label": 0
                },
                {
                    "sent": "So my talk is more about machine learning and I think for the machine learning perspective, this community is probably community of machine learning enthusiasts, so machine learning is not the key problem, but turns out to be quite useful in all applications.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to talk about this something which is rarely discussed, is how they actually build a fairly large machine learning system over whatever we call big data right now, and I'm going to talk about later whether or not we can call Twitter big data, but I think it's got some of the kind of processes and thought processes that we went through in trying to make it scalable and trying to make it useful for both data experts or scientists feel like.",
                    "label": 0
                },
                {
                    "sent": "And that enthusiasm.",
                    "label": 0
                },
                {
                    "sent": "So let me ask everybody how many people actually use their.",
                    "label": 0
                },
                {
                    "sent": "Their hands so lot so I wasn't quite sure how much they have to explain about Twitter about me.",
                    "label": 0
                },
                {
                    "sent": "Just show some.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some cool pictures, so this is an event which happened a few years ago in Los Angeles, so there's a mid sized earthquake.",
                    "label": 0
                },
                {
                    "sent": "Which then caused a whole lot of damage, but we managed to shook to shake supermarket shelves.",
                    "label": 0
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                },
                {
                    "sent": "So this is an interesting statistics about how the news about this information spread.",
                    "label": 0
                },
                {
                    "sent": "So the national media in the US caught on to this in about 9 minutes.",
                    "label": 0
                },
                {
                    "sent": "Now the local media in Airlaid Radio stations, if you like, was faster.",
                    "label": 0
                },
                {
                    "sent": "So only about four minutes.",
                    "label": 0
                },
                {
                    "sent": "3 problems event.",
                    "label": 0
                },
                {
                    "sent": "Now the first tweet about this happened 5 seconds.",
                    "label": 0
                },
                {
                    "sent": "After and by the time the national media caught onto it, if you actually combined all the tweets about this event, you could publish a whole book.",
                    "label": 0
                },
                {
                    "sent": "So like I'll give you a picture of the spread of information on Twitter and the real time aspects of it.",
                    "label": 0
                },
                {
                    "sent": "Let's take a look at.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other example, So what you see here is essentially add replies to and from Japan over Twitter network.",
                    "label": 0
                },
                {
                    "sent": "This is kind of like a normal day.",
                    "label": 0
                },
                {
                    "sent": "Go often going and going.",
                    "label": 0
                },
                {
                    "sent": "Nothing much changes.",
                    "label": 0
                },
                {
                    "sent": "So right now what's happening is like big Earthquake in Japan.",
                    "label": 0
                },
                {
                    "sent": "See the increase of volume.",
                    "label": 0
                },
                {
                    "sent": "So those are just add replies.",
                    "label": 0
                },
                {
                    "sent": "People who follow people in Japan out applying them and vice versa.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a corresponding traffic of retweets.",
                    "label": 0
                },
                {
                    "sent": "So retweeting people from Japan was the kind of pinkish color.",
                    "label": 0
                },
                {
                    "sent": "And then the retweets propagate over the rest of the world over the green network.",
                    "label": 0
                },
                {
                    "sent": "So with the exception of very very cold countries and very very hot countries before we cover the whole world.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, in a nutshell, water square.",
                    "label": 0
                },
                {
                    "sent": "So some people call it microblogging service with a lot of this term so much.",
                    "label": 0
                },
                {
                    "sent": "But it's probably true.",
                    "label": 0
                },
                {
                    "sent": "It's really about having this open channel communication network in which people can share opinions and exchange information in the person to person present a group of people, person to everybody, essentially Mallory.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "Characterizing factor is that the tweets are restricted to 140 characters, which probably everybody knows, and so some people see it as a constraint.",
                    "label": 1
                },
                {
                    "sent": "But actually it doesn't.",
                    "label": 0
                },
                {
                    "sent": "To be pretty handy when it comes to sharing important ideas and helping people to organize and exchange information so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To give some concrete examples.",
                    "label": 0
                },
                {
                    "sent": "So those are some events from last year, so we probably all aware of the Arab Spring movement which happened all over Northern Africa and the Middle East so.",
                    "label": 0
                },
                {
                    "sent": "What happened is that we're actually is quite useful for helping people to figure out where those protests happening.",
                    "label": 0
                },
                {
                    "sent": "What is going on?",
                    "label": 0
                },
                {
                    "sent": "Where is the police intervention so on so forth, and typically the way people do this on Twitter via hashtags.",
                    "label": 0
                },
                {
                    "sent": "So by inserting hashtags in tweets, people can search for them and find out what is going on right now with respect to the speaker on topic.",
                    "label": 0
                },
                {
                    "sent": "And interest.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only a very similar effect happened first in the US and then it spread actually all over the world again with respect to the Occupy Wall Street movement.",
                    "label": 0
                },
                {
                    "sent": "So again very similar concept trying to exchange information and inform ourselves kind of outside the established media channels which don't necessarily reporting this all the time, or can perhaps sometimes marginalized what is going on.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's a scale of three right now, so this is not exactly up to the information is from April, so the numbers could have changed a little bit, but with about 140 million active users, so people who use it fairly frequently, there's about 340 million tweets.",
                    "label": 0
                },
                {
                    "sent": "Published per day and essentially much, many more consume.",
                    "label": 0
                },
                {
                    "sent": "There's 400 million visitors through.com domain.",
                    "label": 0
                },
                {
                    "sent": "And about 50 million people log into Twitter every day.",
                    "label": 1
                },
                {
                    "sent": "Soldiers.",
                    "label": 0
                },
                {
                    "sent": "Large scale stats.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can interface that we have a number of ways.",
                    "label": 0
                },
                {
                    "sent": "Some people just use the web interface.",
                    "label": 0
                },
                {
                    "sent": "Some people use various apps like Tweetdeck for example, which is displayed in the whole here.",
                    "label": 0
                },
                {
                    "sent": "There's also SMS and whereas mobile phone clients and actually over 50% of our users are mobile users, so it's actually particularly useful for people who check stuff out on the on the mobile phones while sitting in a box I guess.",
                    "label": 1
                },
                {
                    "sent": "And not only.",
                    "label": 0
                },
                {
                    "sent": "It was about really about the real time distribution of content or close to real time.",
                    "label": 1
                },
                {
                    "sent": "And it's not only that there's also services which sit on top of it and help users to find interesting information.",
                    "label": 0
                },
                {
                    "sent": "So what are those services?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This all while there's search and there is user recommendation and there's various other forms of recommendation which help people to understand what is going on.",
                    "label": 0
                },
                {
                    "sent": "So do they extend?",
                    "label": 0
                },
                {
                    "sent": "Machine learning is relevant?",
                    "label": 0
                },
                {
                    "sent": "Where is relevant in helping?",
                    "label": 0
                },
                {
                    "sent": "To help users to find relevant stuff.",
                    "label": 0
                },
                {
                    "sent": "It's not the only way of to do so, but it turns out it can be actually quite useful.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's take a look at the problems which I need to solve with machine learning and otherwise.",
                    "label": 1
                },
                {
                    "sent": "So one of such problems, this search, or the relevance in search?",
                    "label": 1
                },
                {
                    "sent": "So when people come to search on Twitter, their search for number of things, one of such things is users.",
                    "label": 0
                },
                {
                    "sent": "So people want to find other users.",
                    "label": 0
                },
                {
                    "sent": "The users could be celebrities.",
                    "label": 0
                },
                {
                    "sent": "Could be bloggers clear people.",
                    "label": 0
                },
                {
                    "sent": "I already know from somewhere else, so I'm really find them.",
                    "label": 0
                },
                {
                    "sent": "A lot of things could be events.",
                    "label": 0
                },
                {
                    "sent": "So I know something is happening.",
                    "label": 0
                },
                {
                    "sent": "I want to come up here and find out what is going on about this particular event.",
                    "label": 0
                },
                {
                    "sent": "Maybe there's election happening, maybe there's an earthquake, maybe something else.",
                    "label": 0
                },
                {
                    "sent": "And really, people have two mindsets about this, so one is show me the freshest stuff about this thing, whatever it is, even if it's noisy.",
                    "label": 0
                },
                {
                    "sent": "So this is typical when people follow hashtags.",
                    "label": 0
                },
                {
                    "sent": "It's kind of interesting the rofi.",
                    "label": 0
                },
                {
                    "sent": "And another way to look at it, and it's like I really want to find the relevant information about a particular event, so I really want to find out about the Occupy Wall Street movement, but not the kind of blow by blow accounts of what everybody is doing.",
                    "label": 0
                },
                {
                    "sent": "But maybe just the things that more informative people had said about this event in the recent past.",
                    "label": 0
                },
                {
                    "sent": "So those things are not necessarily In Sync, so they clash with each other.",
                    "label": 0
                },
                {
                    "sent": "So the trick is is to solve the relevance problem real time search, which really is an open question right now in the research community, how did this so best?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second problem is how to grow the tree graph.",
                    "label": 0
                },
                {
                    "sent": "So as you probably know, the way to receive information into here is to follow other people.",
                    "label": 1
                },
                {
                    "sent": "So I can follow other people for a variety of reasons.",
                    "label": 0
                },
                {
                    "sent": "Those could be our friends and family, colleagues, coworkers, so forth.",
                    "label": 0
                },
                {
                    "sent": "But they also could be media sources.",
                    "label": 0
                },
                {
                    "sent": "Could be influential.",
                    "label": 0
                },
                {
                    "sent": "Bloggers could be government agencies and so forth, so it could be a vast variety of reasons why I should be following somebody.",
                    "label": 0
                },
                {
                    "sent": "And on top of this, there's also the timescale of the interest I could be interested in somebody for a very short time or forever.",
                    "label": 0
                },
                {
                    "sent": "So to figure it out, actually it's quite tricky.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the third recommendation problem is the problem of content recommendations so.",
                    "label": 0
                },
                {
                    "sent": "Yes, I can be following other users, but they're not necessarily guaranteed to provide me with all information which I could be finding interesting.",
                    "label": 0
                },
                {
                    "sent": "So for example, new stories, media video school pictures.",
                    "label": 0
                },
                {
                    "sent": "Also for something that could be happening into it right now, which could be interesting to me, how do we actually figure out what to show to what to who?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a bunch of other problems, so there is.",
                    "label": 1
                },
                {
                    "sent": "How do they take the trending topics?",
                    "label": 1
                },
                {
                    "sent": "How text is like language?",
                    "label": 0
                },
                {
                    "sent": "How to do antispam antimalware?",
                    "label": 0
                },
                {
                    "sent": "How to optimize our revenue?",
                    "label": 0
                },
                {
                    "sent": "How to optimize our growth and so on so forth?",
                    "label": 0
                },
                {
                    "sent": "So it's like a myriad of problems, at least for some of the machine learning can or is playing a crucial component.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can see from those examples the problems we're trying to solve can be cost more or less as recommender style problems, which I recommend people to people.",
                    "label": 0
                },
                {
                    "sent": "Items to people, URLs to people, whatever.",
                    "label": 0
                },
                {
                    "sent": "Essentially those are recommended style problems and they can be solved partially through solving secondary problems such as such as classification and clustering.",
                    "label": 0
                },
                {
                    "sent": "So classic machine learning problems.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, so is this really big data?",
                    "label": 0
                },
                {
                    "sent": "So we do the math.",
                    "label": 0
                },
                {
                    "sent": "If you think OK, wealthier in 50 million tweets per day.",
                    "label": 0
                },
                {
                    "sent": "If we just multiplied by the size of the tweet.",
                    "label": 0
                },
                {
                    "sent": "So you could probably fit in the laptop.",
                    "label": 0
                },
                {
                    "sent": "So it's not really that big.",
                    "label": 0
                },
                {
                    "sent": "But then, if you actually combined all the associated media which come with those tweets.",
                    "label": 0
                },
                {
                    "sent": "And the clickstream of all the various events that could be happening.",
                    "label": 0
                },
                {
                    "sent": "Blouse updates to the graph, and so on, so forth.",
                    "label": 0
                },
                {
                    "sent": "It becomes pretty large.",
                    "label": 0
                },
                {
                    "sent": "So just to give an interesting number, so just the injectors for log data in just about 10 terabytes per day and then analytics pipeline.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I guess if you say well, if you need a data center to process this data in the long term, that's probably big data.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, what are the challenges?",
                    "label": 0
                },
                {
                    "sent": "I mean, there's many challenges just to name a few.",
                    "label": 0
                },
                {
                    "sent": "Very international, so over 70% of our users actually.",
                    "label": 0
                },
                {
                    "sent": "Are outside of the US.",
                    "label": 1
                },
                {
                    "sent": "And as I mentioned before, there is real time.",
                    "label": 0
                },
                {
                    "sent": "And I mean this is very important.",
                    "label": 0
                },
                {
                    "sent": "So people come to Twitter and really expect things to be relevant to whatever is happening right now.",
                    "label": 0
                },
                {
                    "sent": "And that's the key.",
                    "label": 0
                },
                {
                    "sent": "And of course, the brevity tweets are very short, then other shoulder search queries, but really short and sometimes very noisy.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So having said that.",
                    "label": 0
                },
                {
                    "sent": ", the question is, So what type of machine learning do actually need to solve any of those problems?",
                    "label": 1
                },
                {
                    "sent": "So I'm going to claim that we don't need any new type of machine learning as I was showing before a lot of those problems are really known problems in some form.",
                    "label": 0
                },
                {
                    "sent": "However, there is specificity which is.",
                    "label": 0
                },
                {
                    "sent": "Pertinent to the Twitter data and Twitter traffic which we need to solve.",
                    "label": 0
                },
                {
                    "sent": "And also there is the questions about where this thing actually operating.",
                    "label": 0
                },
                {
                    "sent": "What is our infrastructure?",
                    "label": 0
                },
                {
                    "sent": "How do we actually put it in?",
                    "label": 1
                },
                {
                    "sent": "And the decisions on what to build.",
                    "label": 0
                },
                {
                    "sent": "What algorithm should be applied, applying and so forth are really dependent on this kind of infrastructure implementational issues.",
                    "label": 0
                },
                {
                    "sent": "Plus the problems we're trying to solve.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me start by saying we more or less trying to apply machine learning to social networks so Twitter is a social network, if you like.",
                    "label": 0
                },
                {
                    "sent": "And there's a social network where a lot of information comes in the form of text.",
                    "label": 0
                },
                {
                    "sent": "So what does it really?",
                    "label": 0
                },
                {
                    "sent": "Tell us, I mean tells us that.",
                    "label": 0
                },
                {
                    "sent": "We probably can get away with using fairly simple models, and why can I say that whether it's like long, long, long line of research papers, both by people like adima.",
                    "label": 0
                },
                {
                    "sent": "Any industry which tend to show that for problems involving tests takes an especially large quantities of text.",
                    "label": 0
                },
                {
                    "sent": "It pays off to use fairly simple models.",
                    "label": 1
                },
                {
                    "sent": "Which can actually process lots of data rather than concentrating or on complex models, which most likely really cannot handle this data at all in the first place.",
                    "label": 0
                },
                {
                    "sent": "And if you actually can tell the data, the accuracy gains are pretty small.",
                    "label": 0
                },
                {
                    "sent": "If they actually exist at all.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The second thing which is probably more important, is.",
                    "label": 0
                },
                {
                    "sent": "We want to use machine learning for social networks in a way which is really easy to use.",
                    "label": 1
                },
                {
                    "sent": "So not everybody is a machine learning expert, and even not everybody is a data scientist.",
                    "label": 0
                },
                {
                    "sent": "So a lot of people who want to apply those models need to be able to actually apply them in a way which fits with their day-to-day dealing with the data.",
                    "label": 0
                },
                {
                    "sent": "So if you use it or some kind of analytic pipeline, you probably have your own tool set of things you like to do.",
                    "label": 0
                },
                {
                    "sent": "You know how to do, and to the extent you would like to play with models you want to be able to integrate them very easily.",
                    "label": 0
                },
                {
                    "sent": "And to us it was a key requirement for making this happen.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Machine learning for social networks.",
                    "label": 1
                },
                {
                    "sent": "Of course, social networks, as the name suggests, are graphs.",
                    "label": 0
                },
                {
                    "sent": "But this graph processing really requirement, I would say the existence of graphs really provides an asset to whatever we do.",
                    "label": 0
                },
                {
                    "sent": "It's not necessarily a hard requirement for whatever machine learning want to apply.",
                    "label": 0
                },
                {
                    "sent": "It really stems from the power of the social graph, so the graphic connected by users usually for purpose and the signal propagation in the graph tends to bring relevance.",
                    "label": 0
                },
                {
                    "sent": "So even if we apply simple models over a graph, degradation over the graph increases the power of those models, making them more accurate.",
                    "label": 0
                },
                {
                    "sent": "So it's a plus.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the real requirement is scalability.",
                    "label": 0
                },
                {
                    "sent": "So we need to scale to all the data we have and all that they were going to have.",
                    "label": 0
                },
                {
                    "sent": "We need to scale with the time of the data arrival, so processing over data streams and we need to update those models pretty fast.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "So it's pretty tall order.",
                    "label": 0
                },
                {
                    "sent": "They should build all of this together and we get a bunch of engineers and researchers and scientists in the room.",
                    "label": 0
                },
                {
                    "sent": "The natural tendency is to kind of build a lot of stuff.",
                    "label": 0
                },
                {
                    "sent": "Let's just call this thing up.",
                    "label": 0
                },
                {
                    "sent": "So yes, I mean it's possible to build everything from scratch, but what's the real benefit in doing so?",
                    "label": 0
                },
                {
                    "sent": "We probably wouldn't be able to finish anything.",
                    "label": 0
                },
                {
                    "sent": "So the real questions are, I mean, what do we actually need to build?",
                    "label": 0
                },
                {
                    "sent": "In our infrastructure to make it happen and how can we possibly reuse existing stuff from wherever it comes?",
                    "label": 0
                },
                {
                    "sent": "So we should be building should be laying low level machine learning libraries.",
                    "label": 0
                },
                {
                    "sent": "The feature extraction pipelines, maybe they distributed processing platforms.",
                    "label": 0
                },
                {
                    "sent": "Maybe the glue code.",
                    "label": 0
                },
                {
                    "sent": "This whole visualization code and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "So those are kind of the questions which naturally come to mind and need to be answered in order to build the real system.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Fortunately when we started looking at this problem, we're not operating in a vacuum, so to some extent the answers are constrained by whatever infrastructure was already in place.",
                    "label": 0
                },
                {
                    "sent": "So just to show you some of the things which are operating in our pipeline.",
                    "label": 0
                },
                {
                    "sent": "It's about the Hadoop, essentially with a lot of components around it, so the.",
                    "label": 0
                },
                {
                    "sent": "The languages such as Scala and Java and Pig.",
                    "label": 0
                },
                {
                    "sent": "There's things which make the cluster happen, such as missiles and zookeeper and storage component such as Cassandra and Edge base and so forth.",
                    "label": 0
                },
                {
                    "sent": "So those things provide like real constraints to how we're going to build stuff.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And naturally, we decided that.",
                    "label": 0
                },
                {
                    "sent": "We want to capitalize on the use of Hadoop.",
                    "label": 1
                },
                {
                    "sent": "So the data can be processed in in many different ways, but because our analytics pipeline already produces everything in Hadoop.",
                    "label": 0
                },
                {
                    "sent": "We wanted really to do everything Hadoop as well, essentially as as fitting into the map reduce process.",
                    "label": 0
                },
                {
                    "sent": "Secondly, most of our pipeline operates using one particular technology called Pig.",
                    "label": 0
                },
                {
                    "sent": "So for those who don't know much about magic, produce big is a high level dataflow language that people write MapReduce jobs with is much easier to work with pig than with working with low level Java code for example.",
                    "label": 0
                },
                {
                    "sent": "They wanted to integrate our pipeline as close as possible with Peg to make it easy for users to actually use it.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we wanted to avoid certain processes that are actually very common and probably some of you have done this in the past are doing this.",
                    "label": 0
                },
                {
                    "sent": "I'm doing this myself once in awhile, but let me call it the janky modeling process.",
                    "label": 0
                },
                {
                    "sent": "So we are facing this big data somewhere in the cluster and I want to do some modeling on it so we have some tool of choice sitting in our laptop and obviously we cannot fit this data onto the laptop.",
                    "label": 0
                },
                {
                    "sent": "So what do we do?",
                    "label": 0
                },
                {
                    "sent": "Well, probably going to downsample and somehow so whatever we get fits in the laptop OK?",
                    "label": 0
                },
                {
                    "sent": "Well, how do we know that you know this is the right sampling rate or we don't know really?",
                    "label": 0
                },
                {
                    "sent": "I mean, if it's in the laptop, right?",
                    "label": 0
                },
                {
                    "sent": "So next we're going to build some kind of a model, test it a little bit.",
                    "label": 0
                },
                {
                    "sent": "And then maybe push back to this cluster and let it drop.",
                    "label": 0
                },
                {
                    "sent": "So what's wrong with this picture?",
                    "label": 0
                },
                {
                    "sent": "Well, maybe the model is actually good.",
                    "label": 0
                },
                {
                    "sent": "I don't know, maybe not.",
                    "label": 0
                },
                {
                    "sent": "But the biggest problem is that there is no.",
                    "label": 0
                },
                {
                    "sent": "Guarantee this thing actually works and the next person which comes around and tries to like work and update this model.",
                    "label": 0
                },
                {
                    "sent": "I mean doesn't really know what happened.",
                    "label": 0
                },
                {
                    "sent": "You know what tool actually was used to build it?",
                    "label": 0
                },
                {
                    "sent": "Was the analytical process what really happened?",
                    "label": 0
                },
                {
                    "sent": "I mean, nobody knows.",
                    "label": 0
                },
                {
                    "sent": "So it's really unmaintainable.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And by saying so I'm not really shooting down the experimentation with small data.",
                    "label": 0
                },
                {
                    "sent": "I think experimentation with small data is very valuable.",
                    "label": 1
                },
                {
                    "sent": "It can provide a lot of insights, but when you have a lot of people doing this over production pipelines.",
                    "label": 1
                },
                {
                    "sent": "It really becomes a mess.",
                    "label": 0
                },
                {
                    "sent": "And we can't really have it as, like the defector standard of whatever you do.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for those of you who probably know about marriages, frameworks and maybe machine learning frameworks operate on it.",
                    "label": 0
                },
                {
                    "sent": "So the natural question would be OK, why don't you just take one of the existing learning frameworks which already operates Papa Juice?",
                    "label": 0
                },
                {
                    "sent": "Just put it in.",
                    "label": 0
                },
                {
                    "sent": "So one such open source framework is called Mahal.",
                    "label": 0
                },
                {
                    "sent": "Which is also in the project project and we actually thought hard about it.",
                    "label": 0
                },
                {
                    "sent": "Could we use Apache mahout for whatever we do?",
                    "label": 0
                },
                {
                    "sent": "And the answer was not really primarily for one particular reason, and the reason was ease of integration.",
                    "label": 0
                },
                {
                    "sent": "We really wanted to make whatever we do really easy for users to actually interface with and use it in day-to-day analysis.",
                    "label": 0
                },
                {
                    "sent": "And they said to integrate Mahout into pig.",
                    "label": 1
                },
                {
                    "sent": "Processing flows is pretty hard and not natural.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show example later on how this can be done, but this is something which would probably prevent a lot of people from getting the maximum benefit from using any machine learning.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So having said that, what did we actually do?",
                    "label": 0
                },
                {
                    "sent": "So first of all we built a library of machine learning routines.",
                    "label": 1
                },
                {
                    "sent": "As I mentioned before, we focused on fairly simple models such as logistic regression for example, which are very easy to implement.",
                    "label": 0
                },
                {
                    "sent": "And by implementing things ourselves, we're able to put some extra optimizations which would otherwise.",
                    "label": 0
                },
                {
                    "sent": "It's difficult to get from outside, but we also integrated bunch of our libraries to the extent we could, so we did everything.",
                    "label": 0
                },
                {
                    "sent": "Implementing from scratch.",
                    "label": 0
                },
                {
                    "sent": "Now the important thing was to build a bridge between this library and the high level processing languages that people use for doing the analytics jobs.",
                    "label": 0
                },
                {
                    "sent": "So in this case Pig and Scala and Python, which some people use but not most of the people.",
                    "label": 0
                },
                {
                    "sent": "So big email is the primary and result of this effort which I'm going to talk about in detail in a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is how it works.",
                    "label": 0
                },
                {
                    "sent": "So there is this library.",
                    "label": 0
                },
                {
                    "sent": "Of low level code which actually performs the learning and execution of machine learning.",
                    "label": 0
                },
                {
                    "sent": "There is our data pipeline which produces the data.",
                    "label": 0
                },
                {
                    "sent": "There's an integration of internal next door components in the form of this library.",
                    "label": 0
                },
                {
                    "sent": "There's execution of jobs dope using big and there is this marriage of Pagan machine learning via the pig email bridge which I'm going to show you in a second.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's start with just having a very, very brief overview of how MapReduce works.",
                    "label": 0
                },
                {
                    "sent": "So usually we take the data in the form of key value pairs produced by some process.",
                    "label": 0
                },
                {
                    "sent": "We randomly partition this.",
                    "label": 0
                },
                {
                    "sent": "Into a number of mappers which do some processing of this data so they can be for example doing some feature extraction or transformations of words and maybe some approximate matching.",
                    "label": 0
                },
                {
                    "sent": "So and so forth.",
                    "label": 0
                },
                {
                    "sent": "And this produces another layer of key value.",
                    "label": 0
                },
                {
                    "sent": "Pairs which are sorted by the value of the key.",
                    "label": 0
                },
                {
                    "sent": "So once we sort by the value of the key, we can essentially send all the.",
                    "label": 0
                },
                {
                    "sent": "All the elements of the same key value to this particular processor called Reducer, which is going to do something with them.",
                    "label": 0
                },
                {
                    "sent": "For example, we can count the number of words we can, the summary statistics on words which would be fairly common to do when we do text processing, and at the end we store this data to the Hadoop file system and do something else with it.",
                    "label": 0
                },
                {
                    "sent": "So that's in a nutshell the MapReduce pipeline.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, this is how you program this more or less in Java, which is the primary language for who do so right?",
                    "label": 0
                },
                {
                    "sent": "A lot of.",
                    "label": 0
                },
                {
                    "sent": "Lower level boilerplate code, which is actually pretty hard to do, and almost nobody does it.",
                    "label": 0
                },
                {
                    "sent": "So what we do instead?",
                    "label": 0
                },
                {
                    "sent": "Well, right this very very.",
                    "label": 0
                },
                {
                    "sent": "Short script which does everything everything for us so allows the data that some grouping of the data by some key.",
                    "label": 0
                },
                {
                    "sent": "It does some statistics you can do joining of different tables and so on and so forth and at the end of the day we just store the results to file let's say.",
                    "label": 0
                },
                {
                    "sent": "So a lot of people can get very proficient very fast writing.",
                    "label": 0
                },
                {
                    "sent": "This kind of code.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how we do machine learning integration into this process?",
                    "label": 0
                },
                {
                    "sent": "So they want to embed whatever machine learning you want to do into the pig processing language.",
                    "label": 0
                },
                {
                    "sent": "We want to make it flow naturally with other people are already doing.",
                    "label": 1
                },
                {
                    "sent": "And we want to minimize the learning curve for for our users.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's say we want to learn a model of some kind.",
                    "label": 1
                },
                {
                    "sent": "So what we do here we load the data from file and we're assuming here the data is being processed in some way, so we may be our label and some features.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "What we do next.",
                    "label": 0
                },
                {
                    "sent": "We just store this data.",
                    "label": 0
                },
                {
                    "sent": "With some extra parameters and the special storage function.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So essentially our our whole learner is just a storage function.",
                    "label": 1
                },
                {
                    "sent": "So from the end user perspective, they're not doing anything different than before, which is loading the data.",
                    "label": 0
                },
                {
                    "sent": "Maybe they do some extra transformations on it and they store it, let's say so the whole whole learning is actually in capsulated in the storage function.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, let's say we have a learned model.",
                    "label": 0
                },
                {
                    "sent": "Want to apply to some new data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Well, we load the model from file with some special evaluated function.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But otherwise we just processing as before.",
                    "label": 0
                },
                {
                    "sent": "Which is a lot of data.",
                    "label": 0
                },
                {
                    "sent": "We apply our model to the data via mapper.",
                    "label": 0
                },
                {
                    "sent": "We do some maybe statistical processing of the result and we store the results.",
                    "label": 0
                },
                {
                    "sent": "So that's pretty much it.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now it's going to be important to understand.",
                    "label": 0
                },
                {
                    "sent": "Well, the limitation of this kind of framework so.",
                    "label": 0
                },
                {
                    "sent": "All the mappers and reducers are used here, actually implemented via so-called user defined functions.",
                    "label": 0
                },
                {
                    "sent": "Pig and.",
                    "label": 0
                },
                {
                    "sent": "So using the find function sitting in the reducer has limited resources.",
                    "label": 1
                },
                {
                    "sent": "So remember we operating over big Data, so we cannot really pump.",
                    "label": 0
                },
                {
                    "sent": "Gigabytes of data into single reducer, which at best kind of a couple of gigs of RAM.",
                    "label": 0
                },
                {
                    "sent": "So this poses certain limitations for what kind of machine learning we can actually do over this.",
                    "label": 1
                },
                {
                    "sent": "And primarily we cannot iterate over the whole data while doing the learning.",
                    "label": 0
                },
                {
                    "sent": "It just wouldn't work.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this leaves the option of doing online learning or learning with.",
                    "label": 0
                },
                {
                    "sent": "Fairly small amounts of data per single reducer.",
                    "label": 0
                },
                {
                    "sent": "So how do we solve this problem?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just give a very quick overview of.",
                    "label": 0
                },
                {
                    "sent": "How generally this whole process works?",
                    "label": 0
                },
                {
                    "sent": "I mean machine learning.",
                    "label": 0
                },
                {
                    "sent": "So we got some data which comes in the form of some.",
                    "label": 0
                },
                {
                    "sent": "Oh well, maybe not so fast so that it comes in the form of.",
                    "label": 0
                },
                {
                    "sent": "Some input vectors feature vectors, and probably some labels, maybe class labels, maybe some target functions.",
                    "label": 0
                },
                {
                    "sent": "So that's our training set.",
                    "label": 0
                },
                {
                    "sent": "And we want to find the mapping from our input representation to our labels.",
                    "label": 0
                },
                {
                    "sent": "Such that we minimize some kind of a loss function.",
                    "label": 1
                },
                {
                    "sent": "So this is our loss function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we're doing an optimization problem of finding some kind of vector of parameters, usually, which leads to the minimum value of this loss function.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "One of the things to keep in mind is closed form solutions of this another possible, so we have to solve it numerically.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one such numerical optimization technique which people use a lot of this called gradient descent.",
                    "label": 1
                },
                {
                    "sent": "Think probably a lot of people already familiar with this.",
                    "label": 0
                },
                {
                    "sent": "So we compute the gradient of this loss function by looking at.",
                    "label": 0
                },
                {
                    "sent": "The values of of whatever we actually optimizing.",
                    "label": 0
                },
                {
                    "sent": "He returned for every single amount of data set, and this implies we're doing an iteration over all of our data.",
                    "label": 0
                },
                {
                    "sent": "Just be able to compute one value of this gradient.",
                    "label": 0
                },
                {
                    "sent": "So we need to consider everything actually to compute this gradient.",
                    "label": 0
                },
                {
                    "sent": "So this is actually pretty bad, right?",
                    "label": 0
                },
                {
                    "sent": "Because I mean we cannot hold this thing in memory in computers all the time.",
                    "label": 0
                },
                {
                    "sent": "So the option is to do something called the Gothic gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So what's the difference is instead of computing the whole gradient over all of our data, we approximated by looking at the value of this gradient for one instance.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean?",
                    "label": 0
                },
                {
                    "sent": "We can stream from a data set 1 by 1 and essentially update our problem from parameter vector after seeing each example in the sequence.",
                    "label": 0
                },
                {
                    "sent": "So it's very efficient.",
                    "label": 0
                },
                {
                    "sent": "Essentially, we're doing online learning.",
                    "label": 1
                },
                {
                    "sent": "And you might say it doesn't really work.",
                    "label": 1
                },
                {
                    "sent": "Are we losing anything?",
                    "label": 1
                },
                {
                    "sent": "Well, it turns out in practice we almost never lose anything.",
                    "label": 1
                },
                {
                    "sent": "Essentially works just as well as doing the full gradient.",
                    "label": 0
                },
                {
                    "sent": "So it solves our iteration iterative process, so we all need to go over our data over and over again.",
                    "label": 0
                },
                {
                    "sent": "We can just stream all our data for a single reducer, even with very limited memory resources.",
                    "label": 0
                },
                {
                    "sent": "So that's very important.",
                    "label": 0
                },
                {
                    "sent": "But what we we have a huge data set?",
                    "label": 0
                },
                {
                    "sent": "Do we really need to stream it through a single node in a cluster which could potentially call cause a network congestion problem?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the answer is ensembles so classifying ensembles are classified.",
                    "label": 0
                },
                {
                    "sent": "Committees have been used extensively in the machine learning community and usually perform extremely well, and boosting is 1 example, which unfortunately doesn't fit into the map reduce framework very well.",
                    "label": 0
                },
                {
                    "sent": "But there are others which are made based on randomization which actually fit into this framework very well.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we compare a single classifier?",
                    "label": 0
                },
                {
                    "sent": "Learning with a somber learning?",
                    "label": 0
                },
                {
                    "sent": "It's actually very analogous, so in a single graph for learning.",
                    "label": 0
                },
                {
                    "sent": "We take the data which we loaded from disk and we process via mappers.",
                    "label": 0
                },
                {
                    "sent": "And we bump it to single register.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "And there is some storage function which essentially learns the model.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Let's say we now.",
                    "label": 0
                },
                {
                    "sent": "Do the same thing as before, but instead of pumping everything for a single reducer here, which is randomly split this data so that someday that goes to this producer someday that goes into this reducer.",
                    "label": 0
                },
                {
                    "sent": "So effectively we're training two different models on different subsets of the data.",
                    "label": 0
                },
                {
                    "sent": "And we'll make the prediction.",
                    "label": 0
                },
                {
                    "sent": "There's really no difference.",
                    "label": 0
                },
                {
                    "sent": "We blow the model as a single file.",
                    "label": 0
                },
                {
                    "sent": "And apply our UDF.",
                    "label": 0
                },
                {
                    "sent": "Overload the model is a collection of model files and internally do the model aggregation.",
                    "label": 0
                },
                {
                    "sent": "Apply the model, that's it.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is and what is an individual modeling symbol?",
                    "label": 0
                },
                {
                    "sent": "It can be also a linear model trained over stochastic gradient descent, or it could be something else, such as a decision tree.",
                    "label": 0
                },
                {
                    "sent": "Which creates an architecture which some people call a random forest.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is another interesting uses of over clusters, such as parameter tuning and learning.",
                    "label": 0
                },
                {
                    "sent": "Counting based model such navbase, but this is perhaps not so interesting.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me give you a concrete example which is probably relevant to this Community, so this is sentiment detection.",
                    "label": 0
                },
                {
                    "sent": "So sentiment detection is something that people like to study for tweets.",
                    "label": 1
                },
                {
                    "sent": "For a variety of reasons, let's say I want to predict the election results went to the target.",
                    "label": 0
                },
                {
                    "sent": "People like certain colors or not.",
                    "label": 0
                },
                {
                    "sent": "Or maybe they people want to figure out if people like certain movies or not.",
                    "label": 0
                },
                {
                    "sent": "So in our case we wanted to apply a very, very simple technique for doing so and see if it works with a large quantity of data, and more importantly, how does it actually depend on the amount of data we apply to the problem.",
                    "label": 0
                },
                {
                    "sent": "So one problem with sentiment detection people face is how to get the label data.",
                    "label": 0
                },
                {
                    "sent": "I mean how do we actually know if something is like positive sentiment and negative negative sentiment is a hard problem and we kind of cheated a little bit by using the emoticons.",
                    "label": 0
                },
                {
                    "sent": "So the emoticons smileys is something people are very often attached to.",
                    "label": 0
                },
                {
                    "sent": "Personal messages or tweets or not?",
                    "label": 0
                },
                {
                    "sent": "So we took the assumption that the :) happy face represents the positive sentiment and sad face and negative sentiment.",
                    "label": 0
                },
                {
                    "sent": "So we took this data and instead of doing fairly deep deep semantic analysis of what keywords are likely to be sentiment bearing and so forth, we actually just extracted all four grams from those tweets.",
                    "label": 0
                },
                {
                    "sent": "By 4 grams I mean character based programs, not word level 4 grams.",
                    "label": 1
                },
                {
                    "sent": "And we build a logistic regression model or a collection of such.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And these are the results.",
                    "label": 0
                },
                {
                    "sent": "So what it shows is that if we change a single or just aggression model over such a presentation using more data definitely improves the performance.",
                    "label": 0
                },
                {
                    "sent": "I mean clearly.",
                    "label": 0
                },
                {
                    "sent": "Now, Interestingly, even a small sample of three classifiers.",
                    "label": 0
                },
                {
                    "sent": "Vastly outperforms a single model.",
                    "label": 0
                },
                {
                    "sent": "Using fewer data, so this is trained with 100 million.",
                    "label": 0
                },
                {
                    "sent": "Examples and all of those are trained with just 10,000,000 examples and this is the number of ensemble elements in the collection.",
                    "label": 0
                },
                {
                    "sent": "Securely one element with.",
                    "label": 0
                },
                {
                    "sent": "100 million examples is not as good as three trained with just 10,000,000.",
                    "label": 0
                },
                {
                    "sent": "So symbols win, and it's interesting that those are examples of linear classifiers, which often find people which often people find to be not as effective as long as classifiers.",
                    "label": 0
                },
                {
                    "sent": "But in this case they work pretty well.",
                    "label": 0
                },
                {
                    "sent": "And there is a lot of diminishing returns by going into essentially.",
                    "label": 1
                },
                {
                    "sent": "More data with with with the samples through the use of ensembles was more important in this case.",
                    "label": 0
                },
                {
                    "sent": "In the use of of more data, but more later still helps.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Some people may ask.",
                    "label": 0
                },
                {
                    "sent": "OK, so you proposing this category descent online algorithm?",
                    "label": 0
                },
                {
                    "sent": "Which streams for the data.",
                    "label": 0
                },
                {
                    "sent": "But what I what if I really have something which requires iterations?",
                    "label": 1
                },
                {
                    "sent": "So what do I do now?",
                    "label": 0
                },
                {
                    "sent": "So there is a few options.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not impossible.",
                    "label": 0
                },
                {
                    "sent": "So if the number of iterations really small, we can just like manually unroll them.",
                    "label": 1
                },
                {
                    "sent": "You know we can just unroll the loop and then we can do it straight in pig.",
                    "label": 0
                },
                {
                    "sent": "Well, the problem is like we've very often done, know the number of iterations ahead of time, and even if we did, it would probably be fairly large.",
                    "label": 0
                },
                {
                    "sent": "Well, the second is to.",
                    "label": 0
                },
                {
                    "sent": "Actually implement this thing in.",
                    "label": 1
                },
                {
                    "sent": "In something like cascading Framework in Python Scala, but it's extra work, it doesn't really fit well with whatever we do.",
                    "label": 0
                },
                {
                    "sent": "Recently there's been some options of adding custom control flow to pick, but I mean it's very recent.",
                    "label": 0
                },
                {
                    "sent": "It's actually not fully baked yet.",
                    "label": 0
                },
                {
                    "sent": "So the really option is to write the custom map reduce job.",
                    "label": 0
                },
                {
                    "sent": "Or use something like an external framework like Mahal which can do it for us.",
                    "label": 0
                },
                {
                    "sent": "So really faced one particula.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem where this was interesting, that was stopping modeling.",
                    "label": 0
                },
                {
                    "sent": "So topic modeling is something a lot of people study for a variety of reasons and we also found it useful for our applications.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is like one particular topic.",
                    "label": 0
                },
                {
                    "sent": "Corresponding to GOP or Republican primaries in the states from sometime spring this year, you can recognize a lot of candidate names and politician names here.",
                    "label": 0
                },
                {
                    "sent": "Just to give one example.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the technique we used I wanted to use it's called LDA or latent rich location is beige and soft clustering technique.",
                    "label": 0
                },
                {
                    "sent": "A lot of people like to use for topic modeling.",
                    "label": 0
                },
                {
                    "sent": "And we also like to be able to do this over our data.",
                    "label": 0
                },
                {
                    "sent": "And what do we care?",
                    "label": 0
                },
                {
                    "sent": "Or we care about it because we want to model the interests so want to employ, improve our ability to figure out what things could be good.",
                    "label": 0
                },
                {
                    "sent": "Could be good for recommending to what users.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is how that kind of a problem can be solved.",
                    "label": 0
                },
                {
                    "sent": "So we can still process our data in our pipeline using Pig.",
                    "label": 0
                },
                {
                    "sent": "At some point we have to break this thing altogether.",
                    "label": 0
                },
                {
                    "sent": "Launch another process, in this case Mahal, which is going to compute the whole day model for us using whatever number of iterations needs and then one is done.",
                    "label": 0
                },
                {
                    "sent": "We need to then relaunch our.",
                    "label": 0
                },
                {
                    "sent": "Whatever is left of our of our pipeline pig to finish off the model creation and then maybe apply the model to data so it's not exactly seamless but doable in some special instances like this or perhaps in others like page rank of other cases of problems where we really need to go over everything.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to skip the LD applications because.",
                    "label": 0
                },
                {
                    "sent": "I already mentioned them.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just wanted to add the one thing that people.",
                    "label": 0
                },
                {
                    "sent": "I found interesting in LDA or useful when applying them to data over and over again is to anchor them to specific topics.",
                    "label": 0
                },
                {
                    "sent": "So let's say we recompute the topic model over and over again.",
                    "label": 0
                },
                {
                    "sent": "You lose the ability to.",
                    "label": 0
                },
                {
                    "sent": "To assign clear semantic labels to individual topic groups, unless we do the manual labeling process ourselves or we have a very good way of doing so automatically.",
                    "label": 0
                },
                {
                    "sent": "But typically what is actually more useful is to.",
                    "label": 0
                },
                {
                    "sent": "Maintain some kind of a consistency in the process, so either see those topics with known topics or essentially use the results of previous iterations for the new iterations.",
                    "label": 0
                },
                {
                    "sent": "So I think you get the picture that we.",
                    "label": 0
                },
                {
                    "sent": "We had.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use a lot of open source software and we contribute back to open source, so just wanted to mention a few things we actually actively contributing to Soma.",
                    "label": 0
                },
                {
                    "sent": "How'd I mentioned already?",
                    "label": 0
                },
                {
                    "sent": "We have one over one of our engineers.",
                    "label": 0
                },
                {
                    "sent": "Jake Mannix is A is a one of the committers there.",
                    "label": 0
                },
                {
                    "sent": "We also have a custom graph processing platform which we.",
                    "label": 0
                },
                {
                    "sent": "Recently released to GitHub.",
                    "label": 0
                },
                {
                    "sent": "I also contribute to pick two cascading with Python And Scala and number of other things.",
                    "label": 1
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the talk is about machine learning in Twitter, but there's also a large community of people which do machine learning outside of Twitter.",
                    "label": 0
                },
                {
                    "sent": "I think I'd like to mention that also, and it's interesting to see what people.",
                    "label": 0
                },
                {
                    "sent": "Find as being exciting outside of Twitter.",
                    "label": 1
                },
                {
                    "sent": "So a lot of people do sentiment analysis, sentiment detection.",
                    "label": 0
                },
                {
                    "sent": "People do event tracking, such as disease tracking.",
                    "label": 0
                },
                {
                    "sent": "Natural disaster tracking so so forth people are interested in politics.",
                    "label": 0
                },
                {
                    "sent": "People interested in locality detection, geotagging, so, and so forth.",
                    "label": 0
                },
                {
                    "sent": "And some people interested in his spam detection.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So actually on this last topic.",
                    "label": 0
                },
                {
                    "sent": "Which is actually a topic close to my heart.",
                    "label": 0
                },
                {
                    "sent": "I did a quick search in the number of publications on Twitter spam in Google Scholar not so long ago, and as you can see, although tour is still very very new, the number of publications catches onto the more established times of sound people already published on.",
                    "label": 1
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And on the flip side, if you look at what?",
                    "label": 0
                },
                {
                    "sent": "Other people are publishing about potentially spammer interesting topics, and Amazon there is a fair number of interest.",
                    "label": 0
                },
                {
                    "sent": "Or making money on Twitter in a variety of forms, and none of which are legit.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we apply machine learning other techniques too.",
                    "label": 0
                },
                {
                    "sent": "That I can do is farm.",
                    "label": 0
                },
                {
                    "sent": "What do we actually look at where we actually try to track and I'm sure some people here I gave are going to be complaining to me about queer spam.",
                    "label": 0
                },
                {
                    "sent": "So let me just.",
                    "label": 0
                },
                {
                    "sent": "Describe the broad types of spam we see it or so.",
                    "label": 0
                },
                {
                    "sent": "The first category is the the old replies that mentions so, so this is very much like emails from somebody is going to contact you directly and try to offer you something.",
                    "label": 0
                },
                {
                    "sent": "Probably clicking on the link.",
                    "label": 0
                },
                {
                    "sent": "All.",
                    "label": 0
                },
                {
                    "sent": "We have transparent.",
                    "label": 0
                },
                {
                    "sent": "So people trying to monetize searches very similarly to people trying to monetize web searches.",
                    "label": 0
                },
                {
                    "sent": "And we have follow spam in which spammers are trying to essentially build out their following follower network.",
                    "label": 0
                },
                {
                    "sent": "And then sell it for money or spam to them sometime in the future.",
                    "label": 0
                },
                {
                    "sent": "So if you look at those types of spam that can be classified into long term interest and short-term interest.",
                    "label": 1
                },
                {
                    "sent": "So they follow.",
                    "label": 0
                },
                {
                    "sent": "Spammers are probably long term interest because it takes time to actually build those networks.",
                    "label": 0
                },
                {
                    "sent": "And those guys are very much shorter, so as long as they can monetize things pretty fast.",
                    "label": 0
                },
                {
                    "sent": "It is a quick game for them.",
                    "label": 0
                },
                {
                    "sent": "So the question is like can we actually detect detect interesting patterns of things in Twitter for spam detection and.",
                    "label": 0
                },
                {
                    "sent": "Just to show you a Cup.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All of examples.",
                    "label": 0
                },
                {
                    "sent": "This is probably not very visible here, but.",
                    "label": 0
                },
                {
                    "sent": "What this shows essentially is the patterns of user interaction in terms of other applying.",
                    "label": 0
                },
                {
                    "sent": "For regular pre users and.",
                    "label": 0
                },
                {
                    "sent": "You probably don't see those kind of connections here, but what is interesting here is that a lot of normal users.",
                    "label": 0
                },
                {
                    "sent": "Quote unquote in Twitter, communicate primarily locally so people have friends.",
                    "label": 0
                },
                {
                    "sent": "People they follow in more or less the same geographical location.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at the patterns of spam, which infinitely are not all visible here, but we should be seeing here is that there's a lot of long-term collections.",
                    "label": 0
                },
                {
                    "sent": "Coming from various places.",
                    "label": 0
                },
                {
                    "sent": "And not so many connections corresponding to people living in the same area.",
                    "label": 0
                },
                {
                    "sent": "So those are ad mentions essentially corresponding to spam interactions.",
                    "label": 0
                },
                {
                    "sent": "So there's definitely data related to the interaction and the network, which is very meaningful for detecting spam.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Just to run.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up up, I really wanted to give credit to a lot of people which worked.",
                    "label": 0
                },
                {
                    "sent": "We're on building out infrastructure and from various size bubble in the core machine learning and building pipelines, and think feature extraction so it's not giving credit to all of them, but those colleagues of mine that primary creators of the system and.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That I wanted to end and ask you for questions.",
                    "label": 0
                },
                {
                    "sent": "So you made an interesting comment when you talked about what the definition of big data is and the definition was something like.",
                    "label": 0
                },
                {
                    "sent": "If you have to have a data warehouse, then it's big data.",
                    "label": 0
                },
                {
                    "sent": "And then my question is, can researchers like us who don't happen to have data warehouses lying around actually ever do research on big data?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I think so.",
                    "label": 0
                },
                {
                    "sent": "I mean, the interesting thing about the big data is that.",
                    "label": 0
                },
                {
                    "sent": "When you analyze various problems, you very rarely need all of the data at the same time.",
                    "label": 0
                },
                {
                    "sent": "So if I say that we need the data warehouse to process the data, it means that all of the components of the surveys needed, but each of the components you know touches perhaps only a fraction of this data.",
                    "label": 0
                },
                {
                    "sent": "So from the research perspective, you can definitely look at large data repositories, but you know maybe which fit on, not in the data center.",
                    "label": 0
                },
                {
                    "sent": "Can you maybe talk about how you did the recommendations for The Who to follow?",
                    "label": 0
                },
                {
                    "sent": "Task because this is doesn't really fit in what you said so far.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can do it with the methods you just mentioned, but maybe there are better ones for doing that more suitable.",
                    "label": 0
                },
                {
                    "sent": "Well, I cannot give you like all the details on how it works.",
                    "label": 0
                },
                {
                    "sent": "But you know who to follow is a problem involving essentially recommendation of a graph.",
                    "label": 0
                },
                {
                    "sent": "So you might say that there are variety of of relevance propagation on the graph, which don't necessarily require machine learning.",
                    "label": 0
                },
                {
                    "sent": "But I'm just going to say that if you take the same signals which you can build, you know heuristically or via some formulas and use them in features in the machine learning process where you have labels from user interactions.",
                    "label": 0
                },
                {
                    "sent": "You can probably improve on this quite a bit.",
                    "label": 0
                },
                {
                    "sent": "So hopefully that kind of answers the question.",
                    "label": 0
                },
                {
                    "sent": "Do you have indicators of how this is impacting in Twitter users?",
                    "label": 0
                },
                {
                    "sent": "How is it impacting on Twitter scissors?",
                    "label": 0
                },
                {
                    "sent": "I mean how they're perceiving the benefit of these different techniques and the.",
                    "label": 0
                },
                {
                    "sent": "In the daily use of two.",
                    "label": 0
                },
                {
                    "sent": "Well, sure, I mean I cannot tell you well it's improving by X percent, But definitely for everything we do, we try to measure the impact and essentially use it only if it proves useful.",
                    "label": 0
                },
                {
                    "sent": "So the whole the whole premise is not not to build machine learning for its own right.",
                    "label": 0
                },
                {
                    "sent": "Just because we can, but you know that's actually improve.",
                    "label": 0
                },
                {
                    "sent": "Our metrics are people more happy with the content or engaging more?",
                    "label": 0
                },
                {
                    "sent": "Are they interacting more?",
                    "label": 0
                },
                {
                    "sent": "Essentially all those measures are applied to figure out what methods are useful and what methods should be retained, or which ones should be scrapped.",
                    "label": 0
                },
                {
                    "sent": "So we have sort of similar questions with the training topics you have global training topics.",
                    "label": 0
                },
                {
                    "sent": "You have local training topics.",
                    "label": 0
                },
                {
                    "sent": "I've been debating questions and how you compute those training topics is clearly a mixture between freshness of the new hashtag and whether you can analyze recurring trending topics.",
                    "label": 0
                },
                {
                    "sent": "And if you do something with this sort of question.",
                    "label": 0
                },
                {
                    "sent": "Well, it's a good question with which.",
                    "label": 0
                },
                {
                    "sent": "Again, I've I can only provide a vague answer.",
                    "label": 0
                },
                {
                    "sent": "So training topic is clearly like an important thing that people like to see on Twitter.",
                    "label": 0
                },
                {
                    "sent": "And I can say there is a number of competing models which are being evaluated and it's really very much work in progress, so we try to improve.",
                    "label": 0
                },
                {
                    "sent": "What is the trending topic?",
                    "label": 0
                },
                {
                    "sent": "Is the definition an how they are personalizing of visibly different users?",
                    "label": 0
                },
                {
                    "sent": "But unfortunately I can't really tell you.",
                    "label": 0
                },
                {
                    "sent": "OK, this is exactly how we do it.",
                    "label": 0
                },
                {
                    "sent": "OK, so I understand that of course it's not possible like see the details on a lot of these techniques.",
                    "label": 0
                },
                {
                    "sent": "I was wondering if it would be possible for lack organization like Twitter, but we could ask the same question to the Google just today.",
                    "label": 0
                },
                {
                    "sent": "Is there if there's kind of a mean half at least share like the way these techniques are evaluated and kind of evaluation set?",
                    "label": 0
                },
                {
                    "sent": "Or if these brings in some problem because just showing like the the data set that are used to evaluate this techniques is the kind of way to reveal also how the techniques work.",
                    "label": 0
                },
                {
                    "sent": "Well, it's a good question and I think evaluation itself is a fairly big problem for a lot of things in Twitter, because as I mentioned before, because of the real time aspect of a lot of things.",
                    "label": 0
                },
                {
                    "sent": "So to the extent that you can have static data set which actually tells you K is this method performing better than others, it's actually pretty difficult without doing like a proper AB test and doing a live test.",
                    "label": 0
                },
                {
                    "sent": "So that is really the crux of the problem that they really figure out if something is.",
                    "label": 0
                },
                {
                    "sent": "Is better than something else you really need to do a real user study on the life system.",
                    "label": 0
                },
                {
                    "sent": "To show if your your metrics in terms of user.",
                    "label": 0
                },
                {
                    "sent": "Satisfaction of the data are better or not.",
                    "label": 0
                },
                {
                    "sent": "So publishing a static set probably would not be very useful.",
                    "label": 0
                },
                {
                    "sent": "I have a question on the topic computation.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning of the talk you started saying that well, sometimes simpler classifiers perform extremely well on certain tasks, right?",
                    "label": 0
                },
                {
                    "sent": "Then I was puzzled to see I mean LDA on your slides becausw.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is a relatively complex and computationally demanding.",
                    "label": 0
                },
                {
                    "sent": "Model, you know compared to something as simple as I know, K means clustering to find to mind the topic.",
                    "label": 0
                },
                {
                    "sent": "So do you have evidence that you're finding better topics using?",
                    "label": 0
                },
                {
                    "sent": "Something relatively complex is a compared to simpler approaches to find topics.",
                    "label": 0
                },
                {
                    "sent": "Well, it's it's a very good question, so to some extent the LDA in this case is an exception to the rule.",
                    "label": 0
                },
                {
                    "sent": "So the vast majority, the vast majority of models were trying to use as I described, the actually quite simple and follow the online learning paradigm.",
                    "label": 0
                },
                {
                    "sent": "The topics are, I mean, the way we actually implemented LDNY was really to do large scale.",
                    "label": 0
                },
                {
                    "sent": "Study internally, to the extent that we work, very or not.",
                    "label": 0
                },
                {
                    "sent": "Anne at this point is still a study in progress, so we found it interesting enough to try it to see if they perform better.",
                    "label": 0
                },
                {
                    "sent": "But as far as I can say, the jury is still out.",
                    "label": 0
                },
                {
                    "sent": "The jury is still out.",
                    "label": 0
                },
                {
                    "sent": "Yes, my question is regarding the number of topics that you are defining in the LDA model.",
                    "label": 0
                },
                {
                    "sent": "How do you get that number?",
                    "label": 0
                },
                {
                    "sent": "So we essentially do well.",
                    "label": 0
                },
                {
                    "sent": "You would want to do.",
                    "label": 0
                },
                {
                    "sent": "We tried different numbers mean there is.",
                    "label": 0
                },
                {
                    "sent": "We have some, of course a priority information about other techniques which we use for simple tasks from which we can derive the likely number of topics.",
                    "label": 0
                },
                {
                    "sent": "But really answer the question.",
                    "label": 0
                },
                {
                    "sent": "OK, is the prior actually a good prior failed EA?",
                    "label": 0
                },
                {
                    "sent": "There is a little basis for saying so, so really kind of expand the number or contract the number of topics to see which which combination actually is better.",
                    "label": 0
                },
                {
                    "sent": "So it's like a data driven approach if you like.",
                    "label": 0
                },
                {
                    "sent": "Let's see if you would have a chance to re decide.",
                    "label": 0
                },
                {
                    "sent": "Which platform to choose?",
                    "label": 0
                },
                {
                    "sent": "Would you do something else nowadays or how?",
                    "label": 0
                },
                {
                    "sent": "It's a good question, I think at this point there is a lot of upcoming experimental technologies which some of them may be offering.",
                    "label": 0
                },
                {
                    "sent": "You know better processing capabilities in the future or or.",
                    "label": 0
                },
                {
                    "sent": "Essentially, more processing in memory, less of touching the source so forth.",
                    "label": 0
                },
                {
                    "sent": "But the advantage, even today of something like dope, is the maturity.",
                    "label": 0
                },
                {
                    "sent": "So in terms of doing things for a fairly large amount of data, such as it were, you have to think about performance and also maturity of the technology and the tools around it.",
                    "label": 0
                },
                {
                    "sent": "So even today, probably it will be the right choice, although I'm not a Hindu backspin myself so I cannot say this is a definitive answer, but that's what I think.",
                    "label": 0
                },
                {
                    "sent": "What about a framework that is built for large graphs, such as something like Pregel or the other graph based systems?",
                    "label": 0
                },
                {
                    "sent": "It's a good question so.",
                    "label": 0
                },
                {
                    "sent": "So our graph processing actually predates Pregel, and if you remember from one of the slides I mentioned cassowary, which is our custom graph structure, which is open source and we have internally kind of new generation of this platform that we use internally.",
                    "label": 0
                },
                {
                    "sent": "So for pure graph processing, which we have something which is essentially specially suited for that.",
                    "label": 0
                },
                {
                    "sent": "But I mean Pregel and the giraffe and other things are actually quite relevant, and if we didn't have anything already, would probably look at using them.",
                    "label": 0
                },
                {
                    "sent": "So I have another question, so there's another thing you didn't much talk about, but you couldn't talk about everything in the Twitter ecosystems.",
                    "label": 0
                },
                {
                    "sent": "There is also all the things that concerns media that you attach new to it.",
                    "label": 0
                },
                {
                    "sent": "So Twitpic, Twitvid and all this stuff on Twitter now you start seeing when we search for topics.",
                    "label": 0
                },
                {
                    "sent": "So events Major Gary generated.",
                    "label": 0
                },
                {
                    "sent": "Sometimes we've even duplicates removed, and so on.",
                    "label": 0
                },
                {
                    "sent": "So what type of machine learning?",
                    "label": 0
                },
                {
                    "sent": "Again, I'm going to apply on this and what are your plans on on media attached to tweets.",
                    "label": 0
                },
                {
                    "sent": "Well, I think we we plan to.",
                    "label": 0
                },
                {
                    "sent": "To use more of it because people interact with media quite a lot and media is interesting.",
                    "label": 0
                },
                {
                    "sent": "As far as I know, the amount of machine learning actually in the current.",
                    "label": 0
                },
                {
                    "sent": "Product the stuff you see is not that high and this is something we are trying to expand it to.",
                    "label": 0
                },
                {
                    "sent": "Could it be a good idea to include information from the list in Twitter in the topic the detection algorithm?",
                    "label": 0
                },
                {
                    "sent": "It probably probably would be a good idea about the topic, so if we talk about topics the topics can be understood in many different ways, so the topics I showed in the graphs where topics detected from the tweets themselves, the list information thank you also refer to your own paper actually on this.",
                    "label": 0
                },
                {
                    "sent": "The list I used by other users in the form of tagging what the users who those users are.",
                    "label": 0
                },
                {
                    "sent": "So it's an alternative way of classifying users, but essentially it's not a guarantee.",
                    "label": 0
                },
                {
                    "sent": "I mean, there's there's.",
                    "label": 0
                },
                {
                    "sent": "There's a correspondence between what the user is is tagged with and what the user is tweeting about.",
                    "label": 0
                },
                {
                    "sent": "Although the guarantee is kind of vague, so even if I use the list data too.",
                    "label": 0
                },
                {
                    "sent": "Aid in the detection of topics I probably need to look at the text itself.",
                    "label": 0
                },
                {
                    "sent": "Actually have some very confident about those topics.",
                    "label": 0
                },
                {
                    "sent": "OK, I guess we exhausted questions like Thanks Alec will be around I guess today.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'll be around if you have more questions.",
                    "label": 0
                },
                {
                    "sent": "So just grab me.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the secret parameters.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks again.",
                    "label": 0
                },
                {
                    "sent": "Well thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}