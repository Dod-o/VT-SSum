{
    "id": "lmu2fl327riktwr55j2quygkvx7fqcht",
    "title": "Mining Diverse Views from Related Articles",
    "info": {
        "author": [
            "Ravali Pochampally, International Institute of Information Technology Hyderabad"
        ],
        "published": "April 22, 2011",
        "recorded": "March 2011",
        "category": [
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/diversiweb2011_pochampally_mdv/",
    "segmentation": [
        [
            "Good afternoon everyone.",
            "I'm traveling from AAA T Hyderabad and this is joint work with my advisor Professor, Carla Polym."
        ],
        [
            "I'll give a little bit of background.",
            "We all know that there is a problem of information overload on the web.",
            "Oh, there is diverse content and almost on any major topic.",
            "You can find hundreds of articles, even authoritative sources like Google News and Amazon, which generally organized content into clusters of related news articles or user reviews.",
            "According to numerical ratings or categories like loved it or hated it.",
            "Present too much text in a category which makes it difficult for the end user to Prof."
        ],
        [
            "Is it?",
            "Summarization is one of the popular techniques to deal with this problem of information overload.",
            "We know that summarization condenses information by presenting the salient points in a group of related articles.",
            "The length is usually inversely related to the content presented by it, and we can often.",
            "Control the length of the summary by certain user specified parameters.",
            "But the main drawbacks of summarization is that it lacks organization.",
            "It does not model the diversity in a content.",
            "By delineating all the issues present in it.",
            "And sometimes if you want to look at all the important point addressed by a group of related articles, the length of the summary can get too long."
        ],
        [
            "We wanted to take a alternate view, 2 summarization by developing an IR model which can mind diverse views from a group of related articles.",
            "So what is a view?",
            "Of user something which intends to represent the issue from a group of related articles by related articles I mean articles concerning a common topic, such as FIFA 2010, etc.",
            "So issue is something which is very specific to a set of related articles.",
            "Like let's say we take a topic such as swine flu in India, an issue can be the list of cities affected by it, number of casualties or the precautionary measures that we can take two or curb swine flu.",
            "So by providing multiple views, we organize the content of a group of related articles and each view has a link to the particular of each sentence.",
            "Interview has a link to the particular source document containing it, so we can facilitate information exploration by this way.",
            "And as we address all the diverse issue yet organized them in effect, we are presenting a detailed snapshot of the group of related articles.",
            "So in the footnote you can see the site which has the comparison between the use and summary and I'll get to that in the coming slides.",
            "A summary is just a chunk of checks text which doesn't have any organization whatsoever, but the views.",
            "Pretend to review data set.",
            "Tell us about the positive aspects of that hotel.",
            "Negative about the food in the hotel and it's our joining restraints level facilities."
        ],
        [
            "So this is an example view generated for reviews of Hotel Taj Krishna which is in hotel in Hyderabad.",
            "If you read the first one, you will see that it talks about the positive attributes of that particular hotel.",
            "The second one is a little bit negative in tone.",
            "Third, one talks about food and the 4th one saying that OK, towels are not good in effect talking about the facilities.",
            "But the numbers in the curly brackets are the IDs of the source documents from which the sentence is taken.",
            "So for user wants to explore that particular document, he can go to, probably.",
            "Document ID 11 from which the first sentence is."
        ],
        [
            "Taken.",
            "So this is the example.",
            "Somebody using a compression ratio of 30.",
            "As you can see, it's pretty long.",
            "I think a big in a lengthy example, but you get the general idea that it is little bit unorganized and if you look at the last two sentences it is saying that Taj Krishna is a masterpiece and there is no limo service, in effect giving a very contradictory picture and not organizing it into positive negative or something like that.",
            "How we do?",
            "I used a baseline algorithm which was developed by someone else.",
            "I think you can find it in the references in my paper."
        ],
        [
            "So this is outline of the talk.",
            "I'll first discuss the related work and address.",
            "The problem that we're trying to solve.",
            "I'll talk about extraction of user.",
            "The focus on ranking and we'll get to results in the discussion."
        ],
        [
            "So in the related work, Allison at all first address the idea of multiple viewpoints and developed a framework whereby they developed viewpoints with a supervised approach by analyzing the text of the documents and manually annotated subject indicators.",
            "It's also query focused approach in which they facilitate information exploration by giving multiple viewpoints.",
            "Tom Rosenthal proposed the idea of clustering of top ranking sentences and proposed it as an effective alternate to document some document clustering.",
            "Text telling is a popular technique developed by Amherst, which divides text into multi paragraph units in each paragraph.",
            "Unit represents a subtopic.",
            "What they do is this core.",
            "Each multi paragraph unit and applaud the units according to the scores degrade and the sub topics are found in the valleys in that particular class."
        ],
        [
            "So there's no problem.",
            "We start with a set of related articles and get her main problem of mining diverse use and output a ranked list of views.",
            "So in effect the black box is a main problem that we're trying to address."
        ],
        [
            "So these are the datasets that we used.",
            "Or you can find the datasets in the site mentioned footnote.",
            "All data set ID one is taken from Google News using the search term financial meltdown and has 49 articles.",
            "You can extend the reasoning to other data."
        ],
        [
            "So we use sources such as Google News, Amazon in Trip Adviser because we found that these sources do not group particles strictly according to the semantic similarity, but group particles which are roughly discussing the same topic.",
            "We crawled using Java Java crawler and we passed using analytical library in Python.",
            "We passed our ticket streaming RSS data.",
            "Sunday cleaning tasks such as the stopper symbol, stemming and duplicate detection will perform use cosine similarity for duplicate detection.",
            "We collected the basic statistiques such as word frequency and DF IDF at this stage."
        ],
        [
            "So the idea was to extract important sentences from the collection from which we can form views.",
            "So for this we scored each sentence in the collection by assigning a measure called importance.",
            "So we define importance of a sentence belonging to a particular article as follows.",
            "It's nothing but the product with TF IDF with the constant words in that particular sentence sentence normalized by the length of that sentence."
        ],
        [
            "So we score sentences in the nonincreasing order of their important scores and select the top and sentences from them for analysis.",
            "So after extracting sentences we need a measure of similarity in order to extract views from them.",
            "There are two important the similarity measures use.",
            "One is lexical matching, another semantic similarity.",
            "But lexical matching assigns a score a bit for two sentences based on the number of overlapping lexical entities, and may not score well for two sentences which which are expressing the same opinion by using different lexical entities such as words.",
            "So semantic similarity, which calculates the lightness of meaning irrespective of the words used, scores well, so we use that for our analysis.",
            "May I see I tell it all proposed that the specificity of a word can be determined by its IDF.",
            "IDF is nothing but inverse document frequency, which is the inverse of the log frequency for particular word.",
            "It indicates how specific is avert a particular document and the score of a word which occurs frequently throughout the corpus is low.",
            "So we use word to word similarity and specificity to calculate the semantic similarity between the."
        ],
        [
            "Two sentences.",
            "So, semantic similarity between a sentence one and sentence two is calculated as follows, or for each word in a sentence one we take the world which has the maximum similarity in sentence two in multiply it with the idea of IDF of that particular word, and we repeat the same process for sentence two and take a numerical average of both the measures.",
            "As you can see, this is a symmetric relationship and has a range of 0 to one with zero indicating sentences which have no semantic overlap and one indicating identically matching segments.",
            "Sorry.",
            "Map.",
            "See if the same word is present of.",
            "You'll get a match of 1 if a closely related word is present.",
            "It will obviously be less than one, and if the words are unrelated to 0, but anyway in any way, we are taking the maximum similarity, so it's maximum of every value form.",
            "So if the same word is that it will probably be fun.",
            "Oh, there's a big variable here that is maximum similarity of a word with any word in the other sentence.",
            "So we use word net for this, which is nothing metal.",
            "Set of cognitive synonyms, or since it's we used Bob, you can refer to the paper.",
            "Of you swap it because it's based on the Portland between sets of words and performs one of the top performance while calculating semantic similarity."
        ],
        [
            "After finding out the semantic similarity between any two sentences, we want to cluster them in order to group the views which are discussing similar content.",
            "We used hierarchical agglomerative clustering or HSE for this because it does not start with an assumption about the number of clusters and we can terminate clustering when the scoring parameter converges in order, in effect obtaining the best possible clustering.",
            "As the previous search similarity measure was a symmetric views upper triangular as an input to the HSE algorithm.",
            "These clusters are grouping sentences which are dealing with similar content or a specific issue and we treat them as views discussing similar can't."
        ],
        [
            "Ain't so while ranking of these views.",
            "We wanted to give importance to views which are drawing of grouping similar content or which have maximum average pairwise similarity between the particular sentences.",
            "So we define the measure called cohesion, which aggregates the pairwise similarity between the sentences in a room and normalizes with the length of the truth is nothing but the number of sentences in it."
        ],
        [
            "So after Rook ordering the views according to their cohesion, we define something called the most relevant view, which is top ranked.",
            "You ask for analysis.",
            "An outlier views are something which consists of only a single sentence.",
            "Because the semantic similarity with others is slow to load.",
            "Have any meaningful grouping and as their pairwise similarity or cohesion is zero, we order them according to their importance values."
        ],
        [
            "So this is a visual representation of our framework or we start with related articles, social history, melon text, and do the standard IR cleaning to get the raw text and extract the top ranking Top Rank sentences and out in put them to the clustering engine which then gives us views.",
            "We rank them according to the measure cohesion proposed by us and we output a rank list of use.",
            "Also the most relevant viewer in the outlier view.",
            "Is it like that goods means after some single for that reason?",
            "This.",
            "Are you saying that the article do it?",
            "Maybe if you put install it and it wasn't easy to program, so you put this radar for yeah?",
            "No, each analysis is performed on a set of articles related to a single topic, but they were host of such topics, so different sets of audience."
        ],
        [
            "View is a sentence or a group of sentences which are discussing the similar content or issues addressed by group of related articles.",
            "Cannot be apart of sentence.",
            "No, it is that it has all the members are complete sentences, no, not phrases.",
            "Well, actually we used organizers so whatever it determines as a sentence, we are using them.",
            "You are getting stop words in the sentence.",
            "Copy eliminate stop words for our analysis.",
            "But while outputing, we give the complete silence.",
            "So we want to correlate the number of top ranking sentence is N versus the cohesion value obtained by us.",
            "So we need to select the value of N which can maximize cohesion.",
            "Ideally we want the median collision to be greater than equal to the mean, because mean is often prone to outliers.",
            "So we found it for the value of N between 20 and 35.",
            "About to crack criteria were satisfied, we use incremental clustering for our analysis or that is.",
            "Let me start with the lower bound of 1st sentences like let's say 20 and incrementally Arctic sentences to obtain to get to upper bound like let's say 35 and we calculate the overall cohesion of the views an output views which give the best question.",
            "So by our analysis, we found that more top ending sentences need not necessarily lead to views with better cohesion."
        ],
        [
            "These are some numbers of correlating a particular data set with the number of four top ranking sentences yielding the best cohesion.",
            "And the second table is correlating each data set with the mean number of sentences per each view and the mean number of fuse for that data set.",
            "As you can see, the values are most of the values are less than or equal to five.",
            "Keeping our representation concise."
        ],
        [
            "So to conclude and say that we wanted to develop an IR model which was an alternate to summarization by providing multiple diverse use and organizing the content but making it easily navigable will help a busy viewer who can browser topics fuse?",
            "Or or just look at the most relevant you rather than somebody where you're confused us to read the first 10 sentences or the last 10 or something like that.",
            "Up we are clustering in a sentence or phrase level or as opposed to document clustering, which is looping sentences disk.",
            "Sorry, grouping documents discussing a common topic.",
            "Play in future we want to mind the polarity of a view that is positive, negative or neutral by using resources like centive, ordnet etc.",
            "We wanted to collect user feedback and that can rate these views.",
            "Implicit feedback that is clicks and time spent on a particular view or explicit in terms of user ratings and all.",
            "So that."
        ],
        [
            "Any questions?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon everyone.",
                    "label": 0
                },
                {
                    "sent": "I'm traveling from AAA T Hyderabad and this is joint work with my advisor Professor, Carla Polym.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll give a little bit of background.",
                    "label": 0
                },
                {
                    "sent": "We all know that there is a problem of information overload on the web.",
                    "label": 0
                },
                {
                    "sent": "Oh, there is diverse content and almost on any major topic.",
                    "label": 1
                },
                {
                    "sent": "You can find hundreds of articles, even authoritative sources like Google News and Amazon, which generally organized content into clusters of related news articles or user reviews.",
                    "label": 0
                },
                {
                    "sent": "According to numerical ratings or categories like loved it or hated it.",
                    "label": 0
                },
                {
                    "sent": "Present too much text in a category which makes it difficult for the end user to Prof.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "Summarization is one of the popular techniques to deal with this problem of information overload.",
                    "label": 0
                },
                {
                    "sent": "We know that summarization condenses information by presenting the salient points in a group of related articles.",
                    "label": 1
                },
                {
                    "sent": "The length is usually inversely related to the content presented by it, and we can often.",
                    "label": 0
                },
                {
                    "sent": "Control the length of the summary by certain user specified parameters.",
                    "label": 1
                },
                {
                    "sent": "But the main drawbacks of summarization is that it lacks organization.",
                    "label": 0
                },
                {
                    "sent": "It does not model the diversity in a content.",
                    "label": 0
                },
                {
                    "sent": "By delineating all the issues present in it.",
                    "label": 0
                },
                {
                    "sent": "And sometimes if you want to look at all the important point addressed by a group of related articles, the length of the summary can get too long.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We wanted to take a alternate view, 2 summarization by developing an IR model which can mind diverse views from a group of related articles.",
                    "label": 0
                },
                {
                    "sent": "So what is a view?",
                    "label": 1
                },
                {
                    "sent": "Of user something which intends to represent the issue from a group of related articles by related articles I mean articles concerning a common topic, such as FIFA 2010, etc.",
                    "label": 1
                },
                {
                    "sent": "So issue is something which is very specific to a set of related articles.",
                    "label": 0
                },
                {
                    "sent": "Like let's say we take a topic such as swine flu in India, an issue can be the list of cities affected by it, number of casualties or the precautionary measures that we can take two or curb swine flu.",
                    "label": 0
                },
                {
                    "sent": "So by providing multiple views, we organize the content of a group of related articles and each view has a link to the particular of each sentence.",
                    "label": 0
                },
                {
                    "sent": "Interview has a link to the particular source document containing it, so we can facilitate information exploration by this way.",
                    "label": 0
                },
                {
                    "sent": "And as we address all the diverse issue yet organized them in effect, we are presenting a detailed snapshot of the group of related articles.",
                    "label": 0
                },
                {
                    "sent": "So in the footnote you can see the site which has the comparison between the use and summary and I'll get to that in the coming slides.",
                    "label": 0
                },
                {
                    "sent": "A summary is just a chunk of checks text which doesn't have any organization whatsoever, but the views.",
                    "label": 0
                },
                {
                    "sent": "Pretend to review data set.",
                    "label": 0
                },
                {
                    "sent": "Tell us about the positive aspects of that hotel.",
                    "label": 0
                },
                {
                    "sent": "Negative about the food in the hotel and it's our joining restraints level facilities.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example view generated for reviews of Hotel Taj Krishna which is in hotel in Hyderabad.",
                    "label": 0
                },
                {
                    "sent": "If you read the first one, you will see that it talks about the positive attributes of that particular hotel.",
                    "label": 0
                },
                {
                    "sent": "The second one is a little bit negative in tone.",
                    "label": 0
                },
                {
                    "sent": "Third, one talks about food and the 4th one saying that OK, towels are not good in effect talking about the facilities.",
                    "label": 0
                },
                {
                    "sent": "But the numbers in the curly brackets are the IDs of the source documents from which the sentence is taken.",
                    "label": 0
                },
                {
                    "sent": "So for user wants to explore that particular document, he can go to, probably.",
                    "label": 0
                },
                {
                    "sent": "Document ID 11 from which the first sentence is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Taken.",
                    "label": 0
                },
                {
                    "sent": "So this is the example.",
                    "label": 0
                },
                {
                    "sent": "Somebody using a compression ratio of 30.",
                    "label": 0
                },
                {
                    "sent": "As you can see, it's pretty long.",
                    "label": 0
                },
                {
                    "sent": "I think a big in a lengthy example, but you get the general idea that it is little bit unorganized and if you look at the last two sentences it is saying that Taj Krishna is a masterpiece and there is no limo service, in effect giving a very contradictory picture and not organizing it into positive negative or something like that.",
                    "label": 0
                },
                {
                    "sent": "How we do?",
                    "label": 0
                },
                {
                    "sent": "I used a baseline algorithm which was developed by someone else.",
                    "label": 0
                },
                {
                    "sent": "I think you can find it in the references in my paper.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is outline of the talk.",
                    "label": 0
                },
                {
                    "sent": "I'll first discuss the related work and address.",
                    "label": 1
                },
                {
                    "sent": "The problem that we're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about extraction of user.",
                    "label": 1
                },
                {
                    "sent": "The focus on ranking and we'll get to results in the discussion.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the related work, Allison at all first address the idea of multiple viewpoints and developed a framework whereby they developed viewpoints with a supervised approach by analyzing the text of the documents and manually annotated subject indicators.",
                    "label": 1
                },
                {
                    "sent": "It's also query focused approach in which they facilitate information exploration by giving multiple viewpoints.",
                    "label": 0
                },
                {
                    "sent": "Tom Rosenthal proposed the idea of clustering of top ranking sentences and proposed it as an effective alternate to document some document clustering.",
                    "label": 1
                },
                {
                    "sent": "Text telling is a popular technique developed by Amherst, which divides text into multi paragraph units in each paragraph.",
                    "label": 0
                },
                {
                    "sent": "Unit represents a subtopic.",
                    "label": 0
                },
                {
                    "sent": "What they do is this core.",
                    "label": 0
                },
                {
                    "sent": "Each multi paragraph unit and applaud the units according to the scores degrade and the sub topics are found in the valleys in that particular class.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's no problem.",
                    "label": 0
                },
                {
                    "sent": "We start with a set of related articles and get her main problem of mining diverse use and output a ranked list of views.",
                    "label": 1
                },
                {
                    "sent": "So in effect the black box is a main problem that we're trying to address.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are the datasets that we used.",
                    "label": 0
                },
                {
                    "sent": "Or you can find the datasets in the site mentioned footnote.",
                    "label": 0
                },
                {
                    "sent": "All data set ID one is taken from Google News using the search term financial meltdown and has 49 articles.",
                    "label": 0
                },
                {
                    "sent": "You can extend the reasoning to other data.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we use sources such as Google News, Amazon in Trip Adviser because we found that these sources do not group particles strictly according to the semantic similarity, but group particles which are roughly discussing the same topic.",
                    "label": 0
                },
                {
                    "sent": "We crawled using Java Java crawler and we passed using analytical library in Python.",
                    "label": 0
                },
                {
                    "sent": "We passed our ticket streaming RSS data.",
                    "label": 1
                },
                {
                    "sent": "Sunday cleaning tasks such as the stopper symbol, stemming and duplicate detection will perform use cosine similarity for duplicate detection.",
                    "label": 0
                },
                {
                    "sent": "We collected the basic statistiques such as word frequency and DF IDF at this stage.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea was to extract important sentences from the collection from which we can form views.",
                    "label": 0
                },
                {
                    "sent": "So for this we scored each sentence in the collection by assigning a measure called importance.",
                    "label": 1
                },
                {
                    "sent": "So we define importance of a sentence belonging to a particular article as follows.",
                    "label": 1
                },
                {
                    "sent": "It's nothing but the product with TF IDF with the constant words in that particular sentence sentence normalized by the length of that sentence.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we score sentences in the nonincreasing order of their important scores and select the top and sentences from them for analysis.",
                    "label": 0
                },
                {
                    "sent": "So after extracting sentences we need a measure of similarity in order to extract views from them.",
                    "label": 1
                },
                {
                    "sent": "There are two important the similarity measures use.",
                    "label": 0
                },
                {
                    "sent": "One is lexical matching, another semantic similarity.",
                    "label": 0
                },
                {
                    "sent": "But lexical matching assigns a score a bit for two sentences based on the number of overlapping lexical entities, and may not score well for two sentences which which are expressing the same opinion by using different lexical entities such as words.",
                    "label": 0
                },
                {
                    "sent": "So semantic similarity, which calculates the lightness of meaning irrespective of the words used, scores well, so we use that for our analysis.",
                    "label": 0
                },
                {
                    "sent": "May I see I tell it all proposed that the specificity of a word can be determined by its IDF.",
                    "label": 1
                },
                {
                    "sent": "IDF is nothing but inverse document frequency, which is the inverse of the log frequency for particular word.",
                    "label": 1
                },
                {
                    "sent": "It indicates how specific is avert a particular document and the score of a word which occurs frequently throughout the corpus is low.",
                    "label": 0
                },
                {
                    "sent": "So we use word to word similarity and specificity to calculate the semantic similarity between the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two sentences.",
                    "label": 0
                },
                {
                    "sent": "So, semantic similarity between a sentence one and sentence two is calculated as follows, or for each word in a sentence one we take the world which has the maximum similarity in sentence two in multiply it with the idea of IDF of that particular word, and we repeat the same process for sentence two and take a numerical average of both the measures.",
                    "label": 1
                },
                {
                    "sent": "As you can see, this is a symmetric relationship and has a range of 0 to one with zero indicating sentences which have no semantic overlap and one indicating identically matching segments.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Map.",
                    "label": 0
                },
                {
                    "sent": "See if the same word is present of.",
                    "label": 0
                },
                {
                    "sent": "You'll get a match of 1 if a closely related word is present.",
                    "label": 0
                },
                {
                    "sent": "It will obviously be less than one, and if the words are unrelated to 0, but anyway in any way, we are taking the maximum similarity, so it's maximum of every value form.",
                    "label": 0
                },
                {
                    "sent": "So if the same word is that it will probably be fun.",
                    "label": 0
                },
                {
                    "sent": "Oh, there's a big variable here that is maximum similarity of a word with any word in the other sentence.",
                    "label": 0
                },
                {
                    "sent": "So we use word net for this, which is nothing metal.",
                    "label": 1
                },
                {
                    "sent": "Set of cognitive synonyms, or since it's we used Bob, you can refer to the paper.",
                    "label": 0
                },
                {
                    "sent": "Of you swap it because it's based on the Portland between sets of words and performs one of the top performance while calculating semantic similarity.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After finding out the semantic similarity between any two sentences, we want to cluster them in order to group the views which are discussing similar content.",
                    "label": 0
                },
                {
                    "sent": "We used hierarchical agglomerative clustering or HSE for this because it does not start with an assumption about the number of clusters and we can terminate clustering when the scoring parameter converges in order, in effect obtaining the best possible clustering.",
                    "label": 1
                },
                {
                    "sent": "As the previous search similarity measure was a symmetric views upper triangular as an input to the HSE algorithm.",
                    "label": 1
                },
                {
                    "sent": "These clusters are grouping sentences which are dealing with similar content or a specific issue and we treat them as views discussing similar can't.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ain't so while ranking of these views.",
                    "label": 0
                },
                {
                    "sent": "We wanted to give importance to views which are drawing of grouping similar content or which have maximum average pairwise similarity between the particular sentences.",
                    "label": 0
                },
                {
                    "sent": "So we define the measure called cohesion, which aggregates the pairwise similarity between the sentences in a room and normalizes with the length of the truth is nothing but the number of sentences in it.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So after Rook ordering the views according to their cohesion, we define something called the most relevant view, which is top ranked.",
                    "label": 1
                },
                {
                    "sent": "You ask for analysis.",
                    "label": 1
                },
                {
                    "sent": "An outlier views are something which consists of only a single sentence.",
                    "label": 0
                },
                {
                    "sent": "Because the semantic similarity with others is slow to load.",
                    "label": 1
                },
                {
                    "sent": "Have any meaningful grouping and as their pairwise similarity or cohesion is zero, we order them according to their importance values.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a visual representation of our framework or we start with related articles, social history, melon text, and do the standard IR cleaning to get the raw text and extract the top ranking Top Rank sentences and out in put them to the clustering engine which then gives us views.",
                    "label": 1
                },
                {
                    "sent": "We rank them according to the measure cohesion proposed by us and we output a rank list of use.",
                    "label": 0
                },
                {
                    "sent": "Also the most relevant viewer in the outlier view.",
                    "label": 0
                },
                {
                    "sent": "Is it like that goods means after some single for that reason?",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Are you saying that the article do it?",
                    "label": 0
                },
                {
                    "sent": "Maybe if you put install it and it wasn't easy to program, so you put this radar for yeah?",
                    "label": 0
                },
                {
                    "sent": "No, each analysis is performed on a set of articles related to a single topic, but they were host of such topics, so different sets of audience.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "View is a sentence or a group of sentences which are discussing the similar content or issues addressed by group of related articles.",
                    "label": 0
                },
                {
                    "sent": "Cannot be apart of sentence.",
                    "label": 0
                },
                {
                    "sent": "No, it is that it has all the members are complete sentences, no, not phrases.",
                    "label": 0
                },
                {
                    "sent": "Well, actually we used organizers so whatever it determines as a sentence, we are using them.",
                    "label": 0
                },
                {
                    "sent": "You are getting stop words in the sentence.",
                    "label": 0
                },
                {
                    "sent": "Copy eliminate stop words for our analysis.",
                    "label": 0
                },
                {
                    "sent": "But while outputing, we give the complete silence.",
                    "label": 0
                },
                {
                    "sent": "So we want to correlate the number of top ranking sentence is N versus the cohesion value obtained by us.",
                    "label": 0
                },
                {
                    "sent": "So we need to select the value of N which can maximize cohesion.",
                    "label": 1
                },
                {
                    "sent": "Ideally we want the median collision to be greater than equal to the mean, because mean is often prone to outliers.",
                    "label": 0
                },
                {
                    "sent": "So we found it for the value of N between 20 and 35.",
                    "label": 0
                },
                {
                    "sent": "About to crack criteria were satisfied, we use incremental clustering for our analysis or that is.",
                    "label": 0
                },
                {
                    "sent": "Let me start with the lower bound of 1st sentences like let's say 20 and incrementally Arctic sentences to obtain to get to upper bound like let's say 35 and we calculate the overall cohesion of the views an output views which give the best question.",
                    "label": 0
                },
                {
                    "sent": "So by our analysis, we found that more top ending sentences need not necessarily lead to views with better cohesion.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are some numbers of correlating a particular data set with the number of four top ranking sentences yielding the best cohesion.",
                    "label": 0
                },
                {
                    "sent": "And the second table is correlating each data set with the mean number of sentences per each view and the mean number of fuse for that data set.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the values are most of the values are less than or equal to five.",
                    "label": 0
                },
                {
                    "sent": "Keeping our representation concise.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude and say that we wanted to develop an IR model which was an alternate to summarization by providing multiple diverse use and organizing the content but making it easily navigable will help a busy viewer who can browser topics fuse?",
                    "label": 1
                },
                {
                    "sent": "Or or just look at the most relevant you rather than somebody where you're confused us to read the first 10 sentences or the last 10 or something like that.",
                    "label": 1
                },
                {
                    "sent": "Up we are clustering in a sentence or phrase level or as opposed to document clustering, which is looping sentences disk.",
                    "label": 1
                },
                {
                    "sent": "Sorry, grouping documents discussing a common topic.",
                    "label": 0
                },
                {
                    "sent": "Play in future we want to mind the polarity of a view that is positive, negative or neutral by using resources like centive, ordnet etc.",
                    "label": 0
                },
                {
                    "sent": "We wanted to collect user feedback and that can rate these views.",
                    "label": 0
                },
                {
                    "sent": "Implicit feedback that is clicks and time spent on a particular view or explicit in terms of user ratings and all.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any questions?",
                    "label": 0
                }
            ]
        }
    }
}