{
    "id": "dovepq7vi2rhsh7o6vpat7zmxnx5oxz4",
    "title": "Domain Specific Languages for Convex Optimization",
    "info": {
        "author": [
            "Stephen P. Boyd, Department of Electrical Engineering, Stanford University"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines",
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization"
        ]
    },
    "url": "http://videolectures.net/roks2013_boyd_language/",
    "segmentation": [
        [
            "So actually I think my callback library divergance between the the advertised talk title and the actual one is less so.",
            "I won't even say anything about kernels so, but that's OK.",
            "I'll say something about the oh part regularization.",
            "OK, maybe I'll say it.",
            "What's that?",
            "Talking about R as well, yeah so OK, so I'm going to talk today about stuff that actually may not be familiar to a bunch of you, some.",
            "Some of it certainly will be.",
            "But actually, what the goal today is actually give you a rough idea about sort of a whole area that most people lots of people use, but a lot of people very few people actually know how it all works.",
            "It's quite simple and I guess I'll show you today how all these things work.",
            "I'll be talking about stuff that goes back maybe four or five, maybe 6 eight years.",
            "Something now by now and it's."
        ],
        [
            "Various people, including Eric Chu, is a recent student Jacob Mattingly bit awhile ago, and Michael Grant quite awhile ago and I'll talk about domain specific languages for convex optimization.",
            "They'll start with just a quick, very quick overview of what is convex optimization.",
            "I know that everyone here knows this, but actually just for the record.",
            "Also, I guess it's being taped.",
            "It's nice to have you know a little part in front that says why we should do this, or why we should care at all.",
            "So I'll start with that and then I'll talk about constructive convex analysis.",
            "So how is it that you detect that you tell whether a function is convex or not, or whether a problem is convex?",
            "And that's a segue actually, into will talk about cone representation and then then I'll start talking about how to make a lot of the analysis actionable.",
            "And that's actually going to be a theme.",
            "So the question is not how to analyze some convex functions, but in fact how to actually do something with them and things like that.",
            "And then I'll veer into computer science, but like undergraduate level, right?",
            "So very simple stuff.",
            "And then I'll talk about parsers solvers and parser generators and then.",
            "I'll finish up OK the 1st."
        ],
        [
            "It's just.",
            "You know two minute introduction when it's convex out."
        ],
        [
            "Possession.",
            "Well, it's an optimization problem where you minimize a convex function subject to convex inequality's and linear equality constraints and everything.",
            "The objective and the constraint functions have to be a convex.",
            "They have to have non negative curvature, so that's a convex optimization problem in standard form.",
            "What is emerged as something?"
        ],
        [
            "A modern Canonical form, which ironically goes also back to the something like a Canonical form from the 1940s right, is the cone problem and that minimize a linear function subject to linear equality constraints and all of the nonlinearities have been expressed in terms of a cone, and then simply says that your variable lies in some cone.",
            "So that's it.",
            "I mean, it looked at first, it looks very specific.",
            "It looks like it's a very special form of convex optimization.",
            "And it turns out it's completely general and you can go back and forth and things like that so.",
            "So you could think of something like that the cone constraint is a generalized non negativity constraint.",
            "And of course if we put in different cones here you get different problem families with names right?",
            "So if K is the nonnegative orthant, you get linear programming.",
            "If K is the embedding of the semidefinite program 7 infinite cone, you get a semidefinite program here.",
            "So this is.",
            "This is sort of the modern Canonical form.",
            "Actually, the idea of Canonical forms is important because it's a.",
            "It's an interface between those who use optimization and those who develop algorithms for them, right?",
            "So it's it's actually from that point of view it's quite important 'cause it means that people can work on solvers for that, whatever, whatever is it the agreed upon Canonical form, and then other people can work on mapping their form to that Canonical form, right?",
            "So OK."
        ],
        [
            "So why convex optimization?",
            "Well, there's a beautiful and fairly complete and useful theory.",
            "Sort of an inverse order of importance in this completely subjective, so this is just my opinion.",
            "So the first one is probably what a lot of people think is the most important.",
            "So the other ones that their solution elements that work well in theory and practice, and actually what the practice means, is that of convex optimization is actually actionable, right?",
            "So it's unlike something like, you know a Brouwer fixed point theorem or something like this, where it's very nice to blabber on and on about the existence of an equilibrium point, but it's not actionable.",
            "Well it is, but with exponential effort, right?",
            "So here the difference.",
            "With convex.",
            "It's actually actionable if you say something that convex problem.",
            "You're actually saying something that you that you can now.",
            "You OK, so that's a I think that's an important part of it.",
            "And of course the main.",
            "I mean, I think the main drivers is just tons of applications and they're in lots of areas.",
            "I guess here people been talking a lot about machine learning and statistics, actually.",
            "So far most people have focused on well, except maybe for one of the a couple of talks yesterday, shallow so called shallow learn, right?",
            "That's good.",
            "That's that's to be distinguished from from deep.",
            "I mean I hate these terms.",
            "It's an unbelievably pedantic.",
            "But anyway, I mean so.",
            "So anyway, and it's been observed, and of course you know the shallow learning with you.",
            "Everything we've seen here and by the way it's what's actually working in a lot of cases.",
            "The lot of these problems are generically convex problems.",
            "I mean, they all look like you minimize an average loss, which is.",
            "Typically convex plus the regularization term, which is convex and so on.",
            "But actually interesting.",
            "Lee is a huge connection to so called deep learning.",
            "If you look at auto encoders this again if you know a little bit about deep stuff or whatever so called deep stuff.",
            "I have to find an insulting name.",
            "So that's right.",
            "So if you let me, if you look at these things, what plays a huge role are things like auto encoders where you agnostically actually fit you.",
            "Do you compress the data at various levels right back?",
            "Not all of these things are absolutely generically biconvex problems, right?",
            "So there in a few cases, like PCA, you actually get the global solution, but in all other cases like non negative matrix factorization, all these kinds of things, every other case, they're biconvex.",
            "Right, so once again it plays a big role in these things because that was just that was just a little just a little side, OK?",
            "But it comes up in lots of other areas, I mean signal and image processing that doesn't count, because that's just.",
            "Basically, that's machine learning and statistics, but with a different accent or something like that, it's under mutually unintelligible, usually, but it's a different accent, but it comes up in lots of other areas.",
            "Control and circuit design and finance and many more.",
            "OK, so how do you solve a convex?"
        ],
        [
            "Position problem.",
            "The easiest is to use someone elses standard solver you know like an LP solver, QPS, OCP, something like that, and that's great, you know, because someone else probably put a lot more time into developing a solver than you would have or something like that.",
            "But the problem is it has to be in the standard form.",
            "Now the flip side the good side in terms of how you structure the whole field is it makes a lot of sense right?",
            "Because you have people who can put in person years of effort into making an LP solver with the full knowledge that thousands and thousands of people will use it in lots of different fields, right?",
            "And it's because a lot of people are going to use it, that you can amortize the development effort.",
            "So I mean, this makes sense.",
            "I mean, Conversely, people can work on mapping.",
            "Their problem to an LP because they know that when they arrive in an LP they can exploit what is now you know, which is probably 100 person years of cumulative effort development, right?",
            "So so this all makes sense, OK?",
            "Now you can also just write your own custom solver.",
            "That's lots of work, but you can take advantage of special structure.",
            "And I mean this is essentially universal in machine learning, right?",
            "Because people don't.",
            "You're not going to use a standard where the problems are already.",
            "Generally Speaking of two largest scale, right?",
            "So work on your own and I think it takes.",
            "I mean, it's hugely there in what people have done.",
            "Is another method you can transform your problem into a standard form and then use a standard solver and that's it's a very interesting idea.",
            "The idea that extends the reach of problems solvable by standard solver, so you don't, and if you've taken a course on optimization, this is even part of it right that you look at a problem that's not an LP, but you can transform it to an LP and then use an LP solver.",
            "OK, so this is this is the idea, and you've seen all these things, and in fact what I'm going to talk about is just simply methods to formalize this.",
            "I mean this has been done.",
            "Since 1948, so and probably earlier, right?",
            "So people have it was well known.",
            "I mean the first before people even invented the word linear programming.",
            "It was well known that it wasn't.",
            "It wasn't just meant to solve problems of that form, but problems with variations of forms that you could massage into form for LP.",
            "OK, so this is the.",
            "This is not a new idea."
        ],
        [
            "OK, so we're going to look at constructive convex analysis.",
            "At first, it's going to look like a lot of things I'm talking about don't have anything to do with each other, but I promise you in the end they're all going to come together so.",
            "Um?"
        ],
        [
            "So basic question is, how do you know if a problem is convex?",
            "Well, what you have to do is you have to check whether funky often detect whether functions are convex.",
            "OK, so how do you do that?",
            "Well, I mean, you could use the basic definition could use a first order condition.",
            "You could compute it smooth.",
            "You can compute the Hessian and try to figure out if it's if it's you know positive semidefinite and this you know for very simple things this is fine, but in fact the most effective method in practice is to do this constructively and you do this through a convex calculus right?",
            "So the way you do it is this.",
            "You construct a function using a library, basic functions that you know to be convex.",
            "And then you have some rules that preserve convexity.",
            "Hey, like for example, the sum of two convex functions is convex.",
            "OK, so this is the idea.",
            "And by the way, this works when you're coming up with the problem, or whether you're doing an analysis of the problem.",
            "Either way, you're going to simply parse something and then and then.",
            "It will look at this idea, so that's the idea of constructive convex analysis.",
            "So."
        ],
        [
            "Just to just so that this is not just all talk, we can say a little bit here some examples.",
            "Basic ones would be various scalar functions like powers are convex for appropriate ranges of ovpi, exponential, negative log, negative entropy, affine functions, quadratic functions with positive semi definite coefficient norms, Max.",
            "Things like these are these are convex functions and it's very easy to show that these things are convex."
        ],
        [
            "I mean, there's less basic example.",
            "I think the simplest non basic, generally speaking the simplest function that most people don't know is convex, but is is X ^2 / Y OK so it's that simple and it actually by the way you might say, well that doesn't come up, it comes up all the time.",
            "I mean a lot.",
            "So do X, ^2, / Y or a matrix version of it is X transpose Y inverse X along some X.",
            "Again, many people would know this.",
            "I guess this is called softmax in a lot of areas.",
            "It's well, we've seen it in logistic.",
            "We saw it not 5 minutes ago.",
            "Log 1 plus the log of the log of the cumulative distribution of a Gaussian is concave, and that's true for any log concave density.",
            "The log determinant of the inverse of a matrix is convex.",
            "Again, if you.",
            "If you've seen these things, you know them.",
            "I mean, this is been known for more than 100 years.",
            "So, but these are.",
            "These are interesting things.",
            "Maximum eigenvalue of a symmetric matrix OK."
        ],
        [
            "Here's some.",
            "Here's some of the calculus rules well.",
            "Any some of these are totally obvious, right?",
            "And when you teach this this is you always start with the obvious ones you know.",
            "Look if you add if you add two convex functions together, the result is convex.",
            "Will sure you know, do things, have furniture and Adam together.",
            "So does this sum.",
            "If you scale by a non negative.",
            "Parameter obviously that preserves convexity affine composition.",
            "That's very straightforward pointwise maximum that's that straightforward partial minimization that says if you have a function which is convex in jointly in two arguments and you minimize over one, the result is convex.",
            "In the other.",
            "I mean, these are all completely straightforward to show.",
            "I mean, these are all very straightforward.",
            "Position.",
            "If you have a convex increasing function of a convex function, the result is convex, so there's more of these.",
            "I'm not going to list anymore, but you list a bunch of these things and then the idea is you take these atoms, which are these basic functions and things, and then you combine them with these calculus rules and make all sorts of interesting functions right, so that would be the idea."
        ],
        [
            "So I mean just we can go over this quickly because I think it's all kind of obvious.",
            "But you can do things like this here.",
            "There's a piecewise linear function expresses the maximum of bunch of afine functions that works because Max is convex, and then the argument is afaan, so that works fine.",
            "There's one, the lasso cost, right?",
            "So it's a it's a sum of squares plus oven affine function plus Lambda times to One North.",
            "Or hear the sum of the K largest elements of affective.",
            "Right, so that would be that's convex and you can check that because it's a maximum over certain things.",
            "And by the way here, if you want just for fun, you can have the sum of the largest 3.2 elements of a vector.",
            "You know what that is?",
            "What do you imagine is the sum of the three point 2 largest elements of effective?",
            "That's it, OK, that's it.",
            "So now you know what the largest 3.2.",
            "The large 20 elements of vectors and it's convex, OK as a function of X OK."
        ],
        [
            "So it turns out there's a general composition rule.",
            "And the general composition rule is this, and it turns out actually.",
            "Here's the good news.",
            "It subsumes all others.",
            "There's actually only one rule.",
            "It turns out only one.",
            "It's this if you know this, you're done.",
            "In fact, you should.",
            "We should print little cards and then you keep this in your wallet or something you know, along with your Emacs.",
            "You know Google Card or something, right?",
            "This is it?",
            "This is 1.",
            "It's very simple.",
            "It says that if you have a convex function of multiple arguments, then it's convex.",
            "When the following occurs, you walk you.",
            "Iterate across its arguments and you test the following.",
            "Either the argument is outlined, in which case it's done and you can even imagine code for this very easily, right?",
            "Or this H is increasing in this argument and this thing is convex or it's decreasing and it's concave.",
            "OK, so that's it.",
            "Now let me I can explain for example.",
            "Here's a how do you know that I'll use this, which is a sledgehammer to show that the sum of two convex functions is convex ready.",
            "I mean it's really stupid, but here it is.",
            "Here's a function ready.",
            "It's the sum of two numbers, it's convex, and it's increasing in both arguments, so therefore it can take as arguments if two convex functions in the SFA.",
            "Good thing for Max, right?",
            "So most of these things I mean, that's kind of.",
            "That's kind of pedantic to save it's it's much simpler to simply say the maximum of two convex functions is fun facts, but in fact it all follows from this one thing here.",
            "OK, so in fact this subsumes all the others.",
            "There's a few, it doesn't, but we're not going to look at them.",
            "But it subsumes almost all the others, and in fact, it turns out it's the same as the partial minimization rule."
        ],
        [
            "OK, so this leads us to constructive convexity verification.",
            "So what you do the idea is you start with a function given as an expression right?",
            "And by the way, this is already a quite a bit of a difference from what you would normally think about.",
            "I mean when people when you think about functions when you teach optimization, when you do machine learning and all that, the normal into the methods you associate with the function are things like this.",
            "I mean, if you want to think in terms of object or you think well for a function, FI should be able to compute its value.",
            "I should be able to compute, for example, a gradient or a subgradient, maybe a second derivative, but these are methods right?",
            "That you would, but in fact I think probably the right way to do this.",
            "Is this a different way of thinking about you?",
            "Actually think of it as an expression so, so we'll start with the function given as an expression, and then you build a parse tree for it, and then the leaves are variables or constants and parameters, right?",
            "And then the nodes are functions of the children, so these are subexpressions, right?",
            "And what we'll do is this.",
            "For constructive convexity verification will insist that every every single subexpression it's convexity or concavity, or whatever it is actually follows locali.",
            "In other words, it basically follows by using that one rule on its children, so it's completely local, right?",
            "No side effects noted.",
            "Look, this is the idea.",
            "We're going to see some examples and what you can do then is now it is, it's completely elementary.",
            "To walk a function to wauka to Parsa, to walk a parse tree, and to determine whether or not it is constructively convex.",
            "Now what this gives you is you gives you.",
            "Obviously it's a sufficient method for convexity, and it is by no means necessary.",
            "An elementary examples show this.",
            "I mean, you could do things like.",
            "Here's one.",
            "This is really dumb and X ^2 -- X ^2.",
            "That's convex, right?",
            "But I mean come on, this is stupid, right?",
            "That's not the point.",
            "In fact, my argument is X ^2 -- X ^2 should be flagged as.",
            "Not constructively convex, because it's not right anymore than square root 1 + X ^2 is it's not constructively convex, so so another way to say it actually is that these are.",
            "It's a it's a subclass of convex functions and it's not really a function right?",
            "It's because it's a it has to do with.",
            "It's the expression actually, so it's it's a language.",
            "In fact is what it is.",
            "It's a language generated by a set of atoms in these rules, and that's it then.",
            "It just generates a bunch of valid strings or valid expressions.",
            "These are the constructively convex functions.",
            "OK, another way to say it, by the way, is that.",
            "The these are expressions which are syntactically convex syntactically means this that the fact that they are convex does not that you don't have to understand even what the functions mean.",
            "You don't have to know what log means.",
            "The only thing you need about log is the following.",
            "It's concave and it's increasing.",
            "You could replace it with square root.",
            "And it would still work.",
            "Everybody what I'm saying here so you don't need to know the meaning of it right?",
            "So OK, now there's a couple of variations on this.",
            "Well, in one variation you can tag subexpression signs and then this would if you tag signs, you can use the signs to flag things like the monotonicity.",
            "So for example, the square function is not monotone, obviously, but if I tell you that it's argument is positive, then it's monotone right?",
            "This makes a big difference because.",
            "If you you if you don't do that square of square of X is not constructively convex because square of X is but square of square is not.",
            "Right because square being non non increasing non monotone has to take his argument in affine function and square is not but it is with the if you flag if you flag the signs OK so OK."
        ],
        [
            "Let's do an example.",
            "This is just for, you know, just for fun, here's an expression.",
            "Here's an expression involving two variables and.",
            "This is the domain of this, but in fact it will see that.",
            "We'll see later that when you do this, actually all the domain stuff just works perfectly, so you don't.",
            "There's no, it's actually harder to save them at the same mathematically than it is to actually write code to actually handle all this.",
            "So handled this perfectly.",
            "OK, so the way you do is you start with the leaves.",
            "It should be like XY and one.",
            "You look at the bottom level subexpression would be this.",
            "Can you mark that is can you mark that is convex?",
            "Right then you maybe look at 1 minus that and you'd say, well, that's a constant.",
            "Will doesn't matter, you can promote it to convex or whatever, or not, but constant minus convex concave.",
            "OK, so this thing is concave and then you recognize this as this quadratic over linear function, and that's convex.",
            "The argument on top is ifying the argument in the bottom is come Kate and that's fine because because you squared over V or something like that.",
            "He's coming back tomorrow and decreasing so it can take.",
            "You can take a concave argument, so that's yeah, but the point about this is it involves absolutely no thought whatsoever.",
            "It's pure syntax and looking stuff up none.",
            "You don't have to understand any of this.",
            "So in fact you can switch Max for any other two argument.",
            "Any other two argument functions with the same properties, namely convex and increasing in both arguments.",
            "So to make it some or anything you like, you can make it log some experts and.",
            "It would just be the same.",
            "OK."
        ],
        [
            "So this is just to make it absolute certain that the goal here is not to identify convex functions.",
            "That is not the goal, right?",
            "That's it?",
            "That's a completely different goal, and this is not that is an example.",
            "Everybody knows that that's convex, but you can't show this using constructive convex analysis, right?",
            "Because I mean if you go from the bottom, that's OK, that's OK, the sum is convex, but you have no rule.",
            "There's no, there's, there's no method that handles basically square root of convex.",
            "None for good reason, because square root of convex can be anything.",
            "In fact with different with different functions put in there right?",
            "It could be convex.",
            "OK, it could be neither.",
            "Right, so this is this doesn't work, but you simply write this like this if you want to use something like this, OK. OK."
        ],
        [
            "And then we get to the idea of discipline convex program.",
            "And so the idea is it's just a framework for describing convex optimization problems.",
            "It's based on constructive convex analysis, and of course it's sufficient but not necessary for convexity and it's the basis of a lot of a growing number of domain specific languages and tools for convex optimization.",
            "So I mean, you might as well get used to this 'cause you maybe already have seen it or will see it and things like that in more and more things.",
            "What's nice about it is it's so easy to check.",
            "Right, that it's just that it doesn't involve any.",
            "There's no semantics, it's just syntactic.",
            "OK."
        ],
        [
            "So what is a DCP look like?",
            "I mean abstractly, it's a disciplined convex program and have an objective which is either minimize convex expression or maximize that concave expression and they can have a bunch of constraints and they can only look like this expression relative expression.",
            "But the only the only obvious the only ones you can do or convex less than concave, concave, bigger than convex or afine equals equals F1.",
            "OK, so this is.",
            "So even all the way up to here this is a mean, so you can if you want to imagine something like a Backus naur form.",
            "For this for a language this is essentially it."
        ],
        [
            "Now the expressions are going to be formed from variables, constants or parameters and functions from a library and the library functions have known convexity monotonicity inside properties.",
            "No.",
            "And the idea is that all subexpressions match the general composition rule, right?",
            "So so this is a language that we've just defined.",
            "I mean depends on your library, but this is.",
            "This is literally a language.",
            "You could write a parser for it.",
            "Well, it's easy to write a parser for."
        ],
        [
            "OK.",
            "So the idea is that a valid DCP it's convex by construction, right?",
            "And by the way, this is completely different from what you might imagine.",
            "You would want to do, and I like 15 years ago.",
            "I'm working with various students.",
            "We imagine that you'd really like to do and there are people who think this is what you want to do is someone should write what they want to do.",
            "They should they want to minimize this subject to this and you should take what it is that they want and then make an attempt to verify convexity in order to transform it into a convex problem if possible.",
            "Everybody following this right so?",
            "Actually, I mean you can do all sorts of stuff with that.",
            "That's a very complex problem, and it turns out actually, the more you think about it, the more you realize in the end it's a very complex problem, and in fact that's not the way it should be done.",
            "'cause I had very students who worked on this, including one who.",
            "Worked out some huge system that bounded.",
            "Basically it was the interval arithmetic on 2nd derivatives, which is which is all you're doing if you're doing convexity analysis and he walked into my office one day and he wrote this horrible expression on the board with like hyperbolic cosines and all sorts of other stuff, big thing and he said did you know that was convex and I said Nope, you know an his this thing he'd written, you know, took only something like you know the proof of convexity with some 700 passes through something where it tightened bounds and.",
            "Literally went through this and then we looked and we both looked at it for quite awhile and we said that's cool and then after a while we both turned each other.",
            "He said that's cool and completely useless right?",
            "Because I mean this, this was not a way to do something you wouldn't do that right?",
            "Because I mean, first of all, it's not maintainable, right?",
            "Because the point is that big expression was convex.",
            "But who the hell that no one knows why it's convex, right?",
            "I mean you change one parameter from half to 3/4 and it's no longer convex and so on, whereas this is dumb enough.",
            "It's on its face.",
            "It's not anywhere so alright, so that's that's posterior convexity analysis, right?",
            "And so I've already mentioned all these things, right?",
            "This is what this is.",
            "OK, so I mean, this is a very simple idea.",
            "OK, so let's look at cone representation."
        ],
        [
            "Pioneer done actually by so.",
            "So here it is, a common representation and like I said, all the things I'm talking about are going to come together.",
            "Trust me.",
            "OK, so a common representation of a convex function is this.",
            "It says you want to represent a function as the optimal value of a cone program in two sets of variables X&Y.",
            "But you you minimize over why so it's the partial minimization rule, which in fact is the same as our general general composition rule, so that's a hint that these are going to be related so.",
            "So you want to write it as the optimal value of something like like this OK. And I mean anything you define this way is convex.",
            "But Conversely many things that any many functions that you're interested in.",
            "You can write this way.",
            "OK, so that's the idea.",
            "OK, here's some examples.",
            "Well let."
        ],
        [
            "See the negative geometric mean that's convex function and it's the optimal value of this SDP where you minimize over over here, why and why next?",
            "Sorry, yeah, so why next to friends, right?",
            "So empty, so you get that?",
            "How about the sum of the K largest entries?",
            "Well, that's the option.",
            "You could check that's the optimal value of the following linear program.",
            "That's here, where the variables are Lambda, mu and Nu.",
            "So that's that's the idea, and the point is, this is a linear program in everything in X, Lambda, mu, Nu.",
            "But you only optimize here over Lambda Mu Nu and the resulting function which is partial minimization, is in fact the sum of the K largest entries events.",
            "OK, so by the way, these kind of hint that these are not totally obvious, some of these things so."
        ],
        [
            "Yuri and many others that worked out.",
            "Actually not that many others.",
            "I have worked out SDP representations alot of a lot of functions right?",
            "So I think like powers you know determinant to the 1 / N the sum of the K largest eigenvalues the norm.",
            "I mean some of these are easier than others.",
            "The dual norm sometimes called the tracer nuclear norm.",
            "Something like that I guess is playing a big role now and various low rank approximation type things OK Alright."
        ],
        [
            "Canonicalization So what?",
            "You?"
        ],
        [
            "As you start the idea of meeting with the idea of canonicalization is you start with the problem in DCP form with cone representable library.",
            "OK, so you start with that and the goal is to automatically transform it to account to an equivalent cone program, right?",
            "So that's that's the big picture.",
            "So let's see how you."
        ],
        [
            "Well, it's actually embarrassingly simple.",
            "I mean, it's not unsophisticated, but it is embarrassingly simple.",
            "It goes like this.",
            "What you do is you take the parse tree of every function appearing in your problem statement, every single one, and then you simply it's a macro substitution that whenever you see F appearing in a parse tree, and it's got this cone representation, then you simply do the following.",
            "You add a new variable Y.",
            "You add this constraint and that constraint, and you replace F with this app line expression.",
            "You do nothing else.",
            "Blind macro you can write.",
            "You can actually if you can.",
            "You can imagine 2 lines of code in any modern language will do this for you to write.",
            "Basically you know constraints plus equals that new variable.",
            "Why constraints plus equals that constraint plus equals that and return that.",
            "That's it.",
            "OK, so now that's a constructive thing.",
            "So if you do this though, you yield it.",
            "You end up with a problem, you eliminate any non affine functions.",
            "And So what it means in the end, you end up with a problem that has only affine constraints and cone constraints, and there's a name for those problems there, called cone programs.",
            "Everybody following this.",
            "So this is the idea, and it turns out this is just a mechanical, you know, macro replacement.",
            "Another question is, how do you know when you do this, that the new problem is equivalent to the old one?",
            "Well, the new problem, by the way, is always the convex relaxation of the of the original one.",
            "But if this is where you need the DCP requirements, the monotonicity.",
            "Right, if the monotonicity assumptions hold, that's the exactly the condition that this transform problem is equivalent to the original 1.",
            "So these are these are connected.",
            "OK, and so, by the way, if you think about what this does, it means that you've we've made with this.",
            "This is it.",
            "You've automated now DCP analysis and that canonicalization.",
            "Canonicalization means to go from a problem description to economical to an equivalent Canonical form.",
            "So it's completely automated.",
            "And not only that, it's like I don't know.",
            "I've seen people implement things like this like full on working systems that look like CBX in 200 lines of a modern language.",
            "So it's really straightforward.",
            "I mean, once you know this, which there's not much to know, it's just this.",
            "OK."
        ],
        [
            "So.",
            "Let's look a little bit deeper at how you might.",
            "You know what you do."
        ],
        [
            "These things well.",
            "Some of these you can use that you can make it build yourself a parser solver and that would be things like CVS or Youngman.",
            "Actually, how many people have used either of these?",
            "So a bunch and the others do it just to see what they look like.",
            "I mean this refund or I mean I mean both of these run in Matlab and have a problem with that.",
            "Which is fine.",
            "I do too.",
            "There's other versions.",
            "Is PBX pie or something like that and play with.",
            "So what these do is these are parser solvers because they don't allow abstract parameters, the IT takes a an instantiate it.",
            "It takes a problem instance, it checks DCP if it satisfies DCP.",
            "It actually generates a cone program and then solves that instance immediately using one of the open source code solver like said to me you SDPT 3, so that's what that does.",
            "OK, now you can also do a parser generator.",
            "So parser generator.",
            "That is something that supports parameters and so you describe a problem family, not a problem instance of problem family.",
            "So you say A is a parameter is a Lambda is a parameter and its positive right?",
            "If you don't tell them it's positive PCP, it can't verify DCP and what happens is you canonicalize the problem family.",
            "That's what symbolic parameters will see.",
            "Examples of this and then what you end up doing in this case is.",
            "Well, you don't solve the problem because the problem hasn't been instantiating you.",
            "What you do is you end up you end up what you can do is you can as well as several ways to do this, but you can generate the mapping that Maps the original problem to the cone program, right?",
            "That's just a function that does this mapping and then then you have several things you could do if you connect that to a custom generated solver, you have a code generator, or you could connect it to a generic solver and now you you would have something like.",
            "Umm, which I will look at.",
            "So this is this is the idea.",
            "OK, so."
        ],
        [
            "Examples will look at we use this same baby.",
            "Problem.",
            "And of course, I guess the whole point of these things in these domain specific languages is that in a very short inline script you can actually describe quite complicated problems when it would be a super duper pain in the ass to handle otherwise right?",
            "I mean to to actually manually transform, I mean this one is not that hard to transform, frankly, right?",
            "But it's so it fits on half a page or something, so here it is.",
            "You want to minimize a lasso objective and for some reason you all your parameters have to be less than one in absolute value.",
            "I mean just we made it up so.",
            "So here the idea is the variables X and the constants and parameters are a B and Lambda lambdas positive.",
            "Otherwise this is not convex.",
            "Or to be quite precise, need not be might not be right so.",
            "So and the goal of course, in designing a language is to have the you should line up the math and latech on one side and the source code on the other, and you should be able to look left and right and say that's the same, right?",
            "That's that's the goal of a domain specific language, right?",
            "I mean if you see some obscur code on the right and you have to actually think hard, that's not, that's not a success, OK?"
        ],
        [
            "So here's what CBS looks like.",
            "This is developed by Michael Grant maybe seven years ago.",
            "I guess me maybe seven years, something like that that's embedded in Matlab that targets multiple cone solvers, and the this is the CVS specification for that example problem.",
            "So and here the presumption is that a B and Lambda are actually their numeric constants, right?",
            "Not only that, but land is positive, right?",
            "If land is not positive, you'll get an error right here, and this will be flagged and it'll say there's a DCP.",
            "They'll be a DCP error and the DCP error if Lando is minus, one would be a very simple one.",
            "It would say, and hopefully I believe it's the error is actually correct.",
            "It says the following.",
            "It basically says I don't know how to add a convex and concave function and notice what it doesn't say.",
            "It doesn't say that's not convex.",
            "So because it might be if Andy were zero and it doesn't matter anyway, we'll leave that Elvis leave that alone.",
            "So that's the idea.",
            "So it takes this, it parses it economic.",
            "Lisa generates a cone program and then that would be solved by SDPT 3 or said to me or something like that.",
            "Oh I, I should mention a couple of things there related to this.",
            "When we first looked at things like this, we assume I mean what happens is actually quite hilarious.",
            "It just get rid of this and this and now you have a least squares problem, right?",
            "That's the oldest optimization problem there is.",
            "I mean, Down's wrote a book in Latin about this.",
            "And like you know, 1805 or something, right?",
            "I mean ridiculous.",
            "As an exact solution and all that kind of stuff if you type it into CBX, it's hilarious.",
            "You know it comes out.",
            "It dutifully transforms it into it.",
            "Until like a second order cone program, so you started with the world's simplest convex optimization problem, at least squares problem and the next thing you know now it's a second order cone program with more variables.",
            "Everyone following this.",
            "So this doesn't sound good, right?",
            "OK, and then you might ask your question.",
            "Well, how much slower is it to solve?",
            "And so on.",
            "And the answer is basically generally not at all.",
            "And the reason is very simple when when you generate when you do this canonicalization, you do end up you start with the problem with thousand variables and then if you have.",
            "If you do even care and you look at it, you'll see that the new problem has 15,000 variables.",
            "Everybody following this, anything that's not good.",
            "About the 50 does have 15,000 variables, but it's extremely sparse, right?",
            "And in fact, modern sparsity loading methods are able to get back basically all of the.",
            "In most cases there's cases where it fails, but mostly it recovers all of it.",
            "OK, that was just in the side, sorry, OK."
        ],
        [
            "So here would be some functions in the CBS library.",
            "Those of you have looked at it would know about this.",
            "Would you get some weird thing?",
            "I mean, some of these we put?",
            "I mean no ones ever, as far as I know, no ones ever used that for any practical purpose that somebody might do it just to show off or something like that.",
            "But so half the functions in there just in there to be bizarre and weird.",
            "Just because we could, you know, like this, some of the five largest eigenvalues of a matrix or something.",
            "So OK, so this is the idea.",
            "And then these are the attributes.",
            "That's the signature of the function.",
            "OK CVS gym."
        ],
        [
            "That's a code generator, which probably far far fewer of you have seen, and probably.",
            "OK, so I'll tell you what it is.",
            "So CDX Jen.",
            "That's a parser generator, no sound like just a couple of years ago by a student of mine Jacob, and again has domain specific input and instead of, but it takes a family's argument, not an instance.",
            "And then what it does is it generates.",
            "Actually it generates entirely black.",
            "See actually library free.",
            "You don't even need the math library if you turn verbose off and the only thing you need from the math libraries math that square root.",
            "To display a normal.",
            "It's library free black see, so it's actually perfect for embedded things, right?",
            "Runs on arms and all sorts of other stuff anyway, so anyway, this is the idea, and so the idea is you type in a problem family.",
            "This thing takes awhile and then outcomes CONA makefile and stuff like that.",
            "And then you compile it and now you have a super fast function that Maps parameters to solutions, but just for that one problem family everybody following this.",
            "That's the idea.",
            "You can do that in stuff like CVS, but I mean that would be.",
            "To say that's inappropriate for embedded applications is a huge understatement.",
            "Even though it is actually used in embedded applications.",
            "Much to my shock and horror.",
            "But it is so OK.",
            "This is what?"
        ],
        [
            "Xgen looks like.",
            "And the source once you start once you understand all these things, these languages all start looking the same as they are all the same.",
            "Basically it looks like this.",
            "Yeah parameters and you declare landing posit, but notice here their parameters.",
            "You haven't said what Lambda is yet.",
            "Right whereas in CVX, you say what Lambda is right here, it has no value.",
            "You give the variables here and then there's the kinds completely readable, right means obvious what it means, and the idea here is that avian Lambda are symbolic parameters.",
            "What comes out is just flaxy.",
            "Which you compile and now you have a solver for that specific problem.",
            "So if you wanted for a small problem like the world's fastest lasso solver, this would generate, right?",
            "So you do this, and these are.",
            "I mean even these numbers are behind, but it gives you roughly the idea.",
            "So for example, if you take little Caesar baby problems with a couple 100 variables, But this would go up to several thousands and things like that or whatever, and you have.",
            "Typically you can solve that and you know 1/3 of a second or a half of a second or something.",
            "You know that's not bad, right?",
            "But the typical speed up is about 1000 X.",
            "Be the typical one, so I mean it's not to mention that's not the real point.",
            "The real point is extreme reliability also, and low software footprint, right?",
            "So it's got you could never embed something like a CV X into some real time thing.",
            "Or if someone did that, I would strongly advise you not to get in that vehicle.",
            "Right 'cause I mean, it's just it's ridiculous, right?",
            "So anyway?",
            "So by the way, you might ask, how did you get 1000 to one?",
            "We would love to take credit for it.",
            "We take none.",
            "It turns out that the credit all the credit goes to our friends from my building, which is electrical engineering, is across the street.",
            "The Computer science Department.",
            "People who build compilers.",
            "Right, so we tried to do all sorts of fancy things since we knew everything that was going to happen.",
            "We re ordered the data and try to make it more, you know, make the memory accesses more local and stuff like that.",
            "When we turned on you turn on optimization and it just always beat us.",
            "So what would happen is if we would do all this work.",
            "And then you turn on optimization and it would be no better from the original 1.",
            "So right now when we generate C source variables come out in the following order.",
            "The order in which they are declared in the source, and then we let GCC minus oh 3 or whatever it is, deal with it right?",
            "So that they are the ones actually there.",
            "We checked and it because it's almost branch free code that compilers go insane.",
            "So they just they love it, they reorder things and we have no idea what they're doing, but.",
            "But it's all this is to make clear is you know somebody has to take credit for the 1000 to one improvement here.",
            "And all I'm saying is I don't know who it is, but I know it's not us.",
            "OK, well, except that we wrote except that we took the care to write C that was almost branch free.",
            "So that was our part of it.",
            "And then we just actually this is better this way because we didn't.",
            "We were hoping.",
            "We did if we if we were the ones starting to worry about memory locality and things like that, that would be not good 'cause.",
            "What's that?",
            "Air Force"
        ],
        [
            "In fact we reverted.",
            "This is a very.",
            "This is a very old money.",
            "This is not even the homogeneous embedding.",
            "This is a very, very old simple one.",
            "Yeah.",
            "Oh, it's much less generic actually.",
            "Yeah no.",
            "It's in fact it's it's it's very unsophisticated.",
            "The method we use.",
            "And we're proud of it.",
            "So we don't apologize so.",
            "OK, so now I'll tell you a little bit about."
        ],
        [
            "A more recent one, this and this is sort of like work in progress, and the idea is to.",
            "Make something that actually works.",
            "You know that that actually is applies to many other things and also, by the way would allow us to do weird things like target.",
            "I should say that the CBX Gen stuff it's made for embedded stuff, so it's single when it comes out of singles.",
            "Red, right?",
            "So?",
            "But you might want to do something where you you might want to target like a GPU, right?",
            "Or or an MPI cluster right?",
            "Or for that matter, you might want to even generate like weird stuff that targets had two percent.",
            "I mean, I.",
            "You can imagine all these things right easily so.",
            "So to do that, we decided to kind of start yet again.",
            "Air 2 is writing something isn't Python, although he's he's written several times in many languages, just 'cause it only takes an afternoon once you know these things, it takes one afternoon, any language or any real language.",
            "It's a right now it targets will see a target CVS, often Python is another target.",
            "It does as well, but it can also do.",
            "It can also generate source code for several targets, so it actually when you're developing these things, you always do that.",
            "And actually the first source code you target is CDX.",
            "So right gets you.",
            "You parse something so you have something very sophisticated written in a real language.",
            "It parses the thing and then admits Matlab source and so, but that's we do that just 'cause you need.",
            "You need to test these things right, so OK, but the idea here is if you if this were done right, you'd end up with a seamless transition from prototyping the code generation.",
            "We'd sit on your laptop and fiddle around and adjust something and mess with some parameters.",
            "See if you like the trading algorithm you're developing or something like that.",
            "And then you say I like it, I want to put it into production or it's a control algorithm.",
            "You're doing simulations at say, 110th real time, and you say you know what I want to download it to the vehicle.",
            "Then it's the same thing.",
            "In fact, you just call well, you'll see.",
            "So this is this is still stuff that is being worked on, but I give you a rough idea of what it looks like a snapshot right now 'cause it gives you an idea of what these."
        ],
        [
            "So.",
            "You would do something like this.",
            "You make use EML parser object and then what you do is you call the parse method on it and then this is just.",
            "This is actually just annotation.",
            "But the idea is this should look now very very familiar right?",
            "So you do this.",
            "That that gives you that.",
            "That is a side effect on this object P, and then you call the canonicalized map and it does exactly the thing I described before, which is.",
            "It walks.",
            "It just walks the tree and does the cone representation substitutions and that's it.",
            "So now you have a.",
            "They have a cone problem embedded in P."
        ],
        [
            "OK, now once this canonicalized in creative you can create a Python solver and so for example you might say you might call the code Gen method on P and that's the target CVS up CBS up.",
            "By the way is a Python based in Interior Point Solver written by leaving Vandenberg.",
            "So you do that and then you.",
            "Then you say FP dot solver and then that's actually a function that solves the problem right?",
            "So then, for example, if you want to solve instances of the problem, you simply say F of params and then will return the solution.",
            "That's it, which is in fact if you think about it, that's what solver is.",
            "The function mapping parameter value problem instances specified by parameter values into solutions, right so?",
            "And if you want to use it like in a CVS mode in interactive mode, you can combine these and you have you have one thing which is.",
            "You can directly call P dot solve params and that will canonicalize you know, generate a solver and then invoke the solver all at once and now it looks like.",
            "So now it's edx, right?",
            "'cause you just specify your problem and then you say solve, instantiate the parameters as an argument and then outcomes the solution right?",
            "So OK, but you can also use this as a code generator for something."
        ],
        [
            "Really so, for example, another project we're working on, actually with some people at EHA is ecosystem embedded cone solver, and it's just a super lightweight.",
            "In this case it's just a second order cone solver, but that's a lot more than CDs Gen, which does QPS, right?",
            "So you can also say p.co Gen echoes, and then this generates like C solver code and then then you get something that's like DX Gen.",
            "Except now it works for a much wider variety of things and also will scale to much, much larger.",
            "Problems because the exchange is done in a very specific way, which doesn't scale to huge problem.",
            "It doesn't even scale the medium size problem.",
            "And so that's the that's the idea there.",
            "OK, and then the idea is that these things eventually will target things like you know, please generate CUDA for me or generate something, or some MPI stuff to run on the cluster.",
            "Weight doesn't matter, so OK, so I'll just I'll finish up.",
            "And the conclusions that they're pretty straightforward.",
            "I mean, one is this idea of this."
        ],
        [
            "Convex programming.",
            "Basically it's a formalization of constructive convex analysis.",
            "So just it's an extremely simple idea and it's a simple method to certify a problem is convex.",
            "It it is a set of sufficient, but by no means necessary conditions for problem to be convex.",
            "But it's it's.",
            "It's extremely useful, even though it's dumb and simple.",
            "It's the basis of a lot of domain specific languages for convex optimization.",
            "And once you know the things that I've told you today, and you know a modern language, you're totally empowered.",
            "Mean you can write.",
            "You can write this yourself in an afternoon if you're fluent in a real language, right?",
            "You can easily write one, and it's actually pretty cool because it means you can do a lot of damage in a couple 100 lines of of code.",
            "So parser solvers they make rapid prototyping easy, and I know that from personal experience I I taught a course on Linux optimization Precedex and post CDX and the difference is just night and day and even for the students who are theoretically oriented, it was night and day.",
            "The class went from one where it was kind of a lot about the math and this, that and the other thing.",
            "And we I would blabber on and on about how some of these things might have applications they had to trust me and then every now and then we have some like baby problem.",
            "It wasn't a pain in the ass to solve using basically by hand the canonicalization right post CBX.",
            "It's different.",
            "I mean, we get to the third week of that class and that's the end of that week and ask him to do anything we like and we have them solve problems in signal processing, machine learning, circuit design everywhere, finance, everything.",
            "So the classes went from one that was kind of a applied math class to one that's actually applied math and highly actionable.",
            "So it's actually been a lot of fun is fun for me.",
            "Fun for them.",
            "It's great.",
            "Um change research too.",
            "The parser generators, so these yield solvers that are extremely fast and they can be embedded in real time applications.",
            "So we also have done other steps.",
            "Since we have now the ability to generate like QP solvers that execute in 50 microseconds, right?",
            "For example, when we when we do various things like in control, when you actually the control on both solving a QP and you want to evaluate something by Monte Carlo, right?",
            "Then you need to solve QP every iteration, so we routinely.",
            "Run for 10 million iterations, right?",
            "Just just 'cause we just to show off, right?",
            "So this because we can solve 10 we can solve 10,000,000 QPS.",
            "Gonna you know 32 core machine and I'm like 12 seconds or something like it's crazy.",
            "So so we do that.",
            "OK so I will.",
            "I'll quit here and I guess the references I mean just go."
        ],
        [
            "Google and type things in and you'll find stuff so your friends.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So actually I think my callback library divergance between the the advertised talk title and the actual one is less so.",
                    "label": 0
                },
                {
                    "sent": "I won't even say anything about kernels so, but that's OK.",
                    "label": 0
                },
                {
                    "sent": "I'll say something about the oh part regularization.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe I'll say it.",
                    "label": 0
                },
                {
                    "sent": "What's that?",
                    "label": 0
                },
                {
                    "sent": "Talking about R as well, yeah so OK, so I'm going to talk today about stuff that actually may not be familiar to a bunch of you, some.",
                    "label": 0
                },
                {
                    "sent": "Some of it certainly will be.",
                    "label": 0
                },
                {
                    "sent": "But actually, what the goal today is actually give you a rough idea about sort of a whole area that most people lots of people use, but a lot of people very few people actually know how it all works.",
                    "label": 0
                },
                {
                    "sent": "It's quite simple and I guess I'll show you today how all these things work.",
                    "label": 0
                },
                {
                    "sent": "I'll be talking about stuff that goes back maybe four or five, maybe 6 eight years.",
                    "label": 0
                },
                {
                    "sent": "Something now by now and it's.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Various people, including Eric Chu, is a recent student Jacob Mattingly bit awhile ago, and Michael Grant quite awhile ago and I'll talk about domain specific languages for convex optimization.",
                    "label": 0
                },
                {
                    "sent": "They'll start with just a quick, very quick overview of what is convex optimization.",
                    "label": 0
                },
                {
                    "sent": "I know that everyone here knows this, but actually just for the record.",
                    "label": 0
                },
                {
                    "sent": "Also, I guess it's being taped.",
                    "label": 0
                },
                {
                    "sent": "It's nice to have you know a little part in front that says why we should do this, or why we should care at all.",
                    "label": 0
                },
                {
                    "sent": "So I'll start with that and then I'll talk about constructive convex analysis.",
                    "label": 1
                },
                {
                    "sent": "So how is it that you detect that you tell whether a function is convex or not, or whether a problem is convex?",
                    "label": 0
                },
                {
                    "sent": "And that's a segue actually, into will talk about cone representation and then then I'll start talking about how to make a lot of the analysis actionable.",
                    "label": 0
                },
                {
                    "sent": "And that's actually going to be a theme.",
                    "label": 0
                },
                {
                    "sent": "So the question is not how to analyze some convex functions, but in fact how to actually do something with them and things like that.",
                    "label": 0
                },
                {
                    "sent": "And then I'll veer into computer science, but like undergraduate level, right?",
                    "label": 0
                },
                {
                    "sent": "So very simple stuff.",
                    "label": 0
                },
                {
                    "sent": "And then I'll talk about parsers solvers and parser generators and then.",
                    "label": 0
                },
                {
                    "sent": "I'll finish up OK the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's just.",
                    "label": 0
                },
                {
                    "sent": "You know two minute introduction when it's convex out.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Possession.",
                    "label": 0
                },
                {
                    "sent": "Well, it's an optimization problem where you minimize a convex function subject to convex inequality's and linear equality constraints and everything.",
                    "label": 1
                },
                {
                    "sent": "The objective and the constraint functions have to be a convex.",
                    "label": 0
                },
                {
                    "sent": "They have to have non negative curvature, so that's a convex optimization problem in standard form.",
                    "label": 1
                },
                {
                    "sent": "What is emerged as something?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A modern Canonical form, which ironically goes also back to the something like a Canonical form from the 1940s right, is the cone problem and that minimize a linear function subject to linear equality constraints and all of the nonlinearities have been expressed in terms of a cone, and then simply says that your variable lies in some cone.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "I mean, it looked at first, it looks very specific.",
                    "label": 0
                },
                {
                    "sent": "It looks like it's a very special form of convex optimization.",
                    "label": 0
                },
                {
                    "sent": "And it turns out it's completely general and you can go back and forth and things like that so.",
                    "label": 0
                },
                {
                    "sent": "So you could think of something like that the cone constraint is a generalized non negativity constraint.",
                    "label": 0
                },
                {
                    "sent": "And of course if we put in different cones here you get different problem families with names right?",
                    "label": 0
                },
                {
                    "sent": "So if K is the nonnegative orthant, you get linear programming.",
                    "label": 0
                },
                {
                    "sent": "If K is the embedding of the semidefinite program 7 infinite cone, you get a semidefinite program here.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the modern Canonical form.",
                    "label": 1
                },
                {
                    "sent": "Actually, the idea of Canonical forms is important because it's a.",
                    "label": 0
                },
                {
                    "sent": "It's an interface between those who use optimization and those who develop algorithms for them, right?",
                    "label": 0
                },
                {
                    "sent": "So it's it's actually from that point of view it's quite important 'cause it means that people can work on solvers for that, whatever, whatever is it the agreed upon Canonical form, and then other people can work on mapping their form to that Canonical form, right?",
                    "label": 0
                },
                {
                    "sent": "So OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why convex optimization?",
                    "label": 0
                },
                {
                    "sent": "Well, there's a beautiful and fairly complete and useful theory.",
                    "label": 1
                },
                {
                    "sent": "Sort of an inverse order of importance in this completely subjective, so this is just my opinion.",
                    "label": 0
                },
                {
                    "sent": "So the first one is probably what a lot of people think is the most important.",
                    "label": 0
                },
                {
                    "sent": "So the other ones that their solution elements that work well in theory and practice, and actually what the practice means, is that of convex optimization is actually actionable, right?",
                    "label": 0
                },
                {
                    "sent": "So it's unlike something like, you know a Brouwer fixed point theorem or something like this, where it's very nice to blabber on and on about the existence of an equilibrium point, but it's not actionable.",
                    "label": 0
                },
                {
                    "sent": "Well it is, but with exponential effort, right?",
                    "label": 0
                },
                {
                    "sent": "So here the difference.",
                    "label": 0
                },
                {
                    "sent": "With convex.",
                    "label": 0
                },
                {
                    "sent": "It's actually actionable if you say something that convex problem.",
                    "label": 0
                },
                {
                    "sent": "You're actually saying something that you that you can now.",
                    "label": 0
                },
                {
                    "sent": "You OK, so that's a I think that's an important part of it.",
                    "label": 0
                },
                {
                    "sent": "And of course the main.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think the main drivers is just tons of applications and they're in lots of areas.",
                    "label": 0
                },
                {
                    "sent": "I guess here people been talking a lot about machine learning and statistics, actually.",
                    "label": 0
                },
                {
                    "sent": "So far most people have focused on well, except maybe for one of the a couple of talks yesterday, shallow so called shallow learn, right?",
                    "label": 0
                },
                {
                    "sent": "That's good.",
                    "label": 0
                },
                {
                    "sent": "That's that's to be distinguished from from deep.",
                    "label": 0
                },
                {
                    "sent": "I mean I hate these terms.",
                    "label": 0
                },
                {
                    "sent": "It's an unbelievably pedantic.",
                    "label": 0
                },
                {
                    "sent": "But anyway, I mean so.",
                    "label": 0
                },
                {
                    "sent": "So anyway, and it's been observed, and of course you know the shallow learning with you.",
                    "label": 0
                },
                {
                    "sent": "Everything we've seen here and by the way it's what's actually working in a lot of cases.",
                    "label": 0
                },
                {
                    "sent": "The lot of these problems are generically convex problems.",
                    "label": 0
                },
                {
                    "sent": "I mean, they all look like you minimize an average loss, which is.",
                    "label": 0
                },
                {
                    "sent": "Typically convex plus the regularization term, which is convex and so on.",
                    "label": 0
                },
                {
                    "sent": "But actually interesting.",
                    "label": 0
                },
                {
                    "sent": "Lee is a huge connection to so called deep learning.",
                    "label": 0
                },
                {
                    "sent": "If you look at auto encoders this again if you know a little bit about deep stuff or whatever so called deep stuff.",
                    "label": 0
                },
                {
                    "sent": "I have to find an insulting name.",
                    "label": 0
                },
                {
                    "sent": "So that's right.",
                    "label": 0
                },
                {
                    "sent": "So if you let me, if you look at these things, what plays a huge role are things like auto encoders where you agnostically actually fit you.",
                    "label": 0
                },
                {
                    "sent": "Do you compress the data at various levels right back?",
                    "label": 0
                },
                {
                    "sent": "Not all of these things are absolutely generically biconvex problems, right?",
                    "label": 0
                },
                {
                    "sent": "So there in a few cases, like PCA, you actually get the global solution, but in all other cases like non negative matrix factorization, all these kinds of things, every other case, they're biconvex.",
                    "label": 0
                },
                {
                    "sent": "Right, so once again it plays a big role in these things because that was just that was just a little just a little side, OK?",
                    "label": 0
                },
                {
                    "sent": "But it comes up in lots of other areas, I mean signal and image processing that doesn't count, because that's just.",
                    "label": 0
                },
                {
                    "sent": "Basically, that's machine learning and statistics, but with a different accent or something like that, it's under mutually unintelligible, usually, but it's a different accent, but it comes up in lots of other areas.",
                    "label": 0
                },
                {
                    "sent": "Control and circuit design and finance and many more.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do you solve a convex?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Position problem.",
                    "label": 0
                },
                {
                    "sent": "The easiest is to use someone elses standard solver you know like an LP solver, QPS, OCP, something like that, and that's great, you know, because someone else probably put a lot more time into developing a solver than you would have or something like that.",
                    "label": 0
                },
                {
                    "sent": "But the problem is it has to be in the standard form.",
                    "label": 0
                },
                {
                    "sent": "Now the flip side the good side in terms of how you structure the whole field is it makes a lot of sense right?",
                    "label": 0
                },
                {
                    "sent": "Because you have people who can put in person years of effort into making an LP solver with the full knowledge that thousands and thousands of people will use it in lots of different fields, right?",
                    "label": 0
                },
                {
                    "sent": "And it's because a lot of people are going to use it, that you can amortize the development effort.",
                    "label": 0
                },
                {
                    "sent": "So I mean, this makes sense.",
                    "label": 0
                },
                {
                    "sent": "I mean, Conversely, people can work on mapping.",
                    "label": 0
                },
                {
                    "sent": "Their problem to an LP because they know that when they arrive in an LP they can exploit what is now you know, which is probably 100 person years of cumulative effort development, right?",
                    "label": 0
                },
                {
                    "sent": "So so this all makes sense, OK?",
                    "label": 0
                },
                {
                    "sent": "Now you can also just write your own custom solver.",
                    "label": 0
                },
                {
                    "sent": "That's lots of work, but you can take advantage of special structure.",
                    "label": 0
                },
                {
                    "sent": "And I mean this is essentially universal in machine learning, right?",
                    "label": 0
                },
                {
                    "sent": "Because people don't.",
                    "label": 0
                },
                {
                    "sent": "You're not going to use a standard where the problems are already.",
                    "label": 0
                },
                {
                    "sent": "Generally Speaking of two largest scale, right?",
                    "label": 0
                },
                {
                    "sent": "So work on your own and I think it takes.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's hugely there in what people have done.",
                    "label": 0
                },
                {
                    "sent": "Is another method you can transform your problem into a standard form and then use a standard solver and that's it's a very interesting idea.",
                    "label": 0
                },
                {
                    "sent": "The idea that extends the reach of problems solvable by standard solver, so you don't, and if you've taken a course on optimization, this is even part of it right that you look at a problem that's not an LP, but you can transform it to an LP and then use an LP solver.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this is the idea, and you've seen all these things, and in fact what I'm going to talk about is just simply methods to formalize this.",
                    "label": 0
                },
                {
                    "sent": "I mean this has been done.",
                    "label": 0
                },
                {
                    "sent": "Since 1948, so and probably earlier, right?",
                    "label": 0
                },
                {
                    "sent": "So people have it was well known.",
                    "label": 0
                },
                {
                    "sent": "I mean the first before people even invented the word linear programming.",
                    "label": 0
                },
                {
                    "sent": "It was well known that it wasn't.",
                    "label": 0
                },
                {
                    "sent": "It wasn't just meant to solve problems of that form, but problems with variations of forms that you could massage into form for LP.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the.",
                    "label": 0
                },
                {
                    "sent": "This is not a new idea.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we're going to look at constructive convex analysis.",
                    "label": 0
                },
                {
                    "sent": "At first, it's going to look like a lot of things I'm talking about don't have anything to do with each other, but I promise you in the end they're all going to come together so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basic question is, how do you know if a problem is convex?",
                    "label": 0
                },
                {
                    "sent": "Well, what you have to do is you have to check whether funky often detect whether functions are convex.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do you do that?",
                    "label": 1
                },
                {
                    "sent": "Well, I mean, you could use the basic definition could use a first order condition.",
                    "label": 0
                },
                {
                    "sent": "You could compute it smooth.",
                    "label": 0
                },
                {
                    "sent": "You can compute the Hessian and try to figure out if it's if it's you know positive semidefinite and this you know for very simple things this is fine, but in fact the most effective method in practice is to do this constructively and you do this through a convex calculus right?",
                    "label": 0
                },
                {
                    "sent": "So the way you do it is this.",
                    "label": 0
                },
                {
                    "sent": "You construct a function using a library, basic functions that you know to be convex.",
                    "label": 0
                },
                {
                    "sent": "And then you have some rules that preserve convexity.",
                    "label": 0
                },
                {
                    "sent": "Hey, like for example, the sum of two convex functions is convex.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the idea.",
                    "label": 0
                },
                {
                    "sent": "And by the way, this works when you're coming up with the problem, or whether you're doing an analysis of the problem.",
                    "label": 0
                },
                {
                    "sent": "Either way, you're going to simply parse something and then and then.",
                    "label": 0
                },
                {
                    "sent": "It will look at this idea, so that's the idea of constructive convex analysis.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to just so that this is not just all talk, we can say a little bit here some examples.",
                    "label": 0
                },
                {
                    "sent": "Basic ones would be various scalar functions like powers are convex for appropriate ranges of ovpi, exponential, negative log, negative entropy, affine functions, quadratic functions with positive semi definite coefficient norms, Max.",
                    "label": 0
                },
                {
                    "sent": "Things like these are these are convex functions and it's very easy to show that these things are convex.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, there's less basic example.",
                    "label": 0
                },
                {
                    "sent": "I think the simplest non basic, generally speaking the simplest function that most people don't know is convex, but is is X ^2 / Y OK so it's that simple and it actually by the way you might say, well that doesn't come up, it comes up all the time.",
                    "label": 0
                },
                {
                    "sent": "I mean a lot.",
                    "label": 0
                },
                {
                    "sent": "So do X, ^2, / Y or a matrix version of it is X transpose Y inverse X along some X.",
                    "label": 0
                },
                {
                    "sent": "Again, many people would know this.",
                    "label": 0
                },
                {
                    "sent": "I guess this is called softmax in a lot of areas.",
                    "label": 0
                },
                {
                    "sent": "It's well, we've seen it in logistic.",
                    "label": 0
                },
                {
                    "sent": "We saw it not 5 minutes ago.",
                    "label": 0
                },
                {
                    "sent": "Log 1 plus the log of the log of the cumulative distribution of a Gaussian is concave, and that's true for any log concave density.",
                    "label": 0
                },
                {
                    "sent": "The log determinant of the inverse of a matrix is convex.",
                    "label": 0
                },
                {
                    "sent": "Again, if you.",
                    "label": 0
                },
                {
                    "sent": "If you've seen these things, you know them.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is been known for more than 100 years.",
                    "label": 0
                },
                {
                    "sent": "So, but these are.",
                    "label": 0
                },
                {
                    "sent": "These are interesting things.",
                    "label": 0
                },
                {
                    "sent": "Maximum eigenvalue of a symmetric matrix OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's some.",
                    "label": 0
                },
                {
                    "sent": "Here's some of the calculus rules well.",
                    "label": 0
                },
                {
                    "sent": "Any some of these are totally obvious, right?",
                    "label": 0
                },
                {
                    "sent": "And when you teach this this is you always start with the obvious ones you know.",
                    "label": 0
                },
                {
                    "sent": "Look if you add if you add two convex functions together, the result is convex.",
                    "label": 0
                },
                {
                    "sent": "Will sure you know, do things, have furniture and Adam together.",
                    "label": 0
                },
                {
                    "sent": "So does this sum.",
                    "label": 0
                },
                {
                    "sent": "If you scale by a non negative.",
                    "label": 0
                },
                {
                    "sent": "Parameter obviously that preserves convexity affine composition.",
                    "label": 0
                },
                {
                    "sent": "That's very straightforward pointwise maximum that's that straightforward partial minimization that says if you have a function which is convex in jointly in two arguments and you minimize over one, the result is convex.",
                    "label": 0
                },
                {
                    "sent": "In the other.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are all completely straightforward to show.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are all very straightforward.",
                    "label": 0
                },
                {
                    "sent": "Position.",
                    "label": 0
                },
                {
                    "sent": "If you have a convex increasing function of a convex function, the result is convex, so there's more of these.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to list anymore, but you list a bunch of these things and then the idea is you take these atoms, which are these basic functions and things, and then you combine them with these calculus rules and make all sorts of interesting functions right, so that would be the idea.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I mean just we can go over this quickly because I think it's all kind of obvious.",
                    "label": 0
                },
                {
                    "sent": "But you can do things like this here.",
                    "label": 0
                },
                {
                    "sent": "There's a piecewise linear function expresses the maximum of bunch of afine functions that works because Max is convex, and then the argument is afaan, so that works fine.",
                    "label": 0
                },
                {
                    "sent": "There's one, the lasso cost, right?",
                    "label": 0
                },
                {
                    "sent": "So it's a it's a sum of squares plus oven affine function plus Lambda times to One North.",
                    "label": 0
                },
                {
                    "sent": "Or hear the sum of the K largest elements of affective.",
                    "label": 0
                },
                {
                    "sent": "Right, so that would be that's convex and you can check that because it's a maximum over certain things.",
                    "label": 0
                },
                {
                    "sent": "And by the way here, if you want just for fun, you can have the sum of the largest 3.2 elements of a vector.",
                    "label": 0
                },
                {
                    "sent": "You know what that is?",
                    "label": 0
                },
                {
                    "sent": "What do you imagine is the sum of the three point 2 largest elements of effective?",
                    "label": 0
                },
                {
                    "sent": "That's it, OK, that's it.",
                    "label": 0
                },
                {
                    "sent": "So now you know what the largest 3.2.",
                    "label": 0
                },
                {
                    "sent": "The large 20 elements of vectors and it's convex, OK as a function of X OK.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it turns out there's a general composition rule.",
                    "label": 0
                },
                {
                    "sent": "And the general composition rule is this, and it turns out actually.",
                    "label": 0
                },
                {
                    "sent": "Here's the good news.",
                    "label": 0
                },
                {
                    "sent": "It subsumes all others.",
                    "label": 0
                },
                {
                    "sent": "There's actually only one rule.",
                    "label": 0
                },
                {
                    "sent": "It turns out only one.",
                    "label": 0
                },
                {
                    "sent": "It's this if you know this, you're done.",
                    "label": 0
                },
                {
                    "sent": "In fact, you should.",
                    "label": 0
                },
                {
                    "sent": "We should print little cards and then you keep this in your wallet or something you know, along with your Emacs.",
                    "label": 0
                },
                {
                    "sent": "You know Google Card or something, right?",
                    "label": 0
                },
                {
                    "sent": "This is it?",
                    "label": 0
                },
                {
                    "sent": "This is 1.",
                    "label": 0
                },
                {
                    "sent": "It's very simple.",
                    "label": 0
                },
                {
                    "sent": "It says that if you have a convex function of multiple arguments, then it's convex.",
                    "label": 0
                },
                {
                    "sent": "When the following occurs, you walk you.",
                    "label": 0
                },
                {
                    "sent": "Iterate across its arguments and you test the following.",
                    "label": 0
                },
                {
                    "sent": "Either the argument is outlined, in which case it's done and you can even imagine code for this very easily, right?",
                    "label": 0
                },
                {
                    "sent": "Or this H is increasing in this argument and this thing is convex or it's decreasing and it's concave.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's it.",
                    "label": 0
                },
                {
                    "sent": "Now let me I can explain for example.",
                    "label": 0
                },
                {
                    "sent": "Here's a how do you know that I'll use this, which is a sledgehammer to show that the sum of two convex functions is convex ready.",
                    "label": 0
                },
                {
                    "sent": "I mean it's really stupid, but here it is.",
                    "label": 0
                },
                {
                    "sent": "Here's a function ready.",
                    "label": 0
                },
                {
                    "sent": "It's the sum of two numbers, it's convex, and it's increasing in both arguments, so therefore it can take as arguments if two convex functions in the SFA.",
                    "label": 0
                },
                {
                    "sent": "Good thing for Max, right?",
                    "label": 0
                },
                {
                    "sent": "So most of these things I mean, that's kind of.",
                    "label": 0
                },
                {
                    "sent": "That's kind of pedantic to save it's it's much simpler to simply say the maximum of two convex functions is fun facts, but in fact it all follows from this one thing here.",
                    "label": 0
                },
                {
                    "sent": "OK, so in fact this subsumes all the others.",
                    "label": 0
                },
                {
                    "sent": "There's a few, it doesn't, but we're not going to look at them.",
                    "label": 0
                },
                {
                    "sent": "But it subsumes almost all the others, and in fact, it turns out it's the same as the partial minimization rule.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this leads us to constructive convexity verification.",
                    "label": 0
                },
                {
                    "sent": "So what you do the idea is you start with a function given as an expression right?",
                    "label": 0
                },
                {
                    "sent": "And by the way, this is already a quite a bit of a difference from what you would normally think about.",
                    "label": 0
                },
                {
                    "sent": "I mean when people when you think about functions when you teach optimization, when you do machine learning and all that, the normal into the methods you associate with the function are things like this.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you want to think in terms of object or you think well for a function, FI should be able to compute its value.",
                    "label": 0
                },
                {
                    "sent": "I should be able to compute, for example, a gradient or a subgradient, maybe a second derivative, but these are methods right?",
                    "label": 0
                },
                {
                    "sent": "That you would, but in fact I think probably the right way to do this.",
                    "label": 0
                },
                {
                    "sent": "Is this a different way of thinking about you?",
                    "label": 0
                },
                {
                    "sent": "Actually think of it as an expression so, so we'll start with the function given as an expression, and then you build a parse tree for it, and then the leaves are variables or constants and parameters, right?",
                    "label": 0
                },
                {
                    "sent": "And then the nodes are functions of the children, so these are subexpressions, right?",
                    "label": 0
                },
                {
                    "sent": "And what we'll do is this.",
                    "label": 0
                },
                {
                    "sent": "For constructive convexity verification will insist that every every single subexpression it's convexity or concavity, or whatever it is actually follows locali.",
                    "label": 0
                },
                {
                    "sent": "In other words, it basically follows by using that one rule on its children, so it's completely local, right?",
                    "label": 0
                },
                {
                    "sent": "No side effects noted.",
                    "label": 0
                },
                {
                    "sent": "Look, this is the idea.",
                    "label": 0
                },
                {
                    "sent": "We're going to see some examples and what you can do then is now it is, it's completely elementary.",
                    "label": 0
                },
                {
                    "sent": "To walk a function to wauka to Parsa, to walk a parse tree, and to determine whether or not it is constructively convex.",
                    "label": 0
                },
                {
                    "sent": "Now what this gives you is you gives you.",
                    "label": 0
                },
                {
                    "sent": "Obviously it's a sufficient method for convexity, and it is by no means necessary.",
                    "label": 0
                },
                {
                    "sent": "An elementary examples show this.",
                    "label": 0
                },
                {
                    "sent": "I mean, you could do things like.",
                    "label": 0
                },
                {
                    "sent": "Here's one.",
                    "label": 0
                },
                {
                    "sent": "This is really dumb and X ^2 -- X ^2.",
                    "label": 0
                },
                {
                    "sent": "That's convex, right?",
                    "label": 0
                },
                {
                    "sent": "But I mean come on, this is stupid, right?",
                    "label": 0
                },
                {
                    "sent": "That's not the point.",
                    "label": 0
                },
                {
                    "sent": "In fact, my argument is X ^2 -- X ^2 should be flagged as.",
                    "label": 0
                },
                {
                    "sent": "Not constructively convex, because it's not right anymore than square root 1 + X ^2 is it's not constructively convex, so so another way to say it actually is that these are.",
                    "label": 0
                },
                {
                    "sent": "It's a it's a subclass of convex functions and it's not really a function right?",
                    "label": 0
                },
                {
                    "sent": "It's because it's a it has to do with.",
                    "label": 0
                },
                {
                    "sent": "It's the expression actually, so it's it's a language.",
                    "label": 0
                },
                {
                    "sent": "In fact is what it is.",
                    "label": 0
                },
                {
                    "sent": "It's a language generated by a set of atoms in these rules, and that's it then.",
                    "label": 0
                },
                {
                    "sent": "It just generates a bunch of valid strings or valid expressions.",
                    "label": 0
                },
                {
                    "sent": "These are the constructively convex functions.",
                    "label": 0
                },
                {
                    "sent": "OK, another way to say it, by the way, is that.",
                    "label": 0
                },
                {
                    "sent": "The these are expressions which are syntactically convex syntactically means this that the fact that they are convex does not that you don't have to understand even what the functions mean.",
                    "label": 0
                },
                {
                    "sent": "You don't have to know what log means.",
                    "label": 0
                },
                {
                    "sent": "The only thing you need about log is the following.",
                    "label": 0
                },
                {
                    "sent": "It's concave and it's increasing.",
                    "label": 0
                },
                {
                    "sent": "You could replace it with square root.",
                    "label": 0
                },
                {
                    "sent": "And it would still work.",
                    "label": 0
                },
                {
                    "sent": "Everybody what I'm saying here so you don't need to know the meaning of it right?",
                    "label": 0
                },
                {
                    "sent": "So OK, now there's a couple of variations on this.",
                    "label": 0
                },
                {
                    "sent": "Well, in one variation you can tag subexpression signs and then this would if you tag signs, you can use the signs to flag things like the monotonicity.",
                    "label": 0
                },
                {
                    "sent": "So for example, the square function is not monotone, obviously, but if I tell you that it's argument is positive, then it's monotone right?",
                    "label": 0
                },
                {
                    "sent": "This makes a big difference because.",
                    "label": 0
                },
                {
                    "sent": "If you you if you don't do that square of square of X is not constructively convex because square of X is but square of square is not.",
                    "label": 0
                },
                {
                    "sent": "Right because square being non non increasing non monotone has to take his argument in affine function and square is not but it is with the if you flag if you flag the signs OK so OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's do an example.",
                    "label": 0
                },
                {
                    "sent": "This is just for, you know, just for fun, here's an expression.",
                    "label": 0
                },
                {
                    "sent": "Here's an expression involving two variables and.",
                    "label": 0
                },
                {
                    "sent": "This is the domain of this, but in fact it will see that.",
                    "label": 0
                },
                {
                    "sent": "We'll see later that when you do this, actually all the domain stuff just works perfectly, so you don't.",
                    "label": 0
                },
                {
                    "sent": "There's no, it's actually harder to save them at the same mathematically than it is to actually write code to actually handle all this.",
                    "label": 0
                },
                {
                    "sent": "So handled this perfectly.",
                    "label": 0
                },
                {
                    "sent": "OK, so the way you do is you start with the leaves.",
                    "label": 0
                },
                {
                    "sent": "It should be like XY and one.",
                    "label": 0
                },
                {
                    "sent": "You look at the bottom level subexpression would be this.",
                    "label": 0
                },
                {
                    "sent": "Can you mark that is can you mark that is convex?",
                    "label": 1
                },
                {
                    "sent": "Right then you maybe look at 1 minus that and you'd say, well, that's a constant.",
                    "label": 1
                },
                {
                    "sent": "Will doesn't matter, you can promote it to convex or whatever, or not, but constant minus convex concave.",
                    "label": 0
                },
                {
                    "sent": "OK, so this thing is concave and then you recognize this as this quadratic over linear function, and that's convex.",
                    "label": 0
                },
                {
                    "sent": "The argument on top is ifying the argument in the bottom is come Kate and that's fine because because you squared over V or something like that.",
                    "label": 0
                },
                {
                    "sent": "He's coming back tomorrow and decreasing so it can take.",
                    "label": 1
                },
                {
                    "sent": "You can take a concave argument, so that's yeah, but the point about this is it involves absolutely no thought whatsoever.",
                    "label": 0
                },
                {
                    "sent": "It's pure syntax and looking stuff up none.",
                    "label": 0
                },
                {
                    "sent": "You don't have to understand any of this.",
                    "label": 0
                },
                {
                    "sent": "So in fact you can switch Max for any other two argument.",
                    "label": 0
                },
                {
                    "sent": "Any other two argument functions with the same properties, namely convex and increasing in both arguments.",
                    "label": 1
                },
                {
                    "sent": "So to make it some or anything you like, you can make it log some experts and.",
                    "label": 0
                },
                {
                    "sent": "It would just be the same.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is just to make it absolute certain that the goal here is not to identify convex functions.",
                    "label": 0
                },
                {
                    "sent": "That is not the goal, right?",
                    "label": 0
                },
                {
                    "sent": "That's it?",
                    "label": 0
                },
                {
                    "sent": "That's a completely different goal, and this is not that is an example.",
                    "label": 0
                },
                {
                    "sent": "Everybody knows that that's convex, but you can't show this using constructive convex analysis, right?",
                    "label": 1
                },
                {
                    "sent": "Because I mean if you go from the bottom, that's OK, that's OK, the sum is convex, but you have no rule.",
                    "label": 0
                },
                {
                    "sent": "There's no, there's, there's no method that handles basically square root of convex.",
                    "label": 0
                },
                {
                    "sent": "None for good reason, because square root of convex can be anything.",
                    "label": 0
                },
                {
                    "sent": "In fact with different with different functions put in there right?",
                    "label": 0
                },
                {
                    "sent": "It could be convex.",
                    "label": 0
                },
                {
                    "sent": "OK, it could be neither.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is this doesn't work, but you simply write this like this if you want to use something like this, OK. OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we get to the idea of discipline convex program.",
                    "label": 0
                },
                {
                    "sent": "And so the idea is it's just a framework for describing convex optimization problems.",
                    "label": 0
                },
                {
                    "sent": "It's based on constructive convex analysis, and of course it's sufficient but not necessary for convexity and it's the basis of a lot of a growing number of domain specific languages and tools for convex optimization.",
                    "label": 0
                },
                {
                    "sent": "So I mean, you might as well get used to this 'cause you maybe already have seen it or will see it and things like that in more and more things.",
                    "label": 0
                },
                {
                    "sent": "What's nice about it is it's so easy to check.",
                    "label": 0
                },
                {
                    "sent": "Right, that it's just that it doesn't involve any.",
                    "label": 0
                },
                {
                    "sent": "There's no semantics, it's just syntactic.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is a DCP look like?",
                    "label": 0
                },
                {
                    "sent": "I mean abstractly, it's a disciplined convex program and have an objective which is either minimize convex expression or maximize that concave expression and they can have a bunch of constraints and they can only look like this expression relative expression.",
                    "label": 0
                },
                {
                    "sent": "But the only the only obvious the only ones you can do or convex less than concave, concave, bigger than convex or afine equals equals F1.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "So even all the way up to here this is a mean, so you can if you want to imagine something like a Backus naur form.",
                    "label": 0
                },
                {
                    "sent": "For this for a language this is essentially it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the expressions are going to be formed from variables, constants or parameters and functions from a library and the library functions have known convexity monotonicity inside properties.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "And the idea is that all subexpressions match the general composition rule, right?",
                    "label": 0
                },
                {
                    "sent": "So so this is a language that we've just defined.",
                    "label": 0
                },
                {
                    "sent": "I mean depends on your library, but this is.",
                    "label": 0
                },
                {
                    "sent": "This is literally a language.",
                    "label": 0
                },
                {
                    "sent": "You could write a parser for it.",
                    "label": 0
                },
                {
                    "sent": "Well, it's easy to write a parser for.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that a valid DCP it's convex by construction, right?",
                    "label": 0
                },
                {
                    "sent": "And by the way, this is completely different from what you might imagine.",
                    "label": 0
                },
                {
                    "sent": "You would want to do, and I like 15 years ago.",
                    "label": 0
                },
                {
                    "sent": "I'm working with various students.",
                    "label": 0
                },
                {
                    "sent": "We imagine that you'd really like to do and there are people who think this is what you want to do is someone should write what they want to do.",
                    "label": 0
                },
                {
                    "sent": "They should they want to minimize this subject to this and you should take what it is that they want and then make an attempt to verify convexity in order to transform it into a convex problem if possible.",
                    "label": 0
                },
                {
                    "sent": "Everybody following this right so?",
                    "label": 0
                },
                {
                    "sent": "Actually, I mean you can do all sorts of stuff with that.",
                    "label": 0
                },
                {
                    "sent": "That's a very complex problem, and it turns out actually, the more you think about it, the more you realize in the end it's a very complex problem, and in fact that's not the way it should be done.",
                    "label": 0
                },
                {
                    "sent": "'cause I had very students who worked on this, including one who.",
                    "label": 0
                },
                {
                    "sent": "Worked out some huge system that bounded.",
                    "label": 0
                },
                {
                    "sent": "Basically it was the interval arithmetic on 2nd derivatives, which is which is all you're doing if you're doing convexity analysis and he walked into my office one day and he wrote this horrible expression on the board with like hyperbolic cosines and all sorts of other stuff, big thing and he said did you know that was convex and I said Nope, you know an his this thing he'd written, you know, took only something like you know the proof of convexity with some 700 passes through something where it tightened bounds and.",
                    "label": 0
                },
                {
                    "sent": "Literally went through this and then we looked and we both looked at it for quite awhile and we said that's cool and then after a while we both turned each other.",
                    "label": 0
                },
                {
                    "sent": "He said that's cool and completely useless right?",
                    "label": 0
                },
                {
                    "sent": "Because I mean this, this was not a way to do something you wouldn't do that right?",
                    "label": 0
                },
                {
                    "sent": "Because I mean, first of all, it's not maintainable, right?",
                    "label": 0
                },
                {
                    "sent": "Because the point is that big expression was convex.",
                    "label": 0
                },
                {
                    "sent": "But who the hell that no one knows why it's convex, right?",
                    "label": 0
                },
                {
                    "sent": "I mean you change one parameter from half to 3/4 and it's no longer convex and so on, whereas this is dumb enough.",
                    "label": 0
                },
                {
                    "sent": "It's on its face.",
                    "label": 0
                },
                {
                    "sent": "It's not anywhere so alright, so that's that's posterior convexity analysis, right?",
                    "label": 0
                },
                {
                    "sent": "And so I've already mentioned all these things, right?",
                    "label": 0
                },
                {
                    "sent": "This is what this is.",
                    "label": 0
                },
                {
                    "sent": "OK, so I mean, this is a very simple idea.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look at cone representation.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pioneer done actually by so.",
                    "label": 0
                },
                {
                    "sent": "So here it is, a common representation and like I said, all the things I'm talking about are going to come together.",
                    "label": 0
                },
                {
                    "sent": "Trust me.",
                    "label": 0
                },
                {
                    "sent": "OK, so a common representation of a convex function is this.",
                    "label": 0
                },
                {
                    "sent": "It says you want to represent a function as the optimal value of a cone program in two sets of variables X&Y.",
                    "label": 0
                },
                {
                    "sent": "But you you minimize over why so it's the partial minimization rule, which in fact is the same as our general general composition rule, so that's a hint that these are going to be related so.",
                    "label": 1
                },
                {
                    "sent": "So you want to write it as the optimal value of something like like this OK. And I mean anything you define this way is convex.",
                    "label": 0
                },
                {
                    "sent": "But Conversely many things that any many functions that you're interested in.",
                    "label": 0
                },
                {
                    "sent": "You can write this way.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the idea.",
                    "label": 0
                },
                {
                    "sent": "OK, here's some examples.",
                    "label": 0
                },
                {
                    "sent": "Well let.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See the negative geometric mean that's convex function and it's the optimal value of this SDP where you minimize over over here, why and why next?",
                    "label": 0
                },
                {
                    "sent": "Sorry, yeah, so why next to friends, right?",
                    "label": 0
                },
                {
                    "sent": "So empty, so you get that?",
                    "label": 0
                },
                {
                    "sent": "How about the sum of the K largest entries?",
                    "label": 0
                },
                {
                    "sent": "Well, that's the option.",
                    "label": 0
                },
                {
                    "sent": "You could check that's the optimal value of the following linear program.",
                    "label": 0
                },
                {
                    "sent": "That's here, where the variables are Lambda, mu and Nu.",
                    "label": 0
                },
                {
                    "sent": "So that's that's the idea, and the point is, this is a linear program in everything in X, Lambda, mu, Nu.",
                    "label": 0
                },
                {
                    "sent": "But you only optimize here over Lambda Mu Nu and the resulting function which is partial minimization, is in fact the sum of the K largest entries events.",
                    "label": 0
                },
                {
                    "sent": "OK, so by the way, these kind of hint that these are not totally obvious, some of these things so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yuri and many others that worked out.",
                    "label": 0
                },
                {
                    "sent": "Actually not that many others.",
                    "label": 0
                },
                {
                    "sent": "I have worked out SDP representations alot of a lot of functions right?",
                    "label": 0
                },
                {
                    "sent": "So I think like powers you know determinant to the 1 / N the sum of the K largest eigenvalues the norm.",
                    "label": 0
                },
                {
                    "sent": "I mean some of these are easier than others.",
                    "label": 0
                },
                {
                    "sent": "The dual norm sometimes called the tracer nuclear norm.",
                    "label": 0
                },
                {
                    "sent": "Something like that I guess is playing a big role now and various low rank approximation type things OK Alright.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Canonicalization So what?",
                    "label": 0
                },
                {
                    "sent": "You?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you start the idea of meeting with the idea of canonicalization is you start with the problem in DCP form with cone representable library.",
                    "label": 0
                },
                {
                    "sent": "OK, so you start with that and the goal is to automatically transform it to account to an equivalent cone program, right?",
                    "label": 0
                },
                {
                    "sent": "So that's that's the big picture.",
                    "label": 0
                },
                {
                    "sent": "So let's see how you.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, it's actually embarrassingly simple.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not unsophisticated, but it is embarrassingly simple.",
                    "label": 0
                },
                {
                    "sent": "It goes like this.",
                    "label": 0
                },
                {
                    "sent": "What you do is you take the parse tree of every function appearing in your problem statement, every single one, and then you simply it's a macro substitution that whenever you see F appearing in a parse tree, and it's got this cone representation, then you simply do the following.",
                    "label": 0
                },
                {
                    "sent": "You add a new variable Y.",
                    "label": 0
                },
                {
                    "sent": "You add this constraint and that constraint, and you replace F with this app line expression.",
                    "label": 0
                },
                {
                    "sent": "You do nothing else.",
                    "label": 0
                },
                {
                    "sent": "Blind macro you can write.",
                    "label": 0
                },
                {
                    "sent": "You can actually if you can.",
                    "label": 0
                },
                {
                    "sent": "You can imagine 2 lines of code in any modern language will do this for you to write.",
                    "label": 0
                },
                {
                    "sent": "Basically you know constraints plus equals that new variable.",
                    "label": 0
                },
                {
                    "sent": "Why constraints plus equals that constraint plus equals that and return that.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "OK, so now that's a constructive thing.",
                    "label": 0
                },
                {
                    "sent": "So if you do this though, you yield it.",
                    "label": 0
                },
                {
                    "sent": "You end up with a problem, you eliminate any non affine functions.",
                    "label": 0
                },
                {
                    "sent": "And So what it means in the end, you end up with a problem that has only affine constraints and cone constraints, and there's a name for those problems there, called cone programs.",
                    "label": 0
                },
                {
                    "sent": "Everybody following this.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea, and it turns out this is just a mechanical, you know, macro replacement.",
                    "label": 0
                },
                {
                    "sent": "Another question is, how do you know when you do this, that the new problem is equivalent to the old one?",
                    "label": 0
                },
                {
                    "sent": "Well, the new problem, by the way, is always the convex relaxation of the of the original one.",
                    "label": 0
                },
                {
                    "sent": "But if this is where you need the DCP requirements, the monotonicity.",
                    "label": 0
                },
                {
                    "sent": "Right, if the monotonicity assumptions hold, that's the exactly the condition that this transform problem is equivalent to the original 1.",
                    "label": 0
                },
                {
                    "sent": "So these are these are connected.",
                    "label": 0
                },
                {
                    "sent": "OK, and so, by the way, if you think about what this does, it means that you've we've made with this.",
                    "label": 0
                },
                {
                    "sent": "This is it.",
                    "label": 0
                },
                {
                    "sent": "You've automated now DCP analysis and that canonicalization.",
                    "label": 0
                },
                {
                    "sent": "Canonicalization means to go from a problem description to economical to an equivalent Canonical form.",
                    "label": 0
                },
                {
                    "sent": "So it's completely automated.",
                    "label": 0
                },
                {
                    "sent": "And not only that, it's like I don't know.",
                    "label": 0
                },
                {
                    "sent": "I've seen people implement things like this like full on working systems that look like CBX in 200 lines of a modern language.",
                    "label": 0
                },
                {
                    "sent": "So it's really straightforward.",
                    "label": 0
                },
                {
                    "sent": "I mean, once you know this, which there's not much to know, it's just this.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's look a little bit deeper at how you might.",
                    "label": 0
                },
                {
                    "sent": "You know what you do.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These things well.",
                    "label": 0
                },
                {
                    "sent": "Some of these you can use that you can make it build yourself a parser solver and that would be things like CVS or Youngman.",
                    "label": 0
                },
                {
                    "sent": "Actually, how many people have used either of these?",
                    "label": 0
                },
                {
                    "sent": "So a bunch and the others do it just to see what they look like.",
                    "label": 0
                },
                {
                    "sent": "I mean this refund or I mean I mean both of these run in Matlab and have a problem with that.",
                    "label": 0
                },
                {
                    "sent": "Which is fine.",
                    "label": 0
                },
                {
                    "sent": "I do too.",
                    "label": 0
                },
                {
                    "sent": "There's other versions.",
                    "label": 0
                },
                {
                    "sent": "Is PBX pie or something like that and play with.",
                    "label": 0
                },
                {
                    "sent": "So what these do is these are parser solvers because they don't allow abstract parameters, the IT takes a an instantiate it.",
                    "label": 0
                },
                {
                    "sent": "It takes a problem instance, it checks DCP if it satisfies DCP.",
                    "label": 0
                },
                {
                    "sent": "It actually generates a cone program and then solves that instance immediately using one of the open source code solver like said to me you SDPT 3, so that's what that does.",
                    "label": 0
                },
                {
                    "sent": "OK, now you can also do a parser generator.",
                    "label": 0
                },
                {
                    "sent": "So parser generator.",
                    "label": 0
                },
                {
                    "sent": "That is something that supports parameters and so you describe a problem family, not a problem instance of problem family.",
                    "label": 0
                },
                {
                    "sent": "So you say A is a parameter is a Lambda is a parameter and its positive right?",
                    "label": 0
                },
                {
                    "sent": "If you don't tell them it's positive PCP, it can't verify DCP and what happens is you canonicalize the problem family.",
                    "label": 0
                },
                {
                    "sent": "That's what symbolic parameters will see.",
                    "label": 0
                },
                {
                    "sent": "Examples of this and then what you end up doing in this case is.",
                    "label": 0
                },
                {
                    "sent": "Well, you don't solve the problem because the problem hasn't been instantiating you.",
                    "label": 0
                },
                {
                    "sent": "What you do is you end up you end up what you can do is you can as well as several ways to do this, but you can generate the mapping that Maps the original problem to the cone program, right?",
                    "label": 0
                },
                {
                    "sent": "That's just a function that does this mapping and then then you have several things you could do if you connect that to a custom generated solver, you have a code generator, or you could connect it to a generic solver and now you you would have something like.",
                    "label": 0
                },
                {
                    "sent": "Umm, which I will look at.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the idea.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples will look at we use this same baby.",
                    "label": 0
                },
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "And of course, I guess the whole point of these things in these domain specific languages is that in a very short inline script you can actually describe quite complicated problems when it would be a super duper pain in the ass to handle otherwise right?",
                    "label": 0
                },
                {
                    "sent": "I mean to to actually manually transform, I mean this one is not that hard to transform, frankly, right?",
                    "label": 0
                },
                {
                    "sent": "But it's so it fits on half a page or something, so here it is.",
                    "label": 0
                },
                {
                    "sent": "You want to minimize a lasso objective and for some reason you all your parameters have to be less than one in absolute value.",
                    "label": 0
                },
                {
                    "sent": "I mean just we made it up so.",
                    "label": 0
                },
                {
                    "sent": "So here the idea is the variables X and the constants and parameters are a B and Lambda lambdas positive.",
                    "label": 0
                },
                {
                    "sent": "Otherwise this is not convex.",
                    "label": 0
                },
                {
                    "sent": "Or to be quite precise, need not be might not be right so.",
                    "label": 0
                },
                {
                    "sent": "So and the goal of course, in designing a language is to have the you should line up the math and latech on one side and the source code on the other, and you should be able to look left and right and say that's the same, right?",
                    "label": 0
                },
                {
                    "sent": "That's that's the goal of a domain specific language, right?",
                    "label": 0
                },
                {
                    "sent": "I mean if you see some obscur code on the right and you have to actually think hard, that's not, that's not a success, OK?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's what CBS looks like.",
                    "label": 0
                },
                {
                    "sent": "This is developed by Michael Grant maybe seven years ago.",
                    "label": 0
                },
                {
                    "sent": "I guess me maybe seven years, something like that that's embedded in Matlab that targets multiple cone solvers, and the this is the CVS specification for that example problem.",
                    "label": 0
                },
                {
                    "sent": "So and here the presumption is that a B and Lambda are actually their numeric constants, right?",
                    "label": 0
                },
                {
                    "sent": "Not only that, but land is positive, right?",
                    "label": 0
                },
                {
                    "sent": "If land is not positive, you'll get an error right here, and this will be flagged and it'll say there's a DCP.",
                    "label": 0
                },
                {
                    "sent": "They'll be a DCP error and the DCP error if Lando is minus, one would be a very simple one.",
                    "label": 0
                },
                {
                    "sent": "It would say, and hopefully I believe it's the error is actually correct.",
                    "label": 0
                },
                {
                    "sent": "It says the following.",
                    "label": 0
                },
                {
                    "sent": "It basically says I don't know how to add a convex and concave function and notice what it doesn't say.",
                    "label": 0
                },
                {
                    "sent": "It doesn't say that's not convex.",
                    "label": 0
                },
                {
                    "sent": "So because it might be if Andy were zero and it doesn't matter anyway, we'll leave that Elvis leave that alone.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea.",
                    "label": 0
                },
                {
                    "sent": "So it takes this, it parses it economic.",
                    "label": 0
                },
                {
                    "sent": "Lisa generates a cone program and then that would be solved by SDPT 3 or said to me or something like that.",
                    "label": 0
                },
                {
                    "sent": "Oh I, I should mention a couple of things there related to this.",
                    "label": 0
                },
                {
                    "sent": "When we first looked at things like this, we assume I mean what happens is actually quite hilarious.",
                    "label": 0
                },
                {
                    "sent": "It just get rid of this and this and now you have a least squares problem, right?",
                    "label": 0
                },
                {
                    "sent": "That's the oldest optimization problem there is.",
                    "label": 0
                },
                {
                    "sent": "I mean, Down's wrote a book in Latin about this.",
                    "label": 0
                },
                {
                    "sent": "And like you know, 1805 or something, right?",
                    "label": 0
                },
                {
                    "sent": "I mean ridiculous.",
                    "label": 0
                },
                {
                    "sent": "As an exact solution and all that kind of stuff if you type it into CBX, it's hilarious.",
                    "label": 0
                },
                {
                    "sent": "You know it comes out.",
                    "label": 0
                },
                {
                    "sent": "It dutifully transforms it into it.",
                    "label": 0
                },
                {
                    "sent": "Until like a second order cone program, so you started with the world's simplest convex optimization problem, at least squares problem and the next thing you know now it's a second order cone program with more variables.",
                    "label": 0
                },
                {
                    "sent": "Everyone following this.",
                    "label": 0
                },
                {
                    "sent": "So this doesn't sound good, right?",
                    "label": 0
                },
                {
                    "sent": "OK, and then you might ask your question.",
                    "label": 0
                },
                {
                    "sent": "Well, how much slower is it to solve?",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "And the answer is basically generally not at all.",
                    "label": 0
                },
                {
                    "sent": "And the reason is very simple when when you generate when you do this canonicalization, you do end up you start with the problem with thousand variables and then if you have.",
                    "label": 0
                },
                {
                    "sent": "If you do even care and you look at it, you'll see that the new problem has 15,000 variables.",
                    "label": 0
                },
                {
                    "sent": "Everybody following this, anything that's not good.",
                    "label": 0
                },
                {
                    "sent": "About the 50 does have 15,000 variables, but it's extremely sparse, right?",
                    "label": 0
                },
                {
                    "sent": "And in fact, modern sparsity loading methods are able to get back basically all of the.",
                    "label": 0
                },
                {
                    "sent": "In most cases there's cases where it fails, but mostly it recovers all of it.",
                    "label": 0
                },
                {
                    "sent": "OK, that was just in the side, sorry, OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here would be some functions in the CBS library.",
                    "label": 0
                },
                {
                    "sent": "Those of you have looked at it would know about this.",
                    "label": 0
                },
                {
                    "sent": "Would you get some weird thing?",
                    "label": 0
                },
                {
                    "sent": "I mean, some of these we put?",
                    "label": 0
                },
                {
                    "sent": "I mean no ones ever, as far as I know, no ones ever used that for any practical purpose that somebody might do it just to show off or something like that.",
                    "label": 0
                },
                {
                    "sent": "But so half the functions in there just in there to be bizarre and weird.",
                    "label": 0
                },
                {
                    "sent": "Just because we could, you know, like this, some of the five largest eigenvalues of a matrix or something.",
                    "label": 0
                },
                {
                    "sent": "So OK, so this is the idea.",
                    "label": 0
                },
                {
                    "sent": "And then these are the attributes.",
                    "label": 0
                },
                {
                    "sent": "That's the signature of the function.",
                    "label": 0
                },
                {
                    "sent": "OK CVS gym.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's a code generator, which probably far far fewer of you have seen, and probably.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'll tell you what it is.",
                    "label": 0
                },
                {
                    "sent": "So CDX Jen.",
                    "label": 0
                },
                {
                    "sent": "That's a parser generator, no sound like just a couple of years ago by a student of mine Jacob, and again has domain specific input and instead of, but it takes a family's argument, not an instance.",
                    "label": 0
                },
                {
                    "sent": "And then what it does is it generates.",
                    "label": 0
                },
                {
                    "sent": "Actually it generates entirely black.",
                    "label": 0
                },
                {
                    "sent": "See actually library free.",
                    "label": 0
                },
                {
                    "sent": "You don't even need the math library if you turn verbose off and the only thing you need from the math libraries math that square root.",
                    "label": 0
                },
                {
                    "sent": "To display a normal.",
                    "label": 0
                },
                {
                    "sent": "It's library free black see, so it's actually perfect for embedded things, right?",
                    "label": 0
                },
                {
                    "sent": "Runs on arms and all sorts of other stuff anyway, so anyway, this is the idea, and so the idea is you type in a problem family.",
                    "label": 0
                },
                {
                    "sent": "This thing takes awhile and then outcomes CONA makefile and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "And then you compile it and now you have a super fast function that Maps parameters to solutions, but just for that one problem family everybody following this.",
                    "label": 0
                },
                {
                    "sent": "That's the idea.",
                    "label": 0
                },
                {
                    "sent": "You can do that in stuff like CVS, but I mean that would be.",
                    "label": 0
                },
                {
                    "sent": "To say that's inappropriate for embedded applications is a huge understatement.",
                    "label": 0
                },
                {
                    "sent": "Even though it is actually used in embedded applications.",
                    "label": 0
                },
                {
                    "sent": "Much to my shock and horror.",
                    "label": 0
                },
                {
                    "sent": "But it is so OK.",
                    "label": 0
                },
                {
                    "sent": "This is what?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Xgen looks like.",
                    "label": 0
                },
                {
                    "sent": "And the source once you start once you understand all these things, these languages all start looking the same as they are all the same.",
                    "label": 0
                },
                {
                    "sent": "Basically it looks like this.",
                    "label": 0
                },
                {
                    "sent": "Yeah parameters and you declare landing posit, but notice here their parameters.",
                    "label": 0
                },
                {
                    "sent": "You haven't said what Lambda is yet.",
                    "label": 0
                },
                {
                    "sent": "Right whereas in CVX, you say what Lambda is right here, it has no value.",
                    "label": 0
                },
                {
                    "sent": "You give the variables here and then there's the kinds completely readable, right means obvious what it means, and the idea here is that avian Lambda are symbolic parameters.",
                    "label": 0
                },
                {
                    "sent": "What comes out is just flaxy.",
                    "label": 0
                },
                {
                    "sent": "Which you compile and now you have a solver for that specific problem.",
                    "label": 0
                },
                {
                    "sent": "So if you wanted for a small problem like the world's fastest lasso solver, this would generate, right?",
                    "label": 0
                },
                {
                    "sent": "So you do this, and these are.",
                    "label": 0
                },
                {
                    "sent": "I mean even these numbers are behind, but it gives you roughly the idea.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you take little Caesar baby problems with a couple 100 variables, But this would go up to several thousands and things like that or whatever, and you have.",
                    "label": 0
                },
                {
                    "sent": "Typically you can solve that and you know 1/3 of a second or a half of a second or something.",
                    "label": 0
                },
                {
                    "sent": "You know that's not bad, right?",
                    "label": 0
                },
                {
                    "sent": "But the typical speed up is about 1000 X.",
                    "label": 0
                },
                {
                    "sent": "Be the typical one, so I mean it's not to mention that's not the real point.",
                    "label": 0
                },
                {
                    "sent": "The real point is extreme reliability also, and low software footprint, right?",
                    "label": 0
                },
                {
                    "sent": "So it's got you could never embed something like a CV X into some real time thing.",
                    "label": 0
                },
                {
                    "sent": "Or if someone did that, I would strongly advise you not to get in that vehicle.",
                    "label": 0
                },
                {
                    "sent": "Right 'cause I mean, it's just it's ridiculous, right?",
                    "label": 0
                },
                {
                    "sent": "So anyway?",
                    "label": 0
                },
                {
                    "sent": "So by the way, you might ask, how did you get 1000 to one?",
                    "label": 0
                },
                {
                    "sent": "We would love to take credit for it.",
                    "label": 0
                },
                {
                    "sent": "We take none.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the credit all the credit goes to our friends from my building, which is electrical engineering, is across the street.",
                    "label": 0
                },
                {
                    "sent": "The Computer science Department.",
                    "label": 0
                },
                {
                    "sent": "People who build compilers.",
                    "label": 0
                },
                {
                    "sent": "Right, so we tried to do all sorts of fancy things since we knew everything that was going to happen.",
                    "label": 0
                },
                {
                    "sent": "We re ordered the data and try to make it more, you know, make the memory accesses more local and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "When we turned on you turn on optimization and it just always beat us.",
                    "label": 0
                },
                {
                    "sent": "So what would happen is if we would do all this work.",
                    "label": 0
                },
                {
                    "sent": "And then you turn on optimization and it would be no better from the original 1.",
                    "label": 0
                },
                {
                    "sent": "So right now when we generate C source variables come out in the following order.",
                    "label": 0
                },
                {
                    "sent": "The order in which they are declared in the source, and then we let GCC minus oh 3 or whatever it is, deal with it right?",
                    "label": 0
                },
                {
                    "sent": "So that they are the ones actually there.",
                    "label": 0
                },
                {
                    "sent": "We checked and it because it's almost branch free code that compilers go insane.",
                    "label": 0
                },
                {
                    "sent": "So they just they love it, they reorder things and we have no idea what they're doing, but.",
                    "label": 0
                },
                {
                    "sent": "But it's all this is to make clear is you know somebody has to take credit for the 1000 to one improvement here.",
                    "label": 0
                },
                {
                    "sent": "And all I'm saying is I don't know who it is, but I know it's not us.",
                    "label": 0
                },
                {
                    "sent": "OK, well, except that we wrote except that we took the care to write C that was almost branch free.",
                    "label": 0
                },
                {
                    "sent": "So that was our part of it.",
                    "label": 0
                },
                {
                    "sent": "And then we just actually this is better this way because we didn't.",
                    "label": 0
                },
                {
                    "sent": "We were hoping.",
                    "label": 0
                },
                {
                    "sent": "We did if we if we were the ones starting to worry about memory locality and things like that, that would be not good 'cause.",
                    "label": 0
                },
                {
                    "sent": "What's that?",
                    "label": 0
                },
                {
                    "sent": "Air Force",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact we reverted.",
                    "label": 0
                },
                {
                    "sent": "This is a very.",
                    "label": 0
                },
                {
                    "sent": "This is a very old money.",
                    "label": 0
                },
                {
                    "sent": "This is not even the homogeneous embedding.",
                    "label": 0
                },
                {
                    "sent": "This is a very, very old simple one.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's much less generic actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah no.",
                    "label": 0
                },
                {
                    "sent": "It's in fact it's it's it's very unsophisticated.",
                    "label": 0
                },
                {
                    "sent": "The method we use.",
                    "label": 0
                },
                {
                    "sent": "And we're proud of it.",
                    "label": 0
                },
                {
                    "sent": "So we don't apologize so.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I'll tell you a little bit about.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A more recent one, this and this is sort of like work in progress, and the idea is to.",
                    "label": 0
                },
                {
                    "sent": "Make something that actually works.",
                    "label": 0
                },
                {
                    "sent": "You know that that actually is applies to many other things and also, by the way would allow us to do weird things like target.",
                    "label": 0
                },
                {
                    "sent": "I should say that the CBX Gen stuff it's made for embedded stuff, so it's single when it comes out of singles.",
                    "label": 0
                },
                {
                    "sent": "Red, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "But you might want to do something where you you might want to target like a GPU, right?",
                    "label": 0
                },
                {
                    "sent": "Or or an MPI cluster right?",
                    "label": 0
                },
                {
                    "sent": "Or for that matter, you might want to even generate like weird stuff that targets had two percent.",
                    "label": 0
                },
                {
                    "sent": "I mean, I.",
                    "label": 0
                },
                {
                    "sent": "You can imagine all these things right easily so.",
                    "label": 0
                },
                {
                    "sent": "So to do that, we decided to kind of start yet again.",
                    "label": 0
                },
                {
                    "sent": "Air 2 is writing something isn't Python, although he's he's written several times in many languages, just 'cause it only takes an afternoon once you know these things, it takes one afternoon, any language or any real language.",
                    "label": 0
                },
                {
                    "sent": "It's a right now it targets will see a target CVS, often Python is another target.",
                    "label": 0
                },
                {
                    "sent": "It does as well, but it can also do.",
                    "label": 0
                },
                {
                    "sent": "It can also generate source code for several targets, so it actually when you're developing these things, you always do that.",
                    "label": 0
                },
                {
                    "sent": "And actually the first source code you target is CDX.",
                    "label": 0
                },
                {
                    "sent": "So right gets you.",
                    "label": 0
                },
                {
                    "sent": "You parse something so you have something very sophisticated written in a real language.",
                    "label": 0
                },
                {
                    "sent": "It parses the thing and then admits Matlab source and so, but that's we do that just 'cause you need.",
                    "label": 0
                },
                {
                    "sent": "You need to test these things right, so OK, but the idea here is if you if this were done right, you'd end up with a seamless transition from prototyping the code generation.",
                    "label": 0
                },
                {
                    "sent": "We'd sit on your laptop and fiddle around and adjust something and mess with some parameters.",
                    "label": 0
                },
                {
                    "sent": "See if you like the trading algorithm you're developing or something like that.",
                    "label": 0
                },
                {
                    "sent": "And then you say I like it, I want to put it into production or it's a control algorithm.",
                    "label": 0
                },
                {
                    "sent": "You're doing simulations at say, 110th real time, and you say you know what I want to download it to the vehicle.",
                    "label": 0
                },
                {
                    "sent": "Then it's the same thing.",
                    "label": 0
                },
                {
                    "sent": "In fact, you just call well, you'll see.",
                    "label": 0
                },
                {
                    "sent": "So this is this is still stuff that is being worked on, but I give you a rough idea of what it looks like a snapshot right now 'cause it gives you an idea of what these.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You would do something like this.",
                    "label": 0
                },
                {
                    "sent": "You make use EML parser object and then what you do is you call the parse method on it and then this is just.",
                    "label": 0
                },
                {
                    "sent": "This is actually just annotation.",
                    "label": 0
                },
                {
                    "sent": "But the idea is this should look now very very familiar right?",
                    "label": 0
                },
                {
                    "sent": "So you do this.",
                    "label": 0
                },
                {
                    "sent": "That that gives you that.",
                    "label": 0
                },
                {
                    "sent": "That is a side effect on this object P, and then you call the canonicalized map and it does exactly the thing I described before, which is.",
                    "label": 0
                },
                {
                    "sent": "It walks.",
                    "label": 0
                },
                {
                    "sent": "It just walks the tree and does the cone representation substitutions and that's it.",
                    "label": 0
                },
                {
                    "sent": "So now you have a.",
                    "label": 0
                },
                {
                    "sent": "They have a cone problem embedded in P.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now once this canonicalized in creative you can create a Python solver and so for example you might say you might call the code Gen method on P and that's the target CVS up CBS up.",
                    "label": 0
                },
                {
                    "sent": "By the way is a Python based in Interior Point Solver written by leaving Vandenberg.",
                    "label": 0
                },
                {
                    "sent": "So you do that and then you.",
                    "label": 0
                },
                {
                    "sent": "Then you say FP dot solver and then that's actually a function that solves the problem right?",
                    "label": 0
                },
                {
                    "sent": "So then, for example, if you want to solve instances of the problem, you simply say F of params and then will return the solution.",
                    "label": 0
                },
                {
                    "sent": "That's it, which is in fact if you think about it, that's what solver is.",
                    "label": 0
                },
                {
                    "sent": "The function mapping parameter value problem instances specified by parameter values into solutions, right so?",
                    "label": 0
                },
                {
                    "sent": "And if you want to use it like in a CVS mode in interactive mode, you can combine these and you have you have one thing which is.",
                    "label": 0
                },
                {
                    "sent": "You can directly call P dot solve params and that will canonicalize you know, generate a solver and then invoke the solver all at once and now it looks like.",
                    "label": 0
                },
                {
                    "sent": "So now it's edx, right?",
                    "label": 0
                },
                {
                    "sent": "'cause you just specify your problem and then you say solve, instantiate the parameters as an argument and then outcomes the solution right?",
                    "label": 0
                },
                {
                    "sent": "So OK, but you can also use this as a code generator for something.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really so, for example, another project we're working on, actually with some people at EHA is ecosystem embedded cone solver, and it's just a super lightweight.",
                    "label": 0
                },
                {
                    "sent": "In this case it's just a second order cone solver, but that's a lot more than CDs Gen, which does QPS, right?",
                    "label": 0
                },
                {
                    "sent": "So you can also say p.co Gen echoes, and then this generates like C solver code and then then you get something that's like DX Gen.",
                    "label": 0
                },
                {
                    "sent": "Except now it works for a much wider variety of things and also will scale to much, much larger.",
                    "label": 0
                },
                {
                    "sent": "Problems because the exchange is done in a very specific way, which doesn't scale to huge problem.",
                    "label": 0
                },
                {
                    "sent": "It doesn't even scale the medium size problem.",
                    "label": 0
                },
                {
                    "sent": "And so that's the that's the idea there.",
                    "label": 0
                },
                {
                    "sent": "OK, and then the idea is that these things eventually will target things like you know, please generate CUDA for me or generate something, or some MPI stuff to run on the cluster.",
                    "label": 0
                },
                {
                    "sent": "Weight doesn't matter, so OK, so I'll just I'll finish up.",
                    "label": 0
                },
                {
                    "sent": "And the conclusions that they're pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "I mean, one is this idea of this.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convex programming.",
                    "label": 0
                },
                {
                    "sent": "Basically it's a formalization of constructive convex analysis.",
                    "label": 0
                },
                {
                    "sent": "So just it's an extremely simple idea and it's a simple method to certify a problem is convex.",
                    "label": 0
                },
                {
                    "sent": "It it is a set of sufficient, but by no means necessary conditions for problem to be convex.",
                    "label": 0
                },
                {
                    "sent": "But it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's extremely useful, even though it's dumb and simple.",
                    "label": 0
                },
                {
                    "sent": "It's the basis of a lot of domain specific languages for convex optimization.",
                    "label": 1
                },
                {
                    "sent": "And once you know the things that I've told you today, and you know a modern language, you're totally empowered.",
                    "label": 0
                },
                {
                    "sent": "Mean you can write.",
                    "label": 0
                },
                {
                    "sent": "You can write this yourself in an afternoon if you're fluent in a real language, right?",
                    "label": 0
                },
                {
                    "sent": "You can easily write one, and it's actually pretty cool because it means you can do a lot of damage in a couple 100 lines of of code.",
                    "label": 0
                },
                {
                    "sent": "So parser solvers they make rapid prototyping easy, and I know that from personal experience I I taught a course on Linux optimization Precedex and post CDX and the difference is just night and day and even for the students who are theoretically oriented, it was night and day.",
                    "label": 0
                },
                {
                    "sent": "The class went from one where it was kind of a lot about the math and this, that and the other thing.",
                    "label": 0
                },
                {
                    "sent": "And we I would blabber on and on about how some of these things might have applications they had to trust me and then every now and then we have some like baby problem.",
                    "label": 0
                },
                {
                    "sent": "It wasn't a pain in the ass to solve using basically by hand the canonicalization right post CBX.",
                    "label": 0
                },
                {
                    "sent": "It's different.",
                    "label": 0
                },
                {
                    "sent": "I mean, we get to the third week of that class and that's the end of that week and ask him to do anything we like and we have them solve problems in signal processing, machine learning, circuit design everywhere, finance, everything.",
                    "label": 0
                },
                {
                    "sent": "So the classes went from one that was kind of a applied math class to one that's actually applied math and highly actionable.",
                    "label": 0
                },
                {
                    "sent": "So it's actually been a lot of fun is fun for me.",
                    "label": 0
                },
                {
                    "sent": "Fun for them.",
                    "label": 0
                },
                {
                    "sent": "It's great.",
                    "label": 0
                },
                {
                    "sent": "Um change research too.",
                    "label": 1
                },
                {
                    "sent": "The parser generators, so these yield solvers that are extremely fast and they can be embedded in real time applications.",
                    "label": 0
                },
                {
                    "sent": "So we also have done other steps.",
                    "label": 0
                },
                {
                    "sent": "Since we have now the ability to generate like QP solvers that execute in 50 microseconds, right?",
                    "label": 0
                },
                {
                    "sent": "For example, when we when we do various things like in control, when you actually the control on both solving a QP and you want to evaluate something by Monte Carlo, right?",
                    "label": 0
                },
                {
                    "sent": "Then you need to solve QP every iteration, so we routinely.",
                    "label": 0
                },
                {
                    "sent": "Run for 10 million iterations, right?",
                    "label": 0
                },
                {
                    "sent": "Just just 'cause we just to show off, right?",
                    "label": 0
                },
                {
                    "sent": "So this because we can solve 10 we can solve 10,000,000 QPS.",
                    "label": 0
                },
                {
                    "sent": "Gonna you know 32 core machine and I'm like 12 seconds or something like it's crazy.",
                    "label": 0
                },
                {
                    "sent": "So so we do that.",
                    "label": 0
                },
                {
                    "sent": "OK so I will.",
                    "label": 0
                },
                {
                    "sent": "I'll quit here and I guess the references I mean just go.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Google and type things in and you'll find stuff so your friends.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}