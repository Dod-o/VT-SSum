{
    "id": "q5rkwjqnzlmt2nf4lnvq7lp6g4bmpula",
    "title": "The Future of Image Search",
    "info": {
        "author": [
            "Jitendra Malik, UC Berkeley"
        ],
        "published": "Sept. 26, 2008",
        "recorded": "August 2008",
        "category": [
            "Top->Computer Science->Image Analysis",
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Search Engines"
        ]
    },
    "url": "http://videolectures.net/kdd08_malik_fis/",
    "segmentation": [
        [
            "OK, good morning again.",
            "And let's start this today's session with today's program with the invited talk, which is the same stuff everyday and I hope you have enjoyed the talks we had Monday and Tuesday and I'm going to introduce the speaker now so he's probably very safe to say.",
            "I mean, everything in this world around some patterns basically and then we dataminers basically in the in the center of this pursuit for patterns and a discovery, however.",
            "We are not really alone.",
            "The many fields, especially in the scientific fields.",
            "The people doing data analysis and data mining, and for the specific purposes.",
            "And the sooner than I thought about this, and we saw that is very interesting to get people from other field to tell us their achievement and their algorithms and hopefully first data miner will be able to see wider and see further and in the future and basically will get better algorithms.",
            "So for this talk we choose the field of computer vision, which is a few of which is extensive data analysis applications.",
            "Today, we're very fortunate to have Professor Gent Indra Malik from University of California, Berkeley, to give us a keynote address on this particular topic.",
            "Professor Matic is 1 the luminaries in computer vision and image analysis, so the title of his talk today is the future of Image Search.",
            "Professor Malik received his B.Tech degree from India Institute of Technology Campus and his PhD degree from Stanford.",
            "And he's currently at Berkeley as the author Cheek professor of Computer Science here serve as a chair of the Computer Science Division from 2002 and 2004, and also serve as the chair of the Department of EECS at Berkeley from 2004 and 2006.",
            "He has received numerous medals and awards since his school years.",
            "Yesterday I was talking to him like he said, me.",
            "He told me, not say too much, OK?",
            "So I was just giving you a few examples so he's received the gold medal for the best graduating students at IIT Campbell in 2000 and 1980.",
            "1999 Hills will receive the Presidential Young Investigators Award here in US, of course.",
            "And most importantly, his research has received languid Higgins test of Time price twice in 2007 and 2008, and he's a fellow of IEEE and has given many keynote speeches and so another thing he's very proud of.",
            "His graduated 25 pages students which is a major contribution and they are mostly owing them permanent places in academia and industry.",
            "And without further ado, let's inviting let's invite.",
            "Professor Matic to give us the address."
        ],
        [
            "OK, can you hear me?",
            "Thank you Ben for this very kind introduction and thank you to the conference organizers for inviting me.",
            "And I hope to tell you a little bit about my field and how it impacts a little bit on your field.",
            "So to begin with, the title of my talk is the future of Image Search and I should start with saying that predictions are very foolhardy and there is this line from Niels Bohr which says it is difficult to make predictions, especially about the future.",
            "So whenever anybody says the future of X, what they're really saying?",
            "The president of X is this, and this is how we extrapolate.",
            "And inevitably they're wrong.",
            "So expect the same of me.",
            "So."
        ],
        [
            "We must start with the motivation, so the motivation is that there are now billions of images on the web and in collections such as Flickr.",
            "And people want access to this content and let's take an example.",
            "Suppose I want to find pictures of monkeys.",
            "Can you hear me in the back and please people wave OK."
        ],
        [
            "So what do I do?",
            "Let's say I take whatever is my favorite web search engine.",
            "I take Google Image search and I do a query for monkey.",
            "So this query was run some time ago, so it maybe things are better now, but you get some.",
            "Back"
        ],
        [
            "Back and then you look and things are not bad bad.",
            "The first 2 queries indeed.",
            "In fact our results are in fact monkeys."
        ],
        [
            "But then you get stuff here, which has.",
            "I think it says no ordinary monkey.com.",
            "And then this guy is website www.monkeybusiness.net.",
            "OK, so it's revealing to you what's going on, so the query is really not done on the basis of image content.",
            "It's best done on the basis of.",
            "Set up set relevant text file names.",
            "Keywords, tags, etc and that's going to make some."
        ],
        [
            "Mistakes.",
            "So, so the slogan here is that just.",
            "Trying to do image search, ignoring the image is perhaps not a good idea.",
            "We words are not enough."
        ],
        [
            "I know we let's look at sort of the leading photo collection Flickr an we can do a search there and there there's a slight difference.",
            "People are allowed to put in tags and they do and sometimes they are good and sometimes they are bad.",
            "So if you do a Flickr search for the tag monkey, these are the kinds of results you get.",
            "And some of these are reasonable, and some of these are not.",
            "And the problem here is that the data is extremely noisy, so there there is the issue of what's called polysomy different meanings of that word photosets.",
            "So sometimes what you have is people upload a collection of 100 photos and they label them all center Barbara trip.",
            "Which is not how much use when you're trying to get something out, so the argument is tags are not enough either.",
            "Dads are what we have today.",
            "I mean, let's acknowledge the fact that this is currently how the work is done, and that's probably what it's going to be in the immediate future.",
            "But there are some limitations and we hope to go beyond that."
        ],
        [
            "OK, so let's look at the field of.",
            "So there was a field of content based image retrieval which was somehow invented in the early 1990s.",
            "Just ignores these things.",
            "It's not quite important.",
            "The details are not important, and the pioneering project was actually at IBM in the so called CU Project.",
            "There was work that we did at Berkeley, and this is from Santa Barbara and various other projects, and mostly these projects were about using color and texture.",
            "And why use color and texture?",
            "Well, it's this old story of you.",
            "Somebody went and saw somebody looking under looking for somewhere down the ground and this person said, what are you looking for?",
            "I'm looking for my keys and then the person said where did you lose them?",
            "He said over there then why looking there?",
            "Well, this is where the light is OK.",
            "So as researchers we tend to look under the light."
        ],
        [
            "And the light was color and texture histograms because we knew how to model them.",
            "And here was the basic ideas.",
            "So color histograms are you take an image, you divide it up into blocks.",
            "Then you find the distribution of various colors.",
            "What percentage is blue, green, yellow, red, etc.",
            "You get a distribution that characterizes an image.",
            "This is pretty good for finding sunsets.",
            "If you try to find images with a lot lot of red, you'll get sunsets.",
            "And so the Canonical example from any CBR.",
            "From the 1990s was showing the detection of sunsets and then the second example was always a little bit tricky.",
            "OK, you can do something based on texture and texture filters.",
            "What we do is this is a bit more sophisticated.",
            "We run some orientation sensitive filters, various Gaussian derivatives, gabors, whatever, and then the output of those filters we can again construct histograms and sort of carry through the same idea.",
            "And but these are.",
            "This essentially works in very, very limited settings."
        ],
        [
            "And it took us a little while to figure that out, but we did.",
            "We have figured it out.",
            "So give us credit for that.",
            "And there is now a slogan which the multimedia community is very fond of using.",
            "It's called the semantic gap, so the semantic gap is that the 1st generation CBR systems were based on color and texture and these do not capture what users are interested in.",
            "So they are interested in pictures of monkeys or kids or Paris Hilton or whatever.",
            "They're not interested in pictures which have 17% red, pretty 3% green.",
            "That's just not what their queries are about.",
            "We we have a lot of evidence from human perception about what are the cues for categorization, and that most important Q is shape and but this is ignored in all this work when we are considering color and texture.",
            "And.",
            "So what just happened is that they've kind of been 2 tax.",
            "If you look at the ACM multimedia conferences by and large, their conclusion from this is OK.",
            "This is now hopeless.",
            "The simple approaches didn't work.",
            "Let's go off and try to develop good annotation tools so people we can bring the user in the loop and produce tags.",
            "That's kind of what you.",
            "I'm caricaturing a bit, but that's what the multimedia community is sort of come to push for in the computer vision community they stand has been.",
            "Hey, we're trying to fight the good fight.",
            "We'll try to solve the real fundamental problem of recognition based on shape.",
            "And now the question is, what have we delivered in the last five to 10 years?",
            "And I will argue that we have made substantial progress and it's not anywhere near human performance, but it's good enough that it's useful for some, and the derivative is high, so this is the promissory note aspect of the talk."
        ],
        [
            "OK.",
            "So let's let's get some.",
            "So here's the research program then.",
            "So essentially we want to take images and analyze them and automatically generate annotations corresponding to object labels or activities in video.",
            "OK.",
            "If if we can automatically generate those annotations, then of course these can be combined with other metadata and then these become the signal to be used for searching.",
            "Because we believe that at at runtime, analyzing analyzing images is very expensive, so you don't want to be analyzing a billion images at runtime.",
            "But if you have boiled down the content of the image into some some things that you're precomputed, then at runtime things can go pretty fast.",
            "That's not that."
        ],
        [
            "Surprising, OK, so let's start with some context of what we know from human vision.",
            "So there is nice slogan from pixels to perception, and in fact this is the basic difference between images and text image in text when you don't have syntactic error semantic analysis, you have words and words are very useful.",
            "They tell you alot.",
            "Pixels unfortunately are not that useful and isolated pixel tells you nothing of pixel which has.",
            "Brightness value 183.",
            "Tells you nothing whatsoever, however, about what's in there watching the image.",
            "So that's the problem.",
            "We have to move to these semantic categories.",
            "We have to sort of break up the image into objects, label them water Tiger grass.",
            "This labeling could of course be extended hierarchically, so let's."
        ],
        [
            "If you a little bit about what the problem is, the problem is what we call category recognition.",
            "It's not recognizing something exactly the same, but something some some set of objects which share a family resemblance.",
            "These are all faces, these are Flowers.",
            "These are airplanes, elephants, cellphones, Buddhas.",
            "Right we can.",
            "Humans have no problem identifying this as one category, even though they're not identical.",
            "So if you just took the image as a long vector and you took differences and those vectors, well, those would be quite significant here.",
            "But humans have no problem."
        ],
        [
            "So, so let's go and look at sort of the some of the key ideas here.",
            "So there's an idea which goes back actually 100 years, which is due to someone called Darcy Thompson, who was a mathematical biologist nearly 100 years ago and he was studying, you know, skulls, for example, and what's common to all these skulls or these side views of faces.",
            "So his basic idea was that you think of the describing shape is hard.",
            "But describing changes among shapes is not that hard, so the idea is that you have some Canonical shape and then you have transformations of that shape which take you to these other examples and it's mathematically rather similar to the following idea.",
            "You have some complex nonlinear thing.",
            "I mean you don't know how to deal with it, but at an operating point you can linearize it and characterize it by its tangent plane, furious here.",
            "Taylor series expansion, that sort of thing, and that's kind of what we're going to do.",
            "We have a shape and then we consider deviations from that shape, and those deviations are easier to understand than the shape in the abstract.",
            "And, uh.",
            "This of course, this idea essentially today the graphics people call it morphing from one shape to another, but it really goes back 100 years."
        ],
        [
            "Some other observations, so this is an example.",
            "It's called Acnes Cat, which is meant to illustrate the importance of shape.",
            "That's why line drawings work.",
            "We have taken this image and replace.",
            "Got rid of the color and texture.",
            "We take the contour and even the contour we've replaced by a set of straight lines.",
            "So it's really being boiled down to its fewest bits in some way.",
            "And yet we can recognize this an.",
            "However, if I told you the percentage of yellow and and red pixels in this image, it wouldn't let you know that it is a cat.",
            "So so there is a lot of abstraction and generalization in our interpretation of an image."
        ],
        [
            "This is kind of a busy slide, but there are hierarchies in this notion of our notion of categories.",
            "So, for example, cats are in the order validate which is mammal mammal.",
            "So there's a hierarchy there, which we must be aware of, and recognition can be at these different levels of abstraction.",
            "There could be something which I don't recognize, but I say, oh, it's a four legged animal.",
            "OK, that's that's a good enough answer for certain purposes.",
            "For certain purposes.",
            "It it I have to be able to say.",
            "This is my cat Bunty.",
            "Then there is another hierarchy, which is that objects have parts.",
            "They have subparts and so on, and in fact we can think of this for humans.",
            "But actually it operates at the high level above objects.",
            "Two objects are part of scenes, so right now we are part of a lecture scene where there are people and chairs and so on, and they are in some arrangement which is a much more loose special arrangement.",
            "So here's a semi made up term patrona me.",
            "So we have to worry about taxonomies and partner Gnomies.",
            "Psychologists have actually given us a sense of how many categories humans can deal with, and there is this estimate of 30,000.",
            "So when we scale up our visual recognition system, that's kind of the target to which we have to go to on the order of 30,000 visual categories.",
            "The number of words in English is obviously more, but I mean a word like faith, Hope or charity doesn't necessarily have a visual connotation.",
            "Well, in some very abstractions, yes, but I'm currently we're dealing with more concrete things, so 30,000 that's what we have to go to, and I'll give you examples which illustrate that where we are at today is on the order of 100.",
            "So we today the state of computer vision is on the order of hundred categories and we need to go up basically two orders of magnitude from that.",
            "And it's not just a computing limitation, it's also a limitation of ideas and so forth.",
            "OK."
        ],
        [
            "So this I think gives you some flavor about the scope of the problem is it's been studied for quite some number of years in human visual perception and in computer vision, which dates back at least 40 years.",
            "So I'll take you through some examples of how we think about this and some concrete results.",
            "So here is one way of thinking about it.",
            "Here is some image and I don't know what it is, but I have my.",
            "I have a set of examples and these are labeled elephant Buddha flower.",
            "ETC etc.",
            "So what I do is I try to do a correspondence and matching between my query image and these exam plus and I evaluate a simile."
        ],
        [
            "City score and let's say the similarity score turns out to be the highest or the difference turns out to be the smallest between these two.",
            "And then I'm in business.",
            "That's my if you want to think of it, put it, put it in machine learning framework.",
            "This is a nearest neighbor classifier with a certain distance function and there is something to be said about nearest neighbor classifiers.",
            "Asymptotically given enough examples, our nearest neighbor classifier gets you within a factor of two of the optimal Bayesian classifier.",
            "So always whenever fancy schemes are tried, remember the humble nearest neighbor classifier."
        ],
        [
            "OK."
        ],
        [
            "So if you notice I showed you these views, but you might ask."
        ],
        [
            "Objects are actually 3 dimensional and our current thinking on this is that will appoint the problem.",
            "Will we know how to solve 2-D22D matching problems?",
            "So we'll deal with 3D objects by just storing multiple 2D views, so you have.",
            "So here is this this Anderson box and what we'll do is we won't store a 3D single 3D model, but we'll store multiple two reviews and here also multiple 2D views and the matching machinery has to be robust too.",
            "Working even though you have a small number of two day beers."
        ],
        [
            "And the answer is that you can actually do that.",
            "Here is an experiment based on some work we had done a few years ago that we needed to.",
            "So this is on the Y axis.",
            "Is the error rate and the X axis is the number of examples you stored, and so these are different similarity functions and this is obviously the fanciest one that we have proposed an even with four prototypes per object we could get an error rate of two 3%.",
            "So pretty small.",
            "So this general idea.",
            "If you cleverly select the views works that you can represent a 3D object by multiple two reviews and this makes life much easier because for natural objects we don't necessarily have 3D models available for industrial parts we do, but industrial parts are very small fraction of what we are interested in.",
            "So if we can just work with images, life is better and that's our current paradigm."
        ],
        [
            "OK, so how do we solve the correspondence problem?",
            "How do we match different parts of an object to each other?",
            "So I'm going to go through some of the ideas there talk about deformable template matching, and then how we use machine learning for fine."
        ],
        [
            "Discriminative features OK, so the correspondence problem can be described this way.",
            "So here are two 2 versions of the letter A and what we are somehow able to do.",
            "Humans intuitively, is to say that these two.",
            "Somehow our corresponding points and rate is a different point on the shape and these are not identical shapes, right?",
            "But somehow we still have this notion of correspondence and this in other settings will mean that from one image, the tip of the nose can be matched to the tip of the nose in another image, and so on.",
            "OK, how do we do this?",
            "And the secret is that we try to come up with some descriptor.",
            "If I just look at that point, the point is the same, right?",
            "But if I try to characterize some?"
        ],
        [
            "Or extended neighborhood?",
            "I can distinguish between the different points in the shape, so here's one idea.",
            "You take this point, and you put a series of this kind of a dartboard like pattern.",
            "Around that point and you count the number of.",
            "I've sort of these these image points in each of these bins, so we count here.",
            "You get 4 points and here you get 10 and so on and so forth, so that what it is doing is at around a point.",
            "It is characterizing the distribution of other points and we call this the shape context."
        ],
        [
            "So here is a point and then so we have got these different bins so that the bins are arranged in space so they have different angular orientations and at different distances.",
            "So this is the distance accesses angular distance, so you get you get.",
            "So we had this arrangement of 60 bins there.",
            "And now we've got counts here.",
            "So dark means more counts, so this is what the pattern around this point looks like.",
            "So most of the action is below and to the right, which is captured here.",
            "And consider this point.",
            "What happens here around that the points are distributed equally all around you.",
            "So therefore the distribution with respect to Theta is much more uniform, and so you get this distribution.",
            "Now what is the case with these guys?",
            "Unlike the original shape, these are now fixed length vectors.",
            "Because we have we have."
        ],
        [
            "Steel bins if I go back here I have.",
            "I have a certain number of, so if I count 12345 and then there are twelve of these.",
            "So I get 60 bins.",
            "So now I've got a 60 length vector a fixed length vector which characterizes a part of an object.",
            "We it's much easier.",
            "Life is much easier with fixed length vectors.",
            "That's what the whole theory of pattern recognition was developed for.",
            "So we're taking our problem, which is more general and complicated, and coercing it into it's the mathematicians trick.",
            "You don't know how to solve a problem, you convert it to something you do know how to solve, so we're converting it to the vector game, which we know how to play."
        ],
        [
            "So now what I described was one way of constructing local descriptors.",
            "There are other ways."
        ],
        [
            "So this is there's something we call geometric blurred where you take the image, you filter it with different oriented filters, you do some blurring, you sample, you get something.",
            "OK, there are other descriptors that you may have heard of, like Sift which is due to David Lowe.",
            "There's something called histogram of oriented gradients and so on.",
            "So in the computer vision community there are three or four of these versions around depending on which group you are talking too, and they're all more or less the same and they all basically work.",
            "OK, so at this point Once Upon a time we used to fight about who's descriptor was slightly better, but.",
            "Basically, that's not what where the things are about.",
            "They are all equally good.",
            "OK, so we have.",
            "We can now describe local parts of a shape and we can describe them by fixed length vectors, so that's progress.",
            "And this is one I think clever, very simple but clever idea that came out in the last 10 years and it has advanced the state of visual recognition, OK?"
        ],
        [
            "Let me illustrate the idea of deformable template matching.",
            "OK.",
            "So to remind."
        ],
        [
            "You have the problem.",
            "This is the Darcy Thompson slide set of skulls, fish, etc.",
            "And what we want to do is we are going to have to recognize one of these guys, but we will have stored examples which are slightly different shape but related by a transformation.",
            "OK, so then how can we make things work?"
        ],
        [
            "OK, so here is an example.",
            "So so I have stored in my previously examples which labels.",
            "So this is a fish.",
            "I know what it is.",
            "Here is some unknown thing.",
            "I don't know what it is.",
            "So what I will try to do is I'll try to match them.",
            "But in the process of matching I allow small deformations and if the two match as a then I will say OK.",
            "This might very well be the same object category.",
            "So let's do this so correspond.",
            "So how do we transform?",
            "Well, transformations actually require that you have a notion of correspondence.",
            "You need to find what the corresponding points are.",
            "So this guy matches this guy.",
            "This tip of the nose matches the tip of the nose.",
            "These various points on the fins match, etc, and that those are indicated here.",
            "And how do we solve the correspondence problem?",
            "So this is where those local shape descriptors come in.",
            "The local shape descriptors unable us to.",
            "To to say, what is the most similar point for for the two shapes.",
            "So we solve the correspondence.",
            "And then and then I can estimate.",
            "I I apologize, I'm I guess consistently using this screen and maybe I should use that word, but I guess I'm right handed so you'll have to bear with it.",
            "I should use the mouse, but anyway, so so these so you get the correspondences and then you transform by by thin plate spline and this shows the transformation.",
            "So now this this guy starts to look like that.",
            "And then we solve the correspondence again and we iterate and after a few transformations which are all smooth transformations using splines, the model starts to look very much like the target and we measure how much we had to transform by this measure of bending energy of the thin plate spline, and that's small, and so if we had started with a chair.",
            "This wouldn't have worked.",
            "You would have needed a much greater bending energy and that becomes your distance measure and then."
        ],
        [
            "Feed it into a nearest neighbor classifier and so we've tried this in different domains, an one classic domain for pattern recognition is handwritten digit recognition, and this is a problem which is their datasets for 15 years and people have been trying this and and there are different approaches based on support vector machines, nearest neighbors, neural networks, etc and our shape matching approached when we tried it.",
            "Sort of immediately gave us sort of results.",
            "Which are the best at that time.",
            "And since then the problem people have got even even lower error rates."
        ],
        [
            "So this is when the error rate is .63%.",
            "You can actually show all the errors.",
            "This is the data set is 10,000.",
            "At Test digits and these are all the errors and some of these you will recognize are difficult even for humans.",
            "So I think the good news is handwritten digit recognition is a problem we can really solve.",
            "I I the proof of that is in the fact that, at least for me, my bank is Wells Fargo.",
            "When I deposit checks in the ATM there, there's a handwritten amount there of the the amount of the check an those are all scanned in and read by a computer program and this stuff works.",
            "I mean so so we can declare success on some part of the problem.",
            "I mean the error rate is of .5% humans are not perfect either, so we may very well be hitting the limb."
        ],
        [
            "There.",
            "Here's another example.",
            "I'm sure you've seen these, so whenever you try to get a FREE Email account from Google or Yahoo or various other things, these captures seem to be very common.",
            "So when we saw these we thought, OK, let's see.",
            "We claim that we can do deformable shape matching, so you'll notice the usual pattern is there is some shape which is deformed and put in some noisy background and the idea here is to break your traditional OCR software, but for our technique, which is to try to do this deformable matching.",
            "This is no problem at all, so this is we can do this 92% of the time.",
            "So ever since that work, I mean, it was reported in the New York Times and so on and so forth.",
            "I always every month I get some shady character who claims that he wants a copy of the software for doing some research, but obviously it's for people who are spammers who want to get, you know, lots of free accounts.",
            "And the interesting thing I note here is that it's all in the public domain, so they could actually implement it.",
            "And they're not doing it, so it must.",
            "So my conclusion from this is that this kind of crime pays.",
            "But not too much, so it's not worth it for them to go through the effort of actually doing this.",
            "So people have since changed these captures, and if you see the new version, they're much much more distorted.",
            "I think, but we haven't tried those, but I think we can really do those, so this is OK success story.",
            "I mean I OK maybe you can say this is easy.",
            "This is digits letters.",
            "Well, let's accept our successes.",
            "AI people have always been criticized for the failing.",
            "That anything which succeeds is no longer regarded as part of AI.",
            "So I hope not to be guilty of that."
        ],
        [
            "OK, so now notice that everything here was actually you could put it in a machine learning framework, but it was a very simple machine learning framework, which is that nearest neighbor.",
            "Now machine learning can actually do more for us and the best way to think about this is as disc learning discriminative features.",
            "What features actually carry more information?"
        ],
        [
            "So let's look at that so.",
            "So I'm trying to find some categories here, so this is a panda bear.",
            "This is a rooster.",
            "What patches are more informative and the goal of the algorithm will be to not wait all the features equally, but wait.",
            "The red here indicates there's a Matlab.",
            "Sort of visualization.",
            "Things that red means are more important.",
            "Feature blue means a less important feature.",
            "Anne.",
            "So what we're going to?"
        ],
        [
            "Two is illustrated here.",
            "We're going to try to find these distance functions, but the distance function will be will be learned and the goal is to tweak the distance function such that the distance is within one category.",
            "You know, from airplanes to airplanes are small, and but from airplanes to giraffes are large, so we'll take the machine learning paradigm to tune the distance function.",
            "So how do we do that?",
            "So a simple way of setting this up is.",
            "Here is an image I there images J&K.",
            "We know that the distance I&J are in the same category I and care in a different category.",
            "So my goal is to make deicer K greater than the subject.",
            "And note that we will always have to work in this paradigm that an image or any object can never be characterized by a single fixed length vector.",
            "Like parts of images can be, but the image itself will have one image may have 100 features, another image may have 70 features.",
            "We always have to work with that problem.",
            "OK."
        ],
        [
            "So then this is kind of more of the details, so we have various features and for each feature we'll try to find the best matching feature in the other view.",
            "And so I'm using big D for the that does full distance function, but that full distance function is made up of weights times elementary distance function which are for single features.",
            "And so we have.",
            "So we have a whole bunch of features here and then we have the distances of each of those features.",
            "Dyesub K. The little days.",
            "And here's another image and then I have the distances dij.",
            "For each of those little features, OK. And so these features are all.",
            "Focused on the distances and the features.",
            "An image I so that defines the dimensionality of this vector.",
            "These vectors which are now equal because they are all referred with respect to the focal image and now what we want to do is to make sure that the DIK which is a different category, is as a larger distance than the same category.",
            "The distance between images and so essentially this becomes the equation the weights.",
            "Dot product it here should be larger than these or I can take this difference vector.",
            "This guy must be greater than 0."
        ],
        [
            "OK, so far so good.",
            "And now we just throw in the usual SVM mumbo jumbo.",
            "OK, so we want to get this guy greater than zero but we want to have some regularization so I apologize for sort of just waving my hands through this thing.",
            "So this turns out to be it's.",
            "It's pretty akin to it's some variation on that theme you you get a minimization problem with the weight vector and then this is kind of the penalty term.",
            "So you want to not have too many of these guys and.",
            "The machine that goes through OK."
        ],
        [
            "So let's see the results of this.",
            "So what this enables us to do is learn distance function, where you put more weights or less weights on features which are more distinctive or or less distinctive over category.",
            "That's what you learn at the end.",
            "Basically so here is a challenge data set which was developed about, you know four.",
            "So that's now four years ago.",
            "And when this data set came out in 2004, people thought that this is this is a horribly challenging problem because at that recall that in 2003 or 2004 the problem which we thought we had solved was digits.",
            "OK, we I could say we would also solve the problem of face detection.",
            "That's where we were at.",
            "We could do digits we could do faces and now this group of perona, an FEI Fei, and so on.",
            "What they did was they collected images of 100 different categories from the web.",
            "So these are images of pianos and various animals, and I think their stop.",
            "So there's a pianos anchors.",
            "Sort of Flowers, cell phones, etc etc.",
            "So they're quite natural categories for each category they collected, say maybe 50 or 60 examples.",
            "By doing a search based on text queries and then having a graduate student go through and collect sort of the right examples.",
            "And So what do you think?",
            "So those are hundred categories, so then so you have some data that you use for training and then you have some data at Test time.",
            "And what's your expectation of how well an algorithm will do?"
        ],
        [
            "Well, OK, I'll come to that.",
            "But this is what our approach does, so we can try to.",
            "We have a similarity based querying so we can take this image and try to find what on the basis of these distance functions.",
            "What are the nearby?"
        ],
        [
            "Sample so let me jump to the results.",
            "So this is the.",
            "This is a curve which shows the Caltech 101 classification results on the X axis is the number of training examples and the Y axis is the performance correct?",
            "So if you have more training examples, you do better.",
            "That's what these curves show when the data set first came out.",
            "The performance was here, so this is 2004.",
            "This was 16% correct 16.",
            "And the Caltech people.",
            "So you could say another way, let me repeat 16% correct, which means 84% wrong.",
            "OK, not something to be very proud about, but the Caltech people their logic was.",
            "Hey, it is much better than chance because what is chance if you have hundred categories and you have to guess it would be 1%.",
            "So it was 16 times better than chance an we were now moving forth in this world of really natural categories and if that technique works it was likely to be useful rather than very very constrained artificial kinds of examples.",
            "I.",
            "Over the last three or four years, the performance has gone up, and so the technique that I just described this is the work of Andrea from your own singer and myself.",
            "We get performance in the range of 65 or 66%, so that's a factor of four improvement in three years, and these other curves correspond to different approaches.",
            "So we had this time for three years, where every conference we would go to OK, the number is gone up from 16 to 40 then.",
            "5565 that kind of thing, and this is exciting.",
            "This means that some real progress is being made.",
            "And finally, now there are numbers which are in the range of 90% and this fellow Verma and Ray.",
            "What they did was they took the leading clear for approaches and then they build a classifier on top of all these classifiers which which which and this is an idea which is well known in machine learning that if you combine various of these, so long as they are somewhat independent you can do better.",
            "Answer Performance is now in the 90% range, so over four years we have gone from 16% correct to 90% correct, which is pretty good and I will this carry over and I don't know, but I this is the kind of thing which makes me feel good and optimistic that we're not just, you know.",
            "Looking in some domain which nobody will ever succeeded."
        ],
        [
            "OK, so this is kind of the error rate I'll skip."
        ],
        [
            "That OK, but now so after this heady success.",
            "Let me bring everybody back to Earth and what's missing.",
            "So you should.",
            "You may have a may have gotten down to what was the cheat there.",
            "These were isolated objects and simple backgrounds, right?",
            "So I had.",
            "One cell phone against the background, one elephant with some grass and trees, but they weren't like a scene with three elephant trees, rivers, mountains, all the rest right?",
            "And the world doesn't give a single images like that.",
            "There are quite a few like that, but it's by no means the universal case.",
            "So real objects are part of scene, so we really need to understand how to process since and I should note there is some good news here.",
            "There is one category where we have solved the general problem which is faces."
        ],
        [
            "And I'll show you some results.",
            "These are from Jackie Kennedy's group at CMU, and there's been several groups which are obtained.",
            "Viola Jones is 1 Anne and there was earlier work for poachers group.",
            "This is back in the late 90s and early 2000s that.",
            "Effectively, we can say the computer vision community has killed this problem.",
            "We can solve this problem of detecting faces and note that these are faces and scenes, right?",
            "The faces have been detected here and they are part of a big image.",
            "It's not that you have a single phase and a nice clean background which makes life easy.",
            "OK, so.",
            "So this works and now it's being used again.",
            "Lots of image search can be image search engines exploit the fact that you can detect faces and build on it, so this is a success story now.",
            "This took quite a lot of effort and a lot of tuning and lot of manners.",
            "Now if the number of manners that went into building a face detection detector, if we had to do this for each of 30,000 categories, the computer vision community would be working at it for the next 1000 years.",
            "OK, we can't possibly do that.",
            "We really need something general.",
            "But let me explain.",
            "A little bit about what the what the key challenge is.",
            "Why is this hard?",
            "OK, and and then I'll.",
            "I'll show you one result from our group which shows that we can do much better."
        ],
        [
            "Had this problem and this is the reason why when we're trying to detect an object which is not an isolated object but an object which is part of a background, so is this?",
            "Is this an X question X could be faces extra be giraffe sex could be cars X could be stop signs So what we do is that the current techniques for this are based on scanning."
        ],
        [
            "So we run a window so you put a little window down and you say in this window is there a face.",
            "Then you slide that window.",
            "And move it around so you move it from left to right, top to down and you in each of these windows.",
            "Now you run your classifier for detecting a face OK. And of course the face could be small or big, so you must run these windows of varying sizes.",
            "So what's the complexity now?",
            "So for a given scale, for a given size or face, the complexity is number of pixels.",
            "OK, and then it is times the number of sizes that you want to try.",
            "OK, now you can tweak a little bit.",
            "You can.",
            "You don't need to search at every pixel.",
            "Maybe in the if you look at one pixel then the second, then the pixel immediately to the right of it will probably be the same.",
            "So you do some jumping and so on.",
            "But you can see the horrendous computational complexity of this problem.",
            "And this computational complexity brings with it some statistical hazards.",
            "And the reason is when you have zillions of these windows to check.",
            "Your false positive rates really go up, because imagine that you have a false positive rate per window of 0.01%, or people say, wow, that's impressive.",
            "Now that you take that 0.01% and you multiply it by a million.",
            "OK, now you are in trouble, right?",
            "So that now you've got 10,000 false today.",
            "Whatever, some 100 false detection.",
            "So.",
            "So this is kind of the problem.",
            "We really.",
            "So there is a statistical problem and there is a computational complexity problem.",
            "So both of these have to be tackled and we have to tackle this not just for faces, but for 30,000 different categories.",
            "And we have to tackle this without hand tuning for each category.",
            "We all have graduate students, but not so many.",
            "OK, I could assign one graduate student for faces, one for giraffes, one for zebras.",
            "You know, it might take quite some time OK?",
            "So so now we could ask the question.",
            "Well it has worked for faces.",
            "Why does it that technique scale?"
        ],
        [
            "So, so first I'll say a little bit about how the face techniques they work.",
            "They will based on boosted decision trees and the idea of a cascade.",
            "So you have early rejection, so most so you make some quick tests which say for example, if in the entire image there is no feature, it's just like blank piece of white wall.",
            "Then you can reject quickly.",
            "Reject quickly and move on.",
            "So that's the idea you want to reject quickly and then only look at detail where where many where it's more likely for there to be a phase now.",
            "The problem with these boosted approach to boosting approaches is that they are very expensive at training time, and it's fine.",
            "You can do it for faces.",
            "The challenge is what if we want to work with multiple categories?",
            "OK, and that's where when you want to scale up to more categories an essentially the boosting techniques basically don't scale up to lots of categories because the feature selection stage essentially requires it's a greedy kind of stage.",
            "So you have to try sort of exponentially many combinations of features, and that there's been some tricks to deal with that, but fundamentally I don't believe that boosted decision tree technique, which has worked beautifully for faces.",
            "Will work when we're trying to deal with hundreds of categories.",
            "The training part really gives you the training part.",
            "On the other hand, for support vector machines is actually quite good.",
            "But there's a well developed optimization machinery for it.",
            "People have worked on it.",
            "It's it's really works clearly, and it repeatedly and predictably.",
            "The problem there is.",
            "We can of course choose linear, SVM's or non linear SVM and linear SVM.",
            "Things are good in terms of both evaluation and training.",
            "But linear SVM's have limitations, and nonlinear SVM's turn out to are what you need, because most of the time we don't have linear hyper.",
            "The decision boundaries are not linear, but for nonlinear SVM the problem is that at runtime your computational complexity is proportional to the number of support vectors that you keep, and this is horrendously hard and."
        ],
        [
            "Let me just give you some examples here.",
            "And So what we have done is essentially a technique which which enables us to."
        ],
        [
            "So much better than this, and this is work which is very recent work presented at CPR.",
            "So branch umaji, Alexa."
        ],
        [
            "Bergen I OK so I'm going to skip these slides which about what support vector machine."
        ],
        [
            "Maybe we want to find decision boundaries.",
            "We want to choose."
        ],
        [
            "That decision boundary which has a maximum."
        ],
        [
            "We like this guy because it has a maximum margin."
        ],
        [
            "And we can do this in in some Hilbert space, and so we have boundaries which in the base space are nonlinear.",
            "But in this high dimensional space are.",
            "Again, in the high dimensional spaces are linear and in lower dimensional space they are curved and that's good."
        ],
        [
            "OK, so I'm so so now, so we so let's see.",
            "So I'm going to skip the the.",
            "I mean we have features for this I am going to take a canonic problem domain which is pedestrian detection which is considered more challenging than face detection.",
            "So these are typically people walking standing, that kind of thing.",
            "And we have positive and."
        ],
        [
            "Examples and use this to illustrate.",
            "So the features that we use are not are you divide the image up into blocks and then you consider orientation histograms in each of these."
        ],
        [
            "OK, the problem what we're trying to do is.",
            "So let me just explain the big idea here.",
            "The big idea is that.",
            "If we want to use support vector machines and we have nonlinear decision boundaries, then the computational complexity at runtime is prohibitively high.",
            "So usually what happens is that you train your classifier, you're left with some support vectors.",
            "Suppose you have Isaiah Gaussian kernel and these might be in the thousands of few 1000 support vectors.",
            "Then at runtime, you kind of have to take the inner product with each of those thousand support vectors, and now we have to do this at every location in the image.",
            "At every scale.",
            "And so we are dead, so nonlinear SVM's really can't be done used for detection in this setting.",
            "So people in fact when they try to do users where they are forced to use linear speeds, which again which now have reduced power.",
            "What we've got now is this result, which shows that for a set of nonlinear kernels we can do a major speed up, and our major speedup is we don't need to have a computational complexity complexity linear in the number of support vectors.",
            "We can get it either logarithmically.",
            "Exactly or in constant in the number of service support vectors with an approximation, and this is a big deal, because suppose you have 10,000 support support vectors.",
            "Either it's over 10,000 or it is O of log 10,000 and there's no approximation or it is over one with a little bit of approximation.",
            "So I'll just explain the idea."
        ],
        [
            "The idea is that actually it turns out that.",
            "There are certain kinds of kernels that are used in in computer vision.",
            "Alot.",
            "The most popular ones are are are Gaussians and and the so called intersection kernel and it turns out that for the Gaussian we can't help you.",
            "But for the intersection kernel we have this chick.",
            "It's a little trick but it it really makes a very big difference.",
            "So the intersection kernel is the following it so it is a legitimate Mercer kernel and so on.",
            "The basic idea is that when we take two histograms.",
            "We really if you have two histograms A&BI, you take the minimum of those two.",
            "Histograms at a bin and then you take some these up.",
            "So if the two are identical, then obviously there's some will be one, and if they are not identical, there will be less than one.",
            "So that's the intersection kernel, and in computer vision we use this for comparing color histograms orientation instead."
        ],
        [
            "Times etc now.",
            "So in any kernel based approach, the decision function is ultimately something like this weighted sum of these kernels, the inner product and that weighted sum for the intersection kernel.",
            "You can expand it out to be them in."
        ],
        [
            "Some of these guys.",
            "And that's so the support vector machine, the usual constant number of support vectors times the cost of kernel computation, and here it's going to be proportional to the feature dimensions, because this computation of this K is going to be proportional to the."
        ],
        [
            "Web dimensions.",
            "And here is the trick, and every computer scientist knows that whenever you have a double summation, you should reverse the order of summation and see if something lucky works out.",
            "So here you have an outer summation over support vectors.",
            "Inner summation over dimensions.",
            "You flip these around.",
            "You get some term like this which now is factorizable for each dimension and it some in time something.",
            "And now if you sort the excise sub J entries to finding them in is, it's trivial.",
            "That's where the log rhythmic part comes in.",
            "And you do this.",
            "You can do this in advance, and I'm jumping over the D."
        ],
        [
            "Yes, but basically you might.",
            "You can sort of just guess that mean sorting logarithmically right?",
            "OK, so now the cost becomes logarithms or the log."
        ],
        [
            "The number of support vectors is a big deal.",
            "And then there is another trick which is this function is a smooth function, so you can approximate it by a P."
        ],
        [
            "Swayze linear function and then it becomes constant, so that's what we call fast iks VM.",
            "So there was a big deal for Fourier transforms in the 60s when instead of N squared you could do N log in, and this is a gain speed up like that, and it's not universal.",
            "It isn't true for all these VM's, all nonlinear kernels, but for this class.",
            "But this is important."
        ],
        [
            "As for computer vision.",
            "And these are just numbers which."
        ],
        [
            "Bear out this visit."
        ],
        [
            "And then it skipped this, but the basic thing was that with this we are able to get the best results on pedestrian detection.",
            "And we didn't do rocket science in terms of thinking of this, that the techniques that we used are more or less standard.",
            "But we could now afford to use a nonlinear kernel, because we had this trick and that gives us."
        ],
        [
            "Better performance.",
            "And these are some results where these are sort of the mistakes actually."
        ],
        [
            "And other."
        ],
        [
            "Data sets I'm going to skip all this."
        ],
        [
            "And that is some generalization of this idea."
        ],
        [
            "Which I'm going to again skip and I'll try to conclude with.",
            "This is my final slide.",
            "So.",
            "So I tried to answer the question that I started the talk with.",
            "What is the future we made search?",
            "And making this bold claim that the secret of image search is that we have to do we have to get our hands dirty, solve the hard problem of shape based object recognition?",
            "It may seem like a very hard problem and it is.",
            "It's been worked on for many years, but in recent years advances in image features.",
            "This is where the idea of those fixed length local descriptors comes in machine learning.",
            "The user support vector machines, but type and many other techniques.",
            "But notice that there's a lot of adaptation of the techniques because essentially we don't.",
            "Our basic domain is not fixed length vectors.",
            "Computing power, of course, and the availability of large data collection.",
            "I mean, if you were working 20 years ago.",
            "You simply want to hide the training data.",
            "All that has made this possible.",
            "I I'm not arguing that you should ignore all the other information that should be used.",
            "Obviously we should use this image information together with all the other metadata.",
            "And.",
            "I do believe that we are making significant progress.",
            "Thank you.",
            "Thank you, I enjoyed your talk.",
            "Could you comment about the trajectory of the increase in the number of concepts that humans learn that you said 30,000 psychology?",
            "Think about 30,000.",
            "Was it like 30,000 two year old or 4 year old?",
            "Is there anything known about that?",
            "Well, not that much.",
            "I mean we know some but not.",
            "I think that a 3 or 4 year old I mean already.",
            "I have a 2 year old son and he is much better than any of my programs.",
            "Maybe he was better than any other programs at 1 1/2 I would say I think that in language this has been studied and I think these go together so we have a notion of somehow there's a concept.",
            "There's a category which you have to form in your mental easier mental language and this has a visual representation and a word associated with it and what we know is that from the age of 1 1/2 days a very rapid explosion.",
            "So by the age of two.",
            "Kids, sort of for all the common objects in their environment.",
            "They know they have the concepts, so they may not know about iguanas, right?",
            "Unless they have a picture book with iguanas.",
            "But all the things that are relevant for their world, they are good at.",
            "There is.",
            "So I think 234.",
            "They're really good.",
            "There is one ability which which takes awhile to develop which is discriminating subtle differences among say faces.",
            "And that there is evidence that even up to 12 or 13 the tablet ability is growing, improving.",
            "One other question, if there's.",
            "Yeah.",
            "Yeah, so the question is, I said something about taxonomies and then I didn't say anything about it afterwards and I didn't say anything about it because I didn't have anything to say in the sense that we recognize that this is an important thing to do and this will obviously that's another way to bring a log arhythmic speedup right computer side, there's no.",
            "Wherever you put a hierarchy, you go from N to log in, so that 30,000 if we could put a hierarchy, we might win, right?",
            "But we haven't yet figured it out.",
            "Yes.",
            "Which year?",
            "Sure, do you think?",
            "Will we reach human level of competence?",
            "Which year will you reach?",
            "We reach human level of competence.",
            "OK, so this is where I refer to the great authority of either Niels Bohr or it's also been attributed to Yogi Berra.",
            "It is difficult to make predictions, especially about the future.",
            "Someone over there.",
            "But seriously, the path of AI is littered with these false predictions, so I think sometimes funding agencies forced me to say things, but.",
            "A respectable audience like you guys, I can't do it.",
            "So this number 30,000 reminds me of a number 20,000.",
            "I used to hear in speech recognition back in the mid 80s when people were still working on digit recognition.",
            "They talked about what I think they call.",
            "Unrestricted vocabulary of 20,000, and they claim that was all the words that people knew.",
            "I knew early on here you you prefaced your 30,000 by saying people do know more words than that, but I wonder if 30,000 is big enough for 30,000 is just the biggest number you can imagine, and that if we did get to 30,000 turn out it wouldn't be enough.",
            "That 30,000 is a is a very crude guestimate.",
            "It was done by Biederman who is a psychologist.",
            "He opened up the dictionary at random.",
            "He tried to sample which words, which words on the page were concrete nouns as opposed to abstract nouns like.",
            "You know, like if you have the word pigeon, it's OK, but the word peace is not OK, and then you do apply some fudge factors and so on.",
            "So I don't take the number that seriously.",
            "I take that to mean anything between 10,000, two 100,000.",
            "It gives me an order of magnitude and it tells me that I'm off by by two orders of magnitude.",
            "It will probably be more than that.",
            "So then I mean we know a little bit from of the data of the distribution of categories of images on the web.",
            "It follows the usual power laws if slow kind of thing.",
            "So there are categories which are very common faces and people.",
            "And then there are these heavy tails, and that's where you have to just set a cut off.",
            "And that's where that will cut off will determine whether it's thirty thousand, 100,000 or 1,000,000.",
            "So I think most of these techniques can be divided into 2 phases.",
            "First one is to extract features, seconds, how to build classifiers.",
            "So my question is we have some progress is.",
            "So for these two accounts, two aspects which one contribute more to this kind of improvement.",
            "I would put OK, so as a vision person I'm always biased in favor of the features because that is where my skills come in most.",
            "I think it's both, but I I think the I always think that.",
            "So my advice to my graduate students always is first try to build a nearest neighbor classifier and nearest neighbor classifier will will force you to get the features right because you're not getting any heavy power from the classification machinery once it sort of makes sense.",
            "Coenen SVM instead, our nearest neighbor, and you'll get 1020% on top.",
            "OK.",
            "So, so I'm revealing my bias here, which is that I think work on the features is important, but.",
            "That's only a mild bias.",
            "I think that what is let me let me give a more serious answer, which is that I think that off the shelf machine learning techniques are not quite what work.",
            "What is really needed is that that for this domain we have to somehow evolve the techniques in the way that is needed for this domain.",
            "And that's really genuine.",
            "Respectable research in machine learning.",
            "I mean, if we talk about human learning, the most important category for humans is in fact visual learning.",
            "About 30 to 50% of the brain is devoted to vision.",
            "So in a sense, this is the most important Canonical case for learning, so I wouldn't.",
            "So it is at the moment which successfully tackle it.",
            "There is one group in Bonn in Germany which is working on that.",
            "But beyond that and IBM at a couple of patent on on trying to doing this, chemical recognition from images but not much has evolved down there.",
            "Classical problem is when you want to search into a patent database we using a chemical structure.",
            "You need to have first extracted chemical structures, but perhaps your approach could allow to do patent identification.",
            "Buy without having first understood the chemical structure.",
            "Have you have any vision or feelings on this?",
            "Thank you.",
            "I have not worked on that problem so I don't know how noisy the images are in the sense that they are scanned in and I don't know what the quality is of the bitmaps, but my prior I guess is that this is a doable problem because extracting linear structure is something which we can do.",
            "I mean there are some algorithms for that which I didn't talk about because that was not the main focus on my talk.",
            "But I think that we have pretty good techniques now for extracting lines and lines and curves, and that should help solve this problem.",
            "And then of course there will be symbols, but that's the character recognition problem so.",
            "I think it's it's a problem which I regard is something which should be solvable, thank you.",
            "Michael."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good morning again.",
                    "label": 0
                },
                {
                    "sent": "And let's start this today's session with today's program with the invited talk, which is the same stuff everyday and I hope you have enjoyed the talks we had Monday and Tuesday and I'm going to introduce the speaker now so he's probably very safe to say.",
                    "label": 0
                },
                {
                    "sent": "I mean, everything in this world around some patterns basically and then we dataminers basically in the in the center of this pursuit for patterns and a discovery, however.",
                    "label": 0
                },
                {
                    "sent": "We are not really alone.",
                    "label": 0
                },
                {
                    "sent": "The many fields, especially in the scientific fields.",
                    "label": 0
                },
                {
                    "sent": "The people doing data analysis and data mining, and for the specific purposes.",
                    "label": 0
                },
                {
                    "sent": "And the sooner than I thought about this, and we saw that is very interesting to get people from other field to tell us their achievement and their algorithms and hopefully first data miner will be able to see wider and see further and in the future and basically will get better algorithms.",
                    "label": 0
                },
                {
                    "sent": "So for this talk we choose the field of computer vision, which is a few of which is extensive data analysis applications.",
                    "label": 0
                },
                {
                    "sent": "Today, we're very fortunate to have Professor Gent Indra Malik from University of California, Berkeley, to give us a keynote address on this particular topic.",
                    "label": 0
                },
                {
                    "sent": "Professor Matic is 1 the luminaries in computer vision and image analysis, so the title of his talk today is the future of Image Search.",
                    "label": 1
                },
                {
                    "sent": "Professor Malik received his B.Tech degree from India Institute of Technology Campus and his PhD degree from Stanford.",
                    "label": 0
                },
                {
                    "sent": "And he's currently at Berkeley as the author Cheek professor of Computer Science here serve as a chair of the Computer Science Division from 2002 and 2004, and also serve as the chair of the Department of EECS at Berkeley from 2004 and 2006.",
                    "label": 0
                },
                {
                    "sent": "He has received numerous medals and awards since his school years.",
                    "label": 0
                },
                {
                    "sent": "Yesterday I was talking to him like he said, me.",
                    "label": 0
                },
                {
                    "sent": "He told me, not say too much, OK?",
                    "label": 0
                },
                {
                    "sent": "So I was just giving you a few examples so he's received the gold medal for the best graduating students at IIT Campbell in 2000 and 1980.",
                    "label": 0
                },
                {
                    "sent": "1999 Hills will receive the Presidential Young Investigators Award here in US, of course.",
                    "label": 0
                },
                {
                    "sent": "And most importantly, his research has received languid Higgins test of Time price twice in 2007 and 2008, and he's a fellow of IEEE and has given many keynote speeches and so another thing he's very proud of.",
                    "label": 0
                },
                {
                    "sent": "His graduated 25 pages students which is a major contribution and they are mostly owing them permanent places in academia and industry.",
                    "label": 0
                },
                {
                    "sent": "And without further ado, let's inviting let's invite.",
                    "label": 0
                },
                {
                    "sent": "Professor Matic to give us the address.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, can you hear me?",
                    "label": 0
                },
                {
                    "sent": "Thank you Ben for this very kind introduction and thank you to the conference organizers for inviting me.",
                    "label": 0
                },
                {
                    "sent": "And I hope to tell you a little bit about my field and how it impacts a little bit on your field.",
                    "label": 0
                },
                {
                    "sent": "So to begin with, the title of my talk is the future of Image Search and I should start with saying that predictions are very foolhardy and there is this line from Niels Bohr which says it is difficult to make predictions, especially about the future.",
                    "label": 0
                },
                {
                    "sent": "So whenever anybody says the future of X, what they're really saying?",
                    "label": 1
                },
                {
                    "sent": "The president of X is this, and this is how we extrapolate.",
                    "label": 0
                },
                {
                    "sent": "And inevitably they're wrong.",
                    "label": 0
                },
                {
                    "sent": "So expect the same of me.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We must start with the motivation, so the motivation is that there are now billions of images on the web and in collections such as Flickr.",
                    "label": 1
                },
                {
                    "sent": "And people want access to this content and let's take an example.",
                    "label": 1
                },
                {
                    "sent": "Suppose I want to find pictures of monkeys.",
                    "label": 0
                },
                {
                    "sent": "Can you hear me in the back and please people wave OK.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what do I do?",
                    "label": 0
                },
                {
                    "sent": "Let's say I take whatever is my favorite web search engine.",
                    "label": 0
                },
                {
                    "sent": "I take Google Image search and I do a query for monkey.",
                    "label": 0
                },
                {
                    "sent": "So this query was run some time ago, so it maybe things are better now, but you get some.",
                    "label": 0
                },
                {
                    "sent": "Back",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back and then you look and things are not bad bad.",
                    "label": 0
                },
                {
                    "sent": "The first 2 queries indeed.",
                    "label": 0
                },
                {
                    "sent": "In fact our results are in fact monkeys.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then you get stuff here, which has.",
                    "label": 0
                },
                {
                    "sent": "I think it says no ordinary monkey.com.",
                    "label": 0
                },
                {
                    "sent": "And then this guy is website www.monkeybusiness.net.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's revealing to you what's going on, so the query is really not done on the basis of image content.",
                    "label": 0
                },
                {
                    "sent": "It's best done on the basis of.",
                    "label": 0
                },
                {
                    "sent": "Set up set relevant text file names.",
                    "label": 0
                },
                {
                    "sent": "Keywords, tags, etc and that's going to make some.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mistakes.",
                    "label": 0
                },
                {
                    "sent": "So, so the slogan here is that just.",
                    "label": 0
                },
                {
                    "sent": "Trying to do image search, ignoring the image is perhaps not a good idea.",
                    "label": 0
                },
                {
                    "sent": "We words are not enough.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I know we let's look at sort of the leading photo collection Flickr an we can do a search there and there there's a slight difference.",
                    "label": 0
                },
                {
                    "sent": "People are allowed to put in tags and they do and sometimes they are good and sometimes they are bad.",
                    "label": 0
                },
                {
                    "sent": "So if you do a Flickr search for the tag monkey, these are the kinds of results you get.",
                    "label": 1
                },
                {
                    "sent": "And some of these are reasonable, and some of these are not.",
                    "label": 0
                },
                {
                    "sent": "And the problem here is that the data is extremely noisy, so there there is the issue of what's called polysomy different meanings of that word photosets.",
                    "label": 1
                },
                {
                    "sent": "So sometimes what you have is people upload a collection of 100 photos and they label them all center Barbara trip.",
                    "label": 0
                },
                {
                    "sent": "Which is not how much use when you're trying to get something out, so the argument is tags are not enough either.",
                    "label": 1
                },
                {
                    "sent": "Dads are what we have today.",
                    "label": 0
                },
                {
                    "sent": "I mean, let's acknowledge the fact that this is currently how the work is done, and that's probably what it's going to be in the immediate future.",
                    "label": 0
                },
                {
                    "sent": "But there are some limitations and we hope to go beyond that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's look at the field of.",
                    "label": 0
                },
                {
                    "sent": "So there was a field of content based image retrieval which was somehow invented in the early 1990s.",
                    "label": 1
                },
                {
                    "sent": "Just ignores these things.",
                    "label": 0
                },
                {
                    "sent": "It's not quite important.",
                    "label": 0
                },
                {
                    "sent": "The details are not important, and the pioneering project was actually at IBM in the so called CU Project.",
                    "label": 0
                },
                {
                    "sent": "There was work that we did at Berkeley, and this is from Santa Barbara and various other projects, and mostly these projects were about using color and texture.",
                    "label": 1
                },
                {
                    "sent": "And why use color and texture?",
                    "label": 0
                },
                {
                    "sent": "Well, it's this old story of you.",
                    "label": 0
                },
                {
                    "sent": "Somebody went and saw somebody looking under looking for somewhere down the ground and this person said, what are you looking for?",
                    "label": 0
                },
                {
                    "sent": "I'm looking for my keys and then the person said where did you lose them?",
                    "label": 0
                },
                {
                    "sent": "He said over there then why looking there?",
                    "label": 0
                },
                {
                    "sent": "Well, this is where the light is OK.",
                    "label": 0
                },
                {
                    "sent": "So as researchers we tend to look under the light.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the light was color and texture histograms because we knew how to model them.",
                    "label": 1
                },
                {
                    "sent": "And here was the basic ideas.",
                    "label": 0
                },
                {
                    "sent": "So color histograms are you take an image, you divide it up into blocks.",
                    "label": 0
                },
                {
                    "sent": "Then you find the distribution of various colors.",
                    "label": 0
                },
                {
                    "sent": "What percentage is blue, green, yellow, red, etc.",
                    "label": 0
                },
                {
                    "sent": "You get a distribution that characterizes an image.",
                    "label": 0
                },
                {
                    "sent": "This is pretty good for finding sunsets.",
                    "label": 0
                },
                {
                    "sent": "If you try to find images with a lot lot of red, you'll get sunsets.",
                    "label": 0
                },
                {
                    "sent": "And so the Canonical example from any CBR.",
                    "label": 0
                },
                {
                    "sent": "From the 1990s was showing the detection of sunsets and then the second example was always a little bit tricky.",
                    "label": 0
                },
                {
                    "sent": "OK, you can do something based on texture and texture filters.",
                    "label": 0
                },
                {
                    "sent": "What we do is this is a bit more sophisticated.",
                    "label": 0
                },
                {
                    "sent": "We run some orientation sensitive filters, various Gaussian derivatives, gabors, whatever, and then the output of those filters we can again construct histograms and sort of carry through the same idea.",
                    "label": 0
                },
                {
                    "sent": "And but these are.",
                    "label": 0
                },
                {
                    "sent": "This essentially works in very, very limited settings.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it took us a little while to figure that out, but we did.",
                    "label": 0
                },
                {
                    "sent": "We have figured it out.",
                    "label": 1
                },
                {
                    "sent": "So give us credit for that.",
                    "label": 0
                },
                {
                    "sent": "And there is now a slogan which the multimedia community is very fond of using.",
                    "label": 0
                },
                {
                    "sent": "It's called the semantic gap, so the semantic gap is that the 1st generation CBR systems were based on color and texture and these do not capture what users are interested in.",
                    "label": 1
                },
                {
                    "sent": "So they are interested in pictures of monkeys or kids or Paris Hilton or whatever.",
                    "label": 0
                },
                {
                    "sent": "They're not interested in pictures which have 17% red, pretty 3% green.",
                    "label": 0
                },
                {
                    "sent": "That's just not what their queries are about.",
                    "label": 0
                },
                {
                    "sent": "We we have a lot of evidence from human perception about what are the cues for categorization, and that most important Q is shape and but this is ignored in all this work when we are considering color and texture.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So what just happened is that they've kind of been 2 tax.",
                    "label": 0
                },
                {
                    "sent": "If you look at the ACM multimedia conferences by and large, their conclusion from this is OK.",
                    "label": 0
                },
                {
                    "sent": "This is now hopeless.",
                    "label": 0
                },
                {
                    "sent": "The simple approaches didn't work.",
                    "label": 0
                },
                {
                    "sent": "Let's go off and try to develop good annotation tools so people we can bring the user in the loop and produce tags.",
                    "label": 0
                },
                {
                    "sent": "That's kind of what you.",
                    "label": 0
                },
                {
                    "sent": "I'm caricaturing a bit, but that's what the multimedia community is sort of come to push for in the computer vision community they stand has been.",
                    "label": 0
                },
                {
                    "sent": "Hey, we're trying to fight the good fight.",
                    "label": 0
                },
                {
                    "sent": "We'll try to solve the real fundamental problem of recognition based on shape.",
                    "label": 0
                },
                {
                    "sent": "And now the question is, what have we delivered in the last five to 10 years?",
                    "label": 0
                },
                {
                    "sent": "And I will argue that we have made substantial progress and it's not anywhere near human performance, but it's good enough that it's useful for some, and the derivative is high, so this is the promissory note aspect of the talk.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let's let's get some.",
                    "label": 0
                },
                {
                    "sent": "So here's the research program then.",
                    "label": 1
                },
                {
                    "sent": "So essentially we want to take images and analyze them and automatically generate annotations corresponding to object labels or activities in video.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "If if we can automatically generate those annotations, then of course these can be combined with other metadata and then these become the signal to be used for searching.",
                    "label": 0
                },
                {
                    "sent": "Because we believe that at at runtime, analyzing analyzing images is very expensive, so you don't want to be analyzing a billion images at runtime.",
                    "label": 0
                },
                {
                    "sent": "But if you have boiled down the content of the image into some some things that you're precomputed, then at runtime things can go pretty fast.",
                    "label": 0
                },
                {
                    "sent": "That's not that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Surprising, OK, so let's start with some context of what we know from human vision.",
                    "label": 0
                },
                {
                    "sent": "So there is nice slogan from pixels to perception, and in fact this is the basic difference between images and text image in text when you don't have syntactic error semantic analysis, you have words and words are very useful.",
                    "label": 1
                },
                {
                    "sent": "They tell you alot.",
                    "label": 0
                },
                {
                    "sent": "Pixels unfortunately are not that useful and isolated pixel tells you nothing of pixel which has.",
                    "label": 0
                },
                {
                    "sent": "Brightness value 183.",
                    "label": 0
                },
                {
                    "sent": "Tells you nothing whatsoever, however, about what's in there watching the image.",
                    "label": 0
                },
                {
                    "sent": "So that's the problem.",
                    "label": 0
                },
                {
                    "sent": "We have to move to these semantic categories.",
                    "label": 1
                },
                {
                    "sent": "We have to sort of break up the image into objects, label them water Tiger grass.",
                    "label": 0
                },
                {
                    "sent": "This labeling could of course be extended hierarchically, so let's.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you a little bit about what the problem is, the problem is what we call category recognition.",
                    "label": 1
                },
                {
                    "sent": "It's not recognizing something exactly the same, but something some some set of objects which share a family resemblance.",
                    "label": 0
                },
                {
                    "sent": "These are all faces, these are Flowers.",
                    "label": 0
                },
                {
                    "sent": "These are airplanes, elephants, cellphones, Buddhas.",
                    "label": 0
                },
                {
                    "sent": "Right we can.",
                    "label": 0
                },
                {
                    "sent": "Humans have no problem identifying this as one category, even though they're not identical.",
                    "label": 0
                },
                {
                    "sent": "So if you just took the image as a long vector and you took differences and those vectors, well, those would be quite significant here.",
                    "label": 0
                },
                {
                    "sent": "But humans have no problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so let's go and look at sort of the some of the key ideas here.",
                    "label": 0
                },
                {
                    "sent": "So there's an idea which goes back actually 100 years, which is due to someone called Darcy Thompson, who was a mathematical biologist nearly 100 years ago and he was studying, you know, skulls, for example, and what's common to all these skulls or these side views of faces.",
                    "label": 0
                },
                {
                    "sent": "So his basic idea was that you think of the describing shape is hard.",
                    "label": 0
                },
                {
                    "sent": "But describing changes among shapes is not that hard, so the idea is that you have some Canonical shape and then you have transformations of that shape which take you to these other examples and it's mathematically rather similar to the following idea.",
                    "label": 0
                },
                {
                    "sent": "You have some complex nonlinear thing.",
                    "label": 0
                },
                {
                    "sent": "I mean you don't know how to deal with it, but at an operating point you can linearize it and characterize it by its tangent plane, furious here.",
                    "label": 0
                },
                {
                    "sent": "Taylor series expansion, that sort of thing, and that's kind of what we're going to do.",
                    "label": 0
                },
                {
                    "sent": "We have a shape and then we consider deviations from that shape, and those deviations are easier to understand than the shape in the abstract.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                },
                {
                    "sent": "This of course, this idea essentially today the graphics people call it morphing from one shape to another, but it really goes back 100 years.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some other observations, so this is an example.",
                    "label": 0
                },
                {
                    "sent": "It's called Acnes Cat, which is meant to illustrate the importance of shape.",
                    "label": 0
                },
                {
                    "sent": "That's why line drawings work.",
                    "label": 1
                },
                {
                    "sent": "We have taken this image and replace.",
                    "label": 1
                },
                {
                    "sent": "Got rid of the color and texture.",
                    "label": 0
                },
                {
                    "sent": "We take the contour and even the contour we've replaced by a set of straight lines.",
                    "label": 0
                },
                {
                    "sent": "So it's really being boiled down to its fewest bits in some way.",
                    "label": 0
                },
                {
                    "sent": "And yet we can recognize this an.",
                    "label": 0
                },
                {
                    "sent": "However, if I told you the percentage of yellow and and red pixels in this image, it wouldn't let you know that it is a cat.",
                    "label": 0
                },
                {
                    "sent": "So so there is a lot of abstraction and generalization in our interpretation of an image.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is kind of a busy slide, but there are hierarchies in this notion of our notion of categories.",
                    "label": 0
                },
                {
                    "sent": "So, for example, cats are in the order validate which is mammal mammal.",
                    "label": 1
                },
                {
                    "sent": "So there's a hierarchy there, which we must be aware of, and recognition can be at these different levels of abstraction.",
                    "label": 0
                },
                {
                    "sent": "There could be something which I don't recognize, but I say, oh, it's a four legged animal.",
                    "label": 0
                },
                {
                    "sent": "OK, that's that's a good enough answer for certain purposes.",
                    "label": 0
                },
                {
                    "sent": "For certain purposes.",
                    "label": 0
                },
                {
                    "sent": "It it I have to be able to say.",
                    "label": 1
                },
                {
                    "sent": "This is my cat Bunty.",
                    "label": 0
                },
                {
                    "sent": "Then there is another hierarchy, which is that objects have parts.",
                    "label": 0
                },
                {
                    "sent": "They have subparts and so on, and in fact we can think of this for humans.",
                    "label": 1
                },
                {
                    "sent": "But actually it operates at the high level above objects.",
                    "label": 0
                },
                {
                    "sent": "Two objects are part of scenes, so right now we are part of a lecture scene where there are people and chairs and so on, and they are in some arrangement which is a much more loose special arrangement.",
                    "label": 0
                },
                {
                    "sent": "So here's a semi made up term patrona me.",
                    "label": 0
                },
                {
                    "sent": "So we have to worry about taxonomies and partner Gnomies.",
                    "label": 0
                },
                {
                    "sent": "Psychologists have actually given us a sense of how many categories humans can deal with, and there is this estimate of 30,000.",
                    "label": 0
                },
                {
                    "sent": "So when we scale up our visual recognition system, that's kind of the target to which we have to go to on the order of 30,000 visual categories.",
                    "label": 0
                },
                {
                    "sent": "The number of words in English is obviously more, but I mean a word like faith, Hope or charity doesn't necessarily have a visual connotation.",
                    "label": 0
                },
                {
                    "sent": "Well, in some very abstractions, yes, but I'm currently we're dealing with more concrete things, so 30,000 that's what we have to go to, and I'll give you examples which illustrate that where we are at today is on the order of 100.",
                    "label": 0
                },
                {
                    "sent": "So we today the state of computer vision is on the order of hundred categories and we need to go up basically two orders of magnitude from that.",
                    "label": 0
                },
                {
                    "sent": "And it's not just a computing limitation, it's also a limitation of ideas and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this I think gives you some flavor about the scope of the problem is it's been studied for quite some number of years in human visual perception and in computer vision, which dates back at least 40 years.",
                    "label": 0
                },
                {
                    "sent": "So I'll take you through some examples of how we think about this and some concrete results.",
                    "label": 0
                },
                {
                    "sent": "So here is one way of thinking about it.",
                    "label": 0
                },
                {
                    "sent": "Here is some image and I don't know what it is, but I have my.",
                    "label": 0
                },
                {
                    "sent": "I have a set of examples and these are labeled elephant Buddha flower.",
                    "label": 0
                },
                {
                    "sent": "ETC etc.",
                    "label": 0
                },
                {
                    "sent": "So what I do is I try to do a correspondence and matching between my query image and these exam plus and I evaluate a simile.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "City score and let's say the similarity score turns out to be the highest or the difference turns out to be the smallest between these two.",
                    "label": 0
                },
                {
                    "sent": "And then I'm in business.",
                    "label": 0
                },
                {
                    "sent": "That's my if you want to think of it, put it, put it in machine learning framework.",
                    "label": 0
                },
                {
                    "sent": "This is a nearest neighbor classifier with a certain distance function and there is something to be said about nearest neighbor classifiers.",
                    "label": 0
                },
                {
                    "sent": "Asymptotically given enough examples, our nearest neighbor classifier gets you within a factor of two of the optimal Bayesian classifier.",
                    "label": 0
                },
                {
                    "sent": "So always whenever fancy schemes are tried, remember the humble nearest neighbor classifier.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you notice I showed you these views, but you might ask.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Objects are actually 3 dimensional and our current thinking on this is that will appoint the problem.",
                    "label": 0
                },
                {
                    "sent": "Will we know how to solve 2-D22D matching problems?",
                    "label": 0
                },
                {
                    "sent": "So we'll deal with 3D objects by just storing multiple 2D views, so you have.",
                    "label": 1
                },
                {
                    "sent": "So here is this this Anderson box and what we'll do is we won't store a 3D single 3D model, but we'll store multiple two reviews and here also multiple 2D views and the matching machinery has to be robust too.",
                    "label": 0
                },
                {
                    "sent": "Working even though you have a small number of two day beers.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the answer is that you can actually do that.",
                    "label": 0
                },
                {
                    "sent": "Here is an experiment based on some work we had done a few years ago that we needed to.",
                    "label": 0
                },
                {
                    "sent": "So this is on the Y axis.",
                    "label": 0
                },
                {
                    "sent": "Is the error rate and the X axis is the number of examples you stored, and so these are different similarity functions and this is obviously the fanciest one that we have proposed an even with four prototypes per object we could get an error rate of two 3%.",
                    "label": 0
                },
                {
                    "sent": "So pretty small.",
                    "label": 0
                },
                {
                    "sent": "So this general idea.",
                    "label": 0
                },
                {
                    "sent": "If you cleverly select the views works that you can represent a 3D object by multiple two reviews and this makes life much easier because for natural objects we don't necessarily have 3D models available for industrial parts we do, but industrial parts are very small fraction of what we are interested in.",
                    "label": 0
                },
                {
                    "sent": "So if we can just work with images, life is better and that's our current paradigm.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how do we solve the correspondence problem?",
                    "label": 0
                },
                {
                    "sent": "How do we match different parts of an object to each other?",
                    "label": 0
                },
                {
                    "sent": "So I'm going to go through some of the ideas there talk about deformable template matching, and then how we use machine learning for fine.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Discriminative features OK, so the correspondence problem can be described this way.",
                    "label": 0
                },
                {
                    "sent": "So here are two 2 versions of the letter A and what we are somehow able to do.",
                    "label": 0
                },
                {
                    "sent": "Humans intuitively, is to say that these two.",
                    "label": 0
                },
                {
                    "sent": "Somehow our corresponding points and rate is a different point on the shape and these are not identical shapes, right?",
                    "label": 0
                },
                {
                    "sent": "But somehow we still have this notion of correspondence and this in other settings will mean that from one image, the tip of the nose can be matched to the tip of the nose in another image, and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, how do we do this?",
                    "label": 0
                },
                {
                    "sent": "And the secret is that we try to come up with some descriptor.",
                    "label": 0
                },
                {
                    "sent": "If I just look at that point, the point is the same, right?",
                    "label": 0
                },
                {
                    "sent": "But if I try to characterize some?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or extended neighborhood?",
                    "label": 0
                },
                {
                    "sent": "I can distinguish between the different points in the shape, so here's one idea.",
                    "label": 0
                },
                {
                    "sent": "You take this point, and you put a series of this kind of a dartboard like pattern.",
                    "label": 0
                },
                {
                    "sent": "Around that point and you count the number of.",
                    "label": 1
                },
                {
                    "sent": "I've sort of these these image points in each of these bins, so we count here.",
                    "label": 0
                },
                {
                    "sent": "You get 4 points and here you get 10 and so on and so forth, so that what it is doing is at around a point.",
                    "label": 1
                },
                {
                    "sent": "It is characterizing the distribution of other points and we call this the shape context.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is a point and then so we have got these different bins so that the bins are arranged in space so they have different angular orientations and at different distances.",
                    "label": 0
                },
                {
                    "sent": "So this is the distance accesses angular distance, so you get you get.",
                    "label": 0
                },
                {
                    "sent": "So we had this arrangement of 60 bins there.",
                    "label": 0
                },
                {
                    "sent": "And now we've got counts here.",
                    "label": 0
                },
                {
                    "sent": "So dark means more counts, so this is what the pattern around this point looks like.",
                    "label": 0
                },
                {
                    "sent": "So most of the action is below and to the right, which is captured here.",
                    "label": 0
                },
                {
                    "sent": "And consider this point.",
                    "label": 0
                },
                {
                    "sent": "What happens here around that the points are distributed equally all around you.",
                    "label": 0
                },
                {
                    "sent": "So therefore the distribution with respect to Theta is much more uniform, and so you get this distribution.",
                    "label": 0
                },
                {
                    "sent": "Now what is the case with these guys?",
                    "label": 0
                },
                {
                    "sent": "Unlike the original shape, these are now fixed length vectors.",
                    "label": 0
                },
                {
                    "sent": "Because we have we have.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Steel bins if I go back here I have.",
                    "label": 0
                },
                {
                    "sent": "I have a certain number of, so if I count 12345 and then there are twelve of these.",
                    "label": 0
                },
                {
                    "sent": "So I get 60 bins.",
                    "label": 0
                },
                {
                    "sent": "So now I've got a 60 length vector a fixed length vector which characterizes a part of an object.",
                    "label": 0
                },
                {
                    "sent": "We it's much easier.",
                    "label": 0
                },
                {
                    "sent": "Life is much easier with fixed length vectors.",
                    "label": 0
                },
                {
                    "sent": "That's what the whole theory of pattern recognition was developed for.",
                    "label": 0
                },
                {
                    "sent": "So we're taking our problem, which is more general and complicated, and coercing it into it's the mathematicians trick.",
                    "label": 0
                },
                {
                    "sent": "You don't know how to solve a problem, you convert it to something you do know how to solve, so we're converting it to the vector game, which we know how to play.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now what I described was one way of constructing local descriptors.",
                    "label": 0
                },
                {
                    "sent": "There are other ways.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is there's something we call geometric blurred where you take the image, you filter it with different oriented filters, you do some blurring, you sample, you get something.",
                    "label": 0
                },
                {
                    "sent": "OK, there are other descriptors that you may have heard of, like Sift which is due to David Lowe.",
                    "label": 0
                },
                {
                    "sent": "There's something called histogram of oriented gradients and so on.",
                    "label": 0
                },
                {
                    "sent": "So in the computer vision community there are three or four of these versions around depending on which group you are talking too, and they're all more or less the same and they all basically work.",
                    "label": 0
                },
                {
                    "sent": "OK, so at this point Once Upon a time we used to fight about who's descriptor was slightly better, but.",
                    "label": 0
                },
                {
                    "sent": "Basically, that's not what where the things are about.",
                    "label": 0
                },
                {
                    "sent": "They are all equally good.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have.",
                    "label": 0
                },
                {
                    "sent": "We can now describe local parts of a shape and we can describe them by fixed length vectors, so that's progress.",
                    "label": 0
                },
                {
                    "sent": "And this is one I think clever, very simple but clever idea that came out in the last 10 years and it has advanced the state of visual recognition, OK?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me illustrate the idea of deformable template matching.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So to remind.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have the problem.",
                    "label": 0
                },
                {
                    "sent": "This is the Darcy Thompson slide set of skulls, fish, etc.",
                    "label": 1
                },
                {
                    "sent": "And what we want to do is we are going to have to recognize one of these guys, but we will have stored examples which are slightly different shape but related by a transformation.",
                    "label": 0
                },
                {
                    "sent": "OK, so then how can we make things work?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here is an example.",
                    "label": 0
                },
                {
                    "sent": "So so I have stored in my previously examples which labels.",
                    "label": 0
                },
                {
                    "sent": "So this is a fish.",
                    "label": 0
                },
                {
                    "sent": "I know what it is.",
                    "label": 0
                },
                {
                    "sent": "Here is some unknown thing.",
                    "label": 0
                },
                {
                    "sent": "I don't know what it is.",
                    "label": 0
                },
                {
                    "sent": "So what I will try to do is I'll try to match them.",
                    "label": 0
                },
                {
                    "sent": "But in the process of matching I allow small deformations and if the two match as a then I will say OK.",
                    "label": 0
                },
                {
                    "sent": "This might very well be the same object category.",
                    "label": 0
                },
                {
                    "sent": "So let's do this so correspond.",
                    "label": 0
                },
                {
                    "sent": "So how do we transform?",
                    "label": 0
                },
                {
                    "sent": "Well, transformations actually require that you have a notion of correspondence.",
                    "label": 0
                },
                {
                    "sent": "You need to find what the corresponding points are.",
                    "label": 0
                },
                {
                    "sent": "So this guy matches this guy.",
                    "label": 0
                },
                {
                    "sent": "This tip of the nose matches the tip of the nose.",
                    "label": 0
                },
                {
                    "sent": "These various points on the fins match, etc, and that those are indicated here.",
                    "label": 0
                },
                {
                    "sent": "And how do we solve the correspondence problem?",
                    "label": 0
                },
                {
                    "sent": "So this is where those local shape descriptors come in.",
                    "label": 0
                },
                {
                    "sent": "The local shape descriptors unable us to.",
                    "label": 0
                },
                {
                    "sent": "To to say, what is the most similar point for for the two shapes.",
                    "label": 0
                },
                {
                    "sent": "So we solve the correspondence.",
                    "label": 0
                },
                {
                    "sent": "And then and then I can estimate.",
                    "label": 0
                },
                {
                    "sent": "I I apologize, I'm I guess consistently using this screen and maybe I should use that word, but I guess I'm right handed so you'll have to bear with it.",
                    "label": 0
                },
                {
                    "sent": "I should use the mouse, but anyway, so so these so you get the correspondences and then you transform by by thin plate spline and this shows the transformation.",
                    "label": 0
                },
                {
                    "sent": "So now this this guy starts to look like that.",
                    "label": 0
                },
                {
                    "sent": "And then we solve the correspondence again and we iterate and after a few transformations which are all smooth transformations using splines, the model starts to look very much like the target and we measure how much we had to transform by this measure of bending energy of the thin plate spline, and that's small, and so if we had started with a chair.",
                    "label": 0
                },
                {
                    "sent": "This wouldn't have worked.",
                    "label": 0
                },
                {
                    "sent": "You would have needed a much greater bending energy and that becomes your distance measure and then.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feed it into a nearest neighbor classifier and so we've tried this in different domains, an one classic domain for pattern recognition is handwritten digit recognition, and this is a problem which is their datasets for 15 years and people have been trying this and and there are different approaches based on support vector machines, nearest neighbors, neural networks, etc and our shape matching approached when we tried it.",
                    "label": 0
                },
                {
                    "sent": "Sort of immediately gave us sort of results.",
                    "label": 0
                },
                {
                    "sent": "Which are the best at that time.",
                    "label": 0
                },
                {
                    "sent": "And since then the problem people have got even even lower error rates.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is when the error rate is .63%.",
                    "label": 0
                },
                {
                    "sent": "You can actually show all the errors.",
                    "label": 0
                },
                {
                    "sent": "This is the data set is 10,000.",
                    "label": 0
                },
                {
                    "sent": "At Test digits and these are all the errors and some of these you will recognize are difficult even for humans.",
                    "label": 0
                },
                {
                    "sent": "So I think the good news is handwritten digit recognition is a problem we can really solve.",
                    "label": 0
                },
                {
                    "sent": "I I the proof of that is in the fact that, at least for me, my bank is Wells Fargo.",
                    "label": 0
                },
                {
                    "sent": "When I deposit checks in the ATM there, there's a handwritten amount there of the the amount of the check an those are all scanned in and read by a computer program and this stuff works.",
                    "label": 0
                },
                {
                    "sent": "I mean so so we can declare success on some part of the problem.",
                    "label": 0
                },
                {
                    "sent": "I mean the error rate is of .5% humans are not perfect either, so we may very well be hitting the limb.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "Here's another example.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you've seen these, so whenever you try to get a FREE Email account from Google or Yahoo or various other things, these captures seem to be very common.",
                    "label": 0
                },
                {
                    "sent": "So when we saw these we thought, OK, let's see.",
                    "label": 0
                },
                {
                    "sent": "We claim that we can do deformable shape matching, so you'll notice the usual pattern is there is some shape which is deformed and put in some noisy background and the idea here is to break your traditional OCR software, but for our technique, which is to try to do this deformable matching.",
                    "label": 0
                },
                {
                    "sent": "This is no problem at all, so this is we can do this 92% of the time.",
                    "label": 0
                },
                {
                    "sent": "So ever since that work, I mean, it was reported in the New York Times and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "I always every month I get some shady character who claims that he wants a copy of the software for doing some research, but obviously it's for people who are spammers who want to get, you know, lots of free accounts.",
                    "label": 0
                },
                {
                    "sent": "And the interesting thing I note here is that it's all in the public domain, so they could actually implement it.",
                    "label": 0
                },
                {
                    "sent": "And they're not doing it, so it must.",
                    "label": 0
                },
                {
                    "sent": "So my conclusion from this is that this kind of crime pays.",
                    "label": 0
                },
                {
                    "sent": "But not too much, so it's not worth it for them to go through the effort of actually doing this.",
                    "label": 0
                },
                {
                    "sent": "So people have since changed these captures, and if you see the new version, they're much much more distorted.",
                    "label": 0
                },
                {
                    "sent": "I think, but we haven't tried those, but I think we can really do those, so this is OK success story.",
                    "label": 0
                },
                {
                    "sent": "I mean I OK maybe you can say this is easy.",
                    "label": 0
                },
                {
                    "sent": "This is digits letters.",
                    "label": 0
                },
                {
                    "sent": "Well, let's accept our successes.",
                    "label": 0
                },
                {
                    "sent": "AI people have always been criticized for the failing.",
                    "label": 0
                },
                {
                    "sent": "That anything which succeeds is no longer regarded as part of AI.",
                    "label": 0
                },
                {
                    "sent": "So I hope not to be guilty of that.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now notice that everything here was actually you could put it in a machine learning framework, but it was a very simple machine learning framework, which is that nearest neighbor.",
                    "label": 0
                },
                {
                    "sent": "Now machine learning can actually do more for us and the best way to think about this is as disc learning discriminative features.",
                    "label": 1
                },
                {
                    "sent": "What features actually carry more information?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at that so.",
                    "label": 0
                },
                {
                    "sent": "So I'm trying to find some categories here, so this is a panda bear.",
                    "label": 0
                },
                {
                    "sent": "This is a rooster.",
                    "label": 0
                },
                {
                    "sent": "What patches are more informative and the goal of the algorithm will be to not wait all the features equally, but wait.",
                    "label": 0
                },
                {
                    "sent": "The red here indicates there's a Matlab.",
                    "label": 0
                },
                {
                    "sent": "Sort of visualization.",
                    "label": 0
                },
                {
                    "sent": "Things that red means are more important.",
                    "label": 0
                },
                {
                    "sent": "Feature blue means a less important feature.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two is illustrated here.",
                    "label": 0
                },
                {
                    "sent": "We're going to try to find these distance functions, but the distance function will be will be learned and the goal is to tweak the distance function such that the distance is within one category.",
                    "label": 0
                },
                {
                    "sent": "You know, from airplanes to airplanes are small, and but from airplanes to giraffes are large, so we'll take the machine learning paradigm to tune the distance function.",
                    "label": 0
                },
                {
                    "sent": "So how do we do that?",
                    "label": 0
                },
                {
                    "sent": "So a simple way of setting this up is.",
                    "label": 0
                },
                {
                    "sent": "Here is an image I there images J&K.",
                    "label": 1
                },
                {
                    "sent": "We know that the distance I&J are in the same category I and care in a different category.",
                    "label": 0
                },
                {
                    "sent": "So my goal is to make deicer K greater than the subject.",
                    "label": 0
                },
                {
                    "sent": "And note that we will always have to work in this paradigm that an image or any object can never be characterized by a single fixed length vector.",
                    "label": 0
                },
                {
                    "sent": "Like parts of images can be, but the image itself will have one image may have 100 features, another image may have 70 features.",
                    "label": 0
                },
                {
                    "sent": "We always have to work with that problem.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then this is kind of more of the details, so we have various features and for each feature we'll try to find the best matching feature in the other view.",
                    "label": 0
                },
                {
                    "sent": "And so I'm using big D for the that does full distance function, but that full distance function is made up of weights times elementary distance function which are for single features.",
                    "label": 0
                },
                {
                    "sent": "And so we have.",
                    "label": 0
                },
                {
                    "sent": "So we have a whole bunch of features here and then we have the distances of each of those features.",
                    "label": 0
                },
                {
                    "sent": "Dyesub K. The little days.",
                    "label": 0
                },
                {
                    "sent": "And here's another image and then I have the distances dij.",
                    "label": 0
                },
                {
                    "sent": "For each of those little features, OK. And so these features are all.",
                    "label": 0
                },
                {
                    "sent": "Focused on the distances and the features.",
                    "label": 0
                },
                {
                    "sent": "An image I so that defines the dimensionality of this vector.",
                    "label": 1
                },
                {
                    "sent": "These vectors which are now equal because they are all referred with respect to the focal image and now what we want to do is to make sure that the DIK which is a different category, is as a larger distance than the same category.",
                    "label": 0
                },
                {
                    "sent": "The distance between images and so essentially this becomes the equation the weights.",
                    "label": 0
                },
                {
                    "sent": "Dot product it here should be larger than these or I can take this difference vector.",
                    "label": 0
                },
                {
                    "sent": "This guy must be greater than 0.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so far so good.",
                    "label": 0
                },
                {
                    "sent": "And now we just throw in the usual SVM mumbo jumbo.",
                    "label": 0
                },
                {
                    "sent": "OK, so we want to get this guy greater than zero but we want to have some regularization so I apologize for sort of just waving my hands through this thing.",
                    "label": 0
                },
                {
                    "sent": "So this turns out to be it's.",
                    "label": 1
                },
                {
                    "sent": "It's pretty akin to it's some variation on that theme you you get a minimization problem with the weight vector and then this is kind of the penalty term.",
                    "label": 0
                },
                {
                    "sent": "So you want to not have too many of these guys and.",
                    "label": 0
                },
                {
                    "sent": "The machine that goes through OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see the results of this.",
                    "label": 0
                },
                {
                    "sent": "So what this enables us to do is learn distance function, where you put more weights or less weights on features which are more distinctive or or less distinctive over category.",
                    "label": 0
                },
                {
                    "sent": "That's what you learn at the end.",
                    "label": 0
                },
                {
                    "sent": "Basically so here is a challenge data set which was developed about, you know four.",
                    "label": 0
                },
                {
                    "sent": "So that's now four years ago.",
                    "label": 0
                },
                {
                    "sent": "And when this data set came out in 2004, people thought that this is this is a horribly challenging problem because at that recall that in 2003 or 2004 the problem which we thought we had solved was digits.",
                    "label": 0
                },
                {
                    "sent": "OK, we I could say we would also solve the problem of face detection.",
                    "label": 0
                },
                {
                    "sent": "That's where we were at.",
                    "label": 0
                },
                {
                    "sent": "We could do digits we could do faces and now this group of perona, an FEI Fei, and so on.",
                    "label": 0
                },
                {
                    "sent": "What they did was they collected images of 100 different categories from the web.",
                    "label": 0
                },
                {
                    "sent": "So these are images of pianos and various animals, and I think their stop.",
                    "label": 0
                },
                {
                    "sent": "So there's a pianos anchors.",
                    "label": 0
                },
                {
                    "sent": "Sort of Flowers, cell phones, etc etc.",
                    "label": 0
                },
                {
                    "sent": "So they're quite natural categories for each category they collected, say maybe 50 or 60 examples.",
                    "label": 0
                },
                {
                    "sent": "By doing a search based on text queries and then having a graduate student go through and collect sort of the right examples.",
                    "label": 0
                },
                {
                    "sent": "And So what do you think?",
                    "label": 0
                },
                {
                    "sent": "So those are hundred categories, so then so you have some data that you use for training and then you have some data at Test time.",
                    "label": 0
                },
                {
                    "sent": "And what's your expectation of how well an algorithm will do?",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, OK, I'll come to that.",
                    "label": 0
                },
                {
                    "sent": "But this is what our approach does, so we can try to.",
                    "label": 0
                },
                {
                    "sent": "We have a similarity based querying so we can take this image and try to find what on the basis of these distance functions.",
                    "label": 0
                },
                {
                    "sent": "What are the nearby?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sample so let me jump to the results.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "This is a curve which shows the Caltech 101 classification results on the X axis is the number of training examples and the Y axis is the performance correct?",
                    "label": 1
                },
                {
                    "sent": "So if you have more training examples, you do better.",
                    "label": 0
                },
                {
                    "sent": "That's what these curves show when the data set first came out.",
                    "label": 0
                },
                {
                    "sent": "The performance was here, so this is 2004.",
                    "label": 0
                },
                {
                    "sent": "This was 16% correct 16.",
                    "label": 0
                },
                {
                    "sent": "And the Caltech people.",
                    "label": 0
                },
                {
                    "sent": "So you could say another way, let me repeat 16% correct, which means 84% wrong.",
                    "label": 0
                },
                {
                    "sent": "OK, not something to be very proud about, but the Caltech people their logic was.",
                    "label": 0
                },
                {
                    "sent": "Hey, it is much better than chance because what is chance if you have hundred categories and you have to guess it would be 1%.",
                    "label": 0
                },
                {
                    "sent": "So it was 16 times better than chance an we were now moving forth in this world of really natural categories and if that technique works it was likely to be useful rather than very very constrained artificial kinds of examples.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Over the last three or four years, the performance has gone up, and so the technique that I just described this is the work of Andrea from your own singer and myself.",
                    "label": 0
                },
                {
                    "sent": "We get performance in the range of 65 or 66%, so that's a factor of four improvement in three years, and these other curves correspond to different approaches.",
                    "label": 0
                },
                {
                    "sent": "So we had this time for three years, where every conference we would go to OK, the number is gone up from 16 to 40 then.",
                    "label": 0
                },
                {
                    "sent": "5565 that kind of thing, and this is exciting.",
                    "label": 0
                },
                {
                    "sent": "This means that some real progress is being made.",
                    "label": 0
                },
                {
                    "sent": "And finally, now there are numbers which are in the range of 90% and this fellow Verma and Ray.",
                    "label": 0
                },
                {
                    "sent": "What they did was they took the leading clear for approaches and then they build a classifier on top of all these classifiers which which which and this is an idea which is well known in machine learning that if you combine various of these, so long as they are somewhat independent you can do better.",
                    "label": 0
                },
                {
                    "sent": "Answer Performance is now in the 90% range, so over four years we have gone from 16% correct to 90% correct, which is pretty good and I will this carry over and I don't know, but I this is the kind of thing which makes me feel good and optimistic that we're not just, you know.",
                    "label": 0
                },
                {
                    "sent": "Looking in some domain which nobody will ever succeeded.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is kind of the error rate I'll skip.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That OK, but now so after this heady success.",
                    "label": 0
                },
                {
                    "sent": "Let me bring everybody back to Earth and what's missing.",
                    "label": 0
                },
                {
                    "sent": "So you should.",
                    "label": 0
                },
                {
                    "sent": "You may have a may have gotten down to what was the cheat there.",
                    "label": 0
                },
                {
                    "sent": "These were isolated objects and simple backgrounds, right?",
                    "label": 1
                },
                {
                    "sent": "So I had.",
                    "label": 0
                },
                {
                    "sent": "One cell phone against the background, one elephant with some grass and trees, but they weren't like a scene with three elephant trees, rivers, mountains, all the rest right?",
                    "label": 0
                },
                {
                    "sent": "And the world doesn't give a single images like that.",
                    "label": 0
                },
                {
                    "sent": "There are quite a few like that, but it's by no means the universal case.",
                    "label": 0
                },
                {
                    "sent": "So real objects are part of scene, so we really need to understand how to process since and I should note there is some good news here.",
                    "label": 1
                },
                {
                    "sent": "There is one category where we have solved the general problem which is faces.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'll show you some results.",
                    "label": 0
                },
                {
                    "sent": "These are from Jackie Kennedy's group at CMU, and there's been several groups which are obtained.",
                    "label": 0
                },
                {
                    "sent": "Viola Jones is 1 Anne and there was earlier work for poachers group.",
                    "label": 0
                },
                {
                    "sent": "This is back in the late 90s and early 2000s that.",
                    "label": 0
                },
                {
                    "sent": "Effectively, we can say the computer vision community has killed this problem.",
                    "label": 0
                },
                {
                    "sent": "We can solve this problem of detecting faces and note that these are faces and scenes, right?",
                    "label": 0
                },
                {
                    "sent": "The faces have been detected here and they are part of a big image.",
                    "label": 0
                },
                {
                    "sent": "It's not that you have a single phase and a nice clean background which makes life easy.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So this works and now it's being used again.",
                    "label": 0
                },
                {
                    "sent": "Lots of image search can be image search engines exploit the fact that you can detect faces and build on it, so this is a success story now.",
                    "label": 0
                },
                {
                    "sent": "This took quite a lot of effort and a lot of tuning and lot of manners.",
                    "label": 0
                },
                {
                    "sent": "Now if the number of manners that went into building a face detection detector, if we had to do this for each of 30,000 categories, the computer vision community would be working at it for the next 1000 years.",
                    "label": 0
                },
                {
                    "sent": "OK, we can't possibly do that.",
                    "label": 0
                },
                {
                    "sent": "We really need something general.",
                    "label": 0
                },
                {
                    "sent": "But let me explain.",
                    "label": 0
                },
                {
                    "sent": "A little bit about what the what the key challenge is.",
                    "label": 0
                },
                {
                    "sent": "Why is this hard?",
                    "label": 0
                },
                {
                    "sent": "OK, and and then I'll.",
                    "label": 0
                },
                {
                    "sent": "I'll show you one result from our group which shows that we can do much better.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Had this problem and this is the reason why when we're trying to detect an object which is not an isolated object but an object which is part of a background, so is this?",
                    "label": 0
                },
                {
                    "sent": "Is this an X question X could be faces extra be giraffe sex could be cars X could be stop signs So what we do is that the current techniques for this are based on scanning.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we run a window so you put a little window down and you say in this window is there a face.",
                    "label": 0
                },
                {
                    "sent": "Then you slide that window.",
                    "label": 0
                },
                {
                    "sent": "And move it around so you move it from left to right, top to down and you in each of these windows.",
                    "label": 0
                },
                {
                    "sent": "Now you run your classifier for detecting a face OK. And of course the face could be small or big, so you must run these windows of varying sizes.",
                    "label": 0
                },
                {
                    "sent": "So what's the complexity now?",
                    "label": 0
                },
                {
                    "sent": "So for a given scale, for a given size or face, the complexity is number of pixels.",
                    "label": 0
                },
                {
                    "sent": "OK, and then it is times the number of sizes that you want to try.",
                    "label": 0
                },
                {
                    "sent": "OK, now you can tweak a little bit.",
                    "label": 0
                },
                {
                    "sent": "You can.",
                    "label": 0
                },
                {
                    "sent": "You don't need to search at every pixel.",
                    "label": 0
                },
                {
                    "sent": "Maybe in the if you look at one pixel then the second, then the pixel immediately to the right of it will probably be the same.",
                    "label": 0
                },
                {
                    "sent": "So you do some jumping and so on.",
                    "label": 0
                },
                {
                    "sent": "But you can see the horrendous computational complexity of this problem.",
                    "label": 0
                },
                {
                    "sent": "And this computational complexity brings with it some statistical hazards.",
                    "label": 0
                },
                {
                    "sent": "And the reason is when you have zillions of these windows to check.",
                    "label": 0
                },
                {
                    "sent": "Your false positive rates really go up, because imagine that you have a false positive rate per window of 0.01%, or people say, wow, that's impressive.",
                    "label": 0
                },
                {
                    "sent": "Now that you take that 0.01% and you multiply it by a million.",
                    "label": 0
                },
                {
                    "sent": "OK, now you are in trouble, right?",
                    "label": 0
                },
                {
                    "sent": "So that now you've got 10,000 false today.",
                    "label": 0
                },
                {
                    "sent": "Whatever, some 100 false detection.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of the problem.",
                    "label": 0
                },
                {
                    "sent": "We really.",
                    "label": 0
                },
                {
                    "sent": "So there is a statistical problem and there is a computational complexity problem.",
                    "label": 0
                },
                {
                    "sent": "So both of these have to be tackled and we have to tackle this not just for faces, but for 30,000 different categories.",
                    "label": 0
                },
                {
                    "sent": "And we have to tackle this without hand tuning for each category.",
                    "label": 0
                },
                {
                    "sent": "We all have graduate students, but not so many.",
                    "label": 0
                },
                {
                    "sent": "OK, I could assign one graduate student for faces, one for giraffes, one for zebras.",
                    "label": 0
                },
                {
                    "sent": "You know, it might take quite some time OK?",
                    "label": 0
                },
                {
                    "sent": "So so now we could ask the question.",
                    "label": 0
                },
                {
                    "sent": "Well it has worked for faces.",
                    "label": 0
                },
                {
                    "sent": "Why does it that technique scale?",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so first I'll say a little bit about how the face techniques they work.",
                    "label": 0
                },
                {
                    "sent": "They will based on boosted decision trees and the idea of a cascade.",
                    "label": 0
                },
                {
                    "sent": "So you have early rejection, so most so you make some quick tests which say for example, if in the entire image there is no feature, it's just like blank piece of white wall.",
                    "label": 0
                },
                {
                    "sent": "Then you can reject quickly.",
                    "label": 0
                },
                {
                    "sent": "Reject quickly and move on.",
                    "label": 0
                },
                {
                    "sent": "So that's the idea you want to reject quickly and then only look at detail where where many where it's more likely for there to be a phase now.",
                    "label": 0
                },
                {
                    "sent": "The problem with these boosted approach to boosting approaches is that they are very expensive at training time, and it's fine.",
                    "label": 0
                },
                {
                    "sent": "You can do it for faces.",
                    "label": 0
                },
                {
                    "sent": "The challenge is what if we want to work with multiple categories?",
                    "label": 0
                },
                {
                    "sent": "OK, and that's where when you want to scale up to more categories an essentially the boosting techniques basically don't scale up to lots of categories because the feature selection stage essentially requires it's a greedy kind of stage.",
                    "label": 0
                },
                {
                    "sent": "So you have to try sort of exponentially many combinations of features, and that there's been some tricks to deal with that, but fundamentally I don't believe that boosted decision tree technique, which has worked beautifully for faces.",
                    "label": 0
                },
                {
                    "sent": "Will work when we're trying to deal with hundreds of categories.",
                    "label": 0
                },
                {
                    "sent": "The training part really gives you the training part.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, for support vector machines is actually quite good.",
                    "label": 0
                },
                {
                    "sent": "But there's a well developed optimization machinery for it.",
                    "label": 0
                },
                {
                    "sent": "People have worked on it.",
                    "label": 0
                },
                {
                    "sent": "It's it's really works clearly, and it repeatedly and predictably.",
                    "label": 0
                },
                {
                    "sent": "The problem there is.",
                    "label": 0
                },
                {
                    "sent": "We can of course choose linear, SVM's or non linear SVM and linear SVM.",
                    "label": 0
                },
                {
                    "sent": "Things are good in terms of both evaluation and training.",
                    "label": 0
                },
                {
                    "sent": "But linear SVM's have limitations, and nonlinear SVM's turn out to are what you need, because most of the time we don't have linear hyper.",
                    "label": 0
                },
                {
                    "sent": "The decision boundaries are not linear, but for nonlinear SVM the problem is that at runtime your computational complexity is proportional to the number of support vectors that you keep, and this is horrendously hard and.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just give you some examples here.",
                    "label": 0
                },
                {
                    "sent": "And So what we have done is essentially a technique which which enables us to.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So much better than this, and this is work which is very recent work presented at CPR.",
                    "label": 0
                },
                {
                    "sent": "So branch umaji, Alexa.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bergen I OK so I'm going to skip these slides which about what support vector machine.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe we want to find decision boundaries.",
                    "label": 0
                },
                {
                    "sent": "We want to choose.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That decision boundary which has a maximum.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We like this guy because it has a maximum margin.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can do this in in some Hilbert space, and so we have boundaries which in the base space are nonlinear.",
                    "label": 0
                },
                {
                    "sent": "But in this high dimensional space are.",
                    "label": 0
                },
                {
                    "sent": "Again, in the high dimensional spaces are linear and in lower dimensional space they are curved and that's good.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'm so so now, so we so let's see.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to skip the the.",
                    "label": 0
                },
                {
                    "sent": "I mean we have features for this I am going to take a canonic problem domain which is pedestrian detection which is considered more challenging than face detection.",
                    "label": 0
                },
                {
                    "sent": "So these are typically people walking standing, that kind of thing.",
                    "label": 0
                },
                {
                    "sent": "And we have positive and.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples and use this to illustrate.",
                    "label": 0
                },
                {
                    "sent": "So the features that we use are not are you divide the image up into blocks and then you consider orientation histograms in each of these.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the problem what we're trying to do is.",
                    "label": 1
                },
                {
                    "sent": "So let me just explain the big idea here.",
                    "label": 1
                },
                {
                    "sent": "The big idea is that.",
                    "label": 0
                },
                {
                    "sent": "If we want to use support vector machines and we have nonlinear decision boundaries, then the computational complexity at runtime is prohibitively high.",
                    "label": 0
                },
                {
                    "sent": "So usually what happens is that you train your classifier, you're left with some support vectors.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have Isaiah Gaussian kernel and these might be in the thousands of few 1000 support vectors.",
                    "label": 0
                },
                {
                    "sent": "Then at runtime, you kind of have to take the inner product with each of those thousand support vectors, and now we have to do this at every location in the image.",
                    "label": 0
                },
                {
                    "sent": "At every scale.",
                    "label": 0
                },
                {
                    "sent": "And so we are dead, so nonlinear SVM's really can't be done used for detection in this setting.",
                    "label": 0
                },
                {
                    "sent": "So people in fact when they try to do users where they are forced to use linear speeds, which again which now have reduced power.",
                    "label": 0
                },
                {
                    "sent": "What we've got now is this result, which shows that for a set of nonlinear kernels we can do a major speed up, and our major speedup is we don't need to have a computational complexity complexity linear in the number of support vectors.",
                    "label": 0
                },
                {
                    "sent": "We can get it either logarithmically.",
                    "label": 0
                },
                {
                    "sent": "Exactly or in constant in the number of service support vectors with an approximation, and this is a big deal, because suppose you have 10,000 support support vectors.",
                    "label": 0
                },
                {
                    "sent": "Either it's over 10,000 or it is O of log 10,000 and there's no approximation or it is over one with a little bit of approximation.",
                    "label": 0
                },
                {
                    "sent": "So I'll just explain the idea.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea is that actually it turns out that.",
                    "label": 0
                },
                {
                    "sent": "There are certain kinds of kernels that are used in in computer vision.",
                    "label": 0
                },
                {
                    "sent": "Alot.",
                    "label": 0
                },
                {
                    "sent": "The most popular ones are are are Gaussians and and the so called intersection kernel and it turns out that for the Gaussian we can't help you.",
                    "label": 0
                },
                {
                    "sent": "But for the intersection kernel we have this chick.",
                    "label": 0
                },
                {
                    "sent": "It's a little trick but it it really makes a very big difference.",
                    "label": 0
                },
                {
                    "sent": "So the intersection kernel is the following it so it is a legitimate Mercer kernel and so on.",
                    "label": 1
                },
                {
                    "sent": "The basic idea is that when we take two histograms.",
                    "label": 0
                },
                {
                    "sent": "We really if you have two histograms A&BI, you take the minimum of those two.",
                    "label": 0
                },
                {
                    "sent": "Histograms at a bin and then you take some these up.",
                    "label": 0
                },
                {
                    "sent": "So if the two are identical, then obviously there's some will be one, and if they are not identical, there will be less than one.",
                    "label": 1
                },
                {
                    "sent": "So that's the intersection kernel, and in computer vision we use this for comparing color histograms orientation instead.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Times etc now.",
                    "label": 0
                },
                {
                    "sent": "So in any kernel based approach, the decision function is ultimately something like this weighted sum of these kernels, the inner product and that weighted sum for the intersection kernel.",
                    "label": 1
                },
                {
                    "sent": "You can expand it out to be them in.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of these guys.",
                    "label": 0
                },
                {
                    "sent": "And that's so the support vector machine, the usual constant number of support vectors times the cost of kernel computation, and here it's going to be proportional to the feature dimensions, because this computation of this K is going to be proportional to the.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Web dimensions.",
                    "label": 0
                },
                {
                    "sent": "And here is the trick, and every computer scientist knows that whenever you have a double summation, you should reverse the order of summation and see if something lucky works out.",
                    "label": 0
                },
                {
                    "sent": "So here you have an outer summation over support vectors.",
                    "label": 0
                },
                {
                    "sent": "Inner summation over dimensions.",
                    "label": 0
                },
                {
                    "sent": "You flip these around.",
                    "label": 0
                },
                {
                    "sent": "You get some term like this which now is factorizable for each dimension and it some in time something.",
                    "label": 0
                },
                {
                    "sent": "And now if you sort the excise sub J entries to finding them in is, it's trivial.",
                    "label": 0
                },
                {
                    "sent": "That's where the log rhythmic part comes in.",
                    "label": 0
                },
                {
                    "sent": "And you do this.",
                    "label": 0
                },
                {
                    "sent": "You can do this in advance, and I'm jumping over the D.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, but basically you might.",
                    "label": 0
                },
                {
                    "sent": "You can sort of just guess that mean sorting logarithmically right?",
                    "label": 0
                },
                {
                    "sent": "OK, so now the cost becomes logarithms or the log.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The number of support vectors is a big deal.",
                    "label": 0
                },
                {
                    "sent": "And then there is another trick which is this function is a smooth function, so you can approximate it by a P.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Swayze linear function and then it becomes constant, so that's what we call fast iks VM.",
                    "label": 0
                },
                {
                    "sent": "So there was a big deal for Fourier transforms in the 60s when instead of N squared you could do N log in, and this is a gain speed up like that, and it's not universal.",
                    "label": 0
                },
                {
                    "sent": "It isn't true for all these VM's, all nonlinear kernels, but for this class.",
                    "label": 0
                },
                {
                    "sent": "But this is important.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As for computer vision.",
                    "label": 0
                },
                {
                    "sent": "And these are just numbers which.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bear out this visit.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then it skipped this, but the basic thing was that with this we are able to get the best results on pedestrian detection.",
                    "label": 1
                },
                {
                    "sent": "And we didn't do rocket science in terms of thinking of this, that the techniques that we used are more or less standard.",
                    "label": 0
                },
                {
                    "sent": "But we could now afford to use a nonlinear kernel, because we had this trick and that gives us.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Better performance.",
                    "label": 0
                },
                {
                    "sent": "And these are some results where these are sort of the mistakes actually.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And other.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data sets I'm going to skip all this.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that is some generalization of this idea.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which I'm going to again skip and I'll try to conclude with.",
                    "label": 0
                },
                {
                    "sent": "This is my final slide.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So I tried to answer the question that I started the talk with.",
                    "label": 0
                },
                {
                    "sent": "What is the future we made search?",
                    "label": 1
                },
                {
                    "sent": "And making this bold claim that the secret of image search is that we have to do we have to get our hands dirty, solve the hard problem of shape based object recognition?",
                    "label": 0
                },
                {
                    "sent": "It may seem like a very hard problem and it is.",
                    "label": 1
                },
                {
                    "sent": "It's been worked on for many years, but in recent years advances in image features.",
                    "label": 0
                },
                {
                    "sent": "This is where the idea of those fixed length local descriptors comes in machine learning.",
                    "label": 0
                },
                {
                    "sent": "The user support vector machines, but type and many other techniques.",
                    "label": 0
                },
                {
                    "sent": "But notice that there's a lot of adaptation of the techniques because essentially we don't.",
                    "label": 0
                },
                {
                    "sent": "Our basic domain is not fixed length vectors.",
                    "label": 0
                },
                {
                    "sent": "Computing power, of course, and the availability of large data collection.",
                    "label": 1
                },
                {
                    "sent": "I mean, if you were working 20 years ago.",
                    "label": 0
                },
                {
                    "sent": "You simply want to hide the training data.",
                    "label": 0
                },
                {
                    "sent": "All that has made this possible.",
                    "label": 0
                },
                {
                    "sent": "I I'm not arguing that you should ignore all the other information that should be used.",
                    "label": 1
                },
                {
                    "sent": "Obviously we should use this image information together with all the other metadata.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I do believe that we are making significant progress.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you, I enjoyed your talk.",
                    "label": 1
                },
                {
                    "sent": "Could you comment about the trajectory of the increase in the number of concepts that humans learn that you said 30,000 psychology?",
                    "label": 0
                },
                {
                    "sent": "Think about 30,000.",
                    "label": 0
                },
                {
                    "sent": "Was it like 30,000 two year old or 4 year old?",
                    "label": 0
                },
                {
                    "sent": "Is there anything known about that?",
                    "label": 0
                },
                {
                    "sent": "Well, not that much.",
                    "label": 0
                },
                {
                    "sent": "I mean we know some but not.",
                    "label": 0
                },
                {
                    "sent": "I think that a 3 or 4 year old I mean already.",
                    "label": 0
                },
                {
                    "sent": "I have a 2 year old son and he is much better than any of my programs.",
                    "label": 0
                },
                {
                    "sent": "Maybe he was better than any other programs at 1 1/2 I would say I think that in language this has been studied and I think these go together so we have a notion of somehow there's a concept.",
                    "label": 0
                },
                {
                    "sent": "There's a category which you have to form in your mental easier mental language and this has a visual representation and a word associated with it and what we know is that from the age of 1 1/2 days a very rapid explosion.",
                    "label": 0
                },
                {
                    "sent": "So by the age of two.",
                    "label": 0
                },
                {
                    "sent": "Kids, sort of for all the common objects in their environment.",
                    "label": 0
                },
                {
                    "sent": "They know they have the concepts, so they may not know about iguanas, right?",
                    "label": 0
                },
                {
                    "sent": "Unless they have a picture book with iguanas.",
                    "label": 0
                },
                {
                    "sent": "But all the things that are relevant for their world, they are good at.",
                    "label": 0
                },
                {
                    "sent": "There is.",
                    "label": 0
                },
                {
                    "sent": "So I think 234.",
                    "label": 0
                },
                {
                    "sent": "They're really good.",
                    "label": 0
                },
                {
                    "sent": "There is one ability which which takes awhile to develop which is discriminating subtle differences among say faces.",
                    "label": 0
                },
                {
                    "sent": "And that there is evidence that even up to 12 or 13 the tablet ability is growing, improving.",
                    "label": 0
                },
                {
                    "sent": "One other question, if there's.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is, I said something about taxonomies and then I didn't say anything about it afterwards and I didn't say anything about it because I didn't have anything to say in the sense that we recognize that this is an important thing to do and this will obviously that's another way to bring a log arhythmic speedup right computer side, there's no.",
                    "label": 0
                },
                {
                    "sent": "Wherever you put a hierarchy, you go from N to log in, so that 30,000 if we could put a hierarchy, we might win, right?",
                    "label": 0
                },
                {
                    "sent": "But we haven't yet figured it out.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Which year?",
                    "label": 0
                },
                {
                    "sent": "Sure, do you think?",
                    "label": 1
                },
                {
                    "sent": "Will we reach human level of competence?",
                    "label": 0
                },
                {
                    "sent": "Which year will you reach?",
                    "label": 0
                },
                {
                    "sent": "We reach human level of competence.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is where I refer to the great authority of either Niels Bohr or it's also been attributed to Yogi Berra.",
                    "label": 0
                },
                {
                    "sent": "It is difficult to make predictions, especially about the future.",
                    "label": 0
                },
                {
                    "sent": "Someone over there.",
                    "label": 0
                },
                {
                    "sent": "But seriously, the path of AI is littered with these false predictions, so I think sometimes funding agencies forced me to say things, but.",
                    "label": 0
                },
                {
                    "sent": "A respectable audience like you guys, I can't do it.",
                    "label": 0
                },
                {
                    "sent": "So this number 30,000 reminds me of a number 20,000.",
                    "label": 0
                },
                {
                    "sent": "I used to hear in speech recognition back in the mid 80s when people were still working on digit recognition.",
                    "label": 0
                },
                {
                    "sent": "They talked about what I think they call.",
                    "label": 0
                },
                {
                    "sent": "Unrestricted vocabulary of 20,000, and they claim that was all the words that people knew.",
                    "label": 0
                },
                {
                    "sent": "I knew early on here you you prefaced your 30,000 by saying people do know more words than that, but I wonder if 30,000 is big enough for 30,000 is just the biggest number you can imagine, and that if we did get to 30,000 turn out it wouldn't be enough.",
                    "label": 0
                },
                {
                    "sent": "That 30,000 is a is a very crude guestimate.",
                    "label": 0
                },
                {
                    "sent": "It was done by Biederman who is a psychologist.",
                    "label": 0
                },
                {
                    "sent": "He opened up the dictionary at random.",
                    "label": 0
                },
                {
                    "sent": "He tried to sample which words, which words on the page were concrete nouns as opposed to abstract nouns like.",
                    "label": 0
                },
                {
                    "sent": "You know, like if you have the word pigeon, it's OK, but the word peace is not OK, and then you do apply some fudge factors and so on.",
                    "label": 0
                },
                {
                    "sent": "So I don't take the number that seriously.",
                    "label": 0
                },
                {
                    "sent": "I take that to mean anything between 10,000, two 100,000.",
                    "label": 0
                },
                {
                    "sent": "It gives me an order of magnitude and it tells me that I'm off by by two orders of magnitude.",
                    "label": 0
                },
                {
                    "sent": "It will probably be more than that.",
                    "label": 0
                },
                {
                    "sent": "So then I mean we know a little bit from of the data of the distribution of categories of images on the web.",
                    "label": 0
                },
                {
                    "sent": "It follows the usual power laws if slow kind of thing.",
                    "label": 0
                },
                {
                    "sent": "So there are categories which are very common faces and people.",
                    "label": 0
                },
                {
                    "sent": "And then there are these heavy tails, and that's where you have to just set a cut off.",
                    "label": 0
                },
                {
                    "sent": "And that's where that will cut off will determine whether it's thirty thousand, 100,000 or 1,000,000.",
                    "label": 0
                },
                {
                    "sent": "So I think most of these techniques can be divided into 2 phases.",
                    "label": 0
                },
                {
                    "sent": "First one is to extract features, seconds, how to build classifiers.",
                    "label": 0
                },
                {
                    "sent": "So my question is we have some progress is.",
                    "label": 0
                },
                {
                    "sent": "So for these two accounts, two aspects which one contribute more to this kind of improvement.",
                    "label": 0
                },
                {
                    "sent": "I would put OK, so as a vision person I'm always biased in favor of the features because that is where my skills come in most.",
                    "label": 0
                },
                {
                    "sent": "I think it's both, but I I think the I always think that.",
                    "label": 0
                },
                {
                    "sent": "So my advice to my graduate students always is first try to build a nearest neighbor classifier and nearest neighbor classifier will will force you to get the features right because you're not getting any heavy power from the classification machinery once it sort of makes sense.",
                    "label": 0
                },
                {
                    "sent": "Coenen SVM instead, our nearest neighbor, and you'll get 1020% on top.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, so I'm revealing my bias here, which is that I think work on the features is important, but.",
                    "label": 0
                },
                {
                    "sent": "That's only a mild bias.",
                    "label": 0
                },
                {
                    "sent": "I think that what is let me let me give a more serious answer, which is that I think that off the shelf machine learning techniques are not quite what work.",
                    "label": 1
                },
                {
                    "sent": "What is really needed is that that for this domain we have to somehow evolve the techniques in the way that is needed for this domain.",
                    "label": 0
                },
                {
                    "sent": "And that's really genuine.",
                    "label": 0
                },
                {
                    "sent": "Respectable research in machine learning.",
                    "label": 0
                },
                {
                    "sent": "I mean, if we talk about human learning, the most important category for humans is in fact visual learning.",
                    "label": 0
                },
                {
                    "sent": "About 30 to 50% of the brain is devoted to vision.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, this is the most important Canonical case for learning, so I wouldn't.",
                    "label": 0
                },
                {
                    "sent": "So it is at the moment which successfully tackle it.",
                    "label": 0
                },
                {
                    "sent": "There is one group in Bonn in Germany which is working on that.",
                    "label": 0
                },
                {
                    "sent": "But beyond that and IBM at a couple of patent on on trying to doing this, chemical recognition from images but not much has evolved down there.",
                    "label": 0
                },
                {
                    "sent": "Classical problem is when you want to search into a patent database we using a chemical structure.",
                    "label": 0
                },
                {
                    "sent": "You need to have first extracted chemical structures, but perhaps your approach could allow to do patent identification.",
                    "label": 0
                },
                {
                    "sent": "Buy without having first understood the chemical structure.",
                    "label": 0
                },
                {
                    "sent": "Have you have any vision or feelings on this?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I have not worked on that problem so I don't know how noisy the images are in the sense that they are scanned in and I don't know what the quality is of the bitmaps, but my prior I guess is that this is a doable problem because extracting linear structure is something which we can do.",
                    "label": 0
                },
                {
                    "sent": "I mean there are some algorithms for that which I didn't talk about because that was not the main focus on my talk.",
                    "label": 0
                },
                {
                    "sent": "But I think that we have pretty good techniques now for extracting lines and lines and curves, and that should help solve this problem.",
                    "label": 0
                },
                {
                    "sent": "And then of course there will be symbols, but that's the character recognition problem so.",
                    "label": 0
                },
                {
                    "sent": "I think it's it's a problem which I regard is something which should be solvable, thank you.",
                    "label": 0
                },
                {
                    "sent": "Michael.",
                    "label": 0
                }
            ]
        }
    }
}