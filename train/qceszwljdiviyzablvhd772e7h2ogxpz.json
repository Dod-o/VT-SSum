{
    "id": "qceszwljdiviyzablvhd772e7h2ogxpz",
    "title": "Supermodeling: Consensus by Synchronization of Alternative Models",
    "info": {
        "author": [
            "Gregory Duane, Macedonian Academy of Science and Arts"
        ],
        "published": "Nov. 8, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Data Modeling"
        ]
    },
    "url": "http://videolectures.net/solomon_duane_supermodeling/",
    "segmentation": [
        [
            "This is an approach to computational modeling generally that I think can be compared to artificial consciousness, and I'll tell you in a few minutes while I think that's the case.",
            "I've tried to list all the contributors, apologize to anybody who left off the list.",
            "Um?",
            "So to start."
        ],
        [
            "That starts with an approach to data assimilation.",
            "Data assimilation is.",
            "A test that that should happen all over the place, but really happens more in meteorology.",
            "Then another place is the situation where we have a computational model.",
            "That have a process of that creates new information as the model is running, so didn't give an instant of time.",
            "The The weather prediction model has its idea of what's going on objectively.",
            "That is to say, current forecast and we have new observations from the instruments.",
            "The task is to model.",
            "I mean to Mary the observations and the current state of the model.",
            "Because neither is typically completely right.",
            "And the main point is that the the model is not a slave to observations.",
            "The model is a semi autonomous system which is sort of nudged by the observations.",
            "Therefore."
        ],
        [
            "Um?",
            "Um, the the paradigm of synchronization of chaotic systems.",
            "Chaotic system being general dynamical system which represents.",
            "Or is both reality an model?",
            "The paradigm of synchronization of two such things is relevant, so there's going to have a pointer.",
            "Pointers on the far left.",
            "There is some sticks.",
            "Oh get into less trouble with these things.",
            "So, um.",
            "OK, so say this is your real world which is chaotic, so we represent it as a three variable or in system.",
            "This is your model.",
            "It's been known since 1990 that if we coupled his such things loosely, that is through only one of many variables, despite sensitive dependence on initial conditions, we can get them to synchronize.",
            "This works.",
            "If so, this what I'm showing you here is actually a 5 variable system.",
            "This is slave to that.",
            "If we simply substitute the X variable of one for the X variable of the other, then as I said, despite sensitive initial independence initial conditions, the difference goes to 0.",
            "Thing works for couple, why it doesn't always work doesn't work for couple Z so.",
            "If you're simply observing X, then simply observing X is enough to slave the whole model or in system to reality.",
            "To predict weather.",
            "Yes, question so.",
            "Talk about data data assimilation, so this means, as you observe the data you you substitute the state part of the state variables in your Audi model with the actual observed value rather than the predicted or simulated values.",
            "Yeah, and you just reminded me that this also works if we don't do complete replacement.",
            "If we simply have a nudging term or relaxation term here, OK, that's the point that I wanted to make.",
            "Would only allow you to actually make predictions like for for once, one step ahead or or with a limited horizon becausw you can't make the predictions in dependently unless you observe the real world as you go.",
            "Did the nudging part comes from the real observations?",
            "OK, but you can think of this as a continuous model of a discrete system.",
            "So that you you have to do this every so often, like every six hours and approximating every six hours is a continuous process.",
            "Is takes a bit of work, but it's OK.",
            "So in with him you make true predictions without refering to observations and then after six hours synchronize and then you run the model, make predictions for the next 6 hours.",
            "Yeah, OK?",
            "OK, so we step back.",
            "OK so my point is that what this is is, is perception of this is.",
            "Model of perceiving but not being slaved to reality."
        ],
        [
            "The idea of super modeling is to let a bunch of models perceive each other as well as reality.",
            "So here we have three models.",
            "Couple to each other.",
            "All the different arrows between any given pair of models correspond to different variables XY&Z.",
            "Which we used to nudge each other with different coefficients represented here.",
            "Um?",
            "And then we.",
            "Adapt.",
            "Yeah, the coefficients in some training regimen.",
            "So that this combination of models synchronized with each other as well as with reality.",
            "Yeah, is a better model than anyone considered individually or better than than simply the average of the models, which is what is typically done in.",
            "State of the art in climate projection you run different climate models and if you want to combine them then you take some form of weighted average after the fact.",
            "So this means you simulate each of the models for some.",
            "In advance without any synchronization between them.",
            "Any synchronization with reality you simulate.",
            "I don't know for 10 years you get the different predictions by the three models.",
            "Let's say that you have here and then you average those predictions.",
            "Yeah, I was blurring the difference between weather prediction and climate prediction and obviously in climate prediction.",
            "You turn the connection to reality off.",
            "And then you run the models for 10 years and then something I was about to say in that case.",
            "In that case, you're only interested in the overall shape of the attractor of either the individual model or the supermodel.",
            "You're not interested in the instantaneous state as your weather prediction.",
            "You don't care what's going to be happening on January 1st in 2050.",
            "You wanna know the overall shape of the attractor?",
            "Point is that you average the predictions post facto after the predictions are made.",
            "You don't make a new prediction by considering the three models in combination.",
            "That's the current state of the art, yes."
        ],
        [
            "OK. And what's wrong with that current state of the art is that.",
            "Um?",
            "These models differ widely in the magnitude of climate change by up to a factor, but better factor of two among them in the projected temperature increase globally averaged over the next 100 years.",
            "They're pretty much useless for for original long term regional projections because of the differences between them, and likewise for short term predictions.",
            "So the question is, can we do better than averaging?",
            "And so the Super modeling idea is to take the synchronization view of data assimilation and let the models synchronize with each other as well as as reality.",
            "And.",
            "The question is how do we?",
            "How do we connect the models?",
            "Well, it turns out.",
            "That's a.",
            "So in chaos synchronization it's easy if systems can be synchronized.",
            "If identical systems can be synchronized.",
            "And a few very few parameters and one.",
            "It's generally easy to extend the dynamical equations to synchronize parameters as well as states.",
            "So the learning isn't hard.",
            "And.",
            "Nudging, nudging means."
        ],
        [
            "Let's see we in the worst case we have till 11 right?",
            "You've got the lecture on mental health."
        ],
        [
            "People will start disappearing after 11.",
            "Um?",
            "Merging would mean that.",
            "Small pushing someday action.",
            "Translation of the English.",
            "Yeah.",
            "Thanks.",
            "Plus some, so we put back in next one equation, but then we just add some constant times.",
            "So we nudge.",
            "X1 to X you can.",
            "So here instead of completely replacing X with the value, compare the model of reality.",
            "You just had this small term correcting for this difference."
        ],
        [
            "OK. All don't worry about the details of this slide.",
            "Horizontal axis is era enological algorithmics scale.",
            "The P stands for Project Climate Model Intercomparison project.",
            "These are three different projects over the course of time to compare.",
            "Different climate models.",
            "And we see that the climate models are getting better.",
            "Point is, the black circles are just averages.",
            "And we always do better by averaging climate models.",
            "Aria is re analysis, which is the best estimate of truth.",
            "This is a pre industrial control run but with the same climate models but with different.",
            "Levels of forcing.",
            "What is axis mean?",
            "Wait, what?",
            "There on the right, no further on the left is better, right?",
            "This is era.",
            "OK. Yeah, so they're getting better overtime they still.",
            "Are widespread.",
            "Left"
        ],
        [
            "Combine.",
            "Right?",
            "Yeah.",
            "And, um.",
            "OK um.",
            "So, um.",
            "This is the last of my client Model Intercomparison Project and the point here is the magnitude of of the numbers that you see.",
            "This is the air and annual mean surface air temperatures.",
            "I see numbers like 24.",
            "Um so.",
            "Um?",
            "This is the mean state.",
            "I mean the mean model.",
            "And a point is, these numbers are pretty big."
        ],
        [
            "And this is for precipitation.",
            "The white areas are where less than 2/3 of the models even agree on the sign of precipitation change.",
            "So again, big divergent."
        ],
        [
            "Among the models.",
            "OK, and again, all of this is not just for climate modeling, it's for any situation where we have a computational model of an objective process where the objective process continues to provide data as the model is running.",
            "So to test the overall idea.",
            "First, did it with a just with simple Lawrence systems.",
            "Again, this is your Lawrence, your system, which you're calling truth.",
            "Um?",
            "And then you have three models of truth indexed by I, each of which has three variables XY&Z.",
            "And.",
            "So, um.",
            "In each of these three models you have the same dynamics that you have in truth, but with different parameters.",
            "That's what's different.",
            "I actually threw in an extra parameter to represent the fact that.",
            "Some models may have actually different equations, so I just added this constant term to see if we can deal with that.",
            "And then we have these big Kays nudge the models to truth.",
            "The seas are the connections nudging the models to each other.",
            "So for which both nudges and interconnects the model so so performance, both data assimilation and model synchronization at the same time, right?",
            "OK, so first we go through a training phase.",
            "Where, um.",
            "As I said, you can general when you have synchronization, you can generally add a dynamical law to adapt the parameters synchronized parameters as well as States and this is such an added equation for the parameters except the parameters in this case are these connection coefficients, not the internal parameters of the system.",
            "So this may not be the best way to do learning, but it's particularly simple way.",
            "Um?",
            "And.",
            "What?",
            "OK, what this says is that imagine integrating this this equation overtime.",
            "And what you're doing is taking a correlation.",
            "Between the difference, the synchronization error between any two models.",
            "And the the overall supermodel error where I'm taking the supermodel output to be the simply the average of the corresponding variables in the three models.",
            "Correlation between that era and the difference between the two models.",
            "You want to increase or decrease the coefficients depending on the magnitude & of that correlations that make sense.",
            "Time varying coefficients.",
            "These are not constant coefficients in the training phase, you let the coefficients be time varying, and then you freeze them and freeze them here.",
            "OK, so.",
            "OK um.",
            "And so the era.",
            "Rapidly goes to a small value, not zero.",
            "Turns out you know at first I thought this was some sort of local optimum, but the reason that it doesn't go all the way to 0 is simply that we're not.",
            "Um?",
            "Yeah.",
            "We're not doing complete replacement.",
            "So, um.",
            "Anyway, um.",
            "Now if we compare that to send to the error that we get from simply averaging the models get a lot less error from the supermodel, and we get from the average.",
            "Well, what if we did some kind of a weighted average instead?",
            "Well, I set this up.",
            "I set the parameters up so that in each of the three models there was exactly 1 equation.",
            "One of the three equations that was completely right where all the parameters were right.",
            "OK so um.",
            "You'd so if so one of the models has actually not the only best the equation, but it perfectly equation.",
            "But that doesn't help you at all.",
            "Tends to suggest that even a weighted average is much worse than the supermodel.",
            "Approach.",
            "Supermodel result"
        ],
        [
            "How?",
            "So what we have is a 3 way synchronization of.",
            "Well, if we had two models it would be 3 way.",
            "If it's more models it's more ways.",
            "Love, truth and alternative models and we're using sort of the collective synchronization effect.",
            "Um?",
            "And the learning law can be sort of that can be seen as sort of a generalization of heavy, heavy in learning and have been learning.",
            "Yeah, you rely on synchronous.",
            "If you have synchronization between neurons.",
            "Another side of a signups signups kits.",
            "I mean, the connection becomes stronger.",
            "Here, sort of a supervised version of the same thing where.",
            "A synapse become stronger if, as a result of the.",
            "Two neurons collectively do their thing in concert with reality."
        ],
        [
            "Um?",
            "And as I said, we're really interested in the overall attractor is not in the.",
            "On instantaneous states.",
            "So without telling you how we change the learning law, this is going from my simple learning law to a more standard approach to to machine learning.",
            "Although the attractors that we get with a simple learning law don't look bad either.",
            "I haven't found the result.",
            "This is just the attractor for one of the individual models.",
            "Tractor for another of the individual models.",
            "The grey in the background is."
        ],
        [
            "Ruth.",
            "Third model.",
            "I'm.",
            "Despite all that, I mean just despite the big differences from reality, the supermodel actually helps you.",
            "Um and a point that it's worth making is that.",
            "Um?",
            "Suppose we are.",
            "We're just interested in the statistical properties of the attractor.",
            "Something like globally average temperature.",
            "How?"
        ],
        [
            "Well, supposed, suppose this is X, the globally average temperature in the individual models."
        ],
        [
            "Still way off.",
            "But we get an attractor with the correct globally averaged.",
            "Temperature in log X.",
            "If I said that correctly."
        ],
        [
            "OK, and just to show you what the learning algorithm is that produced those results.",
            "So is due to work by.",
            "When event in Virgin, Frank Sultan and invigorating myself.",
            "Um?",
            "Here we introduce a cost function for the supermodel lattices supermodel.",
            "Just a function of the connection coefficients overtime.",
            "And I.",
            "We introduced kind of a damping factor in this cost function so that we're continuously re initializing.",
            "But as time goes on, we count the error less and less in the cost function.",
            "Is this game over T term gamma to the power term drops?",
            "Um?",
            "And minimizing that through, especially a gradient descent approach which.",
            "I'm not gonna be able to describe this talk.",
            "We got the attractors that I."
        ],
        [
            "Just showed you.",
            "OK, so.",
            "The rest of what I'm going to say corresponds to a whole bunch of questions that you might ask about this approach.",
            "The first one is a.",
            "What if we go from from simple things like Lawrence system to to models where there's a wide range of time scales?",
            "Well, this is such a model.",
            "XY and Z.",
            "It's actually another model due to Lawrence.",
            "Standard Lawrence model comes from.",
            "Taking equations for convection and just taking a few Fourier components of.",
            "Have a special fields.",
            "This corresponds to doing the same thing not with convection, but with another model for upper atmospheric circulation.",
            "And then we couple this to this other two variable model, which is a very simple model of color box model of the ocean.",
            "Where is TNS actually?",
            "Our temperature gradients from equator, equator to pole?",
            "We have one box representing equator, another box representing pole living the polar regions.",
            "And these constants that appear in these two equations are very small.",
            "So overall the ocean evolves on a much slower timescale than the atmosphere.",
            "So, but what I did, so I took three of these perturbed parameters in both the atmospheric and the Oceanic components.",
            "And I got the same phenomenon that the.",
            "A supermodel goes to truth.",
            "Over.",
            "Not too long period of time the the the ocean part of a supermodel goes to ocean truth.",
            "This is temperature gradient in the ocean.",
            "Turns out that what's really happening here is that.",
            "Inform the supermodel you're adding, nudging terms to these equations.",
            "So that.",
            "The nudging terms because these coefficients are smaller, much bigger than the.",
            "The dynamical terms you're basically forcing your ocean model to truth very quickly, and then using ocean observations to train the atmospheric model.",
            "But that's not a bad strategy.",
            "First, train the fast time scales using some sort of climatological average for the slow time skills.",
            "Then worry about training the ocean."
        ],
        [
            "More fundamental question.",
            "Is what happens if if all the models error in the same direction?",
            "If we have a bunch of experts, all of whom predict a temperature that is too high.",
            "Well, um.",
            "I mean, one thing you can do is is use the.",
            "Use the prediction.",
            "That's consistently the least wrong in the training phase and extrapolate outside of the range.",
            "That's obviously a high."
        ],
        [
            "A risky and unstable procedure, but you can try it with the Lawrence models.",
            "What happens if you take a parameter?",
            "Sigma was a parameter in the Lorenz system and what happens if you take all the sigmas in the.",
            "Individual models that comprise the supermodel to be greater than.",
            "The true signal.",
            "Well, if you allow the Kona connections to become negative.",
            "You still get a workable supermodel.",
            "If you remember the plots I showed you before, this is roughly the same scale of blown up.",
            "You know it's better than other nothing and better than averaging.",
            "But not as good as an ordinary supermodel with with positive connections.",
            "And this is still in weather prediction mode, where the where you're coupling it to reality.",
            "OK, so you're using your super model to predict weather again in the mode where you constantly have input every six hours analogously.",
            "But um.",
            "It turns out that.",
            "We think we can get this to work under some conditions.",
            "For some conditions in climate prediction mode where we just disconnect reality and let it run freely, but so far we've only seen it blow up.",
            "So need some.",
            "Predictions sign in the wrong direction.",
            "When you ever reach them, the average prediction will be in the wrong direction, not a few loud negative coefficients as the weights.",
            "OK, but this means that.",
            "You don't just have everything, but the fact or so if we.",
            "I mean there's a whole area of learning ensembles within the machine learning community, and they're the kind of approach that is most often taken is to average or majority vote or something along these lines on the predictions of the base classic words, the distinction is to another approach which is called stacking, where you actually learn.",
            "From the predictions of the basic models and reality, you have an extra learning layer where you don't just adopt the coefficients, but you really allow completely unrestricted learning.",
            "For example, you can learn to completely reverse the predictions of one of the models if one of the models consistently predicts the opposite of truth, and you say, oh, this is very easy.",
            "I just.",
            "Yeah, that's exactly the sort of thing I was looking for.",
            "OK, but I want to ask you how it's done, but why don't we talk about it later?",
            "Yeah, so essentially.",
            "Could use another learning problem where the predictions by the models and reality are important.",
            "You learn the connections.",
            "In this particular case from that.",
            "So it's a separate learning problem.",
            "So how you combine the predictions?",
            "OK, it's not just the averaging, but it's you.",
            "You learn general function approximation for the combination."
        ],
        [
            "OK. Um?",
            "The other big question is what are we doing here?",
            "Where we're running a bunch of climate models with training them on present day data so that we should be able to use this in weather prediction mode.",
            "But then what we're doing is we're asking what happens if we change the amount of carbon dioxide in the atmosphere or other greenhouse gases corresponds to changing one parameter.",
            "So you're training with a bunch of of models, and then you're somehow shifting the models.",
            "Uh, some parameter in the models that you think represents a real parameter.",
            "I picked row because if you go back to."
        ],
        [
            "Supermodels yeah row is the same role.",
            "Wasn't one of the parameters that varies among the different models.",
            "Rose just fixed parameters.",
            "Zero is CO2 level or some function thereof."
        ],
        [
            "So, um.",
            "OK, So what happens if you train with Withrow equals 28, which is a standard value Florence system.",
            "But then you shift row in both reality and models while the error goes up a little.",
            "If you shifted a lot.",
            "It's goes up a little more.",
            "Turns out this corresponds you can you can study bifurcations and Lawrence and this has been done.",
            "This is a large number from from here to here is a large number of bifurcations, I think it's on the order of maybe 100 something like that, but.",
            "And you can tell that by looking at the attractors.",
            "This almost looks like a quasi periodic thing.",
            "It's not like strange attractor anymore.",
            "This is the real equals 100.",
            "Yeah, the error is still pretty small.",
            "And certainly better than than averaging."
        ],
        [
            "OK, um both the simple learning law that I showed you and the.",
            "Even more, the one based on the more complicated cost function suffer from the possible problem of non global non global local Optima.",
            "So far, the only thing we've done with to get out of to deal with this is.",
            "Is that noise in one form or another?",
            "This is a fairly complicated of.",
            "Learning method.",
            "I'm not gonna describe, but the point is that.",
            "One measure of.",
            "Of the model is difference between autocorrelation functions of the truth and the supermodel.",
            "And, uh.",
            "This is for the three variables.",
            "The dotted line is for a deterministic learning scheme.",
            "Solid line is for a stochastic learning scheme.",
            "In all cases, Ungra is truth.",
            "In all cases, Stochastic City helps, not surprisingly.",
            "Using the method for learning the coefficients.",
            "Yeah, for example stochastic differential equation.",
            "Since then, before you know."
        ],
        [
            "How?",
            "OK, so far I've just been talking about Lorenz systems.",
            "Need to extend this to PDE's.",
            "Just before we go to anything as complicated as a climate model.",
            "I this is just promoted civil shinsky.",
            "Simple one time 1 space dimensional PDE.",
            "It's been used to represent propagation and that wave propagation and.",
            "Dissipative media.",
            "And, um.",
            "So, um.",
            "And if we couple these models not only discretely in time, but actually I guess we're not doing it discreetly in time here, but discretely in space.",
            "It's only to fix data points, which is what we want to do.",
            "I mean not only with weather prediction.",
            "Also, again, we don't just make.",
            "The observations are not only sparse and time every six hours, but there's Parson space.",
            "One question for PDS, then is can we say anything about?",
            "About how close the observations need to be in order to get synchronization.",
            "Well.",
            "This is a the two axes are spaced in time and you see propagating coherent structures.",
            "So actually this is not ordinary KSKS with this extra third derivative added which gives you wave propagation.",
            "Um?",
            "And, um.",
            "So what do we do if log is Ares?",
            "Is log Avera versus of nudging coefficient?",
            "The models are uncouple.",
            "The arrow slowly goes down.",
            "If we fix the connections between the models, so this is a manually set supermodel, not a trained supermodel.",
            "We do somewhat better, but if we adapt the connections according to the simple learning law, we do better yet.",
            "So, where, where are these coefficients in the equations on this slide?",
            "They're not there, because this is just one model.",
            "This is true, yeah?",
            "Many more coefficients for the PDS.",
            "Well, that's one question.",
            "How many independent the symmetry of this thing is simple, so we keep the connections.",
            "I mean we have just translational symmetry.",
            "There's no reason to think the connections should be different at different points.",
            "So we only have like a.",
            "Three or six independent connections.",
            "Put them for the ordinary differential equations.",
            "Then you were learning the coefficients.",
            "Yeah, in one of the schemes, coefficients evolved overtime and in the end you froze them.",
            "Here, in principle the coefficients would need to evolve over both time and space, and then you freeze them.",
            "Um?",
            "Very well, the coefficients are just functions of time, not functions of space.",
            "We assume that they are the same at all points in space.",
            "They stay that way.",
            "Why should they?",
            "Will discuss that offline OK."
        ],
        [
            "And, um.",
            "So what variables?",
            "So another question is what variable should we couple of performing a climate prediction supermodel?",
            "We don't really want a couple everything.",
            "Even independently of.",
            "If we assume we're working in physical space and we have translational symmetry, which we don't because topography changes, but.",
            "Uh, we still have lots of variables at each point and we don't need to work in physical space.",
            "So, um.",
            "Here what we did was to.",
            "I.",
            "Instead, OK first of all, instead of working in physical space, you can work in Fourier space or on a sphere, which this model is a model on a sphere of spherical harmonics are the basis functions.",
            "And you can compare coupling with the basis of spherical harmonics to basis of empirical orthogonal functions, otherwise known as principle components.",
            "The nudging timescale is basically one over the sea, or I think it was called KB 4.",
            "So as you go this way, the timescale is increasing, which means the nudging strength is decreasing, which means the era is going up.",
            "The grey is for spherical harmonics of the light Gray, or actually it's white.",
            "Here is fork using principle components and not surprisingly, we do somewhat better this role components.",
            "In each of these panels here, the horizontal axis represents the number of components that are coupled, and we need fewer ones to get the error down to effectively zero.",
            "If we are intelligence about choosing.",
            "The basis."
        ],
        [
            "I'm OK.",
            "I put these in here.",
            "I wasn't sure if there was going to be time or interest.",
            "This is a more complicated PDE, so across edges, traffic channel model used to represent weather.",
            "Let me just tell you quickly what this is.",
            "This is a two layer model.",
            "These are not two layers.",
            "These are two models.",
            "Each model.",
            "Satisfies this equation, which says that potential vorticity.",
            "I'll tell you what that is in a minute.",
            "This quantity Q is is almost conserved.",
            "This isn't effective derivative.",
            "It's conserved except for forcing and dissipation.",
            "This, uh, this isn't approximation that gets us beyond every Stokes that gives us some pretty realistic representation of some weather phenomena.",
            "Potential vorticity is sort of the curl vorticity would be like the curl of velocity.",
            "Potential vorticity is.",
            "A modification of that to include effects from the Earths rotation and from the fact that vortices.",
            "The stretcher compressed in each of the two layers and we still want conservation of angular momentum.",
            "Overall, that allows us to define the quantity Q which I'm not going to define here, but.",
            "But we chose this is a different kind of coupling.",
            "Jay is a Jacobian TDX the first term minus DX.",
            "The first term, TDY have a second term, minus TDY.",
            "The first term DDX of the first term of the second term.",
            "The derivatives of the stream function PSI give us velocity, so maybe you can take my word for it that this J normally gives you the affective component.",
            "We put the coupling into the affective component.",
            "And I describe this later.",
            "If anybody really wants to know.",
            "But the point is that even with this more complicated form of coupling, we can derive learning law for this."
        ],
        [
            "Simple models.",
            "And here is true.",
            "This is a model with a jet stream over the Atlantic.",
            "Some model with jet stream over the Pacific.",
            "Is there a little different at the beginning as time goes on, they synchronize both with each other and truth.",
            "So if you go back to the previous slide, you don't couple here over the.",
            "System variables, but you couple over these advective terms.",
            "You don't.",
            "Instead of you have something.",
            "More complicated than this.",
            "Yeah.",
            "Yeah, and there the lodging coefficient is something more complicated.",
            "Yeah yeah, but you can still do it.",
            "And the reason you do that."
        ],
        [
            "Is because if you do it this way.",
            "Then it turns out that.",
            "The the average of the solutions to the two model equations separately is exactly the solution to the model with the average forcing.",
            "In other words, with the jet stream over both Atlantic and Pacific, which is what you really want.",
            "So this requires extra knowledge on what would be a good term.",
            "Yeah, yeah.",
            "Case I could imagine somebody like me who is a machine learning per person doesn't know much about climate modeling.",
            "Still, I can understand the difference between system variables is a reasonable term to use for lodging, right?",
            "Whereas when we get to this, you know I have no knowledge of the climate modeling, so this for me is beyond beyond my reach.",
            "No.",
            "Well.",
            "No, I think that's an overstatement.",
            "Beyond your reach.",
            "But I don't think I want to explain it in the next.",
            "Yes."
        ],
        [
            "Um?",
            "You want see to be 1/2 in this simple case because.",
            "You want equal contributions from the two models and with a simple learning law, C does go to 1/2."
        ],
        [
            "OK um.",
            "I just stuck those few slides in because that was the most complicated case that we've dealt with so far in super modeling.",
            "But um.",
            "OK, so where are we and where we going?",
            "So so far if we have local Optima we rely just on stochasticity.",
            "But what we'd like to do is, is define triggers based on the state of.",
            "Of those individual models.",
            "But will tell us when we might need effectively in your tip.",
            "Mutation OK?",
            "These negative coefficients we need to do just as you said.",
            "Some super learning approach.",
            "That oh I'm sorry, not negative coefficients, but to tell us when we need to extrapolate away from the individual models.",
            "And, um.",
            "That's sort of a metal level.",
            "And another point is that was raised is how do we use our knowledge of the system?",
            "To restrict the number of of connections that we train separately, if we have translational symmetry, it's simple.",
            "But how do we use other kinds of symmetry?",
            "Or some sort of partial knowledge or guesses so that we don't.",
            "Need to risk overtraining with limited data.",
            "Um?",
            "With all of this, what we're dealing with is a situation where the amount of data is limited.",
            "We only appeared in climate prediction.",
            "We only have good data for the last 50 or 60 years, but we have as much computer time as we want to do the learning.",
            "So we need some more domain specificity.",
            "Yeah, in the way that we do the Super modeling overall, and that's that's kind of what I'd like to.",
            "To end with.",
            "Um?",
            "And what did I forget?",
            "Yeah, I said I was going to tell you why this is artificial consciousness that.",
            "Uh, I think data simulation clearly compared compared to perception.",
            "We have a bunch of alternative representations of the same model doing data simulation from each other.",
            "Then we have self perception.",
            "Could be called consciousness and synchronization at a much lower level.",
            "Figures in most theories of consciousness roll processing synchronized spike trains a synchronization at a higher level.",
            "Once the connection that I'd like to make.",
            "So.",
            "Anyway, um, so questions.",
            "Thank you very much babe.",
            "And the timing is perfect so we can test quite depression.",
            "Although they wouldn't make errors in the same way, so they would make errors in different places you would still.",
            "Encourage themselves into a total wrong direction.",
            "Is this a problem and public?",
            "Um?",
            "Well, if we in what and what?",
            "I'm calling weather prediction mode where we're nuts to reality, we don't have to worry about it.",
            "If we disconnect from reality.",
            "It doesn't run away.",
            "Empirically, I can say this.",
            "What is theoretically?",
            "Well, OK, in the case for the case where the coefficients are positive.",
            "It doesn't get outside of.",
            "The domain in which each model normally lives.",
            "I'm not sure I can come up with more intuition for it than that right now.",
            "Synchronize.",
            "Yeah, great.",
            "Well tested it with Lorenz systems.",
            "Tested it with Kuramoto sufficient ski in a very limited way so far with these weather prediction with these weather PD models.",
            "Um?",
            "And, um.",
            "I.",
            "The PDE is so far we've just used a simple learning love.",
            "The more complicated machine.",
            "Learning is too computationally expensive.",
            "OK, is there anything else?",
            "Question was very technical in the sense.",
            "Do you use Matlab or do you use Mathematica oh?",
            "Cause any input from the climate models and then the climate models leave on a supercomputer somewhere in Germany and you have this and that interface to actually obtain the data from the climate models or this kind of things.",
            "OK for Lawrence Systems and PZ these simple PZ everything's on the same computer for the climate models were still struggling with a question.",
            "There's a.",
            "There's a climate model couple are called Oasis and Europe.",
            "And in car in the US has a something called data simulation research testbed that it takes one copy of a model.",
            "Call OGO calls the truth.",
            "Another copy of the model calls it model does what's considered an identical twin experiment actually runs an ensemble of models for different purpose than this, so it runs in ensemble of models for the purpose of determining spreader background error which you need in common filtering, which is the way that assimilation is normally done.",
            "So we're trying to generalize all of this.",
            "Um and the ODS.",
            "Um?",
            "I use an old piece of software called DS Tool on my colleagues in Holland use Matlab.",
            "And for the stochastic stuff I'm planning to use Mathematica.",
            "I haven't gotten to it yet.",
            "Other stuff is in Fortran, it's everything all over the place.",
            "Miss access to his anything to do with R&S in the statistical packages?",
            "DS store the SSL is is it S2 or DS?",
            "No, it's DS tool for dynamical systems.",
            "Yeah, it's I think it was popular in the 90s.",
            "It's not even supported anymore, but I have it on my laptop.",
            "I can show you.",
            "But it allows you just to write a system of odies the way you would normally write them, simulate them immediately, that's all.",
            "Any other questions or comments?",
            "I have a couple of general questions so.",
            "Are there any conditions on the systems of ODS or models that you can use here in order to apply the synchronization approach?",
            "Or are some types of equations more prone, let's say separation than others?",
            "OK, I think that's about synchronization.",
            "It's not about super modeling per say.",
            "And.",
            "Um?",
            "What's about really?",
            "What variables you couple, it's usually.",
            "If you want, let's say to learn parts of the supermodel, either the component is or the interconnections.",
            "I guess you need to worry about this.",
            "At least, that's my intention.",
            "Certain certain types of models.",
            "Let's say if you simply look at the ody structures.",
            "Some highly nonlinear structures versus simple linear structures.",
            "There must be differences in how easy it is to synchronize.",
            "Um?",
            "Well, I mean the heart it has to do with.",
            "My thesis is that synchronize ability has to do with internal synchronization within a system.",
            "The more internally synchronized something is easier it is to synchronize it with something else.",
            "So if you have a high degree of coherence, if you have lots of coherent structures that tells you both something about the ease of synchronizing it with something else and about what you need to observe, which makes sense.",
            "I mean whether you need to observe the storms and track them, or the high pressure centers something coherent.",
            "So.",
            "He the hardest systems to synchronize, typically are Hamiltonian systems, but you can get synchronization with Hamiltonian systems.",
            "Different forms of synchronization.",
            "But I'm not sure we need to.",
            "I don't want to tell you about those different forms right now.",
            "Yeah, well the one I found was where the coherent structures tend to occur in the same place, but but everything else gets more spread out.",
            "It has to because it's Hamiltonian, so the face base can't volume face basically occupies can't collapse and still have synchronization, but does it OK?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an approach to computational modeling generally that I think can be compared to artificial consciousness, and I'll tell you in a few minutes while I think that's the case.",
                    "label": 0
                },
                {
                    "sent": "I've tried to list all the contributors, apologize to anybody who left off the list.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So to start.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That starts with an approach to data assimilation.",
                    "label": 0
                },
                {
                    "sent": "Data assimilation is.",
                    "label": 0
                },
                {
                    "sent": "A test that that should happen all over the place, but really happens more in meteorology.",
                    "label": 0
                },
                {
                    "sent": "Then another place is the situation where we have a computational model.",
                    "label": 0
                },
                {
                    "sent": "That have a process of that creates new information as the model is running, so didn't give an instant of time.",
                    "label": 0
                },
                {
                    "sent": "The The weather prediction model has its idea of what's going on objectively.",
                    "label": 0
                },
                {
                    "sent": "That is to say, current forecast and we have new observations from the instruments.",
                    "label": 0
                },
                {
                    "sent": "The task is to model.",
                    "label": 0
                },
                {
                    "sent": "I mean to Mary the observations and the current state of the model.",
                    "label": 0
                },
                {
                    "sent": "Because neither is typically completely right.",
                    "label": 0
                },
                {
                    "sent": "And the main point is that the the model is not a slave to observations.",
                    "label": 0
                },
                {
                    "sent": "The model is a semi autonomous system which is sort of nudged by the observations.",
                    "label": 0
                },
                {
                    "sent": "Therefore.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Um, the the paradigm of synchronization of chaotic systems.",
                    "label": 1
                },
                {
                    "sent": "Chaotic system being general dynamical system which represents.",
                    "label": 0
                },
                {
                    "sent": "Or is both reality an model?",
                    "label": 0
                },
                {
                    "sent": "The paradigm of synchronization of two such things is relevant, so there's going to have a pointer.",
                    "label": 0
                },
                {
                    "sent": "Pointers on the far left.",
                    "label": 0
                },
                {
                    "sent": "There is some sticks.",
                    "label": 0
                },
                {
                    "sent": "Oh get into less trouble with these things.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "OK, so say this is your real world which is chaotic, so we represent it as a three variable or in system.",
                    "label": 0
                },
                {
                    "sent": "This is your model.",
                    "label": 0
                },
                {
                    "sent": "It's been known since 1990 that if we coupled his such things loosely, that is through only one of many variables, despite sensitive dependence on initial conditions, we can get them to synchronize.",
                    "label": 1
                },
                {
                    "sent": "This works.",
                    "label": 0
                },
                {
                    "sent": "If so, this what I'm showing you here is actually a 5 variable system.",
                    "label": 0
                },
                {
                    "sent": "This is slave to that.",
                    "label": 1
                },
                {
                    "sent": "If we simply substitute the X variable of one for the X variable of the other, then as I said, despite sensitive initial independence initial conditions, the difference goes to 0.",
                    "label": 0
                },
                {
                    "sent": "Thing works for couple, why it doesn't always work doesn't work for couple Z so.",
                    "label": 0
                },
                {
                    "sent": "If you're simply observing X, then simply observing X is enough to slave the whole model or in system to reality.",
                    "label": 0
                },
                {
                    "sent": "To predict weather.",
                    "label": 1
                },
                {
                    "sent": "Yes, question so.",
                    "label": 0
                },
                {
                    "sent": "Talk about data data assimilation, so this means, as you observe the data you you substitute the state part of the state variables in your Audi model with the actual observed value rather than the predicted or simulated values.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and you just reminded me that this also works if we don't do complete replacement.",
                    "label": 0
                },
                {
                    "sent": "If we simply have a nudging term or relaxation term here, OK, that's the point that I wanted to make.",
                    "label": 0
                },
                {
                    "sent": "Would only allow you to actually make predictions like for for once, one step ahead or or with a limited horizon becausw you can't make the predictions in dependently unless you observe the real world as you go.",
                    "label": 0
                },
                {
                    "sent": "Did the nudging part comes from the real observations?",
                    "label": 0
                },
                {
                    "sent": "OK, but you can think of this as a continuous model of a discrete system.",
                    "label": 0
                },
                {
                    "sent": "So that you you have to do this every so often, like every six hours and approximating every six hours is a continuous process.",
                    "label": 0
                },
                {
                    "sent": "Is takes a bit of work, but it's OK.",
                    "label": 0
                },
                {
                    "sent": "So in with him you make true predictions without refering to observations and then after six hours synchronize and then you run the model, make predictions for the next 6 hours.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so we step back.",
                    "label": 1
                },
                {
                    "sent": "OK so my point is that what this is is, is perception of this is.",
                    "label": 0
                },
                {
                    "sent": "Model of perceiving but not being slaved to reality.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea of super modeling is to let a bunch of models perceive each other as well as reality.",
                    "label": 1
                },
                {
                    "sent": "So here we have three models.",
                    "label": 0
                },
                {
                    "sent": "Couple to each other.",
                    "label": 0
                },
                {
                    "sent": "All the different arrows between any given pair of models correspond to different variables XY&Z.",
                    "label": 0
                },
                {
                    "sent": "Which we used to nudge each other with different coefficients represented here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then we.",
                    "label": 0
                },
                {
                    "sent": "Adapt.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the coefficients in some training regimen.",
                    "label": 0
                },
                {
                    "sent": "So that this combination of models synchronized with each other as well as with reality.",
                    "label": 0
                },
                {
                    "sent": "Yeah, is a better model than anyone considered individually or better than than simply the average of the models, which is what is typically done in.",
                    "label": 0
                },
                {
                    "sent": "State of the art in climate projection you run different climate models and if you want to combine them then you take some form of weighted average after the fact.",
                    "label": 0
                },
                {
                    "sent": "So this means you simulate each of the models for some.",
                    "label": 0
                },
                {
                    "sent": "In advance without any synchronization between them.",
                    "label": 0
                },
                {
                    "sent": "Any synchronization with reality you simulate.",
                    "label": 0
                },
                {
                    "sent": "I don't know for 10 years you get the different predictions by the three models.",
                    "label": 0
                },
                {
                    "sent": "Let's say that you have here and then you average those predictions.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I was blurring the difference between weather prediction and climate prediction and obviously in climate prediction.",
                    "label": 0
                },
                {
                    "sent": "You turn the connection to reality off.",
                    "label": 0
                },
                {
                    "sent": "And then you run the models for 10 years and then something I was about to say in that case.",
                    "label": 0
                },
                {
                    "sent": "In that case, you're only interested in the overall shape of the attractor of either the individual model or the supermodel.",
                    "label": 0
                },
                {
                    "sent": "You're not interested in the instantaneous state as your weather prediction.",
                    "label": 0
                },
                {
                    "sent": "You don't care what's going to be happening on January 1st in 2050.",
                    "label": 0
                },
                {
                    "sent": "You wanna know the overall shape of the attractor?",
                    "label": 0
                },
                {
                    "sent": "Point is that you average the predictions post facto after the predictions are made.",
                    "label": 0
                },
                {
                    "sent": "You don't make a new prediction by considering the three models in combination.",
                    "label": 0
                },
                {
                    "sent": "That's the current state of the art, yes.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. And what's wrong with that current state of the art is that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "These models differ widely in the magnitude of climate change by up to a factor, but better factor of two among them in the projected temperature increase globally averaged over the next 100 years.",
                    "label": 0
                },
                {
                    "sent": "They're pretty much useless for for original long term regional projections because of the differences between them, and likewise for short term predictions.",
                    "label": 0
                },
                {
                    "sent": "So the question is, can we do better than averaging?",
                    "label": 1
                },
                {
                    "sent": "And so the Super modeling idea is to take the synchronization view of data assimilation and let the models synchronize with each other as well as as reality.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The question is how do we?",
                    "label": 0
                },
                {
                    "sent": "How do we connect the models?",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out.",
                    "label": 0
                },
                {
                    "sent": "That's a.",
                    "label": 1
                },
                {
                    "sent": "So in chaos synchronization it's easy if systems can be synchronized.",
                    "label": 0
                },
                {
                    "sent": "If identical systems can be synchronized.",
                    "label": 0
                },
                {
                    "sent": "And a few very few parameters and one.",
                    "label": 0
                },
                {
                    "sent": "It's generally easy to extend the dynamical equations to synchronize parameters as well as states.",
                    "label": 0
                },
                {
                    "sent": "So the learning isn't hard.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Nudging, nudging means.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see we in the worst case we have till 11 right?",
                    "label": 0
                },
                {
                    "sent": "You've got the lecture on mental health.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People will start disappearing after 11.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Merging would mean that.",
                    "label": 0
                },
                {
                    "sent": "Small pushing someday action.",
                    "label": 0
                },
                {
                    "sent": "Translation of the English.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Plus some, so we put back in next one equation, but then we just add some constant times.",
                    "label": 0
                },
                {
                    "sent": "So we nudge.",
                    "label": 0
                },
                {
                    "sent": "X1 to X you can.",
                    "label": 0
                },
                {
                    "sent": "So here instead of completely replacing X with the value, compare the model of reality.",
                    "label": 0
                },
                {
                    "sent": "You just had this small term correcting for this difference.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. All don't worry about the details of this slide.",
                    "label": 0
                },
                {
                    "sent": "Horizontal axis is era enological algorithmics scale.",
                    "label": 0
                },
                {
                    "sent": "The P stands for Project Climate Model Intercomparison project.",
                    "label": 0
                },
                {
                    "sent": "These are three different projects over the course of time to compare.",
                    "label": 0
                },
                {
                    "sent": "Different climate models.",
                    "label": 0
                },
                {
                    "sent": "And we see that the climate models are getting better.",
                    "label": 0
                },
                {
                    "sent": "Point is, the black circles are just averages.",
                    "label": 0
                },
                {
                    "sent": "And we always do better by averaging climate models.",
                    "label": 0
                },
                {
                    "sent": "Aria is re analysis, which is the best estimate of truth.",
                    "label": 0
                },
                {
                    "sent": "This is a pre industrial control run but with the same climate models but with different.",
                    "label": 0
                },
                {
                    "sent": "Levels of forcing.",
                    "label": 0
                },
                {
                    "sent": "What is axis mean?",
                    "label": 0
                },
                {
                    "sent": "Wait, what?",
                    "label": 0
                },
                {
                    "sent": "There on the right, no further on the left is better, right?",
                    "label": 0
                },
                {
                    "sent": "This is era.",
                    "label": 0
                },
                {
                    "sent": "OK. Yeah, so they're getting better overtime they still.",
                    "label": 0
                },
                {
                    "sent": "Are widespread.",
                    "label": 0
                },
                {
                    "sent": "Left",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Combine.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "This is the last of my client Model Intercomparison Project and the point here is the magnitude of of the numbers that you see.",
                    "label": 0
                },
                {
                    "sent": "This is the air and annual mean surface air temperatures.",
                    "label": 0
                },
                {
                    "sent": "I see numbers like 24.",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This is the mean state.",
                    "label": 0
                },
                {
                    "sent": "I mean the mean model.",
                    "label": 0
                },
                {
                    "sent": "And a point is, these numbers are pretty big.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is for precipitation.",
                    "label": 0
                },
                {
                    "sent": "The white areas are where less than 2/3 of the models even agree on the sign of precipitation change.",
                    "label": 1
                },
                {
                    "sent": "So again, big divergent.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Among the models.",
                    "label": 0
                },
                {
                    "sent": "OK, and again, all of this is not just for climate modeling, it's for any situation where we have a computational model of an objective process where the objective process continues to provide data as the model is running.",
                    "label": 0
                },
                {
                    "sent": "So to test the overall idea.",
                    "label": 0
                },
                {
                    "sent": "First, did it with a just with simple Lawrence systems.",
                    "label": 0
                },
                {
                    "sent": "Again, this is your Lawrence, your system, which you're calling truth.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then you have three models of truth indexed by I, each of which has three variables XY&Z.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "In each of these three models you have the same dynamics that you have in truth, but with different parameters.",
                    "label": 1
                },
                {
                    "sent": "That's what's different.",
                    "label": 0
                },
                {
                    "sent": "I actually threw in an extra parameter to represent the fact that.",
                    "label": 0
                },
                {
                    "sent": "Some models may have actually different equations, so I just added this constant term to see if we can deal with that.",
                    "label": 0
                },
                {
                    "sent": "And then we have these big Kays nudge the models to truth.",
                    "label": 0
                },
                {
                    "sent": "The seas are the connections nudging the models to each other.",
                    "label": 0
                },
                {
                    "sent": "So for which both nudges and interconnects the model so so performance, both data assimilation and model synchronization at the same time, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so first we go through a training phase.",
                    "label": 0
                },
                {
                    "sent": "Where, um.",
                    "label": 0
                },
                {
                    "sent": "As I said, you can general when you have synchronization, you can generally add a dynamical law to adapt the parameters synchronized parameters as well as States and this is such an added equation for the parameters except the parameters in this case are these connection coefficients, not the internal parameters of the system.",
                    "label": 0
                },
                {
                    "sent": "So this may not be the best way to do learning, but it's particularly simple way.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "OK, what this says is that imagine integrating this this equation overtime.",
                    "label": 0
                },
                {
                    "sent": "And what you're doing is taking a correlation.",
                    "label": 0
                },
                {
                    "sent": "Between the difference, the synchronization error between any two models.",
                    "label": 0
                },
                {
                    "sent": "And the the overall supermodel error where I'm taking the supermodel output to be the simply the average of the corresponding variables in the three models.",
                    "label": 0
                },
                {
                    "sent": "Correlation between that era and the difference between the two models.",
                    "label": 0
                },
                {
                    "sent": "You want to increase or decrease the coefficients depending on the magnitude & of that correlations that make sense.",
                    "label": 0
                },
                {
                    "sent": "Time varying coefficients.",
                    "label": 0
                },
                {
                    "sent": "These are not constant coefficients in the training phase, you let the coefficients be time varying, and then you freeze them and freeze them here.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "And so the era.",
                    "label": 0
                },
                {
                    "sent": "Rapidly goes to a small value, not zero.",
                    "label": 0
                },
                {
                    "sent": "Turns out you know at first I thought this was some sort of local optimum, but the reason that it doesn't go all the way to 0 is simply that we're not.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "We're not doing complete replacement.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Anyway, um.",
                    "label": 0
                },
                {
                    "sent": "Now if we compare that to send to the error that we get from simply averaging the models get a lot less error from the supermodel, and we get from the average.",
                    "label": 0
                },
                {
                    "sent": "Well, what if we did some kind of a weighted average instead?",
                    "label": 0
                },
                {
                    "sent": "Well, I set this up.",
                    "label": 0
                },
                {
                    "sent": "I set the parameters up so that in each of the three models there was exactly 1 equation.",
                    "label": 0
                },
                {
                    "sent": "One of the three equations that was completely right where all the parameters were right.",
                    "label": 0
                },
                {
                    "sent": "OK so um.",
                    "label": 0
                },
                {
                    "sent": "You'd so if so one of the models has actually not the only best the equation, but it perfectly equation.",
                    "label": 0
                },
                {
                    "sent": "But that doesn't help you at all.",
                    "label": 0
                },
                {
                    "sent": "Tends to suggest that even a weighted average is much worse than the supermodel.",
                    "label": 0
                },
                {
                    "sent": "Approach.",
                    "label": 0
                },
                {
                    "sent": "Supermodel result",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "So what we have is a 3 way synchronization of.",
                    "label": 1
                },
                {
                    "sent": "Well, if we had two models it would be 3 way.",
                    "label": 0
                },
                {
                    "sent": "If it's more models it's more ways.",
                    "label": 0
                },
                {
                    "sent": "Love, truth and alternative models and we're using sort of the collective synchronization effect.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And the learning law can be sort of that can be seen as sort of a generalization of heavy, heavy in learning and have been learning.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you rely on synchronous.",
                    "label": 0
                },
                {
                    "sent": "If you have synchronization between neurons.",
                    "label": 0
                },
                {
                    "sent": "Another side of a signups signups kits.",
                    "label": 0
                },
                {
                    "sent": "I mean, the connection becomes stronger.",
                    "label": 0
                },
                {
                    "sent": "Here, sort of a supervised version of the same thing where.",
                    "label": 1
                },
                {
                    "sent": "A synapse become stronger if, as a result of the.",
                    "label": 0
                },
                {
                    "sent": "Two neurons collectively do their thing in concert with reality.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And as I said, we're really interested in the overall attractor is not in the.",
                    "label": 0
                },
                {
                    "sent": "On instantaneous states.",
                    "label": 0
                },
                {
                    "sent": "So without telling you how we change the learning law, this is going from my simple learning law to a more standard approach to to machine learning.",
                    "label": 0
                },
                {
                    "sent": "Although the attractors that we get with a simple learning law don't look bad either.",
                    "label": 0
                },
                {
                    "sent": "I haven't found the result.",
                    "label": 0
                },
                {
                    "sent": "This is just the attractor for one of the individual models.",
                    "label": 0
                },
                {
                    "sent": "Tractor for another of the individual models.",
                    "label": 0
                },
                {
                    "sent": "The grey in the background is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ruth.",
                    "label": 0
                },
                {
                    "sent": "Third model.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Despite all that, I mean just despite the big differences from reality, the supermodel actually helps you.",
                    "label": 0
                },
                {
                    "sent": "Um and a point that it's worth making is that.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Suppose we are.",
                    "label": 0
                },
                {
                    "sent": "We're just interested in the statistical properties of the attractor.",
                    "label": 0
                },
                {
                    "sent": "Something like globally average temperature.",
                    "label": 0
                },
                {
                    "sent": "How?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, supposed, suppose this is X, the globally average temperature in the individual models.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Still way off.",
                    "label": 0
                },
                {
                    "sent": "But we get an attractor with the correct globally averaged.",
                    "label": 0
                },
                {
                    "sent": "Temperature in log X.",
                    "label": 0
                },
                {
                    "sent": "If I said that correctly.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and just to show you what the learning algorithm is that produced those results.",
                    "label": 0
                },
                {
                    "sent": "So is due to work by.",
                    "label": 0
                },
                {
                    "sent": "When event in Virgin, Frank Sultan and invigorating myself.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Here we introduce a cost function for the supermodel lattices supermodel.",
                    "label": 0
                },
                {
                    "sent": "Just a function of the connection coefficients overtime.",
                    "label": 0
                },
                {
                    "sent": "And I.",
                    "label": 0
                },
                {
                    "sent": "We introduced kind of a damping factor in this cost function so that we're continuously re initializing.",
                    "label": 0
                },
                {
                    "sent": "But as time goes on, we count the error less and less in the cost function.",
                    "label": 0
                },
                {
                    "sent": "Is this game over T term gamma to the power term drops?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And minimizing that through, especially a gradient descent approach which.",
                    "label": 0
                },
                {
                    "sent": "I'm not gonna be able to describe this talk.",
                    "label": 0
                },
                {
                    "sent": "We got the attractors that I.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just showed you.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "The rest of what I'm going to say corresponds to a whole bunch of questions that you might ask about this approach.",
                    "label": 0
                },
                {
                    "sent": "The first one is a.",
                    "label": 0
                },
                {
                    "sent": "What if we go from from simple things like Lawrence system to to models where there's a wide range of time scales?",
                    "label": 0
                },
                {
                    "sent": "Well, this is such a model.",
                    "label": 0
                },
                {
                    "sent": "XY and Z.",
                    "label": 0
                },
                {
                    "sent": "It's actually another model due to Lawrence.",
                    "label": 0
                },
                {
                    "sent": "Standard Lawrence model comes from.",
                    "label": 0
                },
                {
                    "sent": "Taking equations for convection and just taking a few Fourier components of.",
                    "label": 0
                },
                {
                    "sent": "Have a special fields.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to doing the same thing not with convection, but with another model for upper atmospheric circulation.",
                    "label": 0
                },
                {
                    "sent": "And then we couple this to this other two variable model, which is a very simple model of color box model of the ocean.",
                    "label": 0
                },
                {
                    "sent": "Where is TNS actually?",
                    "label": 0
                },
                {
                    "sent": "Our temperature gradients from equator, equator to pole?",
                    "label": 0
                },
                {
                    "sent": "We have one box representing equator, another box representing pole living the polar regions.",
                    "label": 0
                },
                {
                    "sent": "And these constants that appear in these two equations are very small.",
                    "label": 0
                },
                {
                    "sent": "So overall the ocean evolves on a much slower timescale than the atmosphere.",
                    "label": 0
                },
                {
                    "sent": "So, but what I did, so I took three of these perturbed parameters in both the atmospheric and the Oceanic components.",
                    "label": 0
                },
                {
                    "sent": "And I got the same phenomenon that the.",
                    "label": 0
                },
                {
                    "sent": "A supermodel goes to truth.",
                    "label": 0
                },
                {
                    "sent": "Over.",
                    "label": 0
                },
                {
                    "sent": "Not too long period of time the the the ocean part of a supermodel goes to ocean truth.",
                    "label": 0
                },
                {
                    "sent": "This is temperature gradient in the ocean.",
                    "label": 0
                },
                {
                    "sent": "Turns out that what's really happening here is that.",
                    "label": 0
                },
                {
                    "sent": "Inform the supermodel you're adding, nudging terms to these equations.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                },
                {
                    "sent": "The nudging terms because these coefficients are smaller, much bigger than the.",
                    "label": 0
                },
                {
                    "sent": "The dynamical terms you're basically forcing your ocean model to truth very quickly, and then using ocean observations to train the atmospheric model.",
                    "label": 0
                },
                {
                    "sent": "But that's not a bad strategy.",
                    "label": 0
                },
                {
                    "sent": "First, train the fast time scales using some sort of climatological average for the slow time skills.",
                    "label": 0
                },
                {
                    "sent": "Then worry about training the ocean.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More fundamental question.",
                    "label": 0
                },
                {
                    "sent": "Is what happens if if all the models error in the same direction?",
                    "label": 1
                },
                {
                    "sent": "If we have a bunch of experts, all of whom predict a temperature that is too high.",
                    "label": 0
                },
                {
                    "sent": "Well, um.",
                    "label": 0
                },
                {
                    "sent": "I mean, one thing you can do is is use the.",
                    "label": 0
                },
                {
                    "sent": "Use the prediction.",
                    "label": 0
                },
                {
                    "sent": "That's consistently the least wrong in the training phase and extrapolate outside of the range.",
                    "label": 1
                },
                {
                    "sent": "That's obviously a high.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A risky and unstable procedure, but you can try it with the Lawrence models.",
                    "label": 0
                },
                {
                    "sent": "What happens if you take a parameter?",
                    "label": 0
                },
                {
                    "sent": "Sigma was a parameter in the Lorenz system and what happens if you take all the sigmas in the.",
                    "label": 0
                },
                {
                    "sent": "Individual models that comprise the supermodel to be greater than.",
                    "label": 0
                },
                {
                    "sent": "The true signal.",
                    "label": 0
                },
                {
                    "sent": "Well, if you allow the Kona connections to become negative.",
                    "label": 1
                },
                {
                    "sent": "You still get a workable supermodel.",
                    "label": 0
                },
                {
                    "sent": "If you remember the plots I showed you before, this is roughly the same scale of blown up.",
                    "label": 0
                },
                {
                    "sent": "You know it's better than other nothing and better than averaging.",
                    "label": 1
                },
                {
                    "sent": "But not as good as an ordinary supermodel with with positive connections.",
                    "label": 1
                },
                {
                    "sent": "And this is still in weather prediction mode, where the where you're coupling it to reality.",
                    "label": 0
                },
                {
                    "sent": "OK, so you're using your super model to predict weather again in the mode where you constantly have input every six hours analogously.",
                    "label": 0
                },
                {
                    "sent": "But um.",
                    "label": 0
                },
                {
                    "sent": "It turns out that.",
                    "label": 0
                },
                {
                    "sent": "We think we can get this to work under some conditions.",
                    "label": 0
                },
                {
                    "sent": "For some conditions in climate prediction mode where we just disconnect reality and let it run freely, but so far we've only seen it blow up.",
                    "label": 0
                },
                {
                    "sent": "So need some.",
                    "label": 0
                },
                {
                    "sent": "Predictions sign in the wrong direction.",
                    "label": 0
                },
                {
                    "sent": "When you ever reach them, the average prediction will be in the wrong direction, not a few loud negative coefficients as the weights.",
                    "label": 0
                },
                {
                    "sent": "OK, but this means that.",
                    "label": 0
                },
                {
                    "sent": "You don't just have everything, but the fact or so if we.",
                    "label": 0
                },
                {
                    "sent": "I mean there's a whole area of learning ensembles within the machine learning community, and they're the kind of approach that is most often taken is to average or majority vote or something along these lines on the predictions of the base classic words, the distinction is to another approach which is called stacking, where you actually learn.",
                    "label": 0
                },
                {
                    "sent": "From the predictions of the basic models and reality, you have an extra learning layer where you don't just adopt the coefficients, but you really allow completely unrestricted learning.",
                    "label": 0
                },
                {
                    "sent": "For example, you can learn to completely reverse the predictions of one of the models if one of the models consistently predicts the opposite of truth, and you say, oh, this is very easy.",
                    "label": 0
                },
                {
                    "sent": "I just.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's exactly the sort of thing I was looking for.",
                    "label": 0
                },
                {
                    "sent": "OK, but I want to ask you how it's done, but why don't we talk about it later?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so essentially.",
                    "label": 0
                },
                {
                    "sent": "Could use another learning problem where the predictions by the models and reality are important.",
                    "label": 0
                },
                {
                    "sent": "You learn the connections.",
                    "label": 0
                },
                {
                    "sent": "In this particular case from that.",
                    "label": 0
                },
                {
                    "sent": "So it's a separate learning problem.",
                    "label": 0
                },
                {
                    "sent": "So how you combine the predictions?",
                    "label": 0
                },
                {
                    "sent": "OK, it's not just the averaging, but it's you.",
                    "label": 0
                },
                {
                    "sent": "You learn general function approximation for the combination.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Um?",
                    "label": 0
                },
                {
                    "sent": "The other big question is what are we doing here?",
                    "label": 0
                },
                {
                    "sent": "Where we're running a bunch of climate models with training them on present day data so that we should be able to use this in weather prediction mode.",
                    "label": 0
                },
                {
                    "sent": "But then what we're doing is we're asking what happens if we change the amount of carbon dioxide in the atmosphere or other greenhouse gases corresponds to changing one parameter.",
                    "label": 0
                },
                {
                    "sent": "So you're training with a bunch of of models, and then you're somehow shifting the models.",
                    "label": 0
                },
                {
                    "sent": "Uh, some parameter in the models that you think represents a real parameter.",
                    "label": 0
                },
                {
                    "sent": "I picked row because if you go back to.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Supermodels yeah row is the same role.",
                    "label": 0
                },
                {
                    "sent": "Wasn't one of the parameters that varies among the different models.",
                    "label": 0
                },
                {
                    "sent": "Rose just fixed parameters.",
                    "label": 0
                },
                {
                    "sent": "Zero is CO2 level or some function thereof.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "OK, So what happens if you train with Withrow equals 28, which is a standard value Florence system.",
                    "label": 0
                },
                {
                    "sent": "But then you shift row in both reality and models while the error goes up a little.",
                    "label": 0
                },
                {
                    "sent": "If you shifted a lot.",
                    "label": 0
                },
                {
                    "sent": "It's goes up a little more.",
                    "label": 0
                },
                {
                    "sent": "Turns out this corresponds you can you can study bifurcations and Lawrence and this has been done.",
                    "label": 0
                },
                {
                    "sent": "This is a large number from from here to here is a large number of bifurcations, I think it's on the order of maybe 100 something like that, but.",
                    "label": 1
                },
                {
                    "sent": "And you can tell that by looking at the attractors.",
                    "label": 0
                },
                {
                    "sent": "This almost looks like a quasi periodic thing.",
                    "label": 0
                },
                {
                    "sent": "It's not like strange attractor anymore.",
                    "label": 0
                },
                {
                    "sent": "This is the real equals 100.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the error is still pretty small.",
                    "label": 1
                },
                {
                    "sent": "And certainly better than than averaging.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, um both the simple learning law that I showed you and the.",
                    "label": 0
                },
                {
                    "sent": "Even more, the one based on the more complicated cost function suffer from the possible problem of non global non global local Optima.",
                    "label": 0
                },
                {
                    "sent": "So far, the only thing we've done with to get out of to deal with this is.",
                    "label": 0
                },
                {
                    "sent": "Is that noise in one form or another?",
                    "label": 0
                },
                {
                    "sent": "This is a fairly complicated of.",
                    "label": 0
                },
                {
                    "sent": "Learning method.",
                    "label": 0
                },
                {
                    "sent": "I'm not gonna describe, but the point is that.",
                    "label": 0
                },
                {
                    "sent": "One measure of.",
                    "label": 0
                },
                {
                    "sent": "Of the model is difference between autocorrelation functions of the truth and the supermodel.",
                    "label": 0
                },
                {
                    "sent": "And, uh.",
                    "label": 0
                },
                {
                    "sent": "This is for the three variables.",
                    "label": 0
                },
                {
                    "sent": "The dotted line is for a deterministic learning scheme.",
                    "label": 1
                },
                {
                    "sent": "Solid line is for a stochastic learning scheme.",
                    "label": 1
                },
                {
                    "sent": "In all cases, Ungra is truth.",
                    "label": 0
                },
                {
                    "sent": "In all cases, Stochastic City helps, not surprisingly.",
                    "label": 0
                },
                {
                    "sent": "Using the method for learning the coefficients.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for example stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "Since then, before you know.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "OK, so far I've just been talking about Lorenz systems.",
                    "label": 0
                },
                {
                    "sent": "Need to extend this to PDE's.",
                    "label": 0
                },
                {
                    "sent": "Just before we go to anything as complicated as a climate model.",
                    "label": 0
                },
                {
                    "sent": "I this is just promoted civil shinsky.",
                    "label": 0
                },
                {
                    "sent": "Simple one time 1 space dimensional PDE.",
                    "label": 0
                },
                {
                    "sent": "It's been used to represent propagation and that wave propagation and.",
                    "label": 0
                },
                {
                    "sent": "Dissipative media.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "And if we couple these models not only discretely in time, but actually I guess we're not doing it discreetly in time here, but discretely in space.",
                    "label": 0
                },
                {
                    "sent": "It's only to fix data points, which is what we want to do.",
                    "label": 0
                },
                {
                    "sent": "I mean not only with weather prediction.",
                    "label": 0
                },
                {
                    "sent": "Also, again, we don't just make.",
                    "label": 0
                },
                {
                    "sent": "The observations are not only sparse and time every six hours, but there's Parson space.",
                    "label": 0
                },
                {
                    "sent": "One question for PDS, then is can we say anything about?",
                    "label": 0
                },
                {
                    "sent": "About how close the observations need to be in order to get synchronization.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "This is a the two axes are spaced in time and you see propagating coherent structures.",
                    "label": 0
                },
                {
                    "sent": "So actually this is not ordinary KSKS with this extra third derivative added which gives you wave propagation.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "So what do we do if log is Ares?",
                    "label": 0
                },
                {
                    "sent": "Is log Avera versus of nudging coefficient?",
                    "label": 0
                },
                {
                    "sent": "The models are uncouple.",
                    "label": 0
                },
                {
                    "sent": "The arrow slowly goes down.",
                    "label": 0
                },
                {
                    "sent": "If we fix the connections between the models, so this is a manually set supermodel, not a trained supermodel.",
                    "label": 0
                },
                {
                    "sent": "We do somewhat better, but if we adapt the connections according to the simple learning law, we do better yet.",
                    "label": 0
                },
                {
                    "sent": "So, where, where are these coefficients in the equations on this slide?",
                    "label": 0
                },
                {
                    "sent": "They're not there, because this is just one model.",
                    "label": 0
                },
                {
                    "sent": "This is true, yeah?",
                    "label": 0
                },
                {
                    "sent": "Many more coefficients for the PDS.",
                    "label": 0
                },
                {
                    "sent": "Well, that's one question.",
                    "label": 0
                },
                {
                    "sent": "How many independent the symmetry of this thing is simple, so we keep the connections.",
                    "label": 0
                },
                {
                    "sent": "I mean we have just translational symmetry.",
                    "label": 0
                },
                {
                    "sent": "There's no reason to think the connections should be different at different points.",
                    "label": 0
                },
                {
                    "sent": "So we only have like a.",
                    "label": 0
                },
                {
                    "sent": "Three or six independent connections.",
                    "label": 0
                },
                {
                    "sent": "Put them for the ordinary differential equations.",
                    "label": 0
                },
                {
                    "sent": "Then you were learning the coefficients.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in one of the schemes, coefficients evolved overtime and in the end you froze them.",
                    "label": 0
                },
                {
                    "sent": "Here, in principle the coefficients would need to evolve over both time and space, and then you freeze them.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Very well, the coefficients are just functions of time, not functions of space.",
                    "label": 0
                },
                {
                    "sent": "We assume that they are the same at all points in space.",
                    "label": 0
                },
                {
                    "sent": "They stay that way.",
                    "label": 0
                },
                {
                    "sent": "Why should they?",
                    "label": 0
                },
                {
                    "sent": "Will discuss that offline OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "So what variables?",
                    "label": 0
                },
                {
                    "sent": "So another question is what variable should we couple of performing a climate prediction supermodel?",
                    "label": 0
                },
                {
                    "sent": "We don't really want a couple everything.",
                    "label": 0
                },
                {
                    "sent": "Even independently of.",
                    "label": 0
                },
                {
                    "sent": "If we assume we're working in physical space and we have translational symmetry, which we don't because topography changes, but.",
                    "label": 0
                },
                {
                    "sent": "Uh, we still have lots of variables at each point and we don't need to work in physical space.",
                    "label": 0
                },
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Here what we did was to.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Instead, OK first of all, instead of working in physical space, you can work in Fourier space or on a sphere, which this model is a model on a sphere of spherical harmonics are the basis functions.",
                    "label": 0
                },
                {
                    "sent": "And you can compare coupling with the basis of spherical harmonics to basis of empirical orthogonal functions, otherwise known as principle components.",
                    "label": 1
                },
                {
                    "sent": "The nudging timescale is basically one over the sea, or I think it was called KB 4.",
                    "label": 0
                },
                {
                    "sent": "So as you go this way, the timescale is increasing, which means the nudging strength is decreasing, which means the era is going up.",
                    "label": 0
                },
                {
                    "sent": "The grey is for spherical harmonics of the light Gray, or actually it's white.",
                    "label": 0
                },
                {
                    "sent": "Here is fork using principle components and not surprisingly, we do somewhat better this role components.",
                    "label": 1
                },
                {
                    "sent": "In each of these panels here, the horizontal axis represents the number of components that are coupled, and we need fewer ones to get the error down to effectively zero.",
                    "label": 0
                },
                {
                    "sent": "If we are intelligence about choosing.",
                    "label": 0
                },
                {
                    "sent": "The basis.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm OK.",
                    "label": 0
                },
                {
                    "sent": "I put these in here.",
                    "label": 0
                },
                {
                    "sent": "I wasn't sure if there was going to be time or interest.",
                    "label": 0
                },
                {
                    "sent": "This is a more complicated PDE, so across edges, traffic channel model used to represent weather.",
                    "label": 0
                },
                {
                    "sent": "Let me just tell you quickly what this is.",
                    "label": 0
                },
                {
                    "sent": "This is a two layer model.",
                    "label": 0
                },
                {
                    "sent": "These are not two layers.",
                    "label": 0
                },
                {
                    "sent": "These are two models.",
                    "label": 0
                },
                {
                    "sent": "Each model.",
                    "label": 0
                },
                {
                    "sent": "Satisfies this equation, which says that potential vorticity.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you what that is in a minute.",
                    "label": 0
                },
                {
                    "sent": "This quantity Q is is almost conserved.",
                    "label": 0
                },
                {
                    "sent": "This isn't effective derivative.",
                    "label": 0
                },
                {
                    "sent": "It's conserved except for forcing and dissipation.",
                    "label": 0
                },
                {
                    "sent": "This, uh, this isn't approximation that gets us beyond every Stokes that gives us some pretty realistic representation of some weather phenomena.",
                    "label": 0
                },
                {
                    "sent": "Potential vorticity is sort of the curl vorticity would be like the curl of velocity.",
                    "label": 0
                },
                {
                    "sent": "Potential vorticity is.",
                    "label": 0
                },
                {
                    "sent": "A modification of that to include effects from the Earths rotation and from the fact that vortices.",
                    "label": 0
                },
                {
                    "sent": "The stretcher compressed in each of the two layers and we still want conservation of angular momentum.",
                    "label": 0
                },
                {
                    "sent": "Overall, that allows us to define the quantity Q which I'm not going to define here, but.",
                    "label": 0
                },
                {
                    "sent": "But we chose this is a different kind of coupling.",
                    "label": 0
                },
                {
                    "sent": "Jay is a Jacobian TDX the first term minus DX.",
                    "label": 0
                },
                {
                    "sent": "The first term, TDY have a second term, minus TDY.",
                    "label": 0
                },
                {
                    "sent": "The first term DDX of the first term of the second term.",
                    "label": 0
                },
                {
                    "sent": "The derivatives of the stream function PSI give us velocity, so maybe you can take my word for it that this J normally gives you the affective component.",
                    "label": 0
                },
                {
                    "sent": "We put the coupling into the affective component.",
                    "label": 0
                },
                {
                    "sent": "And I describe this later.",
                    "label": 0
                },
                {
                    "sent": "If anybody really wants to know.",
                    "label": 0
                },
                {
                    "sent": "But the point is that even with this more complicated form of coupling, we can derive learning law for this.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simple models.",
                    "label": 0
                },
                {
                    "sent": "And here is true.",
                    "label": 0
                },
                {
                    "sent": "This is a model with a jet stream over the Atlantic.",
                    "label": 1
                },
                {
                    "sent": "Some model with jet stream over the Pacific.",
                    "label": 1
                },
                {
                    "sent": "Is there a little different at the beginning as time goes on, they synchronize both with each other and truth.",
                    "label": 1
                },
                {
                    "sent": "So if you go back to the previous slide, you don't couple here over the.",
                    "label": 0
                },
                {
                    "sent": "System variables, but you couple over these advective terms.",
                    "label": 0
                },
                {
                    "sent": "You don't.",
                    "label": 0
                },
                {
                    "sent": "Instead of you have something.",
                    "label": 0
                },
                {
                    "sent": "More complicated than this.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and there the lodging coefficient is something more complicated.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, but you can still do it.",
                    "label": 0
                },
                {
                    "sent": "And the reason you do that.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is because if you do it this way.",
                    "label": 0
                },
                {
                    "sent": "Then it turns out that.",
                    "label": 0
                },
                {
                    "sent": "The the average of the solutions to the two model equations separately is exactly the solution to the model with the average forcing.",
                    "label": 1
                },
                {
                    "sent": "In other words, with the jet stream over both Atlantic and Pacific, which is what you really want.",
                    "label": 0
                },
                {
                    "sent": "So this requires extra knowledge on what would be a good term.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Case I could imagine somebody like me who is a machine learning per person doesn't know much about climate modeling.",
                    "label": 0
                },
                {
                    "sent": "Still, I can understand the difference between system variables is a reasonable term to use for lodging, right?",
                    "label": 0
                },
                {
                    "sent": "Whereas when we get to this, you know I have no knowledge of the climate modeling, so this for me is beyond beyond my reach.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "No, I think that's an overstatement.",
                    "label": 0
                },
                {
                    "sent": "Beyond your reach.",
                    "label": 0
                },
                {
                    "sent": "But I don't think I want to explain it in the next.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You want see to be 1/2 in this simple case because.",
                    "label": 0
                },
                {
                    "sent": "You want equal contributions from the two models and with a simple learning law, C does go to 1/2.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "I just stuck those few slides in because that was the most complicated case that we've dealt with so far in super modeling.",
                    "label": 0
                },
                {
                    "sent": "But um.",
                    "label": 0
                },
                {
                    "sent": "OK, so where are we and where we going?",
                    "label": 0
                },
                {
                    "sent": "So so far if we have local Optima we rely just on stochasticity.",
                    "label": 1
                },
                {
                    "sent": "But what we'd like to do is, is define triggers based on the state of.",
                    "label": 0
                },
                {
                    "sent": "Of those individual models.",
                    "label": 0
                },
                {
                    "sent": "But will tell us when we might need effectively in your tip.",
                    "label": 0
                },
                {
                    "sent": "Mutation OK?",
                    "label": 0
                },
                {
                    "sent": "These negative coefficients we need to do just as you said.",
                    "label": 0
                },
                {
                    "sent": "Some super learning approach.",
                    "label": 0
                },
                {
                    "sent": "That oh I'm sorry, not negative coefficients, but to tell us when we need to extrapolate away from the individual models.",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "That's sort of a metal level.",
                    "label": 0
                },
                {
                    "sent": "And another point is that was raised is how do we use our knowledge of the system?",
                    "label": 0
                },
                {
                    "sent": "To restrict the number of of connections that we train separately, if we have translational symmetry, it's simple.",
                    "label": 1
                },
                {
                    "sent": "But how do we use other kinds of symmetry?",
                    "label": 0
                },
                {
                    "sent": "Or some sort of partial knowledge or guesses so that we don't.",
                    "label": 0
                },
                {
                    "sent": "Need to risk overtraining with limited data.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "With all of this, what we're dealing with is a situation where the amount of data is limited.",
                    "label": 0
                },
                {
                    "sent": "We only appeared in climate prediction.",
                    "label": 0
                },
                {
                    "sent": "We only have good data for the last 50 or 60 years, but we have as much computer time as we want to do the learning.",
                    "label": 0
                },
                {
                    "sent": "So we need some more domain specificity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in the way that we do the Super modeling overall, and that's that's kind of what I'd like to.",
                    "label": 0
                },
                {
                    "sent": "To end with.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And what did I forget?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I said I was going to tell you why this is artificial consciousness that.",
                    "label": 0
                },
                {
                    "sent": "Uh, I think data simulation clearly compared compared to perception.",
                    "label": 0
                },
                {
                    "sent": "We have a bunch of alternative representations of the same model doing data simulation from each other.",
                    "label": 0
                },
                {
                    "sent": "Then we have self perception.",
                    "label": 0
                },
                {
                    "sent": "Could be called consciousness and synchronization at a much lower level.",
                    "label": 0
                },
                {
                    "sent": "Figures in most theories of consciousness roll processing synchronized spike trains a synchronization at a higher level.",
                    "label": 0
                },
                {
                    "sent": "Once the connection that I'd like to make.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Anyway, um, so questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much babe.",
                    "label": 0
                },
                {
                    "sent": "And the timing is perfect so we can test quite depression.",
                    "label": 0
                },
                {
                    "sent": "Although they wouldn't make errors in the same way, so they would make errors in different places you would still.",
                    "label": 0
                },
                {
                    "sent": "Encourage themselves into a total wrong direction.",
                    "label": 0
                },
                {
                    "sent": "Is this a problem and public?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, if we in what and what?",
                    "label": 0
                },
                {
                    "sent": "I'm calling weather prediction mode where we're nuts to reality, we don't have to worry about it.",
                    "label": 0
                },
                {
                    "sent": "If we disconnect from reality.",
                    "label": 0
                },
                {
                    "sent": "It doesn't run away.",
                    "label": 0
                },
                {
                    "sent": "Empirically, I can say this.",
                    "label": 0
                },
                {
                    "sent": "What is theoretically?",
                    "label": 0
                },
                {
                    "sent": "Well, OK, in the case for the case where the coefficients are positive.",
                    "label": 0
                },
                {
                    "sent": "It doesn't get outside of.",
                    "label": 0
                },
                {
                    "sent": "The domain in which each model normally lives.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure I can come up with more intuition for it than that right now.",
                    "label": 0
                },
                {
                    "sent": "Synchronize.",
                    "label": 0
                },
                {
                    "sent": "Yeah, great.",
                    "label": 0
                },
                {
                    "sent": "Well tested it with Lorenz systems.",
                    "label": 0
                },
                {
                    "sent": "Tested it with Kuramoto sufficient ski in a very limited way so far with these weather prediction with these weather PD models.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And, um.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "The PDE is so far we've just used a simple learning love.",
                    "label": 0
                },
                {
                    "sent": "The more complicated machine.",
                    "label": 0
                },
                {
                    "sent": "Learning is too computationally expensive.",
                    "label": 0
                },
                {
                    "sent": "OK, is there anything else?",
                    "label": 0
                },
                {
                    "sent": "Question was very technical in the sense.",
                    "label": 0
                },
                {
                    "sent": "Do you use Matlab or do you use Mathematica oh?",
                    "label": 0
                },
                {
                    "sent": "Cause any input from the climate models and then the climate models leave on a supercomputer somewhere in Germany and you have this and that interface to actually obtain the data from the climate models or this kind of things.",
                    "label": 0
                },
                {
                    "sent": "OK for Lawrence Systems and PZ these simple PZ everything's on the same computer for the climate models were still struggling with a question.",
                    "label": 0
                },
                {
                    "sent": "There's a.",
                    "label": 0
                },
                {
                    "sent": "There's a climate model couple are called Oasis and Europe.",
                    "label": 0
                },
                {
                    "sent": "And in car in the US has a something called data simulation research testbed that it takes one copy of a model.",
                    "label": 0
                },
                {
                    "sent": "Call OGO calls the truth.",
                    "label": 0
                },
                {
                    "sent": "Another copy of the model calls it model does what's considered an identical twin experiment actually runs an ensemble of models for different purpose than this, so it runs in ensemble of models for the purpose of determining spreader background error which you need in common filtering, which is the way that assimilation is normally done.",
                    "label": 0
                },
                {
                    "sent": "So we're trying to generalize all of this.",
                    "label": 0
                },
                {
                    "sent": "Um and the ODS.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I use an old piece of software called DS Tool on my colleagues in Holland use Matlab.",
                    "label": 0
                },
                {
                    "sent": "And for the stochastic stuff I'm planning to use Mathematica.",
                    "label": 0
                },
                {
                    "sent": "I haven't gotten to it yet.",
                    "label": 0
                },
                {
                    "sent": "Other stuff is in Fortran, it's everything all over the place.",
                    "label": 0
                },
                {
                    "sent": "Miss access to his anything to do with R&S in the statistical packages?",
                    "label": 0
                },
                {
                    "sent": "DS store the SSL is is it S2 or DS?",
                    "label": 0
                },
                {
                    "sent": "No, it's DS tool for dynamical systems.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's I think it was popular in the 90s.",
                    "label": 0
                },
                {
                    "sent": "It's not even supported anymore, but I have it on my laptop.",
                    "label": 0
                },
                {
                    "sent": "I can show you.",
                    "label": 0
                },
                {
                    "sent": "But it allows you just to write a system of odies the way you would normally write them, simulate them immediately, that's all.",
                    "label": 0
                },
                {
                    "sent": "Any other questions or comments?",
                    "label": 0
                },
                {
                    "sent": "I have a couple of general questions so.",
                    "label": 0
                },
                {
                    "sent": "Are there any conditions on the systems of ODS or models that you can use here in order to apply the synchronization approach?",
                    "label": 0
                },
                {
                    "sent": "Or are some types of equations more prone, let's say separation than others?",
                    "label": 0
                },
                {
                    "sent": "OK, I think that's about synchronization.",
                    "label": 0
                },
                {
                    "sent": "It's not about super modeling per say.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What's about really?",
                    "label": 0
                },
                {
                    "sent": "What variables you couple, it's usually.",
                    "label": 0
                },
                {
                    "sent": "If you want, let's say to learn parts of the supermodel, either the component is or the interconnections.",
                    "label": 0
                },
                {
                    "sent": "I guess you need to worry about this.",
                    "label": 0
                },
                {
                    "sent": "At least, that's my intention.",
                    "label": 0
                },
                {
                    "sent": "Certain certain types of models.",
                    "label": 0
                },
                {
                    "sent": "Let's say if you simply look at the ody structures.",
                    "label": 0
                },
                {
                    "sent": "Some highly nonlinear structures versus simple linear structures.",
                    "label": 0
                },
                {
                    "sent": "There must be differences in how easy it is to synchronize.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, I mean the heart it has to do with.",
                    "label": 0
                },
                {
                    "sent": "My thesis is that synchronize ability has to do with internal synchronization within a system.",
                    "label": 0
                },
                {
                    "sent": "The more internally synchronized something is easier it is to synchronize it with something else.",
                    "label": 0
                },
                {
                    "sent": "So if you have a high degree of coherence, if you have lots of coherent structures that tells you both something about the ease of synchronizing it with something else and about what you need to observe, which makes sense.",
                    "label": 0
                },
                {
                    "sent": "I mean whether you need to observe the storms and track them, or the high pressure centers something coherent.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "He the hardest systems to synchronize, typically are Hamiltonian systems, but you can get synchronization with Hamiltonian systems.",
                    "label": 0
                },
                {
                    "sent": "Different forms of synchronization.",
                    "label": 0
                },
                {
                    "sent": "But I'm not sure we need to.",
                    "label": 0
                },
                {
                    "sent": "I don't want to tell you about those different forms right now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well the one I found was where the coherent structures tend to occur in the same place, but but everything else gets more spread out.",
                    "label": 0
                },
                {
                    "sent": "It has to because it's Hamiltonian, so the face base can't volume face basically occupies can't collapse and still have synchronization, but does it OK?",
                    "label": 0
                }
            ]
        }
    }
}