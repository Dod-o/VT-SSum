{
    "id": "fndpwoyr2o4fcx2aqk7qabp2a45w7rrv",
    "title": "Network embeddings for modeling polypharmacy and drug-drug interactions",
    "info": {
        "author": [
            "Marinka \u017ditnik, Computer Science Department, Stanford University"
        ],
        "published": "June 28, 2019",
        "recorded": "May 2019",
        "category": [
            "Top->Data Science",
            "Top->Computer Science->Big Data",
            "Top->Computer Science"
        ]
    },
    "url": "http://videolectures.net/icgeb_zitnik_network_embeddings/",
    "segmentation": [
        [
            "Thank you for coming to the second part of this lecture."
        ],
        [
            "So let me briefly recall the outline.",
            "So as you remember yesterday we talked about shallow network embeddings and different various several applications of those embeddings to problem seen bioinformatics, including prediction of protein, protein interactions, disease pathways and protein functions in different tissues.",
            "So what we will do next is today will focus on deep network embeddings in particular describing.",
            "I will describe how we can learn embeddings for notes in.",
            "Large heterogeneous networks using multiple layers of nonlinear transformations which will give us powerful embeddings, and then as has been advertised on the web, I'll focus specifically on polypharmacy and drug repurposing as applications of those of those new methods.",
            "So remember my my talk is more or less about promoting networks or graphs or some means, as in a general language that allow us to bring heterogeneous biomedical data together at the level of populations in the form of interactions between humans down to the level of individuals, and then various kinds of interactions between."
        ],
        [
            "Molecules in a cell and networks really allow us to bring these different scales together and have one one unified representation.",
            "Across multiple scales and different kinds of interactions.",
            "OK, so once we have such heterogeneous networks, our next goal is to have methodology that allow us to train.",
            "Now the models on networks and make useful predictions about various properties of individual nodes, pairs of nodes or higher order structures in the networks."
        ],
        [
            "Today, as I said, I will focus on the graph neural networks as one such powerful methodology that can be used for making accurate predictions on large heterogeneous networks and the outline of this lecture is first, I will briefly I will discuss the algorithms and then I will focus on the 1st application of that is related to polypharmacy drug interactions and drug combinations.",
            "Then I will focus on drug repurposing.",
            "And finally, the last two points here are more discussion points where I will outline some of the new directions and I think exciting opportunities for those in the audience that are interested in excited about developing new algorithms that would address certain challenges in current biomedical research.",
            "And finally, I will conclude with some practical advice, and I also have some demos prepared so there will be time left I can actually show you a very simple model.",
            "That we will describe in the first part of the talk that really implements all these mathematical equations and we can.",
            "We will see how it is, how quickly does it work, and how does it work on a four on a one particular application.",
            "OK, and feel free to interrupt me during my talk and I can take questions anytime or at the end.",
            "Whatever works best."
        ],
        [
            "OK, so let's start with the first point.",
            "Um so.",
            "Since this is the first lecture after the yesterday's blanket, so let me."
        ],
        [
            "Just recall recap what we have learned yesterday.",
            "So yesterday we learned about this principle of embedding notes and that has been mentioned several times throughout this workshop and the idea here is that we want once we have the net or network we want to map notes in that network in a particular embedding space, such that similarity of notes in the embedding space, how closely together they are embedded will reflect similarity of notes.",
            "In the input network.",
            "Anan RE."
        ],
        [
            "Really, the goal, so mathematically what it means, we want to approximate similarity between nodes or pair of notes and V in the network, which in the simplest case with with the DOT product between the embeddings for those two nodes that we wanted to learn and hear this, these two key components are the definition, the notion of similarity that we want to capture and the mapping or transformation code function that will map the notes to the dementia."
        ],
        [
            "Space, so these are two key components.",
            "The encoder that will map a note to low dimensional Victor and 2nd the similarity function that will define what kind of similarities do we want to capture."
        ],
        [
            "And so far.",
            "Meaning yesterday what we learned.",
            "What about we learned about shallow encoders so shallow.",
            "Encoders are methods for learning embeddings of nodes in the network through as one scene, one layer of transformation, and examples as we have seen.",
            "Where are various matrix factorization models, and when more recent models such as no two week Deep Walk line and instruct week that I have discussed yesterday.",
            "So for shallow.",
            "Encoders what is typical is that for a particular note during optimization, we learn directly how to learn.",
            "We learn directly, does evictor for that note meaning the embedding for that note.",
            "And that is, and you can interpret that as actually learning a table that will represent an embedding look up.",
            "So there were some of the limitations of those shallow encoder encoder's that were mentioned yesterday, and at the end of the mother my lecture yesterday there were there was there were some interesting question that highlighted some of the limitations of shallow encoders in."
        ],
        [
            "There are limitations of shallow encodings are that the number of parameters that we need is large.",
            "The number of parameters is in the duration of the size of the network, meaning that for every note in the network, we directly learns the dimensional vector.",
            "There is no notion of sharing parameters across embeddings of the nodes because we directly learn an embedding.",
            "This means as a consequence, this means that our embeddings are inherently transductive.",
            "What this means is that.",
            "When, for example, and you know it would come in the network for the methods that I discussed yesterday, it's impossible to simply generate embedding for the new node, right?",
            "So in principle would need to what we would need to learn, or what we would need to do when you note or new notes arrive, retrain the model from scratched.",
            "So this means that we cannot generate embeddings for nodes that were not seen during training, and typically we would not want to do that Ann, and finally another an important limitation of shallow encoding methods, especially in the context of biomedical research, is that they do not incorporate note features at edge attributes or this additional very rich extra information that we often have in many biomedical applications.",
            "And that's something that would have been highlight."
        ],
        [
            "It yesterday.",
            "So next, what we will do is we will will address these limitations by discussing deep model methods that are based on graph neural networks.",
            "In particular, an important notion that we will discuss is this encoding or the mapping function that will now make notes to note to a dimensional Victor through multiple layers of nonlinear transformation defined on the graph structure.",
            "So if you if you would not know much about graph neural networks, you can quickly think about what would be a naive approach to doing them."
        ],
        [
            "So and if approach would be to say, well, if we have, we have many existing deep models, many variants of conversion, neural networks and recurrent neural networks, or LCMS, and those methods work extremely well on images or sequence data, and image is represented by matrix.",
            "And of course when we have a graph, we can also represented by matrix its adjacency matrix of the graph.",
            "So naive approach would be to take the graph and represent it with adjacency matrix.",
            "And concatenate potential features that we might have for notes as additional columns in that matrix.",
            "And once what we would have such matrix, we would simply feed it into some perhaps standard feedforward neural network.",
            "So here's one example.",
            "When we could do that.",
            "So Megan have the network on the left.",
            "It's a simple network with five nodes, meaning that adjacency matrix when there will be a 5 by 5 adjacency matrix and there is one that provided for in that in that one syndicate actually edges between nodes and zero indicate indicates no edge between parents and we might have some additional features which we can concatenate here.",
            "So this could simply be best.",
            "To feed forward neural network and or some other existing architecture and that would potentially give us predictions or would give us embeddings for the notes so and so we could do that and then one would say, well, why do we need new class of neural networks?",
            "Because this already works well.",
            "So what might be the problem with this idea?",
            "So the problem with this idea that fundamentally the problem is that.",
            "Then did the.",
            "These methods are not invariant to note orderings, so this in particular what why what I want to highlight here is that if we think of our Jason C matrix as interpreted as an image and it use it as input to these models, then the then the model.",
            "What we will learn, it will really capture this spatial locality which is not relevant for graphs.",
            "So if we.",
            "Would simply take a network and we were three label our notes in the network.",
            "This does not change the graph structure, so the network is actually the same.",
            "However, the adjacency matrix would complete look completely different, so the the image representation of adjacency matrix would be completely different, right?",
            "Because we have just real randomly re labeled the notes and so our prediction are embeddings would be different as well, but that's not what we want because actually the underlying graph structure has not changed at all.",
            "So the problem with that is that and if approach is really not invariant to northward, to note ordering or, which is something that is crucial here, since there is no specific reference point in graphs that would apply or redefine the ordering of the nodes.",
            "The second problem is like, let's say if you train this model now on this network on five notes, what happens when we have a network on 6 notes?",
            "We would need to essentially train a different architecture with different number of.",
            "Neurons on the input layer because now we have a network on six or more nodes, so it's not applicable to graphs of different sizes, which is what is very important in many applications.",
            "And finally, perhaps a bit subtle differences.",
            "That is, the number of parameters that we would have with some of the standard models that would require very, very large datasets to be trained.",
            "So what we need in what we will do next is we we will generalize convolutions beyond simple lattices, meaning that the standard conversions that are defined for images and sequences, and we will generalize them to multimodal networks that can leverage note features, note attributes."
        ],
        [
            "And the approach now for for doing that will really start with the multimodal network, and then this green boxes and the specified nonlinear functions and dropouts is something that will define graph conversions, which I will explain next."
        ],
        [
            "But before that, let me spend one minute on redefining what I mean by multimodal networks, since there are many different notions and terminology for referring to heterogeneous networks.",
            "Positive clicks, network multilayer networks, and so on.",
            "So for the purpose of this talk, the idea is that a multimodal network is a network where you have multiple notes of different types and edges of different types.",
            "So in this example, for here, what we have is green triangles indicate.",
            "Different drugs apparent drugs are connected based on potential interaction between those two drugs and there the type of interaction is represented by a type of an edge which is indicated here by an R representation.",
            "So we might have different various kinds of additional feature information for the drugs, which might indicate might, which allows us to integrate.",
            "For example, chemical structure of trucks in their model.",
            "Of course, we don't have just one mode, meaning one type of notes we might want to integrate in our model.",
            "Information on what are the proteins that the drugs are associated with, which would introduce this second mode of information, and then we know how proteins might interact with each other in the body.",
            "So that would be then.",
            "That would then be encoded as various kind of interactions between proteins.",
            "So this example here what it represents, a multimodal network with two modes, in this case drugs and proteins.",
            "And we have interactions between nodes of within each mode, as well as notes across nodes and edges.",
            "Here can have different types.",
            "We might also have multiple types of edges between every pair of nodes.",
            "So this is the structure that will be working with and in the next few minutes I will describe the methodology that takes this as such networks as input and then learn deep embedding."
        ],
        [
            "And then I will discuss that applications that are have also been highlighted yesterday.",
            "The polypharmacy problem and the problem of drug with purpose.",
            "But before we go discuss this applications in detail let."
        ],
        [
            "Leon provides an overview of the of our approach for deep learning on multimodal networks, so the approach has two key components.",
            "The first component is the encoder component, which will take the multimodal network.",
            "It will learn an embedding for every note and in the decoder phrase we will use those learned embeddings to make interesting new predictions and importantly, what this this is, something that we will do in an end to end fashion, meaning that embeddings will be optimized for prediction.",
            "OK, so let's start with the in code."
        ],
        [
            "Face so remember what we were discussing yesterday?",
            "The goal here that we want to do in the encoding stage is to learn that mapping function F that will map the nodes in some D dimensional space with the purpose of.",
            "Server, or in preserving the information on similarity of or the properties of local topology around the note and this very much aligns with many observations that were made in biology during the course of the last two decades where it has been shown repeatedly then that for many biomedical entities, similar interaction patterns indicate that those entities might have that those entities are involved in similar phenotypes.",
            "Might have similar clinical manifestations, might be involved in similar protein complexes antilla?"
        ],
        [
            "OK, so how will we learn that mapping functional if our key idea here we will be that we will generate embeddings based on local network neighborhoods and we will take into account what are the types of edges that exist within a neighborhood of every note and the notion that I will be using here is this notion of nodes computation graph.",
            "So for every note, let's say we are currently looking at Note V in our network, we will determine uh, nodes computation graph.",
            "An node computer note computation graph might be some local network will be some local network neighborhood of the of that.",
            "Note in the second phase will we learn what is the best way to transform and propagate information across their computation graph?",
            "So for example, for this note, we will look at for every type of edges.",
            "Let's say we are currently looking for edge type R3.",
            "We will look at what our first order neighbors of.",
            "Note we in edge type R3 and we have two neighbors, the red ones.",
            "What their second order neighbors in that edge type.",
            "And again we have three neighbors and we will learn what is the best, most effective way of propagating transforming information across those.",
            "Across across edges, taking into account the type of edges that appear in the neighborhood of notary, and this will be dancing with Tanias Lee for all notes in there."
        ],
        [
            "So an example of that is if we use our multimodal network that we have previously defined.",
            "Let's say we are currently looking now at the drug.",
            "Note that drug not see what I'm highlighting on the left is the 1st Order Network neighborhood, which would mean that computation graph for notes is defined based on these immediate neighbors of node C. So Notsi has a several neighbors, but their neighbors are of three different types, so it has neighbors of type R2R1 and T. So this means that our computation graph will have three separate processing channels and the one.",
            "And in each processing channel, let's include cartoon.",
            "The idea would be to say, well, what are the neighbors of seeing our two?",
            "So they are not S&D and then SMB will lerwill true, will send their current Victor values messages or embedding central discussing along along edges to see and learn.",
            "What is the best way to incorporate the propagate?",
            "This information in the same will be done for the two and.",
            "Other edge types that appear in the neighborhood to float C4P and RR1 and then this information would integrate to be integrated to get the presentation or embedding or Victor valid message for Nazi at the next layer of our computation.",
            "Well, so the idea is that, well, this is the computation graph for node C and."
        ],
        [
            "Every note will will learn, will have its own computation graph, unique computation graph based on the structure of its local local network neighborhood, the way you can think of this problem is that instead of having one neural network for the entire graph, every, we will have a very large number of small neural network networks.",
            "In particular, every note will define its own neural network architecture.",
            "That architecture will depend on the.",
            "Topology of local network neighborhood.",
            "In order to effectively train the model, we will share certain parameters weight matrices across those nodes."
        ],
        [
            "So in order to get deep model what what we what we'll be doing is will effectively stack multiple layers to information together.",
            "So for example, if you would be interested in getting model that we will learn embeddings for, notes embedding for node C based on two layer of transformation, we would first use the the computation graph that we have seen in the previous example.",
            "And the layer, the first layer that computation graph will start with initial embeddings, which might be 0 hot and one hot encoding characters or feature vectors for for the neighbors of notes.",
            "And we will we would we would run forward.",
            "We do that computation graph to generate an embedding for Nazi based on its immediate neighbors, and then in the second layer of transformation, the same idea.",
            "Exactly same idea would be repeated on the current new version of them, Bendix.",
            "So effectively, what that would mean is that the model can be of arbitrary depth.",
            "You can think of notes have embeddings at each layer of transformation at layer zero.",
            "Embeddings are one hot encoding victors or not initial note features.",
            "And then at each layer, every note looks at its neighbors and it applies the current value of the current set of parameters that transform the information.",
            "The information from neighbors to update embeddings for death.",
            "Note that is done simultaneously for every note in the network, and that defines one layer of transformation in the second layer.",
            "Then again, every note will again look at his direct neighbors.",
            "Take their current embeddings in, apply that formula again, but now the current embeddings of neighbors are results of the previous of transformation from the previous layer, so effectively means that if we have a network with key layers, this means that the embeddings that will be generated a generated depend on the structure of K hop neighborhoods around notes, so meaning that for two nodes that we have of two nodes there.",
            "If their embeddings are similar in a layer with K in a network with K layers, that would mean that their K hop neighborhoods have similar local structure."
        ],
        [
            "OK, so that might seem.",
            "Incidentally, perhaps hard to work hard to ground, but here is actually one slide of equations that implement this idea.",
            "So the key is the key element.",
            "Intuitively, is this notion that each nodes computation graph defines its own neural network and the architecture depends on the local topology of that network of that low of that node's neighborhood?",
            "Once this is done, when we have computation graphs for the notes, we have these three equations that we need to run multiple times depending on the number of hidden layers or the depth of the graph.",
            "Neural network that we want to have.",
            "In particular, at layer zero of all transformation, we say, well initial embedding for notary, at Layer Zero is set to initial note.",
            "Feature vector for note we that we might have.",
            "So this is opportunity that allow us to integrate site information about nodes in the network.",
            "So if, for example if we would be a drug note, then exactly might be might be chemical structure of drug, some form of fingerprint that were that were mentioned yesterday several times.",
            "If we would be an image then we might have an embedding could that would come for us a result of convolutional neural.",
            "If there are no note, features are.",
            "If no note features are available, then the these initials embeddings are one hot encoding.",
            "So after that then we apply the following formula that in this formula wanted us.",
            "It takes embeddings from the previous layer and it transforms them to get an impending for notary at layer cake.",
            "So how does how how this is done exactly so it's done the following for a particular for any notes.",
            "So note we we go to all different edge types that exist and we look at what are the neighbors of node V according to that edge type.",
            "So let's say that this is not you and with this taking that information, we then take embeddings for no for for the neighbors in that edge type, we aggregate them according to AW matrix which is indexed by ARM, which means that we have a separate weight matrix for every type of edges.",
            "And then we combine that with the embedding of node V from the previous layer.",
            "Enterprise these two along linear functions to login activation function.",
            "What might be important here is that this constant or this December CR normalization constants initially what it was popular, was to use constants that were the verse degrees of the nodes now, so they were fixed values and not optimize during training.",
            "Nowadays there's or meaning in the last year or so there's been a huge interest in attention mechanisms.",
            "So which implement the idea that different neighbors have different importances for learning the.",
            "Adult bedding of the note and attention weights can automatically capture that importance.",
            "So then this equation is applied to multiple multiple times depending on the depth of our neural network.",
            "And finally after K layers of neighborhood degradation we get and the final embedding for nodes.",
            "So the final in values of before.",
            "Note we is the output of.",
            "Of these computation, after clear layers of transformation."
        ],
        [
            "OK, so that's the encoder stage of our model.",
            "Assuming we have we have, we are able we estimated the values for our parameters, which were the parameter weight matrices.",
            "A separate matrix for every type of edges we can generate embeddings by simply applying those equations that I have shown in the previous slide, and that will give us an embedding for every note in the network, and it's possible to do that because parameters those parameters weight matrices W are shared across.",
            "Notes if you'll notice parameter matrix W's were not indexed by note but they were indexed by edge type, meaning that all nodes have the same.",
            "All notes in the network learn what is the most effective way of transforming and propagating information along edges in a similar way or in the same way, depending on an edge down.",
            "OK, once we have embeddings now in the decoder phase will use the learned embeddings to make predictions.",
            "Different kinds of predictions would would require different kinds of decoders, but for the purpose of this talk, the one that we are really interested in would be the decoder that will be take that will take as input a pair of embeddings of also embeddings for two nodes, and it will predict the probability of a specific type of relationship existing between those two nodes."
        ],
        [
            "So this is something known as his true genius edge decoder.",
            "So why it's edge decoder?",
            "Because what will be decoding is our edges will be predicting edges, and it's heterogeneous because we we were not just predicting the existence of any kind of Association between a pair of notes, but we want to be more precise and predict what kind of Association.",
            "What kind of relationship might exist between two nodes.",
            "So the way the decoder works is it takes at its input a pair of nodes.",
            "Say we have.",
            "We are currently looking at notes C&C&S and their embeddings.",
            "These obscene these S which we got from the encoder stage of the model.",
            "So the decoder, what it will do, it will.",
            "Take those two embeddings and it will combine them in such a way that the combined value will indicate what is the probability route would represent.",
            "What is the probability of an edge of a particular type?",
            "Say are one existing between a pair of nodes and this will be done such that the model will be able to predict any kind of edge and the probability of any kind of any kind of edge existing between a pair of nodes.",
            "Now what kind of model this actually is?",
            "It turns out that this heterogeneous edge decoder that I'm describing here is actually a teams or factorized model.",
            "So what you what you can think of having here is for for a pair of nodes we have one parameter matrix R that.",
            "Is shared across all different types of edges, and then for every type of for every edge I can have a separate parameter matrix D sub R1 for each type.",
            "One that tell us what is the importance of specific hidden dimensions for each type R1 so we know that embeddings have the dimensions and the matrices D will will tell us how important.",
            "Is a particular dimension towards predicting a particular edge type.",
            "So.",
            "And it turns out that that is actually a form of a factorization model, where we have one core matrix R that is shared across all modes.",
            "In this case, all edge types and for every edge type we have a separate the matrix, which is actually a diagonal matrix with non zero values only along the diagonal.",
            "OK, so why mentioning that is that is because depending on your concrete application there is lots of freedom and flexibility that you get here because we you could.",
            "If you think there is a particular type of decoder that might work well for your application, you might use that really well and you might use my.",
            "You might plug it.",
            "You must plug it in here and use it for for your model in particular, the kind of embedding methods that we discussed yesterday are.",
            "Those are for example methods.",
            "That could be used in this phase in this phase.",
            "In this stage of model here.",
            "So the reason why we're using things or factors model here will be is really the motivation for using it.",
            "Is the fact that we want to capture protect potential correlations between edge types as it will turn out later in some of the applications different kinds of edges will indicate different kinds of side effects, and we would want we we are we will want to capture dependencies and similarities between side effects.",
            "That's why we need to have some form of coupling between different edge types in our model."
        ],
        [
            "So this is defines the decoder which is which was the 2nd component of our model that used the learned embeddings to predict labeled edges between nodes.",
            "So to actually train this model what we do is we fit embeddings into any loss function that you would love, that you would like to optimize.",
            "Perhaps most commonly that that is cross entropy, but might might be a different kind of loss function, for example based on Max margin.",
            "And then we used to cast a gradient descent to train embeddings and to estimate to upper parameters of the model in an end to end fashion in those parameters are the W matrices that that were part of the encoder and the R&D matrices that were part of the decoder stage.",
            "So we can use different kinds of losses, and the important is really that we can directly train the model because it's the entire model is different."
        ],
        [
            "So to recap, the model that I just described and put it into a more broader context of this.",
            "Of Of of literature is the model data described?",
            "Is a particular instance of graph, neural or graph convolutional models.",
            "They wanted that I highlighted here is the one that is designed for multimodal networks that have reached note features and potentially add edge edge attributes.",
            "It has the power to generate very potential goal, often very useful deep embeddings.",
            "Unlike some of the shallow network embedding methods and it often leads to more accurate predictions than what we then predictions that we get by using shallow embeddings.",
            "Importantly, what is interesting here is that we can define new kinds of prediction problems on networks and partially many of those prediction problems are then very useful for problems in chemistry.",
            "For example, doing net graph level classification or modeling the data that might be temporal or dynamic in in many ways.",
            "So what this means that the application at the high level is that we can now apply deep learning models much more broadly, not only to images and sequence data, we can apply them to any graph or any particular multimodal graph, multimodal network that we have.",
            "And this really creates lots of lots of opportunities for new kinds of applications in biology and medicine.",
            "So next yes, yes, of course.",
            "Clean this in relational terms because what?",
            "To me is that you actually do aggregation.",
            "So if you use a particular type of.",
            "And you go separator between the different types of relations, yes, so let's take the notes on which involves yes.",
            "Then you find all other nodes which are related by articular relations with yes and then you aggregate their features for us.",
            "Yes, so I mean this is an OK neural networks are all the hype.",
            "And yes, it's great to use this technology.",
            "But you understand this, Does this translate database terms?",
            "Because in database terms you also have aggregation operations and you know you can say OK, fine, we all of the top ones which are related to this one another again.",
            "Yes, so that's that's great question.",
            "So, so here is actually there's a read value for the tries to put graph neural networks in the context of some of the related concepts, and those concepts come one set.",
            "One class of concepts comes from databases.",
            "More broadly on class of concepts comes from label propagation, so you probably have noted that the terminology that I've been using was our central.",
            "We propagate that information along edges and there is.",
            "Our label propagation algorithms that have been developed around 2000 or earlier that had this idea of propagating information along edges of the graph in order to make useful predictions.",
            "So let's let's focus on these two.",
            "So first, in the context of aggregating features.",
            "So here it's really only the zero or only the first layer of graph.",
            "Neural network is the one that aggregates note features.",
            "If those features are available so that the key idea is that in the first layer.",
            "We will note we look at its neighbors in a particular edge type.",
            "It will aggregate their note features in that knowledge and pass it on a linear function.",
            "Those not features are now so so, so.",
            "The result of this operation defines an embedding for the target node, which is the embedding after the first layer of transformation.",
            "And this is done for all of the neighbors also right?",
            "So all of the neighbors of the of the current target node also get their own embeddings.",
            "After this first layer transformation in the second half transformation, we apply the same function, but that function is now update.",
            "Functional does not aggregate feature vectors, but that it aggregates embeddings from the first layer.",
            "So this is the idea of convolution.",
            "So these are this.",
            "This these are graph conversions.",
            "So what is the knology with standard conversions that we have in images?",
            "So if you if you think of commercial neural networks they define convolutions.",
            "Think of if we have an image.",
            "Typically convolutions are small filters, three by three, 5 by 5.",
            "In the simplest case, and the idea is that we we go through every pixel offer image.",
            "For a given pixel, we apply that filter.",
            "How does how do we apply that?",
            "We look at?",
            "We apply that we put the three by three or five by five mask.",
            "On top of that pixel, we look at what are the neighboring pixels.",
            "We average them.",
            "We take maximum of that pixel and that declares transformed value of for that central pixel.",
            "So the analogy here is that, well, in the context of graphs, we cannot have this fixed three by three or five by five pixels, because.",
            "Every node can have a different number of neighbors an every note and there is no ordering to the neighbors of a note, which is what exists in image.",
            "So what graph conversions do instead is well, because there is no ordering of the notes, they need to think about what are the aggregate are functions that are invariant to the note ordering.",
            "So in that is then many inspirations.",
            "Here we come from the field of.",
            "Label propagation the filtered database systems where the idea is well where this kind of aggregate or operators have been studied in the past.",
            "The simplest case and the model that that I described is really a simple variant of the of the raffle network for multimodal networks, which can be explained quite easily.",
            "The idea is that we will simply look at the neighbors and we will average them and the averaging the weights that average can be.",
            "Weighted or unweighted, depending on the set of weights that were indicated in the formulas with C values.",
            "Instead of aggregating them, there are different kinds of correlation function that one might use.",
            "One more popular nowadays are is Max pooling, for example.",
            "But that is really the idea of graph conversions.",
            "Interesting, no, that's great question.",
            "Interesting connections here really also come from the field of label propagation, where you can think of this kind of models as models that.",
            "Propagate information along edges and the context of label propagation algorithms.",
            "The information that was propagated that is typically propagated along edges are labels of nodes, but what we are propagating here are victors.",
            "So you can think of these models as models that propagate Victor value to messages.",
            "That's often the term that is used in literature.",
            "OK, I'll briefly return to that at the end of the talk."
        ],
        [
            "OK.",
            "So perhaps it will be become become more clear where, where all these concepts will be very practically used for the problem of that I'll be discussing next, and that is the problem of."
        ],
        [
            "Pharmacy."
        ],
        [
            "So I mentioned to you pharmacy several times today and yesterday and this is really the term debt that refers to the situation when patients take multiple drugs at the same time to treat complex or coexisting disease and the statistics for the US is Sergeant at around 46% of people of age 65 or more take more than five drugs at the same time, and it's not uncommon to encounter patients that can take up to 20 drugs at the same time to treat complex diseases.",
            "Such as depression, heart disease or cancer.",
            "The problem, however, we taking too many drugs at the same time, is that patients are at a much higher risk of adverse events and unwanted side effects.",
            "In particular, the estimate is that 50 percent, 15% of the US population is affected by such unwanted side effects and this represents a burden not only for the individual patient but also for the entire healthcare system.",
            "Because now new car, because of the need to treat those unwanted side effects.",
            "So why do we see real side effects?",
            "And why are those?",
            "Side effects even more dangerous in the context of combinations of drugs that patients are taking.",
            "The reason is really that those side effects appear because of unexpected interactions between drugs, which is something that is not really tested during the during clinical trials.",
            "So the kind of data that we are looking here."
        ],
        [
            "Is.",
            "Our reports on unwanted side effects side effects.",
            "In particular, we teamed up with FDA and we are currently looking at international adverse Event Reporting system there and intuitively.",
            "You can think of the adverse event reporting system as as a large database that contains the following information.",
            "So it's a database that is maintained by the National Registry.",
            "It's constructed based on reports.",
            "Our debt our patients provide to physicians and physicians, then encoding the database and contains the following information.",
            "So for example.",
            "Is the drop that that patient states in its deficiencies in Red Rock and for patients that they quit drugs.",
            "These are the kind of side effects of patients are experiencing meaning and his numbers here with indicated for example around 3% of patients on their drug, might experience about equivalence in the reason.",
            "So these are just these are made up side effects.",
            "I can explain it into this.",
            "Similarly, a patient that they clean drug might experience different kinds of side effects or orange rug might express completely different set of side effects.",
            "Also, there is information on what happens to patients that are, but they're taking orange and green drug at the same time, or red and green."
        ],
        [
            "In some of the interesting patterns that we can see, here are the following.",
            "So for patients that take red and green drop at the same time, what would you expect?",
            "What kind of side effects would you expect those patients to have?",
            "Well, if there would be, there would know there would not be any interaction between red and green drug.",
            "We would expect that patients that take these drugs together experience side effects that are due to Red Rock Plus side.",
            "Things that are due to gridlock, sort of.",
            "That might be a form of the Union of the side effects that are that are due to each track individually.",
            "What is interesting here is that while there is indeed the case for the pair of red and green Rock, but if you look at orange and green drop and then we see that all of a sudden patients that take these two drugs also experienced side effects colon cancer and predict that there really side effects that we would not expect.",
            "If we look at the side effects that are associated only with red or green or only with orange truck.",
            "So these are the used to that these are two new side effects that we cannot really.",
            "We would we are not expected.",
            "We are not expecting we were not expecting them to see and this is due to unexpected drug drug interactions."
        ],
        [
            "So more concretely, what we mean by unexpected drug docking direction is the following situation.",
            "Imagine we have a system which do different with two different drugs, and when the patients are prescribed these and then when the patients take this blue pill, they do not experience any side effect.",
            "When patient take red pill alone, no side effects.",
            "But then when patients take red and blue pill together then they have side effects and this is something really dealt.",
            "We want to model.",
            "And capture computationally.",
            "So the question in the test that we will be solving here is the following for a particular combination of drugs we want to have a model that will predict how likely it is that a particular combination of drug will lead to a particular type of side effect and the kind of side affected side effects that we're interested interested in predicting are those side effects that are unexpected that are due to drug drug interactions."
        ],
        [
            "So modeling polypharmacy is hard problem for a number of reasons.",
            "Of the first is certainly the computer to combinatorial explosion of possible combinations of drugs very quickly.",
            "If you would look or we we get a lot of so many combinations that that we need to be very careful an when if you want to study them systematically.",
            "For the case of US, we there are 30 million possible combinations involving a pair of drugs.",
            "And more than 20 billion possible combinations of involving three drugs.",
            "But I mentioned before that there are many patients on five drugs, or even that, or even take 20 drugs.",
            "So the second problem is that the kind of.",
            "Outputs that we want to get our exactly those outputs that are due to unexpected nonlinear nonadditive effects.",
            "So really what we want to predict are side effects that are due to drug drug interactions and by definitions.",
            "Those are these unexpected events where the union of side effects or some additive model of side effects of individual drugs is different from what we actually see in in real patient.",
            "And Thirdly, you might think that of that as a big data problem, because what the data that will be working with is really the data that covers all patients in the US and that seems to be a big data problem.",
            "However, very quickly when we drill down to any particular combination of drugs, there's only a small set of patients on that combination of drugs and even fewer number of those patients then experienced side effect.",
            "So even though we have altogether large population of drugs.",
            "Then we really quickly get this small subset of patients that we can use for making a particular prediction.",
            "What we will be leveraging here is the fact that those side effects that we are capturing are not really independent of each other because the assumption is that side effects that affect for example similar organ systems might have some common biological underpinnings, and that's something that we will leverage.",
            "OK, so the first, the first problem that we need to solve here is really need to be able to construct and a polypharmacy data set to tackle to tackle the problem of predicting side effects of drug combinations."
        ],
        [
            "And the objective here for us was to capture Molecular Dragon patient data for all drugs prescribed in the US.",
            "So for that we be spent significant amount of time building a unique data set that contains information on.",
            "Currently available information on side effects associated with drug combinations from the FDA.",
            "Information on what?",
            "How do drugs so affect human body in the form of drug target information, and how do those and how do they target proteins?",
            "Interact with each other.",
            "Additionally, we have various kinds of site information or extra information describing drugs.",
            "Chemical structure describing membership of proteins in pathways which is encoded in the model by.",
            "To note feature vectors.",
            "So this gives us actually a multimodal letter that we have seen earlier today in the lecture where what we have are two 2 modes.",
            "We have these green triangles that represent notes.",
            "The fact that there is an edge between a pair of nodes.",
            "C&S type R2 means that when patients take CNS together, they are likely to experience side effects are two which might be pretty cardio side effect and that side effect is not cannot be.",
            "Attributed to either C alone or either S alone.",
            "So the edges, the temple that here also have weights because not all patients will experience the side effects.",
            "So their way to Tejas and their typed edges.",
            "Furthermore, when CNS are taken together that might lead not only to bradycardia side effect but also different kinds of side effects.",
            "Becomes quite complicated because now a relationship between CNS vis that there might be multiple edges between CSF, CNS, each edge of a different type and there is a weight associated with average.",
            "And then here we have information on what are the proteins associated with C and how do those proteins interact with each other.",
            "So.",
            "The nature of that we get is a highly multimodal network because it has around 1000 different types of edges."
        ],
        [
            "What we will do next is will apply the model that I have described before to this multimodal network, with the goal of predicting side effects for drug bears, particular the kind of query that we want to our model to be able to answer is the following.",
            "Here's an example, so we might want to ask how likely it is that when two drugs form of stating and ciprofloxacin when they are taken together, how likely it is that they will lead to breakdown of muscle tissue.",
            "If domain expertise interesting in this question, this means that what we are really asking of our model is we are asking the model to say how likely it is that that on edge of type of breakdown of muscle tissue exists in our network between and.",
            "In particular, this edge exists between nodes C&NS.",
            "So that's exactly the link prediction problem where we are aiming to predict label link labeled links between.",
            "Pairs of notes, which means that we can exactly use the encoder and decoder that I have described earlier.",
            "And really, the idea is here is that we take the data from patient reportes molecular information.",
            "We construct this large knowledge graphs which are partially observed graph that represents currently available information about biology and how drugs works and what are the side effects that human patient population experience.",
            "And that's a partially observed graph that we will that we leverage in order to make new discoveries.",
            "In this case, new predictions about side effects."
        ],
        [
            "So the first thing that we did when we trained our model is to evaluate it empirically using cross validation.",
            "So here we what I'm showing is in the red bars is the performance of the model based on different beddings and the three other bars indicate various simplify simplifications of the model.",
            "What is important here to say is that we wanted to understand how important are different components.",
            "Of the deep model towards accurate prediction and what we see is the following.",
            "So first the deep net or the graph neural network model performs better than shallow network embeddings.",
            "Those are embeddings that we have seen yesterday and there are in the reason why this model now today works better is because we can optimize it in an end to end fashion rather than to have two or multiple independent stages where we would first learned embeddings and then.",
            "Taken beddings as input to train a downstream classifier.",
            "Second, we wanted to say well, is it really useful to have these deep encoder model that learns embeddings based on multiple layers of transformation?",
            "What would happen if you would simply represent our data so large things or and then run tensor factorization?",
            "So in in here provided to Shoney's, the comparison between two very well known teams or factorization model by maximum comfort and others at the disco, Driscoll.",
            "And finally there are some other shallow network companion methods in the form of multi relational factorization that we are also comparing here.",
            "And these are the reasons that the the the numbers here measure the AUC under.",
            "Receiver operating curve and average precision at top 50.",
            "Beyond that, wanted to understand what is actually the utility?",
            "What is the potential or utility of this new prediction?"
        ],
        [
            "So the next experiment we did was the perspective or actually time based experiment where the idea was to train the following.",
            "We trained the model on all data generated prior to 2012.",
            "And then as the model to make predictions and test well how many of those predictions that the models most confident about were confirmed after 2012.",
            "So what I'm showing here on this table are 10 predictions that the model was most confident about what predictions as you would expect come in the form of a pair of drugs and a side effect that is most likely to be associated with that pair of drugs.",
            "So for five out of this 10 most predictions that the model most most confident about there is direct evidence in the literature.",
            "After 2012, that is that reports.",
            "Patients that are on specific combination of drugs and experienced side effects that are due to this truck drug interactions.",
            "Which is already very exciting and then we ask, well, what about this white space here?",
            "Does this white space might represent actually representing you predictions?",
            "Or it might just represent a mistakes made by the model?",
            "So to make one step further and go beyond cross validation and beyond this time based."
        ],
        [
            "Sleep we we.",
            "We teamed up with.",
            "It matters to general in Boston and Stanford Medicine and we are currently validating some of the predictions made by the model in the actual clinic using various kinds of drug tracking, direction markers, lab values and surrogates, and what is even more exciting is that this population level approach that I that I have described so far that does not include any information that is personalized to particular patient.",
            "It can actually be extended in such a way that we can make personalized predictions and then we can inform design of new combinatorial drug therapies.",
            "But to make this part a bit more tangible, let me just let me show you how we can actually evaluate or or or prediction using data from the clinic in real patients."
        ],
        [
            "So the key idea here is that we use the principles of causal analysis, or really propensity score matching.",
            "So imagine our model makes the prediction, which says that the model predicts that when a patient will take the group, this green and orange duck together, they will experience nausea side effect.",
            "Let's say the model makes this prediction and now we want to validate if that prediction is sexually is actually true.",
            "So how we will do that?",
            "So we do that in the following manner.",
            "So we what we look for.",
            "We go through our database of patients and we look for large number of triplets of patients.",
            "Each triplet should have the following form.",
            "So we have three patients.",
            "We know that for patient number one that patient was at some time that he was prescribed the green drop and sometime later everything was fine.",
            "No no anti nausea medication.",
            "No reports about nausea.",
            "The second patient was prescribed orange drug alone and again everything was fine.",
            "No reports of nausea.",
            "For the third patient, we see that patient had was taking red and or sorry or green and orange drugs, and will tanias Lee.",
            "And sometime later we see that the patient re was put on anti nausea medication.",
            "So why was patient re put on anti nausea medication so patiently could be put on anti nausea medication because?",
            "He developed some start disease independently of this of that combination of drugs that patients was on or the patient was taking these two drugs together.",
            "As a result, he experienced side effects nausea and we had to treat the physician had to treat nausea.",
            "So the physician patient re on anti nausea medication.",
            "So if we are able to find 1 three plus of patients with these kind, this provides very weak evidence.",
            "That prediction made by the model is actually true.",
            "So then what we need to do is we need to find lots of triplets of patients of this kind.",
            "The more triple the larger number of triplets of patients that we find, the more likely are the prediction really represents a viable interesting prediction for further research.",
            "So.",
            "You might wonder that that might be quite challenging to find large number of triplets of patients of discounting.",
            "Indeed it is.",
            "So what is really important here is to have access to large database of patients were there in particular health care systems where there are thousands or hundreds of thousands of patients.",
            "That that we can then mine to find support for.",
            "Of support for predictions.",
            "In another comment here is then this example that I provided here really focused only by looking at what are the drugs that what are the patient was put on some time after the drugs that were involved in prediction there.",
            "And this is actually the surrogate measure here that was used to evaluate predictions.",
            "There are various kinds of other surrogate measures including clap values, some genomic biomarkers, biomarkers that we are using to validate predictions in the clinic, but I think.",
            "What is really exciting here is because the idea here is to make this large jumps by building bridges from molecular level information on on how drugs affect or how drugs target proteins, help proteins interact with each other, which is part of the data used to train the model and go all the way up to real patients in the data that is reported in the clinic, which I think is really exciting because it's it kind of tries.",
            "To bring bring together some of the data that is generated by basic.",
            "Experiments with really translational data sets that come with its own set of challenges and statistical problems."
        ],
        [
            "OK, so this concludes the polypharmacy example and then the next application that I will discuss is that of drug repurposing."
        ],
        [
            "OK, so there's been already lots of discussion in the last few days about drug discovery and rocket purpose, and also repurposing costs."
        ],
        [
            "Of several times so introduction introduction here can be really very short in our case.",
            "From the computational point of view, our goal will be to to think about what are effective ways that allow us to map this large space of molecules.",
            "Only a small number of which are actual drugs to very large space of phenotypes and diseases, with the goal of finding which diseases a new drug or molecule could treat."
        ],
        [
            "In particular, in the context of drug repurposing, this means that the goal is to.",
            "Take an existing drug on the market and repurpose it for an you disease.",
            "That is something we might want because it really is much, much faster and much, much cheaper than if.",
            "A new drug would need to be designed completely from scratch, so there's lots of interest into finding these new tricks for alter existing drugs.",
            "The challenge, however, is that it's very hard to do that in a systematic manner, and most of the drugs that were re purposed in the last decades were due to various accidental findings.",
            "So we will do.",
            "We will approach this problem here computationally."
        ],
        [
            "The key inside that we that we have here is that we will now move beyond looking at individual edges or pair of nodes, and we will operate on the level of subgraphs.",
            "In particular, our setting will be the following, so we have the underlying graph of proteins in human body, so these are these a wide circles where edges indicate physical interactions.",
            "As we have seen several times during this two lectures and we will overlay this network with a large number of subgraphs, in particular for every disease that we have in our system will represent disease by all my subgraph of protein interaction network, which is defined.",
            "On disease associated proteins.",
            "And for every drug will represented by a subgraph of protein networks, protein network defined on drugs target proteins.",
            "Here also included various information on off targets or off target proteins.",
            "And others.",
            "So what why do we want to do that?",
            "We want to do that because of some of the known conceptual explanation why I dropped my slightly to treat the disease that says that a drug is likely to treat the disease if it is close to the disease in pharmacological space.",
            "So then this is very hard to define or computationally operationalized, But what we will do here or trick will be to use the power of embeddings to operationalize this concept so that what we will do is we will measure closeness of a drug of a drug disease pair by measuring closeness between their embeddings in the embedding space."
        ],
        [
            "So really, the prediction test that we are solving here is the following.",
            "Given a drug C and given a disease D, want to predict if C has the potential to treat the if it has a positive therapeutic effect for the.",
            "So our input data, the way it comes, it comes in the form of a large number of disease subgraphs.",
            "A large number of drug subgraphs, and this black edges across sub graphs indicate no indication information, so these are this, for example, this edge indicates that the start diseases currently approved to treat this this particular drug number one.",
            "Our goal will be to learn embeddings for every subgraph in our net.",
            "For every subgraph, so for every disease and drug subgraph and then use those embeddings to predict new links between subgraphs.",
            "So that's again a link prediction problem, but it's now we're not predicting clicks between individual notes, but we will be predicting clicks between subgraphs intuitively.",
            "Why do you want to do that?",
            "We want to do that because.",
            "We we really want to integrate in.",
            "Consider lots of information about drugs and diseases rather than representing drug as a single note or representing the disease as a single note, which would really throw away lots of potentially very useful information."
        ],
        [
            "So, and that's why we work with subgraphs so methodologically, there is some interesting twist here, and that interesting twist is that now that we need to think about what is, what is the right encoder to use now, because we're not only encoding notes, but we want to encode subgraphs.",
            "So for that we develop a subgraph encoder, which is an encoder that takes as input a subgraph, and it learns and embedding for the top graph.",
            "A baseline underneath model here that you could think of you say well.",
            "To get an embedding of the sub graph, we will first learn embedding for every note and then we simply taken every championing of notes in the subgraph and will say that is the embedding for the sub graph.",
            "That does not work, that that's a valid baseline and it's good baseline.",
            "It does not work well because it completely ignores the internal interaction is so interactions between proteins internal to the subgraphs, so various importance of nodes that participate in the sub graph.",
            "So what is what works well?",
            "What is needed to hear is a type of encoder that can learn embeddings at the level of subgraphs.",
            "An idea here is very similar to what I described before, in the sense that we will learn how to propagate those Victor valued messages or feature or embeddings along edges of the network and now also along edges the defined subgraphs.",
            "OK, so in the the model that does that."
        ],
        [
            "Old sugar.",
            "So once we have the model, the next thing again that we need is we need to high quality drug repurposing data set and for that we spent quite some quite significant number of significant amount of time preparing and cleaning the data set.",
            "But now data set is ready.",
            "It contains information on protein, protein, interactions, information on what are drug targets in disease, associated proteins from various public databases and is also enriched with some of the.",
            "Data from our collaborators.",
            "Information on currently approved medical indications.",
            "Meaning information on what on what are drugs?",
            "What are diseases that are treated by drugs that are currently approved on the US system and that comes from repository such as Drug Bank report.",
            "DB also FDA orange book if that is for me, you're familiar with that and lots of side informations on drugs, diseases, parties for example.",
            "What are molecular pathways that proteins are involved in that comes from the Broad Institute MSIT DB database?",
            "What are the symptoms that diseases have that are associated with the disease?",
            "Is this comes?",
            "This comes from the various disease comorbidity data sources.",
            "What are side effects of individual drugs?",
            "This comes from a cider that is maintained by Embelin.",
            "A few other resources.",
            "I'm happy to talk more about it.",
            "We also made all these datasets publicly available, so there's a clean preprocessed version of these datasets that you can download the news.",
            "OK, so we have the data set have the model.",
            "The next thing that we will do we will evaluate."
        ],
        [
            "Model in a in a cross validation setting.",
            "So our prediction test will be given a disease and a drug.",
            "We want to predict if drug will treat the disease, the kind of cross validation that we do here is a drug centric cross validation and then also disease centric cross validation.",
            "But I'm showing here the results of drug centric cross validation which means that one drug appears in the test set but none of its indications or any of its information is available on the test in the in the training set.",
            "So what the results that are shown here compared the proposed method that is called sugar to some of the existing methods, or for drug repurposing where we can see improvement that is quite substantial.",
            "But what is even more interesting is improvement over this recent set of methods that were proposed.",
            "That is even more substantial, and the reason why this improvement was achieved is the following.",
            "So this set, this second class of.",
            "Baseline methods that we consider are those methods that operationalize this idea of closeness in pharmacological space, that that we that I described earlier by simply calculating shortest path lengths between drug subgraphs, indices, subgraphs, and that is much less flexible than actually learning embeddings for notes in such a way that's most useful for prediction.",
            "So this really shows the power of learning those embeddings over thinking more of the standard approach on performing machine learning on graphs."
        ],
        [
            "Furthermore, what is really interesting here is that including side information leads to much, much better if.",
            "Performance and substantially improves performance, so the kind of science information that we are including here inside information on protein pathways, metabolic Patriots, and various types of genetic factors that proteins are involved in.",
            "So in the way this is done is we have this underlying put input interaction at work and we have seen that we have a large number of drug and disease sub graphs that are all relate on that on that PPI network, but in.",
            "Listen to that now.",
            "We also had a large number of other kinds of subgraphs that represents various types of metabolic pathways that we're actually not interested in predicting.",
            "Any associations for them.",
            "But these pathways effectively serve as a form of regularization because for all proteins that participate in a particular pathway, their embed their embeddings, which are used for learning companions of subgraphs, will be pushed closer together.",
            "And including that information on on site information or proteins really further boost performance of the model."
        ],
        [
            "Beyond cross validation, we then asked well what, how useful are predictions made by the model for real world truck repurposing?",
            "So for that, we teamed up with Stanford Spark, which is international Center for translational research and we got from them the list of drugs that were repurposed at Stanford and Boot in that center over the course of the last two decades.",
            "And we think thought of that as a gold standard data set and then we asked, well, for those drugs that were repurposed at Stanford.",
            "Let's say, what are?",
            "What are the predictions?",
            "Bye bye you buy sugar model so an inch predictions turned out to be very good.",
            "So the way we can read that is if you look at focus on this particular role.",
            "It says that covered the law was re purposed for Chagas disease.",
            "Also.",
            "There's something that is a known fact, so the model that make prediction and actually ranked Cardinal's ninth most rank most most likely drug that is used for Chagas disease out of 5000 drugs on the use lock and for many other cases you see that the drugs that were actually repurposed for to treat these new kinds of diseases were always ranked very highly.",
            "In by default which which which was very promising and it has led to exciting follow-up research on prostate cancer where we are now focusing on developing and identifying combinatorial drug therapies that are most useful for prostate cancer patients and minimize side effects.",
            "In particular, various kinds of incontinence.",
            "That is the problem here, and also for.",
            "For for schizophrenia, for which none of the.",
            "Current now, not the treatments.",
            "Rather current treatments actually work in our treat only symptoms rather than the causes of diseases, and for Sister Frania in particular, it's very interesting and important to have this information or an ability to bring different kinds of information through multimodal networks, because the goal is not to study schizophrenia only from the neck above, but also from the neck below, which is something that has not been done before and most of the efforts have really put been put towards.",
            "Understanding and finding treatment for schizophrenia by really focusing on what's going on in the brain.",
            "But recently, this recent discoveries have shown that it's really important what's going on in the rest of the body as well.",
            "And then multimodal networks allow us to bring that kind of information together."
        ],
        [
            "OK, so one important challenge here was really that challenge of how to communicate with domain experts and convince us that this.",
            "Great black box models produce predictions that are actually interesting and potentially useful to them so.",
            "That was quite a difficult challenge.",
            "That and it was important to design systems that allow domain experts to interact with with this machine.",
            "Learning models in the form of.",
            "Providing explanations not only pointwise predictions.",
            "OK."
        ],
        [
            "So this concludes the drug repurposing case study.",
            "Then the fault.",
            "Well, I think I have 10 more minutes.",
            "OK, so in the rest of the time I will talk about some of new directions and opportunities to further research in this field.",
            "And then I also talk about practical advice.",
            "I don't think I'll have time to go to demos, but I'll provide a code so you can do that offline."
        ],
        [
            "OK, so new directions and opportunities.",
            "I think there are many new directions for those here available for to further this current models that we have an."
        ],
        [
            "In particular, I will mention three exciting directions that.",
            "That I'm especially passionate about."
        ],
        [
            "The first direction is certainly direction direction towards providing a meaningful explanations, since in biomedical settings it's not only about getting the highest AUC, but it's also about understanding prediction and really for that what we need are various kinds of new means that can transform these black box models into white box models so that we have predictions that we can interpret meaningfully and that those white boxes models can be opened in in kind of probed.",
            "And some of the ongoing research here really uses these principles that come from.",
            "A counterfactual inference that.",
            "That tend to work quite.",
            "Well and address some of the problems related to explanations, but I think there's much much more that can be."
        ],
        [
            "Here.",
            "OK.",
            "The second direction is that of towards more training, more with less data.",
            "So I think what we all really need here is very algorithms that can train more with.",
            "And really can generalize to never be forcing systems.",
            "In particular here.",
            "What I mean, we did a very simple test where we trained the model on data from one particular clinic in one hospital and then take and then took the trained model and apply it to a corresponding clinic in a different hospital.",
            "Both hospitals were in the same state and actually very close to each other and they got the same profile of patients came to both hospitals.",
            "It turns out that the model performed very miserably in the second clinic in the in the different hospital, then the hospital data model was trained on and although both hospitals use use use the same as healthcare.",
            "Database system with trust epic system.",
            "There were different subtle internal differences in internal guidelines for how to encode information about patients, and that has really.",
            "That was that was really the problem that made this current.",
            "Existing models performed so miserably.",
            "So there's lots of opportunities and lots of work that needs to be done that will really allow the models that we currently have to learn and generalize to different contexts.",
            "With this context can mean different diseases, different patients, different environments in the sense of different hospitals or environments in the sense of ecological systems.",
            "There are many natural case studies for such algorithms that can go from single cell genomics to health informatics.",
            "Another direction related to this is that many of the very successful examples of these deep models in the literature were really.",
            "Very simplistic in the sense that the input to those model was a simple image.",
            "For example, a simple image of a skin lesion with the goal of predicting whether that image contains a benign or malign skin lesion.",
            "Of course this is great and it's a great progress, but it completely ignores any knowledge about the disease.",
            "Any knowledge about patient and all these other kinds of data that we might want to have?"
        ],
        [
            "Second, finally the third direction here is really that, well, we soon.",
            "I believe that there will be a state of the state of any person will be described not only by genetic information, but also about data that goes to the describes behaviors and lifestyles.",
            "So it's really how do we integrate now?",
            "This data from the from the gene level all the way to behaviors, so we need new methods that can.",
            "Bring these data to Heather and then can answer different kinds of complex prediction problems on graphs.",
            "Some of the initial results that we did in this direction that I didn't go into details are frameworks that can answer logical queries or knowledge graphs, so this is more very exciting from the point of view that allows domain experts to ask any kind of logical query in this that might be very complex.",
            "So not only asking.",
            "Given a disease and a protein, is that protein likely to be associated with disease?",
            "But the domain expert can ask questions of the form of.",
            "Oh how how likely it is that the disease will treat a disease.",
            "A will treat drug B and read rugby should target to proteins C&D and those two protein C&D should interact with each other, so that's a very for complex query that that can be answered by the model on the fly in any kind of query that can be formulated in a conjunctive logical language can be formulated in this way and then insert insult so that I think it's a very exciting direction towards having this kind of interactive systems.",
            "The domain experts can interact with.",
            "Think of it us.",
            "Especially in some of the.",
            "Move the large systems is now lots of interest into constructing Clark knowledge graphs that we can then learn and reasonover.",
            "So having such a system that can answer these queries would be very exciting.",
            "I think from the machine learning point of view, what is really needed here are is there's lots of food that needs to be done in the form of data infrastructure, so having high quality, preprocessed, clean public datasets that can be used by computer scientists who developed new exciting algorithms and so that in the paper that we published.",
            "This new exciting benchmark.",
            "There will be new exciting benchmark datasets used in experiments that come from biology and medicine, not only from some, perhaps domains that are not indicative of the application cases of this methodology.",
            "We made some first steps toward this goal, but there's lots of lots of that needs to be done."
        ],
        [
            "OK.",
            "The last two minutes."
        ],
        [
            "I'll give some practical advice."
        ],
        [
            "If you are exciting about this area of research, how to start?"
        ],
        [
            "So here in this slide I provide some lecture of some some resources, in particular the first is mumble.",
            "That's something that I mentioned yesterday, it's it's really.",
            "At all that allows you to construct very large heterogeneous networks networks that have up to two billion edges, so I think there is discovers lots of problems in biology, medicine, exciting network data.",
            "These are cleaned, preprocessed, high quality datasets.",
            "Some of those, some of some of the datasets listed here are those that I described throughout the throughout the lecture today that allow you to design new algorithms and benchmark them On this date."
        ],
        [
            "Set.",
            "Second, once you have the data set and you have the tool to represent the data, will you actually want to train some of these models so there is a number of code bases that allow you to try out some of these models quite easily on your own network on your own networks, and this goes from notably shallow and place of bad thoughts that I described yesterday to GCN models all the way to some of the.",
            "The industry supported libraries for graph neural networks, in particular graph that is 1 example and deep graph libraries and library.",
            "Another example that contains lots of tutorials, demos that it's so that it's very easy for you to start."
        ],
        [
            "Finally, to recap, I think there are like two kinds of proof.",
            "Two kinds of people in the audience here that might have different view of graphs.",
            "So if you have been using graph seeing your current research project, then I would encourage you to keep on using them.",
            "The reason so some of the advantages that the methods that I described yesterday and today bring is that you don't need to do a lot of manual tedious feature engineering anymore.",
            "This new class of methods allowed to combine note edge attributes and do end to end to end training which achieves state of the art performance of a number of tasks.",
            "If you have not yet used graph in graphs.",
            "In your research projects, because perhaps your data datasets that you work with are primarily image based datasets, sequences or more standard feature feature tables.",
            "Then there, then they are exciting opportunities for graphs could be used in an could lead to improvement in performance, so the kind of questions that you need to ask is if the data is that you have is such that there really is there data set that you have really contains ID examples or there is some form of dependence or some form of relationship between images between different sequences between objects in routine and image.",
            "And if that is the case then it makes lots of lots of sense too.",
            "To represent those dependencies explicitly in the form of graphs and use that as part of the input to your favorite classifiers or to favorite graph or to your favorite neural network.",
            "The reason why I would want to do that is because this can often lead at least too much, much faster training, meaning that you would need much less time and less data to get the same performance.",
            "So what I mean by there just more concretely, is imagine you are.",
            "Something you're pulling some prediction tablet is defined an image, and classically the inputs to their test would be on raw image of pixels, and that's OK, but very recent research has shown that the model can be trained with much less data if you supplement that role image with with the graph of objects detected in the image in various kinds of relationships or between those objects.",
            "So imagine we would do that, but now not in the context of buildings and cars and boys and girls, but in the context of for example, itself, like a large number of cells that are in your particular image."
        ],
        [
            "OK, finally we talked a lot about this heterogeneous networks and I think that's really an exciting paradigm that can integrate knowledge with diverse.",
            "Diverse kinds of experimental readouts to perform discovery."
        ],
        [
            "OK, and the final slide is.",
            "Different, I talked throughout these two days.",
            "I talked about different kinds of predictions we can make when we have data provided to us in the forest graphs and that those predictions can be note predictions.",
            "Meaning we're we're we're goal is to predict some property about notes in that graph.",
            "Some form of relationship between pairs of nodes, some form of relationship between subgraphs.",
            "What I didn't talk about, but some of the other speakers have mentioned is then predicting properties about entire graphs, which which is.",
            "Which is now quite popular in the form of predicting various properties about molecular graphs.",
            "OK, so I didn't.",
            "I don't have time to go through demos, but.",
            "I'll, I'll put them online so you can check them later and this concludes the talk for today.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for coming to the second part of this lecture.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me briefly recall the outline.",
                    "label": 0
                },
                {
                    "sent": "So as you remember yesterday we talked about shallow network embeddings and different various several applications of those embeddings to problem seen bioinformatics, including prediction of protein, protein interactions, disease pathways and protein functions in different tissues.",
                    "label": 1
                },
                {
                    "sent": "So what we will do next is today will focus on deep network embeddings in particular describing.",
                    "label": 0
                },
                {
                    "sent": "I will describe how we can learn embeddings for notes in.",
                    "label": 0
                },
                {
                    "sent": "Large heterogeneous networks using multiple layers of nonlinear transformations which will give us powerful embeddings, and then as has been advertised on the web, I'll focus specifically on polypharmacy and drug repurposing as applications of those of those new methods.",
                    "label": 0
                },
                {
                    "sent": "So remember my my talk is more or less about promoting networks or graphs or some means, as in a general language that allow us to bring heterogeneous biomedical data together at the level of populations in the form of interactions between humans down to the level of individuals, and then various kinds of interactions between.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Molecules in a cell and networks really allow us to bring these different scales together and have one one unified representation.",
                    "label": 0
                },
                {
                    "sent": "Across multiple scales and different kinds of interactions.",
                    "label": 1
                },
                {
                    "sent": "OK, so once we have such heterogeneous networks, our next goal is to have methodology that allow us to train.",
                    "label": 0
                },
                {
                    "sent": "Now the models on networks and make useful predictions about various properties of individual nodes, pairs of nodes or higher order structures in the networks.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Today, as I said, I will focus on the graph neural networks as one such powerful methodology that can be used for making accurate predictions on large heterogeneous networks and the outline of this lecture is first, I will briefly I will discuss the algorithms and then I will focus on the 1st application of that is related to polypharmacy drug interactions and drug combinations.",
                    "label": 1
                },
                {
                    "sent": "Then I will focus on drug repurposing.",
                    "label": 0
                },
                {
                    "sent": "And finally, the last two points here are more discussion points where I will outline some of the new directions and I think exciting opportunities for those in the audience that are interested in excited about developing new algorithms that would address certain challenges in current biomedical research.",
                    "label": 0
                },
                {
                    "sent": "And finally, I will conclude with some practical advice, and I also have some demos prepared so there will be time left I can actually show you a very simple model.",
                    "label": 0
                },
                {
                    "sent": "That we will describe in the first part of the talk that really implements all these mathematical equations and we can.",
                    "label": 0
                },
                {
                    "sent": "We will see how it is, how quickly does it work, and how does it work on a four on a one particular application.",
                    "label": 0
                },
                {
                    "sent": "OK, and feel free to interrupt me during my talk and I can take questions anytime or at the end.",
                    "label": 0
                },
                {
                    "sent": "Whatever works best.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's start with the first point.",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                },
                {
                    "sent": "Since this is the first lecture after the yesterday's blanket, so let me.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just recall recap what we have learned yesterday.",
                    "label": 0
                },
                {
                    "sent": "So yesterday we learned about this principle of embedding notes and that has been mentioned several times throughout this workshop and the idea here is that we want once we have the net or network we want to map notes in that network in a particular embedding space, such that similarity of notes in the embedding space, how closely together they are embedded will reflect similarity of notes.",
                    "label": 1
                },
                {
                    "sent": "In the input network.",
                    "label": 0
                },
                {
                    "sent": "Anan RE.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really, the goal, so mathematically what it means, we want to approximate similarity between nodes or pair of notes and V in the network, which in the simplest case with with the DOT product between the embeddings for those two nodes that we wanted to learn and hear this, these two key components are the definition, the notion of similarity that we want to capture and the mapping or transformation code function that will map the notes to the dementia.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space, so these are two key components.",
                    "label": 0
                },
                {
                    "sent": "The encoder that will map a note to low dimensional Victor and 2nd the similarity function that will define what kind of similarities do we want to capture.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so far.",
                    "label": 0
                },
                {
                    "sent": "Meaning yesterday what we learned.",
                    "label": 0
                },
                {
                    "sent": "What about we learned about shallow encoders so shallow.",
                    "label": 1
                },
                {
                    "sent": "Encoders are methods for learning embeddings of nodes in the network through as one scene, one layer of transformation, and examples as we have seen.",
                    "label": 0
                },
                {
                    "sent": "Where are various matrix factorization models, and when more recent models such as no two week Deep Walk line and instruct week that I have discussed yesterday.",
                    "label": 0
                },
                {
                    "sent": "So for shallow.",
                    "label": 1
                },
                {
                    "sent": "Encoders what is typical is that for a particular note during optimization, we learn directly how to learn.",
                    "label": 0
                },
                {
                    "sent": "We learn directly, does evictor for that note meaning the embedding for that note.",
                    "label": 0
                },
                {
                    "sent": "And that is, and you can interpret that as actually learning a table that will represent an embedding look up.",
                    "label": 0
                },
                {
                    "sent": "So there were some of the limitations of those shallow encoder encoder's that were mentioned yesterday, and at the end of the mother my lecture yesterday there were there was there were some interesting question that highlighted some of the limitations of shallow encoders in.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are limitations of shallow encodings are that the number of parameters that we need is large.",
                    "label": 1
                },
                {
                    "sent": "The number of parameters is in the duration of the size of the network, meaning that for every note in the network, we directly learns the dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "There is no notion of sharing parameters across embeddings of the nodes because we directly learn an embedding.",
                    "label": 0
                },
                {
                    "sent": "This means as a consequence, this means that our embeddings are inherently transductive.",
                    "label": 0
                },
                {
                    "sent": "What this means is that.",
                    "label": 0
                },
                {
                    "sent": "When, for example, and you know it would come in the network for the methods that I discussed yesterday, it's impossible to simply generate embedding for the new node, right?",
                    "label": 0
                },
                {
                    "sent": "So in principle would need to what we would need to learn, or what we would need to do when you note or new notes arrive, retrain the model from scratched.",
                    "label": 0
                },
                {
                    "sent": "So this means that we cannot generate embeddings for nodes that were not seen during training, and typically we would not want to do that Ann, and finally another an important limitation of shallow encoding methods, especially in the context of biomedical research, is that they do not incorporate note features at edge attributes or this additional very rich extra information that we often have in many biomedical applications.",
                    "label": 1
                },
                {
                    "sent": "And that's something that would have been highlight.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It yesterday.",
                    "label": 0
                },
                {
                    "sent": "So next, what we will do is we will will address these limitations by discussing deep model methods that are based on graph neural networks.",
                    "label": 1
                },
                {
                    "sent": "In particular, an important notion that we will discuss is this encoding or the mapping function that will now make notes to note to a dimensional Victor through multiple layers of nonlinear transformation defined on the graph structure.",
                    "label": 0
                },
                {
                    "sent": "So if you if you would not know much about graph neural networks, you can quickly think about what would be a naive approach to doing them.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and if approach would be to say, well, if we have, we have many existing deep models, many variants of conversion, neural networks and recurrent neural networks, or LCMS, and those methods work extremely well on images or sequence data, and image is represented by matrix.",
                    "label": 0
                },
                {
                    "sent": "And of course when we have a graph, we can also represented by matrix its adjacency matrix of the graph.",
                    "label": 0
                },
                {
                    "sent": "So naive approach would be to take the graph and represent it with adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "And concatenate potential features that we might have for notes as additional columns in that matrix.",
                    "label": 0
                },
                {
                    "sent": "And once what we would have such matrix, we would simply feed it into some perhaps standard feedforward neural network.",
                    "label": 0
                },
                {
                    "sent": "So here's one example.",
                    "label": 0
                },
                {
                    "sent": "When we could do that.",
                    "label": 0
                },
                {
                    "sent": "So Megan have the network on the left.",
                    "label": 0
                },
                {
                    "sent": "It's a simple network with five nodes, meaning that adjacency matrix when there will be a 5 by 5 adjacency matrix and there is one that provided for in that in that one syndicate actually edges between nodes and zero indicate indicates no edge between parents and we might have some additional features which we can concatenate here.",
                    "label": 0
                },
                {
                    "sent": "So this could simply be best.",
                    "label": 0
                },
                {
                    "sent": "To feed forward neural network and or some other existing architecture and that would potentially give us predictions or would give us embeddings for the notes so and so we could do that and then one would say, well, why do we need new class of neural networks?",
                    "label": 0
                },
                {
                    "sent": "Because this already works well.",
                    "label": 0
                },
                {
                    "sent": "So what might be the problem with this idea?",
                    "label": 0
                },
                {
                    "sent": "So the problem with this idea that fundamentally the problem is that.",
                    "label": 0
                },
                {
                    "sent": "Then did the.",
                    "label": 0
                },
                {
                    "sent": "These methods are not invariant to note orderings, so this in particular what why what I want to highlight here is that if we think of our Jason C matrix as interpreted as an image and it use it as input to these models, then the then the model.",
                    "label": 0
                },
                {
                    "sent": "What we will learn, it will really capture this spatial locality which is not relevant for graphs.",
                    "label": 0
                },
                {
                    "sent": "So if we.",
                    "label": 0
                },
                {
                    "sent": "Would simply take a network and we were three label our notes in the network.",
                    "label": 0
                },
                {
                    "sent": "This does not change the graph structure, so the network is actually the same.",
                    "label": 0
                },
                {
                    "sent": "However, the adjacency matrix would complete look completely different, so the the image representation of adjacency matrix would be completely different, right?",
                    "label": 0
                },
                {
                    "sent": "Because we have just real randomly re labeled the notes and so our prediction are embeddings would be different as well, but that's not what we want because actually the underlying graph structure has not changed at all.",
                    "label": 0
                },
                {
                    "sent": "So the problem with that is that and if approach is really not invariant to northward, to note ordering or, which is something that is crucial here, since there is no specific reference point in graphs that would apply or redefine the ordering of the nodes.",
                    "label": 0
                },
                {
                    "sent": "The second problem is like, let's say if you train this model now on this network on five notes, what happens when we have a network on 6 notes?",
                    "label": 0
                },
                {
                    "sent": "We would need to essentially train a different architecture with different number of.",
                    "label": 0
                },
                {
                    "sent": "Neurons on the input layer because now we have a network on six or more nodes, so it's not applicable to graphs of different sizes, which is what is very important in many applications.",
                    "label": 0
                },
                {
                    "sent": "And finally, perhaps a bit subtle differences.",
                    "label": 0
                },
                {
                    "sent": "That is, the number of parameters that we would have with some of the standard models that would require very, very large datasets to be trained.",
                    "label": 0
                },
                {
                    "sent": "So what we need in what we will do next is we we will generalize convolutions beyond simple lattices, meaning that the standard conversions that are defined for images and sequences, and we will generalize them to multimodal networks that can leverage note features, note attributes.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the approach now for for doing that will really start with the multimodal network, and then this green boxes and the specified nonlinear functions and dropouts is something that will define graph conversions, which I will explain next.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But before that, let me spend one minute on redefining what I mean by multimodal networks, since there are many different notions and terminology for referring to heterogeneous networks.",
                    "label": 0
                },
                {
                    "sent": "Positive clicks, network multilayer networks, and so on.",
                    "label": 0
                },
                {
                    "sent": "So for the purpose of this talk, the idea is that a multimodal network is a network where you have multiple notes of different types and edges of different types.",
                    "label": 0
                },
                {
                    "sent": "So in this example, for here, what we have is green triangles indicate.",
                    "label": 0
                },
                {
                    "sent": "Different drugs apparent drugs are connected based on potential interaction between those two drugs and there the type of interaction is represented by a type of an edge which is indicated here by an R representation.",
                    "label": 0
                },
                {
                    "sent": "So we might have different various kinds of additional feature information for the drugs, which might indicate might, which allows us to integrate.",
                    "label": 0
                },
                {
                    "sent": "For example, chemical structure of trucks in their model.",
                    "label": 0
                },
                {
                    "sent": "Of course, we don't have just one mode, meaning one type of notes we might want to integrate in our model.",
                    "label": 0
                },
                {
                    "sent": "Information on what are the proteins that the drugs are associated with, which would introduce this second mode of information, and then we know how proteins might interact with each other in the body.",
                    "label": 0
                },
                {
                    "sent": "So that would be then.",
                    "label": 0
                },
                {
                    "sent": "That would then be encoded as various kind of interactions between proteins.",
                    "label": 0
                },
                {
                    "sent": "So this example here what it represents, a multimodal network with two modes, in this case drugs and proteins.",
                    "label": 0
                },
                {
                    "sent": "And we have interactions between nodes of within each mode, as well as notes across nodes and edges.",
                    "label": 0
                },
                {
                    "sent": "Here can have different types.",
                    "label": 0
                },
                {
                    "sent": "We might also have multiple types of edges between every pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "So this is the structure that will be working with and in the next few minutes I will describe the methodology that takes this as such networks as input and then learn deep embedding.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I will discuss that applications that are have also been highlighted yesterday.",
                    "label": 0
                },
                {
                    "sent": "The polypharmacy problem and the problem of drug with purpose.",
                    "label": 0
                },
                {
                    "sent": "But before we go discuss this applications in detail let.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Leon provides an overview of the of our approach for deep learning on multimodal networks, so the approach has two key components.",
                    "label": 1
                },
                {
                    "sent": "The first component is the encoder component, which will take the multimodal network.",
                    "label": 1
                },
                {
                    "sent": "It will learn an embedding for every note and in the decoder phrase we will use those learned embeddings to make interesting new predictions and importantly, what this this is, something that we will do in an end to end fashion, meaning that embeddings will be optimized for prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's start with the in code.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Face so remember what we were discussing yesterday?",
                    "label": 0
                },
                {
                    "sent": "The goal here that we want to do in the encoding stage is to learn that mapping function F that will map the nodes in some D dimensional space with the purpose of.",
                    "label": 1
                },
                {
                    "sent": "Server, or in preserving the information on similarity of or the properties of local topology around the note and this very much aligns with many observations that were made in biology during the course of the last two decades where it has been shown repeatedly then that for many biomedical entities, similar interaction patterns indicate that those entities might have that those entities are involved in similar phenotypes.",
                    "label": 0
                },
                {
                    "sent": "Might have similar clinical manifestations, might be involved in similar protein complexes antilla?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how will we learn that mapping functional if our key idea here we will be that we will generate embeddings based on local network neighborhoods and we will take into account what are the types of edges that exist within a neighborhood of every note and the notion that I will be using here is this notion of nodes computation graph.",
                    "label": 1
                },
                {
                    "sent": "So for every note, let's say we are currently looking at Note V in our network, we will determine uh, nodes computation graph.",
                    "label": 0
                },
                {
                    "sent": "An node computer note computation graph might be some local network will be some local network neighborhood of the of that.",
                    "label": 0
                },
                {
                    "sent": "Note in the second phase will we learn what is the best way to transform and propagate information across their computation graph?",
                    "label": 1
                },
                {
                    "sent": "So for example, for this note, we will look at for every type of edges.",
                    "label": 0
                },
                {
                    "sent": "Let's say we are currently looking for edge type R3.",
                    "label": 0
                },
                {
                    "sent": "We will look at what our first order neighbors of.",
                    "label": 0
                },
                {
                    "sent": "Note we in edge type R3 and we have two neighbors, the red ones.",
                    "label": 0
                },
                {
                    "sent": "What their second order neighbors in that edge type.",
                    "label": 0
                },
                {
                    "sent": "And again we have three neighbors and we will learn what is the best, most effective way of propagating transforming information across those.",
                    "label": 0
                },
                {
                    "sent": "Across across edges, taking into account the type of edges that appear in the neighborhood of notary, and this will be dancing with Tanias Lee for all notes in there.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So an example of that is if we use our multimodal network that we have previously defined.",
                    "label": 0
                },
                {
                    "sent": "Let's say we are currently looking now at the drug.",
                    "label": 0
                },
                {
                    "sent": "Note that drug not see what I'm highlighting on the left is the 1st Order Network neighborhood, which would mean that computation graph for notes is defined based on these immediate neighbors of node C. So Notsi has a several neighbors, but their neighbors are of three different types, so it has neighbors of type R2R1 and T. So this means that our computation graph will have three separate processing channels and the one.",
                    "label": 1
                },
                {
                    "sent": "And in each processing channel, let's include cartoon.",
                    "label": 0
                },
                {
                    "sent": "The idea would be to say, well, what are the neighbors of seeing our two?",
                    "label": 0
                },
                {
                    "sent": "So they are not S&D and then SMB will lerwill true, will send their current Victor values messages or embedding central discussing along along edges to see and learn.",
                    "label": 0
                },
                {
                    "sent": "What is the best way to incorporate the propagate?",
                    "label": 0
                },
                {
                    "sent": "This information in the same will be done for the two and.",
                    "label": 0
                },
                {
                    "sent": "Other edge types that appear in the neighborhood to float C4P and RR1 and then this information would integrate to be integrated to get the presentation or embedding or Victor valid message for Nazi at the next layer of our computation.",
                    "label": 0
                },
                {
                    "sent": "Well, so the idea is that, well, this is the computation graph for node C and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Every note will will learn, will have its own computation graph, unique computation graph based on the structure of its local local network neighborhood, the way you can think of this problem is that instead of having one neural network for the entire graph, every, we will have a very large number of small neural network networks.",
                    "label": 1
                },
                {
                    "sent": "In particular, every note will define its own neural network architecture.",
                    "label": 0
                },
                {
                    "sent": "That architecture will depend on the.",
                    "label": 0
                },
                {
                    "sent": "Topology of local network neighborhood.",
                    "label": 0
                },
                {
                    "sent": "In order to effectively train the model, we will share certain parameters weight matrices across those nodes.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to get deep model what what we what we'll be doing is will effectively stack multiple layers to information together.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you would be interested in getting model that we will learn embeddings for, notes embedding for node C based on two layer of transformation, we would first use the the computation graph that we have seen in the previous example.",
                    "label": 0
                },
                {
                    "sent": "And the layer, the first layer that computation graph will start with initial embeddings, which might be 0 hot and one hot encoding characters or feature vectors for for the neighbors of notes.",
                    "label": 0
                },
                {
                    "sent": "And we will we would we would run forward.",
                    "label": 0
                },
                {
                    "sent": "We do that computation graph to generate an embedding for Nazi based on its immediate neighbors, and then in the second layer of transformation, the same idea.",
                    "label": 0
                },
                {
                    "sent": "Exactly same idea would be repeated on the current new version of them, Bendix.",
                    "label": 0
                },
                {
                    "sent": "So effectively, what that would mean is that the model can be of arbitrary depth.",
                    "label": 1
                },
                {
                    "sent": "You can think of notes have embeddings at each layer of transformation at layer zero.",
                    "label": 0
                },
                {
                    "sent": "Embeddings are one hot encoding victors or not initial note features.",
                    "label": 0
                },
                {
                    "sent": "And then at each layer, every note looks at its neighbors and it applies the current value of the current set of parameters that transform the information.",
                    "label": 0
                },
                {
                    "sent": "The information from neighbors to update embeddings for death.",
                    "label": 0
                },
                {
                    "sent": "Note that is done simultaneously for every note in the network, and that defines one layer of transformation in the second layer.",
                    "label": 0
                },
                {
                    "sent": "Then again, every note will again look at his direct neighbors.",
                    "label": 0
                },
                {
                    "sent": "Take their current embeddings in, apply that formula again, but now the current embeddings of neighbors are results of the previous of transformation from the previous layer, so effectively means that if we have a network with key layers, this means that the embeddings that will be generated a generated depend on the structure of K hop neighborhoods around notes, so meaning that for two nodes that we have of two nodes there.",
                    "label": 0
                },
                {
                    "sent": "If their embeddings are similar in a layer with K in a network with K layers, that would mean that their K hop neighborhoods have similar local structure.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that might seem.",
                    "label": 0
                },
                {
                    "sent": "Incidentally, perhaps hard to work hard to ground, but here is actually one slide of equations that implement this idea.",
                    "label": 0
                },
                {
                    "sent": "So the key is the key element.",
                    "label": 1
                },
                {
                    "sent": "Intuitively, is this notion that each nodes computation graph defines its own neural network and the architecture depends on the local topology of that network of that low of that node's neighborhood?",
                    "label": 1
                },
                {
                    "sent": "Once this is done, when we have computation graphs for the notes, we have these three equations that we need to run multiple times depending on the number of hidden layers or the depth of the graph.",
                    "label": 0
                },
                {
                    "sent": "Neural network that we want to have.",
                    "label": 0
                },
                {
                    "sent": "In particular, at layer zero of all transformation, we say, well initial embedding for notary, at Layer Zero is set to initial note.",
                    "label": 0
                },
                {
                    "sent": "Feature vector for note we that we might have.",
                    "label": 1
                },
                {
                    "sent": "So this is opportunity that allow us to integrate site information about nodes in the network.",
                    "label": 0
                },
                {
                    "sent": "So if, for example if we would be a drug note, then exactly might be might be chemical structure of drug, some form of fingerprint that were that were mentioned yesterday several times.",
                    "label": 0
                },
                {
                    "sent": "If we would be an image then we might have an embedding could that would come for us a result of convolutional neural.",
                    "label": 0
                },
                {
                    "sent": "If there are no note, features are.",
                    "label": 0
                },
                {
                    "sent": "If no note features are available, then the these initials embeddings are one hot encoding.",
                    "label": 0
                },
                {
                    "sent": "So after that then we apply the following formula that in this formula wanted us.",
                    "label": 0
                },
                {
                    "sent": "It takes embeddings from the previous layer and it transforms them to get an impending for notary at layer cake.",
                    "label": 0
                },
                {
                    "sent": "So how does how how this is done exactly so it's done the following for a particular for any notes.",
                    "label": 0
                },
                {
                    "sent": "So note we we go to all different edge types that exist and we look at what are the neighbors of node V according to that edge type.",
                    "label": 1
                },
                {
                    "sent": "So let's say that this is not you and with this taking that information, we then take embeddings for no for for the neighbors in that edge type, we aggregate them according to AW matrix which is indexed by ARM, which means that we have a separate weight matrix for every type of edges.",
                    "label": 0
                },
                {
                    "sent": "And then we combine that with the embedding of node V from the previous layer.",
                    "label": 0
                },
                {
                    "sent": "Enterprise these two along linear functions to login activation function.",
                    "label": 0
                },
                {
                    "sent": "What might be important here is that this constant or this December CR normalization constants initially what it was popular, was to use constants that were the verse degrees of the nodes now, so they were fixed values and not optimize during training.",
                    "label": 0
                },
                {
                    "sent": "Nowadays there's or meaning in the last year or so there's been a huge interest in attention mechanisms.",
                    "label": 0
                },
                {
                    "sent": "So which implement the idea that different neighbors have different importances for learning the.",
                    "label": 1
                },
                {
                    "sent": "Adult bedding of the note and attention weights can automatically capture that importance.",
                    "label": 0
                },
                {
                    "sent": "So then this equation is applied to multiple multiple times depending on the depth of our neural network.",
                    "label": 0
                },
                {
                    "sent": "And finally after K layers of neighborhood degradation we get and the final embedding for nodes.",
                    "label": 0
                },
                {
                    "sent": "So the final in values of before.",
                    "label": 0
                },
                {
                    "sent": "Note we is the output of.",
                    "label": 0
                },
                {
                    "sent": "Of these computation, after clear layers of transformation.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's the encoder stage of our model.",
                    "label": 1
                },
                {
                    "sent": "Assuming we have we have, we are able we estimated the values for our parameters, which were the parameter weight matrices.",
                    "label": 0
                },
                {
                    "sent": "A separate matrix for every type of edges we can generate embeddings by simply applying those equations that I have shown in the previous slide, and that will give us an embedding for every note in the network, and it's possible to do that because parameters those parameters weight matrices W are shared across.",
                    "label": 0
                },
                {
                    "sent": "Notes if you'll notice parameter matrix W's were not indexed by note but they were indexed by edge type, meaning that all nodes have the same.",
                    "label": 0
                },
                {
                    "sent": "All notes in the network learn what is the most effective way of transforming and propagating information along edges in a similar way or in the same way, depending on an edge down.",
                    "label": 0
                },
                {
                    "sent": "OK, once we have embeddings now in the decoder phase will use the learned embeddings to make predictions.",
                    "label": 1
                },
                {
                    "sent": "Different kinds of predictions would would require different kinds of decoders, but for the purpose of this talk, the one that we are really interested in would be the decoder that will be take that will take as input a pair of embeddings of also embeddings for two nodes, and it will predict the probability of a specific type of relationship existing between those two nodes.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is something known as his true genius edge decoder.",
                    "label": 0
                },
                {
                    "sent": "So why it's edge decoder?",
                    "label": 0
                },
                {
                    "sent": "Because what will be decoding is our edges will be predicting edges, and it's heterogeneous because we we were not just predicting the existence of any kind of Association between a pair of notes, but we want to be more precise and predict what kind of Association.",
                    "label": 0
                },
                {
                    "sent": "What kind of relationship might exist between two nodes.",
                    "label": 0
                },
                {
                    "sent": "So the way the decoder works is it takes at its input a pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "Say we have.",
                    "label": 0
                },
                {
                    "sent": "We are currently looking at notes C&C&S and their embeddings.",
                    "label": 0
                },
                {
                    "sent": "These obscene these S which we got from the encoder stage of the model.",
                    "label": 0
                },
                {
                    "sent": "So the decoder, what it will do, it will.",
                    "label": 0
                },
                {
                    "sent": "Take those two embeddings and it will combine them in such a way that the combined value will indicate what is the probability route would represent.",
                    "label": 0
                },
                {
                    "sent": "What is the probability of an edge of a particular type?",
                    "label": 1
                },
                {
                    "sent": "Say are one existing between a pair of nodes and this will be done such that the model will be able to predict any kind of edge and the probability of any kind of any kind of edge existing between a pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "Now what kind of model this actually is?",
                    "label": 0
                },
                {
                    "sent": "It turns out that this heterogeneous edge decoder that I'm describing here is actually a teams or factorized model.",
                    "label": 1
                },
                {
                    "sent": "So what you what you can think of having here is for for a pair of nodes we have one parameter matrix R that.",
                    "label": 0
                },
                {
                    "sent": "Is shared across all different types of edges, and then for every type of for every edge I can have a separate parameter matrix D sub R1 for each type.",
                    "label": 0
                },
                {
                    "sent": "One that tell us what is the importance of specific hidden dimensions for each type R1 so we know that embeddings have the dimensions and the matrices D will will tell us how important.",
                    "label": 0
                },
                {
                    "sent": "Is a particular dimension towards predicting a particular edge type.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that that is actually a form of a factorization model, where we have one core matrix R that is shared across all modes.",
                    "label": 0
                },
                {
                    "sent": "In this case, all edge types and for every edge type we have a separate the matrix, which is actually a diagonal matrix with non zero values only along the diagonal.",
                    "label": 0
                },
                {
                    "sent": "OK, so why mentioning that is that is because depending on your concrete application there is lots of freedom and flexibility that you get here because we you could.",
                    "label": 0
                },
                {
                    "sent": "If you think there is a particular type of decoder that might work well for your application, you might use that really well and you might use my.",
                    "label": 0
                },
                {
                    "sent": "You might plug it.",
                    "label": 0
                },
                {
                    "sent": "You must plug it in here and use it for for your model in particular, the kind of embedding methods that we discussed yesterday are.",
                    "label": 0
                },
                {
                    "sent": "Those are for example methods.",
                    "label": 0
                },
                {
                    "sent": "That could be used in this phase in this phase.",
                    "label": 0
                },
                {
                    "sent": "In this stage of model here.",
                    "label": 0
                },
                {
                    "sent": "So the reason why we're using things or factors model here will be is really the motivation for using it.",
                    "label": 0
                },
                {
                    "sent": "Is the fact that we want to capture protect potential correlations between edge types as it will turn out later in some of the applications different kinds of edges will indicate different kinds of side effects, and we would want we we are we will want to capture dependencies and similarities between side effects.",
                    "label": 0
                },
                {
                    "sent": "That's why we need to have some form of coupling between different edge types in our model.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is defines the decoder which is which was the 2nd component of our model that used the learned embeddings to predict labeled edges between nodes.",
                    "label": 1
                },
                {
                    "sent": "So to actually train this model what we do is we fit embeddings into any loss function that you would love, that you would like to optimize.",
                    "label": 0
                },
                {
                    "sent": "Perhaps most commonly that that is cross entropy, but might might be a different kind of loss function, for example based on Max margin.",
                    "label": 1
                },
                {
                    "sent": "And then we used to cast a gradient descent to train embeddings and to estimate to upper parameters of the model in an end to end fashion in those parameters are the W matrices that that were part of the encoder and the R&D matrices that were part of the decoder stage.",
                    "label": 0
                },
                {
                    "sent": "So we can use different kinds of losses, and the important is really that we can directly train the model because it's the entire model is different.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to recap, the model that I just described and put it into a more broader context of this.",
                    "label": 0
                },
                {
                    "sent": "Of Of of literature is the model data described?",
                    "label": 0
                },
                {
                    "sent": "Is a particular instance of graph, neural or graph convolutional models.",
                    "label": 1
                },
                {
                    "sent": "They wanted that I highlighted here is the one that is designed for multimodal networks that have reached note features and potentially add edge edge attributes.",
                    "label": 0
                },
                {
                    "sent": "It has the power to generate very potential goal, often very useful deep embeddings.",
                    "label": 0
                },
                {
                    "sent": "Unlike some of the shallow network embedding methods and it often leads to more accurate predictions than what we then predictions that we get by using shallow embeddings.",
                    "label": 0
                },
                {
                    "sent": "Importantly, what is interesting here is that we can define new kinds of prediction problems on networks and partially many of those prediction problems are then very useful for problems in chemistry.",
                    "label": 0
                },
                {
                    "sent": "For example, doing net graph level classification or modeling the data that might be temporal or dynamic in in many ways.",
                    "label": 0
                },
                {
                    "sent": "So what this means that the application at the high level is that we can now apply deep learning models much more broadly, not only to images and sequence data, we can apply them to any graph or any particular multimodal graph, multimodal network that we have.",
                    "label": 1
                },
                {
                    "sent": "And this really creates lots of lots of opportunities for new kinds of applications in biology and medicine.",
                    "label": 0
                },
                {
                    "sent": "So next yes, yes, of course.",
                    "label": 0
                },
                {
                    "sent": "Clean this in relational terms because what?",
                    "label": 0
                },
                {
                    "sent": "To me is that you actually do aggregation.",
                    "label": 0
                },
                {
                    "sent": "So if you use a particular type of.",
                    "label": 0
                },
                {
                    "sent": "And you go separator between the different types of relations, yes, so let's take the notes on which involves yes.",
                    "label": 0
                },
                {
                    "sent": "Then you find all other nodes which are related by articular relations with yes and then you aggregate their features for us.",
                    "label": 0
                },
                {
                    "sent": "Yes, so I mean this is an OK neural networks are all the hype.",
                    "label": 0
                },
                {
                    "sent": "And yes, it's great to use this technology.",
                    "label": 0
                },
                {
                    "sent": "But you understand this, Does this translate database terms?",
                    "label": 0
                },
                {
                    "sent": "Because in database terms you also have aggregation operations and you know you can say OK, fine, we all of the top ones which are related to this one another again.",
                    "label": 0
                },
                {
                    "sent": "Yes, so that's that's great question.",
                    "label": 0
                },
                {
                    "sent": "So, so here is actually there's a read value for the tries to put graph neural networks in the context of some of the related concepts, and those concepts come one set.",
                    "label": 0
                },
                {
                    "sent": "One class of concepts comes from databases.",
                    "label": 0
                },
                {
                    "sent": "More broadly on class of concepts comes from label propagation, so you probably have noted that the terminology that I've been using was our central.",
                    "label": 0
                },
                {
                    "sent": "We propagate that information along edges and there is.",
                    "label": 0
                },
                {
                    "sent": "Our label propagation algorithms that have been developed around 2000 or earlier that had this idea of propagating information along edges of the graph in order to make useful predictions.",
                    "label": 0
                },
                {
                    "sent": "So let's let's focus on these two.",
                    "label": 0
                },
                {
                    "sent": "So first, in the context of aggregating features.",
                    "label": 0
                },
                {
                    "sent": "So here it's really only the zero or only the first layer of graph.",
                    "label": 0
                },
                {
                    "sent": "Neural network is the one that aggregates note features.",
                    "label": 0
                },
                {
                    "sent": "If those features are available so that the key idea is that in the first layer.",
                    "label": 0
                },
                {
                    "sent": "We will note we look at its neighbors in a particular edge type.",
                    "label": 0
                },
                {
                    "sent": "It will aggregate their note features in that knowledge and pass it on a linear function.",
                    "label": 0
                },
                {
                    "sent": "Those not features are now so so, so.",
                    "label": 0
                },
                {
                    "sent": "The result of this operation defines an embedding for the target node, which is the embedding after the first layer of transformation.",
                    "label": 0
                },
                {
                    "sent": "And this is done for all of the neighbors also right?",
                    "label": 0
                },
                {
                    "sent": "So all of the neighbors of the of the current target node also get their own embeddings.",
                    "label": 0
                },
                {
                    "sent": "After this first layer transformation in the second half transformation, we apply the same function, but that function is now update.",
                    "label": 0
                },
                {
                    "sent": "Functional does not aggregate feature vectors, but that it aggregates embeddings from the first layer.",
                    "label": 0
                },
                {
                    "sent": "So this is the idea of convolution.",
                    "label": 0
                },
                {
                    "sent": "So these are this.",
                    "label": 0
                },
                {
                    "sent": "This these are graph conversions.",
                    "label": 0
                },
                {
                    "sent": "So what is the knology with standard conversions that we have in images?",
                    "label": 0
                },
                {
                    "sent": "So if you if you think of commercial neural networks they define convolutions.",
                    "label": 0
                },
                {
                    "sent": "Think of if we have an image.",
                    "label": 0
                },
                {
                    "sent": "Typically convolutions are small filters, three by three, 5 by 5.",
                    "label": 0
                },
                {
                    "sent": "In the simplest case, and the idea is that we we go through every pixel offer image.",
                    "label": 0
                },
                {
                    "sent": "For a given pixel, we apply that filter.",
                    "label": 0
                },
                {
                    "sent": "How does how do we apply that?",
                    "label": 0
                },
                {
                    "sent": "We look at?",
                    "label": 0
                },
                {
                    "sent": "We apply that we put the three by three or five by five mask.",
                    "label": 0
                },
                {
                    "sent": "On top of that pixel, we look at what are the neighboring pixels.",
                    "label": 0
                },
                {
                    "sent": "We average them.",
                    "label": 0
                },
                {
                    "sent": "We take maximum of that pixel and that declares transformed value of for that central pixel.",
                    "label": 0
                },
                {
                    "sent": "So the analogy here is that, well, in the context of graphs, we cannot have this fixed three by three or five by five pixels, because.",
                    "label": 0
                },
                {
                    "sent": "Every node can have a different number of neighbors an every note and there is no ordering to the neighbors of a note, which is what exists in image.",
                    "label": 0
                },
                {
                    "sent": "So what graph conversions do instead is well, because there is no ordering of the notes, they need to think about what are the aggregate are functions that are invariant to the note ordering.",
                    "label": 0
                },
                {
                    "sent": "So in that is then many inspirations.",
                    "label": 0
                },
                {
                    "sent": "Here we come from the field of.",
                    "label": 0
                },
                {
                    "sent": "Label propagation the filtered database systems where the idea is well where this kind of aggregate or operators have been studied in the past.",
                    "label": 0
                },
                {
                    "sent": "The simplest case and the model that that I described is really a simple variant of the of the raffle network for multimodal networks, which can be explained quite easily.",
                    "label": 0
                },
                {
                    "sent": "The idea is that we will simply look at the neighbors and we will average them and the averaging the weights that average can be.",
                    "label": 0
                },
                {
                    "sent": "Weighted or unweighted, depending on the set of weights that were indicated in the formulas with C values.",
                    "label": 0
                },
                {
                    "sent": "Instead of aggregating them, there are different kinds of correlation function that one might use.",
                    "label": 0
                },
                {
                    "sent": "One more popular nowadays are is Max pooling, for example.",
                    "label": 0
                },
                {
                    "sent": "But that is really the idea of graph conversions.",
                    "label": 0
                },
                {
                    "sent": "Interesting, no, that's great question.",
                    "label": 0
                },
                {
                    "sent": "Interesting connections here really also come from the field of label propagation, where you can think of this kind of models as models that.",
                    "label": 0
                },
                {
                    "sent": "Propagate information along edges and the context of label propagation algorithms.",
                    "label": 0
                },
                {
                    "sent": "The information that was propagated that is typically propagated along edges are labels of nodes, but what we are propagating here are victors.",
                    "label": 0
                },
                {
                    "sent": "So you can think of these models as models that propagate Victor value to messages.",
                    "label": 0
                },
                {
                    "sent": "That's often the term that is used in literature.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll briefly return to that at the end of the talk.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So perhaps it will be become become more clear where, where all these concepts will be very practically used for the problem of that I'll be discussing next, and that is the problem of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pharmacy.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I mentioned to you pharmacy several times today and yesterday and this is really the term debt that refers to the situation when patients take multiple drugs at the same time to treat complex or coexisting disease and the statistics for the US is Sergeant at around 46% of people of age 65 or more take more than five drugs at the same time, and it's not uncommon to encounter patients that can take up to 20 drugs at the same time to treat complex diseases.",
                    "label": 1
                },
                {
                    "sent": "Such as depression, heart disease or cancer.",
                    "label": 0
                },
                {
                    "sent": "The problem, however, we taking too many drugs at the same time, is that patients are at a much higher risk of adverse events and unwanted side effects.",
                    "label": 1
                },
                {
                    "sent": "In particular, the estimate is that 50 percent, 15% of the US population is affected by such unwanted side effects and this represents a burden not only for the individual patient but also for the entire healthcare system.",
                    "label": 0
                },
                {
                    "sent": "Because now new car, because of the need to treat those unwanted side effects.",
                    "label": 0
                },
                {
                    "sent": "So why do we see real side effects?",
                    "label": 0
                },
                {
                    "sent": "And why are those?",
                    "label": 0
                },
                {
                    "sent": "Side effects even more dangerous in the context of combinations of drugs that patients are taking.",
                    "label": 0
                },
                {
                    "sent": "The reason is really that those side effects appear because of unexpected interactions between drugs, which is something that is not really tested during the during clinical trials.",
                    "label": 0
                },
                {
                    "sent": "So the kind of data that we are looking here.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "Our reports on unwanted side effects side effects.",
                    "label": 1
                },
                {
                    "sent": "In particular, we teamed up with FDA and we are currently looking at international adverse Event Reporting system there and intuitively.",
                    "label": 1
                },
                {
                    "sent": "You can think of the adverse event reporting system as as a large database that contains the following information.",
                    "label": 0
                },
                {
                    "sent": "So it's a database that is maintained by the National Registry.",
                    "label": 0
                },
                {
                    "sent": "It's constructed based on reports.",
                    "label": 0
                },
                {
                    "sent": "Our debt our patients provide to physicians and physicians, then encoding the database and contains the following information.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "Is the drop that that patient states in its deficiencies in Red Rock and for patients that they quit drugs.",
                    "label": 0
                },
                {
                    "sent": "These are the kind of side effects of patients are experiencing meaning and his numbers here with indicated for example around 3% of patients on their drug, might experience about equivalence in the reason.",
                    "label": 0
                },
                {
                    "sent": "So these are just these are made up side effects.",
                    "label": 0
                },
                {
                    "sent": "I can explain it into this.",
                    "label": 0
                },
                {
                    "sent": "Similarly, a patient that they clean drug might experience different kinds of side effects or orange rug might express completely different set of side effects.",
                    "label": 0
                },
                {
                    "sent": "Also, there is information on what happens to patients that are, but they're taking orange and green drug at the same time, or red and green.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some of the interesting patterns that we can see, here are the following.",
                    "label": 0
                },
                {
                    "sent": "So for patients that take red and green drop at the same time, what would you expect?",
                    "label": 0
                },
                {
                    "sent": "What kind of side effects would you expect those patients to have?",
                    "label": 0
                },
                {
                    "sent": "Well, if there would be, there would know there would not be any interaction between red and green drug.",
                    "label": 0
                },
                {
                    "sent": "We would expect that patients that take these drugs together experience side effects that are due to Red Rock Plus side.",
                    "label": 0
                },
                {
                    "sent": "Things that are due to gridlock, sort of.",
                    "label": 0
                },
                {
                    "sent": "That might be a form of the Union of the side effects that are that are due to each track individually.",
                    "label": 0
                },
                {
                    "sent": "What is interesting here is that while there is indeed the case for the pair of red and green Rock, but if you look at orange and green drop and then we see that all of a sudden patients that take these two drugs also experienced side effects colon cancer and predict that there really side effects that we would not expect.",
                    "label": 0
                },
                {
                    "sent": "If we look at the side effects that are associated only with red or green or only with orange truck.",
                    "label": 0
                },
                {
                    "sent": "So these are the used to that these are two new side effects that we cannot really.",
                    "label": 0
                },
                {
                    "sent": "We would we are not expected.",
                    "label": 0
                },
                {
                    "sent": "We are not expecting we were not expecting them to see and this is due to unexpected drug drug interactions.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So more concretely, what we mean by unexpected drug docking direction is the following situation.",
                    "label": 0
                },
                {
                    "sent": "Imagine we have a system which do different with two different drugs, and when the patients are prescribed these and then when the patients take this blue pill, they do not experience any side effect.",
                    "label": 0
                },
                {
                    "sent": "When patient take red pill alone, no side effects.",
                    "label": 0
                },
                {
                    "sent": "But then when patients take red and blue pill together then they have side effects and this is something really dealt.",
                    "label": 0
                },
                {
                    "sent": "We want to model.",
                    "label": 0
                },
                {
                    "sent": "And capture computationally.",
                    "label": 0
                },
                {
                    "sent": "So the question in the test that we will be solving here is the following for a particular combination of drugs we want to have a model that will predict how likely it is that a particular combination of drug will lead to a particular type of side effect and the kind of side affected side effects that we're interested interested in predicting are those side effects that are unexpected that are due to drug drug interactions.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So modeling polypharmacy is hard problem for a number of reasons.",
                    "label": 1
                },
                {
                    "sent": "Of the first is certainly the computer to combinatorial explosion of possible combinations of drugs very quickly.",
                    "label": 1
                },
                {
                    "sent": "If you would look or we we get a lot of so many combinations that that we need to be very careful an when if you want to study them systematically.",
                    "label": 0
                },
                {
                    "sent": "For the case of US, we there are 30 million possible combinations involving a pair of drugs.",
                    "label": 0
                },
                {
                    "sent": "And more than 20 billion possible combinations of involving three drugs.",
                    "label": 1
                },
                {
                    "sent": "But I mentioned before that there are many patients on five drugs, or even that, or even take 20 drugs.",
                    "label": 0
                },
                {
                    "sent": "So the second problem is that the kind of.",
                    "label": 0
                },
                {
                    "sent": "Outputs that we want to get our exactly those outputs that are due to unexpected nonlinear nonadditive effects.",
                    "label": 1
                },
                {
                    "sent": "So really what we want to predict are side effects that are due to drug drug interactions and by definitions.",
                    "label": 0
                },
                {
                    "sent": "Those are these unexpected events where the union of side effects or some additive model of side effects of individual drugs is different from what we actually see in in real patient.",
                    "label": 0
                },
                {
                    "sent": "And Thirdly, you might think that of that as a big data problem, because what the data that will be working with is really the data that covers all patients in the US and that seems to be a big data problem.",
                    "label": 0
                },
                {
                    "sent": "However, very quickly when we drill down to any particular combination of drugs, there's only a small set of patients on that combination of drugs and even fewer number of those patients then experienced side effect.",
                    "label": 0
                },
                {
                    "sent": "So even though we have altogether large population of drugs.",
                    "label": 0
                },
                {
                    "sent": "Then we really quickly get this small subset of patients that we can use for making a particular prediction.",
                    "label": 0
                },
                {
                    "sent": "What we will be leveraging here is the fact that those side effects that we are capturing are not really independent of each other because the assumption is that side effects that affect for example similar organ systems might have some common biological underpinnings, and that's something that we will leverage.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first, the first problem that we need to solve here is really need to be able to construct and a polypharmacy data set to tackle to tackle the problem of predicting side effects of drug combinations.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the objective here for us was to capture Molecular Dragon patient data for all drugs prescribed in the US.",
                    "label": 1
                },
                {
                    "sent": "So for that we be spent significant amount of time building a unique data set that contains information on.",
                    "label": 0
                },
                {
                    "sent": "Currently available information on side effects associated with drug combinations from the FDA.",
                    "label": 0
                },
                {
                    "sent": "Information on what?",
                    "label": 0
                },
                {
                    "sent": "How do drugs so affect human body in the form of drug target information, and how do those and how do they target proteins?",
                    "label": 0
                },
                {
                    "sent": "Interact with each other.",
                    "label": 0
                },
                {
                    "sent": "Additionally, we have various kinds of site information or extra information describing drugs.",
                    "label": 0
                },
                {
                    "sent": "Chemical structure describing membership of proteins in pathways which is encoded in the model by.",
                    "label": 0
                },
                {
                    "sent": "To note feature vectors.",
                    "label": 0
                },
                {
                    "sent": "So this gives us actually a multimodal letter that we have seen earlier today in the lecture where what we have are two 2 modes.",
                    "label": 0
                },
                {
                    "sent": "We have these green triangles that represent notes.",
                    "label": 0
                },
                {
                    "sent": "The fact that there is an edge between a pair of nodes.",
                    "label": 0
                },
                {
                    "sent": "C&S type R2 means that when patients take CNS together, they are likely to experience side effects are two which might be pretty cardio side effect and that side effect is not cannot be.",
                    "label": 0
                },
                {
                    "sent": "Attributed to either C alone or either S alone.",
                    "label": 0
                },
                {
                    "sent": "So the edges, the temple that here also have weights because not all patients will experience the side effects.",
                    "label": 0
                },
                {
                    "sent": "So their way to Tejas and their typed edges.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, when CNS are taken together that might lead not only to bradycardia side effect but also different kinds of side effects.",
                    "label": 0
                },
                {
                    "sent": "Becomes quite complicated because now a relationship between CNS vis that there might be multiple edges between CSF, CNS, each edge of a different type and there is a weight associated with average.",
                    "label": 0
                },
                {
                    "sent": "And then here we have information on what are the proteins associated with C and how do those proteins interact with each other.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The nature of that we get is a highly multimodal network because it has around 1000 different types of edges.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we will do next is will apply the model that I have described before to this multimodal network, with the goal of predicting side effects for drug bears, particular the kind of query that we want to our model to be able to answer is the following.",
                    "label": 0
                },
                {
                    "sent": "Here's an example, so we might want to ask how likely it is that when two drugs form of stating and ciprofloxacin when they are taken together, how likely it is that they will lead to breakdown of muscle tissue.",
                    "label": 1
                },
                {
                    "sent": "If domain expertise interesting in this question, this means that what we are really asking of our model is we are asking the model to say how likely it is that that on edge of type of breakdown of muscle tissue exists in our network between and.",
                    "label": 0
                },
                {
                    "sent": "In particular, this edge exists between nodes C&NS.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly the link prediction problem where we are aiming to predict label link labeled links between.",
                    "label": 0
                },
                {
                    "sent": "Pairs of notes, which means that we can exactly use the encoder and decoder that I have described earlier.",
                    "label": 0
                },
                {
                    "sent": "And really, the idea is here is that we take the data from patient reportes molecular information.",
                    "label": 0
                },
                {
                    "sent": "We construct this large knowledge graphs which are partially observed graph that represents currently available information about biology and how drugs works and what are the side effects that human patient population experience.",
                    "label": 0
                },
                {
                    "sent": "And that's a partially observed graph that we will that we leverage in order to make new discoveries.",
                    "label": 0
                },
                {
                    "sent": "In this case, new predictions about side effects.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first thing that we did when we trained our model is to evaluate it empirically using cross validation.",
                    "label": 0
                },
                {
                    "sent": "So here we what I'm showing is in the red bars is the performance of the model based on different beddings and the three other bars indicate various simplify simplifications of the model.",
                    "label": 0
                },
                {
                    "sent": "What is important here to say is that we wanted to understand how important are different components.",
                    "label": 0
                },
                {
                    "sent": "Of the deep model towards accurate prediction and what we see is the following.",
                    "label": 0
                },
                {
                    "sent": "So first the deep net or the graph neural network model performs better than shallow network embeddings.",
                    "label": 0
                },
                {
                    "sent": "Those are embeddings that we have seen yesterday and there are in the reason why this model now today works better is because we can optimize it in an end to end fashion rather than to have two or multiple independent stages where we would first learned embeddings and then.",
                    "label": 0
                },
                {
                    "sent": "Taken beddings as input to train a downstream classifier.",
                    "label": 0
                },
                {
                    "sent": "Second, we wanted to say well, is it really useful to have these deep encoder model that learns embeddings based on multiple layers of transformation?",
                    "label": 0
                },
                {
                    "sent": "What would happen if you would simply represent our data so large things or and then run tensor factorization?",
                    "label": 0
                },
                {
                    "sent": "So in in here provided to Shoney's, the comparison between two very well known teams or factorization model by maximum comfort and others at the disco, Driscoll.",
                    "label": 0
                },
                {
                    "sent": "And finally there are some other shallow network companion methods in the form of multi relational factorization that we are also comparing here.",
                    "label": 0
                },
                {
                    "sent": "And these are the reasons that the the the numbers here measure the AUC under.",
                    "label": 0
                },
                {
                    "sent": "Receiver operating curve and average precision at top 50.",
                    "label": 0
                },
                {
                    "sent": "Beyond that, wanted to understand what is actually the utility?",
                    "label": 0
                },
                {
                    "sent": "What is the potential or utility of this new prediction?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the next experiment we did was the perspective or actually time based experiment where the idea was to train the following.",
                    "label": 0
                },
                {
                    "sent": "We trained the model on all data generated prior to 2012.",
                    "label": 1
                },
                {
                    "sent": "And then as the model to make predictions and test well how many of those predictions that the models most confident about were confirmed after 2012.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing here on this table are 10 predictions that the model was most confident about what predictions as you would expect come in the form of a pair of drugs and a side effect that is most likely to be associated with that pair of drugs.",
                    "label": 0
                },
                {
                    "sent": "So for five out of this 10 most predictions that the model most most confident about there is direct evidence in the literature.",
                    "label": 0
                },
                {
                    "sent": "After 2012, that is that reports.",
                    "label": 0
                },
                {
                    "sent": "Patients that are on specific combination of drugs and experienced side effects that are due to this truck drug interactions.",
                    "label": 0
                },
                {
                    "sent": "Which is already very exciting and then we ask, well, what about this white space here?",
                    "label": 0
                },
                {
                    "sent": "Does this white space might represent actually representing you predictions?",
                    "label": 0
                },
                {
                    "sent": "Or it might just represent a mistakes made by the model?",
                    "label": 0
                },
                {
                    "sent": "So to make one step further and go beyond cross validation and beyond this time based.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sleep we we.",
                    "label": 0
                },
                {
                    "sent": "We teamed up with.",
                    "label": 0
                },
                {
                    "sent": "It matters to general in Boston and Stanford Medicine and we are currently validating some of the predictions made by the model in the actual clinic using various kinds of drug tracking, direction markers, lab values and surrogates, and what is even more exciting is that this population level approach that I that I have described so far that does not include any information that is personalized to particular patient.",
                    "label": 0
                },
                {
                    "sent": "It can actually be extended in such a way that we can make personalized predictions and then we can inform design of new combinatorial drug therapies.",
                    "label": 1
                },
                {
                    "sent": "But to make this part a bit more tangible, let me just let me show you how we can actually evaluate or or or prediction using data from the clinic in real patients.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key idea here is that we use the principles of causal analysis, or really propensity score matching.",
                    "label": 1
                },
                {
                    "sent": "So imagine our model makes the prediction, which says that the model predicts that when a patient will take the group, this green and orange duck together, they will experience nausea side effect.",
                    "label": 0
                },
                {
                    "sent": "Let's say the model makes this prediction and now we want to validate if that prediction is sexually is actually true.",
                    "label": 0
                },
                {
                    "sent": "So how we will do that?",
                    "label": 0
                },
                {
                    "sent": "So we do that in the following manner.",
                    "label": 0
                },
                {
                    "sent": "So we what we look for.",
                    "label": 0
                },
                {
                    "sent": "We go through our database of patients and we look for large number of triplets of patients.",
                    "label": 0
                },
                {
                    "sent": "Each triplet should have the following form.",
                    "label": 0
                },
                {
                    "sent": "So we have three patients.",
                    "label": 0
                },
                {
                    "sent": "We know that for patient number one that patient was at some time that he was prescribed the green drop and sometime later everything was fine.",
                    "label": 0
                },
                {
                    "sent": "No no anti nausea medication.",
                    "label": 0
                },
                {
                    "sent": "No reports about nausea.",
                    "label": 0
                },
                {
                    "sent": "The second patient was prescribed orange drug alone and again everything was fine.",
                    "label": 0
                },
                {
                    "sent": "No reports of nausea.",
                    "label": 0
                },
                {
                    "sent": "For the third patient, we see that patient had was taking red and or sorry or green and orange drugs, and will tanias Lee.",
                    "label": 0
                },
                {
                    "sent": "And sometime later we see that the patient re was put on anti nausea medication.",
                    "label": 1
                },
                {
                    "sent": "So why was patient re put on anti nausea medication so patiently could be put on anti nausea medication because?",
                    "label": 0
                },
                {
                    "sent": "He developed some start disease independently of this of that combination of drugs that patients was on or the patient was taking these two drugs together.",
                    "label": 1
                },
                {
                    "sent": "As a result, he experienced side effects nausea and we had to treat the physician had to treat nausea.",
                    "label": 0
                },
                {
                    "sent": "So the physician patient re on anti nausea medication.",
                    "label": 0
                },
                {
                    "sent": "So if we are able to find 1 three plus of patients with these kind, this provides very weak evidence.",
                    "label": 0
                },
                {
                    "sent": "That prediction made by the model is actually true.",
                    "label": 0
                },
                {
                    "sent": "So then what we need to do is we need to find lots of triplets of patients of this kind.",
                    "label": 0
                },
                {
                    "sent": "The more triple the larger number of triplets of patients that we find, the more likely are the prediction really represents a viable interesting prediction for further research.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You might wonder that that might be quite challenging to find large number of triplets of patients of discounting.",
                    "label": 0
                },
                {
                    "sent": "Indeed it is.",
                    "label": 0
                },
                {
                    "sent": "So what is really important here is to have access to large database of patients were there in particular health care systems where there are thousands or hundreds of thousands of patients.",
                    "label": 0
                },
                {
                    "sent": "That that we can then mine to find support for.",
                    "label": 0
                },
                {
                    "sent": "Of support for predictions.",
                    "label": 0
                },
                {
                    "sent": "In another comment here is then this example that I provided here really focused only by looking at what are the drugs that what are the patient was put on some time after the drugs that were involved in prediction there.",
                    "label": 0
                },
                {
                    "sent": "And this is actually the surrogate measure here that was used to evaluate predictions.",
                    "label": 1
                },
                {
                    "sent": "There are various kinds of other surrogate measures including clap values, some genomic biomarkers, biomarkers that we are using to validate predictions in the clinic, but I think.",
                    "label": 0
                },
                {
                    "sent": "What is really exciting here is because the idea here is to make this large jumps by building bridges from molecular level information on on how drugs affect or how drugs target proteins, help proteins interact with each other, which is part of the data used to train the model and go all the way up to real patients in the data that is reported in the clinic, which I think is really exciting because it's it kind of tries.",
                    "label": 0
                },
                {
                    "sent": "To bring bring together some of the data that is generated by basic.",
                    "label": 0
                },
                {
                    "sent": "Experiments with really translational data sets that come with its own set of challenges and statistical problems.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this concludes the polypharmacy example and then the next application that I will discuss is that of drug repurposing.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there's been already lots of discussion in the last few days about drug discovery and rocket purpose, and also repurposing costs.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of several times so introduction introduction here can be really very short in our case.",
                    "label": 0
                },
                {
                    "sent": "From the computational point of view, our goal will be to to think about what are effective ways that allow us to map this large space of molecules.",
                    "label": 0
                },
                {
                    "sent": "Only a small number of which are actual drugs to very large space of phenotypes and diseases, with the goal of finding which diseases a new drug or molecule could treat.",
                    "label": 1
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In particular, in the context of drug repurposing, this means that the goal is to.",
                    "label": 0
                },
                {
                    "sent": "Take an existing drug on the market and repurpose it for an you disease.",
                    "label": 0
                },
                {
                    "sent": "That is something we might want because it really is much, much faster and much, much cheaper than if.",
                    "label": 0
                },
                {
                    "sent": "A new drug would need to be designed completely from scratch, so there's lots of interest into finding these new tricks for alter existing drugs.",
                    "label": 0
                },
                {
                    "sent": "The challenge, however, is that it's very hard to do that in a systematic manner, and most of the drugs that were re purposed in the last decades were due to various accidental findings.",
                    "label": 0
                },
                {
                    "sent": "So we will do.",
                    "label": 0
                },
                {
                    "sent": "We will approach this problem here computationally.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The key inside that we that we have here is that we will now move beyond looking at individual edges or pair of nodes, and we will operate on the level of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "In particular, our setting will be the following, so we have the underlying graph of proteins in human body, so these are these a wide circles where edges indicate physical interactions.",
                    "label": 0
                },
                {
                    "sent": "As we have seen several times during this two lectures and we will overlay this network with a large number of subgraphs, in particular for every disease that we have in our system will represent disease by all my subgraph of protein interaction network, which is defined.",
                    "label": 0
                },
                {
                    "sent": "On disease associated proteins.",
                    "label": 0
                },
                {
                    "sent": "And for every drug will represented by a subgraph of protein networks, protein network defined on drugs target proteins.",
                    "label": 1
                },
                {
                    "sent": "Here also included various information on off targets or off target proteins.",
                    "label": 0
                },
                {
                    "sent": "And others.",
                    "label": 0
                },
                {
                    "sent": "So what why do we want to do that?",
                    "label": 0
                },
                {
                    "sent": "We want to do that because of some of the known conceptual explanation why I dropped my slightly to treat the disease that says that a drug is likely to treat the disease if it is close to the disease in pharmacological space.",
                    "label": 1
                },
                {
                    "sent": "So then this is very hard to define or computationally operationalized, But what we will do here or trick will be to use the power of embeddings to operationalize this concept so that what we will do is we will measure closeness of a drug of a drug disease pair by measuring closeness between their embeddings in the embedding space.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So really, the prediction test that we are solving here is the following.",
                    "label": 0
                },
                {
                    "sent": "Given a drug C and given a disease D, want to predict if C has the potential to treat the if it has a positive therapeutic effect for the.",
                    "label": 0
                },
                {
                    "sent": "So our input data, the way it comes, it comes in the form of a large number of disease subgraphs.",
                    "label": 0
                },
                {
                    "sent": "A large number of drug subgraphs, and this black edges across sub graphs indicate no indication information, so these are this, for example, this edge indicates that the start diseases currently approved to treat this this particular drug number one.",
                    "label": 0
                },
                {
                    "sent": "Our goal will be to learn embeddings for every subgraph in our net.",
                    "label": 1
                },
                {
                    "sent": "For every subgraph, so for every disease and drug subgraph and then use those embeddings to predict new links between subgraphs.",
                    "label": 1
                },
                {
                    "sent": "So that's again a link prediction problem, but it's now we're not predicting clicks between individual notes, but we will be predicting clicks between subgraphs intuitively.",
                    "label": 0
                },
                {
                    "sent": "Why do you want to do that?",
                    "label": 0
                },
                {
                    "sent": "We want to do that because.",
                    "label": 0
                },
                {
                    "sent": "We we really want to integrate in.",
                    "label": 0
                },
                {
                    "sent": "Consider lots of information about drugs and diseases rather than representing drug as a single note or representing the disease as a single note, which would really throw away lots of potentially very useful information.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, and that's why we work with subgraphs so methodologically, there is some interesting twist here, and that interesting twist is that now that we need to think about what is, what is the right encoder to use now, because we're not only encoding notes, but we want to encode subgraphs.",
                    "label": 0
                },
                {
                    "sent": "So for that we develop a subgraph encoder, which is an encoder that takes as input a subgraph, and it learns and embedding for the top graph.",
                    "label": 0
                },
                {
                    "sent": "A baseline underneath model here that you could think of you say well.",
                    "label": 0
                },
                {
                    "sent": "To get an embedding of the sub graph, we will first learn embedding for every note and then we simply taken every championing of notes in the subgraph and will say that is the embedding for the sub graph.",
                    "label": 0
                },
                {
                    "sent": "That does not work, that that's a valid baseline and it's good baseline.",
                    "label": 0
                },
                {
                    "sent": "It does not work well because it completely ignores the internal interaction is so interactions between proteins internal to the subgraphs, so various importance of nodes that participate in the sub graph.",
                    "label": 0
                },
                {
                    "sent": "So what is what works well?",
                    "label": 0
                },
                {
                    "sent": "What is needed to hear is a type of encoder that can learn embeddings at the level of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "An idea here is very similar to what I described before, in the sense that we will learn how to propagate those Victor valued messages or feature or embeddings along edges of the network and now also along edges the defined subgraphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the the model that does that.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Old sugar.",
                    "label": 0
                },
                {
                    "sent": "So once we have the model, the next thing again that we need is we need to high quality drug repurposing data set and for that we spent quite some quite significant number of significant amount of time preparing and cleaning the data set.",
                    "label": 0
                },
                {
                    "sent": "But now data set is ready.",
                    "label": 0
                },
                {
                    "sent": "It contains information on protein, protein, interactions, information on what are drug targets in disease, associated proteins from various public databases and is also enriched with some of the.",
                    "label": 0
                },
                {
                    "sent": "Data from our collaborators.",
                    "label": 0
                },
                {
                    "sent": "Information on currently approved medical indications.",
                    "label": 1
                },
                {
                    "sent": "Meaning information on what on what are drugs?",
                    "label": 1
                },
                {
                    "sent": "What are diseases that are treated by drugs that are currently approved on the US system and that comes from repository such as Drug Bank report.",
                    "label": 1
                },
                {
                    "sent": "DB also FDA orange book if that is for me, you're familiar with that and lots of side informations on drugs, diseases, parties for example.",
                    "label": 0
                },
                {
                    "sent": "What are molecular pathways that proteins are involved in that comes from the Broad Institute MSIT DB database?",
                    "label": 0
                },
                {
                    "sent": "What are the symptoms that diseases have that are associated with the disease?",
                    "label": 0
                },
                {
                    "sent": "Is this comes?",
                    "label": 1
                },
                {
                    "sent": "This comes from the various disease comorbidity data sources.",
                    "label": 0
                },
                {
                    "sent": "What are side effects of individual drugs?",
                    "label": 0
                },
                {
                    "sent": "This comes from a cider that is maintained by Embelin.",
                    "label": 0
                },
                {
                    "sent": "A few other resources.",
                    "label": 0
                },
                {
                    "sent": "I'm happy to talk more about it.",
                    "label": 0
                },
                {
                    "sent": "We also made all these datasets publicly available, so there's a clean preprocessed version of these datasets that you can download the news.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have the data set have the model.",
                    "label": 0
                },
                {
                    "sent": "The next thing that we will do we will evaluate.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model in a in a cross validation setting.",
                    "label": 0
                },
                {
                    "sent": "So our prediction test will be given a disease and a drug.",
                    "label": 1
                },
                {
                    "sent": "We want to predict if drug will treat the disease, the kind of cross validation that we do here is a drug centric cross validation and then also disease centric cross validation.",
                    "label": 0
                },
                {
                    "sent": "But I'm showing here the results of drug centric cross validation which means that one drug appears in the test set but none of its indications or any of its information is available on the test in the in the training set.",
                    "label": 0
                },
                {
                    "sent": "So what the results that are shown here compared the proposed method that is called sugar to some of the existing methods, or for drug repurposing where we can see improvement that is quite substantial.",
                    "label": 0
                },
                {
                    "sent": "But what is even more interesting is improvement over this recent set of methods that were proposed.",
                    "label": 0
                },
                {
                    "sent": "That is even more substantial, and the reason why this improvement was achieved is the following.",
                    "label": 0
                },
                {
                    "sent": "So this set, this second class of.",
                    "label": 0
                },
                {
                    "sent": "Baseline methods that we consider are those methods that operationalize this idea of closeness in pharmacological space, that that we that I described earlier by simply calculating shortest path lengths between drug subgraphs, indices, subgraphs, and that is much less flexible than actually learning embeddings for notes in such a way that's most useful for prediction.",
                    "label": 0
                },
                {
                    "sent": "So this really shows the power of learning those embeddings over thinking more of the standard approach on performing machine learning on graphs.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Furthermore, what is really interesting here is that including side information leads to much, much better if.",
                    "label": 1
                },
                {
                    "sent": "Performance and substantially improves performance, so the kind of science information that we are including here inside information on protein pathways, metabolic Patriots, and various types of genetic factors that proteins are involved in.",
                    "label": 1
                },
                {
                    "sent": "So in the way this is done is we have this underlying put input interaction at work and we have seen that we have a large number of drug and disease sub graphs that are all relate on that on that PPI network, but in.",
                    "label": 0
                },
                {
                    "sent": "Listen to that now.",
                    "label": 0
                },
                {
                    "sent": "We also had a large number of other kinds of subgraphs that represents various types of metabolic pathways that we're actually not interested in predicting.",
                    "label": 0
                },
                {
                    "sent": "Any associations for them.",
                    "label": 0
                },
                {
                    "sent": "But these pathways effectively serve as a form of regularization because for all proteins that participate in a particular pathway, their embed their embeddings, which are used for learning companions of subgraphs, will be pushed closer together.",
                    "label": 0
                },
                {
                    "sent": "And including that information on on site information or proteins really further boost performance of the model.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Beyond cross validation, we then asked well what, how useful are predictions made by the model for real world truck repurposing?",
                    "label": 0
                },
                {
                    "sent": "So for that, we teamed up with Stanford Spark, which is international Center for translational research and we got from them the list of drugs that were repurposed at Stanford and Boot in that center over the course of the last two decades.",
                    "label": 0
                },
                {
                    "sent": "And we think thought of that as a gold standard data set and then we asked, well, for those drugs that were repurposed at Stanford.",
                    "label": 0
                },
                {
                    "sent": "Let's say, what are?",
                    "label": 0
                },
                {
                    "sent": "What are the predictions?",
                    "label": 0
                },
                {
                    "sent": "Bye bye you buy sugar model so an inch predictions turned out to be very good.",
                    "label": 0
                },
                {
                    "sent": "So the way we can read that is if you look at focus on this particular role.",
                    "label": 0
                },
                {
                    "sent": "It says that covered the law was re purposed for Chagas disease.",
                    "label": 1
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "There's something that is a known fact, so the model that make prediction and actually ranked Cardinal's ninth most rank most most likely drug that is used for Chagas disease out of 5000 drugs on the use lock and for many other cases you see that the drugs that were actually repurposed for to treat these new kinds of diseases were always ranked very highly.",
                    "label": 0
                },
                {
                    "sent": "In by default which which which was very promising and it has led to exciting follow-up research on prostate cancer where we are now focusing on developing and identifying combinatorial drug therapies that are most useful for prostate cancer patients and minimize side effects.",
                    "label": 1
                },
                {
                    "sent": "In particular, various kinds of incontinence.",
                    "label": 0
                },
                {
                    "sent": "That is the problem here, and also for.",
                    "label": 0
                },
                {
                    "sent": "For for schizophrenia, for which none of the.",
                    "label": 0
                },
                {
                    "sent": "Current now, not the treatments.",
                    "label": 0
                },
                {
                    "sent": "Rather current treatments actually work in our treat only symptoms rather than the causes of diseases, and for Sister Frania in particular, it's very interesting and important to have this information or an ability to bring different kinds of information through multimodal networks, because the goal is not to study schizophrenia only from the neck above, but also from the neck below, which is something that has not been done before and most of the efforts have really put been put towards.",
                    "label": 0
                },
                {
                    "sent": "Understanding and finding treatment for schizophrenia by really focusing on what's going on in the brain.",
                    "label": 0
                },
                {
                    "sent": "But recently, this recent discoveries have shown that it's really important what's going on in the rest of the body as well.",
                    "label": 0
                },
                {
                    "sent": "And then multimodal networks allow us to bring that kind of information together.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one important challenge here was really that challenge of how to communicate with domain experts and convince us that this.",
                    "label": 0
                },
                {
                    "sent": "Great black box models produce predictions that are actually interesting and potentially useful to them so.",
                    "label": 0
                },
                {
                    "sent": "That was quite a difficult challenge.",
                    "label": 0
                },
                {
                    "sent": "That and it was important to design systems that allow domain experts to interact with with this machine.",
                    "label": 0
                },
                {
                    "sent": "Learning models in the form of.",
                    "label": 0
                },
                {
                    "sent": "Providing explanations not only pointwise predictions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this concludes the drug repurposing case study.",
                    "label": 1
                },
                {
                    "sent": "Then the fault.",
                    "label": 0
                },
                {
                    "sent": "Well, I think I have 10 more minutes.",
                    "label": 1
                },
                {
                    "sent": "OK, so in the rest of the time I will talk about some of new directions and opportunities to further research in this field.",
                    "label": 1
                },
                {
                    "sent": "And then I also talk about practical advice.",
                    "label": 0
                },
                {
                    "sent": "I don't think I'll have time to go to demos, but I'll provide a code so you can do that offline.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so new directions and opportunities.",
                    "label": 0
                },
                {
                    "sent": "I think there are many new directions for those here available for to further this current models that we have an.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In particular, I will mention three exciting directions that.",
                    "label": 0
                },
                {
                    "sent": "That I'm especially passionate about.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first direction is certainly direction direction towards providing a meaningful explanations, since in biomedical settings it's not only about getting the highest AUC, but it's also about understanding prediction and really for that what we need are various kinds of new means that can transform these black box models into white box models so that we have predictions that we can interpret meaningfully and that those white boxes models can be opened in in kind of probed.",
                    "label": 0
                },
                {
                    "sent": "And some of the ongoing research here really uses these principles that come from.",
                    "label": 0
                },
                {
                    "sent": "A counterfactual inference that.",
                    "label": 0
                },
                {
                    "sent": "That tend to work quite.",
                    "label": 0
                },
                {
                    "sent": "Well and address some of the problems related to explanations, but I think there's much much more that can be.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The second direction is that of towards more training, more with less data.",
                    "label": 1
                },
                {
                    "sent": "So I think what we all really need here is very algorithms that can train more with.",
                    "label": 0
                },
                {
                    "sent": "And really can generalize to never be forcing systems.",
                    "label": 0
                },
                {
                    "sent": "In particular here.",
                    "label": 0
                },
                {
                    "sent": "What I mean, we did a very simple test where we trained the model on data from one particular clinic in one hospital and then take and then took the trained model and apply it to a corresponding clinic in a different hospital.",
                    "label": 0
                },
                {
                    "sent": "Both hospitals were in the same state and actually very close to each other and they got the same profile of patients came to both hospitals.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the model performed very miserably in the second clinic in the in the different hospital, then the hospital data model was trained on and although both hospitals use use use the same as healthcare.",
                    "label": 0
                },
                {
                    "sent": "Database system with trust epic system.",
                    "label": 0
                },
                {
                    "sent": "There were different subtle internal differences in internal guidelines for how to encode information about patients, and that has really.",
                    "label": 0
                },
                {
                    "sent": "That was that was really the problem that made this current.",
                    "label": 0
                },
                {
                    "sent": "Existing models performed so miserably.",
                    "label": 0
                },
                {
                    "sent": "So there's lots of opportunities and lots of work that needs to be done that will really allow the models that we currently have to learn and generalize to different contexts.",
                    "label": 0
                },
                {
                    "sent": "With this context can mean different diseases, different patients, different environments in the sense of different hospitals or environments in the sense of ecological systems.",
                    "label": 1
                },
                {
                    "sent": "There are many natural case studies for such algorithms that can go from single cell genomics to health informatics.",
                    "label": 0
                },
                {
                    "sent": "Another direction related to this is that many of the very successful examples of these deep models in the literature were really.",
                    "label": 0
                },
                {
                    "sent": "Very simplistic in the sense that the input to those model was a simple image.",
                    "label": 1
                },
                {
                    "sent": "For example, a simple image of a skin lesion with the goal of predicting whether that image contains a benign or malign skin lesion.",
                    "label": 0
                },
                {
                    "sent": "Of course this is great and it's a great progress, but it completely ignores any knowledge about the disease.",
                    "label": 0
                },
                {
                    "sent": "Any knowledge about patient and all these other kinds of data that we might want to have?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second, finally the third direction here is really that, well, we soon.",
                    "label": 0
                },
                {
                    "sent": "I believe that there will be a state of the state of any person will be described not only by genetic information, but also about data that goes to the describes behaviors and lifestyles.",
                    "label": 0
                },
                {
                    "sent": "So it's really how do we integrate now?",
                    "label": 0
                },
                {
                    "sent": "This data from the from the gene level all the way to behaviors, so we need new methods that can.",
                    "label": 0
                },
                {
                    "sent": "Bring these data to Heather and then can answer different kinds of complex prediction problems on graphs.",
                    "label": 1
                },
                {
                    "sent": "Some of the initial results that we did in this direction that I didn't go into details are frameworks that can answer logical queries or knowledge graphs, so this is more very exciting from the point of view that allows domain experts to ask any kind of logical query in this that might be very complex.",
                    "label": 1
                },
                {
                    "sent": "So not only asking.",
                    "label": 0
                },
                {
                    "sent": "Given a disease and a protein, is that protein likely to be associated with disease?",
                    "label": 0
                },
                {
                    "sent": "But the domain expert can ask questions of the form of.",
                    "label": 0
                },
                {
                    "sent": "Oh how how likely it is that the disease will treat a disease.",
                    "label": 0
                },
                {
                    "sent": "A will treat drug B and read rugby should target to proteins C&D and those two protein C&D should interact with each other, so that's a very for complex query that that can be answered by the model on the fly in any kind of query that can be formulated in a conjunctive logical language can be formulated in this way and then insert insult so that I think it's a very exciting direction towards having this kind of interactive systems.",
                    "label": 0
                },
                {
                    "sent": "The domain experts can interact with.",
                    "label": 0
                },
                {
                    "sent": "Think of it us.",
                    "label": 0
                },
                {
                    "sent": "Especially in some of the.",
                    "label": 0
                },
                {
                    "sent": "Move the large systems is now lots of interest into constructing Clark knowledge graphs that we can then learn and reasonover.",
                    "label": 0
                },
                {
                    "sent": "So having such a system that can answer these queries would be very exciting.",
                    "label": 0
                },
                {
                    "sent": "I think from the machine learning point of view, what is really needed here are is there's lots of food that needs to be done in the form of data infrastructure, so having high quality, preprocessed, clean public datasets that can be used by computer scientists who developed new exciting algorithms and so that in the paper that we published.",
                    "label": 0
                },
                {
                    "sent": "This new exciting benchmark.",
                    "label": 0
                },
                {
                    "sent": "There will be new exciting benchmark datasets used in experiments that come from biology and medicine, not only from some, perhaps domains that are not indicative of the application cases of this methodology.",
                    "label": 0
                },
                {
                    "sent": "We made some first steps toward this goal, but there's lots of lots of that needs to be done.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The last two minutes.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll give some practical advice.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you are exciting about this area of research, how to start?",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here in this slide I provide some lecture of some some resources, in particular the first is mumble.",
                    "label": 0
                },
                {
                    "sent": "That's something that I mentioned yesterday, it's it's really.",
                    "label": 0
                },
                {
                    "sent": "At all that allows you to construct very large heterogeneous networks networks that have up to two billion edges, so I think there is discovers lots of problems in biology, medicine, exciting network data.",
                    "label": 1
                },
                {
                    "sent": "These are cleaned, preprocessed, high quality datasets.",
                    "label": 0
                },
                {
                    "sent": "Some of those, some of some of the datasets listed here are those that I described throughout the throughout the lecture today that allow you to design new algorithms and benchmark them On this date.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "Second, once you have the data set and you have the tool to represent the data, will you actually want to train some of these models so there is a number of code bases that allow you to try out some of these models quite easily on your own network on your own networks, and this goes from notably shallow and place of bad thoughts that I described yesterday to GCN models all the way to some of the.",
                    "label": 0
                },
                {
                    "sent": "The industry supported libraries for graph neural networks, in particular graph that is 1 example and deep graph libraries and library.",
                    "label": 0
                },
                {
                    "sent": "Another example that contains lots of tutorials, demos that it's so that it's very easy for you to start.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, to recap, I think there are like two kinds of proof.",
                    "label": 0
                },
                {
                    "sent": "Two kinds of people in the audience here that might have different view of graphs.",
                    "label": 0
                },
                {
                    "sent": "So if you have been using graph seeing your current research project, then I would encourage you to keep on using them.",
                    "label": 1
                },
                {
                    "sent": "The reason so some of the advantages that the methods that I described yesterday and today bring is that you don't need to do a lot of manual tedious feature engineering anymore.",
                    "label": 0
                },
                {
                    "sent": "This new class of methods allowed to combine note edge attributes and do end to end to end training which achieves state of the art performance of a number of tasks.",
                    "label": 0
                },
                {
                    "sent": "If you have not yet used graph in graphs.",
                    "label": 0
                },
                {
                    "sent": "In your research projects, because perhaps your data datasets that you work with are primarily image based datasets, sequences or more standard feature feature tables.",
                    "label": 0
                },
                {
                    "sent": "Then there, then they are exciting opportunities for graphs could be used in an could lead to improvement in performance, so the kind of questions that you need to ask is if the data is that you have is such that there really is there data set that you have really contains ID examples or there is some form of dependence or some form of relationship between images between different sequences between objects in routine and image.",
                    "label": 0
                },
                {
                    "sent": "And if that is the case then it makes lots of lots of sense too.",
                    "label": 0
                },
                {
                    "sent": "To represent those dependencies explicitly in the form of graphs and use that as part of the input to your favorite classifiers or to favorite graph or to your favorite neural network.",
                    "label": 0
                },
                {
                    "sent": "The reason why I would want to do that is because this can often lead at least too much, much faster training, meaning that you would need much less time and less data to get the same performance.",
                    "label": 0
                },
                {
                    "sent": "So what I mean by there just more concretely, is imagine you are.",
                    "label": 0
                },
                {
                    "sent": "Something you're pulling some prediction tablet is defined an image, and classically the inputs to their test would be on raw image of pixels, and that's OK, but very recent research has shown that the model can be trained with much less data if you supplement that role image with with the graph of objects detected in the image in various kinds of relationships or between those objects.",
                    "label": 0
                },
                {
                    "sent": "So imagine we would do that, but now not in the context of buildings and cars and boys and girls, but in the context of for example, itself, like a large number of cells that are in your particular image.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, finally we talked a lot about this heterogeneous networks and I think that's really an exciting paradigm that can integrate knowledge with diverse.",
                    "label": 0
                },
                {
                    "sent": "Diverse kinds of experimental readouts to perform discovery.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and the final slide is.",
                    "label": 0
                },
                {
                    "sent": "Different, I talked throughout these two days.",
                    "label": 0
                },
                {
                    "sent": "I talked about different kinds of predictions we can make when we have data provided to us in the forest graphs and that those predictions can be note predictions.",
                    "label": 0
                },
                {
                    "sent": "Meaning we're we're we're goal is to predict some property about notes in that graph.",
                    "label": 0
                },
                {
                    "sent": "Some form of relationship between pairs of nodes, some form of relationship between subgraphs.",
                    "label": 1
                },
                {
                    "sent": "What I didn't talk about, but some of the other speakers have mentioned is then predicting properties about entire graphs, which which is.",
                    "label": 1
                },
                {
                    "sent": "Which is now quite popular in the form of predicting various properties about molecular graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, so I didn't.",
                    "label": 0
                },
                {
                    "sent": "I don't have time to go through demos, but.",
                    "label": 0
                },
                {
                    "sent": "I'll, I'll put them online so you can check them later and this concludes the talk for today.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}