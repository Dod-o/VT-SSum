{
    "id": "435bdohwi4nognflegto4umx2nhbax6r",
    "title": "Colorful Image Colorization",
    "info": {
        "author": [
            "Richard Zhang, Department of Electrical Engineering and Computer Sciences, UC Berkeley"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_zhang_image_colorization/",
    "segmentation": [
        [
            "So this is joint work with Phillip Isola and Alyosha Efros from UC Berkeley.",
            "Consider this iconic photo."
        ],
        [
            "Graph of Yosemite Valley Bridge from Ansel Adams.",
            "How would it look like in color?"
        ],
        [
            "On the face of it, this problem is very under constrained, as we're looking to produce a 3 dimensional signal from a 1 dimensional signal.",
            "However, you and I have seen many color photos and we have no trouble doing this.",
            "We know that the Sky is probably blue, the mountain is likely Brown and the vegetation is most definitely green.",
            "And so this problem clearly calls for the use of data, and we can use machine learning techniques to help solve the problem.",
            "Now, formally, we're working in the."
        ],
        [
            "LAB color space.",
            "So the L channel has a grayscale information and serves as the input to our system.",
            "We're looking."
        ],
        [
            "Predict the AB channels or the color information and we learn the mapping from LDB use."
        ],
        [
            "CNN, we can then take the output predicted baby channels, concatenate them with the input and hopefully get applause."
        ],
        [
            "So colorization of."
        ],
        [
            "Input grayscale image.",
            "Now note that any color image can serve."
        ],
        [
            "Is a free supervisory signal for training this deep network.",
            "After all, any image can be broken up into its L&AB components, so perhaps by learning to color we can."
        ],
        [
            "You achieve a deep representation that has some sort of higher level abstractions or perhaps even semantics.",
            "Now training this deep network may not be as straightforward as one may expect.",
            "For example, can."
        ],
        [
            "For this example image, if we take the image pass through our system here."
        ],
        [
            "Result.",
            "It looks plausable.",
            "Here's the ground truth."
        ],
        [
            "Edge will note that even though our prediction is red and the ground truth is blue, and these are actually very far apart, in a BSP where perhaps just as happy with the red colorization as we are with the blue, because it seems plausible."
        ],
        [
            "And what this indicates to us is that some sort of loss which has some sort of unimodal assumption underneath, such as regression with L2 is going to be an adequate for this problem, because in that case, if we have multiple modes, the L2 loss will simply average between them and give us a desaturated, unexciting result.",
            "As such, we recast the problem."
        ],
        [
            "Just wanted multinomial classification so we take the output space and divide it up into discrete bins of size 10.",
            "So here's an example."
        ],
        [
            "Predicted distribution from our system.",
            "The input image is on the upper left of the bird.",
            "Now each of these tiles corresponds to one of the output bins in our multinomial classification problem, and within each of the bins, the regions with high lightness value indicate high probability of being that color."
        ],
        [
            "Presuming here you can see that the system has predicted the foreground object, the bird to be blue, red, perhaps purple, and."
        ],
        [
            "Background vegetation to be green, yellow maybe little Brown, but this is."
        ],
        [
            "At the end of the story we also have to take into account the natural image statistics of natural images.",
            "So in the right here we have a histogram showing occurrences of all the colors within all the pixels of image data and this is shown on a log scale and what you see is the majority of the pixels are concentrated in the middle of the gamut where images or the colors are desaturated or bland, and so without taking this into account with any uncertainty, the predictions that the network provides will tend to be desaturated or blend."
        ],
        [
            "As such, we add a class rebalancing term into our training objective and this effectively resamples the rarer colors so that there are more represented than their actual representation within the training set.",
            "And it's the consequences of these two design decisions.",
            "Going from regression classification and then adding the class rebalancing term that gives us results that are qualitatively more colorful than previous and current approaches.",
            "Hence the name of our project colorful image colorization."
        ],
        [
            "So how does your system compare to previous work?",
            "Well, many previous techniques have focused on using a non parametric framework.",
            "So the nonparametric framework, a reference image is first obtained and the colors from the reference image are then transferred over to the grayscale input image.",
            "Now this technique can actually work very well, but it can also fail to generalize and also getting the reference image itself can be slow or require some user intervention.",
            "Now parametric techniques, some previous parametric techniques have also used Lt regression, both with hand engineered features as well as deep networks.",
            "We're also not the first, of course, to cast the colorization problem as multinomial classification.",
            "There's actually some older work from Sharp ya at all from the CV 2008, which proposed the using using a classification framework for the colorization problem, and this work actually inspired us.",
            "There's actually some concurrent work from Larson at all that are going to appear in these proceedings, and they'll have a."
        ],
        [
            "Presentation tomorrow morning.",
            "So we highly encourage you to attend their talk as well.",
            "OK, so how do we map from the?"
        ],
        [
            "And input lightness image into an output color.",
            "Well, first we note that we've converted this problem into one where we predict."
        ],
        [
            "I'll probably distribution for every pixel, and as such we can draw on many of the insights and advances in this man."
        ],
        [
            "Segmentation literature to help solve our problem.",
            "So we start with a VGG network.",
            "This is actually train from scratch, so it's just the architecture.",
            "We remove the FC layers."
        ],
        [
            "We add some additional."
        ],
        [
            "Spatial resolution in the bottleneck using out true or dilated convolutions.",
            "We had some additional convolutional layers on top and then map."
        ],
        [
            "The features into a predicted distribution for every pixel.",
            "Now there's one final step."
        ],
        [
            "Which is going from the predicted distribution into a single point estimate.",
            "To do this, we take an interpolation between the mean and the mode and this allows us to keep the vibrancy of the output colors while maintaining some spatial consistency.",
            "OK, so how do we do?"
        ],
        [
            "Let's consider this input image of a boat.",
            "If we use an L2 regret."
        ],
        [
            "In loss you see that the result looks just fine, and this is because the Sky is blue and the vegetation is green and there's very little uncertainty.",
            "So L2 service serves us well."
        ],
        [
            "Our file system does just as well on this images as well."
        ],
        [
            "But let's consider the input image of this bird."
        ],
        [
            "While using L2 regression will give a cepia or desaturated result."
        ],
        [
            "Whereas our technique will give us a bright blue colorization with a nice yellow belly.",
            "Now, how does the input actually look in ground truth?"
        ],
        [
            "Well, you see at the yellow bird is actually yellow and even though yellow, the yellow ground truth bird and are blue prediction are far apart.",
            "Were happy with our results because it seems like a plausible colorization."
        ],
        [
            "OK, of course the problem is most definitely not solved, so there are failure cases that we have observed in our system.",
            "So one common failure case is that man made objects can actually be one of many different colors in our network.",
            "At times has difficulty in choosing one to ultimately go with in.",
            "This can result in the output having some sort of tie dye pattern.",
            "There are also some kind of."
        ],
        [
            "Your spicy's that we fished out of the system.",
            "What we notice is that when the network sees a dog face, it actually expects the dog to have its mouth open its tongue out, and even when this doesn't happen, the network goes ahead and hallucinates one for us anyways."
        ],
        [
            "OK, so one of our contributions is to really carefully think about how to carefully evaluate the colorization problem.",
            "So previous papers have used metrics such as per pixel accuracy and we evaluate these in our paper as well, but per pixel actually does not speak to the joint interaction between pixels as well as the overall perceptual quality that we're really shooting for.",
            "Now no metric is perfect, so we propose a number of them that get a different aspect."
        ],
        [
            "Of this problem now, note that our problem is an example of an image synthesis problem and actually some of the approaches that we've proposed can be applied in those other image synthesis problems as well.",
            "We also evaluate the colorization of task itself for its ability to produce strong representations.",
            "Now, due to time constraints, we won't be able to discuss all these evaluations, so please come to our poster for additional details.",
            "To begin, we will."
        ],
        [
            "Discuss a perceptual realism test that we ran using Amazon Mechanical Turk ears to provide real human judgments as to how are cyst."
        ],
        [
            "I was doing and will actually invite all of you to participate in a version of this test right now.",
            "OK, so we're going to show you 2 images.",
            "One is going to be ground truth and the other is going to be our fake image, and it's up to you decide which which one is fake.",
            "OK, so if you're ready, will begin now.",
            "Image #1 and Image #2 now.",
            "Please clap if the left image is fake."
        ],
        [
            "Now please clap if the right image is fake."
        ],
        [
            "OK, very good.",
            "So I think all of you were able to identify this very visible smudge and the lack of spatial consistency on the truck which served as a dead giveaway on an otherwise perhaps good colorization.",
            "Let's try a case that perhaps we perform a little better in.",
            "Image #1 and image #2.",
            "Clap at the left is fake.",
            "Clap if the right is fake.",
            "OK, about 5050."
        ],
        [
            "So in this case we predicted a color that was actually very close to the ground truth in these cases will fool participants at about a 50% rate.",
            "Let's try 1 final Test.",
            "Image #1 image #2.",
            "Capital F to seek."
        ],
        [
            "A clap at the right is."
        ],
        [
            "Like OK, So what happened in this case?",
            "While the ground truth image was of a blue chameleon, but our network actually learn, the chameleons typically appear green and so on.",
            "These kind of outlier cases our network, can actually make predictions that are more prototypical then perhaps the input image, and we can actually get fooling rates above 50% in these cases.",
            "There's some other examples of this behavior that we've seen."
        ],
        [
            "As well, so this input image is actually from a Reddit user, and what we find is that if you take your dog out for a color run, you can actually use our system."
        ],
        [
            "To clean him up.",
            "If you take a."
        ],
        [
            "Early child Yoda We can actually make him grow."
        ],
        [
            "And again.",
            "And so these these images were actually processed by the Reddit colorize bot, which a third party or another user wrote and is using our system in the back end."
        ],
        [
            "OK, so how do we fare quantitatively on this metric?"
        ],
        [
            "Well, if we were to produce perfect ground truth, colorizations would achieve 50% almost by definition.",
            "If we."
        ],
        [
            "Add the colors from a random image.",
            "We get 13% with."
        ],
        [
            "To regression we get 21."
        ],
        [
            "With classification we get 24 an hour full system."
        ],
        [
            "32 The systempro."
        ],
        [
            "Post by Larson at all which is concurrent work which uses a multinomial classification framework with different architecture gets 27.",
            "And this suggests to us that our design decisions going to classification and using a class rebalancing term gave us colorizations that were more plausable as judged by real human users."
        ],
        [
            "So let's try to get some insight into how our network is actually doing this.",
            "So if we try to color these two equal lumen and vegetables."
        ],
        [
            "Our system does OK now how about this Mac?"
        ],
        [
            "Math chart, which is never seen in training.",
            "Well, it fails."
        ],
        [
            "And this indicates to us that instead of using some sort of low level hack or Q, such as perhaps chromatic aberration, the network actually is learning perhaps how to recognize the objects themselves."
        ],
        [
            "Now normally to get a representation that recognizes objects, we can directly train for the task using object labels.",
            "For example, in an image net classification framework.",
            "And this is in a supervised setting."
        ],
        [
            "Colorization on the other hand, is an example of unsupervised, sometimes referred to as self, supervised learning, and in this paradigm we take the input split into two pieces and then ask the network to predict a held out piece from the remaining piece.",
            "Now there's been a flurry of activity."
        ],
        [
            "We kind of in this paradigm, especially in the past year using cues such as Co occurrence, context, egomotion video.",
            "And actually yesterday we saw."
        ],
        [
            "Sample of audio and there's been other concurrent work in this in these proceedings in this conference on they have extended some of these frameworks as well.",
            "Now our network or.",
            "Coloration task is sort of is somewhat similar to denoising auto encoders, so for denoising auto coders we take the input image.",
            "We had some random corruption and ask the network to undo this random corruption.",
            "On the other hand, for our task we add a systematic modification to the to the signal.",
            "That is, we drop out to the channels and ask the network to predict those two channels from the remaining grayscale channel, and so we call this general framework cross channel encoding."
        ],
        [
            "OK, so how does our system do in comparison to others?",
            "While to help answer this we retrained the network for the colorization task, but this time using an Alex.",
            "NET Framework we strip away everything that specific to the colorization task itself and we're left with a generic."
        ],
        [
            "Feedforward feature extractor.",
            "So to begin, we'd like to qualitatively assess if any of the units."
        ],
        [
            "May have some learned semantics and to do this we observe images which maximally activate certain units in the comp five layer.",
            "So what we see is some units which correspond to stuff categories such."
        ],
        [
            "The Sky, trees and water.",
            "And others that correspond to more thing categories such as faces, dogs."
        ],
        [
            "Faces and Flowers and note that the network was able to discover these units without the aid of class without the aid of labels, so this was done in an unsupervised regime."
        ],
        [
            "So we have some indications that the network is learning semantics.",
            "But how does the feature representation do when it's asked to transfer to other datasets and tasks?",
            "So to get at this quantitatively, we fine tune the network on the task of classification detection and segmentation on the Pascal VLC data set using some established frameworks from literature.",
            "So here on the Y is equal to zero line."
        ],
        [
            "The performance, if we were to simply use a Gaussian initialization for our network.",
            "The performance that we're looking to match, or hopefully someday beat, is if we pre trained using image net labels themselves.",
            "And the Y axis.",
            "Here we're going to plot the amount of ground we've made up between Gaussian initialization and a fully supervised pre training.",
            "Now, one way to get features is to use an auto encoder, but all encoders do not seem to actually get very semantic features.",
            "Now if we use a stack K means approach as implemented by crumble at all we this will take us partway between Gaussian initialization, an image net labels.",
            "Here we've shown some previous self supervision techniques using cues such as Eagle Motion in painting video, relative content, relative contexts.",
            "The method from Don Hewitt all is an adverse aerial feature learning framework.",
            "And here are results.",
            "So note that other than the very strong performance of the door's method on the detection task.",
            "Using colorization actually serves is very competitive, and sometimes even stay the art relative to previous self supervision methods, and this was actually kind of a surprise to us because at the outset of our project where mostly focused on the graphics task of colorization, but do note that there is still a very large gap between all these self supervision methods and pre training with image net labels, so there's still a lot of work to be done in learning semantic representations an unsupervised way.",
            "OK, so we've seen a bunch of examples of images, but those in."
        ],
        [
            "Just started off as color images.",
            "How does our method actually work on legacy black and white photos?",
            "We show a few examples here."
        ],
        [
            "So this is a thyla scene which went extinct in 1936, so there are no actual no color photos of it as far as we know."
        ],
        [
            "And so here is our result.",
            "Here's an app."
        ],
        [
            "Mature family photo taken in the 50s and this is actually of my father and my great Gran father."
        ],
        [
            "This is a professional photograph."
        ],
        [
            "From Henri Cartier bresson."
        ],
        [
            "And finally, this is an iconic American photograph of migrant mother."
        ],
        [
            "OK, so for some additional information you can go online, see the demo.",
            "You can also test our system.",
            "Our system on Reddit.",
            "You can also look at our code or go to our website for full paper or full paper and visualizations and some user examples and will actually play us out within a user example.",
            "A user video that was submitted to us while we take questions.",
            "Thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is joint work with Phillip Isola and Alyosha Efros from UC Berkeley.",
                    "label": 0
                },
                {
                    "sent": "Consider this iconic photo.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graph of Yosemite Valley Bridge from Ansel Adams.",
                    "label": 0
                },
                {
                    "sent": "How would it look like in color?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the face of it, this problem is very under constrained, as we're looking to produce a 3 dimensional signal from a 1 dimensional signal.",
                    "label": 0
                },
                {
                    "sent": "However, you and I have seen many color photos and we have no trouble doing this.",
                    "label": 0
                },
                {
                    "sent": "We know that the Sky is probably blue, the mountain is likely Brown and the vegetation is most definitely green.",
                    "label": 0
                },
                {
                    "sent": "And so this problem clearly calls for the use of data, and we can use machine learning techniques to help solve the problem.",
                    "label": 0
                },
                {
                    "sent": "Now, formally, we're working in the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "LAB color space.",
                    "label": 0
                },
                {
                    "sent": "So the L channel has a grayscale information and serves as the input to our system.",
                    "label": 0
                },
                {
                    "sent": "We're looking.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Predict the AB channels or the color information and we learn the mapping from LDB use.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "CNN, we can then take the output predicted baby channels, concatenate them with the input and hopefully get applause.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So colorization of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Input grayscale image.",
                    "label": 0
                },
                {
                    "sent": "Now note that any color image can serve.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is a free supervisory signal for training this deep network.",
                    "label": 0
                },
                {
                    "sent": "After all, any image can be broken up into its L&AB components, so perhaps by learning to color we can.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You achieve a deep representation that has some sort of higher level abstractions or perhaps even semantics.",
                    "label": 0
                },
                {
                    "sent": "Now training this deep network may not be as straightforward as one may expect.",
                    "label": 0
                },
                {
                    "sent": "For example, can.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For this example image, if we take the image pass through our system here.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result.",
                    "label": 0
                },
                {
                    "sent": "It looks plausable.",
                    "label": 0
                },
                {
                    "sent": "Here's the ground truth.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Edge will note that even though our prediction is red and the ground truth is blue, and these are actually very far apart, in a BSP where perhaps just as happy with the red colorization as we are with the blue, because it seems plausible.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what this indicates to us is that some sort of loss which has some sort of unimodal assumption underneath, such as regression with L2 is going to be an adequate for this problem, because in that case, if we have multiple modes, the L2 loss will simply average between them and give us a desaturated, unexciting result.",
                    "label": 0
                },
                {
                    "sent": "As such, we recast the problem.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just wanted multinomial classification so we take the output space and divide it up into discrete bins of size 10.",
                    "label": 0
                },
                {
                    "sent": "So here's an example.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Predicted distribution from our system.",
                    "label": 0
                },
                {
                    "sent": "The input image is on the upper left of the bird.",
                    "label": 0
                },
                {
                    "sent": "Now each of these tiles corresponds to one of the output bins in our multinomial classification problem, and within each of the bins, the regions with high lightness value indicate high probability of being that color.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Presuming here you can see that the system has predicted the foreground object, the bird to be blue, red, perhaps purple, and.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Background vegetation to be green, yellow maybe little Brown, but this is.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At the end of the story we also have to take into account the natural image statistics of natural images.",
                    "label": 0
                },
                {
                    "sent": "So in the right here we have a histogram showing occurrences of all the colors within all the pixels of image data and this is shown on a log scale and what you see is the majority of the pixels are concentrated in the middle of the gamut where images or the colors are desaturated or bland, and so without taking this into account with any uncertainty, the predictions that the network provides will tend to be desaturated or blend.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As such, we add a class rebalancing term into our training objective and this effectively resamples the rarer colors so that there are more represented than their actual representation within the training set.",
                    "label": 0
                },
                {
                    "sent": "And it's the consequences of these two design decisions.",
                    "label": 0
                },
                {
                    "sent": "Going from regression classification and then adding the class rebalancing term that gives us results that are qualitatively more colorful than previous and current approaches.",
                    "label": 0
                },
                {
                    "sent": "Hence the name of our project colorful image colorization.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how does your system compare to previous work?",
                    "label": 0
                },
                {
                    "sent": "Well, many previous techniques have focused on using a non parametric framework.",
                    "label": 0
                },
                {
                    "sent": "So the nonparametric framework, a reference image is first obtained and the colors from the reference image are then transferred over to the grayscale input image.",
                    "label": 0
                },
                {
                    "sent": "Now this technique can actually work very well, but it can also fail to generalize and also getting the reference image itself can be slow or require some user intervention.",
                    "label": 0
                },
                {
                    "sent": "Now parametric techniques, some previous parametric techniques have also used Lt regression, both with hand engineered features as well as deep networks.",
                    "label": 0
                },
                {
                    "sent": "We're also not the first, of course, to cast the colorization problem as multinomial classification.",
                    "label": 0
                },
                {
                    "sent": "There's actually some older work from Sharp ya at all from the CV 2008, which proposed the using using a classification framework for the colorization problem, and this work actually inspired us.",
                    "label": 0
                },
                {
                    "sent": "There's actually some concurrent work from Larson at all that are going to appear in these proceedings, and they'll have a.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Presentation tomorrow morning.",
                    "label": 0
                },
                {
                    "sent": "So we highly encourage you to attend their talk as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we map from the?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And input lightness image into an output color.",
                    "label": 0
                },
                {
                    "sent": "Well, first we note that we've converted this problem into one where we predict.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll probably distribution for every pixel, and as such we can draw on many of the insights and advances in this man.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Segmentation literature to help solve our problem.",
                    "label": 0
                },
                {
                    "sent": "So we start with a VGG network.",
                    "label": 0
                },
                {
                    "sent": "This is actually train from scratch, so it's just the architecture.",
                    "label": 0
                },
                {
                    "sent": "We remove the FC layers.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We add some additional.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spatial resolution in the bottleneck using out true or dilated convolutions.",
                    "label": 0
                },
                {
                    "sent": "We had some additional convolutional layers on top and then map.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The features into a predicted distribution for every pixel.",
                    "label": 0
                },
                {
                    "sent": "Now there's one final step.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is going from the predicted distribution into a single point estimate.",
                    "label": 0
                },
                {
                    "sent": "To do this, we take an interpolation between the mean and the mode and this allows us to keep the vibrancy of the output colors while maintaining some spatial consistency.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we do?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's consider this input image of a boat.",
                    "label": 0
                },
                {
                    "sent": "If we use an L2 regret.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In loss you see that the result looks just fine, and this is because the Sky is blue and the vegetation is green and there's very little uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So L2 service serves us well.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our file system does just as well on this images as well.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But let's consider the input image of this bird.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "While using L2 regression will give a cepia or desaturated result.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whereas our technique will give us a bright blue colorization with a nice yellow belly.",
                    "label": 0
                },
                {
                    "sent": "Now, how does the input actually look in ground truth?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, you see at the yellow bird is actually yellow and even though yellow, the yellow ground truth bird and are blue prediction are far apart.",
                    "label": 0
                },
                {
                    "sent": "Were happy with our results because it seems like a plausible colorization.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, of course the problem is most definitely not solved, so there are failure cases that we have observed in our system.",
                    "label": 0
                },
                {
                    "sent": "So one common failure case is that man made objects can actually be one of many different colors in our network.",
                    "label": 0
                },
                {
                    "sent": "At times has difficulty in choosing one to ultimately go with in.",
                    "label": 0
                },
                {
                    "sent": "This can result in the output having some sort of tie dye pattern.",
                    "label": 0
                },
                {
                    "sent": "There are also some kind of.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your spicy's that we fished out of the system.",
                    "label": 0
                },
                {
                    "sent": "What we notice is that when the network sees a dog face, it actually expects the dog to have its mouth open its tongue out, and even when this doesn't happen, the network goes ahead and hallucinates one for us anyways.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one of our contributions is to really carefully think about how to carefully evaluate the colorization problem.",
                    "label": 0
                },
                {
                    "sent": "So previous papers have used metrics such as per pixel accuracy and we evaluate these in our paper as well, but per pixel actually does not speak to the joint interaction between pixels as well as the overall perceptual quality that we're really shooting for.",
                    "label": 0
                },
                {
                    "sent": "Now no metric is perfect, so we propose a number of them that get a different aspect.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this problem now, note that our problem is an example of an image synthesis problem and actually some of the approaches that we've proposed can be applied in those other image synthesis problems as well.",
                    "label": 0
                },
                {
                    "sent": "We also evaluate the colorization of task itself for its ability to produce strong representations.",
                    "label": 0
                },
                {
                    "sent": "Now, due to time constraints, we won't be able to discuss all these evaluations, so please come to our poster for additional details.",
                    "label": 0
                },
                {
                    "sent": "To begin, we will.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Discuss a perceptual realism test that we ran using Amazon Mechanical Turk ears to provide real human judgments as to how are cyst.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I was doing and will actually invite all of you to participate in a version of this test right now.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're going to show you 2 images.",
                    "label": 0
                },
                {
                    "sent": "One is going to be ground truth and the other is going to be our fake image, and it's up to you decide which which one is fake.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you're ready, will begin now.",
                    "label": 0
                },
                {
                    "sent": "Image #1 and Image #2 now.",
                    "label": 0
                },
                {
                    "sent": "Please clap if the left image is fake.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now please clap if the right image is fake.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, very good.",
                    "label": 0
                },
                {
                    "sent": "So I think all of you were able to identify this very visible smudge and the lack of spatial consistency on the truck which served as a dead giveaway on an otherwise perhaps good colorization.",
                    "label": 0
                },
                {
                    "sent": "Let's try a case that perhaps we perform a little better in.",
                    "label": 0
                },
                {
                    "sent": "Image #1 and image #2.",
                    "label": 0
                },
                {
                    "sent": "Clap at the left is fake.",
                    "label": 0
                },
                {
                    "sent": "Clap if the right is fake.",
                    "label": 0
                },
                {
                    "sent": "OK, about 5050.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this case we predicted a color that was actually very close to the ground truth in these cases will fool participants at about a 50% rate.",
                    "label": 0
                },
                {
                    "sent": "Let's try 1 final Test.",
                    "label": 0
                },
                {
                    "sent": "Image #1 image #2.",
                    "label": 0
                },
                {
                    "sent": "Capital F to seek.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A clap at the right is.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like OK, So what happened in this case?",
                    "label": 0
                },
                {
                    "sent": "While the ground truth image was of a blue chameleon, but our network actually learn, the chameleons typically appear green and so on.",
                    "label": 0
                },
                {
                    "sent": "These kind of outlier cases our network, can actually make predictions that are more prototypical then perhaps the input image, and we can actually get fooling rates above 50% in these cases.",
                    "label": 0
                },
                {
                    "sent": "There's some other examples of this behavior that we've seen.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As well, so this input image is actually from a Reddit user, and what we find is that if you take your dog out for a color run, you can actually use our system.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To clean him up.",
                    "label": 0
                },
                {
                    "sent": "If you take a.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Early child Yoda We can actually make him grow.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And again.",
                    "label": 0
                },
                {
                    "sent": "And so these these images were actually processed by the Reddit colorize bot, which a third party or another user wrote and is using our system in the back end.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how do we fare quantitatively on this metric?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, if we were to produce perfect ground truth, colorizations would achieve 50% almost by definition.",
                    "label": 0
                },
                {
                    "sent": "If we.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Add the colors from a random image.",
                    "label": 0
                },
                {
                    "sent": "We get 13% with.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To regression we get 21.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With classification we get 24 an hour full system.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "32 The systempro.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Post by Larson at all which is concurrent work which uses a multinomial classification framework with different architecture gets 27.",
                    "label": 0
                },
                {
                    "sent": "And this suggests to us that our design decisions going to classification and using a class rebalancing term gave us colorizations that were more plausable as judged by real human users.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's try to get some insight into how our network is actually doing this.",
                    "label": 0
                },
                {
                    "sent": "So if we try to color these two equal lumen and vegetables.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our system does OK now how about this Mac?",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Math chart, which is never seen in training.",
                    "label": 0
                },
                {
                    "sent": "Well, it fails.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this indicates to us that instead of using some sort of low level hack or Q, such as perhaps chromatic aberration, the network actually is learning perhaps how to recognize the objects themselves.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now normally to get a representation that recognizes objects, we can directly train for the task using object labels.",
                    "label": 0
                },
                {
                    "sent": "For example, in an image net classification framework.",
                    "label": 0
                },
                {
                    "sent": "And this is in a supervised setting.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Colorization on the other hand, is an example of unsupervised, sometimes referred to as self, supervised learning, and in this paradigm we take the input split into two pieces and then ask the network to predict a held out piece from the remaining piece.",
                    "label": 0
                },
                {
                    "sent": "Now there's been a flurry of activity.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We kind of in this paradigm, especially in the past year using cues such as Co occurrence, context, egomotion video.",
                    "label": 0
                },
                {
                    "sent": "And actually yesterday we saw.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sample of audio and there's been other concurrent work in this in these proceedings in this conference on they have extended some of these frameworks as well.",
                    "label": 0
                },
                {
                    "sent": "Now our network or.",
                    "label": 0
                },
                {
                    "sent": "Coloration task is sort of is somewhat similar to denoising auto encoders, so for denoising auto coders we take the input image.",
                    "label": 0
                },
                {
                    "sent": "We had some random corruption and ask the network to undo this random corruption.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, for our task we add a systematic modification to the to the signal.",
                    "label": 0
                },
                {
                    "sent": "That is, we drop out to the channels and ask the network to predict those two channels from the remaining grayscale channel, and so we call this general framework cross channel encoding.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how does our system do in comparison to others?",
                    "label": 0
                },
                {
                    "sent": "While to help answer this we retrained the network for the colorization task, but this time using an Alex.",
                    "label": 0
                },
                {
                    "sent": "NET Framework we strip away everything that specific to the colorization task itself and we're left with a generic.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Feedforward feature extractor.",
                    "label": 0
                },
                {
                    "sent": "So to begin, we'd like to qualitatively assess if any of the units.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "May have some learned semantics and to do this we observe images which maximally activate certain units in the comp five layer.",
                    "label": 0
                },
                {
                    "sent": "So what we see is some units which correspond to stuff categories such.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Sky, trees and water.",
                    "label": 0
                },
                {
                    "sent": "And others that correspond to more thing categories such as faces, dogs.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Faces and Flowers and note that the network was able to discover these units without the aid of class without the aid of labels, so this was done in an unsupervised regime.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have some indications that the network is learning semantics.",
                    "label": 0
                },
                {
                    "sent": "But how does the feature representation do when it's asked to transfer to other datasets and tasks?",
                    "label": 1
                },
                {
                    "sent": "So to get at this quantitatively, we fine tune the network on the task of classification detection and segmentation on the Pascal VLC data set using some established frameworks from literature.",
                    "label": 0
                },
                {
                    "sent": "So here on the Y is equal to zero line.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The performance, if we were to simply use a Gaussian initialization for our network.",
                    "label": 0
                },
                {
                    "sent": "The performance that we're looking to match, or hopefully someday beat, is if we pre trained using image net labels themselves.",
                    "label": 0
                },
                {
                    "sent": "And the Y axis.",
                    "label": 0
                },
                {
                    "sent": "Here we're going to plot the amount of ground we've made up between Gaussian initialization and a fully supervised pre training.",
                    "label": 0
                },
                {
                    "sent": "Now, one way to get features is to use an auto encoder, but all encoders do not seem to actually get very semantic features.",
                    "label": 0
                },
                {
                    "sent": "Now if we use a stack K means approach as implemented by crumble at all we this will take us partway between Gaussian initialization, an image net labels.",
                    "label": 0
                },
                {
                    "sent": "Here we've shown some previous self supervision techniques using cues such as Eagle Motion in painting video, relative content, relative contexts.",
                    "label": 0
                },
                {
                    "sent": "The method from Don Hewitt all is an adverse aerial feature learning framework.",
                    "label": 0
                },
                {
                    "sent": "And here are results.",
                    "label": 0
                },
                {
                    "sent": "So note that other than the very strong performance of the door's method on the detection task.",
                    "label": 0
                },
                {
                    "sent": "Using colorization actually serves is very competitive, and sometimes even stay the art relative to previous self supervision methods, and this was actually kind of a surprise to us because at the outset of our project where mostly focused on the graphics task of colorization, but do note that there is still a very large gap between all these self supervision methods and pre training with image net labels, so there's still a lot of work to be done in learning semantic representations an unsupervised way.",
                    "label": 0
                },
                {
                    "sent": "OK, so we've seen a bunch of examples of images, but those in.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just started off as color images.",
                    "label": 0
                },
                {
                    "sent": "How does our method actually work on legacy black and white photos?",
                    "label": 1
                },
                {
                    "sent": "We show a few examples here.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a thyla scene which went extinct in 1936, so there are no actual no color photos of it as far as we know.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so here is our result.",
                    "label": 0
                },
                {
                    "sent": "Here's an app.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mature family photo taken in the 50s and this is actually of my father and my great Gran father.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a professional photograph.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From Henri Cartier bresson.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, this is an iconic American photograph of migrant mother.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so for some additional information you can go online, see the demo.",
                    "label": 1
                },
                {
                    "sent": "You can also test our system.",
                    "label": 0
                },
                {
                    "sent": "Our system on Reddit.",
                    "label": 0
                },
                {
                    "sent": "You can also look at our code or go to our website for full paper or full paper and visualizations and some user examples and will actually play us out within a user example.",
                    "label": 1
                },
                {
                    "sent": "A user video that was submitted to us while we take questions.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}