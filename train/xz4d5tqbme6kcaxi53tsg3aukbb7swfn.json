{
    "id": "xz4d5tqbme6kcaxi53tsg3aukbb7swfn",
    "title": "Graphical Models",
    "info": {
        "author": [
            "Zoubin Ghahramani, Department of Engineering, University of Cambridge"
        ],
        "published": "Nov. 2, 2009",
        "recorded": "August 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/mlss09uk_ghahramani_gm/",
    "segmentation": [
        [
            "Alright.",
            "So I'm going to follow on Ascentia.",
            "Lee from Chris is great introduction an start to talk about graphical models and graphical models are going to be very fundamental to a lot of the things that you'll see throughout this summer school, so.",
            "Hopefully."
        ],
        [
            "This will be useful and I'm going to go into graphical models in a little bit more detail than Chris, but obviously I will be a little bit of overlap with the things he's already presented, so let me just go straight into it.",
            "So I'm going to talk about three main kinds of graphical models, factor graphs that Chris has mentioned already, undirected graphs and directed graphs.",
            "And in all of these graphical models, the property they have is that the nodes correspond to random variables.",
            "And the edges somehow represent statistical dependencies between these variables.",
            "Now I'm going to talk about these three main kinds of graphical models, but that does not mean that there aren't other kinds of graphical models.",
            "In fact, I'll mention something later on, but there's some other interesting kinds of graphical models that you know people actively do research on, but these are the ones that are most widely used right now.",
            "So before I go into the technical details of how these graphical models work again, I want to give you just from my perspective, which is very similar to Chris is on this reasons for."
        ],
        [
            "Why we would want to use graphical models?",
            "So, like Chris said, you know you could just have pages of equations defining our models, but graphs are first of all an intuitive way of representing and visualizing relationships between variables.",
            "And these are things that we use commonly for all sorts of other uses.",
            "We use graphs to represent family trees, electric circuit diagrams, connectivities of things like neural networks, etc.",
            "But they're not just intuitive tools.",
            "There are ways of abstracting properties of probability distributions, and in particular graph allows us to abstract out the conditional independence relationships between the variables from the details of their parametric forms.",
            "So we can answer questions like is a dependent on B, given that we know the value of C just by looking at the graph without having to know what is the probability distribution of a.",
            "Is it gamma Poisson, or is it?",
            "You know this conditional probability table, whatever the details are abstracted away.",
            "And finally, again, in a theme that you'll see several times, graphical models allow us to define general message passing algorithms that implement probabilistic inference efficiently, so we can answer queries like what is the probability of a given that C takes on the value little C without enumerating all the settings of the variables in the model.",
            "We can answer it by passing messages in the graph, so that's just a summary of that.",
            "That's just sort of elegant as well that graphical models really combine ideas from.",
            "Statistics in terms of the conditional independence, some elementary graph theory and computer science in terms of the message passing object oriented algorithms that implement inference."
        ],
        [
            "OK, so.",
            "Graphical models fundamentally represent conditional independence.",
            "So let me just spend a couple of minutes talking about conditional independence.",
            "We're going to use the following notation, which actually I think Phil David introduced to statistics.",
            "Many years ago, so X is conditionally independent from Y given V. That's what this sort of parallel lines here represent.",
            "The independence.",
            "Basically, that is equivalent to saying that the probability of X given Y&V is the probability of X given V wherever probability of Y&V is not strictly 0, because otherwise, then this is conditioning on an impossibility.",
            "So that's a technical.",
            "Condition here also X is independent of Y given V if the probability of X&Y given V factors into the probability of X given V and the probability of Y given V. OK.",
            "So in general, we can think of conditional independence between sets of variables, so use this sort of curly notation for sex sets.",
            "X is independent of Y, given V is this sort of factorization here.",
            "And marginal independence.",
            "This sort of usual form of independence that you know we first learn about is just independence with conditioning on the empty set.",
            "OK, so X is independent of Y is the same as conditional independence given nothing and that just means that the joint distribution of X&Y factors into the distribution of X times this."
        ],
        [
            "Reason of why?",
            "OK, so why is conditional independence important?",
            "And why is marginal independence important?",
            "Well, it tells us what things depend on what other things and what things we can ignore and part of doing things efficiently is being able to ignore as many things as possible.",
            "So conditional independence happens in all sorts of nice intuitive places, and I want to highlight conditional independence as opposed to marginal independence.",
            "Here, so let's just look at some of these examples.",
            "So the amount of a speeding fine is conditionally independent from the type of car that you're driving.",
            "Given that speed that you were caught driving.",
            "OK, so if you're driving a Ferrari at 56 mph, you should get the same speeding fine as if you're driving a Fiat at 56 mph.",
            "Of course, this is a good example of thinking about marginal independence if you just.",
            "Randomly went out and measured speeding fines and you measure types of cars that people were driving.",
            "You would not find that these things are independent, right?",
            "Ferrari drivers will get bigger speeding fines than Fiat drivers, OK?",
            "So again, a classic example is, for example, smoking tends to make people's teeth yellow and is associated with lung cancer, but presumably lung cancer and yellow teeth are conditionally independent given if you know whether somebody is a smoker or not.",
            "Now these are sort of classic things, but you can imagine conditional dependence being used in all sorts of other settings.",
            "Where maybe you're sort of doing something like robotics or tracking.",
            "OK, so let's say you're modeling the dynamics of a system, and you measure the position and velocity and acceleration of that system overtime, and you draw out a model and then you could say, well, the state of the system, the position and velocity at time T plus one is actually independent of the position and velocity at T -- 1.",
            "Given the state, the position and velocity at time T, and the acceleration at time T. OK. You could be doing genetic pedigree analysis and looking at children's genes.",
            "Parents genes their grandparents genes and then you would want to use a conditional independence structure to be able to infer.",
            "Geno, type of a particular individual given their ancestry.",
            "And in a nice example that Chris showed, if we have two teams of players playing against each other, maybe a priore, their abilities are independent, but conditioned on the outcome of the game A versus B, the ability of team A and the ability of Team B become conditionally dependent.",
            "So knowledge of the outcome informs us of both of these things in their dependent on each other.",
            "OK, any questions about that?",
            "Yep, what do we need conditional dependence independence here?",
            "Why do you know?",
            "Just say amount speeding fine doesn't depend on the type of the car.",
            "Long concert, but the question is amount of speeding car doesn't depend on the type of of sorry amount of speeding fine doesn't depend on type of car.",
            "You when you say that you have to say under what assumptions?",
            "OK, So what do you know about what you know about the situation?",
            "If you know that?",
            "If you know the speed, it doesn't depend, but if you just go and measure these things.",
            "Then there is a dependency.",
            "You could plot the dependency between the two.",
            "OK, so all notions of dependence and independence are really conditioned on a state of knowledge.",
            "In some ways, these are representations of state of knowledge, not representations of necessarily physical things out there.",
            "OK, and things can become dependent once you know something else.",
            "OK.",
            "So let me start talking about factor graphs again.",
            "You've heard about this from Chris, so I'm going to go pretty quickly, hopefully."
        ],
        [
            "So you have two types of nodes in a factor graph.",
            "The circles in effect represent random variables.",
            "The squares or filled dots represent factors in the joint distribution.",
            "So here are two different factor graphs over 5 variables, ABCD&E and factor.",
            "Graph A represents this factorization of the joint distribution.",
            "So for example, G1 is a factor that relates A&C.",
            "G2 relates BC and D and G3 relate CD&E this thing at the beginning.",
            "Here is just a normalizing constant so.",
            "What we have here is a probability distribution over these five quantities.",
            "If we sum or integrate over all the variables that has to summer integrate to one.",
            "So we need a normalizing constant to make sure that when we multiply the factors together and we sum it out, it sums to one as well.",
            "OK, what are the factors the factors are functions of their arguments.",
            "OK, so if A&C are binary variables.",
            "This factor is a two by two table.",
            "And so two by two table with non negative entries.",
            "We don't want negative probabilities, otherwise nothing makes much sense.",
            "OK, but we can allow the factors to have any non negative number in them.",
            "'cause then we have a normalizing constant that ensures that things sum to one OK.",
            "So this factor graph represents this factorization.",
            "The factor graph B represents this factorization OK. And I think I've said all of these things.",
            "Now two nodes are neighbors in a graph.",
            "If they share a common factor.",
            "So for example E&D are neighbors in the graph.",
            "And E&D are neighbors in this graph.",
            "OK, any questions?",
            "OK."
        ],
        [
            "So I've just repeated some of these definitions here and we need to think about graph properties to understand the independent structure of these graphs.",
            "So a path is a sequence of neighboring nodes.",
            "For example, here a CDE is a path OK?",
            "So how do we relate these factor graphs with independence structure?",
            "So here is a basic fact that we're going to use.",
            "X is independent of Y given V. If every path between X&Y contains some node V in V, OK, this is curly.",
            "V is a set of variables.",
            "And.",
            "Normal V is just a variable in that set.",
            "OK.",
            "So basically to figure out whether two variables are conditionally independent given some other set of variables, we have to consider all possible ways of getting from X to Y and see whether there in there is node V. On that path that separates X&Y.",
            "OK, and in a minute we're going to be able to show how we prove these conditional independence properties, so it shouldn't be mysterious at all.",
            "Now, given this fact, the corollary is that given the neighbors of a variable X, the variable X is conditionally independent of all other variables.",
            "OK, so X is conditionally independent of Y given the neighbors of X for all Y that are neither X nor neighbor of X.",
            "By all other variables.",
            "OK, so for example.",
            "Just yell it out.",
            "What are the neighbors of E?",
            "C&D so C. And so given.",
            "C&DE is independent of B. OK. Now, how do we prove these things?",
            "I mean this is this I just stated this as a fact, but we really would need to prove a theorem to show this and I'm not going to prove the theorem in a general form, but I'm just going to show you how you would prove it.",
            "It's actually pretty straightforward.",
            "So."
        ],
        [
            "Here's how you would prove conditional independence.",
            "So assume we had the following factor graph.",
            "We have X&V joined by Factor G1 and V&Y joined by Factor G2.",
            "So that corresponds to this joint distribution factoring into one over normalizing constant G 1 * G Two OK, Now we want to be able to show.",
            "The following conditional independence we want to be able to show that X is independent of Y given V. Alright, X is independent of Y given Phi.",
            "So how do we show this, alright?",
            "So starting from this.",
            "We're going to show it algebraically.",
            "We can actually now at this point ignore the graph, OK?",
            "So take expression one.",
            "An summit over the variable X, so I'm going to sum both the left hand side and the right hand side over X.",
            "If I sum the left hand side over XI, get P of Y&V.",
            "Write this joint distribution.",
            "Marginalizing out X is this joint distribution.",
            "If I have some the right hand side over XI can bring that summation into this factor here, because this doesn't.",
            "This is just a normalizing constant and this factor here doesn't depend on X OK. Now.",
            "Take one and divide it by three.",
            "So divide both the left hand and the right hand side of these two equations.",
            "Where do we get the joint distribution of XY&V?",
            "Dividing out the distribution of Y&V is the distribution of X given Y&V.",
            "Case, that's the left hand side.",
            "And if we take this thing here an we divide it by this thing.",
            "Here the two normalizing constants here cancel.",
            "We get G1 over this sum over X of G1 and this G2 cancels that G2.",
            "OK.",
            "So, so what's the big deal?",
            "Alright, so we have an expression for X given Y&V.",
            "And we have a form for that expression just on the basis of the factorization in the factor graph OK?",
            "Now, here's the important thing.",
            "The right hand side of this expression does not functionally depend on Y. OK.",
            "So therefore it follows that the distribution of X given Y&V.",
            "Does not depend on the value of Y. Alright, so this is what we were trying to prove that the distribution of X given Y&V is just the distribution of X given V and we just showed that this quantity here does not depend on the value of Y.",
            "So we've basically shown that independence.",
            "OK, so this basic idea, if you just take it very generally to any factor distribution, you write down the neighbors and so on.",
            "You do the sums and so on.",
            "Then you can prove.",
            "The facts and the corollary is that."
        ],
        [
            "On the previous slide.",
            "OK, so that was factor graphs.",
            "Now factor graphs are in some ways relatively modern invention.",
            "Much older form of graphical model is the undirected graphical model, which is actually very very similar to factor graphs and we'll talk about the differences in a minute.",
            "Undirected graphical models have been around.",
            "For many decades there also known as Markov networks, there known as Markov random fields in computer vision and other fields.",
            "And the basic idea in an undirected graphical model is also that the joint distribution over all variables can be written in a factored form.",
            "So the joint distribution over variables X is one over some normalizing constant.",
            "The product of these factors, right?",
            "Where the notation I'm using is that X sub CJ is just CJ is a subset of all of the nodes in the graph, so there K nodes in the graph or K variables.",
            "CJ is the J subset of that corresponding to the J factor.",
            "Here X of CJ is just take the subset of the vector indexed by CJ.",
            "So.",
            "If we have a factorization like this, then we can specify an undirected graph in the following way.",
            "Create a node for each variable and then connect two nodes I&K if there is some set CJ such that both I is in that set CJ Anki's.",
            "In that set CJ.",
            "In other words, if there's some factor.",
            "Where both ZYAN XC contribute both part of that factor.",
            "So these sets form the cliques of the graph.",
            "These are fully connected subgraphs."
        ],
        [
            "So let's just look at one of these.",
            "Here we have it.",
            "It's an undirected graphical model.",
            "The difference between this and factor graphs is that we're not explicitly representing those factors.",
            "We're just directly connecting the nodes to each other with these undirected edges.",
            "OK, so this undirected graphical model corresponds to this factorization of the joint distribution over these five variables.",
            "Again, we have the fact that X is independent of Y given V if every path between X&Y contains some node in the set V. OK, again we have a corollary.",
            "Given the neighbors of X, the variable X is conditionally independent of all other variables, just like in factor graphs.",
            "And we can define, you know, a couple of other things the Markov blanket.",
            "A Markov blanket is a set of variables for V. Sorry, V is a Markov blanket for X if and only if X is independent of Y.",
            "Given V for all.",
            "Why not in the Union of the set X&V?",
            "Markov boundary is the minimal Markov blanket, so that's what makes you independent of everything else, and that's generally there's the neighbors of your node OK, and you can define these more generally for set."
        ],
        [
            "Knows if you want.",
            "Alright, so I've introduced undirected graphs and factor graphs and they seem remarkably similar.",
            "So what's the point?",
            "What's the reason why we have these two things?",
            "So one of them is historical, so undirected graphs have been around much longer than factor graphs.",
            "That's why I think it's important for me to introduce them here.",
            "But they don't represent exactly the same form.",
            "Properties of distribution are forms of distribution.",
            "Let's consider these three graphs AB&C all right.",
            "The nodes in these graphs have exactly the same neighbors, right?",
            "The neighbors of ERC&D in all three of these graphs.",
            "OK.",
            "Therefore, these three graphs represent exactly the same conditional independence relationships.",
            "So as far as conditional dependence relationships go, they're not different.",
            "But C here.",
            "Also represents the fact that the probability factors into a product of pairwise functions.",
            "So consider this factor here that connects EC&D.",
            "In general, that's a function of three variables, OK, and here in the undirected graph we haven't explicitly represented the factor, so we generally need to have a function of these three variables to capture.",
            "The relationships between these variables.",
            "Whereas here it's explicitly shown that.",
            "These three variables interact through pairwise functions.",
            "Functions of two variables.",
            "This is significant from the point of view of representation and implementation.",
            "An message passing etc because.",
            "If we just think of the variables as being discrete, let's say they take on K possible values, then the functions and A&B are generally tables of order K cubed elements, whereas the functions in CR tables all of order K squared, and more generally, if we have a bigger network with lots of interconnections, the factor graph might represent the forms of the functions more.",
            "Compactly more succinctly than the undirected graph, because it can represent the fact that these functions are not necessarily functions of large sense, but they can be functions of small sets of variables.",
            "Yep, there any qualitative properties of their kind of factorization.",
            "I mean vector graphics press conditional independence, which is qualitative property of probability distributions from qualitatively in terms of probability distributions in terms of conditional independence.",
            "They're going to be equivalent, OK, but but I mean it's fundamentally different to say that this distribution factors into product of pairwise functions or three way functions, or something like that.",
            "It's a bit more fine grained representation if you write out each of the factors explicitly.",
            "OK, yes.",
            "That is subset.",
            "Yes, the question was in particular here.",
            "This is a subset of all distributions captured by this correct?",
            "It's a qualitative.",
            "Say."
        ],
        [
            "Alright, so now why is that naughty?",
            "Why?",
            "Why can't we just use undirected graphs and factor graphs?",
            "Well, the problem with undirected graphs and factor graphs is that.",
            "Many useful in dependencies are not explicitly represented, so two variables have to be merely connected because some other variable depends on them.",
            "Alright, so this is a classic example from Udaya Perl who wrote an important book on this topic.",
            "Where he was thinking of, you know, this sort of life in California you have rained occasionally and you have sprinklers for watering your garden or lawn.",
            "And both of these things can make the ground wet now.",
            "Whether it rains or not, and whether your sprinkler is on or not might be marginally independent.",
            "If your slinker is on a timer, for example, that is ignores the weather, but the ground being wet depends on both of these things.",
            "So here we have a nice directed graph that represents these dependencies.",
            "If we were representing these with a factor graph or an undirected graph, we would have to join up all three of these variables into a.",
            "Single factor or put this undirected edge between these two OK, why do we have to put this undirected edge here?",
            "Because if we didn't put this undirected edge, what would it mean?",
            "Well, the graph would look like this.",
            "That would mean observing the ground was wet.",
            "Would make the probability of it having rained or the sprinkler being an independent, and that's not true if we observe the ground is wet then there are two reasonable explanations.",
            "Either it rained or the sprinklers on maybe both.",
            "But certainly these two variables are not independent of each other.",
            "They're conditionally dependent given this, so it's a bit annoying in these undirected representations that you have to connect up lots of things that are not a priority related just because something else depends on them.",
            "Um?",
            "And this also sort of explains it's a way of mentioning the whole idea of explaining away if you have multiple explanations for something.",
            "Observing that the cplink sprinkler is on would explain away the observation to the ground was wet, making it less probable that it rained.",
            "OK, so there is a complicated dependency between causes and effects that.",
            "Is well captured by directed representations."
        ],
        [
            "OK, so let me now talk about directed graphical models which go by several names.",
            "We could call them directed acyclic graphical models or Bayesian networks, although there is a footnote here 'cause you can do maximum likelihood or frequentist learning of Bayesian networks.",
            "So yeah, sure.",
            "Make use of.",
            "This kind of.",
            "So the question is, are there inference algorithms that make use of this kind of conditional independence?",
            "Yes, so in fact the message passing or belief propagation algorithms are really making trying to make use of conditional independence.",
            "The form of the belief propagation algorithm is slightly different for directed graphs than factor graphs.",
            "It turns out not to make a big not to make it practical.",
            "Difference so.",
            "Well, it's important if it's important.",
            "If you want to have a representation of conditional independence in your graph.",
            "I mean you basically have thrown away information by converting this into this, but from the point of view of the messages that get passed around on a computer algorithm, you can convert a directly graph into a factor graph and you know the algorithm will run correctly still.",
            "Alright, so here is a directed graph or Bayesian network or sometimes called a belief network.",
            "And it corresponds again to factorization of joint probability distribution.",
            "The joint distribution over these variables factors into a product of variables given their parents.",
            "As Chris already introduced.",
            "So the joint probability over X1 through XN is a product over each variable.",
            "The probability of each variable given its parents.",
            "So the parents.",
            "Of ERC&D right?"
        ],
        [
            "OK, so now it was very easy to determine independence in an undirected graph or a factor graph.",
            "It's also not very hard to do it, it's a notion of separation.",
            "In directed graphs we call this D separation for dependency separation.",
            "So the idea is if I have a directed graph, then X is independent of Y given V. If the set VD separates X from Y. OK.",
            "So how do we determine whether VD separates X from Y?",
            "Well.",
            "These these separates X from Y if every undirected path between X&Y is blocked by V. So we're basically, I mean the way I like to think about this intuitively is that we're trying to see whether information from X can get to Y and vice versa without getting blocked by V. If V blocks all information that can get from X to Y and vice versa.",
            "Then X&Y are independent, given Phi.",
            "So.",
            "So we need to consider every undirected path alright.",
            "What's an undirected path?",
            "Well, if I have a graph like this, I can consider paths on this graph that can go either with the direction of the arrows or against the direction of the arrows.",
            "That would be like a CED would be an undirected path, right?",
            "Because I go sometimes again, sometimes with the direction of the arrow.",
            "So I need to check whether it's blocked by V. And the way it's going to be blocked by V is.",
            "A path is blocked by V if there is some node W on the path such that either one of these two conditions holds.",
            "So W has converging arrows along the path.",
            "So in other words, you go into West.",
            "Along the arrow and then you go out of W against the arrow and I neither W nor is descendants are observed in V. In other words, observed just means conditioned on, in, in V or W does not have converging arrows along the path.",
            "And W. Is observed, so it's an element of the.",
            "OK, so this is slightly, you know, it's like I don't.",
            "If you haven't seen this before, I don't.",
            "Expect you to look at this immediately and say, haha, that makes perfect sense.",
            "OK, it's a slightly slightly involved definition, but there are only really two kinds of conditions and after a while you can look at these graphs and determine that fairly easily.",
            "I'll give you a couple of examples in a minute as well.",
            "Yep, question just curious about the direct cross.",
            "Is there any other any theorems we say?",
            "Any directed graph can be converted to a photograph or I'll talk about that.",
            "Yeah, I mean you can convert between these representations always, but what you might get is losing.",
            "You might lose some things that were represented in one thing into another thing, OK?",
            "Without losing is more tricky so.",
            "So no, any directed graph cannot be converted into a factor graph without losing by.",
            "By this property here, this is the simplest directed graph.",
            "OK, which has the property that these two variables are marginally independent but conditionally dependent, and there is no factor graph over three variables that captures exactly those independence properties, so that's a counterexample for that proof, OK?",
            "Yep.",
            "Transformation factor graphs from invading it, and then you have that example of factor having three variables, yet which is another form, right?",
            "Represented independently, but can can modify your CPT situated.",
            "Yeah, so the question is, can you still do it?",
            "I mean modify your CPT so that you capture the same.",
            "You can capture the same probability distribution, but the form of the graph will not capture the same conditional independence structures OK.",
            "So OK, so this was the dependency separation definition.",
            "To check whether two things are conditionally independent or not, just."
        ],
        [
            "Show a couple of examples which you can read up afterwards if you want.",
            "Here is a graph.",
            "Now A is independent of B.",
            "Marginally so conditioned on nothing, since let's consider all the paths between A&BACB is blocked.",
            "Bye see I have blocked one because that means blocked according to condition one.",
            "OK there is something with converging arrows and it's not observed so C has converging arrows and it's not observed right?",
            "It's not being conditioned on so ACB is blocked ACDB is blocked by D for the same reason etc.",
            "Every path between these two is blocked.",
            "OK, so a is independent of of B.",
            "Marginally, but it's not true that a is independent of B given C, since ASB this path here is not blocked.",
            "OK. A is independent of the given B&C.",
            "Again, a is independent of D given B&C.",
            "You kind of see that these two things would block a alpass from A&D.",
            "If you've looked at these graphs long enough, but you can check them by checking all of these properties OK. And again, something that Chris mentioned as well.",
            "Note that it's the absence of edges that conveys conditional independence OK?"
        ],
        [
            "Alright, so here is to answer your question about converting between different representations.",
            "You can always convert from a directed tree to an undirected tree that has equivalent.",
            "Dependence structure.",
            "OK, so I'm not proving this, I'm just showing you an example with seven nodes.",
            "If you're not a mathematician, that's almost a proof.",
            "OK, so here is an example of a tree with seven nodes.",
            "This corresponds to.",
            "This factorization of the joint distribution over those seven variables, we can write this in terms.",
            "Each of these conditional distributions we can write it as.",
            "A.",
            "Joint over the marginal.",
            "The thing you're conditioning on, so probability of X1 given X3 can be written as probability of X1 and X3 divided by the probability of X3.",
            "So essentially, if we rewrite this, we can think of each of these guys as.",
            "Cliques in an undirected graph.",
            "Some factors in an undirected graph.",
            "So G1 is a factor involving X1 and X3.",
            "Alright, so that's the factor involved in these two guys.",
            "G2 is a factor involving these two guys, etc.",
            "The things in the denominator we can stick into either of these factors that contain X3.",
            "It doesn't matter where we stick it in.",
            "OK, so now if we have this factorization, well that's a factor graph or undirected graph.",
            "Where the form of it is exactly.",
            "If it was an undirected graph, the form of it is exactly the same as this, except remove the arrowheads OK. And we can do this generally for any tree structured graph.",
            "But not for all graphs.",
            "Yep, question you mentioned the undirected graphs and factor graphs can capture some kinds of relationships which the directed ones can do and what Khan directed graphs capture.",
            "It's a couple of battery, so I'll show a slide at example of that in a bit OK.",
            "So there are things directed graphs, cat capture that undirected graphs can.",
            "Yes, so there there are not overlapping sort of sets of conditional dependencies.",
            "I'll just check.",
            "And there are things that both can capture, yes, and that's why we have other graphical formalisms.",
            "OK, if you write down for a set of variables, the set of all possible coherent conditional independence ease.",
            "That's very, very large, and the set of graphs of any of these formalisms is not large enough to capture all of that, but there are large enough to capture a lot of intuitive stuff, and that's why they've been useful."
        ],
        [
            "OK, so Chris already introduced this plate notation, so imagine we wanted to use a graphical model for a simple statistical model like N data points generated independently and identically from a Gaussian with mean mu and standard deviation Sigma.",
            "So the joint distribution over everything I've mentioned here is X one through XN.",
            "The data points mu for the mean and Sigma for the standard deviation.",
            "We could imagine a model where we have mu and Sigma in the model and then the the data points X one through XN are generated independently given mu and Sigma.",
            "Note that's the graphical model for independence given mu and Sigma, because there is no edge between X1 and X2.",
            "Given Mu and Sigma X1 and X2 and any other X is are independent of each other.",
            "So that's a graph corresponding to that little bit here that says ID OK. At because it's tedious to write X one X2 dot dot X and we have this plate notation where we just save X sub end with some.",
            "Indicator here of the index.",
            "So little N goes from say one to begin OK."
        ],
        [
            "So here is to answer the question on expressive power of directed undirected graphs.",
            "So I've already shown you that no undirected graph or factor graph exactly over these three variables can capture the independence ease the dependent structures captured by this little graph here.",
            "OK, now this graph here.",
            "Over 4 variables is an example of.",
            "Graph where no directed graph.",
            "Over 4 variables can represent these and only these in dependencies.",
            "OK, so the in dependencies we have in this graph are that.",
            "You know, let's call this.",
            "North and South are independent given East and West right?",
            "And vice versa.",
            "That East and West are independent given North and South.",
            "OK, and we can't do that by putting in directed edges in any way.",
            "You can try, but you'll fail, yeah?",
            "Yes, this really strictly speaking you can have errors going back to yourself and you can have errors between two nodes that goes into the action.",
            "Directed graphs are a cyclic.",
            "In other words, you can never have a loop that follows all the directions of the arrows and also some people find that unsatisfactory because they want to model dynamical systems or something like that.",
            "But in a dynamical system, a variable doesn't depend on itself.",
            "The variable at the.",
            "At the next point in time depends on that variable at the previous point in time.",
            "So we really don't have loops.",
            "We don't need loops.",
            "We can always represent things temporally as Chris did for the chess example by taking time and writing out the variables in sequence.",
            "OK."
        ],
        [
            "Alright, so I'm going to summarize the first half of this lecture.",
            "So we I showed you three different kinds of graphs.",
            "I talked about marginal conditional independence, Markov boundaries and separation, and then differences between directed and undirected graphs.",
            "We could take like not a break where everybody goes away but a two or three minutes stretch, break, and then I'll go into talking about exact inference and propagation algorithms.",
            "And then in following lectures on Tuesday, I'm going to introduce parameter and structure, learning graphs, and then I'm going to go to slightly more advanced topic which will bring together ideas from nonparametric Bayesian learning and graphical models and so on.",
            "Just to give you a more interesting flavor of current."
        ],
        [
            "Research and graphical models.",
            "So again, if you look at this thing, it's exactly the right thing.",
            "It's going to be up to normalization.",
            "The probability of X4 given X1 takes on the value a something out all the other variables."
        ],
        [
            "Now another way of understanding message passing is by thinking of operations on graphs.",
            "That eliminate variables.",
            "So let's say I'm interested in the probability distribution over X score.",
            "Can I do something to this graph?",
            "Over 4 variables such that I eliminate three out of four of those variables that I end up with the correct distribution of tax form.",
            "So these are called illumination rules, and you're not going to get anything particularly novel from doing this, other than maybe a different perspective on how to derive message passing methods OK.",
            "So if I have a graph like this, if I have some observed variables.",
            "What I could do is eliminate those variables.",
            "By doing the following, well, the variable X what is observed is values given, so it is constant in all it all factors that include that variable.",
            "OK, so I could take this factor F1, which was formerly a function of two things.",
            "Add set X12.",
            "It's observed constant value and now what is only a function of X21V.",
            "So then I will imitated value the variable X one.",
            "That's what you do to eliminate that variable graph.",
            "OK, so that's illuminating observed variables.",
            "I can also eliminate hidden variables not observed."
        ],
        [
            "Animals.",
            "If a variable X one is hidden or out of RXI is hidden or an observer, we're not interested in it, we can eliminate it from the graph by summing over its value.",
            "OK.",
            "So what does that correspond to?",
            "Let's say I have a joint distribution over all the variables.",
            "And I want to sum out XI.",
            "From that you're going to distribution over everything else.",
            "So I take this thing, the normalizing costs and then the sub over XI of this factorization that I had for that drug distribution.",
            "This corresponds to the product over all the factors.",
            "In my own translation.",
            "OK, so I'm going to send out XI.",
            "Now XI.",
            "Is a variable that participates in some of the factors but not in other factors.",
            "So let me just split it up this product into a product over factors that are not neighbors of XI.",
            "These factors don't depend on XI at all, and these factors in blue do depend on XI, so.",
            "Factor K is a neighbor of inside, alright, so about what I'm selling out.",
            "XII can just sum out over all these factors that do depend on that side.",
            "Alright.",
            "Now this thing in blue.",
            "Is a new function or a new factor?",
            "And this new factor.",
            "Is defined just to be this big in blue this is some function of a bunch of variables, But the set of variables that this new factor depends on is the union of the set of all of the variables.",
            "In the constituent factors.",
            "Removing I OK.",
            "So you take the union of all the variables you remove.",
            "I and you get this set here.",
            "So that was the elimination of a hidden variable, and this hidden variable when it's illuminated, it causes all this neighboring factor nodes to merge into one U factor node.",
            "So again, if we sorry if we go to this graph, if I eliminate X one because it's not observed.",
            "Then I create a new factor which is basically just a function of X2, so that's not a big problem, But if I eliminate X2.",
            "First, then I get a view factor that's a function of X, one X3 and X4.",
            "So the order in which I eliminate variables becomes important here in terms of efficiency of the algorithms.",
            "And I can apply these illumination rules to any graph.",
            "It does not have to be simply connected and is still valid.",
            "Alright, so that's just the.",
            "A little bit more than factor graph propagation and elimination rules.",
            "Let's talk about this in a more general historical context, permitted so.",
            "Yeah.",
            "Variables.",
            "It.",
            "It doesn't.",
            "It's not really central to.",
            "Belief propagation with active application you might help you understand things that you can do for doing inference.",
            "You could actually combine illumination with Packer graph propagation if you want to deal with.",
            "With lot we connected graphs.",
            "There might be interesting things you can do with it, but it's just basically to give you intuition for how.",
            "Also, for how to prove correct ways of doing inference in graphs.",
            "So elimination is is all we are doing with factor graph propagation and elimination and so on is operations that we know are correct.",
            "Given some assumptions.",
            "There's no magic.",
            "Basically we're just applying the basic rules of probability.",
            "Using our knowledge of conditional independence.",
            "We just try to do them efficiently, yes.",
            "Ordering.",
            "That's a very good question.",
            "I don't think it.",
            "I don't think it's possible to figure out the optimal ordering of illumination for general graph.",
            "Don't quote me on that, but it's NP complete.",
            "It's NP complete, right?",
            "For him.",
            "There are certainly heuristics.",
            "There are heuristics for figuring out orders of elimination.",
            "And yeah, that's fine.",
            "The nice thing about this applies to any graph unlike factor graph propagation, which is only exact trees."
        ],
        [
            "OK, so let me talk about a particular important class of graphs for time series.",
            "So consider a time series model where you have some hidden states.",
            "Hide is going in this direction, left to right.",
            "Yes, some hidden SpaceX one for XT and you have some observed variables Y one through YT and graphs of this kind directed graphs of this kind are ways of representing the conditional independence structure in hidden Markov models.",
            "And state space models or linear Gaussian dynamical systems, which are two of the most the most fundamental models for time series data.",
            "OK, so they both can be represented as a directed graph that looks like this, except that it hidden Markov models.",
            "The states are discrete, whereas linear Gaussian state space models the state variables are real Gaussian vectors, real valued Gaussian vector.",
            "So this is a single connected bag.",
            "Directed acyclic graph is also a tree.",
            "We can convert it into an undirected graph or a factor graph.",
            "And we have well known algorithms.",
            "For example, the forward backward algorithm in hidden Markov models is a message passing algorithm on this graph.",
            "The common smoothing algorithm, which just common filtering in the forward direction and then a backward pass of messages.",
            "For state space models, is another message passing graph and the nice thing from a historical perspective is that these things were independently invented, but they're all equivalent.",
            "OK, they're all just instances of belief propagation or factor graph propagation.",
            "So we can immediately generalize them to other architectures.",
            "Trees, tree structured architectures, etc.",
            "We don't have to stick the chains."
        ],
        [
            "And this wasn't really understood until about 15 years ago.",
            "Although these algorithms are more like.",
            "30 or 40 years old.",
            "For more.",
            "Alright, so.",
            "So what do we do if we have a multiply connected graph?",
            "Well, we've heard about loopy belief propagation already.",
            "I'm going to briefly mention Junction Tree algorithm not going to give you full tutorial on that.",
            "It would take much too long to do that.",
            "I talked about illumination algorithms, cutset conditioning and then their cuts at commissioning is where you take a particular variable an you condition it on different values.",
            "If you could find a set of variables such that the rest of the graph is simply connected, then you can condition over all the possible values in that set and get exact inference is over all of the variables, so again, I will talk in detail about that, and then there is a whole bunch of approximate inference methods that only 10 participants.",
            "So let me just talk to."
        ],
        [
            "Little bit about junction tree and then I'll wrap up.",
            "So very, very quickly the junction tree algorithm was developed as an exact inference algorithm for directed graphs of arbitrary topology and the basic idea is the following.",
            "You start with a directed graph."
        ],
        [
            "You do a step where you turn it into an undirected graph by something called moralizing.",
            "Which is marrying the sorry you start with this graph.",
            "This variable has two parents A&B you want to marry their parents.",
            "This is Terrence OK, so you've introduced an edge to marry the parents of seed.",
            "That's the moralization step, so we introduce another edge to marry C&B.",
            "So now you have this graph.",
            "You remove the edge directions so we have an undirected graph.",
            "So this results in an undirected graph where we haven't added any additional conditional independence relationships.",
            "OK, so we you know the worry would be converting into an undirected graph where we now have assumed something that is not true in our previous directly graph and we haven't added anything either."
        ],
        [
            "So now the next step is we need to do another graph operation which is called triangulation so that issues is this red edge, so there's no loop of length greater than three without the cord going across that move.",
            "So there was a loop of LED 4, then go back loop of lead four.",
            "We need to introduce accord along that loop.",
            "That's called triangulation.",
            "OK, that seems mysterious.",
            "Sort of is until you understand that is actually necessary, so the final junction tree that you end up with satisfies something known as a running intersection property in geometry.",
            "So that was triangulation and then.",
            "So yeah.",
            "Site.",
            "OK, why could we add this edge?",
            "Alright, so the worry is.",
            "If we.",
            "If we don't have an edge, then we.",
            "Then we need.",
            "Sorry if we yeah, if we don't have an edge that we need, then we've assumed and independence that wasn't true originally, OK. That's the worry.",
            "We can add edges because basically what they what they do is they.",
            "Allow.",
            "Sort of, if we add, let's take the extreme.",
            "If we Add all of the edges so the graph is fully connected, then that graph represents any possible probability distribution.",
            "There are no independencies in that distribution, so that graph is general enough to capture anything you want, but it's not very useful because that has one click with everything in one set of variables, so computations are exponential in the number of variables, so every time we added edge, we.",
            "Lose some of the representational power of our original graph and we make things less efficient.",
            "So we want to add a few entries as possible in this sort of sequence of transformations.",
            "We could have added the E as well, I think, yeah.",
            "So there are different different algorithms for triangulation and again, I think the optimal triangulation is.",
            "Probably also every completed area.",
            "But they're good heuristics.",
            "They're very good here.",
            "Thanks for doing this stuff.",
            "Alright, so I will be labor this too much.",
            "So now I have an undirected graph.",
            "What I'm going to do is I'm going to group variables together.",
            "Take 5, all the clicks, the clicks are the fully connected subgraphs, group them."
        ],
        [
            "Gather.",
            "That looks like this.",
            "ABC are this green dashed clique etc.",
            "So you."
        ],
        [
            "Liveleaks and then.",
            "I going to create these super variables which are products have their state space, is the product of all of the variables in each of the corresponding cliques.",
            "So AB&C were in one clique, so if they were binary, this variable now has eight possible states.",
            "QQ.",
            "So I have these.",
            "The clicks.",
            "And they have intersections because there are certain variables that are jointly appearing in neighboring cliques.",
            "And the point now is that I could take my cliques and form was called a junction tree.",
            "And the junction tree is a tree of overlapping sets of variables, and it's a tree importantly, so I can run a belief propagation algorithm on that tree, sending messages back and forth and I won't get this sort of problem of information coming from multiple sources, so that's the junction tree algorithm that converts it into this in.",
            "It's basically the same.",
            "Yeah, I think you know there might be different site different ways of implementing this, yeah?",
            "So the important thing is, yeah, so basically the state space of these variables.",
            "And a safe space of these variables overlap, so there are sort of hard constraints.",
            "There are factors that represent hard constraints between the settings of these variables in these variables.",
            "So equality constraints those have to be included in the junction.",
            "Pre tree algorithm.",
            "OK, so this mysterious triangulation thing had to be done so that if a variable appears in more than one click, it appears in all intermediate quick so that that variable doesn't get incoherent probabilities assigned to it from different parts of the graph.",
            "So that's what the.",
            "Relation is there for.",
            "Anyway, so this is down, junction tree propagation is algorithm for ensuring the neighboring cliques have consistent probability distributions in the same messages between them, and local consistency between these implies that global consistency of the whole probability distribution.",
            "That's all I'm going to say about Junction tree I'm running over now, but I think that's."
        ],
        [
            "Summary, So let me just summarize.",
            "So inference consists of the problem of computing the probability of variables of interest given some observed variables.",
            "I talked about belief propagation, a factor graph propagation, these are.",
            "Generalizations of classical things like common filtering or forward backward algorithms.",
            "And for multiply connected graphs I talked about the junction tree algorithm, which solves exact inference problem, but it can be very slow because it is exponential in the cardinality of the largest.",
            "Think that you end up with when you do this whole triangulation normalization.",
            "Add the possibility, but alright, so that's it for elite or today we're going to have lunch break with.",
            "You can ask a few questions today.",
            "Any questions?",
            "Everybody's hungry.",
            "Alright, alright so."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to follow on Ascentia.",
                    "label": 0
                },
                {
                    "sent": "Lee from Chris is great introduction an start to talk about graphical models and graphical models are going to be very fundamental to a lot of the things that you'll see throughout this summer school, so.",
                    "label": 0
                },
                {
                    "sent": "Hopefully.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This will be useful and I'm going to go into graphical models in a little bit more detail than Chris, but obviously I will be a little bit of overlap with the things he's already presented, so let me just go straight into it.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk about three main kinds of graphical models, factor graphs that Chris has mentioned already, undirected graphs and directed graphs.",
                    "label": 1
                },
                {
                    "sent": "And in all of these graphical models, the property they have is that the nodes correspond to random variables.",
                    "label": 1
                },
                {
                    "sent": "And the edges somehow represent statistical dependencies between these variables.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to talk about these three main kinds of graphical models, but that does not mean that there aren't other kinds of graphical models.",
                    "label": 0
                },
                {
                    "sent": "In fact, I'll mention something later on, but there's some other interesting kinds of graphical models that you know people actively do research on, but these are the ones that are most widely used right now.",
                    "label": 0
                },
                {
                    "sent": "So before I go into the technical details of how these graphical models work again, I want to give you just from my perspective, which is very similar to Chris is on this reasons for.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why we would want to use graphical models?",
                    "label": 0
                },
                {
                    "sent": "So, like Chris said, you know you could just have pages of equations defining our models, but graphs are first of all an intuitive way of representing and visualizing relationships between variables.",
                    "label": 0
                },
                {
                    "sent": "And these are things that we use commonly for all sorts of other uses.",
                    "label": 0
                },
                {
                    "sent": "We use graphs to represent family trees, electric circuit diagrams, connectivities of things like neural networks, etc.",
                    "label": 0
                },
                {
                    "sent": "But they're not just intuitive tools.",
                    "label": 0
                },
                {
                    "sent": "There are ways of abstracting properties of probability distributions, and in particular graph allows us to abstract out the conditional independence relationships between the variables from the details of their parametric forms.",
                    "label": 1
                },
                {
                    "sent": "So we can answer questions like is a dependent on B, given that we know the value of C just by looking at the graph without having to know what is the probability distribution of a.",
                    "label": 1
                },
                {
                    "sent": "Is it gamma Poisson, or is it?",
                    "label": 1
                },
                {
                    "sent": "You know this conditional probability table, whatever the details are abstracted away.",
                    "label": 0
                },
                {
                    "sent": "And finally, again, in a theme that you'll see several times, graphical models allow us to define general message passing algorithms that implement probabilistic inference efficiently, so we can answer queries like what is the probability of a given that C takes on the value little C without enumerating all the settings of the variables in the model.",
                    "label": 0
                },
                {
                    "sent": "We can answer it by passing messages in the graph, so that's just a summary of that.",
                    "label": 0
                },
                {
                    "sent": "That's just sort of elegant as well that graphical models really combine ideas from.",
                    "label": 0
                },
                {
                    "sent": "Statistics in terms of the conditional independence, some elementary graph theory and computer science in terms of the message passing object oriented algorithms that implement inference.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Graphical models fundamentally represent conditional independence.",
                    "label": 1
                },
                {
                    "sent": "So let me just spend a couple of minutes talking about conditional independence.",
                    "label": 0
                },
                {
                    "sent": "We're going to use the following notation, which actually I think Phil David introduced to statistics.",
                    "label": 0
                },
                {
                    "sent": "Many years ago, so X is conditionally independent from Y given V. That's what this sort of parallel lines here represent.",
                    "label": 0
                },
                {
                    "sent": "The independence.",
                    "label": 0
                },
                {
                    "sent": "Basically, that is equivalent to saying that the probability of X given Y&V is the probability of X given V wherever probability of Y&V is not strictly 0, because otherwise, then this is conditioning on an impossibility.",
                    "label": 0
                },
                {
                    "sent": "So that's a technical.",
                    "label": 0
                },
                {
                    "sent": "Condition here also X is independent of Y given V if the probability of X&Y given V factors into the probability of X given V and the probability of Y given V. OK.",
                    "label": 0
                },
                {
                    "sent": "So in general, we can think of conditional independence between sets of variables, so use this sort of curly notation for sex sets.",
                    "label": 1
                },
                {
                    "sent": "X is independent of Y, given V is this sort of factorization here.",
                    "label": 0
                },
                {
                    "sent": "And marginal independence.",
                    "label": 0
                },
                {
                    "sent": "This sort of usual form of independence that you know we first learn about is just independence with conditioning on the empty set.",
                    "label": 0
                },
                {
                    "sent": "OK, so X is independent of Y is the same as conditional independence given nothing and that just means that the joint distribution of X&Y factors into the distribution of X times this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reason of why?",
                    "label": 0
                },
                {
                    "sent": "OK, so why is conditional independence important?",
                    "label": 0
                },
                {
                    "sent": "And why is marginal independence important?",
                    "label": 0
                },
                {
                    "sent": "Well, it tells us what things depend on what other things and what things we can ignore and part of doing things efficiently is being able to ignore as many things as possible.",
                    "label": 0
                },
                {
                    "sent": "So conditional independence happens in all sorts of nice intuitive places, and I want to highlight conditional independence as opposed to marginal independence.",
                    "label": 0
                },
                {
                    "sent": "Here, so let's just look at some of these examples.",
                    "label": 0
                },
                {
                    "sent": "So the amount of a speeding fine is conditionally independent from the type of car that you're driving.",
                    "label": 1
                },
                {
                    "sent": "Given that speed that you were caught driving.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you're driving a Ferrari at 56 mph, you should get the same speeding fine as if you're driving a Fiat at 56 mph.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is a good example of thinking about marginal independence if you just.",
                    "label": 0
                },
                {
                    "sent": "Randomly went out and measured speeding fines and you measure types of cars that people were driving.",
                    "label": 0
                },
                {
                    "sent": "You would not find that these things are independent, right?",
                    "label": 0
                },
                {
                    "sent": "Ferrari drivers will get bigger speeding fines than Fiat drivers, OK?",
                    "label": 0
                },
                {
                    "sent": "So again, a classic example is, for example, smoking tends to make people's teeth yellow and is associated with lung cancer, but presumably lung cancer and yellow teeth are conditionally independent given if you know whether somebody is a smoker or not.",
                    "label": 0
                },
                {
                    "sent": "Now these are sort of classic things, but you can imagine conditional dependence being used in all sorts of other settings.",
                    "label": 0
                },
                {
                    "sent": "Where maybe you're sort of doing something like robotics or tracking.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's say you're modeling the dynamics of a system, and you measure the position and velocity and acceleration of that system overtime, and you draw out a model and then you could say, well, the state of the system, the position and velocity at time T plus one is actually independent of the position and velocity at T -- 1.",
                    "label": 0
                },
                {
                    "sent": "Given the state, the position and velocity at time T, and the acceleration at time T. OK. You could be doing genetic pedigree analysis and looking at children's genes.",
                    "label": 0
                },
                {
                    "sent": "Parents genes their grandparents genes and then you would want to use a conditional independence structure to be able to infer.",
                    "label": 0
                },
                {
                    "sent": "Geno, type of a particular individual given their ancestry.",
                    "label": 1
                },
                {
                    "sent": "And in a nice example that Chris showed, if we have two teams of players playing against each other, maybe a priore, their abilities are independent, but conditioned on the outcome of the game A versus B, the ability of team A and the ability of Team B become conditionally dependent.",
                    "label": 0
                },
                {
                    "sent": "So knowledge of the outcome informs us of both of these things in their dependent on each other.",
                    "label": 0
                },
                {
                    "sent": "OK, any questions about that?",
                    "label": 0
                },
                {
                    "sent": "Yep, what do we need conditional dependence independence here?",
                    "label": 0
                },
                {
                    "sent": "Why do you know?",
                    "label": 0
                },
                {
                    "sent": "Just say amount speeding fine doesn't depend on the type of the car.",
                    "label": 0
                },
                {
                    "sent": "Long concert, but the question is amount of speeding car doesn't depend on the type of of sorry amount of speeding fine doesn't depend on type of car.",
                    "label": 0
                },
                {
                    "sent": "You when you say that you have to say under what assumptions?",
                    "label": 0
                },
                {
                    "sent": "OK, So what do you know about what you know about the situation?",
                    "label": 0
                },
                {
                    "sent": "If you know that?",
                    "label": 0
                },
                {
                    "sent": "If you know the speed, it doesn't depend, but if you just go and measure these things.",
                    "label": 0
                },
                {
                    "sent": "Then there is a dependency.",
                    "label": 0
                },
                {
                    "sent": "You could plot the dependency between the two.",
                    "label": 0
                },
                {
                    "sent": "OK, so all notions of dependence and independence are really conditioned on a state of knowledge.",
                    "label": 0
                },
                {
                    "sent": "In some ways, these are representations of state of knowledge, not representations of necessarily physical things out there.",
                    "label": 0
                },
                {
                    "sent": "OK, and things can become dependent once you know something else.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So let me start talking about factor graphs again.",
                    "label": 0
                },
                {
                    "sent": "You've heard about this from Chris, so I'm going to go pretty quickly, hopefully.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you have two types of nodes in a factor graph.",
                    "label": 1
                },
                {
                    "sent": "The circles in effect represent random variables.",
                    "label": 0
                },
                {
                    "sent": "The squares or filled dots represent factors in the joint distribution.",
                    "label": 1
                },
                {
                    "sent": "So here are two different factor graphs over 5 variables, ABCD&E and factor.",
                    "label": 0
                },
                {
                    "sent": "Graph A represents this factorization of the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "So for example, G1 is a factor that relates A&C.",
                    "label": 0
                },
                {
                    "sent": "G2 relates BC and D and G3 relate CD&E this thing at the beginning.",
                    "label": 0
                },
                {
                    "sent": "Here is just a normalizing constant so.",
                    "label": 0
                },
                {
                    "sent": "What we have here is a probability distribution over these five quantities.",
                    "label": 1
                },
                {
                    "sent": "If we sum or integrate over all the variables that has to summer integrate to one.",
                    "label": 0
                },
                {
                    "sent": "So we need a normalizing constant to make sure that when we multiply the factors together and we sum it out, it sums to one as well.",
                    "label": 0
                },
                {
                    "sent": "OK, what are the factors the factors are functions of their arguments.",
                    "label": 0
                },
                {
                    "sent": "OK, so if A&C are binary variables.",
                    "label": 0
                },
                {
                    "sent": "This factor is a two by two table.",
                    "label": 0
                },
                {
                    "sent": "And so two by two table with non negative entries.",
                    "label": 0
                },
                {
                    "sent": "We don't want negative probabilities, otherwise nothing makes much sense.",
                    "label": 0
                },
                {
                    "sent": "OK, but we can allow the factors to have any non negative number in them.",
                    "label": 0
                },
                {
                    "sent": "'cause then we have a normalizing constant that ensures that things sum to one OK.",
                    "label": 1
                },
                {
                    "sent": "So this factor graph represents this factorization.",
                    "label": 0
                },
                {
                    "sent": "The factor graph B represents this factorization OK. And I think I've said all of these things.",
                    "label": 1
                },
                {
                    "sent": "Now two nodes are neighbors in a graph.",
                    "label": 0
                },
                {
                    "sent": "If they share a common factor.",
                    "label": 0
                },
                {
                    "sent": "So for example E&D are neighbors in the graph.",
                    "label": 0
                },
                {
                    "sent": "And E&D are neighbors in this graph.",
                    "label": 0
                },
                {
                    "sent": "OK, any questions?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I've just repeated some of these definitions here and we need to think about graph properties to understand the independent structure of these graphs.",
                    "label": 0
                },
                {
                    "sent": "So a path is a sequence of neighboring nodes.",
                    "label": 1
                },
                {
                    "sent": "For example, here a CDE is a path OK?",
                    "label": 0
                },
                {
                    "sent": "So how do we relate these factor graphs with independence structure?",
                    "label": 0
                },
                {
                    "sent": "So here is a basic fact that we're going to use.",
                    "label": 1
                },
                {
                    "sent": "X is independent of Y given V. If every path between X&Y contains some node V in V, OK, this is curly.",
                    "label": 0
                },
                {
                    "sent": "V is a set of variables.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Normal V is just a variable in that set.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So basically to figure out whether two variables are conditionally independent given some other set of variables, we have to consider all possible ways of getting from X to Y and see whether there in there is node V. On that path that separates X&Y.",
                    "label": 0
                },
                {
                    "sent": "OK, and in a minute we're going to be able to show how we prove these conditional independence properties, so it shouldn't be mysterious at all.",
                    "label": 0
                },
                {
                    "sent": "Now, given this fact, the corollary is that given the neighbors of a variable X, the variable X is conditionally independent of all other variables.",
                    "label": 1
                },
                {
                    "sent": "OK, so X is conditionally independent of Y given the neighbors of X for all Y that are neither X nor neighbor of X.",
                    "label": 0
                },
                {
                    "sent": "By all other variables.",
                    "label": 0
                },
                {
                    "sent": "OK, so for example.",
                    "label": 0
                },
                {
                    "sent": "Just yell it out.",
                    "label": 0
                },
                {
                    "sent": "What are the neighbors of E?",
                    "label": 0
                },
                {
                    "sent": "C&D so C. And so given.",
                    "label": 0
                },
                {
                    "sent": "C&DE is independent of B. OK. Now, how do we prove these things?",
                    "label": 0
                },
                {
                    "sent": "I mean this is this I just stated this as a fact, but we really would need to prove a theorem to show this and I'm not going to prove the theorem in a general form, but I'm just going to show you how you would prove it.",
                    "label": 0
                },
                {
                    "sent": "It's actually pretty straightforward.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's how you would prove conditional independence.",
                    "label": 0
                },
                {
                    "sent": "So assume we had the following factor graph.",
                    "label": 0
                },
                {
                    "sent": "We have X&V joined by Factor G1 and V&Y joined by Factor G2.",
                    "label": 0
                },
                {
                    "sent": "So that corresponds to this joint distribution factoring into one over normalizing constant G 1 * G Two OK, Now we want to be able to show.",
                    "label": 0
                },
                {
                    "sent": "The following conditional independence we want to be able to show that X is independent of Y given V. Alright, X is independent of Y given Phi.",
                    "label": 1
                },
                {
                    "sent": "So how do we show this, alright?",
                    "label": 0
                },
                {
                    "sent": "So starting from this.",
                    "label": 0
                },
                {
                    "sent": "We're going to show it algebraically.",
                    "label": 0
                },
                {
                    "sent": "We can actually now at this point ignore the graph, OK?",
                    "label": 0
                },
                {
                    "sent": "So take expression one.",
                    "label": 0
                },
                {
                    "sent": "An summit over the variable X, so I'm going to sum both the left hand side and the right hand side over X.",
                    "label": 0
                },
                {
                    "sent": "If I sum the left hand side over XI, get P of Y&V.",
                    "label": 0
                },
                {
                    "sent": "Write this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "Marginalizing out X is this joint distribution.",
                    "label": 0
                },
                {
                    "sent": "If I have some the right hand side over XI can bring that summation into this factor here, because this doesn't.",
                    "label": 0
                },
                {
                    "sent": "This is just a normalizing constant and this factor here doesn't depend on X OK. Now.",
                    "label": 0
                },
                {
                    "sent": "Take one and divide it by three.",
                    "label": 0
                },
                {
                    "sent": "So divide both the left hand and the right hand side of these two equations.",
                    "label": 0
                },
                {
                    "sent": "Where do we get the joint distribution of XY&V?",
                    "label": 0
                },
                {
                    "sent": "Dividing out the distribution of Y&V is the distribution of X given Y&V.",
                    "label": 0
                },
                {
                    "sent": "Case, that's the left hand side.",
                    "label": 0
                },
                {
                    "sent": "And if we take this thing here an we divide it by this thing.",
                    "label": 0
                },
                {
                    "sent": "Here the two normalizing constants here cancel.",
                    "label": 0
                },
                {
                    "sent": "We get G1 over this sum over X of G1 and this G2 cancels that G2.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So, so what's the big deal?",
                    "label": 0
                },
                {
                    "sent": "Alright, so we have an expression for X given Y&V.",
                    "label": 0
                },
                {
                    "sent": "And we have a form for that expression just on the basis of the factorization in the factor graph OK?",
                    "label": 0
                },
                {
                    "sent": "Now, here's the important thing.",
                    "label": 0
                },
                {
                    "sent": "The right hand side of this expression does not functionally depend on Y. OK.",
                    "label": 0
                },
                {
                    "sent": "So therefore it follows that the distribution of X given Y&V.",
                    "label": 0
                },
                {
                    "sent": "Does not depend on the value of Y. Alright, so this is what we were trying to prove that the distribution of X given Y&V is just the distribution of X given V and we just showed that this quantity here does not depend on the value of Y.",
                    "label": 0
                },
                {
                    "sent": "So we've basically shown that independence.",
                    "label": 0
                },
                {
                    "sent": "OK, so this basic idea, if you just take it very generally to any factor distribution, you write down the neighbors and so on.",
                    "label": 0
                },
                {
                    "sent": "You do the sums and so on.",
                    "label": 0
                },
                {
                    "sent": "Then you can prove.",
                    "label": 0
                },
                {
                    "sent": "The facts and the corollary is that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the previous slide.",
                    "label": 0
                },
                {
                    "sent": "OK, so that was factor graphs.",
                    "label": 0
                },
                {
                    "sent": "Now factor graphs are in some ways relatively modern invention.",
                    "label": 0
                },
                {
                    "sent": "Much older form of graphical model is the undirected graphical model, which is actually very very similar to factor graphs and we'll talk about the differences in a minute.",
                    "label": 0
                },
                {
                    "sent": "Undirected graphical models have been around.",
                    "label": 1
                },
                {
                    "sent": "For many decades there also known as Markov networks, there known as Markov random fields in computer vision and other fields.",
                    "label": 0
                },
                {
                    "sent": "And the basic idea in an undirected graphical model is also that the joint distribution over all variables can be written in a factored form.",
                    "label": 1
                },
                {
                    "sent": "So the joint distribution over variables X is one over some normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "The product of these factors, right?",
                    "label": 0
                },
                {
                    "sent": "Where the notation I'm using is that X sub CJ is just CJ is a subset of all of the nodes in the graph, so there K nodes in the graph or K variables.",
                    "label": 0
                },
                {
                    "sent": "CJ is the J subset of that corresponding to the J factor.",
                    "label": 0
                },
                {
                    "sent": "Here X of CJ is just take the subset of the vector indexed by CJ.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we have a factorization like this, then we can specify an undirected graph in the following way.",
                    "label": 1
                },
                {
                    "sent": "Create a node for each variable and then connect two nodes I&K if there is some set CJ such that both I is in that set CJ Anki's.",
                    "label": 0
                },
                {
                    "sent": "In that set CJ.",
                    "label": 0
                },
                {
                    "sent": "In other words, if there's some factor.",
                    "label": 1
                },
                {
                    "sent": "Where both ZYAN XC contribute both part of that factor.",
                    "label": 0
                },
                {
                    "sent": "So these sets form the cliques of the graph.",
                    "label": 0
                },
                {
                    "sent": "These are fully connected subgraphs.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's just look at one of these.",
                    "label": 0
                },
                {
                    "sent": "Here we have it.",
                    "label": 0
                },
                {
                    "sent": "It's an undirected graphical model.",
                    "label": 0
                },
                {
                    "sent": "The difference between this and factor graphs is that we're not explicitly representing those factors.",
                    "label": 0
                },
                {
                    "sent": "We're just directly connecting the nodes to each other with these undirected edges.",
                    "label": 0
                },
                {
                    "sent": "OK, so this undirected graphical model corresponds to this factorization of the joint distribution over these five variables.",
                    "label": 0
                },
                {
                    "sent": "Again, we have the fact that X is independent of Y given V if every path between X&Y contains some node in the set V. OK, again we have a corollary.",
                    "label": 0
                },
                {
                    "sent": "Given the neighbors of X, the variable X is conditionally independent of all other variables, just like in factor graphs.",
                    "label": 1
                },
                {
                    "sent": "And we can define, you know, a couple of other things the Markov blanket.",
                    "label": 0
                },
                {
                    "sent": "A Markov blanket is a set of variables for V. Sorry, V is a Markov blanket for X if and only if X is independent of Y.",
                    "label": 0
                },
                {
                    "sent": "Given V for all.",
                    "label": 0
                },
                {
                    "sent": "Why not in the Union of the set X&V?",
                    "label": 0
                },
                {
                    "sent": "Markov boundary is the minimal Markov blanket, so that's what makes you independent of everything else, and that's generally there's the neighbors of your node OK, and you can define these more generally for set.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Knows if you want.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I've introduced undirected graphs and factor graphs and they seem remarkably similar.",
                    "label": 1
                },
                {
                    "sent": "So what's the point?",
                    "label": 0
                },
                {
                    "sent": "What's the reason why we have these two things?",
                    "label": 0
                },
                {
                    "sent": "So one of them is historical, so undirected graphs have been around much longer than factor graphs.",
                    "label": 0
                },
                {
                    "sent": "That's why I think it's important for me to introduce them here.",
                    "label": 0
                },
                {
                    "sent": "But they don't represent exactly the same form.",
                    "label": 0
                },
                {
                    "sent": "Properties of distribution are forms of distribution.",
                    "label": 0
                },
                {
                    "sent": "Let's consider these three graphs AB&C all right.",
                    "label": 0
                },
                {
                    "sent": "The nodes in these graphs have exactly the same neighbors, right?",
                    "label": 1
                },
                {
                    "sent": "The neighbors of ERC&D in all three of these graphs.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Therefore, these three graphs represent exactly the same conditional independence relationships.",
                    "label": 1
                },
                {
                    "sent": "So as far as conditional dependence relationships go, they're not different.",
                    "label": 0
                },
                {
                    "sent": "But C here.",
                    "label": 0
                },
                {
                    "sent": "Also represents the fact that the probability factors into a product of pairwise functions.",
                    "label": 1
                },
                {
                    "sent": "So consider this factor here that connects EC&D.",
                    "label": 0
                },
                {
                    "sent": "In general, that's a function of three variables, OK, and here in the undirected graph we haven't explicitly represented the factor, so we generally need to have a function of these three variables to capture.",
                    "label": 0
                },
                {
                    "sent": "The relationships between these variables.",
                    "label": 0
                },
                {
                    "sent": "Whereas here it's explicitly shown that.",
                    "label": 0
                },
                {
                    "sent": "These three variables interact through pairwise functions.",
                    "label": 0
                },
                {
                    "sent": "Functions of two variables.",
                    "label": 0
                },
                {
                    "sent": "This is significant from the point of view of representation and implementation.",
                    "label": 0
                },
                {
                    "sent": "An message passing etc because.",
                    "label": 0
                },
                {
                    "sent": "If we just think of the variables as being discrete, let's say they take on K possible values, then the functions and A&B are generally tables of order K cubed elements, whereas the functions in CR tables all of order K squared, and more generally, if we have a bigger network with lots of interconnections, the factor graph might represent the forms of the functions more.",
                    "label": 0
                },
                {
                    "sent": "Compactly more succinctly than the undirected graph, because it can represent the fact that these functions are not necessarily functions of large sense, but they can be functions of small sets of variables.",
                    "label": 0
                },
                {
                    "sent": "Yep, there any qualitative properties of their kind of factorization.",
                    "label": 0
                },
                {
                    "sent": "I mean vector graphics press conditional independence, which is qualitative property of probability distributions from qualitatively in terms of probability distributions in terms of conditional independence.",
                    "label": 0
                },
                {
                    "sent": "They're going to be equivalent, OK, but but I mean it's fundamentally different to say that this distribution factors into product of pairwise functions or three way functions, or something like that.",
                    "label": 0
                },
                {
                    "sent": "It's a bit more fine grained representation if you write out each of the factors explicitly.",
                    "label": 0
                },
                {
                    "sent": "OK, yes.",
                    "label": 0
                },
                {
                    "sent": "That is subset.",
                    "label": 0
                },
                {
                    "sent": "Yes, the question was in particular here.",
                    "label": 0
                },
                {
                    "sent": "This is a subset of all distributions captured by this correct?",
                    "label": 0
                },
                {
                    "sent": "It's a qualitative.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so now why is that naughty?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Why can't we just use undirected graphs and factor graphs?",
                    "label": 0
                },
                {
                    "sent": "Well, the problem with undirected graphs and factor graphs is that.",
                    "label": 1
                },
                {
                    "sent": "Many useful in dependencies are not explicitly represented, so two variables have to be merely connected because some other variable depends on them.",
                    "label": 1
                },
                {
                    "sent": "Alright, so this is a classic example from Udaya Perl who wrote an important book on this topic.",
                    "label": 0
                },
                {
                    "sent": "Where he was thinking of, you know, this sort of life in California you have rained occasionally and you have sprinklers for watering your garden or lawn.",
                    "label": 0
                },
                {
                    "sent": "And both of these things can make the ground wet now.",
                    "label": 0
                },
                {
                    "sent": "Whether it rains or not, and whether your sprinkler is on or not might be marginally independent.",
                    "label": 0
                },
                {
                    "sent": "If your slinker is on a timer, for example, that is ignores the weather, but the ground being wet depends on both of these things.",
                    "label": 0
                },
                {
                    "sent": "So here we have a nice directed graph that represents these dependencies.",
                    "label": 0
                },
                {
                    "sent": "If we were representing these with a factor graph or an undirected graph, we would have to join up all three of these variables into a.",
                    "label": 0
                },
                {
                    "sent": "Single factor or put this undirected edge between these two OK, why do we have to put this undirected edge here?",
                    "label": 0
                },
                {
                    "sent": "Because if we didn't put this undirected edge, what would it mean?",
                    "label": 0
                },
                {
                    "sent": "Well, the graph would look like this.",
                    "label": 0
                },
                {
                    "sent": "That would mean observing the ground was wet.",
                    "label": 0
                },
                {
                    "sent": "Would make the probability of it having rained or the sprinkler being an independent, and that's not true if we observe the ground is wet then there are two reasonable explanations.",
                    "label": 0
                },
                {
                    "sent": "Either it rained or the sprinklers on maybe both.",
                    "label": 0
                },
                {
                    "sent": "But certainly these two variables are not independent of each other.",
                    "label": 0
                },
                {
                    "sent": "They're conditionally dependent given this, so it's a bit annoying in these undirected representations that you have to connect up lots of things that are not a priority related just because something else depends on them.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And this also sort of explains it's a way of mentioning the whole idea of explaining away if you have multiple explanations for something.",
                    "label": 0
                },
                {
                    "sent": "Observing that the cplink sprinkler is on would explain away the observation to the ground was wet, making it less probable that it rained.",
                    "label": 1
                },
                {
                    "sent": "OK, so there is a complicated dependency between causes and effects that.",
                    "label": 0
                },
                {
                    "sent": "Is well captured by directed representations.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me now talk about directed graphical models which go by several names.",
                    "label": 0
                },
                {
                    "sent": "We could call them directed acyclic graphical models or Bayesian networks, although there is a footnote here 'cause you can do maximum likelihood or frequentist learning of Bayesian networks.",
                    "label": 1
                },
                {
                    "sent": "So yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Make use of.",
                    "label": 0
                },
                {
                    "sent": "This kind of.",
                    "label": 0
                },
                {
                    "sent": "So the question is, are there inference algorithms that make use of this kind of conditional independence?",
                    "label": 0
                },
                {
                    "sent": "Yes, so in fact the message passing or belief propagation algorithms are really making trying to make use of conditional independence.",
                    "label": 1
                },
                {
                    "sent": "The form of the belief propagation algorithm is slightly different for directed graphs than factor graphs.",
                    "label": 0
                },
                {
                    "sent": "It turns out not to make a big not to make it practical.",
                    "label": 0
                },
                {
                    "sent": "Difference so.",
                    "label": 0
                },
                {
                    "sent": "Well, it's important if it's important.",
                    "label": 0
                },
                {
                    "sent": "If you want to have a representation of conditional independence in your graph.",
                    "label": 0
                },
                {
                    "sent": "I mean you basically have thrown away information by converting this into this, but from the point of view of the messages that get passed around on a computer algorithm, you can convert a directly graph into a factor graph and you know the algorithm will run correctly still.",
                    "label": 0
                },
                {
                    "sent": "Alright, so here is a directed graph or Bayesian network or sometimes called a belief network.",
                    "label": 1
                },
                {
                    "sent": "And it corresponds again to factorization of joint probability distribution.",
                    "label": 0
                },
                {
                    "sent": "The joint distribution over these variables factors into a product of variables given their parents.",
                    "label": 1
                },
                {
                    "sent": "As Chris already introduced.",
                    "label": 0
                },
                {
                    "sent": "So the joint probability over X1 through XN is a product over each variable.",
                    "label": 0
                },
                {
                    "sent": "The probability of each variable given its parents.",
                    "label": 0
                },
                {
                    "sent": "So the parents.",
                    "label": 0
                },
                {
                    "sent": "Of ERC&D right?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now it was very easy to determine independence in an undirected graph or a factor graph.",
                    "label": 0
                },
                {
                    "sent": "It's also not very hard to do it, it's a notion of separation.",
                    "label": 0
                },
                {
                    "sent": "In directed graphs we call this D separation for dependency separation.",
                    "label": 0
                },
                {
                    "sent": "So the idea is if I have a directed graph, then X is independent of Y given V. If the set VD separates X from Y. OK.",
                    "label": 0
                },
                {
                    "sent": "So how do we determine whether VD separates X from Y?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "These these separates X from Y if every undirected path between X&Y is blocked by V. So we're basically, I mean the way I like to think about this intuitively is that we're trying to see whether information from X can get to Y and vice versa without getting blocked by V. If V blocks all information that can get from X to Y and vice versa.",
                    "label": 1
                },
                {
                    "sent": "Then X&Y are independent, given Phi.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So we need to consider every undirected path alright.",
                    "label": 0
                },
                {
                    "sent": "What's an undirected path?",
                    "label": 0
                },
                {
                    "sent": "Well, if I have a graph like this, I can consider paths on this graph that can go either with the direction of the arrows or against the direction of the arrows.",
                    "label": 0
                },
                {
                    "sent": "That would be like a CED would be an undirected path, right?",
                    "label": 0
                },
                {
                    "sent": "Because I go sometimes again, sometimes with the direction of the arrow.",
                    "label": 0
                },
                {
                    "sent": "So I need to check whether it's blocked by V. And the way it's going to be blocked by V is.",
                    "label": 0
                },
                {
                    "sent": "A path is blocked by V if there is some node W on the path such that either one of these two conditions holds.",
                    "label": 1
                },
                {
                    "sent": "So W has converging arrows along the path.",
                    "label": 0
                },
                {
                    "sent": "So in other words, you go into West.",
                    "label": 0
                },
                {
                    "sent": "Along the arrow and then you go out of W against the arrow and I neither W nor is descendants are observed in V. In other words, observed just means conditioned on, in, in V or W does not have converging arrows along the path.",
                    "label": 1
                },
                {
                    "sent": "And W. Is observed, so it's an element of the.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is slightly, you know, it's like I don't.",
                    "label": 0
                },
                {
                    "sent": "If you haven't seen this before, I don't.",
                    "label": 0
                },
                {
                    "sent": "Expect you to look at this immediately and say, haha, that makes perfect sense.",
                    "label": 0
                },
                {
                    "sent": "OK, it's a slightly slightly involved definition, but there are only really two kinds of conditions and after a while you can look at these graphs and determine that fairly easily.",
                    "label": 0
                },
                {
                    "sent": "I'll give you a couple of examples in a minute as well.",
                    "label": 0
                },
                {
                    "sent": "Yep, question just curious about the direct cross.",
                    "label": 0
                },
                {
                    "sent": "Is there any other any theorems we say?",
                    "label": 0
                },
                {
                    "sent": "Any directed graph can be converted to a photograph or I'll talk about that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean you can convert between these representations always, but what you might get is losing.",
                    "label": 0
                },
                {
                    "sent": "You might lose some things that were represented in one thing into another thing, OK?",
                    "label": 0
                },
                {
                    "sent": "Without losing is more tricky so.",
                    "label": 0
                },
                {
                    "sent": "So no, any directed graph cannot be converted into a factor graph without losing by.",
                    "label": 0
                },
                {
                    "sent": "By this property here, this is the simplest directed graph.",
                    "label": 0
                },
                {
                    "sent": "OK, which has the property that these two variables are marginally independent but conditionally dependent, and there is no factor graph over three variables that captures exactly those independence properties, so that's a counterexample for that proof, OK?",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Transformation factor graphs from invading it, and then you have that example of factor having three variables, yet which is another form, right?",
                    "label": 0
                },
                {
                    "sent": "Represented independently, but can can modify your CPT situated.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the question is, can you still do it?",
                    "label": 0
                },
                {
                    "sent": "I mean modify your CPT so that you capture the same.",
                    "label": 0
                },
                {
                    "sent": "You can capture the same probability distribution, but the form of the graph will not capture the same conditional independence structures OK.",
                    "label": 0
                },
                {
                    "sent": "So OK, so this was the dependency separation definition.",
                    "label": 0
                },
                {
                    "sent": "To check whether two things are conditionally independent or not, just.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Show a couple of examples which you can read up afterwards if you want.",
                    "label": 0
                },
                {
                    "sent": "Here is a graph.",
                    "label": 0
                },
                {
                    "sent": "Now A is independent of B.",
                    "label": 0
                },
                {
                    "sent": "Marginally so conditioned on nothing, since let's consider all the paths between A&BACB is blocked.",
                    "label": 0
                },
                {
                    "sent": "Bye see I have blocked one because that means blocked according to condition one.",
                    "label": 0
                },
                {
                    "sent": "OK there is something with converging arrows and it's not observed so C has converging arrows and it's not observed right?",
                    "label": 0
                },
                {
                    "sent": "It's not being conditioned on so ACB is blocked ACDB is blocked by D for the same reason etc.",
                    "label": 0
                },
                {
                    "sent": "Every path between these two is blocked.",
                    "label": 0
                },
                {
                    "sent": "OK, so a is independent of of B.",
                    "label": 0
                },
                {
                    "sent": "Marginally, but it's not true that a is independent of B given C, since ASB this path here is not blocked.",
                    "label": 1
                },
                {
                    "sent": "OK. A is independent of the given B&C.",
                    "label": 0
                },
                {
                    "sent": "Again, a is independent of D given B&C.",
                    "label": 0
                },
                {
                    "sent": "You kind of see that these two things would block a alpass from A&D.",
                    "label": 0
                },
                {
                    "sent": "If you've looked at these graphs long enough, but you can check them by checking all of these properties OK. And again, something that Chris mentioned as well.",
                    "label": 0
                },
                {
                    "sent": "Note that it's the absence of edges that conveys conditional independence OK?",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so here is to answer your question about converting between different representations.",
                    "label": 0
                },
                {
                    "sent": "You can always convert from a directed tree to an undirected tree that has equivalent.",
                    "label": 1
                },
                {
                    "sent": "Dependence structure.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm not proving this, I'm just showing you an example with seven nodes.",
                    "label": 0
                },
                {
                    "sent": "If you're not a mathematician, that's almost a proof.",
                    "label": 0
                },
                {
                    "sent": "OK, so here is an example of a tree with seven nodes.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to.",
                    "label": 0
                },
                {
                    "sent": "This factorization of the joint distribution over those seven variables, we can write this in terms.",
                    "label": 0
                },
                {
                    "sent": "Each of these conditional distributions we can write it as.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "Joint over the marginal.",
                    "label": 0
                },
                {
                    "sent": "The thing you're conditioning on, so probability of X1 given X3 can be written as probability of X1 and X3 divided by the probability of X3.",
                    "label": 0
                },
                {
                    "sent": "So essentially, if we rewrite this, we can think of each of these guys as.",
                    "label": 0
                },
                {
                    "sent": "Cliques in an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "Some factors in an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "So G1 is a factor involving X1 and X3.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's the factor involved in these two guys.",
                    "label": 0
                },
                {
                    "sent": "G2 is a factor involving these two guys, etc.",
                    "label": 0
                },
                {
                    "sent": "The things in the denominator we can stick into either of these factors that contain X3.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter where we stick it in.",
                    "label": 0
                },
                {
                    "sent": "OK, so now if we have this factorization, well that's a factor graph or undirected graph.",
                    "label": 0
                },
                {
                    "sent": "Where the form of it is exactly.",
                    "label": 0
                },
                {
                    "sent": "If it was an undirected graph, the form of it is exactly the same as this, except remove the arrowheads OK. And we can do this generally for any tree structured graph.",
                    "label": 0
                },
                {
                    "sent": "But not for all graphs.",
                    "label": 0
                },
                {
                    "sent": "Yep, question you mentioned the undirected graphs and factor graphs can capture some kinds of relationships which the directed ones can do and what Khan directed graphs capture.",
                    "label": 0
                },
                {
                    "sent": "It's a couple of battery, so I'll show a slide at example of that in a bit OK.",
                    "label": 0
                },
                {
                    "sent": "So there are things directed graphs, cat capture that undirected graphs can.",
                    "label": 0
                },
                {
                    "sent": "Yes, so there there are not overlapping sort of sets of conditional dependencies.",
                    "label": 0
                },
                {
                    "sent": "I'll just check.",
                    "label": 0
                },
                {
                    "sent": "And there are things that both can capture, yes, and that's why we have other graphical formalisms.",
                    "label": 1
                },
                {
                    "sent": "OK, if you write down for a set of variables, the set of all possible coherent conditional independence ease.",
                    "label": 0
                },
                {
                    "sent": "That's very, very large, and the set of graphs of any of these formalisms is not large enough to capture all of that, but there are large enough to capture a lot of intuitive stuff, and that's why they've been useful.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so Chris already introduced this plate notation, so imagine we wanted to use a graphical model for a simple statistical model like N data points generated independently and identically from a Gaussian with mean mu and standard deviation Sigma.",
                    "label": 1
                },
                {
                    "sent": "So the joint distribution over everything I've mentioned here is X one through XN.",
                    "label": 0
                },
                {
                    "sent": "The data points mu for the mean and Sigma for the standard deviation.",
                    "label": 0
                },
                {
                    "sent": "We could imagine a model where we have mu and Sigma in the model and then the the data points X one through XN are generated independently given mu and Sigma.",
                    "label": 0
                },
                {
                    "sent": "Note that's the graphical model for independence given mu and Sigma, because there is no edge between X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "Given Mu and Sigma X1 and X2 and any other X is are independent of each other.",
                    "label": 0
                },
                {
                    "sent": "So that's a graph corresponding to that little bit here that says ID OK. At because it's tedious to write X one X2 dot dot X and we have this plate notation where we just save X sub end with some.",
                    "label": 0
                },
                {
                    "sent": "Indicator here of the index.",
                    "label": 0
                },
                {
                    "sent": "So little N goes from say one to begin OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is to answer the question on expressive power of directed undirected graphs.",
                    "label": 1
                },
                {
                    "sent": "So I've already shown you that no undirected graph or factor graph exactly over these three variables can capture the independence ease the dependent structures captured by this little graph here.",
                    "label": 0
                },
                {
                    "sent": "OK, now this graph here.",
                    "label": 1
                },
                {
                    "sent": "Over 4 variables is an example of.",
                    "label": 0
                },
                {
                    "sent": "Graph where no directed graph.",
                    "label": 0
                },
                {
                    "sent": "Over 4 variables can represent these and only these in dependencies.",
                    "label": 1
                },
                {
                    "sent": "OK, so the in dependencies we have in this graph are that.",
                    "label": 0
                },
                {
                    "sent": "You know, let's call this.",
                    "label": 0
                },
                {
                    "sent": "North and South are independent given East and West right?",
                    "label": 0
                },
                {
                    "sent": "And vice versa.",
                    "label": 0
                },
                {
                    "sent": "That East and West are independent given North and South.",
                    "label": 1
                },
                {
                    "sent": "OK, and we can't do that by putting in directed edges in any way.",
                    "label": 0
                },
                {
                    "sent": "You can try, but you'll fail, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yes, this really strictly speaking you can have errors going back to yourself and you can have errors between two nodes that goes into the action.",
                    "label": 0
                },
                {
                    "sent": "Directed graphs are a cyclic.",
                    "label": 0
                },
                {
                    "sent": "In other words, you can never have a loop that follows all the directions of the arrows and also some people find that unsatisfactory because they want to model dynamical systems or something like that.",
                    "label": 0
                },
                {
                    "sent": "But in a dynamical system, a variable doesn't depend on itself.",
                    "label": 0
                },
                {
                    "sent": "The variable at the.",
                    "label": 0
                },
                {
                    "sent": "At the next point in time depends on that variable at the previous point in time.",
                    "label": 0
                },
                {
                    "sent": "So we really don't have loops.",
                    "label": 0
                },
                {
                    "sent": "We don't need loops.",
                    "label": 0
                },
                {
                    "sent": "We can always represent things temporally as Chris did for the chess example by taking time and writing out the variables in sequence.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so I'm going to summarize the first half of this lecture.",
                    "label": 0
                },
                {
                    "sent": "So we I showed you three different kinds of graphs.",
                    "label": 0
                },
                {
                    "sent": "I talked about marginal conditional independence, Markov boundaries and separation, and then differences between directed and undirected graphs.",
                    "label": 1
                },
                {
                    "sent": "We could take like not a break where everybody goes away but a two or three minutes stretch, break, and then I'll go into talking about exact inference and propagation algorithms.",
                    "label": 0
                },
                {
                    "sent": "And then in following lectures on Tuesday, I'm going to introduce parameter and structure, learning graphs, and then I'm going to go to slightly more advanced topic which will bring together ideas from nonparametric Bayesian learning and graphical models and so on.",
                    "label": 0
                },
                {
                    "sent": "Just to give you a more interesting flavor of current.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Research and graphical models.",
                    "label": 0
                },
                {
                    "sent": "So again, if you look at this thing, it's exactly the right thing.",
                    "label": 0
                },
                {
                    "sent": "It's going to be up to normalization.",
                    "label": 0
                },
                {
                    "sent": "The probability of X4 given X1 takes on the value a something out all the other variables.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now another way of understanding message passing is by thinking of operations on graphs.",
                    "label": 0
                },
                {
                    "sent": "That eliminate variables.",
                    "label": 0
                },
                {
                    "sent": "So let's say I'm interested in the probability distribution over X score.",
                    "label": 0
                },
                {
                    "sent": "Can I do something to this graph?",
                    "label": 0
                },
                {
                    "sent": "Over 4 variables such that I eliminate three out of four of those variables that I end up with the correct distribution of tax form.",
                    "label": 0
                },
                {
                    "sent": "So these are called illumination rules, and you're not going to get anything particularly novel from doing this, other than maybe a different perspective on how to derive message passing methods OK.",
                    "label": 0
                },
                {
                    "sent": "So if I have a graph like this, if I have some observed variables.",
                    "label": 0
                },
                {
                    "sent": "What I could do is eliminate those variables.",
                    "label": 0
                },
                {
                    "sent": "By doing the following, well, the variable X what is observed is values given, so it is constant in all it all factors that include that variable.",
                    "label": 1
                },
                {
                    "sent": "OK, so I could take this factor F1, which was formerly a function of two things.",
                    "label": 0
                },
                {
                    "sent": "Add set X12.",
                    "label": 0
                },
                {
                    "sent": "It's observed constant value and now what is only a function of X21V.",
                    "label": 0
                },
                {
                    "sent": "So then I will imitated value the variable X one.",
                    "label": 0
                },
                {
                    "sent": "That's what you do to eliminate that variable graph.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's illuminating observed variables.",
                    "label": 0
                },
                {
                    "sent": "I can also eliminate hidden variables not observed.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Animals.",
                    "label": 0
                },
                {
                    "sent": "If a variable X one is hidden or out of RXI is hidden or an observer, we're not interested in it, we can eliminate it from the graph by summing over its value.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So what does that correspond to?",
                    "label": 0
                },
                {
                    "sent": "Let's say I have a joint distribution over all the variables.",
                    "label": 0
                },
                {
                    "sent": "And I want to sum out XI.",
                    "label": 0
                },
                {
                    "sent": "From that you're going to distribution over everything else.",
                    "label": 0
                },
                {
                    "sent": "So I take this thing, the normalizing costs and then the sub over XI of this factorization that I had for that drug distribution.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to the product over all the factors.",
                    "label": 0
                },
                {
                    "sent": "In my own translation.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to send out XI.",
                    "label": 0
                },
                {
                    "sent": "Now XI.",
                    "label": 0
                },
                {
                    "sent": "Is a variable that participates in some of the factors but not in other factors.",
                    "label": 0
                },
                {
                    "sent": "So let me just split it up this product into a product over factors that are not neighbors of XI.",
                    "label": 0
                },
                {
                    "sent": "These factors don't depend on XI at all, and these factors in blue do depend on XI, so.",
                    "label": 0
                },
                {
                    "sent": "Factor K is a neighbor of inside, alright, so about what I'm selling out.",
                    "label": 0
                },
                {
                    "sent": "XII can just sum out over all these factors that do depend on that side.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Now this thing in blue.",
                    "label": 0
                },
                {
                    "sent": "Is a new function or a new factor?",
                    "label": 0
                },
                {
                    "sent": "And this new factor.",
                    "label": 0
                },
                {
                    "sent": "Is defined just to be this big in blue this is some function of a bunch of variables, But the set of variables that this new factor depends on is the union of the set of all of the variables.",
                    "label": 0
                },
                {
                    "sent": "In the constituent factors.",
                    "label": 0
                },
                {
                    "sent": "Removing I OK.",
                    "label": 0
                },
                {
                    "sent": "So you take the union of all the variables you remove.",
                    "label": 0
                },
                {
                    "sent": "I and you get this set here.",
                    "label": 1
                },
                {
                    "sent": "So that was the elimination of a hidden variable, and this hidden variable when it's illuminated, it causes all this neighboring factor nodes to merge into one U factor node.",
                    "label": 0
                },
                {
                    "sent": "So again, if we sorry if we go to this graph, if I eliminate X one because it's not observed.",
                    "label": 0
                },
                {
                    "sent": "Then I create a new factor which is basically just a function of X2, so that's not a big problem, But if I eliminate X2.",
                    "label": 0
                },
                {
                    "sent": "First, then I get a view factor that's a function of X, one X3 and X4.",
                    "label": 0
                },
                {
                    "sent": "So the order in which I eliminate variables becomes important here in terms of efficiency of the algorithms.",
                    "label": 0
                },
                {
                    "sent": "And I can apply these illumination rules to any graph.",
                    "label": 0
                },
                {
                    "sent": "It does not have to be simply connected and is still valid.",
                    "label": 0
                },
                {
                    "sent": "Alright, so that's just the.",
                    "label": 0
                },
                {
                    "sent": "A little bit more than factor graph propagation and elimination rules.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about this in a more general historical context, permitted so.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Variables.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                },
                {
                    "sent": "It doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's not really central to.",
                    "label": 0
                },
                {
                    "sent": "Belief propagation with active application you might help you understand things that you can do for doing inference.",
                    "label": 0
                },
                {
                    "sent": "You could actually combine illumination with Packer graph propagation if you want to deal with.",
                    "label": 0
                },
                {
                    "sent": "With lot we connected graphs.",
                    "label": 0
                },
                {
                    "sent": "There might be interesting things you can do with it, but it's just basically to give you intuition for how.",
                    "label": 0
                },
                {
                    "sent": "Also, for how to prove correct ways of doing inference in graphs.",
                    "label": 0
                },
                {
                    "sent": "So elimination is is all we are doing with factor graph propagation and elimination and so on is operations that we know are correct.",
                    "label": 0
                },
                {
                    "sent": "Given some assumptions.",
                    "label": 0
                },
                {
                    "sent": "There's no magic.",
                    "label": 0
                },
                {
                    "sent": "Basically we're just applying the basic rules of probability.",
                    "label": 0
                },
                {
                    "sent": "Using our knowledge of conditional independence.",
                    "label": 0
                },
                {
                    "sent": "We just try to do them efficiently, yes.",
                    "label": 0
                },
                {
                    "sent": "Ordering.",
                    "label": 0
                },
                {
                    "sent": "That's a very good question.",
                    "label": 0
                },
                {
                    "sent": "I don't think it.",
                    "label": 0
                },
                {
                    "sent": "I don't think it's possible to figure out the optimal ordering of illumination for general graph.",
                    "label": 0
                },
                {
                    "sent": "Don't quote me on that, but it's NP complete.",
                    "label": 0
                },
                {
                    "sent": "It's NP complete, right?",
                    "label": 0
                },
                {
                    "sent": "For him.",
                    "label": 0
                },
                {
                    "sent": "There are certainly heuristics.",
                    "label": 0
                },
                {
                    "sent": "There are heuristics for figuring out orders of elimination.",
                    "label": 0
                },
                {
                    "sent": "And yeah, that's fine.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about this applies to any graph unlike factor graph propagation, which is only exact trees.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me talk about a particular important class of graphs for time series.",
                    "label": 0
                },
                {
                    "sent": "So consider a time series model where you have some hidden states.",
                    "label": 0
                },
                {
                    "sent": "Hide is going in this direction, left to right.",
                    "label": 0
                },
                {
                    "sent": "Yes, some hidden SpaceX one for XT and you have some observed variables Y one through YT and graphs of this kind directed graphs of this kind are ways of representing the conditional independence structure in hidden Markov models.",
                    "label": 0
                },
                {
                    "sent": "And state space models or linear Gaussian dynamical systems, which are two of the most the most fundamental models for time series data.",
                    "label": 0
                },
                {
                    "sent": "OK, so they both can be represented as a directed graph that looks like this, except that it hidden Markov models.",
                    "label": 1
                },
                {
                    "sent": "The states are discrete, whereas linear Gaussian state space models the state variables are real Gaussian vectors, real valued Gaussian vector.",
                    "label": 1
                },
                {
                    "sent": "So this is a single connected bag.",
                    "label": 0
                },
                {
                    "sent": "Directed acyclic graph is also a tree.",
                    "label": 0
                },
                {
                    "sent": "We can convert it into an undirected graph or a factor graph.",
                    "label": 1
                },
                {
                    "sent": "And we have well known algorithms.",
                    "label": 0
                },
                {
                    "sent": "For example, the forward backward algorithm in hidden Markov models is a message passing algorithm on this graph.",
                    "label": 0
                },
                {
                    "sent": "The common smoothing algorithm, which just common filtering in the forward direction and then a backward pass of messages.",
                    "label": 0
                },
                {
                    "sent": "For state space models, is another message passing graph and the nice thing from a historical perspective is that these things were independently invented, but they're all equivalent.",
                    "label": 1
                },
                {
                    "sent": "OK, they're all just instances of belief propagation or factor graph propagation.",
                    "label": 0
                },
                {
                    "sent": "So we can immediately generalize them to other architectures.",
                    "label": 0
                },
                {
                    "sent": "Trees, tree structured architectures, etc.",
                    "label": 0
                },
                {
                    "sent": "We don't have to stick the chains.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this wasn't really understood until about 15 years ago.",
                    "label": 0
                },
                {
                    "sent": "Although these algorithms are more like.",
                    "label": 0
                },
                {
                    "sent": "30 or 40 years old.",
                    "label": 0
                },
                {
                    "sent": "For more.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "So what do we do if we have a multiply connected graph?",
                    "label": 0
                },
                {
                    "sent": "Well, we've heard about loopy belief propagation already.",
                    "label": 1
                },
                {
                    "sent": "I'm going to briefly mention Junction Tree algorithm not going to give you full tutorial on that.",
                    "label": 0
                },
                {
                    "sent": "It would take much too long to do that.",
                    "label": 0
                },
                {
                    "sent": "I talked about illumination algorithms, cutset conditioning and then their cuts at commissioning is where you take a particular variable an you condition it on different values.",
                    "label": 0
                },
                {
                    "sent": "If you could find a set of variables such that the rest of the graph is simply connected, then you can condition over all the possible values in that set and get exact inference is over all of the variables, so again, I will talk in detail about that, and then there is a whole bunch of approximate inference methods that only 10 participants.",
                    "label": 1
                },
                {
                    "sent": "So let me just talk to.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Little bit about junction tree and then I'll wrap up.",
                    "label": 0
                },
                {
                    "sent": "So very, very quickly the junction tree algorithm was developed as an exact inference algorithm for directed graphs of arbitrary topology and the basic idea is the following.",
                    "label": 1
                },
                {
                    "sent": "You start with a directed graph.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You do a step where you turn it into an undirected graph by something called moralizing.",
                    "label": 0
                },
                {
                    "sent": "Which is marrying the sorry you start with this graph.",
                    "label": 0
                },
                {
                    "sent": "This variable has two parents A&B you want to marry their parents.",
                    "label": 0
                },
                {
                    "sent": "This is Terrence OK, so you've introduced an edge to marry the parents of seed.",
                    "label": 0
                },
                {
                    "sent": "That's the moralization step, so we introduce another edge to marry C&B.",
                    "label": 0
                },
                {
                    "sent": "So now you have this graph.",
                    "label": 0
                },
                {
                    "sent": "You remove the edge directions so we have an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "So this results in an undirected graph where we haven't added any additional conditional independence relationships.",
                    "label": 1
                },
                {
                    "sent": "OK, so we you know the worry would be converting into an undirected graph where we now have assumed something that is not true in our previous directly graph and we haven't added anything either.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now the next step is we need to do another graph operation which is called triangulation so that issues is this red edge, so there's no loop of length greater than three without the cord going across that move.",
                    "label": 0
                },
                {
                    "sent": "So there was a loop of LED 4, then go back loop of lead four.",
                    "label": 0
                },
                {
                    "sent": "We need to introduce accord along that loop.",
                    "label": 0
                },
                {
                    "sent": "That's called triangulation.",
                    "label": 0
                },
                {
                    "sent": "OK, that seems mysterious.",
                    "label": 0
                },
                {
                    "sent": "Sort of is until you understand that is actually necessary, so the final junction tree that you end up with satisfies something known as a running intersection property in geometry.",
                    "label": 1
                },
                {
                    "sent": "So that was triangulation and then.",
                    "label": 0
                },
                {
                    "sent": "So yeah.",
                    "label": 0
                },
                {
                    "sent": "Site.",
                    "label": 0
                },
                {
                    "sent": "OK, why could we add this edge?",
                    "label": 0
                },
                {
                    "sent": "Alright, so the worry is.",
                    "label": 0
                },
                {
                    "sent": "If we.",
                    "label": 0
                },
                {
                    "sent": "If we don't have an edge, then we.",
                    "label": 0
                },
                {
                    "sent": "Then we need.",
                    "label": 0
                },
                {
                    "sent": "Sorry if we yeah, if we don't have an edge that we need, then we've assumed and independence that wasn't true originally, OK. That's the worry.",
                    "label": 0
                },
                {
                    "sent": "We can add edges because basically what they what they do is they.",
                    "label": 0
                },
                {
                    "sent": "Allow.",
                    "label": 0
                },
                {
                    "sent": "Sort of, if we add, let's take the extreme.",
                    "label": 0
                },
                {
                    "sent": "If we Add all of the edges so the graph is fully connected, then that graph represents any possible probability distribution.",
                    "label": 0
                },
                {
                    "sent": "There are no independencies in that distribution, so that graph is general enough to capture anything you want, but it's not very useful because that has one click with everything in one set of variables, so computations are exponential in the number of variables, so every time we added edge, we.",
                    "label": 0
                },
                {
                    "sent": "Lose some of the representational power of our original graph and we make things less efficient.",
                    "label": 0
                },
                {
                    "sent": "So we want to add a few entries as possible in this sort of sequence of transformations.",
                    "label": 0
                },
                {
                    "sent": "We could have added the E as well, I think, yeah.",
                    "label": 0
                },
                {
                    "sent": "So there are different different algorithms for triangulation and again, I think the optimal triangulation is.",
                    "label": 0
                },
                {
                    "sent": "Probably also every completed area.",
                    "label": 0
                },
                {
                    "sent": "But they're good heuristics.",
                    "label": 0
                },
                {
                    "sent": "They're very good here.",
                    "label": 0
                },
                {
                    "sent": "Thanks for doing this stuff.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I will be labor this too much.",
                    "label": 0
                },
                {
                    "sent": "So now I have an undirected graph.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to do is I'm going to group variables together.",
                    "label": 0
                },
                {
                    "sent": "Take 5, all the clicks, the clicks are the fully connected subgraphs, group them.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gather.",
                    "label": 0
                },
                {
                    "sent": "That looks like this.",
                    "label": 0
                },
                {
                    "sent": "ABC are this green dashed clique etc.",
                    "label": 0
                },
                {
                    "sent": "So you.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Liveleaks and then.",
                    "label": 0
                },
                {
                    "sent": "I going to create these super variables which are products have their state space, is the product of all of the variables in each of the corresponding cliques.",
                    "label": 0
                },
                {
                    "sent": "So AB&C were in one clique, so if they were binary, this variable now has eight possible states.",
                    "label": 0
                },
                {
                    "sent": "QQ.",
                    "label": 0
                },
                {
                    "sent": "So I have these.",
                    "label": 0
                },
                {
                    "sent": "The clicks.",
                    "label": 0
                },
                {
                    "sent": "And they have intersections because there are certain variables that are jointly appearing in neighboring cliques.",
                    "label": 0
                },
                {
                    "sent": "And the point now is that I could take my cliques and form was called a junction tree.",
                    "label": 0
                },
                {
                    "sent": "And the junction tree is a tree of overlapping sets of variables, and it's a tree importantly, so I can run a belief propagation algorithm on that tree, sending messages back and forth and I won't get this sort of problem of information coming from multiple sources, so that's the junction tree algorithm that converts it into this in.",
                    "label": 1
                },
                {
                    "sent": "It's basically the same.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think you know there might be different site different ways of implementing this, yeah?",
                    "label": 0
                },
                {
                    "sent": "So the important thing is, yeah, so basically the state space of these variables.",
                    "label": 0
                },
                {
                    "sent": "And a safe space of these variables overlap, so there are sort of hard constraints.",
                    "label": 0
                },
                {
                    "sent": "There are factors that represent hard constraints between the settings of these variables in these variables.",
                    "label": 0
                },
                {
                    "sent": "So equality constraints those have to be included in the junction.",
                    "label": 0
                },
                {
                    "sent": "Pre tree algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so this mysterious triangulation thing had to be done so that if a variable appears in more than one click, it appears in all intermediate quick so that that variable doesn't get incoherent probabilities assigned to it from different parts of the graph.",
                    "label": 1
                },
                {
                    "sent": "So that's what the.",
                    "label": 0
                },
                {
                    "sent": "Relation is there for.",
                    "label": 1
                },
                {
                    "sent": "Anyway, so this is down, junction tree propagation is algorithm for ensuring the neighboring cliques have consistent probability distributions in the same messages between them, and local consistency between these implies that global consistency of the whole probability distribution.",
                    "label": 0
                },
                {
                    "sent": "That's all I'm going to say about Junction tree I'm running over now, but I think that's.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summary, So let me just summarize.",
                    "label": 0
                },
                {
                    "sent": "So inference consists of the problem of computing the probability of variables of interest given some observed variables.",
                    "label": 1
                },
                {
                    "sent": "I talked about belief propagation, a factor graph propagation, these are.",
                    "label": 0
                },
                {
                    "sent": "Generalizations of classical things like common filtering or forward backward algorithms.",
                    "label": 0
                },
                {
                    "sent": "And for multiply connected graphs I talked about the junction tree algorithm, which solves exact inference problem, but it can be very slow because it is exponential in the cardinality of the largest.",
                    "label": 1
                },
                {
                    "sent": "Think that you end up with when you do this whole triangulation normalization.",
                    "label": 0
                },
                {
                    "sent": "Add the possibility, but alright, so that's it for elite or today we're going to have lunch break with.",
                    "label": 0
                },
                {
                    "sent": "You can ask a few questions today.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Everybody's hungry.",
                    "label": 0
                },
                {
                    "sent": "Alright, alright so.",
                    "label": 0
                }
            ]
        }
    }
}