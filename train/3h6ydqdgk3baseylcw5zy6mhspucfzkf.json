{
    "id": "3h6ydqdgk3baseylcw5zy6mhspucfzkf",
    "title": "Escaping Groundhog Day",
    "info": {
        "author": [
            "James MacGlashan, Department of Computer Science, Brown University"
        ],
        "published": "July 28, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Psychology",
            "Top->Social Sciences->Economics",
            "Top->Medicine->Neuroscience",
            "Top->Technology->Engineering->Electrical Engineering->Control Engineering"
        ]
    },
    "url": "http://videolectures.net/rldm2015_macglashan_groundhog_day/",
    "segmentation": [
        [
            "So the goal of this talk today is actually to highlight a learning problem.",
            "I think lies at the heart of a few different sub areas of reinforcement learning and hopefully encourage more people to investigate and see what we can do by directly thinking about this kind of problem.",
            "I'll get back a little bit later on to why this talk is called Scaping Groundhog Day, so just bear with me and it should become clear."
        ],
        [
            "So the key message you should have in your head as I go through this talk involves this economy between ground and figure.",
            "So if you're not familiar with the terminology, an example of it is if you have black text on a white background, the white background is ground.",
            "It's the things you don't really care about.",
            "It's not really changing, and then the text or the things that are changing.",
            "It's the figure.",
            "It's what you have to pay attention to all the time.",
            "And what I'm going to advocate for is what we really want to start looking at is something all problem generators which exist somewhere in between this ground and figure where there's some things that are going to be the same across and agents experience, and some things that vary so the agent needs to kind of cash away.",
            "The things are the same and be active and adapt to things that are changing."
        ],
        [
            "OK, so to motivate this framework I want to start with the standard reinforcement learning paradigm.",
            "Even though I think everyone here is fairly familiar with it.",
            "The idea is we have an agent who's dropped into environment an they select from some actions and every time they select an action they get a new set of observations and a reward signal, and they're trying to optimize.",
            "The rewards are going to get overtime based on what they're doing.",
            "So in this video it's grid world.",
            "We have a reinforcement learning agent playing in.",
            "If you play a lot with reinforcement learning agents who might be recognized.",
            "Algorithms is even, but it's a gridworld and the agents trying to get to the top right corner.",
            "It's marked in blue here and you can see fumble around a whole bunch.",
            "We eventually can just start optimizing against and he's doing really well now.",
            "OK, so great."
        ],
        [
            "But what if something changes right?",
            "So once the agent had learned to get to that top right corner before right before is going up here.",
            "And then we moved the goal over to here.",
            "Well, we had a Q learning agent and we said OK, we just change things go and continue learning.",
            "We get behavior that looks kind of like this.",
            "Which doesn't feel very sensible.",
            "I hope a human wouldn't act like this, but maybe the psychologist will say they do.",
            "But you know he's spending a lot of time just kind of slowly backing away from this corner.",
            "And if I let this run long enough you will eventually get back over this goal and things smooth out.",
            "But it takes a really long time.",
            "In fact, we probably would have been better.",
            "Just restart Q learning from the beginning with like an optimistic, optimistic initialization of the Q values and he would have learned faster, but he does eventually get there, but it's not not really what we want."
        ],
        [
            "So why doesn't this work?",
            "Why didn't this?",
            "Continuing on changing the goal, work with Standard Q, learning the reasons we kind of broke the assumptions that we typically have in mind when we're doing reinforcement learning.",
            "So this is the normal kind of paradigm diagram we often see where there's an environment in an agent agents taking actions affecting environment environment, spitting back out reward in state.",
            "I'm actually good."
        ],
        [
            "Modify this slightly, but there's one other piece which is kind of important that we tend to do, which is we have this notion of state resets, so the agents can be acting.",
            "The environment eventually completes the task and then the state resets again to somewhere he's already been before it gets to go again, so they just keeps resetting over and over and over again.",
            "The agents optimizing over and over for this environment that he has, so we're calling."
        ],
        [
            "Groundhog Day assumptions where the reward function is always the same states kind of reset in indefinitely and it resets the states.",
            "They just kind of seen before in its past, and so we call in the Groundhog Day assumptions."
        ],
        [
            "As they might remind you of the movie Groundhog Day, right?",
            "So if you haven't seen this movie, you should.",
            "But it's a movie where Bill Murray is in this interesting situation where at the end of the day he resets back to the beginning of time of that day, so he gets to reply to say, over and over again.",
            "If he kills himself, he still comes back to the beginning of the day and this allows him to do some interesting things because he gets to replay this day over and over again.",
            "So here's.",
            "Video give an example of what you can do.",
            "Know if you'll be able to hear this, but it is captured so you can see what you're saying.",
            "It's gonna be 2 sharks.",
            "So you can see right now just predicting what's going to happen before it happens is kind of a timer.",
            "So in this thing he managed to steal the money without anyone noticing because he just played this day so many times he knows how to time everything perfectly so that no one will notice."
        ],
        [
            "So the point here is these Groundhog Day assumptions basically enable an agent or Bill Murray in this case to do hyper optimization of things he's doing before."
        ],
        [
            "These assumptions have actually been pretty good in the past.",
            "We've had some good success is about using them.",
            "We've been able to solve a bunch of games we've got to do things like make elevators work better, have some robot controllers for motion control and things like that.",
            "And in fact, some of the recent things we've seen with.",
            "With the Atari game learning environment has been kind of step away from that.",
            "We have a whole bunch of games in Agent can play and we may be tuned some some vision learning algorithms for that and it works well for all of them.",
            "But"
        ],
        [
            "That said, I think we maybe want to step away from that.",
            "We don't think Groundhog Day.",
            "The movie is a realistic scenario in itself, so that means there's problems that we should be looking beyond.",
            "This kind of reset and hyper optimization.",
            "The same things over and over again.",
            "So if we think about this, we have the ground.",
            "So Groundhog Day really is all ground.",
            "Everything is the same all the time, and there's no figure.",
            "So just to optimize for the same stuff over and over again.",
            "But we want something that's in between our kind of ground and figure paradigm.",
            "So in this case we took our grid world and we said all these blue locations are possible.",
            "Goal locations the agent gets to experience a whole bunch of different worlds where it seemed that the goal changes to one of these positions, and the rest is actually stays the same.",
            "The way the agent moves the physics and everything.",
            "All that's going to stay the same.",
            "So we might want a sensible agent to do then is he's going to learn how the world works.",
            "And then he's going to know how he moves, and he's going to look for where those goals are."
        ],
        [
            "So if it happened to be the goal now moved to this top left corner again, but he's learned in this case using our Max, which is a model based reinforcement learning on how the world works and then he gets to play through this world instead of having this kind of very slow backup from from the end of the world, we see something that looks more informed like this.",
            "Right, so this is this is very nice.",
            "This is kind of hand given to it.",
            "This is the structure, but we would like to see where he's learning the things that are the same and adapting to things that are new so you get more informed behavior like that."
        ],
        [
            "OK, so if we want to move that kind of paradigm we need to do a few things.",
            "First we need to relax our assumptions.",
            "Then we need to investigate new benchmark.",
            "Problem generates.",
            "I can generate these differences a different kinds of problems.",
            "Agents going to face overtime and then develop appropriate learning machinery that can handle learning these kinds of environments."
        ],
        [
            "So as far as relaxing assumptions, I don't think we have to do a whole lot of new work.",
            "What we can do is we can basically add we had some problem general up here and it's going to change aspects of the environment and state reset properties.",
            "So you can imagine each problem maybe has potentially a different initial state distribution, different reward function or goal.",
            "Maybe the action I'll itself can change.",
            "These are things that can all vary between different problems that get generated from generator and then after the agent learns in one problem.",
            "OK, he learns that problem.",
            "He gets a new one.",
            "The problem yet so no one has to behave in that one.",
            "So the key here is something's going to remain the same between each problems and some things are going to be different in Agent should learn what's the same and then be adaptive to things that are different."
        ],
        [
            "OK, so I think it's worth pointing out that some of the sub areas in reinforcement learning I think are actually all coming down, Whoops.",
            "Or actually all kind of focusing on this problem in some kind of unified way, right?",
            "So we have work that's looking at learning action hierarchy, so things like learning options or Max you hierarchies.",
            "We have various transfer learning.",
            "We have beige and RL which are all kind of starting to look at this problem.",
            "You know, there may be seen as different areas.",
            "They all kind of look the same problem.",
            "We need to generalize the whole distribution of different kinds of problems that we're going to face overtime, so hopefully we can.",
            "We can focus on this unifying problem and also explore new ways that we can work with it."
        ],
        [
            "So we're going to work on this problem.",
            "We need some interesting problem generators and tasks we can.",
            "We can work at solving an two areas that I think we should be investigating more in this capacity are robotics and the game Minecraft."
        ],
        [
            "So robotics is really good because the world is just kind of naturally complex right.",
            "In fact, oftentimes in about people were trying to control the environment, so it is more on the ground side overtime, because it's very easy to introduce variation in it without a whole lot of work.",
            "So I think robotics is a great area to investigate new problems where the, but we allow the environment to keep changing, and we're trying to have agent learn the same things.",
            "Things that are the same between those merits and adapt to things that are different overtime, and in particular, that means probably moving away from just the motion controllers where we get to kind of control the space.",
            "Look at more larger kinds of tasks, such as interacting with people or manipulating environments with different kinds of objects around in them."
        ],
        [
            "OK, in Minecraft is also I really like to advocate.",
            "This is a really great world.",
            "It's nice because we expand.",
            "We really huge, probably largely environment.",
            "You would normally have robots operate in.",
            "It's very expressive.",
            "It's actually turning complete.",
            "You can build computers within Minecraft, they're very large, but you can actually build computers, so you can imagine a whole large space of problems you can solve, or you can make them smaller.",
            "And also importantly, it's safe so you don't worry about people getting hurt, and there's no hardware failures, which is just a pain to work through when you're doing experience with real robotics, so there's lots of goals, it's.",
            "Easy manipulate answer.",
            "Really interesting rich space that we should be investigating."
        ],
        [
            "So we're going to be doing reasoning in these kinds of problem spaces.",
            "We need some way some kind of glue to tie together.",
            "We're going to be doing that, so some of the other research areas I mentioned, like transfer, learning, learning, action hierarchies are already kind of starting to look at some ways that we could use like we could.",
            "We could represent problems we can reason between different problem.",
            "There's Agent space features where there's a set of core features that are always the same for the agent, even though other feature is going to be changing their inner task mapping.",
            "So we can look at the map, the state variables in one problem to another problem.",
            "An horde which is learning high level features from low level sensors, so it's general across a bunch of different changes, but I'd like to highlight is object oriented DPS."
        ],
        [
            "An object or MVP's are kind of like a growth of just using a standard vector state vector representation of the world.",
            "Instead, the world is going to consist of a bunch of different objects that each belong to classes they can manage.",
            "We have a robot in this environment we have rooms which are objects, we've doors, which are objects."
        ],
        [
            "And blocks and each object in the world has its own kind of properties.",
            "You can sign into it.",
            "So here you can imagine the robot has a position.",
            "In this simplified world, their blocks have positioned shape, color and things like that."
        ],
        [
            "And the next thing about doing this kind of object representation is you can do a lot of generalization that works across different environments because you can factor it within the objects themselves.",
            "So in particular, in this case you imagine the robot might learn that pushing a chair moves both him and the Sheriff there adjacent to each other.",
            "So this is so.",
            "This is really nice because we had lots of different objects in the world.",
            "Maybe the task requires a whole lot of actions, but there's some similarity you can learn between them because of the dynamics."
        ],
        [
            "OK, so we're going to be working this kind of problem, spaces maybe using these kind of expressive representations.",
            "We would like to have a tool so we have one that hopefully you'll use in like it's called burlap.",
            "You can get blocked so proud that you it's a reinforcement learning and planning library.",
            "It has tools for working with problem generators and state generators.",
            "It has a known DP state representation underneath.",
            "You can do this kind of expressive tasks and representations and also astharoshe interface.",
            "We're working with robots and also just very recently started building an released.",
            "A Minecraft interface so you can have burlap.",
            "Airl owns controlling Minecraft player in real Minecraft."
        ],
        [
            "So as far as what we can learn these types environments, there's actually a whole bunch of different things we can learn.",
            "As I mentioned, we can learn world physics.",
            "We can basically do learning to learn.",
            "The agent can learn things that allowed to learn faster environments.",
            "There's learning to plan, so the agent might be able to plan environment, but planning is slow, so you want to learn how to accelerate your planning.",
            "There's task decomposition and state representation, and also even slightly tangentially learning about language that you might interact with the person and how it applies to these worlds."
        ],
        [
            "As far as learning to learn, I'm running out of time very quickly and this isn't helping.",
            "OK, so in this case we imagine if we had a whole bunch of different learning outcomes and each had their own different parameters, but we had to deploy these learnings to solve a whole bunch of future problems.",
            "How we choose the right one?",
            "We've introduced some means so you can build some generalization down space and just training data, training each of these algorithms classes on a set of data so you can figure out how well actually work across the whole distribution."
        ],
        [
            "As far as learning to plan, we have some work where we're learning what actions are useful for the kind of goal you're trying to solve.",
            "Any given time in the states here ends.",
            "You can prune away your relevant actions and narrow the search space.",
            "We had this working in simplified versions of Minecraft and ended up speeding up our plan results quite a bit."
        ],
        [
            "We have a poster actually, so if you want to talk about those things, please come find me and we can get into more detail or we can talk about anything we've talked about here."
        ],
        [
            "So in conclusion, I promoted using working to our problem general.",
            "We have a bunch of things that have changed overtime and some things that are constant that you can cash away an reuse talked about using Robotics an Minecraft as being interesting.",
            "Problem areas we can exploit is very rich types of problems that are changing overtime and talk about some new machinery and some tools.",
            "With burlap you can use for working in Robotics and Minecraft and doing a bunch of other stuff."
        ],
        [
            "Really just wanted on the collaborators who worked on the learning to learn, learn to plan stuff that I mentioned."
        ],
        [
            "And thank you for your time.",
            "Very interesting model and very nice talk.",
            "Are you assuming that the problems are appear?",
            "Are I ID from some distribution or can we have for example structure like promap then problem be the problem?",
            "See bacteria.",
            "That's a great question, so I think we feel either way.",
            "I think the important thing is that we moved to the problem general, but we're also interested in the notion of scaffolding.",
            "In particular, where you can have easy problems.",
            "1st and the agents building that to the Minecraft stuff actually was kind of scaffold, did he said?",
            "Here's a bunch of easy problems we know you can plan in pretty well.",
            "It solves those.",
            "And then we gave it harder problems and it's solved the hard problems better.",
            "And if it didn't do any training before, so so ID, sure, but I think scaffolding also is a really interesting thing we should be looking at as well.",
            "Thank you.",
            "So as I've spent a fair amount of time down the rabbit hole of what are objects and concepts and.",
            "In Minecraft, I can see how you might.",
            "I mean, it literally does have objects in the world that are fairly well defined, but the whole robot pushing pushing a chair.",
            "What's a chair?",
            "What can you push?",
            "So in the new kind of new machinery you're presenting, the object oriented MTPS.",
            "How do you avoid the massive hand engineering problem you have that's tremendously domain specific?",
            "And yeah, so well, I think I think one thing we should look at doing with that is building kind of multiple classes and hierarchy of your objects so things are related.",
            "You can have right now there's attributes of some things are going to be different objects with similar custom have similar types of attributes that bind them together, but now it is a hand engineering exercise by the.",
            "Programmers as programmers.",
            "So I think learning these objects in particular is also going to be really useful, and that's something we're interested in.",
            "Yeah, so remove the burn from the programmer would be good.",
            "Great talk so one of the cool things about Minecraft is that people play it an I wonder if you've compared or thought about comparing how your algorithms perform relative to humans and humans do on your problem set badly, I think because Minecraft is so large that the algorithms are the humans do badly, so the algorithms the space is so large it's really hard to get any traction at all with the classic ones we have right now.",
            "Which is why it's a really great space to go.",
            "But the human thing is also really interesting because.",
            "Like there's just data on the Internet, but you can.",
            "My Nan used to improve these items, so as far as there's language and there's even videos an maybe even you can get people to actually playing and recording their their movements, or set this up on EM to cause something to actually get you know, control data in the exact same problems that you're.",
            "Yeah, that would be really nice.",
            "So you're pointing out a lot of interesting issues about how you manage, change and deal with different kinds of change.",
            "I don't know, it's I just want to say it's it's not really necessary to formulate it as a as a change in the problem or as a problem generator that you can just consider it.",
            "One problem that's continually changing maybe different rates in different parts of it.",
            "Yeah, so to an extent you can imagine it being a very large MDP an with only piece that tends to be actually how we're doing what we say.",
            "There's one large MVP.",
            "One caveat I put with that is the goal itself might change, and so we can have some.",
            "Maybe humans only have one reward function that's there, always an we're kind of making up the rewards in between as far as actual intelligent agents, we're going to build that might not quite be the case.",
            "We might be actually changing the goal.",
            "It's going to happen any given time, so as far as the goal changing that might still be important in terms of the problem generator.",
            "Paradigm."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the goal of this talk today is actually to highlight a learning problem.",
                    "label": 0
                },
                {
                    "sent": "I think lies at the heart of a few different sub areas of reinforcement learning and hopefully encourage more people to investigate and see what we can do by directly thinking about this kind of problem.",
                    "label": 0
                },
                {
                    "sent": "I'll get back a little bit later on to why this talk is called Scaping Groundhog Day, so just bear with me and it should become clear.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key message you should have in your head as I go through this talk involves this economy between ground and figure.",
                    "label": 1
                },
                {
                    "sent": "So if you're not familiar with the terminology, an example of it is if you have black text on a white background, the white background is ground.",
                    "label": 0
                },
                {
                    "sent": "It's the things you don't really care about.",
                    "label": 0
                },
                {
                    "sent": "It's not really changing, and then the text or the things that are changing.",
                    "label": 0
                },
                {
                    "sent": "It's the figure.",
                    "label": 0
                },
                {
                    "sent": "It's what you have to pay attention to all the time.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to advocate for is what we really want to start looking at is something all problem generators which exist somewhere in between this ground and figure where there's some things that are going to be the same across and agents experience, and some things that vary so the agent needs to kind of cash away.",
                    "label": 0
                },
                {
                    "sent": "The things are the same and be active and adapt to things that are changing.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so to motivate this framework I want to start with the standard reinforcement learning paradigm.",
                    "label": 0
                },
                {
                    "sent": "Even though I think everyone here is fairly familiar with it.",
                    "label": 0
                },
                {
                    "sent": "The idea is we have an agent who's dropped into environment an they select from some actions and every time they select an action they get a new set of observations and a reward signal, and they're trying to optimize.",
                    "label": 0
                },
                {
                    "sent": "The rewards are going to get overtime based on what they're doing.",
                    "label": 0
                },
                {
                    "sent": "So in this video it's grid world.",
                    "label": 0
                },
                {
                    "sent": "We have a reinforcement learning agent playing in.",
                    "label": 0
                },
                {
                    "sent": "If you play a lot with reinforcement learning agents who might be recognized.",
                    "label": 0
                },
                {
                    "sent": "Algorithms is even, but it's a gridworld and the agents trying to get to the top right corner.",
                    "label": 0
                },
                {
                    "sent": "It's marked in blue here and you can see fumble around a whole bunch.",
                    "label": 0
                },
                {
                    "sent": "We eventually can just start optimizing against and he's doing really well now.",
                    "label": 0
                },
                {
                    "sent": "OK, so great.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what if something changes right?",
                    "label": 0
                },
                {
                    "sent": "So once the agent had learned to get to that top right corner before right before is going up here.",
                    "label": 0
                },
                {
                    "sent": "And then we moved the goal over to here.",
                    "label": 0
                },
                {
                    "sent": "Well, we had a Q learning agent and we said OK, we just change things go and continue learning.",
                    "label": 0
                },
                {
                    "sent": "We get behavior that looks kind of like this.",
                    "label": 0
                },
                {
                    "sent": "Which doesn't feel very sensible.",
                    "label": 0
                },
                {
                    "sent": "I hope a human wouldn't act like this, but maybe the psychologist will say they do.",
                    "label": 0
                },
                {
                    "sent": "But you know he's spending a lot of time just kind of slowly backing away from this corner.",
                    "label": 0
                },
                {
                    "sent": "And if I let this run long enough you will eventually get back over this goal and things smooth out.",
                    "label": 0
                },
                {
                    "sent": "But it takes a really long time.",
                    "label": 0
                },
                {
                    "sent": "In fact, we probably would have been better.",
                    "label": 0
                },
                {
                    "sent": "Just restart Q learning from the beginning with like an optimistic, optimistic initialization of the Q values and he would have learned faster, but he does eventually get there, but it's not not really what we want.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So why doesn't this work?",
                    "label": 0
                },
                {
                    "sent": "Why didn't this?",
                    "label": 0
                },
                {
                    "sent": "Continuing on changing the goal, work with Standard Q, learning the reasons we kind of broke the assumptions that we typically have in mind when we're doing reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "So this is the normal kind of paradigm diagram we often see where there's an environment in an agent agents taking actions affecting environment environment, spitting back out reward in state.",
                    "label": 0
                },
                {
                    "sent": "I'm actually good.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Modify this slightly, but there's one other piece which is kind of important that we tend to do, which is we have this notion of state resets, so the agents can be acting.",
                    "label": 0
                },
                {
                    "sent": "The environment eventually completes the task and then the state resets again to somewhere he's already been before it gets to go again, so they just keeps resetting over and over and over again.",
                    "label": 0
                },
                {
                    "sent": "The agents optimizing over and over for this environment that he has, so we're calling.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Groundhog Day assumptions where the reward function is always the same states kind of reset in indefinitely and it resets the states.",
                    "label": 0
                },
                {
                    "sent": "They just kind of seen before in its past, and so we call in the Groundhog Day assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As they might remind you of the movie Groundhog Day, right?",
                    "label": 0
                },
                {
                    "sent": "So if you haven't seen this movie, you should.",
                    "label": 0
                },
                {
                    "sent": "But it's a movie where Bill Murray is in this interesting situation where at the end of the day he resets back to the beginning of time of that day, so he gets to reply to say, over and over again.",
                    "label": 0
                },
                {
                    "sent": "If he kills himself, he still comes back to the beginning of the day and this allows him to do some interesting things because he gets to replay this day over and over again.",
                    "label": 0
                },
                {
                    "sent": "So here's.",
                    "label": 0
                },
                {
                    "sent": "Video give an example of what you can do.",
                    "label": 0
                },
                {
                    "sent": "Know if you'll be able to hear this, but it is captured so you can see what you're saying.",
                    "label": 0
                },
                {
                    "sent": "It's gonna be 2 sharks.",
                    "label": 0
                },
                {
                    "sent": "So you can see right now just predicting what's going to happen before it happens is kind of a timer.",
                    "label": 0
                },
                {
                    "sent": "So in this thing he managed to steal the money without anyone noticing because he just played this day so many times he knows how to time everything perfectly so that no one will notice.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the point here is these Groundhog Day assumptions basically enable an agent or Bill Murray in this case to do hyper optimization of things he's doing before.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These assumptions have actually been pretty good in the past.",
                    "label": 0
                },
                {
                    "sent": "We've had some good success is about using them.",
                    "label": 0
                },
                {
                    "sent": "We've been able to solve a bunch of games we've got to do things like make elevators work better, have some robot controllers for motion control and things like that.",
                    "label": 0
                },
                {
                    "sent": "And in fact, some of the recent things we've seen with.",
                    "label": 0
                },
                {
                    "sent": "With the Atari game learning environment has been kind of step away from that.",
                    "label": 0
                },
                {
                    "sent": "We have a whole bunch of games in Agent can play and we may be tuned some some vision learning algorithms for that and it works well for all of them.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That said, I think we maybe want to step away from that.",
                    "label": 0
                },
                {
                    "sent": "We don't think Groundhog Day.",
                    "label": 0
                },
                {
                    "sent": "The movie is a realistic scenario in itself, so that means there's problems that we should be looking beyond.",
                    "label": 0
                },
                {
                    "sent": "This kind of reset and hyper optimization.",
                    "label": 0
                },
                {
                    "sent": "The same things over and over again.",
                    "label": 0
                },
                {
                    "sent": "So if we think about this, we have the ground.",
                    "label": 0
                },
                {
                    "sent": "So Groundhog Day really is all ground.",
                    "label": 0
                },
                {
                    "sent": "Everything is the same all the time, and there's no figure.",
                    "label": 0
                },
                {
                    "sent": "So just to optimize for the same stuff over and over again.",
                    "label": 0
                },
                {
                    "sent": "But we want something that's in between our kind of ground and figure paradigm.",
                    "label": 0
                },
                {
                    "sent": "So in this case we took our grid world and we said all these blue locations are possible.",
                    "label": 0
                },
                {
                    "sent": "Goal locations the agent gets to experience a whole bunch of different worlds where it seemed that the goal changes to one of these positions, and the rest is actually stays the same.",
                    "label": 0
                },
                {
                    "sent": "The way the agent moves the physics and everything.",
                    "label": 0
                },
                {
                    "sent": "All that's going to stay the same.",
                    "label": 0
                },
                {
                    "sent": "So we might want a sensible agent to do then is he's going to learn how the world works.",
                    "label": 0
                },
                {
                    "sent": "And then he's going to know how he moves, and he's going to look for where those goals are.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if it happened to be the goal now moved to this top left corner again, but he's learned in this case using our Max, which is a model based reinforcement learning on how the world works and then he gets to play through this world instead of having this kind of very slow backup from from the end of the world, we see something that looks more informed like this.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is this is very nice.",
                    "label": 0
                },
                {
                    "sent": "This is kind of hand given to it.",
                    "label": 0
                },
                {
                    "sent": "This is the structure, but we would like to see where he's learning the things that are the same and adapting to things that are new so you get more informed behavior like that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so if we want to move that kind of paradigm we need to do a few things.",
                    "label": 0
                },
                {
                    "sent": "First we need to relax our assumptions.",
                    "label": 0
                },
                {
                    "sent": "Then we need to investigate new benchmark.",
                    "label": 0
                },
                {
                    "sent": "Problem generates.",
                    "label": 0
                },
                {
                    "sent": "I can generate these differences a different kinds of problems.",
                    "label": 0
                },
                {
                    "sent": "Agents going to face overtime and then develop appropriate learning machinery that can handle learning these kinds of environments.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as far as relaxing assumptions, I don't think we have to do a whole lot of new work.",
                    "label": 0
                },
                {
                    "sent": "What we can do is we can basically add we had some problem general up here and it's going to change aspects of the environment and state reset properties.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine each problem maybe has potentially a different initial state distribution, different reward function or goal.",
                    "label": 1
                },
                {
                    "sent": "Maybe the action I'll itself can change.",
                    "label": 0
                },
                {
                    "sent": "These are things that can all vary between different problems that get generated from generator and then after the agent learns in one problem.",
                    "label": 0
                },
                {
                    "sent": "OK, he learns that problem.",
                    "label": 1
                },
                {
                    "sent": "He gets a new one.",
                    "label": 0
                },
                {
                    "sent": "The problem yet so no one has to behave in that one.",
                    "label": 0
                },
                {
                    "sent": "So the key here is something's going to remain the same between each problems and some things are going to be different in Agent should learn what's the same and then be adaptive to things that are different.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I think it's worth pointing out that some of the sub areas in reinforcement learning I think are actually all coming down, Whoops.",
                    "label": 0
                },
                {
                    "sent": "Or actually all kind of focusing on this problem in some kind of unified way, right?",
                    "label": 0
                },
                {
                    "sent": "So we have work that's looking at learning action hierarchy, so things like learning options or Max you hierarchies.",
                    "label": 0
                },
                {
                    "sent": "We have various transfer learning.",
                    "label": 1
                },
                {
                    "sent": "We have beige and RL which are all kind of starting to look at this problem.",
                    "label": 0
                },
                {
                    "sent": "You know, there may be seen as different areas.",
                    "label": 0
                },
                {
                    "sent": "They all kind of look the same problem.",
                    "label": 0
                },
                {
                    "sent": "We need to generalize the whole distribution of different kinds of problems that we're going to face overtime, so hopefully we can.",
                    "label": 0
                },
                {
                    "sent": "We can focus on this unifying problem and also explore new ways that we can work with it.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to work on this problem.",
                    "label": 0
                },
                {
                    "sent": "We need some interesting problem generators and tasks we can.",
                    "label": 0
                },
                {
                    "sent": "We can work at solving an two areas that I think we should be investigating more in this capacity are robotics and the game Minecraft.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So robotics is really good because the world is just kind of naturally complex right.",
                    "label": 0
                },
                {
                    "sent": "In fact, oftentimes in about people were trying to control the environment, so it is more on the ground side overtime, because it's very easy to introduce variation in it without a whole lot of work.",
                    "label": 0
                },
                {
                    "sent": "So I think robotics is a great area to investigate new problems where the, but we allow the environment to keep changing, and we're trying to have agent learn the same things.",
                    "label": 0
                },
                {
                    "sent": "Things that are the same between those merits and adapt to things that are different overtime, and in particular, that means probably moving away from just the motion controllers where we get to kind of control the space.",
                    "label": 0
                },
                {
                    "sent": "Look at more larger kinds of tasks, such as interacting with people or manipulating environments with different kinds of objects around in them.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, in Minecraft is also I really like to advocate.",
                    "label": 0
                },
                {
                    "sent": "This is a really great world.",
                    "label": 0
                },
                {
                    "sent": "It's nice because we expand.",
                    "label": 0
                },
                {
                    "sent": "We really huge, probably largely environment.",
                    "label": 0
                },
                {
                    "sent": "You would normally have robots operate in.",
                    "label": 0
                },
                {
                    "sent": "It's very expressive.",
                    "label": 0
                },
                {
                    "sent": "It's actually turning complete.",
                    "label": 0
                },
                {
                    "sent": "You can build computers within Minecraft, they're very large, but you can actually build computers, so you can imagine a whole large space of problems you can solve, or you can make them smaller.",
                    "label": 0
                },
                {
                    "sent": "And also importantly, it's safe so you don't worry about people getting hurt, and there's no hardware failures, which is just a pain to work through when you're doing experience with real robotics, so there's lots of goals, it's.",
                    "label": 0
                },
                {
                    "sent": "Easy manipulate answer.",
                    "label": 0
                },
                {
                    "sent": "Really interesting rich space that we should be investigating.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to be doing reasoning in these kinds of problem spaces.",
                    "label": 0
                },
                {
                    "sent": "We need some way some kind of glue to tie together.",
                    "label": 0
                },
                {
                    "sent": "We're going to be doing that, so some of the other research areas I mentioned, like transfer, learning, learning, action hierarchies are already kind of starting to look at some ways that we could use like we could.",
                    "label": 0
                },
                {
                    "sent": "We could represent problems we can reason between different problem.",
                    "label": 0
                },
                {
                    "sent": "There's Agent space features where there's a set of core features that are always the same for the agent, even though other feature is going to be changing their inner task mapping.",
                    "label": 0
                },
                {
                    "sent": "So we can look at the map, the state variables in one problem to another problem.",
                    "label": 0
                },
                {
                    "sent": "An horde which is learning high level features from low level sensors, so it's general across a bunch of different changes, but I'd like to highlight is object oriented DPS.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An object or MVP's are kind of like a growth of just using a standard vector state vector representation of the world.",
                    "label": 0
                },
                {
                    "sent": "Instead, the world is going to consist of a bunch of different objects that each belong to classes they can manage.",
                    "label": 0
                },
                {
                    "sent": "We have a robot in this environment we have rooms which are objects, we've doors, which are objects.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And blocks and each object in the world has its own kind of properties.",
                    "label": 0
                },
                {
                    "sent": "You can sign into it.",
                    "label": 0
                },
                {
                    "sent": "So here you can imagine the robot has a position.",
                    "label": 0
                },
                {
                    "sent": "In this simplified world, their blocks have positioned shape, color and things like that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the next thing about doing this kind of object representation is you can do a lot of generalization that works across different environments because you can factor it within the objects themselves.",
                    "label": 0
                },
                {
                    "sent": "So in particular, in this case you imagine the robot might learn that pushing a chair moves both him and the Sheriff there adjacent to each other.",
                    "label": 0
                },
                {
                    "sent": "So this is so.",
                    "label": 0
                },
                {
                    "sent": "This is really nice because we had lots of different objects in the world.",
                    "label": 0
                },
                {
                    "sent": "Maybe the task requires a whole lot of actions, but there's some similarity you can learn between them because of the dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we're going to be working this kind of problem, spaces maybe using these kind of expressive representations.",
                    "label": 0
                },
                {
                    "sent": "We would like to have a tool so we have one that hopefully you'll use in like it's called burlap.",
                    "label": 0
                },
                {
                    "sent": "You can get blocked so proud that you it's a reinforcement learning and planning library.",
                    "label": 0
                },
                {
                    "sent": "It has tools for working with problem generators and state generators.",
                    "label": 0
                },
                {
                    "sent": "It has a known DP state representation underneath.",
                    "label": 0
                },
                {
                    "sent": "You can do this kind of expressive tasks and representations and also astharoshe interface.",
                    "label": 0
                },
                {
                    "sent": "We're working with robots and also just very recently started building an released.",
                    "label": 0
                },
                {
                    "sent": "A Minecraft interface so you can have burlap.",
                    "label": 0
                },
                {
                    "sent": "Airl owns controlling Minecraft player in real Minecraft.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as far as what we can learn these types environments, there's actually a whole bunch of different things we can learn.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, we can learn world physics.",
                    "label": 0
                },
                {
                    "sent": "We can basically do learning to learn.",
                    "label": 0
                },
                {
                    "sent": "The agent can learn things that allowed to learn faster environments.",
                    "label": 0
                },
                {
                    "sent": "There's learning to plan, so the agent might be able to plan environment, but planning is slow, so you want to learn how to accelerate your planning.",
                    "label": 0
                },
                {
                    "sent": "There's task decomposition and state representation, and also even slightly tangentially learning about language that you might interact with the person and how it applies to these worlds.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As far as learning to learn, I'm running out of time very quickly and this isn't helping.",
                    "label": 1
                },
                {
                    "sent": "OK, so in this case we imagine if we had a whole bunch of different learning outcomes and each had their own different parameters, but we had to deploy these learnings to solve a whole bunch of future problems.",
                    "label": 0
                },
                {
                    "sent": "How we choose the right one?",
                    "label": 0
                },
                {
                    "sent": "We've introduced some means so you can build some generalization down space and just training data, training each of these algorithms classes on a set of data so you can figure out how well actually work across the whole distribution.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As far as learning to plan, we have some work where we're learning what actions are useful for the kind of goal you're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "Any given time in the states here ends.",
                    "label": 0
                },
                {
                    "sent": "You can prune away your relevant actions and narrow the search space.",
                    "label": 0
                },
                {
                    "sent": "We had this working in simplified versions of Minecraft and ended up speeding up our plan results quite a bit.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a poster actually, so if you want to talk about those things, please come find me and we can get into more detail or we can talk about anything we've talked about here.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, I promoted using working to our problem general.",
                    "label": 0
                },
                {
                    "sent": "We have a bunch of things that have changed overtime and some things that are constant that you can cash away an reuse talked about using Robotics an Minecraft as being interesting.",
                    "label": 0
                },
                {
                    "sent": "Problem areas we can exploit is very rich types of problems that are changing overtime and talk about some new machinery and some tools.",
                    "label": 0
                },
                {
                    "sent": "With burlap you can use for working in Robotics and Minecraft and doing a bunch of other stuff.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really just wanted on the collaborators who worked on the learning to learn, learn to plan stuff that I mentioned.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And thank you for your time.",
                    "label": 0
                },
                {
                    "sent": "Very interesting model and very nice talk.",
                    "label": 0
                },
                {
                    "sent": "Are you assuming that the problems are appear?",
                    "label": 0
                },
                {
                    "sent": "Are I ID from some distribution or can we have for example structure like promap then problem be the problem?",
                    "label": 0
                },
                {
                    "sent": "See bacteria.",
                    "label": 0
                },
                {
                    "sent": "That's a great question, so I think we feel either way.",
                    "label": 0
                },
                {
                    "sent": "I think the important thing is that we moved to the problem general, but we're also interested in the notion of scaffolding.",
                    "label": 0
                },
                {
                    "sent": "In particular, where you can have easy problems.",
                    "label": 0
                },
                {
                    "sent": "1st and the agents building that to the Minecraft stuff actually was kind of scaffold, did he said?",
                    "label": 0
                },
                {
                    "sent": "Here's a bunch of easy problems we know you can plan in pretty well.",
                    "label": 0
                },
                {
                    "sent": "It solves those.",
                    "label": 0
                },
                {
                    "sent": "And then we gave it harder problems and it's solved the hard problems better.",
                    "label": 0
                },
                {
                    "sent": "And if it didn't do any training before, so so ID, sure, but I think scaffolding also is a really interesting thing we should be looking at as well.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So as I've spent a fair amount of time down the rabbit hole of what are objects and concepts and.",
                    "label": 0
                },
                {
                    "sent": "In Minecraft, I can see how you might.",
                    "label": 0
                },
                {
                    "sent": "I mean, it literally does have objects in the world that are fairly well defined, but the whole robot pushing pushing a chair.",
                    "label": 0
                },
                {
                    "sent": "What's a chair?",
                    "label": 0
                },
                {
                    "sent": "What can you push?",
                    "label": 0
                },
                {
                    "sent": "So in the new kind of new machinery you're presenting, the object oriented MTPS.",
                    "label": 0
                },
                {
                    "sent": "How do you avoid the massive hand engineering problem you have that's tremendously domain specific?",
                    "label": 0
                },
                {
                    "sent": "And yeah, so well, I think I think one thing we should look at doing with that is building kind of multiple classes and hierarchy of your objects so things are related.",
                    "label": 0
                },
                {
                    "sent": "You can have right now there's attributes of some things are going to be different objects with similar custom have similar types of attributes that bind them together, but now it is a hand engineering exercise by the.",
                    "label": 0
                },
                {
                    "sent": "Programmers as programmers.",
                    "label": 0
                },
                {
                    "sent": "So I think learning these objects in particular is also going to be really useful, and that's something we're interested in.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so remove the burn from the programmer would be good.",
                    "label": 0
                },
                {
                    "sent": "Great talk so one of the cool things about Minecraft is that people play it an I wonder if you've compared or thought about comparing how your algorithms perform relative to humans and humans do on your problem set badly, I think because Minecraft is so large that the algorithms are the humans do badly, so the algorithms the space is so large it's really hard to get any traction at all with the classic ones we have right now.",
                    "label": 0
                },
                {
                    "sent": "Which is why it's a really great space to go.",
                    "label": 0
                },
                {
                    "sent": "But the human thing is also really interesting because.",
                    "label": 0
                },
                {
                    "sent": "Like there's just data on the Internet, but you can.",
                    "label": 0
                },
                {
                    "sent": "My Nan used to improve these items, so as far as there's language and there's even videos an maybe even you can get people to actually playing and recording their their movements, or set this up on EM to cause something to actually get you know, control data in the exact same problems that you're.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that would be really nice.",
                    "label": 0
                },
                {
                    "sent": "So you're pointing out a lot of interesting issues about how you manage, change and deal with different kinds of change.",
                    "label": 0
                },
                {
                    "sent": "I don't know, it's I just want to say it's it's not really necessary to formulate it as a as a change in the problem or as a problem generator that you can just consider it.",
                    "label": 0
                },
                {
                    "sent": "One problem that's continually changing maybe different rates in different parts of it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so to an extent you can imagine it being a very large MDP an with only piece that tends to be actually how we're doing what we say.",
                    "label": 0
                },
                {
                    "sent": "There's one large MVP.",
                    "label": 0
                },
                {
                    "sent": "One caveat I put with that is the goal itself might change, and so we can have some.",
                    "label": 0
                },
                {
                    "sent": "Maybe humans only have one reward function that's there, always an we're kind of making up the rewards in between as far as actual intelligent agents, we're going to build that might not quite be the case.",
                    "label": 0
                },
                {
                    "sent": "We might be actually changing the goal.",
                    "label": 0
                },
                {
                    "sent": "It's going to happen any given time, so as far as the goal changing that might still be important in terms of the problem generator.",
                    "label": 0
                },
                {
                    "sent": "Paradigm.",
                    "label": 0
                }
            ]
        }
    }
}