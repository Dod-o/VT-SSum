{
    "id": "gpfa737i7lw5zle65aeas42gkldlcyab",
    "title": "Automated Selection of Social Media Responses to News",
    "info": {
        "author": [
            "Tadej \u0160tajner, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Sept. 27, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2013_stajner_news_responses/",
    "segmentation": [
        [
            "I'm today and this is joint work with."
        ],
        [
            "Barsana, Maria and Mark and Alejandro and I'll talk about automatic selection of social media responses to news."
        ],
        [
            "So to motivate.",
            "When a lot of news is produced through traditional channels.",
            "Even more.",
            "Content is produced through social media.",
            "Lot of content related to those events is delivered and produced through social media.",
            "So for instance, people post messages that they want to share their particular opinion.",
            "They want to add, add, or refute some information about the topic or the article that specially being discussed.",
            "So we could imagine that displaying those responses from social media could make an experience of reading news articles more interesting."
        ],
        [
            "So the situation to have looks like this.",
            "We have a news article there on the left and there's like a set of tweets referring to that news article, and this can be in the hundreds, even thousands, and what we want to have is the selection of a interesting subset of tweets.",
            "So what is actually interesting is a bit of a philosophical question, but I think here we have a bit more quantitative approach to figure this out.",
            "So just the setup."
        ],
        [
            "And our hypothesis for this is that an interesting subset of its contains a diverse set of tweets which are informative, opinionated, and have some popularity and their produced by users who have some authority on the topic.",
            "So."
        ],
        [
            "What are the problems that we're dealing with when tackling this problem?",
            "So of course there is a volume.",
            "There's a huge number of tweets and The thing is that they don't actually say that many different things in the end, so a lot of people basically either have one or the other opinion, and they just say it in a different way.",
            "Often they just repeat the title of the article and somehow endorse and share it, but don't add anything else.",
            "And often they also produce something which is redundant to other people, so some people just have different ways of expressing themselves.",
            "But some are actually insightful and useful, so these are the ones we'd like to have."
        ],
        [
            "And to formalize this problem statement, we're looking for a set of.",
            "So, given that we have a set of messages M that relate to a single news article, we want a subset South that is of size K, which is like a smaller number that should be the most interesting."
        ],
        [
            "So what we propose here is computational model that takes into account all those four indicators I mentioned earlier that describe interestingness.",
            "That's our model by utility function R and a set level diversity indicator that uses normalized entropy to as a indicator of diversity, so I'll explain it later.",
            "What this actually do.",
            "But the point is that these are the two components and the output of those is an objective function that gives us selection criteria for a particular tweet, so."
        ],
        [
            "So the solution then for this objective function is actually to find the Set S star that maximizes this function G, which is weighted linear combination of individual matches scores, which is the arbiter over there and the normalized entropy which is H_0.",
            "So those two factors are the ones which we hypothesize that actually are important for producing interesting subset.",
            "So why?",
            "How can actually be make an approach that optimizes this in an efficient way?"
        ],
        [
            "So we look at what kind of properties that is have and to achieve this without demonstrate that this function G is actually a submodular set function.",
            "Meaning that the difference of the value of the function that element makes decreases with the set size.",
            "So for instance, this means that if you have a smaller set, adding some particular tweet makes a bigger difference.",
            "Then if this set was already bigger.",
            "So this actually has lots of intuitionist, similar to what diversity means.",
            "So if you already have a quite big set of messages that already show various aspects of diversity, adding one more.",
            "Wouldn't really diversify that much because you already covered the main topics."
        ],
        [
            "So we just then show that this R is submodular.",
            "Basically by definition because it's independent of the actual set.",
            "So because this is just a sum of individual tweets course, this holds automatically and entropy is also known to be submodular since 1973.",
            "That means that a linear combination of those two is still submodular, and this gives us a guarantee that greedy approach will be at most 1 -- 1 / 3 times worse than the best possible solution to the problem.",
            "So.",
            "This makes."
        ],
        [
            "It's easy for us to actually make a efficient algorithm.",
            "And I will now go with deeper into what the scoring function is.",
            "So our is a function that's actually modeled as a supervised regression.",
            "And basically we want to learn models parameters, Theta that actually then are basically feature weights that give us the final score of each individual message given a supervised model.",
            "And we use this by training on support vector regressions by annotations on individual tweets.",
            "So how we measure that?",
            "I'll get a bit later.",
            "Just to clarify what."
        ],
        [
            "Scoring means and this is basically this simple greedy algorithm.",
            "This is actually similar to one of the related works I blame mentioned earlier, but basically just to go shortly.",
            "The first tweet is selected as the one which is has the higher score.",
            "Since we can't the entropy of an empty set is 0, there's no wait, no news to actually calculate entropy, and then we iteratively add tweet or a message in general that actually gives us the highest boost in this function G. In case we would edit, so basically we look at all candidates and we see which one would boost this objective function in the most so, and then when you reach the desired size K that's finished so."
        ],
        [
            "One more important key thinking kissing here is that this scoring features are and selection features that go into the entropy are different.",
            "The thing is that when you're calculating entropy, have to look at the probability model and that means that you're looking at probability of some feature occurring, whereas in scoring we model this as a linear SVM.",
            "So these are like continuous features.",
            "But they're also different in a way that we want to diversify across some features, and not all, and we want to also rank on some and not.",
            "Also.",
            "This subsets are basically like construction of domain expertise, so for selection we're looking at individual engrams.",
            "This basically means that how likely that some engram has a curd location on the counter Garrity, and whether something is retweet or reply.",
            "And those sets give us some probability of a tweet occurring in a given set.",
            "And that those probabilities can then be used to calculate entropy of a sample for scoring features.",
            "There's a much bigger set.",
            "A lot of those are already quite typical for other social media approaches.",
            "It turns out that a lot of those problems can be handled in a way that with a really rich feature set, and this is also one of those.",
            "I would emphasize here that we are also using things like quality models for text intensity detection, controversy detection.",
            "Besides the typical sentiment and other textual.",
            "And social features.",
            "And of course we also use user and user topic authority, which is an important piece of the actual hypothesis here and for details on how we generate this, look at the paper because it's quite a sophisticated piece of."
        ],
        [
            "Work here and.",
            "Let's look at now how other people did it, and why did how did we come up with this approach?",
            "So one part of related work was diversity based sampling two years ago at ICW SM and they actually had a similar task but they just wanted to optimize for diversity so that the goal there was that people would like to see diverse sets of tweets.",
            "They didn't consider any scoring in for individual messages, but the method that they used for this.",
            "Iteratively adding things with regard to entropy was similar to what we then ended up.",
            "In our approach.",
            "And Furthermore, in experience we label this as diversity, as the actual approach.",
            "But The thing is that for interesting, yes, you actually can objectively say that one tweet is more interesting than the other, and this approach doesn't model that second."
        ],
        [
            "The second baseline for using these social context summarization.",
            "This is also two years ago from a cigar conference and the goal here was to jointly summarize news articles.",
            "So select the top sentences in an article that would summarize the content and select the top tweets that would summarize the social response to those news articles.",
            "So this is a bit closer.",
            "They also there already modeling importance of individual tweets and they base their model on a conditional random field that constructs a factor graph over the.",
            "Tweets and connects them with the sentences of their news articles, so it's also has the same domain.",
            "And we label this by DWG as a dual wing factor graph which is the author notation or.",
            "One variation is called other plus, which is logistic regression plus simplified version, which actually is a linear model over the tweets and."
        ],
        [
            "Our contribution, So what do we think that our work can do a bit better, so we focus on more on this whole notion of interestingness instead of just looking at either informativeness or diversity.",
            "And we also consider a bit richer texture features that take care of the texture redundancy there.",
            "Of course the.",
            "Extra features that were using this linguistic parts and behavioral parts with controversy, intensity and texture quality make a difference.",
            "And of course in the end, the approach that we have provided erratic guarantee of the sample quality given this objective function, we."
        ],
        [
            "So just to go through the notation for the experiments, the diversity other plus in DWG are the baselines and our approach is we know them by having SVR with just having message coding.",
            "So this is just this R function that does the work having entropy having just the age 0 function doing the selection.",
            "So basically this one doesn't look at diversity.",
            "This one looks at entropy alone and then a combination is basically that.",
            "The proposed method that we have is combining the scoring and the selection parts.",
            "So."
        ],
        [
            "And we did two scenarios, so for the first one was labeling individual messages in either minus one 0 + 1 for this course on three criteria.",
            "So as I mentioned interesting, this is the primary thing that we're looking at, and informative and opinionated are two of them, which are a bit difficult to do automatically.",
            "So we had annotators label them.",
            "And popularity and authority were done automatically.",
            "So, as I mentioned earlier, the goal is to decompose interesting Ness and see what kind of models it best.",
            "We did this by having."
        ],
        [
            "20,000 messages from Twitter annotated they're referring to 45 articles.",
            "We used 14 editors and we annotated this for those three indicators."
        ],
        [
            "Evaluation for this was using F1 and Rouge, and the idea is that we want to measure how closely these measures the ideal output.",
            "So how can we look at that result?"
        ],
        [
            "Doing this basically gives us this table, so here I'll just go.",
            "In short, what happens is that our approaches in general overcome the baselines and interestingness LR plus is slightly better on our two operators.",
            "But this is not statistically significant.",
            "And Interestingly, if we just use entropy, R2 scores are higher.",
            "But then if we just use scoring so The thing is it makes sense because R2 directly optimizes for diversifying the content, whereas the F1 looks for exact messages that are important.",
            "So here this doesn't give us the whole store."
        ],
        [
            "And what is a bit nicer is then we can actually use this data to look at what is interesting Nest made of here.",
            "So here's a really simplified model.",
            "It explains some of the variance here, but The thing is, the majority signal is from informant informativeness.",
            "There's a strong component for opinionated knus and a bit smaller in popularity and user authority.",
            "So Interestingly, popularity was quite low and the reason for that is that it really correlate strongly with authority.",
            "And basically when we run this regression authority explained away a lot of this signal and popularity just had the remainder there.",
            "So this is like a simple model of what is interesting, knus in a way.",
            "And actually, unfortunately Informativeness is, as you saw earlier, is the most difficult one to actually model.",
            "It has the lowest scores and the Inter annotator agreement here was actually the lowest."
        ],
        [
            "So the second user study that it was actually comparing sets of messages.",
            "So before we had single messages here, we're looking at pairwise sets.",
            "So let's see method A generates attend to its method.",
            "We generate 10 tweets and let's see which one is better and why it's better.",
            "So here we want to say is combining this selection scoring so their selection scoring.",
            "Is this a good idea or is just one enough?",
            "And of course, how do we prove?"
        ],
        [
            "I'm against baselines.",
            "And it turns out that we outperformed baselines by quite a significant margin.",
            "And it turns out also that.",
            "Having squad scoring is also preferred to just having entropy or just having this SVR scoring alone.",
            "So basically combination gives you had higher votes for preference than having just one of them and also comparing against baselines as we're entropy was basically preferred quite significantly more than either of those.",
            "And the baseline themselves.",
            "There is a small difference, but the significance is not really something that would make a conclusion.",
            "So."
        ],
        [
            "Why did people pick this one over the other?",
            "So here we looked at all possible pairs of methods and we also ask people why did they choose one over the other.",
            "So here there's lots of numbers, but I would outline here this one.",
            "Numbers generally correspond to the equation I gave earlier, like majority of is informativeness then opinion it is and the others.",
            "And this has a similar distribution but in some cases operated.",
            "This is much higher.",
            "So this basically shows us that it's important to actually have.",
            "Which features which take into account this opinionated Ness?"
        ],
        [
            "So just to conclude, we show that this SVR entropy, which is a near optimal solution for this message selection objective optimization problems with defined, outperforms the baselines we had.",
            "And it also gives us shows that it's important to combine both methods selection and scoring.",
            "And also we show that how various indicators affect interestingness.",
            "So, for instance, Informativeness, even though it's hard to model it, was being considered most important, followed by opinionated yonassan, sometimes user authority."
        ],
        [
            "So when we look at message sets, there's also a bit different stories, so here it still influences the most important.",
            "While opinionated Ness had quite high high scores in some other places where the difference between sampling methods was basically in the part where they actually either they modeled this explicitly or not.",
            "So that makes it interesting that sometimes message sets have different properties that individual messages, for instance.",
            "In"
        ],
        [
            "Future we would like to extend this by incorporating a bit different and more author and message level indicators, so it's seen that social media benefits greatly with having more diverse feature sets.",
            "It is a big thing, probably in personalizing this interesting model and this is one reason that there was low Internet letter agreement for informativeness is because people consider different things to be informative and even though we defined it clearly, sometimes they used their prior knowledge to consider what was very informative or not.",
            "An interesting upgrade for this is not just to select messages, but also to have an abstractive summarization of them.",
            "So this leads to the pre quite productive field of text summarization that could be connected to this.",
            "And given that now it's quite popular to do big data on online sampling, the project would be actually able to do this in a stream of tweets.",
            "So right now we assume that this is a batch that we're looking at single pass, but in general online sampling and infinite Streamwood.",
            "Have an interesting variation on this.",
            "So."
        ],
        [
            "So thanks for listening any questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm today and this is joint work with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Barsana, Maria and Mark and Alejandro and I'll talk about automatic selection of social media responses to news.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to motivate.",
                    "label": 0
                },
                {
                    "sent": "When a lot of news is produced through traditional channels.",
                    "label": 1
                },
                {
                    "sent": "Even more.",
                    "label": 1
                },
                {
                    "sent": "Content is produced through social media.",
                    "label": 0
                },
                {
                    "sent": "Lot of content related to those events is delivered and produced through social media.",
                    "label": 1
                },
                {
                    "sent": "So for instance, people post messages that they want to share their particular opinion.",
                    "label": 0
                },
                {
                    "sent": "They want to add, add, or refute some information about the topic or the article that specially being discussed.",
                    "label": 0
                },
                {
                    "sent": "So we could imagine that displaying those responses from social media could make an experience of reading news articles more interesting.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the situation to have looks like this.",
                    "label": 0
                },
                {
                    "sent": "We have a news article there on the left and there's like a set of tweets referring to that news article, and this can be in the hundreds, even thousands, and what we want to have is the selection of a interesting subset of tweets.",
                    "label": 1
                },
                {
                    "sent": "So what is actually interesting is a bit of a philosophical question, but I think here we have a bit more quantitative approach to figure this out.",
                    "label": 0
                },
                {
                    "sent": "So just the setup.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our hypothesis for this is that an interesting subset of its contains a diverse set of tweets which are informative, opinionated, and have some popularity and their produced by users who have some authority on the topic.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What are the problems that we're dealing with when tackling this problem?",
                    "label": 0
                },
                {
                    "sent": "So of course there is a volume.",
                    "label": 1
                },
                {
                    "sent": "There's a huge number of tweets and The thing is that they don't actually say that many different things in the end, so a lot of people basically either have one or the other opinion, and they just say it in a different way.",
                    "label": 1
                },
                {
                    "sent": "Often they just repeat the title of the article and somehow endorse and share it, but don't add anything else.",
                    "label": 1
                },
                {
                    "sent": "And often they also produce something which is redundant to other people, so some people just have different ways of expressing themselves.",
                    "label": 0
                },
                {
                    "sent": "But some are actually insightful and useful, so these are the ones we'd like to have.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to formalize this problem statement, we're looking for a set of.",
                    "label": 0
                },
                {
                    "sent": "So, given that we have a set of messages M that relate to a single news article, we want a subset South that is of size K, which is like a smaller number that should be the most interesting.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we propose here is computational model that takes into account all those four indicators I mentioned earlier that describe interestingness.",
                    "label": 0
                },
                {
                    "sent": "That's our model by utility function R and a set level diversity indicator that uses normalized entropy to as a indicator of diversity, so I'll explain it later.",
                    "label": 1
                },
                {
                    "sent": "What this actually do.",
                    "label": 0
                },
                {
                    "sent": "But the point is that these are the two components and the output of those is an objective function that gives us selection criteria for a particular tweet, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the solution then for this objective function is actually to find the Set S star that maximizes this function G, which is weighted linear combination of individual matches scores, which is the arbiter over there and the normalized entropy which is H_0.",
                    "label": 1
                },
                {
                    "sent": "So those two factors are the ones which we hypothesize that actually are important for producing interesting subset.",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "How can actually be make an approach that optimizes this in an efficient way?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we look at what kind of properties that is have and to achieve this without demonstrate that this function G is actually a submodular set function.",
                    "label": 0
                },
                {
                    "sent": "Meaning that the difference of the value of the function that element makes decreases with the set size.",
                    "label": 1
                },
                {
                    "sent": "So for instance, this means that if you have a smaller set, adding some particular tweet makes a bigger difference.",
                    "label": 0
                },
                {
                    "sent": "Then if this set was already bigger.",
                    "label": 0
                },
                {
                    "sent": "So this actually has lots of intuitionist, similar to what diversity means.",
                    "label": 0
                },
                {
                    "sent": "So if you already have a quite big set of messages that already show various aspects of diversity, adding one more.",
                    "label": 0
                },
                {
                    "sent": "Wouldn't really diversify that much because you already covered the main topics.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we just then show that this R is submodular.",
                    "label": 0
                },
                {
                    "sent": "Basically by definition because it's independent of the actual set.",
                    "label": 0
                },
                {
                    "sent": "So because this is just a sum of individual tweets course, this holds automatically and entropy is also known to be submodular since 1973.",
                    "label": 1
                },
                {
                    "sent": "That means that a linear combination of those two is still submodular, and this gives us a guarantee that greedy approach will be at most 1 -- 1 / 3 times worse than the best possible solution to the problem.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This makes.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's easy for us to actually make a efficient algorithm.",
                    "label": 0
                },
                {
                    "sent": "And I will now go with deeper into what the scoring function is.",
                    "label": 0
                },
                {
                    "sent": "So our is a function that's actually modeled as a supervised regression.",
                    "label": 1
                },
                {
                    "sent": "And basically we want to learn models parameters, Theta that actually then are basically feature weights that give us the final score of each individual message given a supervised model.",
                    "label": 0
                },
                {
                    "sent": "And we use this by training on support vector regressions by annotations on individual tweets.",
                    "label": 1
                },
                {
                    "sent": "So how we measure that?",
                    "label": 0
                },
                {
                    "sent": "I'll get a bit later.",
                    "label": 0
                },
                {
                    "sent": "Just to clarify what.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Scoring means and this is basically this simple greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is actually similar to one of the related works I blame mentioned earlier, but basically just to go shortly.",
                    "label": 0
                },
                {
                    "sent": "The first tweet is selected as the one which is has the higher score.",
                    "label": 0
                },
                {
                    "sent": "Since we can't the entropy of an empty set is 0, there's no wait, no news to actually calculate entropy, and then we iteratively add tweet or a message in general that actually gives us the highest boost in this function G. In case we would edit, so basically we look at all candidates and we see which one would boost this objective function in the most so, and then when you reach the desired size K that's finished so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One more important key thinking kissing here is that this scoring features are and selection features that go into the entropy are different.",
                    "label": 1
                },
                {
                    "sent": "The thing is that when you're calculating entropy, have to look at the probability model and that means that you're looking at probability of some feature occurring, whereas in scoring we model this as a linear SVM.",
                    "label": 0
                },
                {
                    "sent": "So these are like continuous features.",
                    "label": 0
                },
                {
                    "sent": "But they're also different in a way that we want to diversify across some features, and not all, and we want to also rank on some and not.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "This subsets are basically like construction of domain expertise, so for selection we're looking at individual engrams.",
                    "label": 0
                },
                {
                    "sent": "This basically means that how likely that some engram has a curd location on the counter Garrity, and whether something is retweet or reply.",
                    "label": 0
                },
                {
                    "sent": "And those sets give us some probability of a tweet occurring in a given set.",
                    "label": 1
                },
                {
                    "sent": "And that those probabilities can then be used to calculate entropy of a sample for scoring features.",
                    "label": 0
                },
                {
                    "sent": "There's a much bigger set.",
                    "label": 1
                },
                {
                    "sent": "A lot of those are already quite typical for other social media approaches.",
                    "label": 0
                },
                {
                    "sent": "It turns out that a lot of those problems can be handled in a way that with a really rich feature set, and this is also one of those.",
                    "label": 0
                },
                {
                    "sent": "I would emphasize here that we are also using things like quality models for text intensity detection, controversy detection.",
                    "label": 0
                },
                {
                    "sent": "Besides the typical sentiment and other textual.",
                    "label": 0
                },
                {
                    "sent": "And social features.",
                    "label": 1
                },
                {
                    "sent": "And of course we also use user and user topic authority, which is an important piece of the actual hypothesis here and for details on how we generate this, look at the paper because it's quite a sophisticated piece of.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work here and.",
                    "label": 0
                },
                {
                    "sent": "Let's look at now how other people did it, and why did how did we come up with this approach?",
                    "label": 0
                },
                {
                    "sent": "So one part of related work was diversity based sampling two years ago at ICW SM and they actually had a similar task but they just wanted to optimize for diversity so that the goal there was that people would like to see diverse sets of tweets.",
                    "label": 0
                },
                {
                    "sent": "They didn't consider any scoring in for individual messages, but the method that they used for this.",
                    "label": 0
                },
                {
                    "sent": "Iteratively adding things with regard to entropy was similar to what we then ended up.",
                    "label": 0
                },
                {
                    "sent": "In our approach.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, in experience we label this as diversity, as the actual approach.",
                    "label": 0
                },
                {
                    "sent": "But The thing is that for interesting, yes, you actually can objectively say that one tweet is more interesting than the other, and this approach doesn't model that second.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second baseline for using these social context summarization.",
                    "label": 1
                },
                {
                    "sent": "This is also two years ago from a cigar conference and the goal here was to jointly summarize news articles.",
                    "label": 0
                },
                {
                    "sent": "So select the top sentences in an article that would summarize the content and select the top tweets that would summarize the social response to those news articles.",
                    "label": 0
                },
                {
                    "sent": "So this is a bit closer.",
                    "label": 0
                },
                {
                    "sent": "They also there already modeling importance of individual tweets and they base their model on a conditional random field that constructs a factor graph over the.",
                    "label": 1
                },
                {
                    "sent": "Tweets and connects them with the sentences of their news articles, so it's also has the same domain.",
                    "label": 0
                },
                {
                    "sent": "And we label this by DWG as a dual wing factor graph which is the author notation or.",
                    "label": 0
                },
                {
                    "sent": "One variation is called other plus, which is logistic regression plus simplified version, which actually is a linear model over the tweets and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our contribution, So what do we think that our work can do a bit better, so we focus on more on this whole notion of interestingness instead of just looking at either informativeness or diversity.",
                    "label": 1
                },
                {
                    "sent": "And we also consider a bit richer texture features that take care of the texture redundancy there.",
                    "label": 0
                },
                {
                    "sent": "Of course the.",
                    "label": 0
                },
                {
                    "sent": "Extra features that were using this linguistic parts and behavioral parts with controversy, intensity and texture quality make a difference.",
                    "label": 1
                },
                {
                    "sent": "And of course in the end, the approach that we have provided erratic guarantee of the sample quality given this objective function, we.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just to go through the notation for the experiments, the diversity other plus in DWG are the baselines and our approach is we know them by having SVR with just having message coding.",
                    "label": 0
                },
                {
                    "sent": "So this is just this R function that does the work having entropy having just the age 0 function doing the selection.",
                    "label": 0
                },
                {
                    "sent": "So basically this one doesn't look at diversity.",
                    "label": 0
                },
                {
                    "sent": "This one looks at entropy alone and then a combination is basically that.",
                    "label": 0
                },
                {
                    "sent": "The proposed method that we have is combining the scoring and the selection parts.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we did two scenarios, so for the first one was labeling individual messages in either minus one 0 + 1 for this course on three criteria.",
                    "label": 1
                },
                {
                    "sent": "So as I mentioned interesting, this is the primary thing that we're looking at, and informative and opinionated are two of them, which are a bit difficult to do automatically.",
                    "label": 0
                },
                {
                    "sent": "So we had annotators label them.",
                    "label": 0
                },
                {
                    "sent": "And popularity and authority were done automatically.",
                    "label": 1
                },
                {
                    "sent": "So, as I mentioned earlier, the goal is to decompose interesting Ness and see what kind of models it best.",
                    "label": 0
                },
                {
                    "sent": "We did this by having.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "20,000 messages from Twitter annotated they're referring to 45 articles.",
                    "label": 0
                },
                {
                    "sent": "We used 14 editors and we annotated this for those three indicators.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evaluation for this was using F1 and Rouge, and the idea is that we want to measure how closely these measures the ideal output.",
                    "label": 0
                },
                {
                    "sent": "So how can we look at that result?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Doing this basically gives us this table, so here I'll just go.",
                    "label": 0
                },
                {
                    "sent": "In short, what happens is that our approaches in general overcome the baselines and interestingness LR plus is slightly better on our two operators.",
                    "label": 0
                },
                {
                    "sent": "But this is not statistically significant.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, if we just use entropy, R2 scores are higher.",
                    "label": 0
                },
                {
                    "sent": "But then if we just use scoring so The thing is it makes sense because R2 directly optimizes for diversifying the content, whereas the F1 looks for exact messages that are important.",
                    "label": 0
                },
                {
                    "sent": "So here this doesn't give us the whole store.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what is a bit nicer is then we can actually use this data to look at what is interesting Nest made of here.",
                    "label": 0
                },
                {
                    "sent": "So here's a really simplified model.",
                    "label": 0
                },
                {
                    "sent": "It explains some of the variance here, but The thing is, the majority signal is from informant informativeness.",
                    "label": 0
                },
                {
                    "sent": "There's a strong component for opinionated knus and a bit smaller in popularity and user authority.",
                    "label": 0
                },
                {
                    "sent": "So Interestingly, popularity was quite low and the reason for that is that it really correlate strongly with authority.",
                    "label": 0
                },
                {
                    "sent": "And basically when we run this regression authority explained away a lot of this signal and popularity just had the remainder there.",
                    "label": 0
                },
                {
                    "sent": "So this is like a simple model of what is interesting, knus in a way.",
                    "label": 0
                },
                {
                    "sent": "And actually, unfortunately Informativeness is, as you saw earlier, is the most difficult one to actually model.",
                    "label": 0
                },
                {
                    "sent": "It has the lowest scores and the Inter annotator agreement here was actually the lowest.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second user study that it was actually comparing sets of messages.",
                    "label": 0
                },
                {
                    "sent": "So before we had single messages here, we're looking at pairwise sets.",
                    "label": 0
                },
                {
                    "sent": "So let's see method A generates attend to its method.",
                    "label": 0
                },
                {
                    "sent": "We generate 10 tweets and let's see which one is better and why it's better.",
                    "label": 0
                },
                {
                    "sent": "So here we want to say is combining this selection scoring so their selection scoring.",
                    "label": 0
                },
                {
                    "sent": "Is this a good idea or is just one enough?",
                    "label": 0
                },
                {
                    "sent": "And of course, how do we prove?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm against baselines.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that we outperformed baselines by quite a significant margin.",
                    "label": 0
                },
                {
                    "sent": "And it turns out also that.",
                    "label": 0
                },
                {
                    "sent": "Having squad scoring is also preferred to just having entropy or just having this SVR scoring alone.",
                    "label": 0
                },
                {
                    "sent": "So basically combination gives you had higher votes for preference than having just one of them and also comparing against baselines as we're entropy was basically preferred quite significantly more than either of those.",
                    "label": 0
                },
                {
                    "sent": "And the baseline themselves.",
                    "label": 0
                },
                {
                    "sent": "There is a small difference, but the significance is not really something that would make a conclusion.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Why did people pick this one over the other?",
                    "label": 0
                },
                {
                    "sent": "So here we looked at all possible pairs of methods and we also ask people why did they choose one over the other.",
                    "label": 0
                },
                {
                    "sent": "So here there's lots of numbers, but I would outline here this one.",
                    "label": 0
                },
                {
                    "sent": "Numbers generally correspond to the equation I gave earlier, like majority of is informativeness then opinion it is and the others.",
                    "label": 0
                },
                {
                    "sent": "And this has a similar distribution but in some cases operated.",
                    "label": 0
                },
                {
                    "sent": "This is much higher.",
                    "label": 0
                },
                {
                    "sent": "So this basically shows us that it's important to actually have.",
                    "label": 0
                },
                {
                    "sent": "Which features which take into account this opinionated Ness?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to conclude, we show that this SVR entropy, which is a near optimal solution for this message selection objective optimization problems with defined, outperforms the baselines we had.",
                    "label": 0
                },
                {
                    "sent": "And it also gives us shows that it's important to combine both methods selection and scoring.",
                    "label": 0
                },
                {
                    "sent": "And also we show that how various indicators affect interestingness.",
                    "label": 1
                },
                {
                    "sent": "So, for instance, Informativeness, even though it's hard to model it, was being considered most important, followed by opinionated yonassan, sometimes user authority.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when we look at message sets, there's also a bit different stories, so here it still influences the most important.",
                    "label": 1
                },
                {
                    "sent": "While opinionated Ness had quite high high scores in some other places where the difference between sampling methods was basically in the part where they actually either they modeled this explicitly or not.",
                    "label": 0
                },
                {
                    "sent": "So that makes it interesting that sometimes message sets have different properties that individual messages, for instance.",
                    "label": 0
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Future we would like to extend this by incorporating a bit different and more author and message level indicators, so it's seen that social media benefits greatly with having more diverse feature sets.",
                    "label": 1
                },
                {
                    "sent": "It is a big thing, probably in personalizing this interesting model and this is one reason that there was low Internet letter agreement for informativeness is because people consider different things to be informative and even though we defined it clearly, sometimes they used their prior knowledge to consider what was very informative or not.",
                    "label": 1
                },
                {
                    "sent": "An interesting upgrade for this is not just to select messages, but also to have an abstractive summarization of them.",
                    "label": 0
                },
                {
                    "sent": "So this leads to the pre quite productive field of text summarization that could be connected to this.",
                    "label": 1
                },
                {
                    "sent": "And given that now it's quite popular to do big data on online sampling, the project would be actually able to do this in a stream of tweets.",
                    "label": 0
                },
                {
                    "sent": "So right now we assume that this is a batch that we're looking at single pass, but in general online sampling and infinite Streamwood.",
                    "label": 0
                },
                {
                    "sent": "Have an interesting variation on this.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thanks for listening any questions.",
                    "label": 0
                }
            ]
        }
    }
}