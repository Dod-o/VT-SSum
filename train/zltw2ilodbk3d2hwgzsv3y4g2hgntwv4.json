{
    "id": "zltw2ilodbk3d2hwgzsv3y4g2hgntwv4",
    "title": "Function Approximation for Imitation Learning in Humanoid Robots",
    "info": {
        "author": [
            "Rajesh P. N. Rao, Department of Computer Science and Engineering, University of Washington"
        ],
        "published": "Aug. 3, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Robotics"
        ]
    },
    "url": "http://videolectures.net/rraa09_rao_fail/",
    "segmentation": [
        [
            "OK, thank you all for coming in like this.",
            "Thank the organizers for inviting me and.",
            "There we go.",
            "So what I'll talk about today is some work that we've been doing over the last few years on applying ideas from functional approximation.",
            "But to the problem of imitation learning in a humanoid robot, and the work that will describe was done predominantly by a two graduate students, so one is.",
            "Robbie Shorey child, who's actually sitting right there and the other person, is David Grimes, actually graduated, and he's now the startup company and funding for this research has been provided by on our NSF and the Packet Foundation."
        ],
        [
            "So here's the problem that we would like to solve the problem of programming humanoid robot through demonstration.",
            "So.",
            "You could do this using cameras, for example using one or or stereo pair of cameras and trying to capture human motion, and that's a very difficult problem.",
            "That computer vision researchers have been trying to solve for a long time.",
            "What we're doing here is to get around the problem by using a motion capture system that gives you the information about human motion directly.",
            "And.",
            "The particular robot that we're going to use for the results that I'll describe as a hope to humanoid robot.",
            "It's manufactured by Fujitsu, and it's actually a miniature robot about 2 feet in height.",
            "So if you come to the lab tours on Tuesday, you'll get a glimpse of that robot in action and on the left is shown David Grimes wearing a motion capture suit, and you can see that they're reflective markers that allow us to capture the emotion.",
            "And and infer the joint angles based on the information from motion."
        ],
        [
            "For system.",
            "So here's an example of what you get.",
            "So if you have a demonstration such as this one where the demonstrator is, for example, just balancing on one leg seems like a pretty simple sort of simple action, right?",
            "You can recover the joint angles and then try to play that back, and you can imagine what would happen, right?",
            "So there's just a kind of Matic playback of the recovered action in a simulator.",
            "It won't work right?",
            "So basically the dynamics don't match, and so if you are just playing back what you get from a motion capture."
        ],
        [
            "So that doesn't work, and so here's what we're trying to achieve through the research that I'll describe.",
            "So first of all, we'd like to learn from the teacher, but only through the observations of the teacher, and not really allowing the teacher to control the robot.",
            "So so for example, if I ask you to imitate me, right?",
            "So let's say I clap my hand.",
            "Right, you can do that, right?",
            "I'm not controlling you using a joystick, right?",
            "So that's the idea here is that we are trying to learn by observing another robot or another human without actually being remote controlled by an expert or a human, and it's also been called the problem of implicit limitation because you don't have access to the actions.",
            "What you have access to all the states or the observations of the states of an expert or or teacher.",
            "And it's very similar to how humans are learned by watching other humans or their peers.",
            "And also we would like to avoid using physics based models, so we might not really have very accurate models of the the different limb joints in the actual mass and the inertia of the different parts of the robot.",
            "And So what we would like to do is to learn directly based on the dynamics that were encoding in terms of the sensory consequences of the action.",
            "So in other words, we're trying to learn first of all a so called forward model of the system, so the dynamics of the system and we're going to do this without actually basing our model on any kind of knowledge of the physics of the system.",
            "And then, once you've learned that we'd like to use the demonstrations provided by the teacher to restrict the search space for the feasible Act actions that will allow us to imitate the teacher.",
            "And this is very similar to what Peter talked about in terms of the trajectory based search for actions."
        ],
        [
            "And so the first step is solving the so called correspondence problem, right?",
            "So if you have a human that's demonstrating a particular action, and you would like to come up with a set of constraints or the constraints on the state of the robot.",
            "So these are basically joint angles for the different angles of the robot, and in a traditional human in a motion capture system, you might get the joint angles based on skeleton, such as the one that's shown on the right of the human right?",
            "So this product is going to start really match the.",
            "The apology of robots joining points structure of the robot that we have is different from the structured data is being used to model human centric.",
            "We could use is to assume that the human is actually a.",
            "And in large version of the robot, right?",
            "That's basically what it amounts to.",
            "So what we're doing is we're assuming the robot is actually the human has the same structure as a robot, and so you have a.",
            "A schedule that looks like this and then you assume that the markers are on a body that is of that particular skeletal structure, and now you can apply the standard inverse kinematics to get the guesses about the different joint angles.",
            "For now, the robot body as opposed to the human skeletal body.",
            "So that's the way in which we in this case or solve the correspondence problem by just hardcoding it to match the."
        ],
        [
            "Structure of the robot.",
            "The second step is in terms of the dimensionality of what we're getting right, so there's a 25 degrees of freedom robot in our case, and in general it could be much larger, and so if you want to actually optimize this very high dimensional space optimized for actions in the side emotional space, it turns out to be very inefficient, or perhaps even interactable, right?",
            "And so.",
            "One thing you notice is when you look at these actions being performed by human teachers.",
            "Most of these actions to be highly redundant.",
            "If you're restricting to particular classes of actions, I'll give you a few examples in the slice default idea here is could use dimensionality reduction techniques such as even PCA for that matter, to represent the actions that are demonstrated by the human in a low dimensional."
        ],
        [
            "Ace so as an example, here's here's that action that I just showed you in terms of balancing on one leg in a 2 dimensional latent space obtained using PCA, and as you can see, the trajectory through the two dimensional space Maps to each of these particular postures, and so in a sense you can cause we call these eigen closes, right?",
            "So we have eigen faces and you have pretty much anything that is characterized.",
            "Using PCA can tag and eigen on top of it right?",
            "So you can call these.",
            "Like but basically this is a low dimensional representation of the motion of the human.",
            "In this case shown in a in a depiction of using the human robot in a simulator."
        ],
        [
            "And if you look at for example other actions in this case, here's an action that is involves motion.",
            "So there's The Walking action you can see.",
            "Once again, that now you have a periodic motion, so it is a cyclic motion, so you get a starting point.",
            "That's down here.",
            "It's labeled by one, and then as you go up to the point where you start walking, right?",
            "So you can see the different points along the trajectory map to different postures of the robot as it executes this particular motion.",
            "And So what?",
            "This lets us do is it lets us first of all, capture the motion in a low dimensional space, which is going to make it.",
            "Intractable for more features.",
            "To learn the dynamics."
        ],
        [
            "But and so here's the idea.",
            "So you first learn a forward model or the dynamics of the robot using the teacher demonstration.",
            "So this is where we're going to use function approximation techniques to map actions to their observed sensory consequences.",
            "And once you've learned the model of how your body behaves, then you can use that in a way you can use that to infer the stable actions that will then give you approximation to human action that you just saw, and you can iterate between that between.",
            "Including the actions that was learning the OR update your forward models at said better, more accurate imitating this feature."
        ],
        [
            "And so I'll give you 2 examples of this broad approach.",
            "So one is using radial basis function network to approximate the dynamics, and this is a deterministic action selection methodology and the second approach I'll talk about is a probabilistic approach to infer actions based on a dynamic basis in network to encode the dynamics of the other robot.",
            "And so you start out with a NTH order Markov function.",
            "So in this case it's mapping the.",
            "States from time step T to some particular previous time step T -- 10 + 1 and the actions for the same time period to the next stage.",
            "So this is basically the standard and order Markov function.",
            "So in our case we use a second order for the examples shown in the in the rest of the talk.",
            "And you can come up with the the state to be.",
            "In this case we just use the gyroscopic signals of the three axes of the gyroscopic signal to be the vector for the state in the second part of the talk will include even the joint angles and the foot pressure sensor and so on.",
            "And then the action is basically the low dimensional representation of the joint angle.",
            "So using server based command paradigm.",
            "So it's going to be just the action the dimensional leg."
        ],
        [
            "Space.",
            "And what about the optimization procedure?",
            "So we have this model that predicts now, so we're learning a function that is now predicting what the next state is going to be, so it's the next step prediction that we're doing using the radial basis function network and the optimization criterion is quite simple, so we're going to optimize, essentially based on the gyroscopic signal so the output remember is the state at time T, plus one is basically the.",
            "The three values for the gyroscopic signal, so we're just going to make the function be awaited squared squared function of the different components of the gyroscopic signal.",
            "What this does is basically measure is a measure of the torso stability, right?",
            "So make sure that you don't have very rapid rotations of the body along those three different axes since we encouraging stability by trying to optimize for the actions that will generate the least amount of the rotation in terms of as measured by these gyroscope signals.",
            "And another important aspect is that we search for the optimal actions only in the neighborhood of the of the trajectory that we are that we obtained from the teacher.",
            "So it only searches in that neighborhood.",
            "And there's of course parameters there in terms of how do you actually measure how much to search for, and so on.",
            "So I'll give an example of how the search seats in."
        ],
        [
            "In the next slide.",
            "So first of all, let's see what happens in terms of The Walking action.",
            "So here's a demonstration of the walk, and this once again is from the motion capture system.",
            "And obviously if you try this just by using a kind of magic approach doesn't work right.",
            "So let me put it back.",
            "Right?"
        ],
        [
            "No good.",
            "So.",
            "Here, so the way that we approach this problem so we start out with a scaled down version of the of the action that you observe, and so you can see that in the case shown at the top, it's basically your scale down the original trajectory down to the point where you get a dynamically stable motion.",
            "So this could be the robot literally taking baby steps, so you never heard the word.",
            "Take baby steps, right?",
            "So we're actually doing this literally.",
            "Hear the robot just takes these very tiny steps, and that's going to be initially a stable motion, but then you can gradually scale up that.",
            "Trajectory and you can see the different scaling up of the trajectory as we as we expand the scale and what that does is it lets you at each of those magnifications you're able to search for and find the optimal stable actions in all those different settings until you get to a point where in our case, in this case, the most we could do was get up to about the last red circles that we saw which closely approximates the original, but not quite identical to the original.",
            "Action for walking."
        ],
        [
            "So in terms of of what that looks like, so here's the original walk.",
            "And then here's what you get after you optimize for a stable actions.",
            "It's not bad.",
            "It's not the best walk you've seen, but it still is a manageable block, right?",
            "So it actually does does this without having to actually have a physics based model of the of its body and its interaction with the frictional forces on the ground and so on."
        ],
        [
            "OK, so we've done other.",
            "I don't have time to go through all the other."
        ],
        [
            "Other examples, but if you talk to choppy there, he'll give you more examples of what other kinds of actions that he said."
        ],
        [
            "So what I'll do what I'll do now is in the in the second part of the talk, I'll give you a variation of this approach, but now using a probabilistic method, right?",
            "So the idea here is once again, we're going to learn a model of the dynamics of the robot in terms of the next date in terms of previous States and actions.",
            "But we're going to embed that within a Bayesian network, So what we're going to do is to model the imitation process itself as a dynamic Bayesian network, and what's shown here is a slice of this network at time step T, and you can see there's an action.",
            "A of tea at the top and then it generates both the demonstrators, States and the observations of T as well as the agent state and the observation of T and the sea of T. There is a constraint node that you can put to constrain the states of the robot to be in a particular range.",
            "So for example, in our case, we'd like the gyroscope readings to be somewhere near 0 so that you maintain stability and so you can add any kind of constraint that you want on the state of the robot by incorporating these additional nodes that.",
            "Impose those constraints on them in a probabilistic manner.",
            "So in our case then the States the observations are.",
            "For example, if you're using vision, it could be observations from the cameras that are then converted to infer states of the of the demonstrator and the States themselves, right are the state consists of the low dimensional joint space.",
            "There's the latent space that I showed you in the previous slides, and then we also add in the gyroscope readings and the foot pressure rating.",
            "So the robot has readings.",
            "It can measure the pressure at different points and it's.",
            "In its feet, and those in turn could be incorporated to provide more information about the stability of the robot.",
            "And those are part of the state space, the robot.",
            "And finally, like I mentioned, the CFG nodes.",
            "These constraint nodes are knows you can incorporate to enforce certain constraints on the states.",
            "In our case, we incorporate these constraints on the gyroscope readings as well as the food pressure."
        ],
        [
            "Our readings and here's the unrolled DBN.",
            "You can see that the same slices now be unrolled overtime, and the place where function approximation comes in, of course, is to learn the forward dynamics, and so you're trying to predict that you're trying to learn the distribution over the next states.",
            "Given the action at time T and the previous state right?",
            "And So what we've used in several different regression models, and so in particular the first ones we tried, the first one we tried was using a Gaussian process based model, and so you can see the typical notation that.",
            "We use for predicting the ITE component of the state at time T given the vector that has the previous state as well as the action you're going to execute and.",
            "And this is done pretty much for all the different components of the state as well.",
            "As I mentioned in the pre."
        ],
        [
            "Slide.",
            "And then once you have a model of the dynamics, right?",
            "So you need to infer the action.",
            "So this is where we do something different from the traditional approach, which is perhaps you could use a variant of reinforcement learning to then figure out the actions and learn a policy, right?",
            "So what we do here is essentially planning based on unrolling the Bayesian network overtime, and then given the observations of the teacher trying and then they learn dynamic model.",
            "You're then going to infer the action, so those are the missing data that you're trying to infer in this.",
            "In this particular case.",
            "And so here's the underlying idea, right?",
            "So you're trying to infer the actions at every time step, given some evidence for your Bayesian network, and the evidence is just the observations of the teacher as well as your as your own state, and then the constraints also are treated as observed variables.",
            "Alright, so any questions.",
            "OK, we can discuss that at the end of your own and then once you've unrolled this network, the question arises how we're actually doing inference in this continuous state and continuous action space, right?",
            "So what we use is a nonparametric belief propagation method.",
            "So this is something that generalizes particle filter based methods for a for essentially a Markov model.",
            "But in this case it's a directed basin network, and so we use this variant of nonparametric building propagation that's also being explored by people.",
            "For example, in the computer vision.",
            "A community.",
            "And the Gaussian process itself is part of this Bayesian network, and so you sample from it to get examples that are then used in the inference process itself, and you're multiplying the messages as part of the belief propagation algorithm, and yeah.",
            "Yeah.",
            "So you're assuming in this case that the demonstrator is actually has a body that's isomorphic to what you have, so they have the same capacities.",
            "It's basically the correspondence assumption right?",
            "And so once you have the observations of the states then you're the same action is being used, and to explain both of the your own states as well as the demonstrator states.",
            "So that's one way of looking at it.",
            "I mean, well, that's only inspiration for this comes from the cognitive science literature.",
            "So there's a hypothesis called the like me hypothesis that one of our collaborators, their name and email's office, suggested that babies and human infants use, and they're trying to imitate an adult or one of their peers, and there's a lot of evidence that we tend to use our own model as a way to to infer the goals or intentions of other people, as well as to do imitation.",
            "So there's this correspondence that we use to do that mapping, and there's some evidence from the mirror neuron system.",
            "Also that speaks to that.",
            "Issue, but that's just a decoration I want on going to that detail.",
            "So the idea here is you're using this graphical model as a way to represent both your forward dynamics as well as a way to infer your action.",
            "So you're also doing the inversion of the forward model through a Bayesian inference process."
        ],
        [
            "And so here's the underlying experimental paradigm.",
            "So you observe the demonstrator, you estimate the kind of MTX, and then you have to initialize the model so the intermediate step here is where you're executing some random actions in the neighborhood of the trajectory of the teacher, and that's called the bootstrapping step.",
            "And once you've done that, then you can iterate through this process where you execute the actions and learn you update your predictive model, and then you again for the actions.",
            "But now you added the constraints of stability in there.",
            "Right, so once you have a rough model of how you behave in the neighborhood of the teachers action, you can.",
            "You can add the constraint such as the stability using the gyroscopic signals.",
            "And you can iterate that process to get better and better at trying to imitate the teacher without falling down for example.",
            "And so I'll just give you a video of.",
            "An example of how you can visualize it."
        ],
        [
            "Process, so here's the teacher demonstration that we saw before and then on the right hand side is the robot again in the simulator, trying to imitate that.",
            "Right, and so it's initially.",
            "It's just exploring the neighborhood of the teachers trajectory and you can see that it actually is not quite there yet, so it's actually.",
            "Executing these actions that are slight variations from what the teacher did, but not not there yet.",
            "And again in this initial phase, there's no constraint on the stability, but after I guess at this point trial number 10 we've imposed the constraint now of trying to have stable oh are near 0 gyroscopic signal.",
            "So the constraint nodes have been turned on and you can see now it gets better and better at getting at the actions that will lead to a more more stable imitation about the teacher did."
        ],
        [
            "And once you've done that, so here's just a quantification of that.",
            "So the Y axis is plotting the balance duration in terms of how long did it remain?",
            "Balance with falling down in the X axis is just the number of trials, and the red red bar.",
            "So just the period where the there was no constraint turned on in terms of trying to be stable, and then the.",
            "Right hand side is what happens when you start.",
            "Once you've learned a decent model, or at least a reasonable model of the of the actions to States and then you've turned on the constraint of stability.",
            "And it does a decent job of remaining stable after around 25 to 30 trials."
        ],
        [
            "And here's just a playback on the real robot.",
            "So once again there's an open loop playback, so there's no feedback involved, and So what we're doing is just testing to see how good is the simulated simulator in actually learning a stable model for the physics of the robot."
        ],
        [
            "And here's just some other examples, so this is an example of sidestepping.",
            "In this case, it's not moving.",
            "To further too much to the side.",
            "And a job is done.",
            "Other work where he's shown ways in which you can actually get to move much faster than what's shown over here.",
            "Here's just a kicking action, right?",
            "So once again.",
            "It's a it's a reasonably stable action.",
            "So one last piece of this.",
            "This research is how do you go from something that's just open loop as demonstrated here, which is based."
        ],
        [
            "Planning by inference and this basic network to learning a policy or something that's reactive, right?",
            "So can we learn close to behaviors that are reactive to the ongoing feedback coming from the sensors?",
            "And so.",
            "One idea you could use this, you could use the output that is the final optimized output from the planner and then the resulting sensory measurements you're making as you're executing your open new behavior, you can have many examples of that, and then you can learn a policy just ate a action policy that's that's going to be captured by, let's say GP or any other."
        ],
        [
            "Regression process and so the underlying task here is you're given examples of a of a task that has a particular parameter.",
            "So as an example, let's say that you're teaching the robot how to lift objects of different weights, right?",
            "So for different kinds of objects in different ways, you might have to change your posture in different ways, and so the teacher is giving examples of this, but not explicitly telling the robot what that parameter is.",
            "So it has two intrinsically know the parameter through measurements.",
            "It makes, right?",
            "So if you're lifting a heavy object, you're going to just oppose.",
            "Based on how heavy that object is, and that's something you know not by reading a label that says 25 KGS or 10 KGS, you get that when you try to lift the object and you know the approximate way that you have to adjust your body too, and so that's the kind of policy that we're trying to get at here in terms of learning based on examples given by the teacher for different weights, but not for some ways that you can test using a function approximator.",
            "And so the idea is to use the planning approach that we described in the previous slides to then infer stable actions and states for different demonstrated values of some underlying parameter data, such as the weight of the object, and then you encode that using a regressor such as a Gaussian process based policy that then Maps any particular state that you're measuring in terms of your sensors to a particular action.",
            "So the this particular term here is just the IAT component of the action that's represented as a.",
            "As you got in process."
        ],
        [
            "And so here is just an example of that where you're not showing the actual object that is being carried here, so the object itself would be in this case simulated by imposing a weight on the hands of the robot, so we can do that in the simulator.",
            "You can make the hand as heavy as possible, right?",
            "So we're not really plotting the actual visual object itself, but if you plan on a particular wait, let's say zero KGS and then you get the robot to lift something heavier such as 7.5 KGS heavier, you can see it doesn't really work right.",
            "So you have to actually re plan that strategy or get in.",
            "Demonstration from the teacher, and so here's an example where I'm showing."
        ],
        [
            "You the three dimensional representation of this lifting action and the trajectory is shown.",
            "So there's one that's blue.",
            "That is the trajectory for, you know, wait, you're just sort of imagining your lifting away and then you're showing if you show the robot another trajectory that's now a planned weight of 1 cagey so there's a slight shift in the posture of the teacher, and you can see that that's given by a slightly different trajectory for a heavier weight.",
            "These are the two projectors that are then shown to the robot, and then you do the.",
            "Planning process and infer the appropriate actions, but once you've learned that that state to action mapping are using the Gaussian process policy, you can then give it a different way, such as a .5 Katie that's intermediate between the two training weights, and you can see that it actually is able to map out a different trajectory based on this different weight.",
            "And so here is just a depiction of that, right?",
            "So you can see that if."
        ],
        [
            "It's now asked to lift a slightly different object.",
            "It can actually do that, so that's just a just a video of that, right so?",
            "It's given different examples of objects being lifted, and then it's only and then it's asked to lift an object that's a different weight, so you can stack stack multiple bricks on there.",
            "If you want to make it heavier or lighter, and so on.",
            "Send email."
        ],
        [
            "I'll conclude by just summarizing, so the goal here is to show that you may be able to achieve full body humanoid imitation without having to use a physics based model, but relying on this idea that learn the forward model first, or learn the dynamics model first, and then invert that model using.",
            "Probabilistic approach or some other optimization approaches.",
            "The one I described in the first part of the talk.",
            "Anne.",
            "In both these cases, the functional approximation techniques are crucial because you're using them to learn the forward model as well as in our case, to also do the inference in a DBN framework.",
            "And you can also use similar techniques for learning policies, or in this case the planning gives you examples of States and actions, and you can then encode that using function approximation techniques to learn these policies that then generalize to other regions of the state space that are not explicitly demonstrated by the teacher.",
            "And then demonstrate reduction turns out to be quite crucial, because otherwise you end up with having to deal with these very large high degrees of freedom of the robot, and so learning and inference may become intractable in those cases.",
            "And of course there's a whole bunch of other open issues and challenges, right?",
            "So, for example, this is really scale up to large numbers of actions.",
            "Can you do learning on the real robot so as opposed to only on the simulator and then just doing open loop control?",
            "How do you actually transition between different actions such as walking and then lifting an object and then combining different actions?",
            "Can you look at some kind of a hierarchical control system that can compose different actions you've learned from the teacher and then create a a task?",
            "Create a solution for attack that's a novel?",
            "To add that the robot has not encountered before, so there's a lot of interesting issues and you can sort of look at the kinds of approaches that I've shown here as being sort of the very first and lowest level step towards learning a Dictionary of actions or or a set of actions that can then perhaps be composed and generalized to solve more complex tasks.",
            "So that's basically thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, thank you all for coming in like this.",
                    "label": 0
                },
                {
                    "sent": "Thank the organizers for inviting me and.",
                    "label": 0
                },
                {
                    "sent": "There we go.",
                    "label": 0
                },
                {
                    "sent": "So what I'll talk about today is some work that we've been doing over the last few years on applying ideas from functional approximation.",
                    "label": 0
                },
                {
                    "sent": "But to the problem of imitation learning in a humanoid robot, and the work that will describe was done predominantly by a two graduate students, so one is.",
                    "label": 0
                },
                {
                    "sent": "Robbie Shorey child, who's actually sitting right there and the other person, is David Grimes, actually graduated, and he's now the startup company and funding for this research has been provided by on our NSF and the Packet Foundation.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the problem that we would like to solve the problem of programming humanoid robot through demonstration.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You could do this using cameras, for example using one or or stereo pair of cameras and trying to capture human motion, and that's a very difficult problem.",
                    "label": 0
                },
                {
                    "sent": "That computer vision researchers have been trying to solve for a long time.",
                    "label": 0
                },
                {
                    "sent": "What we're doing here is to get around the problem by using a motion capture system that gives you the information about human motion directly.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The particular robot that we're going to use for the results that I'll describe as a hope to humanoid robot.",
                    "label": 0
                },
                {
                    "sent": "It's manufactured by Fujitsu, and it's actually a miniature robot about 2 feet in height.",
                    "label": 0
                },
                {
                    "sent": "So if you come to the lab tours on Tuesday, you'll get a glimpse of that robot in action and on the left is shown David Grimes wearing a motion capture suit, and you can see that they're reflective markers that allow us to capture the emotion.",
                    "label": 0
                },
                {
                    "sent": "And and infer the joint angles based on the information from motion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For system.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of what you get.",
                    "label": 1
                },
                {
                    "sent": "So if you have a demonstration such as this one where the demonstrator is, for example, just balancing on one leg seems like a pretty simple sort of simple action, right?",
                    "label": 0
                },
                {
                    "sent": "You can recover the joint angles and then try to play that back, and you can imagine what would happen, right?",
                    "label": 0
                },
                {
                    "sent": "So there's just a kind of Matic playback of the recovered action in a simulator.",
                    "label": 0
                },
                {
                    "sent": "It won't work right?",
                    "label": 0
                },
                {
                    "sent": "So basically the dynamics don't match, and so if you are just playing back what you get from a motion capture.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that doesn't work, and so here's what we're trying to achieve through the research that I'll describe.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we'd like to learn from the teacher, but only through the observations of the teacher, and not really allowing the teacher to control the robot.",
                    "label": 1
                },
                {
                    "sent": "So so for example, if I ask you to imitate me, right?",
                    "label": 0
                },
                {
                    "sent": "So let's say I clap my hand.",
                    "label": 0
                },
                {
                    "sent": "Right, you can do that, right?",
                    "label": 0
                },
                {
                    "sent": "I'm not controlling you using a joystick, right?",
                    "label": 0
                },
                {
                    "sent": "So that's the idea here is that we are trying to learn by observing another robot or another human without actually being remote controlled by an expert or a human, and it's also been called the problem of implicit limitation because you don't have access to the actions.",
                    "label": 0
                },
                {
                    "sent": "What you have access to all the states or the observations of the states of an expert or or teacher.",
                    "label": 0
                },
                {
                    "sent": "And it's very similar to how humans are learned by watching other humans or their peers.",
                    "label": 1
                },
                {
                    "sent": "And also we would like to avoid using physics based models, so we might not really have very accurate models of the the different limb joints in the actual mass and the inertia of the different parts of the robot.",
                    "label": 0
                },
                {
                    "sent": "And So what we would like to do is to learn directly based on the dynamics that were encoding in terms of the sensory consequences of the action.",
                    "label": 1
                },
                {
                    "sent": "So in other words, we're trying to learn first of all a so called forward model of the system, so the dynamics of the system and we're going to do this without actually basing our model on any kind of knowledge of the physics of the system.",
                    "label": 1
                },
                {
                    "sent": "And then, once you've learned that we'd like to use the demonstrations provided by the teacher to restrict the search space for the feasible Act actions that will allow us to imitate the teacher.",
                    "label": 0
                },
                {
                    "sent": "And this is very similar to what Peter talked about in terms of the trajectory based search for actions.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the first step is solving the so called correspondence problem, right?",
                    "label": 0
                },
                {
                    "sent": "So if you have a human that's demonstrating a particular action, and you would like to come up with a set of constraints or the constraints on the state of the robot.",
                    "label": 0
                },
                {
                    "sent": "So these are basically joint angles for the different angles of the robot, and in a traditional human in a motion capture system, you might get the joint angles based on skeleton, such as the one that's shown on the right of the human right?",
                    "label": 0
                },
                {
                    "sent": "So this product is going to start really match the.",
                    "label": 0
                },
                {
                    "sent": "The apology of robots joining points structure of the robot that we have is different from the structured data is being used to model human centric.",
                    "label": 0
                },
                {
                    "sent": "We could use is to assume that the human is actually a.",
                    "label": 0
                },
                {
                    "sent": "And in large version of the robot, right?",
                    "label": 1
                },
                {
                    "sent": "That's basically what it amounts to.",
                    "label": 0
                },
                {
                    "sent": "So what we're doing is we're assuming the robot is actually the human has the same structure as a robot, and so you have a.",
                    "label": 1
                },
                {
                    "sent": "A schedule that looks like this and then you assume that the markers are on a body that is of that particular skeletal structure, and now you can apply the standard inverse kinematics to get the guesses about the different joint angles.",
                    "label": 1
                },
                {
                    "sent": "For now, the robot body as opposed to the human skeletal body.",
                    "label": 1
                },
                {
                    "sent": "So that's the way in which we in this case or solve the correspondence problem by just hardcoding it to match the.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Structure of the robot.",
                    "label": 0
                },
                {
                    "sent": "The second step is in terms of the dimensionality of what we're getting right, so there's a 25 degrees of freedom robot in our case, and in general it could be much larger, and so if you want to actually optimize this very high dimensional space optimized for actions in the side emotional space, it turns out to be very inefficient, or perhaps even interactable, right?",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "One thing you notice is when you look at these actions being performed by human teachers.",
                    "label": 0
                },
                {
                    "sent": "Most of these actions to be highly redundant.",
                    "label": 1
                },
                {
                    "sent": "If you're restricting to particular classes of actions, I'll give you a few examples in the slice default idea here is could use dimensionality reduction techniques such as even PCA for that matter, to represent the actions that are demonstrated by the human in a low dimensional.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ace so as an example, here's here's that action that I just showed you in terms of balancing on one leg in a 2 dimensional latent space obtained using PCA, and as you can see, the trajectory through the two dimensional space Maps to each of these particular postures, and so in a sense you can cause we call these eigen closes, right?",
                    "label": 0
                },
                {
                    "sent": "So we have eigen faces and you have pretty much anything that is characterized.",
                    "label": 0
                },
                {
                    "sent": "Using PCA can tag and eigen on top of it right?",
                    "label": 0
                },
                {
                    "sent": "So you can call these.",
                    "label": 0
                },
                {
                    "sent": "Like but basically this is a low dimensional representation of the motion of the human.",
                    "label": 0
                },
                {
                    "sent": "In this case shown in a in a depiction of using the human robot in a simulator.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you look at for example other actions in this case, here's an action that is involves motion.",
                    "label": 0
                },
                {
                    "sent": "So there's The Walking action you can see.",
                    "label": 0
                },
                {
                    "sent": "Once again, that now you have a periodic motion, so it is a cyclic motion, so you get a starting point.",
                    "label": 0
                },
                {
                    "sent": "That's down here.",
                    "label": 0
                },
                {
                    "sent": "It's labeled by one, and then as you go up to the point where you start walking, right?",
                    "label": 0
                },
                {
                    "sent": "So you can see the different points along the trajectory map to different postures of the robot as it executes this particular motion.",
                    "label": 0
                },
                {
                    "sent": "And So what?",
                    "label": 0
                },
                {
                    "sent": "This lets us do is it lets us first of all, capture the motion in a low dimensional space, which is going to make it.",
                    "label": 0
                },
                {
                    "sent": "Intractable for more features.",
                    "label": 0
                },
                {
                    "sent": "To learn the dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But and so here's the idea.",
                    "label": 0
                },
                {
                    "sent": "So you first learn a forward model or the dynamics of the robot using the teacher demonstration.",
                    "label": 1
                },
                {
                    "sent": "So this is where we're going to use function approximation techniques to map actions to their observed sensory consequences.",
                    "label": 1
                },
                {
                    "sent": "And once you've learned the model of how your body behaves, then you can use that in a way you can use that to infer the stable actions that will then give you approximation to human action that you just saw, and you can iterate between that between.",
                    "label": 0
                },
                {
                    "sent": "Including the actions that was learning the OR update your forward models at said better, more accurate imitating this feature.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so I'll give you 2 examples of this broad approach.",
                    "label": 0
                },
                {
                    "sent": "So one is using radial basis function network to approximate the dynamics, and this is a deterministic action selection methodology and the second approach I'll talk about is a probabilistic approach to infer actions based on a dynamic basis in network to encode the dynamics of the other robot.",
                    "label": 1
                },
                {
                    "sent": "And so you start out with a NTH order Markov function.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's mapping the.",
                    "label": 0
                },
                {
                    "sent": "States from time step T to some particular previous time step T -- 10 + 1 and the actions for the same time period to the next stage.",
                    "label": 1
                },
                {
                    "sent": "So this is basically the standard and order Markov function.",
                    "label": 0
                },
                {
                    "sent": "So in our case we use a second order for the examples shown in the in the rest of the talk.",
                    "label": 0
                },
                {
                    "sent": "And you can come up with the the state to be.",
                    "label": 0
                },
                {
                    "sent": "In this case we just use the gyroscopic signals of the three axes of the gyroscopic signal to be the vector for the state in the second part of the talk will include even the joint angles and the foot pressure sensor and so on.",
                    "label": 0
                },
                {
                    "sent": "And then the action is basically the low dimensional representation of the joint angle.",
                    "label": 0
                },
                {
                    "sent": "So using server based command paradigm.",
                    "label": 0
                },
                {
                    "sent": "So it's going to be just the action the dimensional leg.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "And what about the optimization procedure?",
                    "label": 0
                },
                {
                    "sent": "So we have this model that predicts now, so we're learning a function that is now predicting what the next state is going to be, so it's the next step prediction that we're doing using the radial basis function network and the optimization criterion is quite simple, so we're going to optimize, essentially based on the gyroscopic signal so the output remember is the state at time T, plus one is basically the.",
                    "label": 0
                },
                {
                    "sent": "The three values for the gyroscopic signal, so we're just going to make the function be awaited squared squared function of the different components of the gyroscopic signal.",
                    "label": 0
                },
                {
                    "sent": "What this does is basically measure is a measure of the torso stability, right?",
                    "label": 0
                },
                {
                    "sent": "So make sure that you don't have very rapid rotations of the body along those three different axes since we encouraging stability by trying to optimize for the actions that will generate the least amount of the rotation in terms of as measured by these gyroscope signals.",
                    "label": 0
                },
                {
                    "sent": "And another important aspect is that we search for the optimal actions only in the neighborhood of the of the trajectory that we are that we obtained from the teacher.",
                    "label": 0
                },
                {
                    "sent": "So it only searches in that neighborhood.",
                    "label": 0
                },
                {
                    "sent": "And there's of course parameters there in terms of how do you actually measure how much to search for, and so on.",
                    "label": 0
                },
                {
                    "sent": "So I'll give an example of how the search seats in.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the next slide.",
                    "label": 0
                },
                {
                    "sent": "So first of all, let's see what happens in terms of The Walking action.",
                    "label": 0
                },
                {
                    "sent": "So here's a demonstration of the walk, and this once again is from the motion capture system.",
                    "label": 1
                },
                {
                    "sent": "And obviously if you try this just by using a kind of magic approach doesn't work right.",
                    "label": 0
                },
                {
                    "sent": "So let me put it back.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No good.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Here, so the way that we approach this problem so we start out with a scaled down version of the of the action that you observe, and so you can see that in the case shown at the top, it's basically your scale down the original trajectory down to the point where you get a dynamically stable motion.",
                    "label": 0
                },
                {
                    "sent": "So this could be the robot literally taking baby steps, so you never heard the word.",
                    "label": 1
                },
                {
                    "sent": "Take baby steps, right?",
                    "label": 0
                },
                {
                    "sent": "So we're actually doing this literally.",
                    "label": 0
                },
                {
                    "sent": "Hear the robot just takes these very tiny steps, and that's going to be initially a stable motion, but then you can gradually scale up that.",
                    "label": 0
                },
                {
                    "sent": "Trajectory and you can see the different scaling up of the trajectory as we as we expand the scale and what that does is it lets you at each of those magnifications you're able to search for and find the optimal stable actions in all those different settings until you get to a point where in our case, in this case, the most we could do was get up to about the last red circles that we saw which closely approximates the original, but not quite identical to the original.",
                    "label": 0
                },
                {
                    "sent": "Action for walking.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in terms of of what that looks like, so here's the original walk.",
                    "label": 0
                },
                {
                    "sent": "And then here's what you get after you optimize for a stable actions.",
                    "label": 0
                },
                {
                    "sent": "It's not bad.",
                    "label": 0
                },
                {
                    "sent": "It's not the best walk you've seen, but it still is a manageable block, right?",
                    "label": 0
                },
                {
                    "sent": "So it actually does does this without having to actually have a physics based model of the of its body and its interaction with the frictional forces on the ground and so on.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we've done other.",
                    "label": 0
                },
                {
                    "sent": "I don't have time to go through all the other.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other examples, but if you talk to choppy there, he'll give you more examples of what other kinds of actions that he said.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'll do what I'll do now is in the in the second part of the talk, I'll give you a variation of this approach, but now using a probabilistic method, right?",
                    "label": 0
                },
                {
                    "sent": "So the idea here is once again, we're going to learn a model of the dynamics of the robot in terms of the next date in terms of previous States and actions.",
                    "label": 0
                },
                {
                    "sent": "But we're going to embed that within a Bayesian network, So what we're going to do is to model the imitation process itself as a dynamic Bayesian network, and what's shown here is a slice of this network at time step T, and you can see there's an action.",
                    "label": 1
                },
                {
                    "sent": "A of tea at the top and then it generates both the demonstrators, States and the observations of T as well as the agent state and the observation of T and the sea of T. There is a constraint node that you can put to constrain the states of the robot to be in a particular range.",
                    "label": 0
                },
                {
                    "sent": "So for example, in our case, we'd like the gyroscope readings to be somewhere near 0 so that you maintain stability and so you can add any kind of constraint that you want on the state of the robot by incorporating these additional nodes that.",
                    "label": 0
                },
                {
                    "sent": "Impose those constraints on them in a probabilistic manner.",
                    "label": 0
                },
                {
                    "sent": "So in our case then the States the observations are.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're using vision, it could be observations from the cameras that are then converted to infer states of the of the demonstrator and the States themselves, right are the state consists of the low dimensional joint space.",
                    "label": 0
                },
                {
                    "sent": "There's the latent space that I showed you in the previous slides, and then we also add in the gyroscope readings and the foot pressure rating.",
                    "label": 0
                },
                {
                    "sent": "So the robot has readings.",
                    "label": 0
                },
                {
                    "sent": "It can measure the pressure at different points and it's.",
                    "label": 0
                },
                {
                    "sent": "In its feet, and those in turn could be incorporated to provide more information about the stability of the robot.",
                    "label": 0
                },
                {
                    "sent": "And those are part of the state space, the robot.",
                    "label": 0
                },
                {
                    "sent": "And finally, like I mentioned, the CFG nodes.",
                    "label": 0
                },
                {
                    "sent": "These constraint nodes are knows you can incorporate to enforce certain constraints on the states.",
                    "label": 0
                },
                {
                    "sent": "In our case, we incorporate these constraints on the gyroscope readings as well as the food pressure.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our readings and here's the unrolled DBN.",
                    "label": 0
                },
                {
                    "sent": "You can see that the same slices now be unrolled overtime, and the place where function approximation comes in, of course, is to learn the forward dynamics, and so you're trying to predict that you're trying to learn the distribution over the next states.",
                    "label": 0
                },
                {
                    "sent": "Given the action at time T and the previous state right?",
                    "label": 0
                },
                {
                    "sent": "And So what we've used in several different regression models, and so in particular the first ones we tried, the first one we tried was using a Gaussian process based model, and so you can see the typical notation that.",
                    "label": 0
                },
                {
                    "sent": "We use for predicting the ITE component of the state at time T given the vector that has the previous state as well as the action you're going to execute and.",
                    "label": 0
                },
                {
                    "sent": "And this is done pretty much for all the different components of the state as well.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned in the pre.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Slide.",
                    "label": 0
                },
                {
                    "sent": "And then once you have a model of the dynamics, right?",
                    "label": 0
                },
                {
                    "sent": "So you need to infer the action.",
                    "label": 0
                },
                {
                    "sent": "So this is where we do something different from the traditional approach, which is perhaps you could use a variant of reinforcement learning to then figure out the actions and learn a policy, right?",
                    "label": 0
                },
                {
                    "sent": "So what we do here is essentially planning based on unrolling the Bayesian network overtime, and then given the observations of the teacher trying and then they learn dynamic model.",
                    "label": 0
                },
                {
                    "sent": "You're then going to infer the action, so those are the missing data that you're trying to infer in this.",
                    "label": 0
                },
                {
                    "sent": "In this particular case.",
                    "label": 0
                },
                {
                    "sent": "And so here's the underlying idea, right?",
                    "label": 0
                },
                {
                    "sent": "So you're trying to infer the actions at every time step, given some evidence for your Bayesian network, and the evidence is just the observations of the teacher as well as your as your own state, and then the constraints also are treated as observed variables.",
                    "label": 0
                },
                {
                    "sent": "Alright, so any questions.",
                    "label": 0
                },
                {
                    "sent": "OK, we can discuss that at the end of your own and then once you've unrolled this network, the question arises how we're actually doing inference in this continuous state and continuous action space, right?",
                    "label": 0
                },
                {
                    "sent": "So what we use is a nonparametric belief propagation method.",
                    "label": 1
                },
                {
                    "sent": "So this is something that generalizes particle filter based methods for a for essentially a Markov model.",
                    "label": 0
                },
                {
                    "sent": "But in this case it's a directed basin network, and so we use this variant of nonparametric building propagation that's also being explored by people.",
                    "label": 0
                },
                {
                    "sent": "For example, in the computer vision.",
                    "label": 0
                },
                {
                    "sent": "A community.",
                    "label": 0
                },
                {
                    "sent": "And the Gaussian process itself is part of this Bayesian network, and so you sample from it to get examples that are then used in the inference process itself, and you're multiplying the messages as part of the belief propagation algorithm, and yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So you're assuming in this case that the demonstrator is actually has a body that's isomorphic to what you have, so they have the same capacities.",
                    "label": 0
                },
                {
                    "sent": "It's basically the correspondence assumption right?",
                    "label": 0
                },
                {
                    "sent": "And so once you have the observations of the states then you're the same action is being used, and to explain both of the your own states as well as the demonstrator states.",
                    "label": 0
                },
                {
                    "sent": "So that's one way of looking at it.",
                    "label": 0
                },
                {
                    "sent": "I mean, well, that's only inspiration for this comes from the cognitive science literature.",
                    "label": 0
                },
                {
                    "sent": "So there's a hypothesis called the like me hypothesis that one of our collaborators, their name and email's office, suggested that babies and human infants use, and they're trying to imitate an adult or one of their peers, and there's a lot of evidence that we tend to use our own model as a way to to infer the goals or intentions of other people, as well as to do imitation.",
                    "label": 0
                },
                {
                    "sent": "So there's this correspondence that we use to do that mapping, and there's some evidence from the mirror neuron system.",
                    "label": 0
                },
                {
                    "sent": "Also that speaks to that.",
                    "label": 0
                },
                {
                    "sent": "Issue, but that's just a decoration I want on going to that detail.",
                    "label": 0
                },
                {
                    "sent": "So the idea here is you're using this graphical model as a way to represent both your forward dynamics as well as a way to infer your action.",
                    "label": 0
                },
                {
                    "sent": "So you're also doing the inversion of the forward model through a Bayesian inference process.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so here's the underlying experimental paradigm.",
                    "label": 0
                },
                {
                    "sent": "So you observe the demonstrator, you estimate the kind of MTX, and then you have to initialize the model so the intermediate step here is where you're executing some random actions in the neighborhood of the trajectory of the teacher, and that's called the bootstrapping step.",
                    "label": 0
                },
                {
                    "sent": "And once you've done that, then you can iterate through this process where you execute the actions and learn you update your predictive model, and then you again for the actions.",
                    "label": 0
                },
                {
                    "sent": "But now you added the constraints of stability in there.",
                    "label": 0
                },
                {
                    "sent": "Right, so once you have a rough model of how you behave in the neighborhood of the teachers action, you can.",
                    "label": 0
                },
                {
                    "sent": "You can add the constraint such as the stability using the gyroscopic signals.",
                    "label": 0
                },
                {
                    "sent": "And you can iterate that process to get better and better at trying to imitate the teacher without falling down for example.",
                    "label": 0
                },
                {
                    "sent": "And so I'll just give you a video of.",
                    "label": 0
                },
                {
                    "sent": "An example of how you can visualize it.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Process, so here's the teacher demonstration that we saw before and then on the right hand side is the robot again in the simulator, trying to imitate that.",
                    "label": 0
                },
                {
                    "sent": "Right, and so it's initially.",
                    "label": 0
                },
                {
                    "sent": "It's just exploring the neighborhood of the teachers trajectory and you can see that it actually is not quite there yet, so it's actually.",
                    "label": 0
                },
                {
                    "sent": "Executing these actions that are slight variations from what the teacher did, but not not there yet.",
                    "label": 0
                },
                {
                    "sent": "And again in this initial phase, there's no constraint on the stability, but after I guess at this point trial number 10 we've imposed the constraint now of trying to have stable oh are near 0 gyroscopic signal.",
                    "label": 0
                },
                {
                    "sent": "So the constraint nodes have been turned on and you can see now it gets better and better at getting at the actions that will lead to a more more stable imitation about the teacher did.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And once you've done that, so here's just a quantification of that.",
                    "label": 0
                },
                {
                    "sent": "So the Y axis is plotting the balance duration in terms of how long did it remain?",
                    "label": 0
                },
                {
                    "sent": "Balance with falling down in the X axis is just the number of trials, and the red red bar.",
                    "label": 0
                },
                {
                    "sent": "So just the period where the there was no constraint turned on in terms of trying to be stable, and then the.",
                    "label": 0
                },
                {
                    "sent": "Right hand side is what happens when you start.",
                    "label": 0
                },
                {
                    "sent": "Once you've learned a decent model, or at least a reasonable model of the of the actions to States and then you've turned on the constraint of stability.",
                    "label": 0
                },
                {
                    "sent": "And it does a decent job of remaining stable after around 25 to 30 trials.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's just a playback on the real robot.",
                    "label": 0
                },
                {
                    "sent": "So once again there's an open loop playback, so there's no feedback involved, and So what we're doing is just testing to see how good is the simulated simulator in actually learning a stable model for the physics of the robot.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here's just some other examples, so this is an example of sidestepping.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's not moving.",
                    "label": 0
                },
                {
                    "sent": "To further too much to the side.",
                    "label": 0
                },
                {
                    "sent": "And a job is done.",
                    "label": 0
                },
                {
                    "sent": "Other work where he's shown ways in which you can actually get to move much faster than what's shown over here.",
                    "label": 0
                },
                {
                    "sent": "Here's just a kicking action, right?",
                    "label": 0
                },
                {
                    "sent": "So once again.",
                    "label": 0
                },
                {
                    "sent": "It's a it's a reasonably stable action.",
                    "label": 0
                },
                {
                    "sent": "So one last piece of this.",
                    "label": 0
                },
                {
                    "sent": "This research is how do you go from something that's just open loop as demonstrated here, which is based.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Planning by inference and this basic network to learning a policy or something that's reactive, right?",
                    "label": 1
                },
                {
                    "sent": "So can we learn close to behaviors that are reactive to the ongoing feedback coming from the sensors?",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "One idea you could use this, you could use the output that is the final optimized output from the planner and then the resulting sensory measurements you're making as you're executing your open new behavior, you can have many examples of that, and then you can learn a policy just ate a action policy that's that's going to be captured by, let's say GP or any other.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regression process and so the underlying task here is you're given examples of a of a task that has a particular parameter.",
                    "label": 0
                },
                {
                    "sent": "So as an example, let's say that you're teaching the robot how to lift objects of different weights, right?",
                    "label": 1
                },
                {
                    "sent": "So for different kinds of objects in different ways, you might have to change your posture in different ways, and so the teacher is giving examples of this, but not explicitly telling the robot what that parameter is.",
                    "label": 0
                },
                {
                    "sent": "So it has two intrinsically know the parameter through measurements.",
                    "label": 0
                },
                {
                    "sent": "It makes, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're lifting a heavy object, you're going to just oppose.",
                    "label": 0
                },
                {
                    "sent": "Based on how heavy that object is, and that's something you know not by reading a label that says 25 KGS or 10 KGS, you get that when you try to lift the object and you know the approximate way that you have to adjust your body too, and so that's the kind of policy that we're trying to get at here in terms of learning based on examples given by the teacher for different weights, but not for some ways that you can test using a function approximator.",
                    "label": 0
                },
                {
                    "sent": "And so the idea is to use the planning approach that we described in the previous slides to then infer stable actions and states for different demonstrated values of some underlying parameter data, such as the weight of the object, and then you encode that using a regressor such as a Gaussian process based policy that then Maps any particular state that you're measuring in terms of your sensors to a particular action.",
                    "label": 1
                },
                {
                    "sent": "So the this particular term here is just the IAT component of the action that's represented as a.",
                    "label": 0
                },
                {
                    "sent": "As you got in process.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so here is just an example of that where you're not showing the actual object that is being carried here, so the object itself would be in this case simulated by imposing a weight on the hands of the robot, so we can do that in the simulator.",
                    "label": 0
                },
                {
                    "sent": "You can make the hand as heavy as possible, right?",
                    "label": 0
                },
                {
                    "sent": "So we're not really plotting the actual visual object itself, but if you plan on a particular wait, let's say zero KGS and then you get the robot to lift something heavier such as 7.5 KGS heavier, you can see it doesn't really work right.",
                    "label": 0
                },
                {
                    "sent": "So you have to actually re plan that strategy or get in.",
                    "label": 0
                },
                {
                    "sent": "Demonstration from the teacher, and so here's an example where I'm showing.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You the three dimensional representation of this lifting action and the trajectory is shown.",
                    "label": 0
                },
                {
                    "sent": "So there's one that's blue.",
                    "label": 0
                },
                {
                    "sent": "That is the trajectory for, you know, wait, you're just sort of imagining your lifting away and then you're showing if you show the robot another trajectory that's now a planned weight of 1 cagey so there's a slight shift in the posture of the teacher, and you can see that that's given by a slightly different trajectory for a heavier weight.",
                    "label": 0
                },
                {
                    "sent": "These are the two projectors that are then shown to the robot, and then you do the.",
                    "label": 0
                },
                {
                    "sent": "Planning process and infer the appropriate actions, but once you've learned that that state to action mapping are using the Gaussian process policy, you can then give it a different way, such as a .5 Katie that's intermediate between the two training weights, and you can see that it actually is able to map out a different trajectory based on this different weight.",
                    "label": 1
                },
                {
                    "sent": "And so here is just a depiction of that, right?",
                    "label": 0
                },
                {
                    "sent": "So you can see that if.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's now asked to lift a slightly different object.",
                    "label": 0
                },
                {
                    "sent": "It can actually do that, so that's just a just a video of that, right so?",
                    "label": 0
                },
                {
                    "sent": "It's given different examples of objects being lifted, and then it's only and then it's asked to lift an object that's a different weight, so you can stack stack multiple bricks on there.",
                    "label": 0
                },
                {
                    "sent": "If you want to make it heavier or lighter, and so on.",
                    "label": 0
                },
                {
                    "sent": "Send email.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll conclude by just summarizing, so the goal here is to show that you may be able to achieve full body humanoid imitation without having to use a physics based model, but relying on this idea that learn the forward model first, or learn the dynamics model first, and then invert that model using.",
                    "label": 1
                },
                {
                    "sent": "Probabilistic approach or some other optimization approaches.",
                    "label": 0
                },
                {
                    "sent": "The one I described in the first part of the talk.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "In both these cases, the functional approximation techniques are crucial because you're using them to learn the forward model as well as in our case, to also do the inference in a DBN framework.",
                    "label": 1
                },
                {
                    "sent": "And you can also use similar techniques for learning policies, or in this case the planning gives you examples of States and actions, and you can then encode that using function approximation techniques to learn these policies that then generalize to other regions of the state space that are not explicitly demonstrated by the teacher.",
                    "label": 1
                },
                {
                    "sent": "And then demonstrate reduction turns out to be quite crucial, because otherwise you end up with having to deal with these very large high degrees of freedom of the robot, and so learning and inference may become intractable in those cases.",
                    "label": 0
                },
                {
                    "sent": "And of course there's a whole bunch of other open issues and challenges, right?",
                    "label": 1
                },
                {
                    "sent": "So, for example, this is really scale up to large numbers of actions.",
                    "label": 0
                },
                {
                    "sent": "Can you do learning on the real robot so as opposed to only on the simulator and then just doing open loop control?",
                    "label": 0
                },
                {
                    "sent": "How do you actually transition between different actions such as walking and then lifting an object and then combining different actions?",
                    "label": 0
                },
                {
                    "sent": "Can you look at some kind of a hierarchical control system that can compose different actions you've learned from the teacher and then create a a task?",
                    "label": 0
                },
                {
                    "sent": "Create a solution for attack that's a novel?",
                    "label": 0
                },
                {
                    "sent": "To add that the robot has not encountered before, so there's a lot of interesting issues and you can sort of look at the kinds of approaches that I've shown here as being sort of the very first and lowest level step towards learning a Dictionary of actions or or a set of actions that can then perhaps be composed and generalized to solve more complex tasks.",
                    "label": 0
                },
                {
                    "sent": "So that's basically thanks.",
                    "label": 0
                }
            ]
        }
    }
}